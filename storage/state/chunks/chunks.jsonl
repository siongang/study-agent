{"chunk_id":"4b93df37828d18f0","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"QUANTUM MECHANICS\nA Paradigms Approach\n","page_start":3,"page_end":3,"token_count":13,"section_type":"other","chapter_number":1,"chapter_title":"Stern-Gerlach Experiments","chunk_index":0}
{"chunk_id":"e6ce0acfdaa8391e","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"This page intentionally left blank \n","page_start":4,"page_end":4,"token_count":6,"section_type":"other","chapter_number":1,"chapter_title":"Stern-Gerlach Experiments","chunk_index":1}
{"chunk_id":"229aa98bf39d13eb","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"Boston   Columbus   Indianapolis   New York   San Francisco   Upper Saddle River  \nAmsterdam   Cape Town   Dubai   London   Madrid   Milan   Munich   Paris   Montréal   Toronto  \nDelhi   Mexico City   São Paulo   Sydney   Hong Kong   Seoul   Singapore   Taipei   Tokyo\nQUANTUM MECHANICS\nA Paradigms Approach\nDavid H. McIntyre\nOregon State University\nwith contributions from Corinne A. Manogue, Janet Tate  \nand the Paradigms in Physics group at Oregon State University\n","page_start":5,"page_end":5,"token_count":111,"section_type":"other","chapter_number":1,"chapter_title":"Stern-Gerlach Experiments","chunk_index":2}
{"chunk_id":"48e11f841657080b","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"Publisher: Jim Smith\nEditorial Manager: Laura Kenney\nSenior Project Editor: Katie Conley\nAssistant Editors: Peter Alston and Steven Le\nSenior Marketing Manager: Kerry McGinnis\nManaging Editor: Corinne Benson\nProduction Project Manager: Mary O’Connell\nProduction Management and Composition: \nElement LLC\nCover Design: Mark Ong\nManufacturing Buyer: Kathy Sleys\nManager, Rights and Permissions: Zina Arabia\nManager, Cover Visual Research & \nPermissions: Karen Sanatar\nPrinter and Binder: Courier, Westford\nCover Printer: Courier, Westford\nCover Images: David H. McIntyre\nCopyright © 2012 Pearson Education, Inc., publishing as Pearson Addison-Wesley, 1301 Sansome St., San Francisco, \nCA 94111. All rights reserved. Manufactured in the United States of America. This publication is protected by Copyright \nand permission should be obtained from the publisher prior to any prohibited reproduction, storage in a retrieval system, \nor transmission in any form or by any means, electronic, mechanical, photocopying, recording, or likewise. To obtain \npermission(s) to use material from this work, please submit a written request to Pearson Education, Inc., Permissions \nDepartment, 1900 E. Lake Ave., Glenview, IL 60025. For information regarding permissions, call (847) 486-2635.\nMany of the designations used by manufacturers and sellers to distinguish their products are claimed as trademarks. Where \nthose designations appear in this book, and the publisher was aware of a trademark claim, the designations have been printed \nin initial caps or all caps.\nLibrary of Congress Cataloging-in-Publication Data\nMcIntyre, David H.\n Quantum mechanics : a paradigms approach / David H. McIntyre ; with  \ncontributions from Corinne A. Manogue, Janet Tate, and the Paradigms in \nPhysics group at Oregon State University.\n  p. cm.\n Includes bibliographical references and index.\n ISBN-13: 978-0-321-76579-6\n ISBN-10: 0-321-76579-6\n 1. Quantum theory. 2. Mechanics.  I. Manogue, Corinne A. II. Tate, Janet.\nIII. Oregon State University. IV. Title.\n QC174.12.M3785 2012\n 530.12--dc23\n                2011039322\nISBN 10: 0-321-76579-6  \nISBN 13: 978-0-321-76579-6\n1 2 3 4 5 6 7 8 9 10 —CRW—16 15 14 13 12 11\nwww.pearsonhighered.com\n","page_start":6,"page_end":6,"token_count":579,"section_type":"other","chapter_number":1,"chapter_title":"Stern-Gerlach Experiments","chunk_index":3}
{"chunk_id":"71c4e8d157535bed","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":" \nv\n Brief Contents\n 1 Stern-Gerlach Experiments \n1\n 2 Operators and Measurement \n34\n 3 Schrödinger Time Evolution \n68\n 4 Quantum Spookiness \n97\n 5 Quantized Energies: Particle in a Box \n107\n 6 Unbound States \n161\n 7 Angular Momentum \n202\n 8 Hydrogen Atom \n250\n 9 Harmonic Oscillator \n275\n 10 Perturbation Theory \n312\n 11 Hyperﬁne Structure and the Addition of Angular Momenta \n355\n 12 Perturbation of Hydrogen \n382\n 13 Identical Particles \n410\n 14 Time-Dependent Perturbation Theory \n445\n 15 Periodic Systems \n469\n 16 Modern Applications of Quantum Mechanics \n502\nAppendices \n529\nIndex \n553\n","page_start":7,"page_end":7,"token_count":176,"section_type":"other","chapter_number":1,"chapter_title":"Stern-Gerlach Experiments","chunk_index":4}
{"chunk_id":"20af394f96f25e69","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"This page intentionally left blank \n","page_start":8,"page_end":8,"token_count":6,"section_type":"other","chapter_number":1,"chapter_title":"Stern-Gerlach Experiments","chunk_index":5}
{"chunk_id":"75be35fc01756ab0","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":" \nvii\nContents\nPreface \nxiii\nPrologue \nxix\n \n1 \u0002 Stern-Gerlach Experiments \n1\n1.1 \nStern-Gerlach Experiment 1\n1.1.1 \nExperiment 1 5\n1.1.2 \nExperiment 2 6\n1.1.3 \nExperiment 3 7\n1.1.4 \nExperiment 4 8\n1.2 \nQuantum State Vectors 10\n1.2.1 \nAnalysis of Experiment 1 16\n1.2.2 \nAnalysis of Experiment 2 16\n1.2.3 \nSuperposition States 19\n1.3 \nMatrix Notation 22\n1.4 \nGeneral Quantum Systems 25\n1.5 \nPostulates  27\nSummary 28\nProblems 29\nResources 32\nActivities 32\nFurther Reading 33\n \n2 \u0002 Operators and Measurement \n34\n2.1 \nOperators, Eigenvalues, and Eigenvectors 34\n2.1.1 \nMatrix Representation of Operators 37\n2.1.2 \nDiagonalization of Operators 38\n2.2 \nNew Operators 41\n2.2.1 \nSpin Component in a General Direction 41\n2.2.2 \nHermitian Operators 44\n2.2.3 \nProjection Operators 44\n2.2.4 \nAnalysis of Experiments 3 and 4 47\n2.3 \nMeasurement 50\n2.4 \nCommuting Observables 54\n2.5 \nUncertainty Principle 56\n2.6 \nS2 Operator 57\n2.7 \nSpin-1 System 59\n","page_start":9,"page_end":9,"token_count":366,"section_type":"other","chapter_number":1,"chapter_title":"Stern-Gerlach Experiments","chunk_index":6}
{"chunk_id":"c4d5219e935882a1","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"viii \nContents \n2.8 \nGeneral Quantum Systems 62\nSummary 63\nProblems 64\nResources 67\nActivities 67\n \n3 \u0002 Schrödinger Time Evolution \n68\n3.1 \nSchrödinger Equation 68\n3.2 \nSpin Precession 72\n3.2.1 \nMagnetic Field in the z-Direction 72\n3.2.2 \nMagnetic Field in a General Direction 78\n3.3 \nNeutrino Oscillations 84\n3.4 \nTime-Dependent Hamiltonians 87\n3.4.1 \nMagnetic Resonance 87\n3.4.2 \nLight-Matter Interactions 92\nSummary 93\nProblems 94\nResources 96\nActivities 96\nFurther Reading 96\n \n4 \u0002 Quantum Spookiness \n97\n4.1 \nEinstein-Podolsky-Rosen Paradox 97\n4.2 \nSchrödinger Cat Paradox 102\nProblems 105\nResources 106\nFurther Reading 106\n \n5 \u0002 Quantized Energies: Particle in a Box \n107\n5.1 \nSpectroscopy 107\n5.2 \nEnergy Eigenvalue Equation 110\n5.3 \nThe Wave Function 112\n5.4 \nInﬁnite Square Well 119\n5.5 \nFinite Square Well 128\n5.6 \nCompare and Contrast 133\n5.6.1 \nWave Function Curvature 133\n5.6.2 \nNodes 135\n5.6.3 \nBarrier Penetration 135\n5.6.4 \nInversion Symmetry and Parity 136\n5.6.5 \nOrthonormality 136\n5.6.6 \nCompleteness 137\n5.7 \nSuperposition States and Time Dependence 137\n5.8 \nModern Application: Quantum Wells and Dots 146\n5.9 \n Asymmetric Square Well: Sneak Peek at  \nPerturbations 147\n5.10  Fitting Energy Eigenstates by Eye or by  \nComputer 150\n5.10.1 Qualitative (Eyeball) Solutions 150\n","page_start":10,"page_end":10,"token_count":472,"section_type":"other","chapter_number":1,"chapter_title":"Stern-Gerlach Experiments","chunk_index":7}
{"chunk_id":"d5093cd82fcd2ca6","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"Contents  \n \nix\n5.10.2 Numerical Solutions 151\n5.10.3 General Potential Wells 154\nSummary 154\nProblems 156\nResources 159\nActivities 159\nFurther Reading 160\n \n6 \u0002 Unbound States \n161\n6.1 \nFree Particle Eigenstates 161\n6.1.1 \nEnergy Eigenstates 161\n6.1.2 \nMomentum Eigenstates 163\n6.2 \nWave Packets 168\n6.2.1 \nDiscrete Superposition 168\n6.2.2 \nContinuous Superposition 171\n6.3 \nUncertainty Principle 176\n6.3.1 \nEnergy Estimation 180\n6.4 \nUnbound States and Scattering 181\n6.5 \nTunneling Through Barriers 188\n6.6 \nAtom Interferometry 192\nSummary 197\nProblems 197\nResources 201\nActivities 201\nFurther Reading 201\n \n7 \u0002 Angular Momentum \n202\n7.1 \n Separating Center-of-Mass and Relative  \nMotion 204\n7.2 \n Energy Eigenvalue Equation in Spherical  \nCoordinates 208\n7.3 \nAngular Momentum 210\n7.3.1 \nClassical Angular Momentum 210\n7.3.2 \n Quantum Mechanical Angular  \nMomentum 210\n7.4 \nSeparation of Variables: Spherical Coordinates 215\n7.5 \nMotion of a Particle on a Ring 218\n7.5.1 \nAzimuthal Solution 220\n7.5.2 \n Quantum Measurements on a Particle  \nConﬁned to a Ring 223\n7.5.3 \nSuperposition States 224\n7.6 \nMotion on a Sphere 227\n7.6.1 \nSeries Solution of Legendre’s Equation 228\n7.6.2 \nAssociated Legendre Functions 233\n7.6.3 \nEnergy Eigenvalues of a Rigid Rotor 236\n7.6.4 \nSpherical Harmonics 237\n7.6.5 \nVisualization of Spherical Harmonics 240\n","page_start":11,"page_end":11,"token_count":450,"section_type":"other","chapter_number":1,"chapter_title":"Stern-Gerlach Experiments","chunk_index":8}
{"chunk_id":"906273efe62d98a0","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"x \nContents \nSummary 245\nProblems 245\nResources 249\nActivities 249\n \n8 \u0002 Hydrogen Atom \n250\n8.1 \nThe Radial Eigenvalue Equation 250\n8.2 \nSolving the Radial Equation 252\n8.2.1 \n Asymptotic Solutions to the Radial  \nEquation 252\n8.2.2 \nSeries Solution to the Radial Equation 253\n8.3 \nHydrogen Energies and Spectrum 256\n8.4 \nThe Radial Wave Functions 261\n8.5 \nThe Full Hydrogen Wave Functions 263\n8.6 \nSuperposition States 270\nSummary 272\nProblems 272\nResources 274\nActivities 274\nFurther Reading 274\n \n9 \u0002 Harmonic Oscillator \n275\n9.1 \nClassical Harmonic Oscillator 275\n9.2 \nQuantum Mechanical Harmonic Oscillator 277\n9.3 \nWave Functions 284\n9.4 \nDirac Notation 289\n9.5 \nMatrix Representations 293\n9.6 \nMomentum Space Wave Function 296\n9.7 \nThe Uncertainty Principle 298\n9.8 \nTime Dependence 300\n9.9 \nMolecular Vibrations 305\nSummary 307\nProblems 308\nResources 311\nActivities 311\nFurther Reading 311\n \n10 \u0002 Perturbation Theory \n312\n10.1 Spin-1/2 Example 313\n10.2 General Two-Level Example 317\n10.3 Nondegenerate Perturbation Theory 319\n10.3.1 First-Order Energy Correction 320\n10.3.2 First-Order State Vector Correction 324\n10.4  Second-Order Nondegenerate Perturbation  \nTheory 329\n10.5 Degenerate Perturbation Theory 336\n10.6 More Examples 343\n","page_start":12,"page_end":12,"token_count":403,"section_type":"other","chapter_number":1,"chapter_title":"Stern-Gerlach Experiments","chunk_index":9}
{"chunk_id":"a1a255ae52b6bf5c","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"Contents  \n \nxi\n10.6.1 Harmonic Oscillator 343\n10.6.2 Stark Effect in Hydrogen 346\nSummary 351\nProblems 352\n \n11 \u0002  Hyperﬁne Structure and the Addition of \nAngular Momenta \n355\n11.1 Hyperﬁne Interaction 355\n11.2 Angular Momentum Review 357\n11.3 Angular Momentum Ladder Operators 359\n11.4 Diagonalization of the Hyperﬁne Perturbation 361\n11.5 The Coupled Basis 365\n11.6 Addition of Generalized Angular Momenta 370\n11.7  Angular Momentum in Atoms and Spectroscopic  \nNotation 377\nSummary 377\nProblems 379\nResources 381\nActivities 381\nFurther Reading 381\n \n12 \u0002 Perturbation of Hydrogen \n382\n12.1 Hydrogen Energy Levels 382\n12.2 Fine Structure of Hydrogen 386\n12.2.1 Relativistic Correction 386\n12.2.2 Spin-Orbit Coupling 388\n12.3 Zeeman Effect 393\n12.3.1 Zeeman Effect without Spin 394\n12.3.2 Zeeman Effect with Spin 396\n12.3.2.1 Weak magnetic ﬁeld 396\n12.3.2.2 Strong magnetic ﬁeld 402\n12.3.2.3 Intermediate magnetic ﬁeld 403\n12.3.3  Zeeman Perturbation of the 1s \nHyperﬁne Structure 405\nSummary 407\nProblems 407\nResources 409\nActivities 409\nFurther Reading 409\n \n13 \u0002 Identical Particles \n410\n13.1 Two Spin-1/2 Particles 410\n13.2 Two Identical Particles in One Dimension 414\n13.2.1 Two-Particle Ground State 415\n13.2.2 Two-Particle Excited State 416\n13.2.3 Visualization of States 417\n13.2.4 Exchange Interaction 420\n","page_start":13,"page_end":13,"token_count":441,"section_type":"other","chapter_number":1,"chapter_title":"Stern-Gerlach Experiments","chunk_index":10}
{"chunk_id":"7a267bec0ffb430f","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"xii \nContents \n13.2.5  Consequences of the Symmetrization  \nPostulate 421\n13.3 Interacting Particles 423\n13.4 Example: The Helium Atom 427\n13.4.1 Helium Ground State 428\n13.4.2 Helium Excited States 431\n13.5 The Periodic Table 434\n13.6 Example: The Hydrogen Molecule 437\n13.6.1 The Hydrogen Molecular Ion H2\n+ 438\n13.6.2 The Hydrogen Molecule H2 440\nSummary 442\nProblems 442\nResources 444\nFurther Reading 444\n \n14 \u0002 Time-Dependent Perturbation Theory \n445\n14.1 Transition Probability 445\n14.2 Harmonic Perturbation 450\n14.3 Electric Dipole Interaction 454\n14.3.1 Einstein Model: Broadband Excitation 456\n14.3.2 Laser Excitation 460\n14.4 Selection Rules 462\nSummary 466\nProblems 467\nResources 468\nFurther Reading 468\n \n15 \u0002 Periodic Systems \n469\n15.1  The Energy Eigenvalues and Eigenstates of a  \nPeriodic Chain of Wells 471\n15.1.1 A Two-Well Chain 471\n15.1.2 N-Well Chain 473\n15.2  Boundary Conditions and the Allowed Values  \nof k 476\n15.3 The Brillouin Zones 478\n15.4 Multiple Bands from Multiple Atomic Levels 478\n15.5 Bloch’s Theorem and the Molecular States 480\n15.6 Molecular Wave Functions—a Gallery 482\n15.7 The Density of States 484\n15.8 Calculation of the Model Parameters 486\n15.8.1 LCAO Summary 488\n15.9 The Kronig-Penney Model 489\n15.10  Practical Applications: Metals, Insulators, and  \nSemiconductors 491\n15.11 Effective Mass 494\n15.12 Direct and Indirect Band Gaps 496\n15.13 New Directions—Low-Dimensional Carbon 497\n","page_start":14,"page_end":14,"token_count":460,"section_type":"other","chapter_number":1,"chapter_title":"Stern-Gerlach Experiments","chunk_index":11}
{"chunk_id":"17d423da98c8f355","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"Contents  \n \nxiii\nSummary 498\nProblems 499\nResources 500\nActivities 500\nFurther Reading 500\n \n16 \u0002 Modern Applications of Quantum Mechanics \n502\n16.1  Manipulating Atoms with Quantum  \nMechanical Forces 502\n16.1.1 Magnetic Trapping 502\n16.1.2 Laser Cooling 506\n16.2 Quantum Information Processing 514\n16.2.1 Quantum Bits—Qubits 515\n16.2.2 Quantum Gates 518\n16.2.3 Quantum Teleportation 524\nSummary 526\nProblems 527\nResources 528\nFurther Reading 528\nAppendix A: Probability \n529\nAppendix B: Complex Numbers \n533\nAppendix C: Matrices \n537\nAppendix D: Waves and Fourier Analysis \n541\nAppendix E: Separation of Variables \n547\nAppendix F: Integrals \n549\nAppendix G: Physical Constants \n551\nIndex \n553\n","page_start":15,"page_end":15,"token_count":209,"section_type":"other","chapter_number":1,"chapter_title":"Stern-Gerlach Experiments","chunk_index":12}
{"chunk_id":"9fd50d51d8a9a6ae","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"This page intentionally left blank \n","page_start":16,"page_end":16,"token_count":6,"section_type":"other","chapter_number":1,"chapter_title":"Stern-Gerlach Experiments","chunk_index":13}
{"chunk_id":"668f1b92a8e2684c","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":" \nxv\nPreface\nThis text is designed to introduce undergraduates at the junior and senior levels to quantum mechan-\nics. The text is an outgrowth of the new physics major curriculum developed by the Paradigms in \nPhysics program at Oregon State University. This new curriculum distributes material from the sub-\ndisciplines throughout the two upper-division years and provides students with a more gradual tran-\nsition between introductory and advanced levels. We have also incorporated and developed modern \npedagogical strategies to help improve student learning. This text covers the quantum mechanical \naspects of our curriculum in a way that can also be used in traditional curricula, but that still pre-\nserves the advantages of the Paradigms approach to the ordering of materials and the use of student \nengagement activities.\nPARADIGMS PROGRAM\nThe Paradigms project began in 1997, when the Department of Physics at Oregon State University \nbegan an extensive revision of the upper-division physics major. In an effort to encourage students \nto draw connections between the subdisciplines of physics, the structure of the Paradigms has been \ncrafted to mimic the organization of expert physics knowledge. Students are presented with a model \nof how physicists organize their understanding of physical phenomena and problem solving. Each \nof the nine short junior-year Paradigms courses focuses on a speciﬁc paradigm or class of physics \nproblems that serves as the centerpiece of the course and on which different tools and skills are built. \nIn the senior year, students resume a more traditional curriculum, taking six capstone courses in \nthe traditional disciplines. This curriculum incorporates a diverse set of student activities that allow \nstudents to stay actively engaged in the classroom and to work together in constructing their under-\nstanding of physics. Computer resources are used frequently to help students visualize the systems \nthey are studying.\nCONTENT AND APPROACH\nQuantum mechanics is integrated into four of the junior-year Paradigms courses and one senior-year \ncapstone course at Oregon State University. This text includes all the quantum mechanics topics \ncovered in those ﬁve courses. We adopt a “spins-ﬁrst” approach by introducing quantum mechanics \nthrough the analysis of sequential Stern-Gerlach spin measurements. This approach is based upon \nprevious presentations of spin systems by Feynman, Leighton, and Sands; Cohen-Tannoudji, Diu, \nand Laloe; Sakurai; and Townsend. The aim of the spins-ﬁrst approach is twofold: (1) To imme-\ndiately immerse students in the inherently quantum mechanical aspects of physics by focusing on \nsimple measurements that have no classical explanation, and (2) To give students early and extensive \nexperience with the mechanics of quantum mechanics in the forms of Dirac and matrix notation. \n","page_start":17,"page_end":17,"token_count":578,"section_type":"other","chapter_number":1,"chapter_title":"Stern-Gerlach Experiments","chunk_index":14}
{"chunk_id":"a8cd63d76f34d66e","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"xvi \nPreface \nThe  simplicity of the spin-1/2 and spin-1 systems allows the students to focus on these new features, \nwhich run counter to classical mechanics.\nThe ﬁrst three chapters of this text deal exclusively with spin systems and extensions to general \ntwo- and three-state quantum mechanical systems. The basic postulates of quantum mechanics are \nillustrated through their manifestation in the Stern-Gerlach experiments. After these three chapters, \nstudents have the tools to tackle any quantum mechanical problem presented in Dirac or matrix \nnotation. After a brief interlude into quantum spookiness (the EPR Paradox and Schrödinger’s cat) \nin Chapter 4, we tackle the traditional wave function aspects of quantum mechanics. We present \nseveral quantum systems—a particle in a box, on a ring, on a sphere, the hydrogen atom, and the \nharmonic oscillator—and emphasize their common features and their connections to the basic pos-\ntulates. The differential equations of angular momentum and the hydrogen atom radial problem are \nsolved in detail to expose students to the rigor of series solutions, though we stress that these are \nagain eigenvalue equations, no different in principle from the spin eigenvalue equations. Whenever \npossible, we continue the use of Dirac notation and matrix notation learned in the spin chapters, \nemphasizing the importance of ﬂuency in multiple representations. We build upon the spins-ﬁrst \napproach by using the spin-1/2 example to introduce perturbation theory, the addition of angular \nmomentum, and identical particles.\nUSAGE\nAt Oregon State University, the content of this text is taught in ﬁve courses as shown below.\nJunior-Year Paradigms Courses\nSpin and Quantum \nMeasurement\nWaves\nCentral Forces\nPeriod Systems\n1.  Stern-Gerlach  \nExperiments\n2.  Operators and  \nMeasurement\n3.  Schrödinger Time \nEvolution\n4. Quantum Spookiness\nMechanical waves \nand EM waves\n5.  Quantized Energies:  \nParticle in a Box\n6. Unbound States\nPlanetary orbits\n7.  Angular  \nMomentum\n8. Hydrogen Atom\nCoupled \nOscillations\n15.  Periodic  \nSystems\nSenior-Year Quantum Mechanics Capstone Course\n 9. Harmonic Oscillator\n10. Perturbation Theory\n11.  Hyperﬁne Structure \nand the Addition of \nAngular Momentum\n12.  Perturbation of \nHydrogen\n13. Identical Particles\n14.  Time-Dependent \nPerturbation \nTheory\n16.  Modern \nApplications\nFor a traditional curriculum, the content of this text would cover a full-year course, either two \nsemesters or three quarters. A proposed weekly outline for two 15-week semesters or three 10-week \nquarters is shown below.\n","page_start":18,"page_end":18,"token_count":604,"section_type":"other","chapter_number":1,"chapter_title":"Stern-Gerlach Experiments","chunk_index":15}
{"chunk_id":"b1dd8f2958da1a47","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"Preface  \nxvii\nWeek\nChapter\nTopics\n1\n1\nStern-Gerlach experiment, Quantum State Vectors, Bra-ket notation \n2\n1\nMatrix notation, General Quantum Systems\n3\n2\nOperators, Measurement, Commuting Observables\n4\n2\nUncertainty Principle, S2 Operator, Spin-1 System\n5\n3\nSchrödinger Equation, Time Evolution\n6\n3\nSpin Precession, Neutrino Oscillations, Magnetic Resonance\n7\n4\nEPR Paradox, Bell’s Inequalities, Schrödinger’s Cat\n8\n5\nEnergy Eigenvalue Equation, Wave Function\n9\n5\nOne-Dimensional Potentials, Finite Well, Inﬁnite Well\n10\n6\nFree Particle, Wave Packets, Momentum Space\n11\n6\nUncertainty Principle, Barriers\n12\n7\nThree-Dimensional Energy Eigenvalue Equation, Separation of Variables\n13\n7\nAngular Momentum, Motion on a Ring and Sphere, Spherical Harmonics\n14\n8\nHydrogen Atom, Radial Equation, Energy Eigenvalues\n15\n8\nHydrogen Wave Functions, Spectroscopy\n16\n9\n1-D Harmonic Oscillator, Operator Approach, Energy Spectrum\n17\n9\nHarmonic Oscillator Wave Functions, Matrix Representation\n18\n9\nMomentum Space Wave Functions, Time Dependence, Molecular Vibrations\n19\n10\nTime-Independent Perturbation Theory: Nondegenerate, Degenerate\n20\n10\nPerturbation Examples: Harmonic Oscillator, Stark Effect in Hydrogen\n21\n11\nHyperﬁne Structure, Coupled Basis\n22\n11\nAddition of Angular Momenta, Clebsch-Gordan Coefﬁcients\n23\n12\nHydrogen Atom: Fine Structure, Spin-Orbit, Zeeman Effect\n24\n13\nIdentical Particles, Symmetrization, Helium Atom\n25\n14\nTime-Dependent Perturbation Theory, Harmonic Perturbation\n26\n14\nRadiation, Selection Rules\n27\n15\nPeriodic Potentials, Bloch’s Theorem\n28\n15\nDispersion Relation, Density of States, Semiconductors\n29\n16\nModern Applications of Quantum Mechanics, Laser Cooling and Trapping\n30\n16\nQuantum Information Processing\n","page_start":19,"page_end":19,"token_count":503,"section_type":"other","chapter_number":1,"chapter_title":"Stern-Gerlach Experiments","chunk_index":16}
{"chunk_id":"6098d102b61134c7","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"xviii \nPreface \nAUDIENCE AND EXPECTED BACKGROUND\nThe intended audience is junior and senior physics majors, who are expected to have taken intermediate-\nlevel courses in modern physics and linear algebra. No other upper-level physics or mathematics courses \nare required. For our own students, we review matrix algebra in a seven contact hour “preface” course \nthat precedes the Paradigms courses that teach quantum mechanics. The material for that preface course \nis in Appendix C. The material in Appendix B summarizes an earlier Paradigms course on oscillations, \nand the material in Appendix D summarizes the classical wave part of the Paradigms course on waves.\nSTUDENT ACTIVITIES AND WEBSITE\nStudent engagement activities are an integral part of the Paradigms curriculum. All of the activities \nthat we have developed are freely available on our wiki website:\nhttp://physics.oregonstate.edu/portfolioswiki\nThe wiki contains a wealth of information about the Paradigms project, the courses we teach, and the \nmaterials we have developed. Details about individual activities include descriptions, student handouts, \ninstructor’s guides, advice about how to use active engagement strategies, videos of classroom prac-\ntice, narratives of classroom activities, and comments from users—both internal and external to Oregon \nState University. This is a dynamic website that is continually updated as we develop new activities and \nimprove existing ones. We encourage you to visit the website and join the community. E-mail us with \ncorrections, additions, and suggestions.\nEach of the quantum mechanics activities that we use in our ﬁve courses is referenced in the \nresource section at the end of the appropriate chapter in the text. The quantum mechanics activities are \ncollected within the wiki website with a direct link: \nwww.physics.oregonstate.edu/qmactivities \nThese activities include different types of activities such as computer-based activities, group activities, \nand class response activities. The most extensive activity is a computer simulation of Stern-Gerlach \nexperiments. This SPINS software is a full-featured, menu-driven application that allows students to \nsimulate successive Stern-Gerlach measurements and explore incompatible observables, eigenstate \nexpansions, interference, and quantum dynamics. The use of the SPINS software facilitates our spins-\nﬁrst approach. The beauty of the simulation is that students steeped in classical physics perform a foun-\ndational quantum experiment and learn the most fascinating and counterintuitive aspects of quantum \nmechanics at an early stage.\nACKNOWLEDGMENTS\nThis work is the product of a broad and energetic community of educators and students within the \nParadigms in Physics program. I thank all of our students for their hard work, insights, and innu-\nmerable suggestions. My colleagues Corinne Manogue and Janet Tate have developed some of the \ncourses upon which this text is based. They have worked with me throughout the writing of this text \nand I am indebted to them for their valuable contributions. I gratefully acknowedge my fellow faculty \nwho have developed and taught in the new curriculum: Dedra Demaree, Tevian Dray, Tomasz Gieb-","page_start":20,"page_end":20,"token_count":656,"section_type":"other","chapter_number":1,"chapter_title":"Stern-Gerlach Experiments","chunk_index":17}
{"chunk_id":"c7e84428cda8fc52","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"merable suggestions. My colleagues Corinne Manogue and Janet Tate have developed some of the \ncourses upon which this text is based. They have worked with me throughout the writing of this text \nand I am indebted to them for their valuable contributions. I gratefully acknowedge my fellow faculty \nwho have developed and taught in the new curriculum: Dedra Demaree, Tevian Dray, Tomasz Gieb-\nultowicz, Elizabeth Gire, William Hetherington, Henri Jansen, Kenneth Krane, Yun-Shik Lee, Victor \nMadsen, Ethan Minot, Oksana Ostroverkhova, David Roundy, Philip Siemens, Albert Stetz, William ","page_start":20,"page_end":20,"token_count":145,"section_type":"other","chapter_number":1,"chapter_title":"Stern-Gerlach Experiments","chunk_index":18}
{"chunk_id":"e89c7bc12d369f52","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"Preface   \nxix\nWarren, and Allen Wasserman. I would also like to acknowledge the important contributions of early \nteaching assistants Kerry Browne, Jason Janesky, Cheryl Klipp, Katherine Meyer, Steve Sahyun, and \nEmily Townsend—their expertise, dedication, and enthusiasm were above and beyond the call of \nduty. The many subsequent teaching assistants have also been enthusiastic and valued contributors. \nI also thank those who have contributed in various ways to the development of activities: Mario Bel-\nloni, Tim Budd, Wolfgang Christian, Paco Esquembre, Lichun Jia, and Shannon Mayer. I particularly \nthank Daniel Schroeder for sharing his original SPINS software. I acknowledge useful and construc-\ntive feedback from Jeffrey Dunham, Joshua Folk, Rubin Landau, Edward (Joe) Redish, Joseph Roth-\nberg, Homeyra Sadaghiani, Daniel Schroeder, Chandralekha Singh, and Daniel Styer. The Paradigms \nadvisory committee has also provided valuable feedback and I acknowledge David Grifﬁths, Bruce \nMason, William McCallum, Harriett Platsek, and Michael Wittmann for their help. I am grateful to the \nsuccessive Physics Department chairs, Kenneth Krane and Henri Jansen, and Deans Fred Horne and \nSherman Bloomer at Oregon State University for their endorsement of the Paradigms project.\nThis material is based on work supported by the National Science Foundation under Grant Nos. \n9653250, 0231194, and 0618877. Any opinions, ﬁndings, and conclusions or recommendations \nexpressed in this material are those of the authors and do not necessarily reﬂect the views of the \nNational Science Foundation. I thank Duncan McBride and Jack Hehn for their encouragement and \nsupport of our endeavor.\nJim Smith at Addison Wesley has been enthusiastic about this project from the early stages. Peter \nAlston has navigated me through the editorial process with skill and patience. I am grateful to them \nand also to Katie Conley, Steven Le, and the rest of the staff at Addison Wesley for their work to pro-\nduce this text.\nDavid H. McIntyre\nCorvallis, Oregon  \nNovember 2011\n","page_start":21,"page_end":21,"token_count":472,"section_type":"other","chapter_number":1,"chapter_title":"Stern-Gerlach Experiments","chunk_index":19}
{"chunk_id":"04ef8665e5498697","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"This page intentionally left blank \n","page_start":22,"page_end":22,"token_count":6,"section_type":"other","chapter_number":1,"chapter_title":"Stern-Gerlach Experiments","chunk_index":20}
{"chunk_id":"b42a29627c4aacbb","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":" \nxxi\nPrologue\nIt was a dark and stormy night. Erwin huddled under his covers as he had done numerous times that \nsummer. As the wind and rain lashed at the window, he feared having to retreat to the storm cellar \nonce again. The residents of Erwin’s apartment building sought shelter whenever there were threats of \ntornadoes in the area. While it was safe down there, Erwin feared the ridicule he would face once again \nfrom the other school boys. In the rush to the cellar, Erwin seemed to always end up with a random \npair of socks, and the other boys teased him about it mercilessly.\nNot that Erwin hadn’t tried hard to solve this problem. He had a very simple collection of \nsocks—black or white, for either school or play; short or long, for either trousers or lederhosen. \nAfter the ﬁrst few teasing episodes from the other boys, Erwin had sorted his socks into two sepa-\nrate drawers. He placed all the black socks in one drawer and all the white socks in another drawer. \nErwin ﬁgured he could determine an individual sock’s length in the dark of night simply by feel-\ning it, but he had to have them presorted into white and black because the apartment generally lost \npower before the call to the shelter.\nUnfortunately, Erwin found that this presorting of the socks by color was ineffective. Whenever \nhe reached into the white sock drawer and chose two long socks, or two short socks, there was a 50% \nprobability of any one sock being black or white. The results from the black sock drawer were the \nsame. The socks seemed to have “forgotten” the color that Erwin had determined previously.\nErwin also tried sorting the socks into two drawers based upon their length, without regard to \ncolor. When he chose black or white socks from these long and short drawers, the socks had also “for-\ngotten” whether they were long or short.\nAfter these fruitless attempts to solve his problem through experiments, Erwin decided to save \nhimself the fashion embarrassment, and he replaced his sock collection with a set of medium length \nbrown socks. However, he continued to ponder the mysteries of the socks throughout his childhood.\nAfter many years of daydreaming about the mystery socks, Erwin Schrödinger proposed his the-\nory of “Quantum Socks” and become famous. And that is the beginning of the story of the quantum \nsocks.\nThe End.\nFarfetched?? You bet. But Erwin’s adventure with his socks is the way quantum mechanics works. \nRead on.\n","page_start":23,"page_end":23,"token_count":553,"section_type":"other","chapter_number":1,"chapter_title":"Stern-Gerlach Experiments","chunk_index":21}
{"chunk_id":"a48277bc6f4fb002","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"This page intentionally left blank \n","page_start":24,"page_end":24,"token_count":6,"section_type":"other","chapter_number":1,"chapter_title":"Stern-Gerlach Experiments","chunk_index":22}
{"chunk_id":"cf845a51aeb6cff8","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":" \n1\nC H A P T E R \n1\nStern-Gerlach Experiments\nIt was not a dark and stormy night when Otto Stern and Walther  Gerlach performed their now famous \nexperiment in 1922. The Stern-Gerlach experiment demonstrated that measurements on microscopic \nor quantum particles are not always as certain as we might expect. Quantum particles behave as mys-\nteriously as Erwin’s socks—sometimes forgetting what we have already measured. Erwin’s adven-\nture with the mystery socks is farfetched because you know that everyday objects do not behave like \nhis socks. If you observe a sock to be black, it remains black no matter what other properties of the \nsock you observe. However, the Stern- Gerlach experiment goes against these ideas. Microscopic or \nquantum particles do not behave like the classical objects of your everyday experience. The act of \nobserving a quantum particle affects its measurable properties in a way that is foreign to our classical \nexperience.\nIn these ﬁrst three chapters, we focus on the Stern-Gerlach experiment because it is a conceptu-\nally simple experiment that demonstrates many basic principles of quantum mechanics. We discuss \na variety of experimental results and the quantum theory that has been developed to predict those \nresults. The mathematical formalism of quantum mechanics is based upon six postulates that we will \nintroduce as we develop the theoretical framework. (A complete list of these postulates is in Section 1.5.) \nWe use the Stern-Gerlach experiment to learn about quantum mechanics theory for two primary reasons: \n(1) It demonstrates how quantum mechanics works in principle by illustrating the postulates of quan-\ntum mechanics, and (2) it demonstrates how quantum mechanics works in practice through the use \nof Dirac notation and matrix mechanics to solve problems. By using a simple example, we can focus \non the principles and the new mathematics, rather than having the complexity of the physics obscure \nthese new aspects.\n1.1 \u0002 STERN-GERLACH EXPERIMENT\nIn 1922 Otto Stern and Walther Gerlach performed a seminal experiment in the history of quantum \nmechanics. In its simplest form, the experiment consisted of an oven that produced a beam of neu-\ntral atoms, a region of space with an inhomogeneous magnetic ﬁeld, and a detector for the atoms, as \ndepicted in Fig. 1.1. Stern and Gerlach used a beam of silver atoms and found that the beam was split \ninto two in its passage through the magnetic ﬁeld. One beam was deﬂected upwards and one down-\nwards in relation to the direction of the magnetic ﬁeld gradient.\nTo understand why this result is so at odds with our classical expectations, we must ﬁrst analyze \nthe experiment classically. The results of the experiment suggest an interaction between a neutral parti-\ncle and a magnetic ﬁeld. We expect such an interaction if the particle possesses a magnetic moment M.\nThe potential energy of this interaction is E = -M~B, which results in a force F = \u00021M~B2. In the \n","page_start":25,"page_end":25,"token_count":663,"section_type":"other","chapter_number":1,"chapter_title":"Stern-Gerlach Experiments","chunk_index":23}
{"chunk_id":"575ea9c533658ec9","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"2 \nStern-Gerlach Experiments\nStern-Gerlach experiment, the magnetic ﬁeld gradient is primarily in the z-direction, and the resulting \nz-component of the force is\n \n Fz =\n0\n0z\n 1M~B2 \n(1.1)\n \n \u0002 mz \n0Bz\n0z\n .\n \nThis force is perpendicular to the direction of motion and deﬂects the beam in proportion to the com-\nponent of the magnetic moment in the direction of the magnetic ﬁeld gradient.\nNow consider how to understand the origin of the atom’s magnetic moment from a classical view-\npoint. The atom consists of charged particles, which, if in motion, can produce loops of current that give \nrise to magnetic moments. A loop of area A and current I produces a magnetic moment\n \nm = IA \n(1.2)\nin MKS units. If this loop of current arises from a charge q traveling at speed v in a circle of radius r, \nthen\n \n m =\nq\n2pr>v\n pr 2 \n \n = qrv\n2\n \n(1.3)\n \n =\nq\n2m\n L ,\n \nwhere L = mrv is the orbital angular momentum of the particle. In the same way that the earth \nrevolves around the sun and rotates around its own axis, we can also imagine a charged particle in \nan atom having orbital angular momentum L and a new property, the intrinsic angular momen-\ntum, which we label S and call spin. The intrinsic angular momentum also creates current loops, \nso we expect a similar relation between the magnetic moment M and S. The exact calculation \nx\nOven\nCollimator\nMagnet\nDetector\nMagnet\nCross-Section\ny\nz\nS\nS\nN\nN\nFIGURE 1.1 Stern-Gerlach experiment to measure the spin component of neutral \nparticles along the z-axis. The magnet cross section at right shows the inhomogeneous \nﬁeld used in the experiment.\n","page_start":26,"page_end":26,"token_count":425,"section_type":"other","chapter_number":1,"chapter_title":"Stern-Gerlach Experiments","chunk_index":24}
{"chunk_id":"5f8d385b23034a2a","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"1.1 Stern-Gerlach Experiment \n3\ninvolves an integral over the charge distribution, which we will not do. We simply assume that we \ncan relate the magnetic moment to the intrinsic angular momentum in the same fashion as Eq. (1.3), \ngiving\nM = g q\n2m\n S , \n(1.4)\nwhere the dimensionless gyroscopic ratio g contains the details of that integral.\nA silver atom has 47 electrons, 47 protons, and 60 or 62 neutrons (for the most common isotopes). \nThe magnetic moments depend on the inverse of the particle mass, so we expect the heavy protons and \nneutrons (\u00032000 me) to have little effect on the magnetic moment of the atom and so we neglect them. \nFrom your study of the periodic table in chemistry, you recall that silver has an electronic conﬁgura-\ntion 1s22s22p63s23p64s23d104p64d105s1, which means that there is only the lone 5s electron outside \nof the closed shells. The electrons in the closed shells can be represented by a spherically symmetric \ncloud with no orbital or intrinsic angular momentum (unfortunately we are injecting some quantum \nmechanical knowledge of atomic physics into this classical discussion). That leaves the lone 5s elec-\ntron as a contributor to the magnetic moment of the atom as a whole. An electron in an s state has no \norbital angular momentum, but it does have spin. Hence the magnetic moment of this electron, and \ntherefore of the entire neutral silver atom, is\nM = -g e\n2me\n S , \n(1.5)\nwhere e is the magnitude of the electron charge. The classical force on the atom can now be written as\nFz \u0002 -g e\n2me\n Sz \n0Bz\n0z\n . \n(1.6)\nThe deﬂection of the beam in the Stern-Gerlach experiment is thus a measure of the component (or pro-\njection) Sz of the spin along the z-axis, which is the orientation of the magnetic ﬁeld gradient.\nIf we assume that the 5s electron of each atom has the same magnitude 0 S0  of the intrinsic angular \nmomentum or spin, then classically we would write the z-component as Sz = 0 S0 cos u, where u is \nthe angle between the z-axis and the direction of the spin S. In the thermal environment of the oven, \nwe expect a random distribution of spin directions and hence all possible angles u. Thus we expect \nsome continuous distribution (the details are not important) of spin components from Sz = - 0 S0  to \nSz = + 0 S0 , which would yield a continuous spread in deﬂections of the silver atomic beam. Rather, \nthe experimental result that Stern and Gerlach observed was that there are only two deﬂections, indi-\ncating that there are only two possible values of the z-component of the electron spin. The magnitudes ","page_start":27,"page_end":27,"token_count":659,"section_type":"other","chapter_number":1,"chapter_title":"Stern-Gerlach Experiments","chunk_index":25}
{"chunk_id":"71aa43f2101dde09","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"some continuous distribution (the details are not important) of spin components from Sz = - 0 S0  to \nSz = + 0 S0 , which would yield a continuous spread in deﬂections of the silver atomic beam. Rather, \nthe experimental result that Stern and Gerlach observed was that there are only two deﬂections, indi-\ncating that there are only two possible values of the z-component of the electron spin. The magnitudes \nof these deﬂections are consistent with values of the spin component of\nSz = { U\n2\n ,  \n(1.7)\nwhere U is Planck’s constant h divided by 2p and has the numerical value\n U = 1.0546 * 10-34  J~s \n = 6.5821 * 10-16  eV~s. \n(1.8)\nThis result of the Stern-Gerlach experiment is evidence of the quantization of the electron’s \nspin angular momentum component along an axis. This quantization is at odds with our classical ","page_start":27,"page_end":27,"token_count":229,"section_type":"other","chapter_number":1,"chapter_title":"Stern-Gerlach Experiments","chunk_index":26}
{"chunk_id":"c753bd2e9c1001c8","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"4 \nStern-Gerlach Experiments\nexpectations for this measurement. The factor of 1/2 in Eq. (1.7) leads us to refer to this as a \nspin-1/2 system.\nIn this example, we have chosen the z-axis along which to measure the spin component, but there \nis nothing special about this direction in space. We could have chosen any other axis and we would \nhave obtained the same results.\nNow that we know the ﬁne details of the Stern-Gerlach experiment, we simplify the experiment \nfor the rest of our discussions by focusing on the essential features. A simpliﬁed schematic representa-\ntion of the experiment is shown in Fig. 1.2, which depicts an oven that produces the beam of atoms, a \nStern-Gerlach device with two output ports for the two possible values of the spin component, and two \ncounters to detect the atoms leaving the output ports of the Stern-Gerlach device. The Stern-Gerlach \ndevice is labeled with the axis along which the magnetic ﬁeld is oriented. The up and down arrows \nindicate the two possible measurement results for the device; they correspond respectively to the \nresults Sz = {U>2 in the case where the ﬁeld is oriented along the z-axis. There are only two possible \nresults in this case, so they are generally referred to as spin up and spin down. The physical quantity \nthat is measured, Sz in this case, is called an observable. In our detailed discussion of the experiment \nabove, we chose the ﬁeld gradient in such a manner that the spin up states were deﬂected upwards. \nIn this new simpliﬁcation, the deﬂection itself is not an important issue. We simply label the output \nport with the desired state and count the particles leaving that port. The Stern-Gerlach device sorts \n(or ﬁlters, selects or analyzes) the incoming particles into the two possible outputs Sz = {U>2 in the \nsame way that Erwin sorted his socks according to color or length. We follow convention and refer to \na Stern-Gerlach device as an analyzer.\nIn Fig. 1.2, the input and output beams are labeled with a new symbol called a ket. We use the \nket 0  +9 as a mathematical representation of the quantum state of the atoms that exit the upper port \ncorresponding to Sz = +U>2. The lower output beam is labeled with the ket 0  -9, which corresponds \nto Sz = -U>2, and the input beam is labeled with the more generic ket 0  c9. The kets are representa-\ntions of the quantum states. They are used in mathematical expressions and they represent all the \ninformation that we can know about the state. This ket notation was developed by Paul A. M. Dirac \nand is central to the approach to quantum mechanics that we take in this text. We will discuss the \nmathematics of these kets in full detail later. With regard to notation, you will ﬁnd many different ","page_start":28,"page_end":28,"token_count":661,"section_type":"other","chapter_number":1,"chapter_title":"Stern-Gerlach Experiments","chunk_index":27}
{"chunk_id":"ef2b3a7eadf90510","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"tions of the quantum states. They are used in mathematical expressions and they represent all the \ninformation that we can know about the state. This ket notation was developed by Paul A. M. Dirac \nand is central to the approach to quantum mechanics that we take in this text. We will discuss the \nmathematics of these kets in full detail later. With regard to notation, you will ﬁnd many different \nways of writing the same ket. The symbol within the ket brackets is any simple label to distinguish \nthe ket from other different kets. For example, the kets 0  +9, 0  +U>29, 0 Sz = +U>29, 0  +zn9, and 0 c9 \nare all equivalent ways of writing the same thing, which in this case signiﬁes that we have measured \nthe z-component of the spin and found it to be +U>2 or spin up. Though we may label these kets in \ndifferent ways, they all refer to the same physical state and so they all behave the same mathemati-\ncally. The symbol 0 {9 refers to both the 0  +9 and 0  -9 kets. The ﬁrst postulate of quantum mechanics \ntells us that kets in general describe the quantum state mathematically and that they contain all the \ninformation that we can know about the state. We denote a general ket as 0  c9.\nZ\n50\n50\n\u0002\u0002\u0003\n\u0002\u0003\u0003\n\u0002Ψ\u0003\nFIGURE 1.2 Simpliﬁed schematic of the Stern-Gerlach experiment, \ndepicting a source of atoms, a Stern-Gerlach analyzer, and two counters.","page_start":28,"page_end":28,"token_count":372,"section_type":"other","chapter_number":1,"chapter_title":"Stern-Gerlach Experiments","chunk_index":28}
{"chunk_id":"384c8ae547441a30","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"1.1 Stern-Gerlach Experiment \n5\nPostulate 1\nThe state of a quantum mechanical system, including all the information you \ncan know about it, is represented mathematically by a normalized ket 0  c9.\nWe have chosen the particular simpliﬁed schematic representation of the Stern-Gerlach \nexperiment shown in Fig. 1.2, because it is the same representation used in the SPINS software \nprogram that you may use to simulate these experiments. The SPINS program allows you to per-\nform all the experiments described in this text. This software is freely available, as detailed in \nResources at the end of the chapter. In the SPINS program, the components are connected with \nsimple lines to represent the paths the atoms take. The directions and magnitudes of deﬂections \nof the beams in the program are not relevant. That is, whether the spin up output beam is drawn \nas deﬂected upwards, downwards, or not at all, is not relevant. The labeling on the output port is \nenough to tell us what that state is. Thus the extra ket label 0  +9 on the spin up output beam in Fig. \n1.2 is redundant and will be dropped soon.\nThe SPINS program permits alignment of Stern-Gerlach analyzing devices along all three axes \nand also at any angle f measured from the x-axis in the x-y plane. This would appear to be difﬁcult, if \nnot impossible, given that the atomic beam in Fig. 1.1 is directed along the y-axis, making it unclear \nhow to align the magnet in the y-direction and measure a deﬂection. In our depiction and discussion of \nStern-Gerlach experiments, we ignore this technical complication.\nIn the SPINS program, as in real Stern-Gerlach experiments, the numbers of atoms detected \nin particular states can be predicted by probability rules that we will discuss later. To simplify \nour schematic depictions of Stern-Gerlach experiments, the numbers shown for detected atoms \nare those obtained by using the calculated probabilities without any regard to possible statistical \nuncertainties. That is, if the theoretically predicted probabilities of two measurement possibilities \nare each 50%, then our schematics will display equal numbers for those two possibilities, whereas \nin a real experiment, statistical uncertainties might yield a 55%>45% split in one experiment and \na 47%>53% split in another, etc. The SPINS program simulations are designed to give statistical \nuncertainties, so you will need to perform enough experiments to convince yourself that you have a \nsufﬁciently good estimate of the probability (see SPINS Lab 1 for more information on statistics).\nNow let’s consider a series of simple Stern-Gerlach experiments with slight variations that help to \nillustrate the main features of quantum mechanics. We ﬁrst describe the experiments and their results \nand draw some qualitative conclusions about the nature of quantum mechanics. Then we introduce the \nformal mathematics of the ket notation and show how it can be used to predict the results of each of \nthe experiments.","page_start":29,"page_end":29,"token_count":661,"section_type":"other","chapter_number":1,"chapter_title":"Stern-Gerlach Experiments","chunk_index":29}
{"chunk_id":"71e0bc053ebe4d9c","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"Now let’s consider a series of simple Stern-Gerlach experiments with slight variations that help to \nillustrate the main features of quantum mechanics. We ﬁrst describe the experiments and their results \nand draw some qualitative conclusions about the nature of quantum mechanics. Then we introduce the \nformal mathematics of the ket notation and show how it can be used to predict the results of each of \nthe experiments.\n1.1.1 \u0002 Experiment 1\nThe ﬁrst experiment is shown in Fig. 1.3 and consists of a source of atoms, two Stern-Gerlach ana-\nlyzers both aligned along the z-axis, and counters for the output ports of the analyzers. The atomic \nbeam coming into the ﬁrst Stern-Gerlach analyzer is split into two beams at the output, just like the \noriginal experiment. Now instead of counting the atoms in the upper output beam, the spin compo-\nnent is measured again by directing those atoms into the second Stern-Gerlach analyzer. The result of \nthis experiment is that no atoms are ever detected coming out of the lower output port of the second \nStern-Gerlach analyzer. All atoms that are output from the upper port of the ﬁrst analyzer also pass ","page_start":29,"page_end":29,"token_count":262,"section_type":"other","chapter_number":1,"chapter_title":"Stern-Gerlach Experiments","chunk_index":30}
{"chunk_id":"ff69e9944d020e0f","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"6 \nStern-Gerlach Experiments\nthrough the upper port of the second analyzer. Thus we say that when the ﬁrst Stern-Gerlach analyzer \nmeasures an atom to have a z-component of spin Sz = +U>2, then the second analyzer also measures \nSz = +U>2 for that atom. This result is not surprising, but it sets the stage for results of experiments \nto follow.\nThough both Stern-Gerlach analyzers in Experiment 1 are identical, they play different roles in \nthis experiment. The ﬁrst analyzer prepares the beam in a particular quantum state 10  +92 and the \nsecond analyzer measures the resultant beam, so we often refer to the ﬁrst analyzer as a state prepa-\nration device. By preparing the state with the ﬁrst analyzer, the details of the source of atoms can be \nignored. Thus our main focus in Experiment 1 is what happens at the second analyzer because we \nknow that any atom entering the second analyzer is represented by the 0  +9 ket prepared by the ﬁrst \nanalyzer. All the experiments we will describe employ a ﬁrst analyzer as a state preparation device, \nthough the SPINS program has a feature where the state of the atoms coming from the oven is deter-\nmined but unknown, and the user can perform experiments to determine the unknown state using only \none analyzer in the experiment.\n1.1.2 \u0002 Experiment 2\nThe second experiment is shown in Fig. 1.4 and is identical to Experiment 1 except that the sec-\nond Stern-Gerlach analyzer has been rotated by 90° to be aligned with the x-axis. Now the second \nanalyzer measures the spin component along the x-axis rather the z-axis. Atoms input to the second \nanalyzer are still represented by the ket 0  +9 because the ﬁrst analyzer is unchanged. The result of this \nexperiment is that atoms appear at both possible output ports of the second analyzer. Atoms leaving \nthe upper port of the second analyzer have been measured to have Sx = +U>2, and atoms leaving \nZ\nZ\n50\n50\n0\n\u0002\u0002\u0003\n\u0002\u0002\u0003\n\u0002\u0003\u0003\n\u0002\u0003\u0003\n\u0002Ψ\u0003\nFIGURE 1.3 Experiment 1 measures the spin component along the z-axis twice in succession.\nX\nZ\n50\n25\n25\n\u0002\u0003\u0003\n\u0002\u0003\u0003x\n\u0002\u0002\u0003x\n\u0002\u0002\u0003\n\u0002Ψ\u0003\nFIGURE 1.4 Experiment 2 measures the spin component along the z-axis and then along the x-axis.\n","page_start":30,"page_end":30,"token_count":558,"section_type":"other","chapter_number":1,"chapter_title":"Stern-Gerlach Experiments","chunk_index":31}
{"chunk_id":"ca8e8b2d1c9834ae","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"1.1 Stern-Gerlach Experiment \n7\nthe lower port have Sx = -U>2. On average, each of these ports has 50% of the atoms that left the \nupper port of the ﬁrst analyzer. As shown in Fig. 1.4, the output states of the second analyzer have \nnew labels 0  +9x and 0  -9x, where the x subscript denotes that the spin component has been measured \nalong the x-axis. We assume that if no subscript is present on the quantum ket 1e.g., 0  +92, then the \nspin component is along the z-axis. This use of the z-axis as the default is a common convention \nthroughout our work and also in much of physics.\nA few items are noteworthy about this experiment. First, we notice that there are still only two \npossible outputs of the second Stern-Gerlach analyzer. The fact that it is aligned along a different axis \ndoesn’t affect the fact that we get only two possible results for the case of a spin-1/2 particle. Second, \nit turns out that the results of this experiment would be unchanged if we used the lower port of the ﬁrst \nanalyzer. That is, atoms entering the second analyzer in state 0  -9 would also result in half the atoms \nin each of the 0 {9x output ports. Finally, we cannot predict which of the second analyzer output ports \nany particular atom will come out. This can be demonstrated in actual experiments by recording the \nindividual counts out of each port. The arrival sequences at any counter are completely random. We \ncan say only that there is a 50% probability that an atom from the second analyzer will exit the upper \nanalyzer port and a 50% probability that it will exit the lower port. The random arrival of atoms at the \ndetectors can be seen clearly in the SPINS program simulations.\nThis probabilistic nature is at the heart of quantum mechanics. One might be tempted to say that \nwe just don’t know enough about the system to predict which port the atom will exit. That is to say, \nthere may be some other variables, of which we are ignorant, that would allow us to predict the results. \nSuch a viewpoint is known as a local hidden variable theory. John Bell proved that such theories are \nnot compatible with the experimental results of quantum mechanics. The conclusion to draw from this \nis that even though quantum mechanics is a probabilistic theory, it is a complete description of reality. \nWe will have more to say about this in Chapter 4.\nNote that the 50% probability referred to above is the probability that an atom input to the second \nanalyzer exits one particular output port. It is not the probability for an atom to pass through the whole sys-\ntem of Stern-Gerlach analyzers. It turns out that the results of this experiment (the 50>50 split at the sec-\nond analyzer) are the same for any combination of two orthogonal axes of the ﬁrst and second analyzers.\n1.1.3 \u0002 Experiment 3","page_start":31,"page_end":31,"token_count":651,"section_type":"other","chapter_number":1,"chapter_title":"Stern-Gerlach Experiments","chunk_index":32}
{"chunk_id":"f52a824c753ceabd","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"analyzer exits one particular output port. It is not the probability for an atom to pass through the whole sys-\ntem of Stern-Gerlach analyzers. It turns out that the results of this experiment (the 50>50 split at the sec-\nond analyzer) are the same for any combination of two orthogonal axes of the ﬁrst and second analyzers.\n1.1.3 \u0002 Experiment 3\nExperiment 3, shown in Fig. 1.5, extends Experiment 2 by adding a third Stern-Gerlach analyzer aligned \nalong the z-axis. Atoms entering the third analyzer have been measured by the ﬁrst Stern-Gerlach \nanalyzer to have spin component up along the z-axis, and by the second analyzer to have spin component \nup along the x-axis. The third analyzer then measures how many atoms have spin component up or down \n125\n125\n500\nX\nZ\nZ\n250\n\u0002\u0002\u0003\n\u0002\u0002\u0003\n\u0002\u0003\u0003\n\u0002\u0003\u0003\n\u0002Ψ\u0003\n\u0002\u0003\u0003x\n\u0002\u0002\u0003x\nFIGURE 1.5 Experiment 3 measures the spin component three times in succession.","page_start":31,"page_end":31,"token_count":247,"section_type":"other","chapter_number":1,"chapter_title":"Stern-Gerlach Experiments","chunk_index":33}
{"chunk_id":"71f561518002b923","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"8 \nStern-Gerlach Experiments\nalong the z-axis. Classically, one would expect that the ﬁnal measurement would yield the result spin \nup along the z-axis, because that was measured at the ﬁrst analyzer. That is to say: classically the ﬁrst \ntwo analyzers tell us that the atoms have Sz = +U>2 and Sx = +U>2, so the third measurement must \nyield Sz = +U>2. But that doesn’t happen, as Erwin learned with his quantum socks in the Prologue. \nThe quantum mechanical result is that the atoms are split with 50% probability into each output port at \nthe third analyzer. Thus the last two analyzers behave like the two analyzers of Experiment 2 (except \nwith the order reversed), and the fact that there was an initial measurement that yielded Sz = +U>2 is \nsomehow forgotten or erased.\nThis result demonstrates another key feature of quantum mechanics: a measurement disturbs the \nsystem. The second analyzer has disturbed the system such that the spin component along the z-axis \ndoes not have a unique value, even though we measured it with the ﬁrst analyzer. Erwin saw this \nwhen he sorted, or measured, his socks by color and then by length. When he looked, or measured, \na third time, he found that the color he had measured originally was now random—the socks had \nforgotten about the ﬁrst measurement. One might ask: Can I be more clever in designing the experi-\nment such that I don’t disturb the system? The short answer is no. There is a fundamental incompat-\nibility in trying to measure the spin component of the atom along two different directions. So we say \nthat Sx and Sz are incompatible observables. We cannot know the measured values of both simul-\ntaneously. The state of the system can be represented by the ket 0  +9 = 0 Sz = +U>29 or by the ket \n0  +9x = 0 Sx = +U>29, but it cannot be represented by a ket 0 Sz = +U>2, Sx = +U>29 that speciﬁes \nvalues of both components. Having said this, it should be said that not all pairs of quantum mechanical \nobservables are incompatible. It is possible to do some experiments without disturbing some of the \nother aspects of the system. We will see in Section 2.4 that whether two observables are compatible or \nnot is very important in how we analyze a quantum mechanical system.\nNot being able to measure both the Sz and Sx spin components is clearly distinct from the classi-\ncal case where we can measure all three components of the spin vector, which tells us which direction \nthe spin is pointing. In quantum mechanics, the incompatibility of the spin components means that we \ncannot know which direction the spin is pointing. So when we say “the spin is up,” we really mean \nonly that the spin component along that one axis is up (vs. down). The quantum mechanical spin vec-","page_start":32,"page_end":32,"token_count":647,"section_type":"other","chapter_number":1,"chapter_title":"Stern-Gerlach Experiments","chunk_index":34}
{"chunk_id":"c040066523a10724","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"cal case where we can measure all three components of the spin vector, which tells us which direction \nthe spin is pointing. In quantum mechanics, the incompatibility of the spin components means that we \ncannot know which direction the spin is pointing. So when we say “the spin is up,” we really mean \nonly that the spin component along that one axis is up (vs. down). The quantum mechanical spin vec-\ntor cannot be said to be pointing in any given direction. As is often the case, we must check our classi-\ncal intuition at the door of quantum mechanics.\n1.1.4 \u0002 Experiment 4\nExperiment 4 is depicted in Fig. 1.6 and is a slight variation on Experiment 3. Before we get into the \ndetails, note a few changes in the schematic drawings. As promised, we have dropped the ket labels on \nthe beams because they are redundant. We have deleted the counters on all but the last analyzer and \ninstead simply blocked the unwanted beams and given the average number of atoms passing from one \nanalyzer to the next. The beam blocks are shown explicitly in Fig. 1.6 but will not be shown after this to \nbe consistent with the SPINS program. Note also that in Experiment 4c two output beams are combined \nas input to the following analyzer. This is simple in principle and in the SPINS program but can be \ndifﬁcult in practice. The recombination of the beams must be done properly so as to avoid “disturbing” \nthe beams. If you care to read more about this problem, see Feynman’s Lectures on Physics, volume 3. \nWe will have more to say about the “disturbance” later in Section 2.2. For now we simply assume that \nthe beams can be recombined in the proper manner.\nExperiment 4a is identical to Experiment 3. In Experiment 4b, the upper beam of the second ana-\nlyzer is blocked and the lower beam is sent to the third analyzer. In Experiment 4c, both beams are \ncombined with our new method and sent to the third analyzer. It should be clear from our previous \nexperiments that Experiment 4b has the same results as Experiment 4a. We now ask about the results of ","page_start":32,"page_end":32,"token_count":479,"section_type":"other","chapter_number":1,"chapter_title":"Stern-Gerlach Experiments","chunk_index":35}
{"chunk_id":"7ee1bed53fb5c9ef","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"1.1 Stern-Gerlach Experiment \n9\nExperiment 4c. If we were to use classical probability analysis, then Experiment 4a would indicate that \nthe probability for an atom leaving the ﬁrst analyzer to take the upper path through the second analyzer \nand then exit through the upper port of the third analyzer is 25%, where we are now referring to the total \nprobability for those two steps. Likewise, Experiment 4b would indicate that the total probability to \ntake the lower path through the second  analyzer and exit through the upper port of the third analyzer is \nalso 25%. Hence the total probability to exit from the upper port of the third analyzer when both paths \nare available, which is Experiment 4c, would be 50%, and likewise for the exit from the lower port.\nHowever, the quantum mechanical result in Experiment 4c is that all the atoms exit the upper \nport of the third analyzer and none exits the lower port. The atoms now appear to “remember” that \nthey were initially measured to have spin up along the z-axis. By combining the two beams from \nthe second analyzer, we have avoided the quantum mechanical disturbance that was evident in \nExperiments 3, 4a, and 4b. The result is now the same as Experiment 1, which means it is as if the \nsecond analyzer is not there.\nTo see how odd this is, look carefully at what happens at the lower port of the third analyzer. In \nthis discussion, we refer to percentages of atoms leaving the ﬁrst analyzer, because that analyzer is \nthe same in all three experiments. In Experiments 4a and 4b, 50% of the atoms are blocked after the \nmiddle analyzer and 25% of the atoms exit the lower port of the third analyzer. In Experiment 4c, \n100% of the atoms pass from the second analyzer to the third analyzer, yet fewer atoms come out \nof the lower port. In fact, no atoms make it through the lower port! So we have a situation where \n25\n25\nX\nZ\nZ\n100\n50\n25\n25\nX\nZ\nZ\n100\n(a)\n(b)\n(c)\n50\n100\n0\nX\nZ\nZ\n100\n100\nFIGURE 1.6 Experiment 4 measures the spin component three times in succession \nand uses (a and b) one or (c) two beams from the second analyzer.\n","page_start":33,"page_end":33,"token_count":513,"section_type":"other","chapter_number":1,"chapter_title":"Stern-Gerlach Experiments","chunk_index":36}
{"chunk_id":"6e57054c288c4fc1","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"10 \nStern-Gerlach Experiments\nallowing more ways or paths to reach a counter results in fewer counts. Classical probability theory \ncannot explain this aspect of quantum mechanics. It is as if you opened a second window in a room to \nget more sunlight and the room went dark!\nHowever, you may already know of a way to explain this effect. Imagine a procedure whereby \ncombining two effects leads to cancellation rather than enhancement. The concept of wave interfer-\nence, especially in optics, comes to mind. In the Young’s double-slit experiment, light waves pass \nthrough two narrow slits and create an interference pattern on a distant screen, as shown in Fig. 1.7. \nEither slit by itself produces a nearly uniform illumination of the screen, but the two slits combined \nproduce bright and dark interference fringes, as shown in Fig. 1.7(b). We explain this by adding \ntogether the electric ﬁeld vectors of the light from the two slits, then squaring the resultant vector to \nﬁnd the light intensity. We say that we add the amplitudes and then square the total amplitude to ﬁnd \nthe resultant intensity. See Section 6.6 or an optics textbook for more details about this experiment.\nWe follow a similar prescription in quantum mechanics. We add together amplitudes and then \ntake the square to ﬁnd the resultant probability, which opens the door to interference effects. Before \nwe discuss quantum mechanical interference, we must explain what we mean by an amplitude in \nquantum mechanics and how we calculate it.\n1.2 \u0002 QUANTUM STATE VECTORS\nPostulate 1 of quantum mechanics stipulates that kets are to be used for a mathematical description of a \nquantum mechanical system. These kets are abstract entities that obey many of the rules you know about \nordinary spatial vectors. Hence they are called quantum state vectors. As we will show in Example 1.3, \nthese vectors must employ complex numbers in order to properly describe quantum mechanical systems. \nQuantum state vectors are part of a vector space that we call a Hilbert space. The dimensionality of \nthe Hilbert space is determined by the physics of the system at hand. In the Stern-Gerlach example, \nthe two possible results for a spin  component measurement dictate that the vector space has only two \nPinhole\nSource\nDouble\nSlit\n(a)\n(b)\nScreen\nSingle Slit\nPatterns\nDouble Slit\nPattern\nFIGURE 1.7 (a) Young’s double-slit interference experiment and (b) resultant intensity patterns \nobserved on the screen, demonstrating single-slit diffraction and double-slit interference.\n","page_start":34,"page_end":34,"token_count":563,"section_type":"other","chapter_number":2,"chapter_title":"Operators and Measurement","chunk_index":37}
{"chunk_id":"421a9a2ed1db2a40","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"1.2 Quantum State Vectors \n11\ndimensions. That makes this problem mathematically as simple as it can be, which is why we have chosen \nto study it. Because the quantum state vectors are abstract, it is hard to say much about what they are, \nother than how they behave mathematically and how they lead to physical predictions.\nIn the two-dimensional vector space of a spin-1/2 system, the two kets 0 {9 form a basis, just like \nthe unit vectors in  , jn , and kn form a basis for describing vectors in three-dimensional space. However, \nthe analogy we want to make with these spatial vectors is only mathematical, not physical. The spatial \nunit vectors have three important mathematical properties that are characteristic of a basis: the basis \nvectors in , jn , and kn are normalized, orthogonal, and complete. Spatial vectors are normalized if their \nmagnitudes are unity, and they are orthogonal if they are geometrically perpendicular to each other. \nThe basis is complete if any general vector in the space can be written as a linear superposition of the \nbasis vectors. These properties of spatial basis vectors can be summarized as follows:\n in~in = jn~jn = kn~kn = 1   normalization\n in~jn = in~kn = jn~kn = 0   orthogonality  \n(1.9)\n A = axin + ay jn + azkn   completeness,\nwhere A is a general vector. Note that the dot product, also called the scalar product, is central to the \ndescription of these properties.\nContinuing the mathematical analogy between spatial vectors and abstract vectors, we require that \nthese same properties (at least conceptually) apply to quantum mechanical basis vectors. For the Sz \nmeasurement, there are only two possible results, corresponding to the states 0  +9 and 0  -9, so these \ntwo states comprise a complete set of basis vectors. This basis is known as the Sz basis. We focus on \nthis basis for now and refer to other possible basis sets later. The completeness of the basis kets 0 {9 \nimplies that a general quantum state vector 0  c9 is a linear combination of the two basis kets:\n0  c9 = a0  +9 + b0  -9, \n(1.10)\nwhere a and b are complex scalar numbers multiplying each ket. This addition of two kets yields \nanother ket in the same abstract space. The complex scalar can appear either before or after the ket \nwithout affecting the mathematical properties of the ket 1i.e., a0  +9 = 0  +9a2. It is customary to use \nthe Greek letter c (psi) for a general quantum state. You may have seen c1x2 used before as a quan-\ntum mechanical wave function. However, the state vector or ket 0  c9 is not a wave function. Kets do \nnot have any spatial dependence as wave functions do. We will study wave functions in Chapter 5.\nTo discuss orthogonality and normalization (known together as orthonormality) we must ﬁrst ","page_start":35,"page_end":35,"token_count":665,"section_type":"other","chapter_number":2,"chapter_title":"Operators and Measurement","chunk_index":38}
{"chunk_id":"916d99a97b49b62a","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"the Greek letter c (psi) for a general quantum state. You may have seen c1x2 used before as a quan-\ntum mechanical wave function. However, the state vector or ket 0  c9 is not a wave function. Kets do \nnot have any spatial dependence as wave functions do. We will study wave functions in Chapter 5.\nTo discuss orthogonality and normalization (known together as orthonormality) we must ﬁrst \ndeﬁne scalar products as they apply to these new kets. As we said above, the machinery of quantum \nmechanics requires the use of complex numbers. You may have seen other ﬁelds of physics use com-\nplex numbers. For example, sinusoidal oscillations can be described using the complex exponential \neivt rather than cos(vt). However, in such cases, the complex numbers are not required, but are rather \na convenience to make the mathematics easier. When using complex notation to describe classical \nvectors like electric and magnetic ﬁelds, the deﬁnition of the dot product is generalized slightly, such \nthat one of the vectors is complex conjugated. A similar approach is taken in quantum mechanics. The \nanalog to the complex conjugated vector of classical physics is called a bra in the Dirac notation of \nquantum mechanics. Thus corresponding to a general ket 0  c9, there is a bra, or bra vector, which is \nwritten as 8c 0 . If a general ket 0  c9 is speciﬁed as 0  c9 = a0  +9 + b0  -9, then the corresponding bra \n8c 0  is deﬁned as\n8c 0 = a*8+ 0 + b*8- 0  , \n(1.11)","page_start":35,"page_end":35,"token_count":391,"section_type":"other","chapter_number":2,"chapter_title":"Operators and Measurement","chunk_index":39}
{"chunk_id":"134fe77507e6ffbd","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"12 \nStern-Gerlach Experiments\nwhere the basis bras 8  +  0  and 8  -  0  correspond to the basis kets 0  +9 and 0  -9, respectively, and the \ncoefﬁcients a and b have been complex conjugated.\nThe scalar product in quantum mechanics is deﬁned as the product of a bra and a ket taken in the \nproper order—bra ﬁrst, then ket second:\n18bra0210 ket92. \n(1.12)\nWhen the bra and ket are combined together in this manner, we get a bracket (bra ket)—a little physics \nhumor—that is written in shorthand as\n8bra0 ket9. \n(1.13)\nThus, given the basis kets 0  +9 and 0  -9, one inner product, for example, is written as\n18 + 0210  - 92 = 8 + 0  -9 \n(1.14)\nand so on. Note that we have eliminated the extra vertical bar in the middle. The scalar product in \nquantum mechanics is generally referred to as an inner product or a projection.\nSo how do we calculate the inner product 8+  0  +9? We do it the same way we calculate the dot \nproduct in~ in. We deﬁne it to be unity because we like basis vectors to be unit vectors. There is a little \nmore to it than that, because in quantum mechanics (as we will see shortly) using normalized basis \nvectors is more rooted in physics than in our personal preferences for mathematical cleanliness. But \nfor all practical purposes, if someone presents a set of basis vectors to you, you can probably assume \nthat they are normalized. So the normalization of the spin-1/2 basis vectors is expressed in this new \nnotation as 8+  0  +9 = 1 and 8-  0  -9 = 1.\nNow, what about orthogonality? The spatial unit vectors in, jn, and kn used for spatial vectors are \northogonal to each other because they are at 90° with respect to each other. That orthogonality is \nexpressed mathematically in the dot products in~jn = in~kn = jn~kn = 0. For the spin basis kets 0  +9 and \n0  -9, there is no spatial geometry involved. Rather, the spin basis kets 0  +9 and 0  -9 are orthogonal in \nthe mathematical sense, which we express with the inner product as 8+  0  -9 = 0. Again, we do not \nprove to you that these basis vectors are orthogonal, but we assume that a well-behaved basis set obeys \northogonality. Though there is no geometry in this property for quantum mechanical basis vectors, \nthe fundamental idea of orthogonality is the same, so we use the same language—if a general vector \n“points” in the direction of a basis vector, then there is no component in the “direction” of the other ","page_start":36,"page_end":36,"token_count":669,"section_type":"other","chapter_number":2,"chapter_title":"Operators and Measurement","chunk_index":40}
{"chunk_id":"a6904724d04fe567","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"prove to you that these basis vectors are orthogonal, but we assume that a well-behaved basis set obeys \northogonality. Though there is no geometry in this property for quantum mechanical basis vectors, \nthe fundamental idea of orthogonality is the same, so we use the same language—if a general vector \n“points” in the direction of a basis vector, then there is no component in the “direction” of the other \nunit vectors.\nIn summary, the properties of normalization, orthogonality, and completeness can be expressed \nin the case of a two-state spin-1/2 quantum system as:\n8+  0  +9 = 1\n8-  0  -9 = 1 r    normalization\n8+ 0  -9 = 0\n8- 0  +9 = 0r    orthogonality\n(1.15)\n0  c9 = a0  +9 + b0  -9    completeness    . \nNote that a product of kets 1e.g., 0  +9 0  +92 or a similar product of bras 1e.g., 8 + 08 + 02 is meaningless \nin this new notation, while a product of a ket and a bra in the “wrong” order 1e.g., 0  + 98 + 02 has a \nmeaning that we will deﬁne in Section 2.2.3. Equations (1.15) are sufﬁcient to deﬁne how the basis ","page_start":36,"page_end":36,"token_count":330,"section_type":"other","chapter_number":2,"chapter_title":"Operators and Measurement","chunk_index":41}
{"chunk_id":"1b540827409973fb","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"1.2 Quantum State Vectors \n13\nkets behave mathematically. Note that the inner product is deﬁned using a bra and a ket, though it is \ncommon to refer to the inner product of two kets, where it is understood that one is converted to a bra \nﬁrst. The order does matter, as we will see shortly.\nUsing this new notation, we can learn a little more about general quantum states and derive some \nexpressions that will be useful later. Consider the general state vector 0  c9 = a0  +9 + b0  -9. Take the \ninner product of this ket with the bra 8 + 0  and obtain\n 8 + 0  c9 = 8 + 0  1a0  +9 + b0  -92  \n = 8 + 0 a0  +9 + 8 + 0 b0  -9 \n(1.16)\n = a 8 + 0  +9 + b8 + 0  -9  \n = a ,\nusing the properties that inner products are distributive and that scalars can be moved freely through \nbras or kets. Likewise, you can show that 8- 0 c9 = b. Hence the coefﬁcients multiplying the basis \nkets are simply the inner products or projections of the general state 0 c9 along each basis ket, albeit in \nan abstract complex vector space rather than the concrete three-dimensional space of normal vectors. \nUsing these results, we rewrite the general state as\n 0  c9 = a0  +9 + b0  -9\n = 0  +9a + 0  -9b\n(1.17)\n = 0  +958 + 0  c96 + 0  -958 - 0  c96, \nwhere the rearrangement of the second equation again uses the property that scalars 1e.g., a = 8 + 0  c92 \ncan be moved through bras or kets.\nFor a general state vector 0  c9 = a0  +9 + b0  -9, we deﬁned the corresponding bra to be \n8c 0 = a*8 + 0  +b*8 - 0 . Thus, the inner product of the state 0  c9 with the basis ket 0  +9 taken in the \nreverse order compared to Eq. (1.16) yields\n 8c 0  +9 = 8 + 0 a*0  +9 + 8 - 0 b*0  +9 \n = a*8 +\n 0  +9 + b*8 - 0  +9  \n = a*.\n(1.18)\nThus, we see that an inner product with the states reversed results in a complex conjugation of the \ninner product:\n8 + 0  c 9 = 8c 0  +9*. \n(1.19)\nThis important property holds for any inner product. For example, the inner product of two general \nstates is","page_start":37,"page_end":37,"token_count":660,"section_type":"other","chapter_number":2,"chapter_title":"Operators and Measurement","chunk_index":42}
{"chunk_id":"f068d297a162c768","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":" = a*8 +\n 0  +9 + b*8 - 0  +9  \n = a*.\n(1.18)\nThus, we see that an inner product with the states reversed results in a complex conjugation of the \ninner product:\n8 + 0  c 9 = 8c 0  +9*. \n(1.19)\nThis important property holds for any inner product. For example, the inner product of two general \nstates is\n8f0  c9 = 8c 0 f 9*  . \n(1.20)\nNow we come to a new mathematical aspect of quantum vectors that differs from the use of vec-\ntors in classical mechanics. The rules of quantum mechanics (postulate 1) require that all state vectors \ndescribing a quantum system be normalized, not just the basis kets. This is clearly different from \nordinary spatial vectors, where the length or magnitude of a vector means something and only the unit \nvectors in, jn, and kn are normalized to unity. This new rule means that in the quantum mechanical state ","page_start":37,"page_end":37,"token_count":230,"section_type":"other","chapter_number":2,"chapter_title":"Operators and Measurement","chunk_index":43}
{"chunk_id":"edb526dbfe6c52be","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"14 \nStern-Gerlach Experiments\nspace only the direction—in an abstract sense—is important. If we apply this normalization require-\nment to a general state 0  c9, then we obtain\n8c 0  c9 = 5a*8 + 0 + b*8- 0 65a 0  +9 + b0  -96 = 1 \n 1 a*a 8+ 0  +9 + a*b 8+ 0  -9 + b*a 8 - 0  +9 + b*b 8 - 0  -9 = 1\n 1 a*a + b*b = 1\n(1.21)\n 1 0 a0\n2 + 0 b0\n2 = 1 ,\nor using the expressions for the coefﬁcients obtained above,\n08 + 0  c9 0\n2 + 08 -\n 0  c9 0\n2 = 1. \n(1.22)\nExample 1.1 Normalize the vector 0  c9 = C110  +9 + 2i0  -92. The complex constant C is often \nreferred to as the normalization constant.\nTo normalize 0  c9, we set the inner product of the vector with itself equal to unity and then \nsolve for C—note the requisite complex conjugations\n 1 = 8c 0  c9\n = C*518 + 0 - 2i8- 0 6C510  +9 + 2i0  -96\n = C*C518 + 0  +9 + 2i8 + 0  -9 - 2i8- 0  +9 + 48 - 0  -96 \n(1.23)\n = 50 C0\n2\n 1 0 C0 =\n1\n25\n .\nThe overall phase of the normalization constant is not physically meaningful (Problem 1.3), so \nwe follow the standard convention and choose it to be real and positive. This yields C = 1> 15. \nThe normalized quantum state vector is then\n0  c9 =\n1\n25\n 110  +9 + 2i0  -92. \n(1.24)\nNow comes the crucial element of quantum mechanics. We postulate that each term in the sum \nof Eq. (1.22) is equal to the probability that the quantum state described by the ket 0  c9 is measured \nto be in the corresponding basis state. Thus\nPSz=+ U>2 = 08+  0  c9 0\n2 \n(1.25)\nis the probability that the state 0  c9 is found to be in the state 0  +9 when a measurement of Sz is made, \nmeaning that the result Sz = +U>2 is obtained. Likewise,\nPSz=- U>2 = 08-  0  c9 0\n2 \n(1.26)\nis the probability that the measurement yields the result Sz = -U>2. The subscript on the probability ","page_start":38,"page_end":38,"token_count":667,"section_type":"other","chapter_number":2,"chapter_title":"Operators and Measurement","chunk_index":44}
{"chunk_id":"7f5bfe124829c991","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"(1.25)\nis the probability that the state 0  c9 is found to be in the state 0  +9 when a measurement of Sz is made, \nmeaning that the result Sz = +U>2 is obtained. Likewise,\nPSz=- U>2 = 08-  0  c9 0\n2 \n(1.26)\nis the probability that the measurement yields the result Sz = -U>2. The subscript on the probability \nindicates the measured value. For the spin component measurements, we will usually abbreviate this \nto, for example, P+ for an Sz = +U>2 result or P-y for an Sy = -U>2 measurement.","page_start":38,"page_end":38,"token_count":148,"section_type":"other","chapter_number":2,"chapter_title":"Operators and Measurement","chunk_index":45}
{"chunk_id":"52ec79523070dcab","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"1.2 Quantum State Vectors \n15\nWe now have a prescription for predicting the outcomes of the experiments we have been dis-\ncussing. For example, the experiment shown in Fig. 1.8 has the state 0  c9 = 0  +9 prepared by the \nﬁrst Stern-Gerlach device and then input to the second Stern-Gerlach device aligned along the z-axis. \nTherefore the probabilities of measuring the input state 0  c9 = 0  +9 to have the two output values are \nas shown. Because the spin-1/2 system has only two possible measurement results, these two prob-\nabilities must sum to unity—there is a 100% probability of recording some value in the experiment. \nThis basic rule of probabilities is why the rules of quantum mechanics require that all state vectors \nbe properly normalized before they are used in any calculation of probabilities. The experimental \npredictions shown in Fig. 1.8 are an example of the fourth postulate of quantum mechanics, which is \npresented below.\n50\n0\nP\u0002\u0005\u0006\u0005\u0002\u0004\u0002\u0002\u0002\u0003\u00022 \u0006\u00051\nP\u0003\u0005\u0006\u0005\u0002\u0004\u0003\u0002\u0002\u0003\u00022 \u0006\u00050\nZ\nZ\n\u0002\u0002\u0003\n\u0002\u0002\u0003\n\u0002\u0003\u0003\nFIGURE 1.8 Probabilities of spin component measurements.\nPostulate 4 (Spin-1/2 system)\nThe probability of obtaining the value {U>2 in a measurement of the observ-\nable Sz on a system in the state 0  c9 is\nP{ = 08{ 0  c9 0\n2,\nwhere 0 {9 is the basis ket of Sz corresponding to the result {U>2.\nThis is labeled as the fourth postulate because we have written this postulate using the language of the \nspin-1/2 system, while the general statement of the fourth postulate presented in Section 1.5 requires \nthe second and third postulates of Section 2.1. A general spin component measurement is shown in \nFig. 1.9, along with a histogram that compactly summarizes the measurement results.\nBecause the quantum mechanical probability is found by squaring an inner product, we refer to \nan inner product, 8+ 0  c9 for example, as a probability amplitude or sometimes just an amplitude; \nmuch like a classical wave intensity is found by squaring the wave amplitude. Note that the conven-\ntion is to put the input or initial state on the right and the output or ﬁnal state on the left: 8out0 in9, so \none would read from right to left in describing a problem. Because the probability involves the com-\nplex square of the amplitude, and 8out0 in9 = 8in0 out9*, this convention is not critical for calculat-\ning probabilities. Nonetheless, it is the accepted practice and is important in situations where several \namplitudes are combined.\nArmed with these new quantum mechanical rules and tools, let’s continue to analyze the experi-\nments discussed earlier. Using the experimental results and the new rules we have introduced, we can ","page_start":39,"page_end":39,"token_count":667,"section_type":"other","chapter_number":2,"chapter_title":"Operators and Measurement","chunk_index":46}
{"chunk_id":"6097e854175dfb93","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"plex square of the amplitude, and 8out0 in9 = 8in0 out9*, this convention is not critical for calculat-\ning probabilities. Nonetheless, it is the accepted practice and is important in situations where several \namplitudes are combined.\nArmed with these new quantum mechanical rules and tools, let’s continue to analyze the experi-\nments discussed earlier. Using the experimental results and the new rules we have introduced, we can \nlearn more about the mathematical behavior of the kets and the relationships among them. We will \nfocus on the ﬁrst two experiments for now and return to the others in the next chapter.","page_start":39,"page_end":39,"token_count":131,"section_type":"other","chapter_number":2,"chapter_title":"Operators and Measurement","chunk_index":47}
{"chunk_id":"2978434d4d4aa456","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"16 \nStern-Gerlach Experiments\n1.2.1 \u0002 Analysis of Experiment 1\nIn Experiment 1, the ﬁrst Stern-Gerlach analyzer prepared the system in the 0  +9 state and the sec-\nond analyzer later measured this state to be in the 0  +9 state and not in the 0  -9 state. The results of \nthe experiment are summarized in the histogram in Fig. 1.10. We can use the fourth postulate to pre-\ndict the results of this experiment. We take the inner product of the input state 0  +9 with each of the \npossible output basis states 0  +9 and 0  -9. Because we know that the basis states are normalized and \northogonal, we calculate the probabilities to be\n \nP+ = 08+  0  +9 0\n2 = 1  \n \nP- = 08  - 0  +9 0\n2 = 0 . \n \n(1.27)\nThese predictions agree exactly with the histogram of experimental results shown in Fig. 1.10. A 0  +9 \nstate is always measured to have Sz = +U>2.\n1.2.2 \u0002 Analysis of Experiment 2\nIn Experiment 2, the ﬁrst Stern-Gerlach analyzer prepared the system in the 0  +9 state and the sec-\nond analyzer performed a measurement of the spin component along the x-axis, ﬁnding 50% prob-\nabilities for each of the two possible states 0  +9x and 0  -9x, as shown in the histogram in Fig. 1.11(a). \nFor this experiment, we cannot predict the results of the measurements, because we do not yet have \n\u0002Ψ\u0003\nZ\nP\u0002\u0005\u0006\u0005\u0002\u0004\u0002\u0002Ψ\u0003\u00022\nP\u0003\u0005\u0006\u0005\u0002\u0004\u0003\u0002Ψ\u0003\u00022\n(a)\n(b)\nSz\n1\nP\nP\u0003\nP\u0002\n\u0003\u0002\n2\n\u0002\n2\n\u0002\u0002\u0003\n\u0002\u0003\u0003\nFIGURE 1.9 (a) Spin component measurement for a general input state and \n(b) histogram of measurement results.\n1\nP\nP\u0003\nP\u0002\n\u0002Ψin\u0003\u0005\u0006\u0005\u0002\u0002\u0003\nSz\n\u0003\u0002\n2\n\u0002\n2\nFIGURE 1.10 Histogram of Sz spin component measurements \nfor Experiment 1 with 0 cin9 = 0  + 9.\n","page_start":40,"page_end":40,"token_count":541,"section_type":"other","chapter_number":2,"chapter_title":"Operators and Measurement","chunk_index":48}
{"chunk_id":"6a0700eb0f4555db","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"1.2 Quantum State Vectors \n17\nenough information about how the states 0  +9x and 0  -9x behave mathematically. Rather, we will use \nthe results of the experiment to determine these states. Recalling that the experimental results would \nbe the same if the ﬁrst analyzer prepared the system to be in the 0  -9 state [see Fig. 1.11(b)], we have \nfour results for the two experiments:\nP1,+x = 0 x8+  0  +9 0\n2 = 1\n2  \nP1,-x = 0 x8 - 0  +9 0\n2 = 1\n2  \nP2,+x = 0 x8+  0  -9 0\n2 = 1\n2  \n(1.28)\nP2,-x = 0 x8 - 0  -9 0\n2 = 1\n2. \nBecause the kets 0  +9 and 0  -9 form a complete basis, the kets describing the Sx measurement, 0  +9x \nand 0  -9x, can be written in terms of them. We do not yet know the speciﬁc coefﬁcients of the 0 {9x \nstates, so we use general expressions\n0  +9x = a0  +9 + b0  -9  \n0  -9x = c0  +9 + d0  -9, \n(1.29)\nand now our task is to use the results of Experiment 2 to determine the coefﬁcients a, b, c, and d. The \nﬁrst measured probability in Eq. (1.28) is\nP1,+x = 0 x8+  0  +9 0\n2 = 1\n2. \n(1.30)\nUsing the general expression for 0  +9x in Eq. (1.29), we calculate the probability that the 0  +9 input \nstate is measured to be in the 0  +9x output state, that is, to have Sx = +U>2:\n P1,+x = 0 x8+  0  +9 0\n2\n = 05a*8 + 0 + b*8  - 0 6 0  +9 0\n2 \n(1.31)\n = 0 a*0\n2 = 0 a0\n2 ,\nwhere we convert the 0  +9x ket to a bra x8 + 0  in order to calculate the inner product. Equating the \nexperimental result in Eq. (1.30) and the prediction in Eq. (1.31), we ﬁnd\n0 a0\n2 = 1\n2. \n(1.32)\n(a)\nP\u0003x\n1\nP\nSx\n(b)\nP\u0002x\nP\u0003x\n1\nP\nSx\n\u0003\u0002\n2\n\u0002\n2\n\u0003\u0002\n2\n\u0002\n2","page_start":41,"page_end":41,"token_count":668,"section_type":"other","chapter_number":2,"chapter_title":"Operators and Measurement","chunk_index":49}
{"chunk_id":"296508e3b26c73cd","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"experimental result in Eq. (1.30) and the prediction in Eq. (1.31), we ﬁnd\n0 a0\n2 = 1\n2. \n(1.32)\n(a)\nP\u0003x\n1\nP\nSx\n(b)\nP\u0002x\nP\u0003x\n1\nP\nSx\n\u0003\u0002\n2\n\u0002\n2\n\u0003\u0002\n2\n\u0002\n2\nP\u0002x\n\u0002Ψin\u0003\u0005\u0006\u0005\u0002\u0003\u0003\n\u0002Ψin\u0003\u0005\u0006\u0005\u0002\u0002\u0003\nFIGURE 1.11 Histograms of Sx spin component measurements for Experiment 2 \nfor different input states (a) 0 cin9 = 0  + 9 and (b) 0 cin9 = 0  -9.","page_start":41,"page_end":41,"token_count":171,"section_type":"other","chapter_number":2,"chapter_title":"Operators and Measurement","chunk_index":50}
{"chunk_id":"14c47fb571497e84","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"18 \nStern-Gerlach Experiments\nSimilarly, one can calculate the other three probabilities to arrive at 0 b0\n2 = 0 c0\n2 = 0 d0\n2 = 1\n2 . (Prob-\nlem 1.4) Because each coefﬁcient is complex, each has an amplitude and phase. However, the overall \nphase of a quantum state vector is not physically meaningful (see Problem 1.3). Only the relative \nphase between different components of the state vector is physically measurable. Hence, we are free to \nchoose one coefﬁcient of each vector to be real and positive without any loss of generality. This allows \nus to write the desired states as\n 0  +9x =\n1\n12 3 0  +9 + eia0  -94   \n 0  -9x =\n1\n12 3 0  +9 + eib0  -94,\n(1.33)\nwhere a and b are relative phases that we have yet to determine. Note that these states are already nor-\nmalized because we used all of the experimental results, which reﬂect the fact that the probability for \nall possible results of an experiment must sum to unity.\nWe have used all the experimental results from Experiment 2, but the 0 {9x kets are still not deter-\nmined. We need some more information. If we perform Experiment 1 with both analyzers aligned \nalong the x-axis, the results will be as you expect—all 0  +9x states from the ﬁrst analyzer will be mea-\nsured to have Sx = +U>2 at the second analyzer, that is, all atoms exit in the 0  +9x state and none in the \n0  -9x . The probability calculations for this experiment are\nP+x = 0 x8+  0  +9x0\n2 = 1  \nP-x = 0 x8  - 0  +9x0\n2 = 0, \n(1.34)\nwhich tell us mathematically that the 0 {9x states are orthonormal to each other, just like the 0 {9 \nstates. This also implies that the 0 {9x kets form a basis, the Sx basis, which you might expect because \nthey correspond to the distinct results of a different spin component measurement. The general expres-\nsions we used for the 0 {9x kets are already normalized but are not yet orthogonal. That is the new \npiece of information we need. The orthogonality condition leads to\nx8  - 0  +9x = 0\n1\n12 38+  0 + e-ib8  - 0 4 1\n12 3 0 +9 + eia0  -94 = 0 \n1\n2 31 + ei1a-b24 = 0\n(1.35)\nei1a-b2 = -1\neia = -eib,","page_start":42,"page_end":42,"token_count":651,"section_type":"other","chapter_number":2,"chapter_title":"Operators and Measurement","chunk_index":51}
{"chunk_id":"ce634432f350de0a","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"piece of information we need. The orthogonality condition leads to\nx8  - 0  +9x = 0\n1\n12 38+  0 + e-ib8  - 0 4 1\n12 3 0 +9 + eia0  -94 = 0 \n1\n2 31 + ei1a-b24 = 0\n(1.35)\nei1a-b2 = -1\neia = -eib,\nwhere the complex conjugation of the second coefﬁcient of the x8  - 0  bra should be noted.\nWe now have an equation relating the remaining coefﬁcients a and b, but we need some more \ninformation to determine their values. Unfortunately, there is no more information to be obtained, so \nwe are free to choose the value of the phase a. This freedom comes from the fact that we have required \nonly that the x-axis be perpendicular to the z-axis, which limits the x-axis only to a plane rather than to \na unique direction. We follow convention here and choose the phase a \u0003 0. Thus we can express the \nSx basis kets in terms of the Sz basis kets as\n 0  +9x =\n1\n12 3 0  +9 + 0  -94  \n 0  -9x =\n1\n12 3 0  +9 - 0  -94. \n(1.36)","page_start":42,"page_end":42,"token_count":315,"section_type":"other","chapter_number":2,"chapter_title":"Operators and Measurement","chunk_index":52}
{"chunk_id":"38d42fc2af9b19a0","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"1.2 Quantum State Vectors \n19\nWe generally use the Sz basis as the preferred basis for writing general states, but we could use \nany basis we choose. If we were to use the Sx basis, then we could write the 0 {9 kets as general states \nin terms of the 0 {9x kets. This can be done by solving Eq. (1.36) for the 0 {9 kets, yielding\n 0  +9 =\n1\n12 3 0  +9x + 0  -9x4  \n 0  -9 =\n1\n12 3 0  +9x - 0  -9x4. \n(1.37)\nWith respect to the measurements performed in Experiment 2, Eq. (1.37) tells us that the 0  +9 \nstate is a combination of the states 0  +9x and 0  -9x. The coefﬁcients tell us that there is a 50% probabil-\nity for measuring the spin component to be up along the x-axis, and likewise for the down possibility, \nwhich is in agreement with the histogram of measurements shown in Fig. 1.11(a). We must now take \na moment to describe carefully what a combination of states, such as in Eqs. (1.36) and (1.37), is and \nwhat it is not.\n1.2.3 \u0002 Superposition States\nA general spin-1/2 state vector 0  c9 can be expressed as a combination of the basis kets 0  +9 and 0  -9\n0  c9 = a0  +9 + b0  -9. \n(1.38)\nWe refer to such a combination of states as a superposition state. To understand the importance of a \nquantum mechanical superposition state, consider the particular state\n0  c9 =\n1\n12 10  +9 + 0  -92 \n(1.39)\nand measurements on this state, as shown in Fig. 1.12(a). Note that the state 0  c9 is none other \nthan the state 0  +9x that we found in Eq. (1.36), so we already know what the measurement results \nare. If we measure the spin component along the x-axis for this state, then we record the result \nSx = +U>2 with 100% probability (Experiment 1 with both analyzers along the x-axis). If we mea-\nsure the spin component along the orthogonal z-axis, then we record the two results Sz = {U>2 \nwith 50% probability each (Experiment 2 with the ﬁrst and second analyzers along the x- and \nz-axes, respectively). Based upon this second set of results, one might be tempted to consider the \nstate 0  c9 as describing a beam that contains a mixture of atoms with 50% of the atoms in the 0  +9 ","page_start":43,"page_end":43,"token_count":643,"section_type":"other","chapter_number":2,"chapter_title":"Operators and Measurement","chunk_index":53}
{"chunk_id":"6ad37c82aeb0ac8d","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"with 50% probability each (Experiment 2 with the ﬁrst and second analyzers along the x- and \nz-axes, respectively). Based upon this second set of results, one might be tempted to consider the \nstate 0  c9 as describing a beam that contains a mixture of atoms with 50% of the atoms in the 0  +9 \nstate and 50% in the 0  -9 state. Such a state is called a mixed state and is very different from a \nsuperposition state.\nTo clarify the difference between a mixed state and a superposition state, let’s carefully exam-\nine the results of experiments on the proposed mixed-state beam, as shown in Fig. 1.12(b). If \nwe measure the spin component along the z-axis, then each atom in the 0  +9 state yields the result \nSz = +U>2 with 100% certainty and each atom in the 0  -9 state yields the result Sz = -U>2 with \n100% certainty. The net result is that 50% of the atoms yield Sz = +U>2 and 50% yield Sz = -U>2. \nThis is exactly the same result as that obtained with all atoms in the 0  +9x state, as seen in Fig. 1.12(a). \nIf we instead measure the spin component along the x-axis, then each atom in the 0  +9 state yields the \ntwo results Sx = {U>2 with 50% probability each (Experiment 2 with the ﬁrst and second analyzers \nalong the z- and x-axes, respectively). The atoms in the 0  -9 state yield the same results. The net result \nis that 50% of the atoms yield Sx = +U>2 and 50% yield Sx = -U>2. This is in stark contrast to the \nresults of Experiment 1, which tell us that once we have prepared the state to be 0  +9x, then subsequent \nmeasurements yield Sx = +U>2 with certainty, as seen in Fig. 1.12(a).","page_start":43,"page_end":43,"token_count":456,"section_type":"other","chapter_number":2,"chapter_title":"Operators and Measurement","chunk_index":54}
{"chunk_id":"9b2323d82eb0dcf4","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"20 \nStern-Gerlach Experiments\nHence we must conclude that the system described by the 0  c9 = 0  +9x state is not a mixed \nstate with some atoms in the 0  +9 state and some in the 0  -9 state. Rather, each atom in the 0  +9x \nbeam is in a state that itself is a superposition of the 0  +9 and 0  -9 states. A superposition state is \noften called a coherent superposition because the relative phase of the two terms is important. For \nexample, if the input beam were in the 0  -9x state, then there would be a relative minus sign between \nthe two coefﬁcients, which would result in an Sx = -U>2 measurement but would not affect the Sz \nmeasurement.\nZ\n50\n50\n\u0002Ψ\u0003\u0005\u0006\u0005\u0002\u0002\u0003x  \u0006\u0005(\u0002\u0002\u0003\u0005\u0002\u0005\u0002\u0003\u0003)\u0007\b2\nX\n100\n0\nZ\n50\n50\n50% \u0002\u0002\u0003\n50% \u0002\u0003\u0003\n50% \u0002\u0002\u0003\n50% \u0002\u0003\u0003\nX\n50\n50\n\u0002Ψ\u0003\u0005\u0006\u0005\u0002\u0002\u0003x \u0006\u0005(\u0002\u0002\u0003\u0005\u0002\u0005\u0002\u0003\u0003)\u0007\b2\n(b)\n(a)\nFIGURE 1.12 (a) Superposition state measurements and (b) mixed state measurements.\n","page_start":44,"page_end":44,"token_count":320,"section_type":"other","chapter_number":2,"chapter_title":"Operators and Measurement","chunk_index":55}
{"chunk_id":"04991bab30677776","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"1.2 Quantum State Vectors \n21\nWe will not have any further need to speak of mixed states, so any combination of states we use \nis a superposition state. Note that we cannot even write down a ket describing a mixed state. So if \n someone gives you a quantum state written as a ket, then it must be a superposition state and not a \nmixed state. The random option in the SPINS program produces a mixed state, while the unknown \nstates are all superposition states.\nExample 1.2 Consider the input state\n \n0 cin9 = 30  +9 + 40  -9.  \n(1.40)\nNormalize this state vector and ﬁnd the probabilities of measuring the spin component along the \nz-axis to be Sz = {U>2.\nTo normalize this state, introduce an overall complex multiplicative factor and solve for this \nfactor by imposing the normalization condition:\n \n0 cin9 = C 330  +9 + 40  -94\n \n \n8cin0 cin9 = 1\n \n \n5C* 338  +  0 + 48 - 0465C 330  +9 + 40  -946 = 1\n \n(1.41)\n \nC*C 398  +  0  +9 + 128  +  0  -9 + 128  - 0  +9 + 168  - 0  -94 = 1 \n \nC*C 3254 = 1\n \n \n0 C0\n2 = 1\n25.\n \nBecause an overall phase is physically meaningless, we choose C to be real and positive: C = 1>5. \nHence the normalized input state is\n \n@ cin9 = 3\n5 @  +9 + 4\n5 @  -9. \n(1.42)\nThe probability of measuring Sz = +U>2 is\n \n P+ = @8+ @cin9@\n2\n \n \n = @8  +  @33\n5 @  +9 + 4\n5 @  -94 @\n2 \n(1.43)\n \n = @ 3\n5 8  +  @  +9 + 4\n5 8  +  @  -9@\n2 \n \n = @ 3\n5 @\n2 =\n9\n25.\n \nThe probability of measuring Sz = -U>2 is\n \n P- = @8- @ cin9@\n2\n \n \n = @8- @33\n5 @  +9 + 4\n5 @  -94 @\n2 \n \n = @ 3\n5 8- @  +9 + 4\n5 8- @  -9@\n2 \n \n = @ 4\n5 @\n2 = 16\n25.\n \n(1.44)\n","page_start":45,"page_end":45,"token_count":591,"section_type":"other","chapter_number":2,"chapter_title":"Operators and Measurement","chunk_index":56}
{"chunk_id":"afb33ba34da749d1","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"22 \nStern-Gerlach Experiments\nNote that the two probabilities add to unity, which indicates that we normalized the input state \nproperly. A histogram of the predicted measurement results is shown in Fig. 1.13.\n 1.3 \u0002 MATRIX NOTATION\nUp to this point, we have deﬁned kets mathematically in terms of their inner products with other kets. \nThus, in the general case we write a ket as\n \n0  c9 = 8+  0  c9 0  +9 + 8  - 0  c9 0  -9, \n(1.45)\nor in a speciﬁc case, we write\n \n 0  +9x = 8+  0  +9x 0  +9 + 8  - 0  +9x 0  -9 \n \n =\n1\n12 0  +9 +\n1\n12 0  -9.\n \n \n(1.46)\nIn both of these cases, we have chosen to write the kets in terms of the 0  +9 and 0  -9 basis kets. If we \nagree on that choice of basis as a convention, then the two coefﬁcients 8+  0  +9x and 8  - 0  +9x uniquely \nspecify the quantum state, and we can simplify the notation by using just those numbers. Thus, we \nrepresent a ket as a column vector containing the two coefﬁcients that multiply each basis ket. For \nexample, we represent 0  +9x as\n \n0  +9x \u0003\n1\n22\n ¢1\n1≤ , \n(1.47)\nwhere we have used the new symbol \u0003 to signify “is represented by,” and it is understood that we \nare using the 0  +9 and 0  -9 basis or the Sz basis. We cannot say that the ket equals the column vector, \nbecause the ket is an abstract vector in the state space and the column vector is just two complex num-\nbers. If we were to choose a different basis for representing the vector, then the complex coefﬁcients \nwould be different even though the vector is unchanged. We need to have a convention for the order-\ning of the amplitudes in the column vector. The standard convention is to put the spin up amplitude \nﬁrst (at the top). Thus, the representation of the 0  -9x state in Eq. (1.36) is\n \n0  -9x \u0003\n1\n22\n ¢ 1\n-1≤ d 0  +9\nd 0  -9, \n \n(1.48)\n1\nP\nSz\n\u0003\u0002\n2\n\u0002Ψin\u0003\u0005\u0006\u0005\u0005\u0005\u0005\u0005\u0002\u0002\u0003\u0005\u0002\u0005\u0005\u0005\u0005\u0005\u0002\u0003\u0003\n3\n5\n4\n5\n\u0002\n2\nP\u0003\nP\u0002\nFIGURE 1.13 Histogram of Sz spin component measurements.\n","page_start":46,"page_end":46,"token_count":659,"section_type":"other","chapter_number":2,"chapter_title":"Operators and Measurement","chunk_index":57}
{"chunk_id":"b7f7397cc5dcbc39","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"1.3 Matrix Notation \n23\nwhere we have explicitly labeled the rows according to their corresponding basis kets. Using this con-\nvention, it should be clear that the basis kets themselves are written as\n \n0  +9 \u0003 a1\n0b  \n \n0  -9 \u0003 a0\n1b. \n \n(1.49)\nThis demonstrates the important feature that basis kets are unit vectors when written in their own basis.\nThis new way of expressing a ket simply as the collection of coefﬁcients that multiply the basis \nkets is referred to as a representation. Because we have assumed the Sz kets as the basis kets, this is \ncalled the Sz representation. It is always true that basis kets have the simple form shown in Eq. (1.49) \nwhen written in their own representation. A general ket 0  c9 is written as\n \n0  c9 \u0003 ¢ 8+  0  c9\n8- 0  c9 ≤. \n(1.50)\nThis use of matrix notation simpliﬁes the mathematics of bras and kets. The advantage is not so evident for \nthe simple two-dimensional state space of spin-1/2 systems, but it is very evident for larger dimensional \nproblems. This notation is indispensable when using computers to calculate quantum mechanical results. \nFor example, the SPINS program employs matrix calculations coded in the Java computer language to \nsimulate the Stern-Gerlach experiments using the same probability rules you are learning here.\nWe saw earlier [Eq. (1.11)] that the coefﬁcients of a bra are the complex conjugates of the coef-\nﬁcients of the corresponding ket. We also know that an inner product of a bra and a ket yields a single \ncomplex number. In order for the matrix rules of multiplication to be used, a bra must be represented \nby a row vector, with the entries being the coefﬁcients ordered in the same sense as for the ket. For \nexample, if we use the general ket\n \n0  c9 = a0  +9 + b0  -9, \n(1.51)\nwhich is represented as\n \n0  c9 \u0003 aa\nbb, \n(1.52)\nthen the corresponding bra\n \n8c 0 = a*8 +  0 + b*8  - 0  \n(1.53)\nis represented by a row vector as\n \n8c 0 \u0003 1a* b*2. \n(1.54)\nThe rules of matrix algebra can then be applied to ﬁnd an inner product. For example,\n \n 8c 0  c9 = 1a* b*2aa\nbb \n \n = 0 a0\n2 + 0 b0\n2.  \n \n(1.55)\nSo a bra is represented by a row vector that is the complex conjugate and transpose of the column vec-\ntor representing the corresponding ket.\n","page_start":47,"page_end":47,"token_count":629,"section_type":"other","chapter_number":2,"chapter_title":"Operators and Measurement","chunk_index":58}
{"chunk_id":"3e6d4a9865750a65","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"24 \nStern-Gerlach Experiments\nExample 1.3 To get some practice using this new matrix notation, and to learn some more about \nthe spin-1/2 system, use the results of Experiment 2 to determine the Sy basis kets using the matrix \napproach instead of the Dirac bra-ket approach.\nConsider Experiment 2 in the case where the second Stern-Gerlach analyzer is aligned along \nthe y-axis. We said before that the results are the same as in the case shown in Fig. 1.4. Thus, we \nhave\n \n P1,+y = @ y8+  @  +9@\n2 = 1\n2  \n \n P1,-y = @ y8-  @  +9@\n2 = 1\n2  \n \n P2,+y = @ y8+  @  -9@\n2 = 1\n2  \n(1.56)\n \n P2,-y = @ y8-  @  -9@\n2 = 1\n2, \nas depicted in the histograms of Fig. 1.14.\nThese results allow us to determine the kets 0 {9y corresponding to the spin component up and \ndown along the y-axis. The argument and calculation proceeds exactly as it did earlier for the 0 {9x \nstates up until the point [Eq. (1.35)] where we arbitrarily chose the phase a to be zero. Having done \nthat for the 0 {9x states, we are no longer free to make that same choice for the 0 {9y states. Thus \nwe use Eq. (1.35) to write the 0 {9y states as\n \n 0  +9y =\n1\n22\n 3 0  +9 + eia0  -94 \u0003\n1\n22\n a 1\neiab\n \n \n 0  -9y =\n1\n22\n 3 0  +9 - eia0  -94 \u0003\n1\n22\n a 1\n-eiab. \n(1.57)\nTo determine the phase a, we use some more information at our disposal. Experiment 2 could be \nperformed with the ﬁrst Stern-Gerlach analyzer aligned along the x-axis and the second analyzer \nalong the y-axis. Again the results would be identical (50% at each output port), yielding\n \nP+y = @ y8+  @  +9x@\n2 = 1\n2 \n(1.58)\n(a)\nP\u0002y\nP\u0003y\n1\nP\nSy\n\u0003\u0002\n2\n\u0002\n2\n(b)\nP\u0002y\nP\u0003y\n1\nP\nSy\n\u0003\u0002\n2\n\u0002\n2\n\u0002Ψin\u0003\u0005\u0006\u0005\u0002\u0003\u0003\n\u0002Ψin\u0003\u0005\u0006\u0005\u0002\u0002\u0003\nFIGURE 1.14 Histograms of Sy spin component measurements for input states (a) 0 cin9 = 0  +9 \nand (b) 0 cin9 = 0  -9.\n","page_start":48,"page_end":48,"token_count":653,"section_type":"other","chapter_number":2,"chapter_title":"Operators and Measurement","chunk_index":59}
{"chunk_id":"c893f908ec6e762b","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"1.4 General Quantum Systems \n25\nas one of the measured quantities. Now use matrix algebra to calculate this:\n \n  y8 + 0  +9x =\n1\n12 11 e-ia2 1\n12 a1\n1b\n \n \n = 1\n2 11 + e-ia2\n \n \n @ y8 + 0  +9x@\n2 = 1\n2 11 + e-ia21\n2 11 + eia2 \n(1.59)\n \n = 1\n4 11 + eia + e-ia + 12 \n \n \n = 1\n2 11 + cos a2 = 1\n2.\n \nThis result requires that cos a = 0, or that a = {p>2. The two choices for the phase correspond \nto the two possibilities for the direction of the y-axis relative to the already determined x- and z-axes. \nThe choice a = +p>2 can be shown to correspond to a right-handed coordinate system, which is the \nstandard convention, so we choose that phase. We thus represent the 0 {9y kets as\n \n 0  +9y \u0003\n1\n22\n a1\ni b\n \n \n 0  -9y \u0003\n1\n22\n a 1\n-ib. \n(1.60)\nNote that the imaginary components of these kets are required. They are not merely a mathemati-\ncal convenience as one sees in classical mechanics. In general, quantum mechanical state vectors \nhave complex coefﬁcients. But this does not mean that the results of physical measurements are \ncomplex. On the contrary, we always calculate a measurement probability using a complex square, \nso all quantum mechanics predictions of probabilities are real.\n 1.4 \u0002 GENERAL QUANTUM SYSTEMS\nThe machinery we have developed for spin-1/2 systems can be generalized to other quantum systems. \nFor example, if an observable A yields quantized measurement results an for some ﬁnite range of n, \nthen we generalize the schematic depiction of a Stern-Gerlach measurement to a measurement of the \nA\n\u0002a1\u0003\n\u0002a2\u0003\n\u0002a3\u0003\n\u0002Ψin\u0003\na2\na1\na3\nFIGURE 1.15 Generic depiction of the quantum mechanical measurement of observable A.\n","page_start":49,"page_end":49,"token_count":502,"section_type":"other","chapter_number":2,"chapter_title":"Operators and Measurement","chunk_index":60}
{"chunk_id":"de99410f77b76b73","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"26 \nStern-Gerlach Experiments\nobservable A, as shown in Fig. 1.15. The observable A labels the measurement device and the possible \nresults a1, a2, a3, etc. label the output ports. The basis kets corresponding to the results an are then 0 an9. \nThe mathematical rules about kets in this general case are\n \n 8ai@ aj9 = dij         orthonormality \n \n 0  c9 = a\ni\n8ai0  c9 0 ai9\n completeness,  \n \n(1.61)\nwhere we use the Kronecker delta\n \ndij = e0\n1 i \u0002 j\ni = j \n(1.62)\nto express the orthonormality condition compactly. In this case, the generalization of postulate 4 says \nthat the probability of a measurement of one of the possible results an is\n \nPan = 08an0 cin9 0\n2.  \n(1.63)\nExample 1.4 Imagine a quantum system with an observable A that has three possible measure-\nment results: a1, a2, and a3. The three kets 0 a19, 0 a29, and 0 a39 corresponding to these possible \nresults form a complete orthonormal basis. The system is prepared in the state\n \n0  c9 = 20 a19 - 30 a29 + 4i0 a39. \n(1.64)\nCalculate the probabilities of all possible measurement results of the observable A.\nThe state vector in Eq. (1.64) is not normalized, so we must normalize it before calculating \nprobabilities. Introducing a complex normalization constant C, we ﬁnd\n \n 1 = 8c 0  c9\n \n \n = C*128a10 - 38a20 - 4i8a302C120 a19 - 30 a29 + 4i0 a392 \n \n = 0 C0\n2548a10 a19 - 68a10 a29 + 8i8a10 a39\n \n \n- 68a20 a19 + 98a20 a29 - 12i8a20 a39\n \n(1.65)\n \n \n- 8i8a30 a19 + 12i8a30 a29 + 168a30 a396\n \n \n = 0 C0\n254 + 9 + 166 = 0 C0\n2 29\n \n \n 1 C =\n1\n129.\n \nThe normalized state is\n \n0  c9 =\n1\n129 120 a19 - 30 a29 + 4i0 a392. \n(1.66)\n","page_start":50,"page_end":50,"token_count":572,"section_type":"other","chapter_number":2,"chapter_title":"Operators and Measurement","chunk_index":61}
{"chunk_id":"a30b921c3e7fb35a","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"1.5 Postulates \n27\nThe probabilities of measuring the results a1, a2, and a3 are\n \n Pa1 = 08a10  c9 0\n2 \n \n = @8a10\n1\n129520 a19 - 30 a29 + 4i0 a396@\n2\n \n \n =\n1\n29 0 28a10 a19 - 38a10 a29 + 4i8a10 a39 0\n2 =\n4\n29 \n(1.67)\n \n Pa2 = 0 a20  c9 0\n2 = @8a2@\n1\n12952@ a19 - 3@ a29 + 4i@ a396@\n2\n=\n9\n29 \n \nPa3 = 08a30  c9 @\n2 = @8a3@\n1\n12952@ a19 - 3@ a29 + 4i@ a396@\n2\n= 16\n29 . \nA schematic of this experiment is shown in Fig. 1.16(a) and a histogram of the predicted probabili-\nties is shown in Fig. 1.16(b).\n 1.5 \u0002 POSTULATES\nWe have introduced two of the postulates of quantum mechanics in this chapter. The postulates \nof quantum mechanics dictate how to treat a quantum mechanical system mathematically and \nhow to interpret the mathematics to learn about the physical system in question. These postulates \ncannot be proven, but they have been successfully tested by many experiments, and so we accept \nthem as an accurate way to describe quantum mechanical systems. New results could force us \nto reevaluate these postulates at some later time. All six postulates are listed below to give you \nan idea where we are headed and a framework into which you can place the new concepts as we \nconfront them.\n \nPostulates of Quantum Mechanics\n \n1. The state of a quantum mechanical system, including all the information you can know \nabout it, is represented mathematically by a normalized ket 0 c9.\n \n2. A physical observable is represented mathematically by an operator A that acts on kets.\n \n3. The only possible result of a measurement of an observable is one of the eigenvalues an of \nthe corresponding operator A. \nA a2\na1\na3\n(a)\n(b)\nPa2 \u0006\nPa1\nPa1\nPa2\nPa3\n\u0006\nPa3 \u0006\nA\n1\nP\n4\n29\n9\n29\n16\n29\na3\na2\na1\n\u0002Ψin\u0003\nFIGURE 1.16 (a) Schematic diagram of the measurement of observable A and (b) histogram of the \npredicted measurement probabilities.\n","page_start":51,"page_end":51,"token_count":583,"section_type":"other","chapter_number":2,"chapter_title":"Operators and Measurement","chunk_index":62}
{"chunk_id":"493da952b77d01b2","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"28 \nStern-Gerlach Experiments\n \n4. The probability of obtaining the eigenvalue an in a measurement of the observable A on the \nsystem in the state 0  c9 is\n \nPan = 08an0  c9 0\n2, \n \n where 0 an9 is the normalized eigenvector of A corresponding to the eigenvalue an.\n \n5. After a measurement of A that yields the result an, the quantum system is in a new state that \nis the normalized projection of the original system ket onto the ket (or kets) corresponding \nto the result of the measurement:\n \n0  c\u00049 =\nPn0  c9\n28c 0 Pn0  c9\n. \n \n6. The time evolution of a quantum system is determined by the Hamiltonian or total energy \noperator H(t) through the Schrödinger equation\n \niU d\ndt\n 0  c 1t29 = H 1t2 0  c 1t29. \nAs you read these postulates for the ﬁrst time, you will undoubtedly encounter new terms and \nconcepts. Rather than explain them all here, the plan of this text is to continue to explain them through \ntheir manifestation in the Stern-Gerlach spin-1/2 experiment. We have chosen this example because it \nis inherently quantum mechanical and forces us to break away from reliance on classical intuition or \nconcepts. Moreover, this simple example is a paradigm for many other quantum mechanical systems. \nBy studying it in detail, we can appreciate much of the richness of quantum mechanics.\nSUMMARY\nThrough the Stern-Gerlach experiment we have learned several key concepts about quantum mechan-\nics in this chapter.\n• Quantum mechanics is probabilistic. \n \nWe cannot predict the results of experiments precisely. We can predict only the probability \nthat a certain result is obtained in a measurement.\n• Spin measurements are quantized. \n \nThe possible results of a spin component measurement are quantized. Only these discrete \nvalues are measured.\n• Quantum measurements disturb the system. \n \nMeasuring one physical observable can “destroy” information about other observables.\nWe have learned how to describe the state of a quantum mechanical system mathematically using \na ket, which represents all the information we can know about that state. The kets 0  +9 and 0  -9 result \nwhen the spin component Sz along the z-axis is measured to be up or down, respectively. These kets \nform an orthonormal basis, which we denote by the inner products\n \n 8+  0  +9 = 1  \n \n 8- 0  -9 = 1  \n(1.68)\n \n 8+  0  -9 = 0. \n","page_start":52,"page_end":52,"token_count":581,"section_type":"other","chapter_number":2,"chapter_title":"Operators and Measurement","chunk_index":63}
{"chunk_id":"bb5116cbd992feb9","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"Problems \n29\nThe basis is also complete, which means that it can be used to express all possible kets as superposi-\ntion states\n \n0  c9 = a0  +9 + b0  -9. \n(1.69)\nFor spin component measurements, the kets corresponding to spin up or down along the three \nCartesian axes are\n \n 0  +9   0  +9x =\n1\n12 3 0  +9 + 0  -94   0  +9y =\n1\n12 3 0  +9 + i0  -94\n \n 0  -9   0  -9x =\n1\n12 3 0  +9 - 0  -94   0  -9y =\n1\n12 3 0  +9 - i0  -94. \n(1.70)\nWe also found it useful to introduce a matrix notation for calculations. In this matrix language the kets \nin Eq. (1.70) are represented by\n \n0  +9 \u0003 ¢1\n0≤ \n0  +9x \u0003\n1\n22\n ¢1\n1≤ \n0  +9y \u0003\n1\n22\n ¢1\ni ≤ \n \n0  -9 \u0003 ¢0\n1≤ \n0  -9x \u0003\n1\n22\n ¢ 1\n-1≤ \n0  -9y \u0003\n1\n22\n ¢ 1\n-i≤. \n(1.71)\nThe most important tool we have learned so far is the probability postulate (postulate 4). To \ncalculate the probability that a measurement on an input state 0 cin9 will yield a particular result, for \nexample Sz = U>2, we complex square the inner product of the input state with the ket corresponding \nto the measured result, 0  +9 in this case:\n \nP+ = 08 + 0 cin9 0\n2. \n(1.72)\nThis is generalized to other systems where a measurement yields a particular result an corresponding \nto the ket 0 an9 as:\n \nPan = 08an0 cin9 0\n2.  \n(1.73)\nPROBLEMS\n 1.1 Consider the following state vectors:\n \n 0 c19 = 30  +9 + 40  -9\n \n \n 0 c29 = 0  +9 + 2i0  -9\n \n \n 0 c39 = 30  +9 - eip>30  -9. \na) Normalize each state vector.\nb) For each state vector, calculate the probability that the spin component is up or down \nalong each of the three Cartesian axes. Use bra-ket notation for the entire calculation.\nc) Write each normalized state in matrix notation.\nd) Repeat part (b) using matrix notation for the entire calculation.\n","page_start":53,"page_end":53,"token_count":630,"section_type":"other","chapter_number":2,"chapter_title":"Operators and Measurement","chunk_index":64}
{"chunk_id":"2a97fb51f06c8ad2","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"30 \nStern-Gerlach Experiments\n 1.2 Consider the three quantum states:\n \n 0 c19 =\n1\n13 0  +9 + i 12\n13 0  -9\n \n \n 0 c29 =\n1\n15 0  +9 -\n2\n15 0  -9\n \n \n 0 c39 =\n1\n12 0  +9 + eip>4 1\n12 0  -9. \n \n Use bra-ket notation (not matrix notation) to solve the following problems. Note  \nthat 8+  0  +9 = 1, 8- 0  -9 = 1, and 8+  0  -9 = 0.\na) For each of the 0 ci9 above, ﬁnd the normalized vector 0 fi9 that is orthogonal to it.\nb) Calculate the inner products 8ci0 cj9 for i and j = 1, 2, 3.\n 1.3 Show that a change in the overall phase of a quantum state vector does not change \nthe probability of obtaining a particular result in a measurement. To do this, consider  \nhow the probability is affected by changing the state 0  c9 to the state eid0  c9.\n 1.4 Show by explicit bra-ket calculations using the states in Eq. (1.29) that the four \nexperimental results in Eq. (1.28) lead to the results 0 b0\n2 = 0 c0\n2 = 0 d0\n2 = 1\n2.\n 1.5 A beam of spin-1/2 particles is prepared in the state\n0  c9 =\n2\n113 0  +9 + i 3\n113 0  -9.\na) What are the possible results of a measurement of the spin component Sz, and with \nwhat probabilities would they occur?\nb) What are the possible results of a measurement of the spin component Sx, and with \nwhat probabilities would they occur?\nc) Plot histograms of the predicted measurement results from parts (a) and (b).\n 1.6 A beam of spin-1/2 particles is prepared in the state\n0  c9 =\n2\n113 0  +9x + i 3\n113 0  -9x.\na) What are the possible results of a measurement of the spin component Sz, and with \nwhat probabilities would they occur?\nb) What are the possible results of a measurement of the spin component Sx, and with \nwhat probabilities would they occur?\nc) Plot histograms of the predicted measurement results from parts (a) and (b).\n 1.7 A classical coin is thrown in the air and lands on the ground, where a measurement is \nmade of its state.\na) What are the possible results of this measurement?\nb) What are the predicted probabilities for these possible outcomes?\nc) Plot a histogram of the predicted measurement results.\n 1.8 A classical cubical die is thrown onto a table and comes to rest, where a measurement \nis made of its state.\na) What are the possible results of this measurement?\nb) What are the predicted probabilities for these possible outcomes?\nc) Plot a histogram of the predicted measurement results.\n","page_start":54,"page_end":54,"token_count":693,"section_type":"other","chapter_number":2,"chapter_title":"Operators and Measurement","chunk_index":65}
{"chunk_id":"0da898d57a15bfc4","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"Problems \n31\n 1.9 A pair of dice (classical cubes) are thrown onto a table and come to rest, where a \nmeasurement is made of the state of the system (i.e., the sum of the two dice).\na) What are the possible results of this measurement?\nb) What are the predicted probabilities for these possible outcomes?\nc) Plot a histogram of the predicted measurement results.\n 1.10 Consider the three quantum states:\n \n 0 c19 = 4\n5 0  +9 + i 3\n5 0  -9\n \n \n 0 c29 = 4\n5 0  +9 - i 3\n5 0  -9\n \n \n 0 c39 = -  4\n5 0  +9 + i 3\n5 0  -9. \na) For each of the 0 ci9 above, calculate the probabilities of spin component measurements \nalong the x-, y-, and z-axes.\nb) Use your results from (a) to comment on the importance of the overall phase and of the \nrelative phases of the quantum state vector.\n 1.11  A beam of spin-1/2 particles is prepared in the state\n0  c9 =\n3\n134 0  +9 + i 5\n134 0  -9.\na) What are the possible results of a measurement of the spin component Sz, and with what \nprobabilities would they occur?\nb) Suppose that the Sz measurement yields the result Sz = -U>2. Subsequent to that result \na second measurement is performed to measure the spin component Sx. What are the \npossible results of that measurement, and with what probabilities would they occur?\nc) Draw a schematic diagram depicting the successive measurements in parts (a) and (b).\n 1.12  Consider a quantum system with an observable A that has three possible measurement \nresults: a1, a2, and a3. Write down the orthogonality, normalization, and completeness \nrelations for the three kets comprising the basis corresponding to the possible results of the  \nA measurement.\n 1.13  Consider a quantum system with an observable A that has three possible measurement \nresults: a1, a2, and a3.\na) Write down the three kets 0 a19, 0 a29, and 0 a39 corresponding to these possible results \nusing matrix notation.\nb) The system is prepared in the state\n0  c9 = 10 a19 - 20 a29 + 50 a39.\n \nWrite this state in matrix notation and calculate the probabilities of all possible measurement \nresults of the observable A. Plot a histogram of the predicted measurement results.\nc) In a different experiment, the system is prepared in the state\n0  c9 = 20 a19 + 3i0 a29.\n \nWrite this state in matrix notation and calculate the probabilities of all possible measurement \nresults of the observable A. Plot a histogram of the predicted measurement results.\n","page_start":55,"page_end":55,"token_count":636,"section_type":"other","chapter_number":2,"chapter_title":"Operators and Measurement","chunk_index":66}
{"chunk_id":"6c0f35d94e20750c","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"32 \nStern-Gerlach Experiments\n 1.14  Consider a quantum system in which the energy E is measured and there are four possible \nmeasurement results: 2 eV, 4 eV, 7 eV, and 9 eV. The system is prepared in the state\n0  c9 =\n1\n139 530 2 eV9 - i0 4 eV9 + 2eip>70 7 eV9 + 50 9 eV96.\n \n Calculate the probabilities of all possible measurement results of the energy E. Plot a \nhistogram of the predicted measurement results.\n 1.15  Consider a quantum system described by a basis 0 a19, 0 a29, and 0 a39. The system is initially \nin a state\n0\n ci9 =\ni\n13 0 a19 + 4\n2\n3 0 a29.\n \n Find the probability that the system is measured to be in the ﬁnal state\n@\n cf9 = 1+i\n13 0 a19 +\n1\n16 0 a29 +\n1\n16 0 a39.\n 1.16  The spin components of a beam of atoms prepared in the state 0 cin9 are measured and the fol-\nlowing experimental probabilities are obtained:\n \nP+ = 1\n2 \nP+x = 3\n4 \nP+y = 0.067\n \nP- = 1\n2 \nP-x = 1\n4 \nP-y = 0.933. \n \n From the experimental data, determine the input state.\n 1.17  In part (1) of SPINS Lab #2, you measured the probabilities of all the possible spin compo-\nnents for each of the unknown initial states 0 ci9 (i = 1, 2, 3, 4). Using your data from that \nlab, ﬁnd the unknown states 0 c19, 0 c29, 0 c39, and 0 c49. Express each of the unknown states \nas a linear superposition of the Sz basis states 0  +9 and 0  -9. For each state, use your result \nto calculate the theoretical values of the probabilities for each component measurement and \ncompare these theoretical predictions with your experimental results.\nRESOURCES\nActivities \nSPINS: A software program to simulate Stern-Gerlach spin experiments. The Java software runs on \nall platforms and can be downloaded in two forms:\nOpen Source Physics framework\nwww.physics.oregonstate.edu/~mcintyre/ph425/spins/index_SPINS_OSP.html\nor\nStandalone Java\nwww.physics.oregonstate.edu/~mcintyre/ph425/spins\nThe bulleted activities are available at\nwww.physics.oregonstate.edu/qmactivities\n","page_start":56,"page_end":56,"token_count":595,"section_type":"other","chapter_number":2,"chapter_title":"Operators and Measurement","chunk_index":67}
{"chunk_id":"81dc2c27d96c68c5","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"Resources \n33\n• SPINS Lab 1: An introduction to successive Stern-Gerlach spin-1/2 measurements. The random-\nness of measurements is demonstrated and students use statistical analysis to deduce probabilities \nfrom measurements.\n• SPINS Lab 2: Students deduce unknown quantum state vectors from measurements of spin projec-\ntions (part 3 requires material from Chapter 2 to do the calculations).\nStern-Gerlach simulation: A different simulation of the Stern-Gerlach experiment from the PHET \ngroup at the University of Colorado (somewhat Flashier version):\nhttp://phet.colorado.edu/en/simulation/stern-gerlach\nFurther Reading\nThe history of the Stern-Gerlach experiment and how a bad cigar helped are chronicled in  \na Physics Today article:\nB. Friedrich and D. Herschbach, “Stern and Gerlach: How a Bad Cigar Helped Reorient  \nAtomic Physics,” Phys. Today 56(12), 53–59 (2003). \n \nhttp://dx.doi.org/10.1063/1.1650229\nA different spin on the quantum mechanics of socks is discussed by John S. Bell in this article:\nJ. S. Bell, “Bertlmann’s socks and the nature of reality, ” J. Phys. Colloq. 42, C22 \nC2.41-C2.62 (1981).  \n \nhttp://cdsweb.cern.ch/record/142461\nNature has published a supplement on the milestones in spin physics. An extensive timeline \nof historical events, review articles, and links to original articles are included.\nNature Phys. 4, S1–S43 (2008). \n \nwww.nature.com/milestones/spin\nThe SPINS lab software is described in this pedagogical article:\nD. V. Schroeder and T. A. Moore, “A computer-simulated Stern-Gerlach laboratory,”  \nAm. J. Phys. 61, 798–805 (1993). \n \nhttp://dx.doi.org/10.1119/1.17172\nSome other textbooks that take a spins-ﬁrst approach or have an extensive treatment  \nof Stern-Gerlach experiments:\nR. P. Feynman, R. B. Leighton, and M. Sands, The Feynman Lectures on Physics, \nVolume 3, Quantum Mechanics, Reading, MA: Addison-Wesley Publishing Company, \nInc., 1965.\nJ. J. Sakurai, Modern Quantum Mechanics, Redwood City, CA: Addison-Wesley \nPublishing Company, Inc., 1985.\nJ. S. Townsend, A Modern Approach to Quantum Mechanics, New York: McGraw \nHill, Inc., 1992.\nC. Cohen-Tannoudji, B. Diu, and F. Laloë, Quantum Mechanics, New York: John Wiley & \nSons, 1977.\nD. F. Styer, The Strange World of Quantum Mechanics, Cambridge: Cambridge University \nPress, 2000.\n","page_start":57,"page_end":57,"token_count":652,"section_type":"other","chapter_number":2,"chapter_title":"Operators and Measurement","chunk_index":68}
{"chunk_id":"4976a3da5d472157","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"C H A P T E R \n2\nOperators and Measurement\nIn Chapter 1 we used the results of experiments to deduce a mathematical description of the spin-1/2 \nsystem. The Stern-Gerlach experiments demonstrated that spin component measurements along the \nx-, y-, or z-axes yield only {U>2 as possible results. We learned how to predict the probabilities of \nthese measurements using the basis kets of the spin component observables Sx, Sy, and Sz, and these \npredictions agreed with the experiments. However, the real power of a theory is its ability to predict \nresults of experiments that you haven’t yet done. For example, what are the possible results of a mea-\nsurement of the spin component Sn along an arbitrary direction nn and what are the predicted probabili-\nties? To make these predictions, we need to learn about the operators of quantum mechanics.\n2.1 \u0002 OPERATORS, EIGENVALUES, AND EIGENVECTORS\nThe mathematical theory we developed in Chapter 1 used only quantum state vectors. We said that \nthe state vector represents all the information we can know about the system and we used the state \nvectors to calculate probabilities. With each observable Sx, Sy, and Sz we associated a pair of kets \n corresponding to the possible measurement results of that observable. The observables themselves are \nnot yet included in our mathematical theory, but the distinct association between an observable and its \nmeasurable kets provides the means to do so.\nThe role of physical observables in the mathematics of quantum theory is described by the two \npostulates listed below. Postulate 2 states that physical observables are represented by mathematical \noperators, in the same sense that physical states are represented by mathematical vectors or kets (postu-\nlate 1). An operator is a mathematical object that acts or operates on a ket and transforms it into a new \nket, for example A0 c9 = 0 f9. However, there are special kets that are not changed by the operation \nof a particular operator, except for a possible multiplicative constant, which we know does not change \nanything measurable about the state. An example of a ket that is not changed by an operator would be \nA0 c9 = a0 c9. Such kets are known as eigenvectors of the operator A and the multiplicative constants \nare known as the eigenvalues of the operator. These are important because postulate 3 states that the only \npossible result of a measurement of a physical observable is one of the eigenvalues of the corresponding \noperator.\nPostulate 2\nA physical observable is represented mathematically by an operator A \nthat acts on kets.\n","page_start":58,"page_end":58,"token_count":565,"section_type":"other","chapter_number":2,"chapter_title":"Operators and Measurement","chunk_index":69}
{"chunk_id":"e49f49b0a73d50c4","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"2.1 Operators, Eigenvalues, and Eigenvectors \n35\nWe now have a mathematical description of that special relationship we saw in Chapter 1 between \na physical observable, Sz say, the possible results {U>2, and the kets 0{9 corresponding to those \nresults. This relationship is known as the eigenvalue equation and is depicted in Fig. 2.1 for the case \nof the spin up state in the z-direction. In the eigenvalue equation, the observable is represented by an \noperator, the eigenvalue is one of the possible measurement results of the observable, and the eigen-\nvector is the ket corresponding to the chosen eigenvalue of the operator. The eigenvector appears on \nboth sides of the equation because it is unchanged by the operator.\nThe eigenvalue equations for the Sz operator in a spin-1/2 system are:\n \n Sz0  +9 = +  U\n2 0  +9  \n \n Sz0  -9 = -  U\n2 0  -9. \n \n(2.1)\nThese equations tell us that +U>2 is the eigenvalue of Sz corresponding to the eigenvector 0  +9 and \n-U>2 is the eigenvalue of Sz corresponding to the eigenvector 0  -9. Equations (2.1) are sufﬁcient to \ndeﬁne how the Sz operator acts mathematically on kets. However, it is useful to use matrix notation \nto represent operators in the same sense that we used column vectors and row vectors in Chapter 1 to \nrepresent bras and kets, respectively. For Eqs. (2.1) to be satisﬁed using matrix algebra with the kets \nrepresented as column vectors of size 1*  2, the operator Sz must be represented by a 2 *  2 matrix. The \neigenvalue equations (2.1) provide sufﬁcient information to determine this matrix.\nTo determine the matrix representing the operator Sz, assume the most general form for a 2 *  2 matrix\n \nSz \u0003 aa\nb\nc\ndb, \n(2.2)\nwhere we are again using the \u0003 symbol to mean “is represented by.” Now write the eigenvalue equa-\ntions in matrix form:\n \n aa\nb\nc\ndb a1\n0b = +  U\n2\n a1\n0b  \n \n aa\nb\nc\ndb a0\n1b = -  U\n2\n a0\n1b. \n \n(2.3)\nPostulate 3\nThe only possible result of a measurement of an observable is one of the \neigenvalues an of the corresponding operator A.\neigenvalue\neigenvector\noperator\n\u0002\n2\nSz \u0002\u0002\u0003\u0005\u0006\u0005\u0005\u0005\u0005\u0005\u0005\u0002\u0002\u0003\u0005\nFIGURE 2.1 Eigenvalue equation for the spin up state.\n","page_start":59,"page_end":59,"token_count":622,"section_type":"other","chapter_number":2,"chapter_title":"Operators and Measurement","chunk_index":70}
{"chunk_id":"938eff26b6f494bf","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"36 \nOperators and Measurement\nNote that we are still using the convention that the 0{9 kets are used as the basis for the representation. \nIt is crucial that the rows and columns of the operator matrix are ordered in the same manner as used \nfor the ket column vectors; anything else would amount to nonsense. An explicit labeling of the rows \nand columns of the operator and the basis kets makes this clear:\n \nSz\n0  +9\n0  -9\n8+ 0\na\nb\n8- 0\nc\nd\n \n0  +9\n8+ 0\n1\n8- 0\n0\n \n0  -9\n8+ 0\n0\n8- 0\n1\n . \n(2.4)\nCarrying through the multiplication in Eqs. (2.3) yields\n \n aa\ncb = +  U\n2\n  a1\n0b  \n \n ab\ndb = -  U\n2\n a0\n1b, \n \n(2.5)\nwhich results in\n \na = + U\n2 \nb = 0 \n \nc = 0 \nd = -  U\n2. \n \n(2.6)\nThus the matrix representation of the operator Sz is\n \n Sz \u0003 aU>2\n0\n0\n-U>2b \n \n \u0003 U\n2\n a1\n0\n0\n-1b.\n \n \n(2.7)\nNote two important features of this matrix: (1) it is a diagonal matrix—it has only diagonal elements—\nand (2) the diagonal elements are the eigenvalues of the operator, ordered in the same manner as the \ncorresponding eigenvectors. In this example, the basis used for the matrix representation is that formed \nby the eigenvectors 0{9 of the operator Sz. That the matrix representation of the operator in this case \nis a diagonal matrix is a necessary and general result of linear algebra that will prove valuable as we \nstudy quantum mechanics. In simple terms, we say that an operator is always diagonal in its own \nbasis. This special form of the matrix representing the operator is similar to the special form that the \neigenvectors 0{9 take in this same representation—the eigenvectors are unit vectors in their own \nbasis. These ideas cannot be overemphasized, so we repeat them:\nAn operator is always diagonal in its own basis.  \nEigenvectors are unit vectors in their own basis.\nLet’s also summarize the matrix representations of the Sz operator and its eigenvectors:\n \nSz \u0003 U\n2\n a1\n0\n0\n-1b \n0  +9 \u0003 a1\n0b \n0  -9 \u0003 a0\n1b. \n(2.8)\n","page_start":60,"page_end":60,"token_count":586,"section_type":"other","chapter_number":2,"chapter_title":"Operators and Measurement","chunk_index":71}
{"chunk_id":"d59a0572a2fc4dce","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"2.1 Operators, Eigenvalues, and Eigenvectors \n37\n2.1.1 \u0002 Matrix Representation of Operators\nNow consider how matrix representation works in general. Consider a general operator A describ-\ning a physical observable (still in the two-dimensional spin-1/2 system), which we represent by the \ngeneral matrix\n \nA \u0003 aa\nb\nc\ndb \n(2.9)\nin the Sz basis. The operation of A on the basis ket 0  +9 yields\n \nA0  +9 \u0003 aa\nb\nc\ndba1\n0b = aa\ncb. \n(2.10)\nThe inner product of this new ket A0  +9 with the ket 0  +9 (converted to a bra following the rules) results in\n \n8+ 0 A0  +9 = 11\n02aa\ncb = a , \n(2.11)\nwhich serves to isolate one of the elements of the matrix. Hence an individual element such as \n8+ 0 A0  +9 or 8+ 0 A0  -9 is generally referred to as a matrix element. This “sandwich” of a bra, an \noperator, and a ket\n \n8bra0 OPERATOR0 ket9 \n(2.12)\nplays an important role in many quantum mechanical calculations. Even in cases where the bra and ket \nare not basis kets, such as in 8c0 A0 f9, we still refer to this as a matrix element. A schematic diagram \nof a generic matrix element is depicted in Fig. 2.2(a).\nAll four elements of the matrix representation of A can be determined in the same manner as \nEq. (2.11), with the ﬁnal result\n \nA \u0003 ¢8+ 0 A0  +9\n8+ 0 A0  -9\n8- 0 A0  +9\n8- 0 A0  -9≤. \n(2.13)\nTo emphasize the structure of the matrix, let’s write it with explicit labeling of the rows and columns:\n \nA\n0  +9\n0  -9\n8+ 0\n8+ 0 A0 +9\n8+ 0 A0  -9\n8- 0\n8- 0 A0 +9\n8- 0 A0  -9\n . \n(2.14)\n(a) bra\nket\noperator\n\u0004bra\u0002OPERATOR\u0002ket\u0003\n(b) row\ncolumn\noperator\n\u0004n\u0002A\u0002m\u0003\n\u0004Φ\u0002A\u0002Ψ\u0003\nFIGURE 2.2 (a) Schematic diagram of a generic matrix element. (b) Schematic diagram \nof the row and column labeling convention for matrix elements.\n","page_start":61,"page_end":61,"token_count":592,"section_type":"other","chapter_number":2,"chapter_title":"Operators and Measurement","chunk_index":72}
{"chunk_id":"105e855b86389f46","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"38 \nOperators and Measurement\nIn a more general problem with more than two dimensions in the complex vector space, the matrix \nrepresentation of an operator is\nA \u0003 •\nA11\nA12\nA13\ng\nA21\nA22\nA23\ng\nA31\nA32\nA33\ng\nf\nf\nf\nf\nμ, \n(2.15)\nwhere the matrix elements are\nAij = 8i0\n A0  j9 \n(2.16)\nand the basis is assumed to be the states labeled 0 i9, with the subscripts i and j labeling the rows and \ncolumns respectively, as depicted in Fig. 2.2(b). Using this matrix representation, the action of this\noperator on a general ket 0 c9 = a\ni\nci0 i9 is\nA0 c9 \u0003 •\nA11\nA12\nA13\ng\nA21\nA22\nA23\ng\nA31\nA32\nA33\ng\nf\nf\nf\nf\nμ•\nc1\nc2\nc3\nf\nμ = •\nA11c1 + A12c2 + A13c3 + g\nA21c1 + A22c2 + A23c3 + g\nA31c1 + A32c2 + A33c3 + g\nf\nμ. \n(2.17)\nIf we write the new ket 0  f9 = A0 c9 as 0 f9 = a\ni\nbi0 i9, then from Eq. (2.17) the coefﬁcients bi are\nbi = a\nj\nAij\n cj \n(2.18)\nin summation notation.\n 2.1.2 \u0002 Diagonalization of Operators\nIn the case of the operator Sz above, we used the experimental results and the eigenvalue equations to \nﬁnd the matrix representation of the operator in Eq. (2.7). It is more common to work the other way. \nThat is, one is given the matrix representation of an operator and is asked to ﬁnd the possible results of \na measurement of the corresponding observable. According to the third postulate, the possible results \nare the eigenvalues of the operator, and the eigenvectors are the quantum states representing them. In \nthe case of a general operator A in a two-state system, the eigenvalue equation is\nA0 an9 = an0 an9, \n(2.19)\nwhere we have labeled the eigenvalues an and we have labeled the eigenvectors with the correspond-\ning eigenvalues. In matrix notation, the eigenvalue equation is\n¢A11\nA12\nA21\nA22\n≤¢cn1\ncn2\n≤= an ¢cn1\ncn2\n≤, \n(2.20)\nwhere cn1 and cn2 are the unknown coefﬁcients of the eigenvector 0 an9 corresponding to the eigen-\nvalue an. This matrix equation yields the set of homogeneous equations\n 1A11 - an2cn1 + A12","page_start":62,"page_end":62,"token_count":671,"section_type":"other","chapter_number":2,"chapter_title":"Operators and Measurement","chunk_index":73}
{"chunk_id":"5bdca0fb8ec06c36","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"ing eigenvalues. In matrix notation, the eigenvalue equation is\n¢A11\nA12\nA21\nA22\n≤¢cn1\ncn2\n≤= an ¢cn1\ncn2\n≤, \n(2.20)\nwhere cn1 and cn2 are the unknown coefﬁcients of the eigenvector 0 an9 corresponding to the eigen-\nvalue an. This matrix equation yields the set of homogeneous equations\n 1A11 - an2cn1 + A12\n cn2 = 0  \n A21cn1 + 1A22 - an2cn2 = 0. \n(2.21)","page_start":62,"page_end":62,"token_count":141,"section_type":"other","chapter_number":2,"chapter_title":"Operators and Measurement","chunk_index":74}
{"chunk_id":"ba28812576da3937","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"2.1 Operators, Eigenvalues, and Eigenvectors \n39\nThe rules of linear algebra dictate that a set of homogeneous equations has solutions for the unknowns \ncn1 and cn2 only if the determinant of the coefﬁcients vanishes:\n \n` A11 - an\nA12\nA21\nA22 - an\n` = 0. \n(2.22)\nIt is common notation to use the symbol l for the eigenvalues, in which case this equation is\n \ndet 1A - lI 2 = 0, \n(2.23)\nwhere I is the identity matrix\n \nI = a1\n0\n0\n1b. \n(2.24)\nEquation (2.23) is known as the secular or characteristic equation. It is a second order equation in the \nparameter l and the two roots are identiﬁed as the two eigenvalues a1 and a2 that we are trying to ﬁnd. \nOnce these eigenvalues are found, they are then individually substituted back into Eqs. (2.21), which \nare solved to ﬁnd the coefﬁcients of the corresponding eigenvector.\nExample 2.1 Assume that we know (e.g., from Problem 2.1) that the matrix representation for \nthe operator Sy is\n \nSy \u0003 U\n2\n a0\n-i\ni\n0 b . \n(2.25)\nFind the eigenvalues and eigenvectors of the operator Sy.\nThe general eigenvalue equation is\n \nSy0 l9 = l0 l9, \n(2.26)\nand the possible eigenvalues l are found using the secular equation\n \ndet0 Sy - lI0 = 0. \n(2.27)\nThe secular equation is\n \n∞\n-l\n-i U\n2\ni U\n2\n-l\n∞= 0, \n(2.28)\nand solving yields the eigenvalues\n \n l2 + i 2 a U\n2b\n2\n= 0 \n \n l2 - a U\n2b\n2\n= 0\n \n \n l2 = a U\n2b\n2\n \n \n l = { U\n2,\n \n(2.29)\n","page_start":63,"page_end":63,"token_count":467,"section_type":"other","chapter_number":2,"chapter_title":"Operators and Measurement","chunk_index":75}
{"chunk_id":"f3633e9236deea89","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"40 \nOperators and Measurement\nwhich was to be expected, because we know that the only possible results of a measurement of any \nspin component are {U>2.\nAs before, we label the eigenvectors 0{9y. The eigenvalue equation for the positive eigenvalue is\n \nSy0  +9y = +  U\n2 0  +9y, \n(2.30)\nor in matrix notation\n \nU\n2\n a0\n-i\ni\n0 b aa\nbb = + U\n2\n aa\nbb, \n(2.31)\nwhere we must solve for a and b to determine the eigenvector. Multiplying through and canceling \nthe common factor yields\n \na-ib\nia b = aa\nbb. \n(2.32)\nThis results in two equations, but they are not linearly independent, so we need some more infor-\nmation. The normalization condition provides what we need. Thus we have two equations that \ndetermine the eigenvector coefﬁcients:\n \n b = ia\n \n \n 0 a0\n2 + 0 b0\n2 = 1. \n(2.33)\nSolving these yields\n \n 0 a0\n2 + 0 ia0\n2 = 1 \n \n 0 a0\n2 = 1\n2.\n \n(2.34)\nAgain we follow the convention of choosing the ﬁrst coefﬁcient to be real and positive, resulting in\n \n a =\n1\n12  \n \n b = i 1\n12. \n(2.35)\nThus the eigenvector corresponding to the positive eigenvalue is\n \n0  +9y \u0003\n1\n12\n a1\ni b. \n(2.36)\nLikewise, one can ﬁnd the eigenvector for the negative eigenvalue to be\n \n0  -9y \u0003\n1\n12\n a 1\n-ib . \n(2.37)\nThese are, of course, the same states we found in Chapter 1 (Eq. 1.60).\nThis procedure of ﬁnding the eigenvalues and eigenvectors of a matrix is known as diagonaliza-\ntion of the matrix and is the key step in many quantum mechanics problems. Generally, if we ﬁnd a \nnew operator, the ﬁrst thing we do is diagonalize it to ﬁnd its eigenvalues and eigenvectors. However, \nwe stop short of the mathematical exercise of ﬁnding the matrix that transforms the original matrix to \nits new diagonal form. This would amount to a change of basis from the original basis to a new basis \nof the eigenvectors we have just found, much like a rotation in three dimensions changes from one \ncoordinate system to another. We don’t want to make this change of basis. In the example above, the \nSy matrix is not diagonal, whereas the Sz matrix is diagonal, because we are using the Sz basis. It is \n","page_start":64,"page_end":64,"token_count":624,"section_type":"other","chapter_number":2,"chapter_title":"Operators and Measurement","chunk_index":76}
{"chunk_id":"2fbcff54f93f139a","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"2.2 New Operators \n41\ncommon practice to use the Sz basis as the default basis, so you can assume that is the case unless you \nare told otherwise.\nIn summary, we now know three operators and their eigenvalues and eigenvectors. The spin com-\nponent operators Sx, Sy, and Sz all have eigenvalues {U>2. The matrix representations of the opera-\ntors and eigenvectors are (see Problem 2.1)\n \nSx \u0003 U\n2\n a0\n1\n1\n0b \n0  +9x \u0003\n1\n12\n a1\n1b \n0  -9x \u0003\n1\n12\n a 1\n-1b \n \nSy \u0003 U\n2\n a0\n-i\ni\n0 b \n0  +9y \u0003\n1\n12\n a1\ni b \n0  -9y \u0003\n1\n12\n a 1\n-ib    \n.\n \n \nSz \u0003 U\n2\n a1\n0\n0\n-1b \n0  +9 \u0003 a1\n0b \n0  -9 \u0003 a0\n1b \n(2.38)\n 2.2 \u0002 NEW OPERATORS\n 2.2.1 \u0002 Spin Component in a General Direction\nNow that we know the three operators corresponding to the spin components along the three Cartesian \naxes, we can use them to ﬁnd the operator Sn for the spin component along a general direction nn. This \nnew operator will allow us to predict results of experiments we have not yet performed. The direction \nnn is speciﬁed by the polar and azimuthal angles u and f as shown in Fig. 2.3. The unit vector nn is\n \nn = in sin u cos f + jn sin u sin f + kn cos u. \n(2.39)\nThe spin component along this direction is obtained by projecting the spin vector S onto this new unit \nvector\n \n Sn = S~nn\n \n \n = Sx sin u cos f + Sy sin u sin f + Sz cos u. \n \n(2.40)\nThe matrix representations we found for Sx, Sy, and Sz lead to the matrix representation of the spin \ncomponent operator Sn (Problem 2.6):\n \nSn \u0003 U\n2\n acos u\nsin u  e-if\nsin u  eif\n-cos u\nb. \n(2.41)\nn\nz\nx\ny\nΦ\nΘ\n\u0006\nFIGURE 2.3 General direction along which to measure the spin component.\n","page_start":65,"page_end":65,"token_count":550,"section_type":"other","chapter_number":2,"chapter_title":"Operators and Measurement","chunk_index":77}
{"chunk_id":"15b094e640c21fe5","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"42 \nOperators and Measurement\nWe have found a new operator, so to learn about its properties, we diagonalize it. Following \nthe diagonalization procedure outlined in Section 2.1.2, we ﬁnd that the eigenvalues of Sn are {U>2 \n(Problem 2.7). So if we measure the spin component along any direction, we get only two possible \nresults. This is to be expected from the experiments in Chapter 1. The eigenvectors for these two pos-\nsible measurements are (Problem 2.7):\n0  +9n = cos u\n2 0  +9 + sin u\n2\n eif0  -9  \n0  -9n = sin u\n2 0  +9 - cos u\n2\n eif0  -9, \n(2.42)\nwhere we again use the convention of choosing the ﬁrst coefﬁcient to be real and positive. It is important \nto point out that the 0  +9n eigenstate (or equivalently the 0  -9n eigenstate) can be used to represent any \npossible ket in a spin-1/2 system, if one allows for all possible angles 0 … u 6 p and 0 … f 6 2p.\nWe generally write the most general state as 0 c9 = a0  +9 + b0  -9, where a and b are complex. Requir-\ning that the state be normalized and using the freedom to choose the ﬁrst coefﬁcient real and positive \nreduces this to\n0 c9 = 0 a0 0  +9 + 41 - 0 a0\n2\n eif0  -9. \n(2.43)\nIf we change the parametrization of 0 a0  to cos 1u>22, we see that 0  +9n is equivalent to the most general \nstate 0 c9. This correspondence between the 0  +9n eigenstate and the most general state is only valid in a \ntwo-state system such as spin 1/2. In systems with more dimensionality, it does not hold because more \nparameters are needed to specify the most general state than are afforded by the two angles u and f.\nExample 2.2 Find the probabilities of the measurements shown in Fig. 2.4, assuming that the \nﬁrst Stern-Gerlach analyzer is aligned along the direction nn deﬁned by the angles u = 2p>3 and \nf = p>4.\nThe measurement by the ﬁrst Stern-Gerlach analyzer prepares the system in the spin up state \n0  +9n along the direction nn. This state is then the input state to the second Stern-Gerlach analyzer. \nThe input state is\n 0 cin9 = 0  +9n = cos u\n2 0  +9 + sin u\n2\n eif0  -9 \n = cos p\n3 0  +9 + sin p\n3\n eip/40  -9\n = 1","page_start":66,"page_end":66,"token_count":664,"section_type":"other","chapter_number":2,"chapter_title":"Operators and Measurement","chunk_index":78}
{"chunk_id":"18c1ff0003db3ea8","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"0  +9n along the direction nn. This state is then the input state to the second Stern-Gerlach analyzer. \nThe input state is\n 0 cin9 = 0  +9n = cos u\n2 0  +9 + sin u\n2\n eif0  -9 \n = cos p\n3 0  +9 + sin p\n3\n eip/40  -9\n = 1\n2 0  +9 + 23\n2\n eip/40  -9.\n(2.44)\nX\n?\n?\n^n\nP x\n2\nP x\nx\nn\n2\nx\nn\nFIGURE 2.4  Measurement of the spin component after state preparation in a new direction.","page_start":66,"page_end":66,"token_count":164,"section_type":"other","chapter_number":2,"chapter_title":"Operators and Measurement","chunk_index":79}
{"chunk_id":"ffae3bd687412af0","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"2.2 New Operators \n43\nThe second analyzer is aligned along the x-axis, so the probabilities are\n \n P+x = 0 x8+ 0 cin9 0\n2 = 0 x8+ 0  +9n0\n2  \n \n P-x = 0 x8- 0 cin9 0\n2 = 0 x8- 0  +9n0\n2. \n(2.45)\nLet’s calculate the ﬁrst probability using bra-ket notation, recalling that 0  +9x =\n1\n12 30  +9 + 0  -94:\n \n P+x = 0 x8+ 0  +9n0\n2\n \n \n = @ 1\n12 38+ 0   +  8- 0 4 1\n2 3 0  +9 + 13eip/40  -94@\n2\n \n \n = @\n1\n212 31 + 13eip/44@\n2\n \n \n = 1\n8 31 + 13eip/4431 + 13e-ip/44\n \n \n = 1\n8 31 + 131eip/4 + e-ip/42 + 34\n \n \n = 1\n8 34 + 213 cos 1p>424\n \n \n = 1\n8 34 + 213> 124 \u0002 0.806.\n \n(2.46)\nLet’s calculate the second probability using matrix notation, recalling that 0  -9x =\n1\n12 30  +9 - 0  -94:\n \n P-x = 0 x8- 0  +9n0\n2\n \n \n = ` 1\n12 11\n-12 1\n2 a\n1\n13eip>4b `\n2\n \n \n = @\n1\n212 31 - 13eip/44@\n2\n \n \n = 1\n8 34 - 213 cos 1p>424\n \n \n = 1\n8 34 - 213> 124 \u0002 0.194. \n(2.47)\nThe two results sum to unity as they must. A histogram of the measured results is shown in Fig. 2.5.\n1\nP\nP\u0003x\nP\u0002x\n\u0002Ψin\u0003 \u0006\u0005\u0002\u0002\u0003n\nSx\n\u0003\u0002\n2\n\u0002\n2\nFIGURE 2.5 Histogram of spin component Sx measurement.\n","page_start":67,"page_end":67,"token_count":532,"section_type":"other","chapter_number":2,"chapter_title":"Operators and Measurement","chunk_index":80}
{"chunk_id":"259449897255f93f","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"44 \nOperators and Measurement\n2.2.2 \u0002 Hermitian Operators\nSo far we have deﬁned how operators act upon kets. For example, an operator A acts on a ket 0 c9 to \nproduce a new ket 0 f9 = A0 c9. The operator acts on the ket from the left; if the operator is on the \nright of the ket, the result is not deﬁned, which is clear if you try to use matrix representation. Simi-\nlarly, an operator acting on a bra must be on the right side of the bra\n8j0 = 8c0 A \n(2.48)\nand the result is another bra. However, the bra 8j0 = 8c0 A is not the bra 8f0  that corresponds to the \nket 0 f9 = A0 c9. Rather the bra 8f0  is found by deﬁning a new operator A† that obeys\n8f0 = 8c0 A†. \n(2.49)\nThis new operator A† is called the Hermitian adjoint of the operator A. We can learn something about the \nHermitian adjoint by taking the inner product of the state 0 f9 = A0 c9 with another (unspeciﬁed) state 0 b9\n 8f0 b9 = 8b0 f9*\n 38c0 A+4 0 b9 = 58b03A0 c946* \n 8c0 A+ 0 b9 = 8b0 A0 c9*,\n(2.50)\nwhich relates the matrix elements of A and A†. Equation (2.50) tells us that the matrix representing the \nHermitian adjoint A† is found by transposing and complex conjugating the matrix representing A. This \nis consistent with the deﬁnition of Hermitian adjoint used in matrix algebra.\nAn operator A is said to be Hermitian if it is equal to its Hermitian adjoint A†. If an operator is \nHermitian, then the bra 8c0 A is equal to the bra 8f0  that corresponds to the ket 0 f9 = A0 c9. That is, a \nHermitian operator can act to the right on a ket or to the left on a bra with the same result. In quantum \nmechanics, all operators that correspond to physical observables are Hermitian. This includes the spin \noperators we have already encountered as well as the energy, position, and momentum operators that \nwe will introduce in later chapters. The Hermiticity of physical observables is important in light of two \nfeatures of Hermitian matrices: (1) Hermitian matrices have real eigenvalues, which ensures that results \nof measurements are always real; and (2) the eigenvectors of a Hermitian matrix comprise a complete \nset of basis states, which ensures that we can use the eigenvectors of any observable as a valid basis.\n 2.2.3 \u0002 Projection Operators","page_start":68,"page_end":68,"token_count":663,"section_type":"other","chapter_number":3,"chapter_title":"Schrödinger Time Evolution","chunk_index":81}
{"chunk_id":"db2d6cabd2a0281d","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"features of Hermitian matrices: (1) Hermitian matrices have real eigenvalues, which ensures that results \nof measurements are always real; and (2) the eigenvectors of a Hermitian matrix comprise a complete \nset of basis states, which ensures that we can use the eigenvectors of any observable as a valid basis.\n 2.2.3 \u0002 Projection Operators\nFor the spin-1/2 system, we now know four operators: Sx, Sy, Sz, and Sn. Let’s look for some other \noperators. Consider the ket 0 c9 written in terms of its coefﬁcients in the Sz basis\n 0 c9 = a0  +9 + b0  -9\n = 18+ 0 c92 0  +9 + 18- 0 c92 0  -9. \n(2.51)\nLooking for the moment only at the ﬁrst term, we can write it as a number times a ket, or as a ket times \na number:\n18+ 0 c92 0  +9 = 0  +918+ 0 c92 \n(2.52)\nwithout changing its meaning. Using the second form, we can separate the bra and ket that form the \ninner product and obtain\n0  +918+ 0 c92 = 10  +98+ 02 0 c9. \n(2.53)","page_start":68,"page_end":68,"token_count":303,"section_type":"other","chapter_number":3,"chapter_title":"Schrödinger Time Evolution","chunk_index":82}
{"chunk_id":"95617474057566d7","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"2.2 New Operators \n45\nThe new term in parentheses is a product of a ket and a bra but in the opposite order compared to the \ninner product deﬁned earlier. This new object must be an operator because it acts on the ket 0 c9 and\nproduces another ket: 18+ 0 c92 0  +9. This new type of operator is known as an outer product.\nReturning now to Eq. (2.51), we write 0 c9 using these new operators:\n 0 c9 = 8+ 0 c9 0  +9 + 8- 0 c9 0  -9  \n = 0  +98+ 0 c9 + 0  -98- 0 c9  \n = 10  +98+ 0 + 0  -98- 02 0 c9. \n(2.54)\nThe term in parentheses is a sum of two outer products and is clearly an operator because it acts on a \nket to produce another ket. In this special case, the result is the same as the original ket, so the operator \nmust be the identity operator 1. This relationship is often written as\n0  +98+ 0 + 0  -98- 0 = 1 \n(2.55)\nand is known as the completeness relation or closure. It expresses the fact that the basis states 0 {9 \ncomprise a complete set of states, meaning any arbitrary ket can be written in terms of them. To make \nit obvious that outer products are operators, it is useful to express Eq. (2.55) in matrix notation using \nthe standard rules of matrix multiplication:\n 0  +98+ 0 + 0  -98- 0 \u0003 a1\n0b11\n02 + a0\n1b10\n12 \n \u0003 a1\n0\n0\n0b + a0\n0\n0\n1b\n \u0003 a1\n0\n0\n1b.\n(2.56)\nEach outer product is represented by a matrix, as we expect for operators, and the sum of these two \nouter products is represented by the identity matrix, which we expected from Eq. (2.54).\nNow consider the individual operators 0  +98+ 0  and 0  -98- 0 . These operators are called projec-\ntion operators, and for spin 1/2 they are given by\n P+ = 0  +98+ 0 \u0003 a1\n0\n0\n0b  \n P- = 0  -98- 0 \u0003 a0\n0\n0\n1b. \n(2.57)\nIn terms of these new operators the completeness relation can also be written as\nP+ + P- = 1. \n(2.58)\nWhen a projection operator for a particular eigenstate acts on a state 0 c9, it produces a new ket that is \naligned along the eigenstate and has a magnitude equal to the amplitude (including the phase) for the \nstate 0 c9 to be in that eigenstate. For example,","page_start":69,"page_end":69,"token_count":665,"section_type":"other","chapter_number":3,"chapter_title":"Schrödinger Time Evolution","chunk_index":83}
{"chunk_id":"d3e8decb31703add","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"1b. \n(2.57)\nIn terms of these new operators the completeness relation can also be written as\nP+ + P- = 1. \n(2.58)\nWhen a projection operator for a particular eigenstate acts on a state 0 c9, it produces a new ket that is \naligned along the eigenstate and has a magnitude equal to the amplitude (including the phase) for the \nstate 0 c9 to be in that eigenstate. For example,\nP+ 0 c9 = 0  +98+ 0 c9 = 18+ 0 c92 0  +9  \nP- 0 c9 = 0  -98- 0 c9 = 18- 0 c92 0  -9. \n(2.59)","page_start":69,"page_end":69,"token_count":169,"section_type":"other","chapter_number":3,"chapter_title":"Schrödinger Time Evolution","chunk_index":84}
{"chunk_id":"990e5ef21f0fa89d","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"46 \nOperators and Measurement\nNote also that a projector acting on its corresponding eigenstate results in that eigenstate, and a projec-\ntor acting on an orthogonal state results in zero:\n \n P+ 0  +9 = 0  +98+ 0  +9 = 0  +9 \n \n P- 0  +9 = 0  -98- 0  +9 = 0.  \n \n(2.60)\nBecause the projection operator produces the probability amplitude, we expect that it must be inti-\nmately tied to measurement in quantum mechanics.\nWe found in Chapter 1 that the probability of a measurement is given by the square of the inner \nproduct of initial and ﬁnal states (postulate 4). Using the new projection operators, we rewrite the \nprobability as\n \n P+ = 08+ 0 c9 0\n2\n \n \n = 8+ 0 c9*8+ 0 c9 \n \n = 8c0  +98+ 0 c9  \n \n = 8c0 P+ 0 c9.\n \n \n(2.61)\nThus we say that the probability of the measurement Sz = U>2 can be calculated as a matrix element \nof the projection operator, using the input state 0 c9 and the projector P+ corresponding to the result.\nThe other important aspect of quantum measurement that we learned in Chapter 1 is that a mea-\nsurement disturbs the system. That is, if an input state 0 c9 is measured to have Sz = +U>2, then the \noutput state is no longer 0 c9 but is changed to 0  +9. We saw above that the projection operator does this \noperation for us, with a multiplicative constant of the probability amplitude. Thus, if we divide by this \namplitude, which is the square root of the probability, then we can describe the abrupt change of the \ninput state as\n \n0 c\u00049 =\nP+ 0 c9\n2\n 8c0 P+ 0 c9\n= 0  +9, \n(2.62)\nwhere 0 c\u00049 is the output state. This effect is described by the ﬁfth postulate, which is presented below \nand is often referred to as the projection postulate.\nPostulate 5\nAfter a measurement of A that yields the result an, the quantum system is in a \nnew state that is the normalized projection of the original system ket onto the \nket (or kets) corresponding to the result of the measurement:\n0 c\u00049 =\nPn0 c9\n2\n 8c0 Pn0 c9\n.\nThe projection postulate is at the heart of quantum measurement. This effect is often referred to as the \ncollapse (or reduction or projection) of the quantum state vector. The projection postulate clearly states \nthat quantum measurements cannot be made without disturbing the system (except in the case where the \ninput state is the same as the output state), in sharp contrast to classical measurements. The collapse of \n the quantum state makes quantum mechanics irreversible, again in contrast to classical mechanics.\n","page_start":70,"page_end":70,"token_count":658,"section_type":"other","chapter_number":3,"chapter_title":"Schrödinger Time Evolution","chunk_index":85}
{"chunk_id":"2e65942f2bd62d85","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"2.2 New Operators \n47\nWe can use the projection postulate to make a model of quantum measurement, as shown in the \nrevised depiction of a Stern-Gerlach measurement system in Fig. 2.6. The projection operators act on \nthe input state to produce output states with probabilities given by the squares of the amplitudes that \nthe projection operations yield. For example, the input state 0 cin9 is acted on the projection operator \nP+ = 0  +98+ 0 , producing an output ket 0 cout9 = 0  +918+ 0 cin92 with probability P+ = 08+ 0 cin9 0 2. \nThe output ket 0 cout9 = 0  +918+ 0 cin92 is really just a 0  +9 ket that is not properly normalized, so we \nnormalize it for use in any further calculations. We do not really know what is going on in the mea-\nsurement process, so we cannot explain the mechanism of the collapse of the quantum state vector. \nThis lack of understanding makes some people uncomfortable with this aspect of quantum mechan-\nics and has been the source of much controversy surrounding quantum mechanics. Trying to better \nunderstand the measurement process in quantum mechanics is an ongoing research problem. How-\never, despite our lack of understanding, the theory for predicting the results of experiments has been \nproven with very high accuracy.\n 2.2.4 \u0002 Analysis of Experiments 3 and 4\nWe can now return to Experiments 3 and 4 from Chapter 1 and analyze them with these new tools. \nRecall that Experiment 3 is the same as Experiment 4a, and Experiments 4a and 4b are similar in that \nthey each use only one of the output ports of the second Stern-Gerlach analyzer as input to the third \nanalyzer. Figure 2.7 depicts these experiments again, with Fig. 2.7(a) showing a hybrid experiment \nthat is essentially Experiment 4a in its upper half and Experiment 4b in its lower half, and Fig. 2.7(b) \nshowing Experiment 4c. In this problem, we discuss the probability that an atom leaving the ﬁrst \nanalyzer in the 0  +9 state is detected in one of the counters connected to the output ports of the third \nanalyzer. Such a probability involves two measurements at the second and third analyzers. The total \nprobability is the product of the individual probabilities of each measurement.\nFor the hybrid experiment shown in Fig. 2.7(a), the probability of measuring an atom at the top-\nmost counter is the probability of measuring Sx = +U>2 at the second analyzer, 0 x8+ 0  +9 0\n2, times the \nprobability of measuring Sz = +U>2 at the third analyzer, 08+ 0  +9x0\n2, giving\nPupper, + = 08+ 0  +9x0\n2\n 0 x8+ 0  +9 0\n2. \n(2.63)","page_start":71,"page_end":71,"token_count":665,"section_type":"other","chapter_number":3,"chapter_title":"Schrödinger Time Evolution","chunk_index":86}
{"chunk_id":"70067ef8df614692","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"most counter is the probability of measuring Sx = +U>2 at the second analyzer, 0 x8+ 0  +9 0\n2, times the \nprobability of measuring Sz = +U>2 at the third analyzer, 08+ 0  +9x0\n2, giving\nPupper, + = 08+ 0  +9x0\n2\n 0 x8+ 0  +9 0\n2. \n(2.63)\nLikewise the probability of measuring the atom to have Sx = +U>2 and then Sz = -U>2 is\nPupper, - = 08- 0  +9x0\n2\n 0 x8+ 0  +9 0\n2, \n(2.64)\nZ\n\u0002\u0002\u0003 \u0004\u0002\u0002\n\u0002\u0003\u0003 \u0004\u0003\u0002\n\u0002\u0002\u0003\n\u0002\u0003\u0003\nProject\nNormalize\n\u0002Ψ\u0003\n\u0002\u0002\u0003\u0004\u0002\u0002Ψ\u0003\n\u0002\u0003\u0003\u0004\u0003\u0002Ψ\u0003\nFIGURE 2.6 Schematic diagram of the role of the projection operator in a Stern-Gerlach spin measurement.","page_start":71,"page_end":71,"token_count":252,"section_type":"other","chapter_number":3,"chapter_title":"Schrödinger Time Evolution","chunk_index":87}
{"chunk_id":"64ee69e83e116aea","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"48 \nOperators and Measurement\nwhere we have written the product so as to be read from right to left as is the usual practice with \nquantum mechanical amplitudes and probabilities. For atoms that take the lower path from the second \nanalyzer, the ﬁnal probabilities are\n \nPlower, + = 08+ 0  -9x0\n2\n 0 x8- 0  +9 0\n2  \n \nPlower, - = 08- 0  -9x0\n2\n 0 x8- 0  +9 0\n2. \n \n(2.65)\nFor Experiment 4c, shown in Fig. 2.7(b), we have a new situation at the second analyzer. Both \noutput ports are connected to the third analyzer, which means that the probability of an atom from \nthe ﬁrst analyzer being input to the third analyzer is 100%. So we need only calculate the probability \nof passage through the third analyzer. The crucial step is determining the input state, for which we \nuse the projection postulate. Because both states are used, the relevant projection operator is the sum \nof the two projection operators for each port, P+x + P-x, where P+x = 0  +9x x8+ 0  and P-x = 0  -9x x8- 0 .\nThus the state after the second analyzer is\n \n 0 c29 =\n1P+x + P-x2 0 c19\n2\n 8c101P+x + P-x2 0 c19\n \n \n =\n1P+x + P-x2 0  +9\n2\n 8+ 01P+x + P-x2 0  +9\n . \n \n(2.66)\n100\n0\nX\nZ\nZ\n100\n100\n25\n25\nZ\nX\nZ\n100\n(a)\n(b)\n50\n25\n25\nZ\n50\nFIGURE 2.7 (a) Hybrid Experiment 4a and 4b, and (b) Experiment 4c.\n","page_start":72,"page_end":72,"token_count":440,"section_type":"other","chapter_number":3,"chapter_title":"Schrödinger Time Evolution","chunk_index":88}
{"chunk_id":"c326ad66194d82cc","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"2.2 New Operators \n49\nIn this simple example, the projector P+x + P-x is equal to the identity operator because the two states \nform a complete basis. This clearly simpliﬁes the calculation, giving 0 c29 = 0  +9, but to illustrate our \npoint, let’s simplify only the denominator (which equals one), giving\n 0 c29 = 10  +9x x8+ 0 + 0  -9x x8- 02 0  +9  \n = 0  +9x x8+ 0  +9 + 0  -9x x8- 0  +9. \n(2.67)\nThus the beam entering the third analyzer can be viewed as a coherent superposition of the eigenstates \nof the second analyzer. Now calculate the probability of measuring spin up at the third analyzer:\n P+ = 08+ 0 c29 0\n2\n = 08+ 0  +9x x8+ 0  +9 + 8+ 0  -9x x8- 0  +9 0\n2. \n(2.68)\nThe probability of measuring spin down at the third analyzer is similarly\nP - = 08- 0 c29 0\n2\n = 08- 0  +9x x8+ 0  +9 + 8- 0  -9x x8- 0  +9 0\n2. \n(2.69)\nIn each case, the probability is a square of a sum of amplitudes, each amplitude being the amplitude \nfor a successive pair of measurements. For example, in P- the amplitude 8- 0  +9x x8+ 0  +9 refers to the \nupper path that the initial 0  +9 state takes as it is ﬁrst measured to be in the 0  +9x state and then mea-\nsured to be in the 0  -9 state (read from right to left). This amplitude is added to the amplitude for the \nlower path because the beams of the second analyzer are combined, in the proper fashion, to create the \ninput beam to the third analyzer. When the sum of amplitudes is squared, four terms are obtained, two \nsquares and two cross terms, giving\n P- = 08- 0  +9x x8+ 0  +9 0\n2 + 08- 0  -9x x8- 0  +9 0\n2 \n +8- 0  +9*\nx x8+ 0  +9*8- 0  -9x x8- 0  +9\n +8- 0  +9x x8+ 0  +98- 0  -9*\nx x8- 0  +9*\n = Pupper, - + Plower, - + interference terms. \n(2.70)\nThis tells us that the probability of detecting an atom to have spin down when both paths are used is the ","page_start":73,"page_end":73,"token_count":660,"section_type":"other","chapter_number":3,"chapter_title":"Schrödinger Time Evolution","chunk_index":89}
{"chunk_id":"c815c546dc6c8455","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":" +8- 0  +9x x8+ 0  +98- 0  -9*\nx x8- 0  +9*\n = Pupper, - + Plower, - + interference terms. \n(2.70)\nThis tells us that the probability of detecting an atom to have spin down when both paths are used is the \nsum of the probabilities for detecting a spin down atom when either the upper path or the lower path is \nused alone plus additional cross terms involving both amplitudes, which are commonly called interference \nterms. It is these additional terms, which are not complex squares and so could be positive or negative, that \nallow the total probability to become zero in this case, illustrating the phenomenon of interference.\nThis interference arises from the nature of the superposition of states that enters the third analyzer. \nTo illustrate, consider what happens if we change the superposition state to a mixed state, as we dis-\ncussed previously in Section 1.2.3. Recall that a superposition state implies a beam with each atom in \nthe same state, which is a combination of states, while a mixed state implies that the beam consists of \natoms in separate states. As we have described it so far, Experiment 4c involves a superposition state \nas the input to the third analyzer. We can change this to a mixed state by “watching” to see which of \nthe two output ports of the second analyzer each atom travels through. There are a variety of ways to \nimagine doing this experimentally. The usual idea proposed is to illuminate the paths with light and \nwatch for the scattered light from the atoms. With proper design of the optics, the light can be localized ","page_start":73,"page_end":73,"token_count":356,"section_type":"other","chapter_number":3,"chapter_title":"Schrödinger Time Evolution","chunk_index":90}
{"chunk_id":"c9a4638ad07a3fcb","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"50 \nOperators and Measurement\nsufﬁciently to determine which path the atom takes. Hence, such experiments are generally referred to \nas “Which Path” or “Welcher Weg” experiments. Such experiments can be performed in the SPINS \nprogram by selecting the “Watch” feature. Once we know which path the atom takes, the state is not \nthe superposition 0 c29 described above, but is either 0  +9x or 0  -9x, depending on which path produces \nthe light signal. To ﬁnd the probability that atoms are detected at the spin down counter of the third \nanalyzer, we add the probabilities for atoms to follow the path 0  +9 S 0  +9x S 0  -9 to the probability \nfor other atoms to follow the path 0  +9 S 0  -9x S 0  -9 because these are independent events, giving\n Pwatch,  - = 08- 0  +9x x8+ 0  +9 0\n2 + 08- 0  -9x x8- 0  +9 0\n2 \n = Pupper, - + Plower, - ,\n(2.71)\nin which no interference terms are present.\nThis interference example illustrates again the important distinction between a coherent superpo-\nsition state and a statistical mixed state. In a coherent superposition, there is a deﬁnite relative phase \nbetween the different states, which gives rise to interference effects that are dependent on that phase. In a \nstatistical mixed state, the phase relationship between the states has been destroyed and the interference \nis washed out. Now we can understand what it takes to have the beams “properly” combined after the \nsecond analyzer of Experiment 4c. The relative phases of the two paths must be preserved. Anything that \nrandomizes the phase is equivalent to destroying the superposition and leaving only a statistical mixture. \nIf the beams are properly combined to leave the superposition intact, the results of Experiment 4c are \nthe same as if no measurement were made at the second analyzer. So even though we have used a mea-\nsuring device in the middle of Experiment 4c, we generally say that no measurement was made there. \nWe can summarize our conclusions by saying that if no measurement is made on the intermediate state, \nthen we add amplitudes and then square to ﬁnd the probability, while if an intermediate measurement is \n performed (i.e., watching), then we square the amplitudes ﬁrst and then add to ﬁnd the probability. One \nis the square of a sum and the other is the sum of squares, and only the former exhibits interference.\n 2.3 \u0002 MEASUREMENT\nLet’s discuss how the probabilistic nature of quantum mechanics affects the way experiments are \nperformed and compared with theory. In classical physics, a theoretical prediction can be reliably \ncompared to a single experimental result. For example, a prediction of the range of a projectile can be \ntested by doing an experiment. The experiment may be repeated several times in order to understand ","page_start":74,"page_end":74,"token_count":661,"section_type":"other","chapter_number":3,"chapter_title":"Schrödinger Time Evolution","chunk_index":91}
{"chunk_id":"1f8b2bcf35ee3988","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":" 2.3 \u0002 MEASUREMENT\nLet’s discuss how the probabilistic nature of quantum mechanics affects the way experiments are \nperformed and compared with theory. In classical physics, a theoretical prediction can be reliably \ncompared to a single experimental result. For example, a prediction of the range of a projectile can be \ntested by doing an experiment. The experiment may be repeated several times in order to understand \nand possibly reduce any systematic errors (e.g., wind) and measurement errors (e.g., misreading the \ntape measure). In quantum mechanics, a single measurement is meaningless. If we measure an atom to \nhave spin up in a Stern-Gerlach analyzer, we cannot discern whether the original state was 0  +9 or 0  -9x \nor any arbitrary state 0 c9 1except 0  -92. Moreover, we cannot repeat the measurement on the same \natom, because the original measurement changed the state, per the projection postulate.\nThus, one must, by necessity, perform identical measurements on identically prepared systems. \nIn the spin-1/2 example, an initial Stern-Gerlach analyzer is used to prepare atoms in a particular state \n0 c9. Then a second Stern-Gerlach analyzer is used to perform the same experiment on each identically \n prepared atom. Consider performing a measurement of Sz on N identically prepared atoms. Let N+ be the \nnumber of times the result +U>2 is recorded and N− be the number of times the result -U>2 is recorded. \nBecause there are only two possible results for each measurement, we must have N = N+ + N-. The \nprobability postulate (postulate 4) predicts that the probability of measuring +U>2 is\nP+ = 08+ 0 c9 0\n2. \n(2.72)","page_start":74,"page_end":74,"token_count":391,"section_type":"other","chapter_number":3,"chapter_title":"Schrödinger Time Evolution","chunk_index":92}
{"chunk_id":"4d7e2d77c6dc1908","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"2.3 Measurement \n51\nFor a ﬁnite number N of atoms, we expect that N+ is only approximately equal to P+ N due to the statis-\ntical ﬂuctuations inherent in a random process. Only in the limit of an inﬁnite number N do we expect \nexact agreement:\nlim\nNS \u0005\nN+\nN = P+ = 08+ 0 c9 0\n2. \n(2.73)\nIt is useful to characterize a data set in terms of the mean and standard deviation (see Appendix \nA for further information on probability). The mean value of a data set is the average of all the mea-\nsurements. The expected or predicted mean value of a measurement is the sum of the products of each \npossible result and its probability, which for this spin-1/2 measurement is\n8Sz9 = a+  U\n2b P+ + a-  U\n2b P-   , \n(2.74)\nwhere the angle brackets signify average or mean value. Using the rules of quantum mechanics we \nrewrite this mean value as\n 8Sz9 = +  U\n2\n 08+ 0 c9 0\n2 + a-  U\n2b 08- 0 c9 0\n2\n = +  U\n2\n 8c0  +98+ 0 c9 + a-  U\n2b8c0  -98- 0 c9 \n = 8c0 J\n +  U\n2 0  +98+ 0 c9 + a-  U\n2b 0  -98- 0 c9\n R \n = 8c03Sz0  +98+ 0 c9 + Sz0  -98- 0 c94\n = 8c0 Sz30  +98+ 0 + 0  -98- 04 0 c9.\n(2.75)\nAccording to the completeness relation, the term in square brackets in the last line is unity, so \nwe obtain\n8Sz9 = 8c0 Sz0 c9  . \n(2.76)\nWe now have two ways to calculate the predicted mean value, Eq. (2.74) and Eq. (2.76). Which you \nuse generally depends on what quantities you have readily available. The matrix element version in \nEq. (2.76) is more common and is especially useful in systems that are more complicated than the \n2-level spin-1/2 system. This predicted mean value is commonly called the expectation value, but \nit is not the expected value of any single experiment. Rather it is the expected mean value of a large \nnumber of experiments. It is not a time average, but an average over many identical experiments. For a \ngeneral quantum mechanical observable, the expectation value is\n8A9 = 8c0 A0 c9 = a\nn\nanPan   , \n(2.77)\nwhere an are the eigenvalues of the operator A.\nTo see how the concept of expectation values applies to our study of spin-1/2 systems, consider ","page_start":75,"page_end":75,"token_count":666,"section_type":"other","chapter_number":3,"chapter_title":"Schrödinger Time Evolution","chunk_index":93}
{"chunk_id":"89238f5035e2c50e","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"number of experiments. It is not a time average, but an average over many identical experiments. For a \ngeneral quantum mechanical observable, the expectation value is\n8A9 = 8c0 A0 c9 = a\nn\nanPan   , \n(2.77)\nwhere an are the eigenvalues of the operator A.\nTo see how the concept of expectation values applies to our study of spin-1/2 systems, consider \ntwo examples. First consider a system prepared in the state 0  +9. The expectation value of Sz is\n8Sz9 = 8+ 0 Sz0  +9, \n(2.78)","page_start":75,"page_end":75,"token_count":137,"section_type":"other","chapter_number":3,"chapter_title":"Schrödinger Time Evolution","chunk_index":94}
{"chunk_id":"712aa1320a15d3af","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"52 \nOperators and Measurement\nwhich we calculate with bra-ket notation\n \n 8Sz9 = 8+ 0 Sz0  +9 \n \n = 8+ 0 U\n2 0  +9  \n \n = U\n2\n 8+ 0  +9  \n \n = U\n2.\n \n \n(2.79)\nThis result should seem obvious because +U>2 is the only possible result of a measurement of Sz for \nthe 0  +9 state, so it must be the expectation value.\nNext consider a system prepared in the state 0  +9x. In this case, the expectation value of Sz is\n \n8Sz9 = x8+ 0 Sz0 +9x. \n(2.80)\nUsing matrix notation, we obtain\n \n 8Sz9 =\n1\n12  11\n12 U\n2\n a1\n0\n0\n-1b 1\n12 a1\n1b \n \n = U\n4\n  11\n12a 1\n-1b = 0 U.\n \n \n(2.81)\nAgain this is what you expect, because the two possible measurement results {U>2 each have 50% \nprobability, so the average value is zero. Note that the value of zero is never measured, so it is not the \nvalue “expected” for any given measurement, but rather the expected mean value of an ensemble of \nmeasurements.\nIn addition to the mean value, it is common to characterize a measurement by the standard devia-\ntion, which quantiﬁes the spread of measurements about the mean or expectation value. The standard \ndeviation is deﬁned as the square root of the mean of the square of the deviations from the mean, and \nfor an observable A is given by\n \n\u0006A = 481A - 8A9229, \n(2.82)\nwhere the angle brackets signify average value as used in the deﬁnition of an expectation value. This \nresult is also often called the root-mean-square deviation, or r.m.s. deviation. We need to square the \ndeviations, because the deviations from the mean are equally distributed above and below the mean in \nsuch a way that the average of the deviations themselves is zero. This expression can be simpliﬁed by \nexpanding the square and performing the averages, resulting in\n \n \u0006A = 481A2 - 2A8A9 + 8A9229 \n \n = 48A29 - 28A98A9 + 8A92 \n \n = 48A29 - 8A92,\n \n \n(2.83)\n","page_start":76,"page_end":76,"token_count":555,"section_type":"other","chapter_number":3,"chapter_title":"Schrödinger Time Evolution","chunk_index":95}
{"chunk_id":"8cf44a97b219b606","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"2.3 Measurement \n53\nwhere one must be clear to distinguish between the square of the mean 8A9\n2 and the mean of the \nsquare 8A29. While the mean of the square of an observable may not be a common experimental quan-\ntity, it can be calculated using the deﬁnition of the expectation value\n \n8A29 = 8c0 A20 c9. \n(2.84)\nThe square of an operator means that the operator acts twice in succession:\n \nA20 c9 = AA0 c9 = A1A0 c92. \n(2.85)\nTo gain experience with the standard deviation, return to the two examples used above. To calcu-\nlate the standard deviation, we need to ﬁnd the mean of the square of the operator S z. In the ﬁrst case \nA 0  +9 initial stateB, we get\n \n 8S\n 2\nz 9 = 8+ @S\n 2\nz @  +9 = 8+ @Sz Sz@  +9 = 8+ @Sz U\n2\n @  +9\n \n = 8+ 0 a U\n2b\n2\n0  +9\n \n = a U\n2b\n2\n.\n \n(2.86)\nWe already have the mean of the operator Sz in Eq. (2.79) so the standard deviation is\n \n \u0006Sz = 48S\n 2\nz 9 - 8Sz9\n2  \n \n = Ca U\n2b\n2\n- a U\n2b\n2\n \n \n = 0 U,\n \n \n(2.87)\nwhich is to be expected because there is only one possible result, and hence no spread in the results of \nthe measurement, as shown in the histogram in Fig. 2.8(a).\n(a)\n1\nP\nP−\nP+\nSz\n\u0003\u0002\n2\n\u0002\n2\n1\nP\nP−\nP+\nSz\n\u0003\u0002\n2\n\u0002\n2\n\u000bSz \u0006 \u0002\n2\n\u000bSz \u0006\u00050\n\u0004Sz\u0003 \u0006\u0005\n\u0004Sz\u0003 \u0006\u00050\u0005\n\u0002\n2\n\u0002Ψin\u0003\u0005\u0006\u0005\u0002\u0002\u0003\n\u0002Ψin\u0003\u0005\u0006\u0005\u0002\u0002\u0003x\nFIGURE 2.8 Idealized measurements of Sz with (a) a 0  +9 input state and (b) with a 0  +9x input state.\n","page_start":77,"page_end":77,"token_count":536,"section_type":"other","chapter_number":3,"chapter_title":"Schrödinger Time Evolution","chunk_index":96}
{"chunk_id":"b8ed6567b84a97e2","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"54 \nOperators and Measurement\nIn the second case 1 0  +9x initial state2, the mean of the square of the operator Sz is\n \n 8S\n 2\nz 9 = x8+ @ S\n 2\nz @  +9x\n \n \n =\n1\n12\n 11\n12  U\n2\n a1\n0\n0\n-1b U\n2\n a1\n0\n0\n-1b 1\n12\n a1\n1b \n \n = 1\n2\n a U\n2b\n2\n11\n12a1\n0\n0\n-1ba 1\n-1b\n \n \n = 1\n2\n a U\n2b\n2\n11\n12a1\n1b\n \n \n = a U\n2b\n2\n.\n \n \n(2.88)\nThe mean of the operator Sz is in Eq. (2.81), giving a standard deviation of \n \n \u0006Sz = 48S\n 2\nz 9 - 8Sz9\n2 \n \n = Ca U\n2b\n2\n- 0 U2 \n(2.89)\n \n = U\n2.\nAgain this makes sense because each measurement deviates from the mean (0 U) by the same value of \nU>2, as shown in the histogram in Fig. 2.8(b).\nThe standard deviation \u0006A represents the uncertainty in the results of an experiment. In quan-\ntum mechanics, this uncertainty is inherent and fundamental, meaning that you cannot design the \nexperiment any better to improve the result. What we have calculated then is the minimum uncertainty \nallowed by quantum mechanics. Any actual uncertainty may be larger due to experimental error. \nThis is another ramiﬁcation of the probabilistic nature of quantum mechanics and will lead us to the \nHeisenberg uncertainty relation in Section 2.5.\n 2.4 \u0002 COMMUTING OBSERVABLES\nWe found in Experiment 3 that two incompatible observables could not be known or measured simul-\ntaneously, because measurement of one somehow erased knowledge of the other. Let us now explore \nfurther what it means for two observables to be incompatible and how incompatibility affects the results \nof measurements. First we need to deﬁne a new object called a commutator. The commutator of two \noperators is deﬁned as the difference between the products of the two operators taken in alternate orders:\n \n3A, B4 = AB - BA. \n(2.90)\nIf the commutator is equal to zero, we say that the operators or observables commute; if it is not zero, we \nsay they don’t commute. Whether or not two operators commute has important ramiﬁcations in analyzing \na quantum system and in making measurements of the two observables represented by those operators.\n","page_start":78,"page_end":78,"token_count":608,"section_type":"other","chapter_number":3,"chapter_title":"Schrödinger Time Evolution","chunk_index":97}
{"chunk_id":"81ef10f670f510f9","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"2.4 Commuting Observables \n55\nConsider what happens when two operators A and B do commute:\n \n 3A, B4 = 0\n \n \n AB - BA = 0\n \n \n AB = BA. \n(2.91)\nThus, for commuting operators the order of operation does not matter, whereas it does for noncom-\nmuting operators. Now let 0 a9 be an eigenstate of the operator A with eigenvalue a:\n \nA0 a9 = a0 a9. \n(2.92)\nOperate on both sides of this equation with the operator B and use the fact that A and B commute:\n \n BA0 a9 = Ba0 a9\n \n \n AB0 a9 = aB0 a9\n \n \n A1B0 a92 = a1B0 a92. \n(2.93)\nThe last equation says that the state B0 a9 is also an eigenstate of the operator A with the same eigen-\nvalue a. Assuming that each eigenvalue has a unique eigenstate (which is true if there is no degen-\neracy, but we haven’t discussed degeneracy yet), the state B0 a9 must be some scalar multiple of the \nstate 0 a9. If we call this multiple b, then we can write\n \nB0 a9 = b0 a9, \n(2.94)\nwhich is just an eigenvalue equation for the operator B. Thus, we must conclude that the state 0 a9 is \nalso an eigenstate of the operator B, with the eigenvalue b. The assumption that the operators A and B \ncommute has led us to the result that A and B have common or simultaneous sets of eigenstates. This \nresult bears repeating:\nCommuting operators share common eigenstates.\nThe ramiﬁcations of this result for experiments are very important. Recall that a measurement of \nthe observable A projects the initial state 0 c9 onto an eigenstate of A: 0 a9. A subsequent measurement \nof the observable B then projects the input state 0 a9 onto an eigenstate of B. But the eigenstates of \nthe commuting operators A and B are the same, so the second measurement does not change the state \n0 a9. Thus, another measurement of A following the measurement of B yields the same result as the \n initial measurement of A, as illustrated in Fig. 2.9. Thus we say that we can know the eigenvalues of \nthese two observables simultaneously. It is common to extend this language and say that these two \nobservables can be measured simultaneously, although, as illustrated in Fig. 2.9, we do not really measure \nthem simultaneously. What we mean is that we can measure one observable without erasing our knowl-\nedge of the previous results of the other observable. Observables A and B are said to be compatible.\n100\n0\n0\nA\nB\nA\na1\na1\na1\na2\na3\na1\na2\na3\na1\na2\na3\nb1\nb2\nb3\nFIGURE 2.9 Successive measurements of commuting observables.\n","page_start":79,"page_end":79,"token_count":671,"section_type":"other","chapter_number":3,"chapter_title":"Schrödinger Time Evolution","chunk_index":98}
{"chunk_id":"b7fa276bc6e5dd4c","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"56 \nOperators and Measurement\nConversely, if two operators do not commute, then they are incompatible observables and cannot \nbe measured or known simultaneously. This is what we saw in Experiment 3 in Chapter 1. In that case, the \ntwo observables were Sx and Sz. Let’s take a look at their commutator to show that they are not compatible:\n \n3Sz, Sx4 \u0003 U\n2\n a1\n0\n0\n-1b U\n2\n a0\n1\n1\n0b - U\n2\n a0\n1\n1\n0b U\n2\n a1\n0\n0\n-1b \n \n\u0003 a U\n2b\n2\n c a 0\n1\n-1\n0b - a0\n-1\n1\n0 bd\n \n \n\u0003 a U\n2b\n2\na 0\n2\n-2\n0b\n \n \n= i USy. \n(2.95)\nAs expected, these two operators do not commute. In fact, none of the spin component operators com-\nmute with each other. The complete commutation relations are\n \n3Sx, Sy4 = i USz\n \n \n3Sy, Sz4 = i USx \n \n3Sz, Sx4 = i USy   , \n(2.96)\nso written to make the cyclic relations clear.\nWhen we represent operators as matrices, we can often decide whether two operators commute \nby inspection of the matrices. Recall the important statement: An operator is always diagonal in its \nown basis. If you are presented with two matrices that are both diagonal, they must share a common \nbasis, and so they commute with each other. To be explicit, the product of two diagonal matrices\n \nAB \u0003 §\na1\n0\n0\ng\n0\na2\n0\ng\n0\n0\na3\ng\nf\nf\nf\nf\n¥  §\nb1\n0\n0\ng\n0\nb2\n0\ng\n0\n0\nb3\ng\nf\nf\nf\nf\n¥ \n \n\u0003 §\na1b1\n0\n0\ng\n0\na2b2\n0\ng\n0\n0\na3b3\ng\nf\nf\nf\nf\n¥ , \n(2.97)\nis clearly independent of the order of the product. Note, however, that you may not conclude that two \noperators do not commute if one is diagonal and one is not, nor if both are not diagonal.\n 2.5 \u0002 UNCERTAINTY PRINCIPLE\nThe intimate connection between the commutator of two observables and the possible precision of \nmeasurements of the two corresponding observables is reﬂected in an important relation that we sim-\nply state here (see more advanced texts for a derivation). The product of the uncertainties or standard \ndeviations of two observables is related to the commutator of the two observables:\n \n\u0006A\u0006B Ú 1\n2 083A, B49 0   . \n(2.98)\n","page_start":80,"page_end":80,"token_count":666,"section_type":"other","chapter_number":3,"chapter_title":"Schrödinger Time Evolution","chunk_index":99}
{"chunk_id":"33e61665bef948d3","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"2.6 S2 Operator \n57\nThis is the uncertainty principle of quantum mechanics. Consider what it says about a simple Stern-\nGerlach experiment. The uncertainty principle for the Sx and Sy spin components is\n \n \u0006Sx\u0006Sy Ú 1\n2 083Sx, Sy49 0  \n \n Ú 1\n2 08i USz9 0\n \n \n Ú U\n2 08Sz9 0 .\n \n(2.99)\nThese uncertainties are the minimal quantum mechanical uncertainties that would arise in any experi-\nment. Any experimental uncertainties due to experimenter error, apparatus errors, and statistical limi-\ntations would be additional.\nLet’s now apply the uncertainty principle to Experiment 3 where we ﬁrst learned of the impact of \nmeasurements in quantum mechanics. If the initial state is 0  +9, then a measurement of Sz results in an \nexpectation value 8Sz9 = U>2 with an uncertainty \u0006Sz = 0, as illustrated in Fig. 2.8(a). Thus the uncer-\ntainty principle dictates that the product of the other uncertainties for measurements of the 0  +9 state is\n \n\u0006Sx\u0006Sy Ú a U\n2b\n2\n, \n(2.100)\nor simply\n \n\u0006Sx\u0006Sy \u0002 0. \n(2.101)\nThis implies that\n \n  \u0006Sx \u0002 0  \n \n \u0006Sy \u0002 0. \n(2.102)\nThe conclusion to draw from this is that while we can know one spin component absolutely (\u0006Sz = 0), \nwe can never know all three, nor even two, simultaneously. This is in agreement with our results from \nExperiment 3. This lack of ability to measure all spin components simultaneously implies that the spin \ndoes not really point in a given direction, as a classical spin or angular momentum does. So when we \nsay that we have measured “spin up,” we really mean only that the spin component along that axis is up, \nas opposed to down, and not that the complete spin angular momentum vector points up along that axis.\n 2.6 \u0002 S2 OPERATOR\nAnother indication that the spin does not point along the axis along which you measure the spin com-\nponent is obtained by considering a new operator that represents the magnitude of the spin vector but \nhas no information about the direction. It is common to use the square of the spin vector for this task. \nThis new operator is\n \nS2 = S2\nx + S2\ny + S2\nz , \n(2.103)\nand it is calculated in the Sz representation as\n \nS2 \u0003 a U\n2b\n2\n c a0\n1\n1\n0b a0\n1\n1\n0b + a0\n-i\ni\n0\n ba0\n-i\ni\n0\n b + a1\n0\n0\n-1ba1\n0\n0\n-1bd  \n \n\u0003 a U\n2b\n2\n c a1\n0\n0\n1b + a1\n0\n0\n1b + a1\n0\n0\n1bd  \n(2.104)\n \n\u0003 3\n4 U2 a1\n0\n0\n1b. \n","page_start":81,"page_end":81,"token_count":699,"section_type":"other","chapter_number":3,"chapter_title":"Schrödinger Time Evolution","chunk_index":100}
{"chunk_id":"5a4da90865bda310","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"58 \nOperators and Measurement\nThus the S2 operator is proportional to the identity operator, which means it must commute with all \nthe other operators Sx, Sy, and Sz. It also means that all states are eigenstates of the S2 operator. Thus, \nwe can write \n \nS20 c9 = 3\n4 U20 c9 \n(2.105)\nfor any state 0 c9 in the spin-1/2 system.\nFor the case of spin 1/2, note that the expectation value of the operator S2 is\n \n8S29 = 3\n4 U2, \n(2.106)\nwhich would imply that the “length” of the spin vector is\n \n0 S0 = 48S29 = 23 U\n2. \n(2.107)\nThis is appreciably longer than the measured component of U>2, implying that the spin vector can \nnever be fully aligned along any axis. A useful mental model of the spin vector and its component is \nshown in Fig. 2.10. In this vector model, one can imagine the total spin vector S precessing around the \nz-axis at a constant angle to form a cone, with a constant spin component Sz. For a spin-1/2 system in \nthe “spin up” state 0  +9, this classical model yields the same expectation values and uncertainties as the \nquantum model (Problem 2.9)\n \n 8Sz9 = U\n2   \u0006Sz = 0  \n \n 8Sx9 = 0   \u0006Sx \u0002 0  \n \n 8Sy9 = 0   \u0006Sy \u0002 0. \n(2.108)\nS\nz\ny\nx\n(a)\nS\n(b)\nz\n\u0002\n2\n√3\u0002\n2\n\u0002\u0002\n2\n\u0002\n2\n√3\u0002\n2\n\u0002\u0002\n2\nFIGURE 2.10 (a) Vector model illustrating the classical precision of a spin vector and the allowed \nquantum mechanical components. (b) Two-dimensional version of the vector model with constant spin \nvector length and two possible components.\n","page_start":82,"page_end":82,"token_count":458,"section_type":"other","chapter_number":3,"chapter_title":"Schrödinger Time Evolution","chunk_index":101}
{"chunk_id":"83c0546a460fe9f5","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"2.7 Spin-1 System \n59\n?\n?\n?\n0\n1\n0\n1\nZ\nFIGURE 2.11 Spin-1 Stern-Gerlach experiment.\nHowever, a quantum mechanical experiment on a spin component eigenstate does not yield the time \ndependence of the precession implied by the picture in Fig. 2.10(a). Rather, the quantum mechanical \nspin vector is more accurately thought of as smeared out over the whole cone in a uniform random sense. \nThis randomness is often termed quantum fuzziness and will be evident in other systems we will study \nlater. To avoid the inaccurate precession part of the vector model, it is often illustrated as in Fig. 2.10(b).\n 2.7 \u0002 SPIN-1 SYSTEM\nThe Stern-Gerlach experiment depicted in Fig. 1.1 can be performed on a variety of atoms or par-\nticles. Such experiments always result in a ﬁnite number of discrete beams exiting the analyzer. For \nspin-1/2 particles, there are two output beams. For the case of three output beams, the deﬂections are \nconsistent with magnetic moments arising from spin angular momentum components of 1U, 0 U, and \n-1U. For an analyzer aligned along the z-axis, the three output states are labeled 0 19, 0 09, and 0  -19, \nas shown in Fig. 2.11. This is what we call a spin-1 system. (Note that the SPINS software and our \nStern-Gerlach schematics use arrows for the 0 19 and 0  -19 output beams, but these outputs are not the \nsame as the spin-1/2 states that are also denoted with arrows.)\nThe three eigenvalue equations for the spin component operator Sz of a spin-1 system are\n Sz0 19 = U0 19\n Sz0 09 = 0 U0 09\n Sz0  -19 = -U0  -19. \n(2.109)\nAs we did in the spin-1/2 case, we choose the Sz basis as the standard basis in which to express kets \nand operators using matrix representation. In Section 2.1, we found that eigenvectors are unit vectors \nin their own basis and an operator is always diagonal in its own basis. Using the ﬁrst rule, we can \nimmediately write down the eigenvectors of the Sz operator:\n0 19 \u0003 °\n1\n0\n0\n¢  0 09 \u0003 °\n0\n1\n0\n¢  0  -19 \u0003 °\n0\n0\n1\n¢ , \n(2.110)\nwhere we again use the convention that the ordering of the rows follows the eigenvalues in descending \norder. Using the second rule, we write down the Sz operator\nSz \u0003 °\n1U\n0\n0\n0\n0 U\n0\n0\n0\n-1U\n¢ = U °\n1\n0\n0\n0\n0\n0\n0\n0\n-1\n¢ \n(2.111)","page_start":83,"page_end":83,"token_count":671,"section_type":"other","chapter_number":3,"chapter_title":"Schrödinger Time Evolution","chunk_index":102}
{"chunk_id":"be88ee1398dfd047","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"0\n1\n0\n¢  0  -19 \u0003 °\n0\n0\n1\n¢ , \n(2.110)\nwhere we again use the convention that the ordering of the rows follows the eigenvalues in descending \norder. Using the second rule, we write down the Sz operator\nSz \u0003 °\n1U\n0\n0\n0\n0 U\n0\n0\n0\n-1U\n¢ = U °\n1\n0\n0\n0\n0\n0\n0\n0\n-1\n¢ \n(2.111)\nwith the eigenvalues 1U, 0 U, and -1U ordered along the diagonal. The value zero is a perfectly valid \neigenvalue in some systems.","page_start":83,"page_end":83,"token_count":158,"section_type":"other","chapter_number":3,"chapter_title":"Schrödinger Time Evolution","chunk_index":103}
{"chunk_id":"89293344e682d22d","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"60 \nOperators and Measurement\nThe same four experiments performed on the spin-1/2 system can be performed on a spin-1 sys-\ntem. Conceptually the results are the same. One important difference occurs in Experiment 2, where a \nmeasurement of Sz is ﬁrst performed to prepare a particular state, and then a subsequent measurement \nof Sx (or Sy) is performed. Based upon the results of the spin-1/2 experiment, one might expect each of \nthe possible components to have one-third probability. Such is not the case. Rather, one set of results is\n \n P1x = 0 x810 19 0\n2 = 1\n4\n \n \n P0x = 0 x800 19 0\n2 = 1\n2\n \n \n P-1x = 0 x8-10 19 0\n2 = 1\n4, \n(2.112)\nas illustrated in Fig. 2.12. These experimental results can be used to determine the Sx eigenstates in \nterms of the Sz basis\n \n 0 19x = 1\n2@ 19 +\n1\n12@ 09 + 1\n2 @ -19\n \n \n 0 09x =\n1\n12@ 19 -\n1\n12@  -19\n \n \n 0  -19x = 1\n2@ 19 -\n1\n12@ 09 + 1\n2@  -19. \n(2.113)\nLikewise, we can ﬁnd the Sy eigenstates:\n \n 0 19y = 1\n2@ 19 + i 1\n12@ 09 - 1\n2@  -19\n \n \n 0 09y =\n1\n12@ 19 +\n1\n12@  -19\n \n \n 0  -19y = 1\n2@ 19 - i 1\n12@ 09 - 1\n2@  -19. \n(2.114)\nThe matrix representations of the Sx and Sy operators are\n \nSx \u0003\nU\n12\n °\n0\n1\n0\n1\n0\n1\n0\n1\n0\n¢  Sy \u0003\nU\n12\n °\n0\n-i\n0\ni\n0\n-i\n0\ni\n0\n¢ . \n(2.115)\n25\n25\nX\n0\n50\nZ\n0\n1\n1 x\n0 x\n1 x\nFIGURE 2.12 Experiment 2 in the spin-1 case.\n","page_start":84,"page_end":84,"token_count":542,"section_type":"other","chapter_number":3,"chapter_title":"Schrödinger Time Evolution","chunk_index":104}
{"chunk_id":"410f95983589d8ad","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"2.7 Spin-1 System \n61\n0\nP\nP−1\nP1\nP0\n1\nSz\nΨin\n(2 1\ni 0\ni\n1 )\n√6\n1\nFIGURE 2.13 Histogram of measurements of z-component of spin for spin-1 particle.\nExample 2.3 A spin-1 system is prepared in the state\n \n0 cin9 =\n2\n16 0 19 -\ni\n16 0 09 +\ni\n16 0  -19. \n(2.116)\nFind the probabilities of measuring each of the possible spin components along the z-axis.\nThe probability of measuring Sz = +1U is\n \n P1 = 0810 cin90\n2\n \n \n = @810C 2\n16 0 19 -\ni\n16 0 09 +\ni\n16 0  -19D@\n2\n \n \n = @ 2\n16 810 19 -\ni\n16810 09 +\ni\n16 810  -19@\n2\n \n \n = @ 2\n16\n @\n2\n= 2\n3.\n \n(2.117)\nThe probability of measuring Sz = 0 U is\n \n P0 = 0800 cin90\n2\n \n \n = @800C 2\n16 0 19 -\ni\n16 0 09 +\ni\n16 0  -19D@\n2\n \n \n = @ -i\n16\n @\n2\n= 1\n6.\n \n(2.118)\nThe probability of measuring Sz = -1U is\n \n P-1 = 08-10 cin90\n2\n \n \n = @8-10C 2\n16 0 19 -\ni\n16 0 09 +\ni\n16 0  -19D@\n2\n \n \n = @ i\n16\n @\n2\n= 1\n6.\n \n(2.119)\nThe three probabilities add to unity, as they must. A histogram of the predicted measurement results \nis shown in Fig. 2.13.\n","page_start":85,"page_end":85,"token_count":440,"section_type":"other","chapter_number":3,"chapter_title":"Schrödinger Time Evolution","chunk_index":105}
{"chunk_id":"e4db08911e718bc5","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"62 \nOperators and Measurement\nTo generalize to other possible spin systems, we need to introduce new labels. We use the label \ns to denote the spin of the system, such as spin 1/2, spin 1, spin 3/2. The number of beams exiting a \nStern-Gerlach analyzer is 2s + 1. In each of these cases, a measurement of a spin component along \nany axis yields results ranging from a maximum value of s U to a minimum value of -s U, in unit steps \nof the value U. We denote the possible values of the spin component along the z-axis by the label m, \nthe integer or half-integer multiplying U. A quantum state with speciﬁc values of s and m is denoted as \n0 sm9, yielding the eigenvalue equations\n \n S20 sm9 = s(s + 1) U20 sm9 \n \n Sz0 sm9 = m U0 sm9.\n \n \n(2.120)\nThe label s is referred to as the spin angular momentum quantum number or the spin quantum \nnumber for short. The label m is referred to as the spin component quantum number or the mag-\nnetic quantum number because of its role in magnetic ﬁeld experiments like the Stern-Gerlach \nexperiment. The connection between this new 0 sm9 notation and the spin-1/2 0{9 notation is\n \n @ 1\n2 1\n29 = 0  +9  \n \n @ 1\n2, -1\n29 = 0  -9. \n(2.121)\nFor the spin-1 case, the connection to this new notation is\n \n 0 119 = 0 19\n \n \n 0 109 = 0 09\n \n \n 0 1, -19 = 0  -19. \n(2.122)\nWe will continue to use the 0{9 notation, but we will ﬁnd the new notation useful later (Chapter 7).\n 2.8 \u0002 GENERAL QUANTUM SYSTEMS\nLet’s extend the important results of this chapter to general quantum mechanical systems. For a gen-\neral observable A with quantized measurement results an, the eigenvalue equation is\n \nA0 an9 = an0 an9. \n(2.123)\nIn the basis formed by the eigenstates 0 an9, the operator A is represented by a matrix with the eigen-\nvalues along the diagonal\n \nA \u0003 §\na1\n0\n0\ng\n0\na2\n0\ng\n0\n0\na3\ng\nf\nf\nf\nf\n¥ , \n(2.124)\nwhose size depends on the dimensionality of the system. In this same basis, the eigenstates are repre-\nsented by the column vectors\n \n0 a19 \u0003 §\n1\n0\n0\nf\n¥ , 0 a29 \u0003 §\n0\n1\n0\nf\n¥ , 0 a39 \u0003 §\n0\n0\n1\nf\n¥ , ... . \n(2.125)\n","page_start":86,"page_end":86,"token_count":653,"section_type":"other","chapter_number":3,"chapter_title":"Schrödinger Time Evolution","chunk_index":106}
{"chunk_id":"270243c54d65d0b1","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"Summary \n63\nThe projection operators corresponding to measurement of the eigenvalues an are \n \nPan = 0 an98an0 . \n(2.126)\nThe completeness of the basis states is expressed by saying that the sum of the projection operators is \nthe identity operator\n \na\nn\nPan = a\nn\n0 an98an0 = 1. \n(2.127)\nSUMMARY\nIn this chapter we have extended the mathematical description of quantum mechanics by using \noperators to represent physical observables. The only possible results of measurements are the \neigenvalues of operators. The eigenvectors of the operator are the basis states corresponding to each \npossible eigenvalue. We ﬁnd the eigenvalues and eigenvectors by diagonalizing the matrix representing \nthe operator, which allows us to predict the results of measurements. The eigenvalue equations for the \nspin-1/2 component operator Sz are\n \n Sz0  +9 = +  U\n2 0  +9 \n \n Sz0  -9 = -  U\n2 0  -9. \n(2.128)\nThe matrices representing the spin-1/2 operators are\n \n Sx \u0003 U\n2\n a0\n1\n1\n0b\n \n Sy \u0003 U\n2\n a0\n-i\ni\n0 b  \n \n Sz \u0003 U\n2\n a1\n0\n0\n-1b  \n S2 \u0003 3U2\n4\n a1\n0\n0\n1b. \n(2.129)\nWe characterized quantum mechanical measurements of an observable A by the expectation value\n \n8A9 = 8c0 A0 c9 = a\nn\nanPan \n(2.130)\nand the uncertainty\n \n\u0006A = 48A29 - 8A92. \n(2.131)\nWe made a connection between the commutator [A, B] = AB - BA of two operators and the \nability to measure the two observables. If two operators commute, then we can measure both observ-\nables simultaneously, but if they do not commute, then we cannot measure them simultaneously. \nWe quantiﬁed this disturbance that measurement inﬂicts on quantum systems through the quantum \nmechanical uncertainty principle\n \n\u0006A\u0006B Ú 1\n2@83A, B49@ . \n(2.132)\nWe also introduced the projection postulate, which states how the quantum state vector is changed \nafter a measurement.\n","page_start":87,"page_end":87,"token_count":518,"section_type":"other","chapter_number":3,"chapter_title":"Schrödinger Time Evolution","chunk_index":107}
{"chunk_id":"c74288989253226c","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"64 \nOperators and Measurement\nPROBLEMS\n 2.1 Given the following information:\n \n Sx0{9x = { U\n2 0{9x\n \n Sy0{9y = { U\n2 0{9y\n \n 0{9x =\n1\n12 30  +9 { 0  -94  \n 0{9y =\n1\n12 30  +9 { i0  -94\n \n ﬁnd the matrix representations of Sx and Sy in the Sz basis.\n 2.2 From the previous problem we know that the matrix representation of Sx in the Sz basis is\nSx \u0003 U\n2\n a0\n1\n1\n0b.\n \n Diagonalize this matrix to ﬁnd the eigenvalues and the eigenvectors of Sx.\n 2.3 Find the matrix representation of Sz in the Sx basis for spin 1/2. Diagonalize this matrix to ﬁnd \nthe eigenvalues and the eigenvectors in this basis. Show that the eigenvalue equations for Sz are \nsatisﬁed in this new representation.\n 2.4 Show by explicit matrix calculation that the matrix elements of a general operator A (within a \nspin-1/2 system) are as shown in Eq. (2.13).\n 2.5 Calculate the commutators of the spin-1/2 operators Sx, Sy, and Sz, thus verifying Eqs. (2.96).\n 2.6 Verify that the spin component operator Sn along the direction nn has the matrix representation \nshown in Eq. (2.41).\n 2.7 Diagonalize the spin component operator Sn along the direction nn to ﬁnd its eigenvalues and \nthe eigenvectors.\n 2.8 Find the probabilities of the measurements shown below in Fig. 2.14. The ﬁrst Stern-Gerlach \nanalyzer is aligned along the direction nn deﬁned by the angles u = p>4 and f = 5p>3.\n 2.9 For the state 0 +9, calculate the expectation values and uncertainties for measurements of Sx, Sy, \nand Sz in order to verify Eq. (2.108).\n 2.10 For the state 0 +9y, calculate the expectation values and uncertainties for measurements of Sx, \nSy, and Sz. Draw a diagram of the vector model applied to this state and reconcile your quan-\ntum mechanical calculations with the classical results.\n 2.11 Show that the S2 operator commutes with each of the spin component operators of Sx, Sy, and \nSz. Do this once with matrix notation for a spin-1/2 system and a second time using only the \ncomponent commutation relations in Eqs. (2.96) and the deﬁnition of S2 in Eq. (2.103).\nY\n?\n?\nP\u0002y\nP\u0003y\n^n\nFIGURE 2.14 Measurement of spin components (Prob. 2.8).\n","page_start":88,"page_end":88,"token_count":642,"section_type":"other","chapter_number":3,"chapter_title":"Schrödinger Time Evolution","chunk_index":108}
{"chunk_id":"14859c0e230d5f89","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":" 2.12 Diagonalize the Sx and Sy operators in the spin-1 case to ﬁnd the eigenvalues and the eigenvec-\ntors of both operators.\n 2.13 For a spin-1 system, show by explicit matrix calculation that the spin component operators \nobey the commutation relations in Eqs. (2.96).\n 2.14 Find the matrix representation of the S2 operator for a spin-1 system. Do this once by explicit \nmatrix calculation and a second time by inspection of the S2 eigenvalue equation (2.120).\n 2.15 A beam of spin-1 particles is prepared in the state\n0 c9 =\n2\n129 0 19 + i 3\n129 0 09 -\n4\n129 0  -19.\na) What are the possible results of a measurement of the spin component Sz, and with what \nprobabilities would they occur?\nb) What are the possible results of a measurement of the spin component Sx, and with what \nprobabilities would they occur?\nc) Plot histograms of the predicted measurement results from parts (a) and (b), and calculate \nthe expectation values for both measurements.\n 2.16 A beam of spin-1 particles is prepared in the state\n0 c9 =\n2\n129 0 19y + i 3\n129 0 09y -\n4\n129 0  -19y.\na) What are the possible results of a measurement of the spin component Sz, and with what \nprobabilities would they occur?\nb) What are the possible results of a measurement of the spin component Sy, and with what \nprobabilities would they occur?\nc) Plot histograms of the predicted measurement results from parts (a) and (b), and calculate \nthe expectation values for both measurements.\n 2.17 A spin-1 particle is in the state\n0 c9 \u0003\n1\n130\n °\n1\n2\n5i\n¢ .\na) What are the possible results of a measurement of the spin component Sz, and with what \nprobabilities would they occur? Calculate the expectation value of the spin component Sz.\nb) Calculate the expectation value of the spin component Sx. Suggestion: Use matrix mechan-\nics to evaluate the expectation value.\n 2.18 A spin-1 particle is prepared in the state\n0 c9 =\n1\n114 0 19 -\n3\n114 0 09 + i 2\n114 0  -19.\na) What are the possible results of a measurement of the spin component Sz, and with what \nprobabilities would they occur?\nb) Suppose that the Sz measurement on the particle yields the result Sz = -U. Subsequent to \nthat result a second measurement is performed to measure the spin component Sx. What are \nthe possible results of that measurement, and with what probabilities would they occur?\nc) Draw a schematic diagram depicting the successive measurements in parts (a) and (b).\nProblems \n65\n","page_start":89,"page_end":89,"token_count":628,"section_type":"other","chapter_number":3,"chapter_title":"Schrödinger Time Evolution","chunk_index":109}
{"chunk_id":"d68c632367bddf7e","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"66 \nOperators and Measurement\n 2.19 A spin-1 particle is prepared in the state\n0 ci9 = 4\n1\n6 0 19 - 4\n2\n6 0 09 + i 4\n3\n6 0  -19.\n \n Find the probability that the system is measured to be in the ﬁnal state\n0 cf9 = 1+i\n17 0 19y +\n2\n17 0 09y - i 1\n17 0  -19y.\n 2.20 In part (2) of SPINS Lab #3, you measured the spin components of the unknown (spin 1) ini-\ntial states 0 ci9 (i \u0003 1, 2, 3, 4) along the three axes. Using your measured values, deduce the \nunknown initial states.\n 2.21 In part (3) of SPINS Lab #3, you built a spin-1 interferometer and measured the relative prob-\nabilities after the ﬁnal Stern-Gerlach analyzer for the seven possible cases where one beam, \na pair of beams, or all three beams from the second Stern-Gerlach analyzer were used. Show \nhow you used the projection postulate to calculate the theoretical probabilities.\n 2.22 A beam of spin-1/2 particles is sent through a series of three Stern-Gerlach analyzers, as shown \nin Fig. 2.15. The second Stern-Gerlach analyzer is aligned along the nn direction, which makes \nan angle \u0007 in the x-z plane with respect to the z-axis.\na) Find the probability that particles transmitted through the ﬁrst Stern-Gerlach analyzer are \nmeasured to have spin down at the third Stern-Gerlach analyzer?\nb) How must the angle \u0007 of the second Stern-Gerlach analyzer be oriented so as to maximize \nthe probability that particles are measured to have spin down at the third Stern-Gerlach \nanalyzer? What is this maximum fraction?\nc) What is the probability that particles have spin down at the third Stern-Gerlach analyzer if \nthe second Stern-Gerlach analyzer is removed from the experiment?\n 2.23 Consider a three-dimensional ket space. In the basis deﬁned by three orthogonal kets 0 19, 0 29, \nand 0 39, the operators A and B are represented by\n \nA \u0003 °\na1\n0\n0\n0\na2\n0\n0\n0\na3\n ¢  B \u0003 °\nb1\n0\n0\n0\n0\nb2\n0\nb2\n0\n¢ ,\n \n where all the quantities are real.\na) Do the operators A and B commute?\nb) Find the eigenvalues and normalized eigenvectors of both operators.\nZ\n?\n?\n^n\nZ\nFIGURE 2.15 Measurement of spin components (Prob. 2.22).\n","page_start":90,"page_end":90,"token_count":637,"section_type":"other","chapter_number":3,"chapter_title":"Schrödinger Time Evolution","chunk_index":110}
{"chunk_id":"17ff928da13924e3","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"Resources \n67\nc) Assume the system is initially in the state 0 29. Then the observable corresponding to the oper-\nator B is measured. What are the possible results of this measurement and the probabilities of \neach result? After this measurement, the observable corresponding to the operator A is mea-\nsured. What are the possible results of this measurement and the probabilities of each result?\nd) How are questions (a) and (c) above related?\n 2.24 If a beam of spin-3/2 particles is input to a Stern-Gerlach analyzer, there are four output beams \nwhose deﬂections are consistent with magnetic moments arising from spin angular momentum \ncomponents of 3\n2 U, 1\n2 U, -  1\n2 U, and -  3\n2 U. For a spin-3/2 system:\na) Write down the eigenvalue equations for the Sz operator.\nb) Write down the matrix representation of the Sz eigenstates.\nc) Write down the matrix representation of the Sz operator.\nd) Write down the eigenvalue equations for the S2 operator.\ne) Write down the matrix representation of the S2 operator.\n 2.25 Are the projection operators P+ and P- Hermitian? Explain.\nRESOURCES\nActivities\nThis activity is available at\nwww.physics.oregonstate.edu/qmactivities\nSpins Lab 3: Stern-Gerlach measurements of a spin-1 system.\n","page_start":91,"page_end":91,"token_count":309,"section_type":"other","chapter_number":3,"chapter_title":"Schrödinger Time Evolution","chunk_index":111}
{"chunk_id":"ccf5d6616f3bec7c","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"C H A P T E R \n3\nSchrödinger Time Evolution\nThis chapter marks our ﬁnal step in developing the mathematical basis of a quantum theory. In \n Chapter 1, we learned how to use kets to describe quantum states and how to predict the probabili-\nties of results of measurements. In Chapter 2, we learned how to use operators to represent physical \nobservables and how to determine the possible measurement results. The key missing aspect is the \nability to predict the future. Physics theories are judged on their predictive power. Classical mechan-\nics relies on Newton’s second law F = ma to predict the future of a particle’s motion. The ability to \npredict the quantum future started with Erwin Schrödinger and bears his name.\n3.1 \u0002 SCHRÖDINGER EQUATION\nThe sixth postulate of quantum mechanics says that the time evolution of a quantum system is \n governed by the differential equation\n \niU d\ndt\n 0  c 1t29 = H 1t2 0  c 1t29, \n(3.1)\nwhere the operator H corresponds to the total energy of the system and is called the Hamiltonian \noperator of the system because it is derived from the classical Hamiltonian. This equation is known as \nthe Schrödinger equation.\nPostulate 6\nThe time evolution of a quantum system is determined by the  Hamiltonian \nor total energy operator H1t2 through the Schrödinger equation\niU d\ndt\n 0  c 1t29 = H 1t2 0  c 1t29.\nThe Hamiltonian is a new operator, but we can use the same ideas we developed in Chapter 2 to \nunderstand its basic properties. The Hamiltonian H is an observable, so it is a Hermitian operator. The \neigenvalues of the Hamiltonian are the allowed energies of the quantum system, and the eigenstates \nof H are the energy eigenstates of the system. If we label the allowed energies as En, then the energy \neigenvalue equation is\n \nH 0 En9 = En0 En9 . \n(3.2)\n","page_start":92,"page_end":92,"token_count":463,"section_type":"other","chapter_number":3,"chapter_title":"Schrödinger Time Evolution","chunk_index":112}
{"chunk_id":"514e977c693efc7f","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"3.1 Schrödinger Equation \n69\nIf we have the Hamiltonian H in a matrix representation, then we diagonalize the matrix to ﬁnd the \neigenvalues En and the eigenvectors 0 En9 just as we did with the spin operators in Chapter 2. For the \nmoment, let’s assume that we have already diagonalized the Hamiltonian [i.e., solved Eq. (3.2)] so that \nwe know the eigenvalues En and the eigenvectors 0 En9, and let’s see what we can learn about quantum \ntime evolution in general by solving the Schrödinger equation.\nThe eigenvectors of the Hamiltonian form a complete basis because the Hamiltonian is an observ-\nable, and therefore a Hermitian operator. Because H is the only operator appearing in the Schrödinger \nequation, it would seem reasonable (and will prove invaluable) to consider the energy eigenstates as \nthe basis of choice for expanding general state vectors:\n0 c 1t29 = a\nn\ncn1t2 0 En9. \n(3.3)\nThe basis of eigenvectors of the Hamiltonian is also orthonormal, so\n8Ek\u0004 En9 = dkn. \n(3.4)\nWe refer to this basis as the energy basis.\nFor now, we assume that the Hamiltonian is time independent (we will do the time-dependent case \nH(t) in Section 3.4). The eigenvectors of a time-independent Hamiltonian come from the diagonaliza-\ntion procedure we used in Chapter 2, so there is no reason to expect the eigenvectors themselves to \ncarry any time dependence. Thus if a general state 0 c9 is to be time dependent, as the Schrödinger equa-\ntion implies, then the time dependence must reside in the expansion coefﬁcients cn1t2, as expressed in \nEq. (3.3). Substitute this general state into the Schrödinger equation (3.1)\niU d\ndt a\nn\ncn1t2 0 En9 = Ha\nn\ncn1t2 0 En9 \n(3.5)\nand use the energy eigenvalue equation (3.2) to obtain\niUa\nn\ndcn1t2\ndt\n0 En9 = a\nn\ncn1t2En0 En9. \n(3.6)\nEach side of this equation is a sum over all the energy states of the system. To simplify this equation, \nwe isolate single terms in these two sums by taking the inner product of the ket on each side with one \nparticular ket 0 Ek9 (this ket can have any label k, but must not have the label n that is already used in \nthe summation). The orthonormality condition 8Ek\u0004En9 = dkn then collapses the sums:\n 8Ek0 iUa\nn\ndcn1t2\ndt\n0 En9 = 8Ek0 a\nn\ncn1t2En0 En9 \n iUa\nn\ndcn1t2\ndt","page_start":93,"page_end":93,"token_count":668,"section_type":"other","chapter_number":3,"chapter_title":"Schrödinger Time Evolution","chunk_index":113}
{"chunk_id":"be6aecd90be3fa58","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"particular ket 0 Ek9 (this ket can have any label k, but must not have the label n that is already used in \nthe summation). The orthonormality condition 8Ek\u0004En9 = dkn then collapses the sums:\n 8Ek0 iUa\nn\ndcn1t2\ndt\n0 En9 = 8Ek0 a\nn\ncn1t2En0 En9 \n iUa\nn\ndcn1t2\ndt\n 8Ek0 En9 = a\nn\ncn1t2En8Ek0 En9  \n iUa\nn\ndcn1t2\ndt\n  dkn = a\nn\ncn1t2Endkn\n iU \ndck1t2\ndt\n= ck1t2Ek.\n(3.7)\nWe are left with a single differential equation for each of the possible energy states of the systems \nk = 1, 2, 3, ... . This ﬁrst-order differential equation can be rewritten as\ndck1t2\ndt\n= -i Ek\nU\n ck1t2. \n(3.8)","page_start":93,"page_end":93,"token_count":250,"section_type":"other","chapter_number":3,"chapter_title":"Schrödinger Time Evolution","chunk_index":114}
{"chunk_id":"5d4bc35ecc3715e4","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"70 \nSchrödinger Time Evolution\nThe solution to Eq. (3.8) is a complex exponential\nck1t2 = ck102e-iEkt>U. \n(3.9)\nIn Eq. (3.9), we have denoted the initial condition as ck102, but we denote it simply as ck hereafter. \nEach coefﬁcient in the energy basis expansion of the state obeys the same form of the time dependence \nin Eq. (3.9), but with a different exponent due to the different energies. The time-dependent solution \nfor the full state vector is summarized by saying that if the initial state of the system at time t \u0003 0 is\n0 c1029 = a\nn\ncn0 En9, \n(3.10)\nthen the time evolution of this state under the action of the time-independent Hamiltonian H is\n0 c1t29 = a\nn\ncne-iEnt>U0 En9  . \n(3.11)\nSo the time dependence of the original state vector is found by multiplying each energy eigenstate \ncoefﬁcient by its own phase factor e-iEnt>U that depends on the energy of that eigenstate. Note that the \nfactor E>U is an angular frequency, so that the time dependence is of the form e-ivt, a form commonly \nfound in many areas of physics. It is important to remember that one must use the energy eigenstates for \nthe expansion in Eq. (3.10) in order to use the simple phase factor multiplication in Eq. (3.11) to account \nfor the Schrödinger time evolution of the state. This key role of the energy basis accounts for the impor-\ntance of the Hamiltonian operator and for the common practice of ﬁnding the energy eigenstates to use \nas the preferred basis.\nA few examples help to illustrate some of the important consequences of this time evolution of \nthe quantum mechanical state vector. First, consider the simplest possible situation where the system \nis initially in one particular energy eigenstate:\n0 c1029 = 0 E19, \n(3.12)\nfor example. The prescription for time evolution tells us that after some time t the system is in the state\n0 c1t29 = e-iE1t>U0 E19. \n(3.13)\nBut this state differs from the original state only by an overall phase factor, which we have said before \ndoes not affect any measurements (Problem 1.3). For example, if we measure an observable A, then \nthe probability of measuring an eigenvalue aj is given by\n Paj = 08aj0 c1t290\n2\n = 08aj0 e-iE1t>U0 E190\n2 \n = 08aj0 E190\n2.\n(3.14)\nThis probability is time independent and is equal to the probability at the initial time. Thus, we \n conclude that there is no measureable time evolution for this state. Hence, the energy eigenstates are \ncalled stationary states. If a system begins in an energy eigenstate, then it remains in that state.","page_start":94,"page_end":94,"token_count":664,"section_type":"other","chapter_number":3,"chapter_title":"Schrödinger Time Evolution","chunk_index":115}
{"chunk_id":"1d20b2767d8bf278","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"2\n = 08aj0 e-iE1t>U0 E190\n2 \n = 08aj0 E190\n2.\n(3.14)\nThis probability is time independent and is equal to the probability at the initial time. Thus, we \n conclude that there is no measureable time evolution for this state. Hence, the energy eigenstates are \ncalled stationary states. If a system begins in an energy eigenstate, then it remains in that state.\nNow consider an initial state that is a superposition of two energy eigenstates:\n0 c1029 = c10 E19 + c20 E29. \n(3.15)\nIn this case, time evolution takes the initial state to the later state\n0 c1t29 = c1e-iE1t>U0 E19 + c2e-iE2t>U0 E29. \n(3.16)","page_start":94,"page_end":94,"token_count":187,"section_type":"other","chapter_number":3,"chapter_title":"Schrödinger Time Evolution","chunk_index":116}
{"chunk_id":"9c128f17b5baf36d","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"3.1 Schrödinger Equation \n71\nA measurement of the system energy at the time t would yield the value E1 with a probability\n PE1 = 08E10 c1t290\n2\n = 08E103c1e-iE1t>U0 E19 + c2e-iE2t>U0 E294 0\n2 \n = 0 c10\n2,\n(3.17)\nwhich is independent of time. The same is true for the probability of measuring the energy E2. Thus, \nthe probabilities of measuring the energies are stationary, as they were in the ﬁrst example.\nHowever, now consider what happens if another observable is measured on this system in this \nsuperposition state. There are two distinct situations: (1) If the other observable A commutes with the \nHamiltonian H, then A and H have common eigenstates. In this case, measuring A is equivalent to mea-\nsuring H because the inner products used to calculate the probabilities use the same eigenstates. Hence, \nthe probability of measuring any particular eigenvalue of A is time independent, as in Eq. (3.17). (2) If \nA and H do not commute, then they do not share common eigenstates. In this case, the eigenstates of A \nin general consist of superpositions of energy eigenstates. For example, suppose that the eigenstate of \nA corresponding to the eigenvalue a1 were\n0 a19 = a10 E19 + a20 E29. \n(3.18)\nThen the probability of measuring the eigenvalue a1 would be\n Pa1 = 08a10 c1t290\n2\n = 03a*\n18E10 + a*\n28E2043c1e-iE1t>U0 E19 + c2e-iE2t>U0 E294 0\n2 \n = @ a*\n1c1e-iE1t>U + a*\n2c2e-iE2t>U@\n2.\n(3.19)\nFactoring out the common phase gives\n Pa1 = @ e-iE1t>U@\n2\n @ a*\n1c1 + a*\n2c2e-i1E2-E12t>U@\n2\n = 0 a10\n20 c10\n2 + 0 a20\n20 c20\n2 + 2Re1a1c*\n1a*\n2c2e-i1E2-E12t>U2. \n(3.20)\nThe different time-evolution phases of the two components of 0 c1t29 lead to a time dependence in the \nprobability. The overall phase in Eq. (3.20) drops out, and only the relative phase remains in the prob-\nability calculation. Hence, the time dependence is determined by the difference of the energies of the \ntwo states involved in the superposition. The corresponding angular frequency of the time evolution\nv 21 = E2 - E1\nU\n(3.21)\nis called the Bohr frequency.","page_start":95,"page_end":95,"token_count":647,"section_type":"other","chapter_number":3,"chapter_title":"Schrödinger Time Evolution","chunk_index":117}
{"chunk_id":"06e03c0ceb97b3d7","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"probability. The overall phase in Eq. (3.20) drops out, and only the relative phase remains in the prob-\nability calculation. Hence, the time dependence is determined by the difference of the energies of the \ntwo states involved in the superposition. The corresponding angular frequency of the time evolution\nv 21 = E2 - E1\nU\n(3.21)\nis called the Bohr frequency.\nTo summarize, we list below a recipe for solving a standard time-dependent quantum mechanics \nproblem with a time-independent Hamiltonian.\nGiven a Hamiltonian H and an initial state 0 c1029, what is the probability that \nthe eigenvalue aj of the observable A is measured at time t?\n 1. Diagonalize H (ﬁnd the eigenvalues En and eigenvectors 0 En92.\n 2. Write 0 c1029 in terms of the energy eigenstates 0 En9.\n 3. Multiply each eigenstate coefﬁcient by e-iEnt>U to get 0 c1t29.\n 4. Calculate the probability Paj = 08aj0 c1t290\n2.","page_start":95,"page_end":95,"token_count":237,"section_type":"other","chapter_number":3,"chapter_title":"Schrödinger Time Evolution","chunk_index":118}
{"chunk_id":"79061679d3632a39","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"72 \nSchrödinger Time Evolution\n3.2 \u0002 SPIN PRECESSION\nNow apply this new concept of Schrödinger time evolution to the case of a spin-1/2 system. The Ham-\niltonian operator represents the total energy of the system, but because only energy differences are \nimportant in time-dependent solutions (and because we can deﬁne the zero of potential energy as \nwe wish), we need consider only energy terms that differentiate between the two possible spin states \nin the system. Our experience with the Stern-Gerlach apparatus tells us that the magnetic potential \nenergy of the magnetic dipole differs for the two possible spin-component states. So to begin, we \nconsider the potential energy of a single magnetic dipole (e.g., in a silver atom) in a uniform magnetic \nﬁeld as the sole term in the Hamiltonian. Recalling that the magnetic dipole is given by\n \nM = g q\n2me\n S, \n(3.22)\nthe Hamiltonian is\n \n H = -M~B\n \n \n = -g q\n2me\n S~B \n \n = e\nme\n S~B,\n \n(3.23)\nwhere q = -e and g = 2 have been used in the last line. The gyromagnetic ratio, g, is slightly differ-\nent from 2, but we ignore that detail.\n3.2.1 \u0002 Magnetic Field in the z-Direction\nFor our ﬁrst example, we assume that the magnetic ﬁeld is uniform and directed along the z-axis. \n Writing the magnetic ﬁeld as\n \nB = B0\n zn \n(3.24)\nallows the Hamiltonian to be simpliﬁed to\n \n H = eB0\nme\n Sz \n \n = v0 Sz,  \n(3.25)\nwhere we have introduced the deﬁnition\n \nv0 K eB0\nme\n. \n(3.26)\nThis deﬁnition of an angular frequency simpliﬁes the notation now and will have an obvious \n interpretation at the end of the problem.\nThe Hamiltonian in Eq. (3.25) is proportional to the Sz operator, so H and Sz commute and \n therefore share common eigenstates. This is clear if we write the Hamiltonian as a matrix in the \nSz  representation:\n \nH \u0003 U v0\n2\n a1\n0\n0\n-1b. \n(3.27)\n","page_start":96,"page_end":96,"token_count":522,"section_type":"other","chapter_number":3,"chapter_title":"Schrödinger Time Evolution","chunk_index":119}
{"chunk_id":"799669dcfcfe5537","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"3.2 Spin Precession \n73\nBecause H is diagonal, we have already completed step 1 of the Schrödinger time-evolution recipe. \nThe eigenstates of H are the basis states of the representation, while the eigenvalues are the diagonal \nelements of the matrix in Eq. (3.27). The eigenvalue equations for the Hamiltonian are thus\n \n H 0  +9 = v0Sz0  +9 = U v0\n2\n 0  +9 = E+ 0  +9\n \n \n H 0  -9 = v0Sz0  -9 = -  U v0\n2\n 0  +9 = E - 0  -9, \n(3.28)\nwith eigenvalues and eigenvectors given by\n \n E + = U v 0\n2\n \n E - = -  U v 0\n2  \n \n 0\n E +9 = 0  +9\n \n 0\n E -9 = 0  -9.  \n(3.29)\nThe information regarding the energy eigenvalues and eigenvectors is commonly presented in a \ngraphical diagram, which is shown in Fig. 3.1 for this case. The two energy states are separated \nby the energy E+ - E- = U v0, so the angular frequency v0 characterizes the energy scale of this \nsystem. The spin-up state 0  +9 has a higher energy because the magnetic moment is aligned against \nthe ﬁeld in that state; the negative charge in Eq. (3.22) causes the spin and magnetic moment to be \nantiparallel.\nNow we look at a few examples to illustrate the key features of the behavior of a spin-1/2 system \nin a uniform magnetic ﬁeld. First, consider the case where the initial state is spin up along the z-axis:\n \n0\n c1029 = 0  +9. \n(3.30)\nThis initial state is already expressed in the energy basis (step 2 of the Schrödinger recipe), so the \nSchrödinger equation time evolution takes this initial state to the state\n \n 0\n c1t29 = e-iE +\n t>U0  +9 \n \n = e-iv 0\n t>20  +9 \n(3.31)\n\u00030.5\n\u00030.25\n0.0\n0.25\n0.5\nE/\u0002Ω0\n\u0002\u0002\u0003\n\u0002Ω0\nE\u0002\u0005 \u0002Ω0\n2\n\u0003\nE\u0003\u0005\n\u0002Ω0\n2\n\u0002\u0003\u0003\nFIGURE 3.1 Energy level diagram of a spin-1/2 particle in a uniform magnetic ﬁeld.\n","page_start":97,"page_end":97,"token_count":587,"section_type":"other","chapter_number":4,"chapter_title":"Quantum Spookiness","chunk_index":120}
{"chunk_id":"c005ec326a491e04","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"74 \nSchrödinger Time Evolution\naccording to step 3 of the Schrödinger recipe. As we saw before [(Eq. (3.13)], because the initial state is \nan energy eigenstate, the time-evolved state acquires an overall phase factor, which does not represent \na physical change of the state. The probability for measuring the spin to be up along the z-axis is (step 4 \nof the Schrödinger recipe)\n \n P+ = 08+ 0 c1t290\n2\n \n \n = @8+ 0 e-iv0t>20  +9@\n2 \n \n(3.32)\n \n = 1.\n \n \nAs expected, this probability is not time dependent, and we therefore refer to 0  +9 as a stationary state \nfor this system. A schematic diagram of this experiment is shown in Fig. 3.2, where we have intro-\nduced a new element to represent the applied ﬁeld. This new depiction is the same as the depictions in \nthe SPINS software, where the number in the applied magnetic ﬁeld box (42 in Fig. 3.2) is a measure \nof the magnetic ﬁeld strength. In this experiment, the results shown are independent of the applied \nﬁeld strength, as indicated by Eq. (3.32), and as you can verify with the software.\nNext, consider the most general initial state, which we saw in Chapter 2 corresponds to spin \nup along an arbitrary direction deﬁned by the polar angle u and the azimuthal angle f. The initial \nstate is\n \n0 c1029 = 0  +9n = cos u\n2 0  +9 + sin u\n2\n eif0  -9, \n(3.33)\nor using matrix notation:\n \n0 c1029 \u0003 a cos1u>22\neif sin1u>22b. \n(3.34)\nSchrödinger time evolution introduces a time-dependent phase term for each component, giving\n \n 0 c1t29 \u0003 a e-iE+t>U cos1u>22\ne-iE-t>Ueif sin1u>22b\n \n \n \u0003 a e-iv0t>2 cos1u>22\neiv0t>2eif sin1u>22b\n \n \n(3.35)\n \n \u0003 e-iv0t>2 a\ncos1u>22\nei1f+v0t2 sin1u>22b. \nZ\nZ\n100\n0\n42\nZ\nFIGURE 3.2 Schematic diagram of a Stern-Gerlach measurement with an applied uniform magnetic ﬁeld \nrepresented by the box in the middle, with the number 42 representing the strength of the magnetic ﬁeld.\n","page_start":98,"page_end":98,"token_count":603,"section_type":"other","chapter_number":4,"chapter_title":"Quantum Spookiness","chunk_index":121}
{"chunk_id":"970e75d12759df69","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"3.2 Spin Precession \n75\nNote again that an overall phase does not have a measurable effect, so the evolved state is a spin up \neigenstate along a direction that has the same polar angle u as the initial state and a new azimuthal \nangle f + v0t. The state appears to have simply rotated around the z-axis, the axis of the magnetic \nﬁeld, by the angle v0t. Of course, we have to limit our discussion to results of measurements, so let’s \nﬁrst calculate the probability for measuring the spin component along the z-axis:\n \n P+ = 08+  0 c1t290\n2\n \n \n = 2 11 02e-iv0t>2 a\ncos1u>22\nei1f+v0t2 sin1u>22b 2\n2\n \n \n = 0 e-iv0t>2 cos1u>22 0\n2\n \n \n = cos21u>22.\n \n \n(3.36)\nThis probability is time independent because the Sz eigenstates are also energy eigenstates for this \nproblem (i.e., H and Sz commute). The probability in Eq. (3.36) is consistent with the interpretation \nthat the angle u that the spin vector makes with the z-axis does not change.\nThe probability for measuring spin up along the x-axis is\n \n P+x = 0 x8+  0 c1t290\n2\n \n \n = 2 1\n12 11  12e-iv0t>2a\ncos1u>22\nei(f +v0t) sin1u>22b 2\n2\n \n \n = 1\n2 @ cos1u>22 + ei1f+v0t2 sin1u>22 @\n2\n \n(3.37)\n \n = 1\n2 3cos21u>22 + cos1u>22sin1u>221ei1f+v0t2 + e-i1f +v0t22 + sin21u>224 \n \n = 1\n2 31 + sin u cos1f + v0t24.\n \nThis probability is time dependent because the Sx eigenstates are not stationary states (i.e., H and Sx \ndo not commute). The time dependence in Eq. (3.37) is consistent with the spin precessing around \nthe z-axis.\nTo illustrate this spin precession further, it is useful to calculate the expectation values for each of \nthe spin components. For Sz, we have\n \n 8Sz9 = 8c1t2 0 Sz0 c1t29\n \n \n = eiv0t>2 a\n cos a u\n2b  e-i1f +v0t2 sin a u\n2b b  U\n2\n a1\n0\n0\n-1b e-iv0t>2 a\ncos1u>22\nei1f+v0t2 sin1u>22b \n \n = U\n2\n 3cos21u>22 - sin21u>224\n \n \n = U\n2\n cos u,\n \n(3.38)\n","page_start":99,"page_end":99,"token_count":670,"section_type":"other","chapter_number":4,"chapter_title":"Quantum Spookiness","chunk_index":122}
{"chunk_id":"481203122d8127dc","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"76 \nSchrödinger Time Evolution\nwhile the other components are\n \n 8Sy9 = 8c1t2 0 Sy0 c1t29\n \n \n = eiv0t>2 a\n cos a u\n2b  e-i1f+v0t2 sin a u\n2b b U\n2\n a0\n-i\ni\n0 be-iv0t>2 a\ncos1u>22\nei1f +v0t2 sin1u>22b (3.39)\n \n = U\n2\n sin u sin1f + v0t2 \nand\n \n 8Sx9 = 8c1t2 0 Sx0 c1t29\n \n \n = U\n2\n sin u cos1f + v0t2. \n \n(3.40)\nThe expectation value of the total spin vector 8S9 is shown in Fig. 3.3, where it is seen to precess \naround the magnetic ﬁeld direction with an angular frequency v0. The precession of the spin vector is \nknown as Larmor precession and the frequency of precession is known as the Larmor frequency.\nThe quantum mechanical Larmor precession is analogous to the classical behavior of a magnetic \nmoment in a uniform magnetic ﬁeld. A classical magnetic moment M experiences a torque M * B \nwhen placed in a magnetic ﬁeld. If the magnetic moment is associated with an angular momentum L, \nthen we can write\n \nM =\nq\n2m\n L, \n(3.41)\nwhere q and m are the charge and mass, respectively, of the system. The equation of motion for the \nangular momentum\n \nd L\ndt = M * B \n(3.42)\nthen results in\n \ndM\ndt =\nq\n2m\n M * B. \n(3.43)\ny\nx\nz\n\u0004S(t)\u0003\n\u0004S(0)\u0003\nB\nΩ0t\nFIGURE 3.3 The expectation value of the spin vector precesses in a uniform magnetic ﬁeld.\n","page_start":100,"page_end":100,"token_count":445,"section_type":"other","chapter_number":4,"chapter_title":"Quantum Spookiness","chunk_index":123}
{"chunk_id":"35a7ac7dace76c61","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"3.2 Spin Precession \n77\nBecause the torque M * B is perpendicular to the angular momentum L = 2mM>q, it causes the \nmagnetic moment to precess about the ﬁeld with the classical Larmor frequency vcl = qB>2m.\nIn the quantum mechanical example we are considering, the charge q is negative (meaning the \nspin and magnetic moment are antiparallel), so the precession is counterclockwise around the ﬁeld. A \npositive charge would result in clockwise precession. This precession of the spin vector makes it clear \nthat the system has angular momentum, as opposed to simply having a magnetic dipole moment. The \nequivalence of the classical Larmor precession and the expectation value of the quantum mechanical \nspin vector is one example of Ehrenfest’s theorem, which states that quantum mechanical expecta-\ntion values obey classical laws.\nPrecession experiments like the one discussed here are of great practical value. For example, if \nwe measure the magnetic ﬁeld strength and the precession frequency, then the gyromagnetic ratio can \nbe determined. This spin precession problem is also of considerable theoretical utility because it is \nmathematically equivalent to many other quantum systems that can be modeled as two-state systems. \nThis utility is broader than you might guess at ﬁrst glance, because many multistate quantum systems \ncan be reduced to two-state systems if the experiment is designed to interact only with two of the many \nlevels of the system.\nExample 3.1 A spin-1/2 particle with a magnetic moment is prepared in the state 0  -9x and is \nsubject to a uniform applied magnetic ﬁeld B = B0\n zn. Find the probability of measuring spin up in \nthe x-direction after a time t. This experiment is depicted in Fig. 3.4.\nWe solve this problem using the four steps of the Schrödinger time-evolution recipe from \nSection 3.1. The initial state is\n \n0 c1029 = 0  -9x. \n(3.44)\nThe applied magnetic ﬁeld is in the z-direction, so the Hamiltonian is H = v0Sz and the energy \neigenstates are 0{9 with energies E{ = {U v0>2 (step 1). The Larmor precession frequency is \nv0 = eB0>me. We must express the initial state in the energy basis (step 2):\n \n0 c1029 = 0  -9x =\n1\n12 0  +9 -\n1\n12 0  -9. \n(3.45)\nThe time-evolved state is obtained by multiplying each energy eigenstate coefﬁcient by the appro-\npriate phase factor (step 3):\n \n 0 c1t29 =\n1\n12 e-iE +t>U0  +9 -\n1\n12 e-iE -t>U0  -9 \n(3.46)\n \n =\n1\n12 e-iv0t>20  +9 -\n1\n12 e+iv0t>2 0 -9.\nX\n?\n?\n42\nZ\nX\nFIGURE 3.4 Spin precession experiment.\n","page_start":101,"page_end":101,"token_count":684,"section_type":"other","chapter_number":4,"chapter_title":"Quantum Spookiness","chunk_index":124}
{"chunk_id":"e71dbe4798b7bb48","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"78 \nSchrödinger Time Evolution\nThe measurement probability is found by projecting 0 c1t29 onto the measured state and complex \nsquaring (step 4):\n \n P+x = 0 x8+ 0\n c1t29 0\n2\n \n \n = @x8+ 0A 1\n12 e-iv0t>20  +9 -\n1\n12 e+iv0t>20  -9B @\n2\n \n \n = @ A 1\n128+ 0 +\n1\n128- 0 BA 1\n12 e-iv0t>20  +9 -\n1\n12 e+iv0t>20  -9B @\n2\n \n(3.47)\n \n = 1\n4 @e-iv0t>2 - e+iv0t>2@\n2\n \n \n = sin2 1v0t>22.\n \nThe probability that the system has spin up in the x-direction oscillates between zero and unity \nas time evolves, as shown in Fig. 3.5(a), which is consistent with the model of the spin vector \nprecessing around the applied ﬁeld, as shown in Fig. 3.5(b).\n3.2.2 \u0002 Magnetic Field in a General Direction\nFor our second example, consider a more general direction for the magnetic ﬁeld by adding a magnetic \nﬁeld component along the x-axis to the already existing ﬁeld along the z-axis. The simplest approach \nto solving this new problem would be to redeﬁne the coordinate system so the z-axis pointed along the \ndirection of the new total magnetic ﬁeld. Then the solution would be the same as was obtained above, \nwith a new value for the magnitude of the magnetic ﬁeld being the only change. This approach would \nbe considered astute in many circumstances, but we will not take it because we want to get practice \nsolving this new type of problem and because we want to address some issues that are best posed in the \noriginal coordinate system. Thus, we deﬁne a new magnetic ﬁeld as\n \nB = B0zn + B1xn . \n(3.48)\nt\n0.0\n0.2\n0.4\n0.6\n0.8\n1.0\nP\u0002x\ny\nx\nz\n(a)\n(b)\nΩ0t\nB\n\u0004S(0)\u0003\n\u0004S(t)\u0003\n2Π\nΩ0\n4Π\nΩ0\n6Π\nΩ0\nFIGURE 3.5 (a) Probability of a spin component measurement and (b) the corresponding \nprecession of the expectation value of the spin.\n","page_start":102,"page_end":102,"token_count":582,"section_type":"other","chapter_number":4,"chapter_title":"Quantum Spookiness","chunk_index":125}
{"chunk_id":"54aa4bb0a9a63e04","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"3.2 Spin Precession \n79\nThis ﬁeld is oriented in the xz-plane at an angle u with respect to the z-axis, as shown in Fig. 3.6. In \nlight of the solution above, it is useful to deﬁne Larmor frequencies associated with each of the ﬁeld \ncomponents:\n \nv0 K eB0\nme\n, \nv1 K eB1\nme\n. \n(3.49)\nUsing these deﬁnitions, the Hamiltonian becomes\n \n H = - M~B\n \n \n = v0 Sz + v1Sx, \n(3.50)\nor in matrix representation\n \nH \u0003 U\n2\n av0\nv1\nv1\n-v0\nb. \n(3.51)\nThis Hamiltonian is not diagonal, so its eigenstates are not the same as the eigenstates of Sz. Rather we \nmust use the diagonalization procedure to ﬁnd the new eigenvalues and eigenvectors. The characteristic \nequation determining the energy eigenvalues is\n \n ∞ \nU\n2\n  v0 - l\nU\n2\n  v1\nU\n2\n  v1\n-  U\n2\n  v0 - l\n∞= 0  \n \n - a U\n2\n v0b\n2\n+ l2 - a U\n2\n v1b\n2\n= 0, \n \n(3.52)\nwith solutions\n \nl = { U\n2\n 4v2\n0 + v2\n1. \n(3.53)\nNote that the energy eigenvalues are {1U v0>22 when v1 = 0, which they must be given our previ-\nous solution. Rather than solve directly for the eigenvectors, let’s make them obvious by rewriting the \nHamiltonian. From Fig. 3.6 it is clear that the angle is determined by the equation\n \ntan u = B1\nB0\n= v1\nv0\n. \n(3.54)\nB0\nB1\nB\nθ\nFIGURE 3.6 A uniform magnetic ﬁeld in a general direction.\n","page_start":103,"page_end":103,"token_count":461,"section_type":"other","chapter_number":4,"chapter_title":"Quantum Spookiness","chunk_index":126}
{"chunk_id":"bf850f6ac4c0c314","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"80 \nSchrödinger Time Evolution\nUsing this, the Hamiltonian can be written as\nH \u0003 U\n2\n 4v2\n0 + v2\n1 acos u\nsin u\nsin u\n-cos ub. \n(3.55)\nIf we let nn be the unit vector in the direction of the total magnetic ﬁeld, then the Hamiltonian is propor-\ntional to the spin component Sn along the direction nn:\nH = 4v2\n0 + v2\n1 Sn. \n(3.56)\nThis is what we expected at the beginning: that the problem could be solved by using the ﬁeld direc-\ntion to deﬁne a coordinate system. Thus, the eigenvalues are as we found in Section 2.2.1 and the \neigenstates are the spin up and down states along the direction nn, which are\n0  +9n = cos u\n2\n 0  +9 + sin u\n2\n 0  -9 \n0  -9n = sin u\n2\n 0  +9 - cos u\n2\n 0  -9 \n(3.57)\nfor this case, because the azimuthal angle f is zero. These are the same states you would ﬁnd by \ndirectly solving for the eigenstates of the Hamiltonian. Because we have already done that for the Sn \ncase, we do not repeat it here.\nNow consider performing the following experiment: begin with the system in the spin-up state \nalong the z-axis, and measure the spin component along the z-axis after the system has evolved in \nthis magnetic ﬁeld for some time, as depicted in Fig. 3.7. Let’s speciﬁcally calculate the probabil-\nity that the initial 0  +9 is later found to have evolved to the 0  -9 state. This is commonly known as a \nspin ﬂip. According to our time-evolution prescription, we must ﬁrst write the initial state in terms \nof the energy eigenstates of the system. In the previous examples, this was trivial because the energy \neigenstates were the 0{9 states that we used to express all general states. But now this new problem is \nmore involved, so we proceed more slowly. The initial state\n0\n c1029 = 0  +9 \n(3.58)\nmust be written in the 0{9n basis. Because the 0{9n basis is complete, we can use the completeness \nrelation [Eq. (2.55)] to decompose the initial state\n 0\n c1029 = 10  +9n n8+ 0 + 0  -9n n8- 02 0  +9 \n = 0  +9n n8+ 0  +9 + 0  -9n n8- 0  +9 \n = n8+ 0  +9 0  +9n + n8- 0  +9 0  -9n  \n = cos u\n2\n 0  +9n + sin u\n2","page_start":104,"page_end":104,"token_count":669,"section_type":"other","chapter_number":4,"chapter_title":"Quantum Spookiness","chunk_index":127}
{"chunk_id":"0a1bafe69bb59f45","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":" = 0  +9n n8+ 0  +9 + 0  -9n n8- 0  +9 \n = n8+ 0  +9 0  +9n + n8- 0  +9 0  -9n  \n = cos u\n2\n 0  +9n + sin u\n2\n 0  -9n.\n(3.59)\nZ\n?\n?\n42\n^n\nZ\nFIGURE 3.7 A spin precession experiment with a uniform magnetic ﬁeld aligned in a general direction nn.","page_start":104,"page_end":104,"token_count":127,"section_type":"other","chapter_number":4,"chapter_title":"Quantum Spookiness","chunk_index":128}
{"chunk_id":"34322a940122cdde","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"3.2 Spin Precession \n81\nNow that the initial state is expressed in the energy basis, the time-evolved state is obtained by multi-\nplying each coefﬁcient by a phase factor dependent on the energy of that eigenstate:\n0\n c1t29 = e-iE+t>U cos u\n2\n 0  +9n + e-iE-t>U sin u\n2\n 0  -9n. \n(3.60)\nWe leave it in this form and substitute the energy eigenvalues\nE{ = { U\n2 4v2\n0 + v2\n1 \n(3.61)\nat the end of the example.\nThe probability of a spin ﬂip is\nP+ S  - = 08-  0\n c1t290\n2 \n= 2 8- 0 Je-iE+t>U cos u\n2 0  +9n + e-iE-t>U sin u\n2 0  -9n R 2\n2\n= 2 e-iE+t>U cos u\n2\n 8- 0  +9n + e-iE-t>U sin u\n2\n 8- 0  -9n 2\n2\n= 2 e-iE+t>U cos u\n2 sin u\n2\n + e-iE-t>U sin u\n2\n a-cos u\n2b 2\n2\n(3.62)\n= cos2 u\n2 sin2\n  u\n2\n @ 1 - ei1E+-E-2t>U@\n2 \n= sin2 u\n  sin2 a1E+ - E-2t\n2U\nb. \nThe probability oscillates at the frequency determined by the difference in energies of the eigen-\nstates. This time dependence results because the initial state was a superposition state, as we saw in \nEq. (3.20). In terms of the Larmor frequencies used to deﬁne the Hamiltonian in Eq. (3.51), the prob-\nability of a spin ﬂip is\nP+ S - =\nv2\n1\nv2\n0 + v2\n1\n sin2\n a 2v2\n0 + v2\n1\n2\n tb  . \n(3.63)\nEq. (3.63) is often called Rabi’s formula, and it has important applications in many problems as we \nshall see.\nTo gain insight into Rabi’s formula, consider two simple cases. First, if there is no added ﬁeld in \nthe x-direction, then v1 \u0003 0 and P+ S - = 0 because the initial state is a stationary state. Second, if \nthere is no ﬁeld component in the z-direction, then v0 \u0003 0 and P+ S - oscillates between 0 and 1 at the \nfrequency v1, as shown in Fig. 3.8(a). The second situation corresponds to spin precession around the ","page_start":105,"page_end":105,"token_count":650,"section_type":"other","chapter_number":4,"chapter_title":"Quantum Spookiness","chunk_index":129}
{"chunk_id":"170c2b9aeb92382f","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"the x-direction, then v1 \u0003 0 and P+ S - = 0 because the initial state is a stationary state. Second, if \nthere is no ﬁeld component in the z-direction, then v0 \u0003 0 and P+ S - oscillates between 0 and 1 at the \nfrequency v1, as shown in Fig. 3.8(a). The second situation corresponds to spin precession around the \napplied magnetic ﬁeld in the x-direction, as shown in Fig. 3.8(b), with a complete spin ﬂip from 0  +9 to \n0  -9 and back again occurring at the precession frequency v1. In the general case where both magnetic \nﬁeld components are present, the probability does not reach unity and so there is no time at which the \nspin is certain to ﬂip over. If the x-component of the ﬁeld is small compared to the z-component, then \nv1 << v0 and P+ S - oscillates between 0 and a value much less than 1 at a frequency approximately \nequal to v0, as shown in Fig. 3.9.","page_start":105,"page_end":105,"token_count":250,"section_type":"other","chapter_number":4,"chapter_title":"Quantum Spookiness","chunk_index":130}
{"chunk_id":"6ee79e2e197fc6d8","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"82 \nSchrödinger Time Evolution\nExample 3.2 A spin-1/2 particle with a magnetic moment is prepared in the state 0  -9 and is sub-\nject to a uniform applied magnetic ﬁeld B = B0yn. Find the probability of measuring spin up in the \nz-direction after a time t.\nThe initial state is\n \n0\n c1029 = 0  -9. \n(3.64)\nThe applied magnetic ﬁeld is in the y-direction, so the Hamiltonian is H = v0Sy and the energy \neigenstates are 0{9y with energies E{ = {U v0>2 (step 1). The Larmor precession frequency is \nt\n0\n0.2\n0.4\n0.6\n0.8\n1.0\n)\nb\n(\n)\na\n(\ny\nx\nz\nB\n〈S(0)〉\n〈S(t)〉\n2\u0002\n\u00030\n4\u0002\n\u00030\n6\u0002\n\u00030\nP+→−\nFIGURE 3.9 (a) Spin-ﬂip probability for a uniform magnetic ﬁeld with x- and z-components and \n(b) the corresponding precession of the expectation value of the spin.\nt\n)\nb\n(\n)\na\n(\ny\nx\nz\nB\n0.0\n0.2\n0.4\n0.6\n0.8\n1.0\nP+→−\nS(0)\nS(t)\n2Π\nΩ1\n4Π\nΩ1\n6Π\nΩ1\nFIGURE 3.8 (a) Spin-flip probability for a uniform magnetic ﬁeld in the x-direction and (b) the \ncorresponding precession of the expectation value of the spin.\nP+→−\n","page_start":106,"page_end":106,"token_count":405,"section_type":"other","chapter_number":4,"chapter_title":"Quantum Spookiness","chunk_index":131}
{"chunk_id":"84cf2b8479e48fdb","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"3.2 Spin Precession \n83\nv0 = eB0>me. We must express the initial state in the energy basis (step 2), which in this case is \nthe Sy basis:\n \n 0\n c1029 = 0  -9 = 10  +9y y0  + 0 + 0  -9y y8- 02 0  -9 \n \n = 0  +9y y8+ 0  -9 + 0  -9y y8- 0  -9\n \n \n = y8+ 0  -9 0  +9y + y8- 0  -9 0  -9y\n \n(3.65)\n \n =\n-i\n12 0  +9y +\ni\n12 0  -9y.\n \nThe time evolved state is obtained by multiplying each energy eigenstate coefﬁcient by a phase \nfactor (step 3):\n \n 0\n c1t29 =\n-i\n12\n e-iE +t>U0  +9y +\ni\n12\n e-iE -t>U0  -9y \n \n =\n-i\n12\n e-iv0t>20  +9y +\ni\n12\n e+iv0t>20  -9y. \n(3.66)\nThe measurement probability is found by projecting onto the measured state and squaring (step 4):\n \n P+ = 08+ 0\n c1t290\n2\n \n \n = @8+ 0A -i\n12 e-iv0t>20  +9y +\ni\n12 e+iv0t>20  -9y2@\n2\n \n \n = @ A -i\n12 e-iv0t>28+ 0  +9y +\ni\n12 e+iv0t>28+ 0  -9yB @\n2\n \n \n(3.67)\n \n = @ A -i\n12 e-iv0t>2 A 1\n12B +\ni\n12 e+iv0t>2 A 1\n12B B @\n2\n \n \n = 1\n4 @-ie-iv0t>2 + ie+iv0t>2@\n2\n= 1\n4 @-2sin1v0t>22 @\n2\n \n \n = sin2\n 1v0t>22.\n \n \nThe probability oscillates between zero and unity as time evolves, as shown in Fig. 3.10(a), which \nis consistent with the model of the spin vector precessing around the applied ﬁeld, as shown in \nFig. 3.10(b).\nt\n0.0\n0.2\n0.4\n0.6\n0.8\n1.0\ny\nx\nz\nΩ0t\nB\n(a)\n(b)\nP+→−\n\u0004S(t)\u0003\n\u0004S(0)\u0003\n2Π\nΩ0\n4Π\nΩ0\n6Π\nΩ0\nFIGURE 3.10 (a) Spin measurement probability and (b) the corresponding precession \nof the expectation value of the spin.\n","page_start":107,"page_end":107,"token_count":687,"section_type":"other","chapter_number":5,"chapter_title":"Quantized Energies: Particle in a Box","chunk_index":132}
{"chunk_id":"cf89339f387296ac","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"84 \nSchrödinger Time Evolution\nThough we have derived Rabi’s formula [Eq. (3.63)] in the context of a spin-1/2 particle in a \nuniform magnetic ﬁeld, its applicability is much more general. If we can express the Hamiltonian \nof any two-state system in the matrix form of Eq. (3.51) with the parameters v0 and v1, then we can \nuse Rabi’s formula to ﬁnd the probability that the system starts in the “spin-up” state 0  +9 and is then \nmeasured to be in the “spin-down” state 0  -9 after some time t. In the general case, the 0  +9 and 0  -9 \nstates are whatever states of the system are used to represent the Hamiltonian operator in the form of \nEq. (3.51). In the next section, we’ll look at the example of neutrino oscillations to see how this exam-\nple can be applied more generally.\n3.3 \u0002 NEUTRINO OSCILLATIONS\nNeutrinos have enjoyed an almost mystical history in particle physics because they are very hard to \ndetect and yet play an important role in many fundamental processes. In 1930, the neutrino was pos-\ntulated by Wolfgang Pauli as a solution to the beta decay problem. A free neutron decays to a proton \nand an electron with a lifetime of about 10 minutes in the most basic beta decay process. However, the \ndecay scheme n S p + e- violates conservation of angular momentum, and experimental data sug-\ngest that conservation of energy is also violated. That’s not good. Rather than reject these two basic \nconservation laws, as some suggested, Pauli proposed that a third particle is involved in the decay \nprocess. Enrico Fermi named this new particle the “neutrino.” Fermi developed a theory that used the \nneutrino to properly explain beta decay, but it was 25 more years before a neutrino was detected.\nNeutrinos are uncharged, relativistic particles. In nuclear beta decay, neutrinos are produced in \nprocesses such as\nn S p + e- + ne  \np S n + e+ + ne, \n(3.68)\nwhere the subscript labels the neutrino ne as an electron neutrino and the bar labels ne as an antineu-\ntrino. In the standard model of particle physics, neutrinos are massless, like photons. Neutrinos are so \nelusive because they interact via the weak force or weak interaction, which is the weakest of the four \nfundamental forces—the strong nuclear force, electromagnetism, and gravity being the other three.\nThe reaction p S n + e+ + ne is part of the thermonuclear reaction chain in the sun and other \nstars, so we earthlings are constantly bombarded with neutrinos along with the essential photons we \nreceive from the sun. In the 1960s and 70s, landmark experiments indicated that there are only about \nhalf as many solar neutrinos arriving on earth as we would expect, given reliable models of stellar ther-","page_start":108,"page_end":108,"token_count":661,"section_type":"other","chapter_number":5,"chapter_title":"Quantized Energies: Particle in a Box","chunk_index":133}
{"chunk_id":"08b493d7dd81543f","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"The reaction p S n + e+ + ne is part of the thermonuclear reaction chain in the sun and other \nstars, so we earthlings are constantly bombarded with neutrinos along with the essential photons we \nreceive from the sun. In the 1960s and 70s, landmark experiments indicated that there are only about \nhalf as many solar neutrinos arriving on earth as we would expect, given reliable models of stellar ther-\nmonuclear reactions. This solar neutrino problem has recently been solved by experiments detecting \nneutrinos from the sun and from nuclear reactors that demonstrate that neutrinos have nonzero mass. \nThese results are counter to the standard model and so have profound implications for particle physics \nand cosmology. Understanding how these experiments provide information on the neutrino mass is a \npowerful illustration of the applicability of Rabi’s formula to other two-state systems.\nIn addition to the electron neutrinos in Eq. (3.68), there are other types of neutrinos associated \nwith other reactions, such as\n p+ S m+ + nm\n m- S e- + nm + ne, \n(3.69)\nwhich represent the decay of a pion (p) to a muon (m) and the decay of a muon to an electron, respectively. \nA muon behaves exactly like an electron but has a larger mass. Electrons, muons, and a third particle \n(tau) and their associated neutrinos are collectively called leptons. In reactions involving these particles ","page_start":108,"page_end":108,"token_count":313,"section_type":"other","chapter_number":5,"chapter_title":"Quantized Energies: Particle in a Box","chunk_index":134}
{"chunk_id":"82498b136f1e0ea7","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"3.3 Neutrino Oscillations \n85\nit is convenient to define a lepton “ﬂavor” quantum number L, with the assigned values Le = 1 for the \nelectron e− and its associated neutrino ne, Le = -1 for the positron e+ and the antineutrino ne, Lm = 1\nfor the muon μ− and its associated neutrino nm, and Lm = -1 for the μ+ and nm. With these assignments, \nthe individual electron and muon ﬂavor numbers are conserved in the processes shown above. However, \nthere is no theoretical basis for this conservation, and so we allow for the possibility that these quantum \nnumbers are only approximately conserved. This possibility then allows for reactions of the type\nne 4 nm, \n(3.70)\nwhere an electron neutrino changes its ﬂavor and becomes a muon neutrino, or the reverse. Such \nchanges are called neutrino mixing or neutrino oscillations.\nThe labeling of neutrinos according to their association with electrons or muons arises from their behavior \nin the weak interaction processes described above. In other words, the quantum states 0 ne9 and 0 nm9 are \neigenstates of the Hamiltonian describing the weak interaction. However, when neutrinos propagate in \nfree space, the weak interaction is not relevant and the only Hamiltonian of relevance is that due to the \nrelativistic energy of the particles, which includes their rest masses and momenta. The eigenstates of this \nHamiltonian are generally referred to as the mass eigenstates. If the masses of the two types of neutrinos \n(electron and muon) are different, then, in general, the mass eigenstates do not coincide with the weak \ninteraction eigenstates. This distinction between sets of eigenstates allows for ﬂavor-changing processes.\nTo see why this is so, let the mass eigenstates be labeled 0 n19 and 0 n29. Either one of the two bases \n(mass or weak eigenstates) can be used as a complete basis upon which to expand any general state in \nthis system. Let’s assume that the relation between the bases is\n 0 ne9 = cos u\n2\n 0 n19 + sin u\n2\n 0 n29  \n 0 nm9 = sin u\n2\n 0 n19 - cos u\n2\n 0 n29. \n(3.71)\nThe angle u>2 is generally referred to as the mixing angle (some treatments drop the factor 1/2, but \nwe retain it to be consistent with the previous spin-1/2 discussion). If the mixing angle is small, then \nthe relations become\n 0 ne9 \u0003 0 n19  \n 0 nm9 \u0003 0 n29. \n(3.72)\nAssume that an electron neutrino is created in some weak interaction process and then propagates \nthrough free space to a detector. We wish to know the probability that a muon neutrino is detected, \nwhich is the signature of neutrino ﬂavor mixing. The initial state vector is\n 0 c1029 = 0 ne9","page_start":109,"page_end":109,"token_count":670,"section_type":"other","chapter_number":5,"chapter_title":"Quantized Energies: Particle in a Box","chunk_index":135}
{"chunk_id":"80cd3a78c26e33dc","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":" 0 ne9 \u0003 0 n19  \n 0 nm9 \u0003 0 n29. \n(3.72)\nAssume that an electron neutrino is created in some weak interaction process and then propagates \nthrough free space to a detector. We wish to know the probability that a muon neutrino is detected, \nwhich is the signature of neutrino ﬂavor mixing. The initial state vector is\n 0 c1029 = 0 ne9\n = cos u\n2\n 0 n19 + sin u\n2\n 0 n29. \n(3.73)\nDuring the free-space propagation, the energy eigenstates of the system are the mass eigenstates \nbecause there is no weak interaction present. Thus the Schrödinger time evolution for this state is\n0 c1t29 = cos u\n2\n e-iE1t>U0 n19 + sin u\n2\n e-iE2t>U0 n29. \n(3.74)\nThe energy eigenvalues are simply the relativistic energies, which are determined by the rest masses \nand the momenta:\nEi = 41pc22 + 1mi c222,  i = 1, 2. \n(3.75)","page_start":109,"page_end":109,"token_count":265,"section_type":"other","chapter_number":5,"chapter_title":"Quantized Energies: Particle in a Box","chunk_index":136}
{"chunk_id":"5bcf9e8629efc13f","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"86 \nSchrödinger Time Evolution\nAssuming that the neutrinos are highly relativistic 1mc2 V pc2, we ﬁnd\n Ei = pc c1 + ami c2\npc b\n2\nd\n1>2\n \u0002 pc c1 + 1\n2\n amic2\npc b\n2\nd  \n(3.76)\n \u0002 pc + 1mi c222\n2pc\n.\nThe beauty of studying two-level systems such as spin-1/2 particles and neutrino oscillations is \nthat they are formally identical. In the spin-1/2 case, we phrased the problem in terms of ﬁnding the \nprobability of a spin ﬂip, whereas here we are looking for a change in the ﬂavor of the neutrino. In \nboth cases, the initial and ﬁnal states are not energy eigenstates, but rather orthogonal states in a dif-\nferent basis. The problems are mathematically identical, so the probability of a transition between the \northogonal states takes the same form. The probability of a neutrino oscillation is thus given by the \nsame equation as the spin-ﬂip probability, Eq. (3.62),\n PneSnm = 08nm0 c1t290\n2\n = sin2 u\n  sin2 a1E1 - E22t\n2U\nb, \n(3.77)\nwhere the parameter u has been deﬁned the same in both problems and the energy difference E+ - E- \nhas been changed to the energy difference E1 - E2. This energy difference is\n E1 - E2 = 1m1c22\n2\n2pc\n- 1m2c22\n2\n2pc\n = c3\n2p\n 1m2\n1 - m2\n22.\n(3.78)\nNeutrinos move at nearly the speed of light c, so we approximate the time from the creation of the \nelectron neutrino to the detection of the muon neutrino as t \u0002 L>c, where L is the distance from the \nsource to the detector. We also approximate the relativistic momentum as p = E>c. This gives a prob-\nability for neutrino ﬂavor change of\n PneSnm = sin2 u sin2 a1m2\n1 - m2\n22Lc3\n4E U\nb . \n(3.79)\nAs a function of the distance L, the probability oscillates from 0 to a maximum value of sin2 u—hence \nthe term neutrino oscillation. By measuring the fractions of different neutrino ﬂavors at a distance \nfrom a neutrino source (e.g., the sun or a reactor) and comparing to a model for the expected fractions, \nexperimenters have been able to infer the masses of the different neutrinos, or at least the differences \nof the squares of the masses. Recent results from solar neutrino and reactor neutrino experiments \nindicate a squared mass difference of approximately\nm2\n1 - m2","page_start":110,"page_end":110,"token_count":659,"section_type":"other","chapter_number":5,"chapter_title":"Quantized Energies: Particle in a Box","chunk_index":137}
{"chunk_id":"a6cdd63a153d91ec","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"from a neutrino source (e.g., the sun or a reactor) and comparing to a model for the expected fractions, \nexperimenters have been able to infer the masses of the different neutrinos, or at least the differences \nof the squares of the masses. Recent results from solar neutrino and reactor neutrino experiments \nindicate a squared mass difference of approximately\nm2\n1 - m2\n2 \u0005 8 * 10-5 eV 2>c4. \n(3.80)\nThese experiments also provide information on the mixing angle u, with recent results indicating\nu \u0005 69\b. \n(3.81)\nNeutrino experiments such as these continue to provide information about the fundamental physics of \nthe universe.","page_start":110,"page_end":110,"token_count":155,"section_type":"other","chapter_number":5,"chapter_title":"Quantized Energies: Particle in a Box","chunk_index":138}
{"chunk_id":"91509cdc246b8770","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"3.4 Time-Dependent Hamiltonians \n87\n3.4 \u0002 TIME-DEPENDENT HAMILTONIANS\nUp to now, we have studied the time evolution of quantum mechanical systems where the Hamiltonian \nis time independent. We solved the Schrödinger equation once for the general case and developed \na recipe for the time evolution of the system that we can apply to all cases with time-independent \nHamiltonians. However, if the Hamiltonian is time dependent, then we cannot use that simple recipe. \nWe must know the form of the Hamiltonian time dependence in order to solve the Schrödinger equa-\ntion. Fortunately, there are common forms of time dependence that we can solve in general and then \napply in many cases. The most common form of time dependence is sinusoidal time dependence at one \nfrequency. We will solve this problem in the context of a spin-1/2 particle in a magnetic ﬁeld and then \nalso apply it to atom-light interactions.\n3.4.1 \u0002 Magnetic Resonance\nIn the spin precession example in Section 3.2.2, we concluded that a complete spin ﬂip required a large \nmagnetic ﬁeld in the x-direction, which represents a large change or perturbation compared to the \ninitial situation of a magnetic ﬁeld in the z-direction. Now consider whether we can induce a complete \nspin ﬂip without such a large perturbation. That is, what small magnetic ﬁeld can we add to the system \nthat will cause a 0  +9 state to ﬂip to a 0  -9 state? The answer is that we must apply a time-dependent \nmagnetic ﬁeld that oscillates at a frequency close to the Larmor precession frequency v0 that charac-\nterizes the energy difference between the spin-up and spin-down states, as shown in Fig. 3.1. By mak-\ning the oscillating magnetic ﬁeld resonant with the Larmor frequency, we induce transitions between \nthe energy states shown in Fig. 3.1. This effect is known as magnetic resonance. I. I. Rabi won the \nNobel Prize in physics in 1944 for his work in developing the magnetic resonance technique and using \nit to measure the magnetic moments of nuclei. Following Rabi’s work, nuclear magnetic resonance \n(NMR) became a widely used tool for studying the properties of materials. The Larmor frequency \ndepends on the magnetic ﬁeld magnitude at the location of the particular nucleus being studied. This \nmagnetic ﬁeld includes the applied external ﬁeld and any internal ﬁelds created by the local environ-\nment, such that measuring the resonance frequency provides valuable information about the environ-\nment of the nucleus. In biology and chemistry, NMR has been used extensively to distinguish different \ntypes of bonds and identify structures. More recently, magnetic resonance imaging (MRI) has been \ndeveloped for medical diagnosis.\nTo understand how magnetic resonance works, it is instructive to consider the classical problem \nﬁrst. A classical magnetic moment aligned with an angular momentum precesses around the direc-","page_start":111,"page_end":111,"token_count":661,"section_type":"other","chapter_number":5,"chapter_title":"Quantized Energies: Particle in a Box","chunk_index":139}
{"chunk_id":"d5fdca2673600da3","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"ment, such that measuring the resonance frequency provides valuable information about the environ-\nment of the nucleus. In biology and chemistry, NMR has been used extensively to distinguish different \ntypes of bonds and identify structures. More recently, magnetic resonance imaging (MRI) has been \ndeveloped for medical diagnosis.\nTo understand how magnetic resonance works, it is instructive to consider the classical problem \nﬁrst. A classical magnetic moment aligned with an angular momentum precesses around the direc-\ntion of an applied magnetic ﬁeld. Now imagine going to a reference frame that rotates about the ﬁeld \n(assumed to be in the z-direction) with the same frequency as the precession. An observer in the rotat-\ning frame would see the magnetic moment stationary and so would conclude that there is no magnetic \nﬁeld in that frame. If that rotating observer were asked to ﬂip the magnetic moment from up to down \nalong the z-axis, she would answer, “Simple, just impose a small magnetic ﬁeld perpendicular to the \nz-axis, which will cause the spin to precess around that direction.” Because that ﬁeld is the only ﬁeld \nacting in the rotating frame, it can be as small as one likes. The magnitude simply determines the time \nfor the spin to ﬂip.\nIn this situation, the transverse applied ﬁeld is stationary in the rotating frame, so it will appear to \nbe rotating at the precessional frequency in the original frame. Thus, we could write it as\nB = B1 cos1vt2xn + B1 sin1vt2yn, \n(3.82)\nwhere we allow the frequency v to differ from the precessional frequency v0 in order to solve the \nproblem more generally. In that case, there would be some residual precession in the rotating frame, \nand so the rotating observer would conclude that there is some residual ﬁeld in the z-direction. Hence, ","page_start":111,"page_end":111,"token_count":409,"section_type":"other","chapter_number":5,"chapter_title":"Quantized Energies: Particle in a Box","chunk_index":140}
{"chunk_id":"29e45bf03417905e","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"88 \nSchrödinger Time Evolution\nwe expect that the added transverse ﬁeld would not cause a complete ﬂipping of the magnetic moment \nfrom up to down in this general case.\nLet’s now apply this reasoning to the quantum mechanical case. Assume a magnetic ﬁeld of the form\n \nB = B0zn + B13cos1vt2xn + sin1vt2yn4, \n(3.83)\nwhere the role of B0 is to split the energies of the spin-up and spin-down states and the role of B1 is to \nﬂip the spin between the the up and down states. The Hamiltonian is\n \n H = -M~B\n \n \n = v0 Sz + v13cos1vt2Sx + sin1vt2Sy4, \n \n(3.84)\nwhere we again deﬁne the Larmor frequencies corresponding to the two magnetic ﬁeld components,\n \nv0 K eB0\nme\n,   v1 K eB1\nme\n. \n(3.85)\nThe matrix representation of the Hamiltonian is\n \nH \u0003 U\n2\n ¢ v0\nv1e-ivt\nv1eivt\n-v0\n≤. \n(3.86)\nThis Hamiltonian is time dependent, so we can no longer use our simple recipe for Schrödinger \ntime evolution. Rather, we must return to the Schrödinger equation and solve it with these new time-\ndependent terms. Because we are not using our recipe for Schrödinger time evolution, we are not \nbound to use the energy basis as the preferred basis. The obvious choice would be to use the basis we \nhave used for representing the Hamiltonian as a matrix, which becomes the basis of energy states if the \ntransverse part B1 of the magnetic ﬁeld vanishes. Using this basis, we write the state vector as\n \n0 c1t29 = c+1t2 0  +9 + c-1t2 0  -9 \u0003  ¢c+1t2\nc-1t2≤. \n(3.87)\nSchrödinger’s equation\n \niU d\ndt\n 0\n c1t29 = H1t2 0\n c1t29 \n(3.88)\nin matrix form is\n \niU d\ndt\n ¢c+1t2\nc-1t2≤= U\n2\n ¢ v0\nv1e-ivt\nv1eivt\n-v0\n≤¢c+1t2\nc-1t2≤ \n(3.89)\nand leads to the differential equations\n \niUc#\n+ 1t2 = U v0\n2  c+1t2 + U v1\n2  e-ivtc-1t2 \n \niUc#\n- 1t2 = U v1\n2  eivt c+1t2 - U v0\n2  c-1t2, \n \n(3.90)\nwhere c#\n+1t2 denotes a time derivative. To solve these time-dependent coupled differential equations, \nit is useful to follow the lead of the classical discussion and consider the problem from the rotating \n","page_start":112,"page_end":112,"token_count":700,"section_type":"other","chapter_number":5,"chapter_title":"Quantized Energies: Particle in a Box","chunk_index":141}
{"chunk_id":"8cbe753f4ef09625","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"3.4 Time-Dependent Hamiltonians \n89\nframe. Though we don’t yet have the complete tools to know how to effect this transformation, we take \nit on faith that after a frame transformation the state vector is\n0 c\u00031t29 = c+1t2eivt>2 0  +9 + c-1t2e-ivt>2 0  -9 \u0003 ¢ c+1t2eivt>2\nc-1t2e-ivt>2≤, \n(3.91)\nwhere 0 c\u00031t29 is the state vector as viewed from the rotating frame. If we call the coefﬁcients of this \nvector a{1t2, then we can write\n0 c\u00031t29 = a+1t2 0  +9 + a-1t2 0  -9 \u0003 ¢a+1t2\na-1t2≤, \n(3.92)\nwhere the relations between the sets of coefﬁcients are\n c+1t2 = e-ivt>2a+1t2 \n c-1t2 = eivt>2a-1t2. \n(3.93)\nThe state vector in the nonrotating frame can thus be written as\n0 c1t29 = a+1t2e-ivt>2 0  +9 + a-1t2eivt>2 0  -9 \u0003 ¢a+1t2e-ivt>2\na-1t2eivt>2 ≤. \n(3.94)\nAnother way of viewing this transformation is to say that based upon earlier solutions of similar \nproblems [Eq. (3.35)], we expect the coefﬁcients c{1t2 to have time dependence of the form e|ivt>2, \nand so we have extracted that part of the solution and now need to solve for the remaining time depen-\ndence in the coefﬁcients a{1t2. In this view, we have simply performed a mathematical trick to make \nthe solution easier.\nIf we now substitute the expressions for c{1t2 in terms of a{1t2 into the differential \nequations (3.90), then we obtain\n iUa#\n+1t2 = -  U\u0006v\n2\n a+1t2 + U v1\n2\n a-1t2 \n iUa#\n-1t2 = U v1\n2\n a+1t2 + U\u0006v\n2\n a-1t2,  \n(3.95)\nwhere we have deﬁned a new term\n\u0006v K v - v0, \n(3.96)\nwhich is the difference between the angular frequencies of the rotating ﬁeld and the Larmor preces-\nsion due to the z-component of the magnetic ﬁeld. Because a{1t2 are the coefﬁcients of the trans-","page_start":113,"page_end":113,"token_count":653,"section_type":"other","chapter_number":5,"chapter_title":"Quantized Energies: Particle in a Box","chunk_index":142}
{"chunk_id":"784db1d9c734e3bd","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"2\n a+1t2 + U\u0006v\n2\n a-1t2,  \n(3.95)\nwhere we have deﬁned a new term\n\u0006v K v - v0, \n(3.96)\nwhich is the difference between the angular frequencies of the rotating ﬁeld and the Larmor preces-\nsion due to the z-component of the magnetic ﬁeld. Because a{1t2 are the coefﬁcients of the trans-\nformed state vector 0 c\u00031t29, these differential equations can be considered as comprising a transformed \nSchrödinger equation\niU d\ndt\n 0\n c\u00031t29 = H\u0003\n 0\n c\u00031t29, \n(3.97)\nwhere the new Hamiltonian H\u0003 has the matrix representation\nH\u0003 \u0003 U\n2\n a-\u0006v\nv1\nv1\n\u0006vb. \n(3.98)","page_start":113,"page_end":113,"token_count":205,"section_type":"other","chapter_number":5,"chapter_title":"Quantized Energies: Particle in a Box","chunk_index":143}
{"chunk_id":"b587c29286dadd8b","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"90 \nSchrödinger Time Evolution\nThus, we have transformed (by rotation or mathematical sleight of hand) the original problem \ninto a new problem that has a time-independent Hamiltonian. Once we solve the new problem, we can \nuse the transformation equations to ﬁnd the solution to the original problem. However, because the \nnew Hamiltonian H\u0003 is time independent, we already know the solution. That is, this new problem has \nthe same form of the Hamiltonian as the spin precession problem in Section 3.2.2. Comparing the spin \nprecession Hamiltonian in Eq. (3.51) with the transformed Hamiltonian in Eq. (3.98), we note that the \nterm v0 is replaced by the new term -\u0006v. We are interested in ﬁnding the same probability P+ S - that \nan initial 0  +9 state is later found to have evolved to the 0  -9 state. The rotational transformation does \nnot alter the 0{9 basis states so if\n0 c1029 = 0  +9, \n(3.99)\nthen\n0 c\u00031029 = 0  +9. \n(3.100)\nThe probability for a spin flip is given by\n P+ S - = 08- 0\n c1t290\n2 \n = 0 c-1t20\n2.\n(3.101)\nFrom Eq. (3.93) relating the coefﬁcients, we have\n 0 c-1t20\n2 = 0 e-ivt>2a-1t20\n2 \n = 0 a-1t20\n2\n(3.102)\n = 08- 0 c\u00031t290\n2,  \nwhich means that the probability we desire is\nP+ S - = 08- 0 c\u00031t290\n2. \n(3.103)\nWe obtain this spin-ﬂip probability using Rabi’s formula in Eq. (3.63), with the change v0 S -\u0006v, \nresulting in\n P+ S - =\nv2\n1\n\u0006v2 + v2\n1\n  sin2 ¢ 4\u0006v2 + v2\n1\n2\n t≤ \n =\nv2\n1\n1v - v022 + v2\n1\n  sin2 ¢41v - v022 + v2\n1\n2\n t≤. \n(3.104)\nThis spin-ﬂip probability is a generalization of Rabi’s formula. Note that Eq. (3.104) reduces to \nEq. (3.63) for the case v = 0, which is expected because the applied ﬁeld in Eq. (3.83) is static and \naligned the same as the static ﬁeld in Eq. (3.48) for the case v = 0. The static magnetic ﬁeld case is \ngenerally referred to as spin precession, while the rotating ﬁeld case is referred to as Rabi ﬂopping. ","page_start":114,"page_end":114,"token_count":663,"section_type":"other","chapter_number":5,"chapter_title":"Quantized Energies: Particle in a Box","chunk_index":144}
{"chunk_id":"618310db38e936cd","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"Eq. (3.63) for the case v = 0, which is expected because the applied ﬁeld in Eq. (3.83) is static and \naligned the same as the static ﬁeld in Eq. (3.48) for the case v = 0. The static magnetic ﬁeld case is \ngenerally referred to as spin precession, while the rotating ﬁeld case is referred to as Rabi ﬂopping. \nThough we have used their similarities to help us derive Eq. (3.104), it is important to clarify their dif-\nferences. In the static applied magnetic ﬁeld case, the resulting spin precession is a manifestation of \nthe natural Bohr oscillation of a quantum system that starts in a superposition of energy eigenstates. \nThe initial superposition remains intact and there is no exchange of energy between the system and \nthe applied ﬁeld. In the rotating applied magnetic ﬁeld case, the Rabi ﬂopping represents transitions \nbetween energy eigenstates, and there is exchange of energy between the system and the applied ﬁeld. \nThe energy exchange occurs because the Hamiltonian is time dependent.","page_start":114,"page_end":114,"token_count":245,"section_type":"other","chapter_number":5,"chapter_title":"Quantized Energies: Particle in a Box","chunk_index":145}
{"chunk_id":"dc9240cce0090c69","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"3.4 Time-Dependent Hamiltonians \n91\nThe probability of a Rabi spin ﬂip oscillates with an angular frequency given by\n\t = 41v - v022 + v2\n1, \n(3.105)\nthat is typically referred to as the generalized Rabi frequency. The term Rabi frequency generally \nrefers to the frequency v1, which is the value of the generalized Rabi frequency when the frequency v \nof the rotating ﬁeld is on resonance (i.e., v is set equal to the Larmor precession frequency v0 of the \nsystem in the presence of the magnetic ﬁeld B0 alone). For this choice of v = v0, the probability of a \nspin ﬂip becomes\nP+ S - = sin2 av1\n2\n tb, \n(3.106)\nwhich implies that the spin is ﬂipped with 100% probability at an angular frequency v1. For other off-\nresonance choices of the frequency v, the probability of a spin ﬂip oscillates with an amplitude smaller \nthan one. The amplitude of the spin-ﬂip oscillation, as a function of the frequency v of the rotating \nﬁeld, is plotted in Fig. 3.11. This curve has the form of a Lorentzian curve and clearly exhibits the \nimportant resonant behavior of the spin-ﬂip probability. The full width at half maximum (FWHM) of \nthe resonance curve is 2v1.\nFor the resonance condition v = v0, the probability of a spin ﬂip as a function of time is plotted \nin Fig. 3.12. Because the frequency v1 is proportional to the applied ﬁeld B1, the rate of spin ﬂipping \nincreases with increasing rotating magnetic ﬁeld strength. However, it is important to note that there \nis still 100% probability of a spin ﬂip for very small ﬁelds. This is the property we were looking for at \nthe beginning of the problem—a way to ﬂip the spin without perturbing the system appreciably. After \na time t given by v1t = p, the probability for a spin ﬂip is 100%. We have assumed that the applied \nﬁeld is on continuously, but this spin ﬂip can also be produced by a pulsed ﬁeld with a magnitude and \nduration that satisfy v1t = p. Such a pulse is often called a P-pulse and is used to ﬂip a spin, or more \ngenerally to make a transition from one energy state to another with 100% certainty. The diagram on \nthe right of Fig. 3.12 illustrates the energy levels of the spin in the magnetic ﬁeld and how the spin-ﬂip \noscillations are associated with transitions between the two energy levels. A transition from the upper \nlevel to the lower level takes energy from the atom and gives it to the magnetic ﬁeld and is known as \nemission, while the opposite process takes energy from the ﬁeld and is known as absorption.\n0","page_start":115,"page_end":115,"token_count":671,"section_type":"other","chapter_number":5,"chapter_title":"Quantized Energies: Particle in a Box","chunk_index":146}
{"chunk_id":"fcee1c0e93b7f451","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"the right of Fig. 3.12 illustrates the energy levels of the spin in the magnetic ﬁeld and how the spin-ﬂip \noscillations are associated with transitions between the two energy levels. A transition from the upper \nlevel to the lower level takes energy from the atom and gives it to the magnetic ﬁeld and is known as \nemission, while the opposite process takes energy from the ﬁeld and is known as absorption.\n0\n0.5\n1.0\n2Ω1\nΩ0\nΩ\nP+→−,max\nFIGURE 3.11 Magnetic resonance curve showing the probability \nof a spin ﬂip as a function of the applied  frequency.","page_start":115,"page_end":115,"token_count":153,"section_type":"other","chapter_number":5,"chapter_title":"Quantized Energies: Particle in a Box","chunk_index":147}
{"chunk_id":"c8f9de5e809c314a","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"92 \nSchrödinger Time Evolution\n3.4.2 \u0002 Light-Matter Interactions\nThis same model of the interaction between a two-level system and an applied time-dependent ﬁeld is \nused to explain how atoms absorb and emit light. In the magnetic resonance example above, the oscil-\nlating magnetic ﬁeld interacts with the magnetic dipole and energy is exchanged between the ﬁeld and \nthe dipole. In the interaction of atoms with light, the oscillating electric ﬁeld of the light wave interacts \nwith the electric dipole of the atom, and energy exchange between the ﬁeld and the atom corresponds to \nabsorption and emission of photons. We can use the Rabi ﬂopping formula of Eq. (3.104) to model the \natom-light interaction as long as we express the Hamiltonian of the system in the form of Eq. (3.86). \nThough atoms have more than two energy levels, we can reduce the problem to a two-level system if \nthe frequency v of the applied light ﬁeld is close to just one of the Bohr frequencies of the atom.\nConsider two levels of an atom, as shown in Fig. 3.13. Following the convention used in this com-\nmon problem, we label the lower state 0 g9 (for ground state) and the upper state 0 e9 (for excited state). \nThe energy difference between the two levels is deﬁned to be\n \nEe - Eg = U v0 \n(3.107)\nto connect to the spin notation. The applied light ﬁeld (e.g., laser beam) has a frequency v that is close \nto, but not necessarily equal to, the atomic Bohr frequency v0. Using the same notation as the spin \nproblem [Eq. (3.86)], we express the Hamiltonian for this atom-light system in two parts\n \nH \u0003 U\n2\n a v0\nv1e-ivt\nv1eivt\n-v0\nb = U\n2\n av0\n0\n0\n-v0\nb + U\n2\n a\n0\nv1e-ivt\nv1eivt\n0\nb \n(3.108)\nEe\nEg\n\u0002Ω0\n\u0002Ω\n\u0002e\u0003\n\u0002g\u0003\nFIGURE 3.13 Energy level diagram of a two-level atom interacting with \nan applied light ﬁeld of frequency v.\nt\n0.0\n0.2\n0.4\n0.6\n0.8\n1.0\nemission\nabsorption\nemission\nabsorption\nemission\nabsorption\nP+→−\nΠ\nΩ1\n2Π\nΩ1\n3Π\nΩ1\n4Π\nΩ1\n\u0002\u0004\u0003\n\u0002\u0005\u0003\nFIGURE 3.12 Rabi oscillations of the spin-ﬂip probability for the resonance condition.\n","page_start":116,"page_end":116,"token_count":634,"section_type":"other","chapter_number":5,"chapter_title":"Quantized Energies: Particle in a Box","chunk_index":148}
{"chunk_id":"c4d8ffda0db05f74","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"Summary \n93\nand identify the ﬁrst term as the atomic Hamiltonian and the second term as the interaction Hamilto-\nnian. In this way, we see that the parameter v1 is really an off-diagonal matrix element of the interac-\ntion Hamiltonian that connects the two states:\nv1 = 2\nU\n 8e0 Hint0 g9. \n(3.109)\nThe Rabi formula in Eq. (3.104) then gives the probability for the light ﬁeld to cause transitions \nbetween the two atomic energy states. Transitions between the atomic states correspond to absorption \n10 g9 S 0 e92 and emission 10 e9 S 0 g92 of photons in the light ﬁeld. Total energy is conserved as it is \nexchanged between the atom and the light ﬁeld.\nStudying these induced transitions is the most powerful tool we have for discovering what the \nenergy levels of a system are and ultimately for determining the Hamiltonian of the system. This \ntool is known as spectroscopy and has played a pivotal role in relating experiments and theory in \nquantum mechanics. As we encounter new quantum mechanical systems in this text, we will point \nout the spectroscopic aspects of these systems. For now, we can make a few general comments. If the \nmatrix element of the interaction Hamiltonian in Eq. (3.109) happens to be zero, then the transition \nprobability between the two levels is zero and we say that this is a forbidden transition. By studying \nthe general properties of the matrix elements 8e0 Hint0 g9 for a system and an interaction, we can dis-\ncover a set of basic rules governing whether transitions are allowed or forbidden. These are known as \nselection rules and are often representative of some underlying symmetry in the system. We will discuss \nselection rules brieﬂy as we encounter new systems and then will study them more fully in Chapter 14.\nSUMMARY\nIn this chapter we have learned the key aspect of quantum mechanics—how to predict the future. \nSchrödinger’s equation\niU d\ndt\n 0\n c1t29 = H1t20\n c1t29 \n(3.110)\ntells us how quantum state vectors evolve with time. In the common case where the Hamiltonian \nis time independent, the solution to Schrödinger’s equation has the same form no matter the problem. The \ntime-evolved state includes energy-dependent phase factors for each component of the superposition \nthat the system starts in:\n0 c1t29 = a\nn\ncne-iEnt>U0 En9. \n(3.111)\nThe general recipe for solving time-dependent problems is\nGiven a Hamiltonian H and an initial state 0 c1029, what is the probability that \nthe eigenvalue aj of the observable A is measured at time t?\n 1. Diagonalize H (ﬁnd the eigenvalues En and eigenvectors 0 En92.\n 2. Write 0 c1029 in terms of the energy eigenstates 0 En9.","page_start":117,"page_end":117,"token_count":652,"section_type":"other","chapter_number":5,"chapter_title":"Quantized Energies: Particle in a Box","chunk_index":149}
{"chunk_id":"82bd6fb787cad5b8","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"(3.111)\nThe general recipe for solving time-dependent problems is\nGiven a Hamiltonian H and an initial state 0 c1029, what is the probability that \nthe eigenvalue aj of the observable A is measured at time t?\n 1. Diagonalize H (ﬁnd the eigenvalues En and eigenvectors 0 En92.\n 2. Write 0 c1029 in terms of the energy eigenstates 0 En9.\n 3. Multiply each eigenstate coefﬁcient by e-iEnt>U to get 0 c1t29.\n 4. Calculate the probability Paj = 08aj0 c1t290\n2.\nWe will use this recipe throughout the rest of the book to study the time evolution of quantum mechan-\nical systems where the Hamiltonian is time independent.","page_start":117,"page_end":117,"token_count":171,"section_type":"other","chapter_number":5,"chapter_title":"Quantized Energies: Particle in a Box","chunk_index":150}
{"chunk_id":"12e62f830d7d3ddc","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"94 \nSchrödinger Time Evolution\nPROBLEMS\n 3.1 Write out the Schrödinger equation as expressed in Eq. (3.5) in matrix form for the two-state \nsystem and verify the result in Eq. (3.8).\n 3.2 Show that the probability of a measurement of the energy is time independent for a general state \n 0 c1t29 = a\nn\ncn1t2 0 En9 that evolves due to a time-independent Hamiltonian. Show that the \n probability of measurements of other observables are also time independent if those observables \ncommute with the Hamiltonian.\n 3.3 Show that the Hamiltonian in Eq. (3.51) can be written in the simple form of Eq. (3.56). \nDiagonalize the Hamiltonian in Eq. (3.55) and conﬁrm the results in Eq. (3.57).\n 3.4 Consider a spin-1/2 particle with a magnetic moment placed in a uniform magnetic ﬁeld \naligned with the z-axis. Verify by explicit matrix calculations that the Hamiltonian commutes \nwith the spin component operator in the z-direction but not with spin component operators in \nthe x- and y-directions. Comment on the relevance of these results to spin precession.\n 3.5 Consider a spin-1/2 particle with a magnetic moment. At time t = 0, the state of the particle is \n0 c1t = 029 = 0  +9.\na) If the observable Sx is measured at time t = 0, what are the possible results and the \nprobabilities of those results?\nb) Instead of performing the above measurement, the system is allowed to evolve in a uniform \nmagnetic ﬁeld B = B0yn. Calculate the state of the system (in the Sz basis) after a time t.\nc) At time t, the observable Sx is measured. What is the probability that a value U>2 will be \nfound?\nd) Draw a schematic diagram of the experiment in parts (b) and (c), similar to Fig. 3.2.\n 3.6 Consider a spin-1/2 particle with a magnetic moment.\na) At time t = 0, the observable Sx is measured, with the result U>2. What is the state vector \n0 c1t = 029 immediately after the measurement?\nb) Immediately after the measurement, a magnetic ﬁeld B = B0zn is applied and the particle is \nallowed to evolve for a time T. What is the state of the system at time t \u0003 T?\nc) At t = T, the magnetic ﬁeld is very rapidly changed to B = B0yn. After another time inter-\nval T, a measurement of Sx is carried out once more. What is the probability that a value U>2 \nis found?\n 3.7 A beam of identical neutral particles with spin 1/2 travels along the y-axis. The beam passes \nthrough a series of two Stern-Gerlach spin-analyzing magnets, each of which is designed to ","page_start":118,"page_end":118,"token_count":664,"section_type":"other","chapter_number":5,"chapter_title":"Quantized Energies: Particle in a Box","chunk_index":151}
{"chunk_id":"54aae1fce71cb95e","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"val T, a measurement of Sx is carried out once more. What is the probability that a value U>2 \nis found?\n 3.7 A beam of identical neutral particles with spin 1/2 travels along the y-axis. The beam passes \nthrough a series of two Stern-Gerlach spin-analyzing magnets, each of which is designed to \nanalyze the spin component along the z-axis. The ﬁrst Stern-Gerlach analyzer allows only \nparticles with spin up (along the z-axis) to pass through. The second Stern-Gerlach analyzer \nallows only particles with spin down (along the z-axis) to pass through. The particles travel at \nspeed v between the two analyzers, which are separated by a region of length d in which there \nis a uniform magnetic ﬁeld B0 pointing in the x-direction. Determine the smallest value of d \nsuch that 25% of the particles transmitted by the ﬁrst analyzer are transmitted by the second \nanalyzer.\n 3.8 A beam of identical neutral particles with spin 1/2 is prepared in the 0  +9 state. The beam enters \na uniform magnetic ﬁeld B0, which is in the xz-plane and makes an angle u with the z-axis. \nAfter a time T in the ﬁeld, the beam enters a Stern-Gerlach analyzer oriented along the y-axis. \nWhat is the probability that particles will be measured to have spin up in the y-direction? Check \nyour result by evaluating the special cases u = 0 and u = p>2.","page_start":118,"page_end":118,"token_count":333,"section_type":"other","chapter_number":5,"chapter_title":"Quantized Energies: Particle in a Box","chunk_index":152}
{"chunk_id":"908f827d253a2e74","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":" 3.9 Consider a spin-1/2 particle with a magnetic moment. At time t = 0, the state of the particle is \n0 c1t = 029 = 0  +9n with the direction n = 1xn + yn2> 12. The system is allowed to evolve in \na uniform magnetic ﬁeld B = B0zn. What is the probability that the particle will be measured to \nhave spin up in the y-direction after a time t?\n 3.10 Consider a spin-1/2 particle with a magnetic moment. At time t = 0, the state of the \nparticle is 0 c1t = 029 = 0  +9. The system is allowed to evolve in a uniform magnetic ﬁeld \nB = B01xn + zn2> 12. What is the probability that the particle will be measured to have spin \ndown in the z-direction after a time t?\n 3.11 Consider a spin-1/2 particle with a magnetic moment. At time t = 0, the state of the particle is \n0 c1t = 029 = 0  +9n with the direction n = 1xn + yn2> 12. The system is allowed to evolve in \na uniform magnetic ﬁeld B = B01xn + zn2> 12. What is the probability that the particle will be \nmeasured to have spin up in the y-direction after a time t?\n 3.12 Consider a two-state quantum system with a Hamiltonian\nH \u0003 aE1\n0\n0\nE2\nb .\n Another physical observable A is described by the operator\nA \u0003 a0\na\na\n0b,\n where a is real and positive. Let the initial state of the system be 0 c1029 = 0 a19, where 0 a19 is \nthe eigenstate corresponding to the larger of the two possible eigenvalues of A. What is the \nfrequency of oscillation (i.e., the Bohr frequency) of the expectation value of A?\n 3.13 Let the matrix representation of the Hamiltonian of a three-state system be\nH \u0003 °\nE0\n0\nA\n0\nE1\n0\nA\n0\nE0\n ¢\n using the basis states 0 19, 0 29, and 0 39.\na) If the state of the system at time t = 0 is 0 c1029 = 0 29, what is the probability that the \nsystem is in state 0 29 at time t?\nb) If, instead, the state of the system at time t = 0 is 0 c1029 = 0 39, what is the probability that \nthe system is in state 0 39 at time t?\n 3.14 A quantum mechanical system starts out in the state\n0 c1029 = C130 a19 + 40 a292,\n where 0 ai9 are the normalized eigenstates of the operator A corresponding to the eigenvalues ai. \nIn this 0 ai9 basis, the Hamiltonian of this system is represented by the matrix","page_start":119,"page_end":119,"token_count":669,"section_type":"other","chapter_number":5,"chapter_title":"Quantized Energies: Particle in a Box","chunk_index":153}
{"chunk_id":"79f123e751ad3537","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"the system is in state 0 39 at time t?\n 3.14 A quantum mechanical system starts out in the state\n0 c1029 = C130 a19 + 40 a292,\n where 0 ai9 are the normalized eigenstates of the operator A corresponding to the eigenvalues ai. \nIn this 0 ai9 basis, the Hamiltonian of this system is represented by the matrix\nH \u0003 E0 a2\n1\n1\n2b.\na) If you measure the energy of this system, what values are possible, and what are the \nprobabilities of measuring those values?\nb) Calculate the expectation value 8A9 of the observable A as a function of time.\nProblems \n95","page_start":119,"page_end":119,"token_count":151,"section_type":"other","chapter_number":5,"chapter_title":"Quantized Energies: Particle in a Box","chunk_index":154}
{"chunk_id":"049cd89029041190","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"96 \nSchrödinger Time Evolution\n 3.15 Show that the general energy state superposition 0 c1t29 = a\nn\ncne-iEnt>U0 En9 satisﬁes the \n Schrödinger equation, but not the energy eigenvalue equation.\n 3.16 For a spin-1/2 system undergoing Rabi oscillations, assume that the resonance condition \nv = v0 holds.\na) Solve the differential equations for the coefﬁcients a{1t2. Use your results to ﬁnd the \ntransformed state vector 0 c\u00031t29 and the state vector 0 c1t29, assuming the most general \ninitial state of the system.\nb) Verify that a p-pulse (v1t = p) produces a complete spin ﬂip. Calculate both the \ntransformed state vector 0 c\u00031t29 and the state vector 0 c1t29.\nc) Assume that the interaction time is such that v1t = p>2. Find the effect on the system \nif the initial state is 0  +9.\nd) Discuss the differences between the original reference frame and the rotating reference \nframe in light of your results.\n 3.17 Consider an electron neutrino with an energy of 8 MeV. How far must this neutrino travel \nbefore it oscillates to a muon neutrino? Assume the neutrino mixing parameters given in the \ntext. How many complete oscillations (ne S nm S ne) will take place if this neutrino travels \nfrom the sun to the earth? Through the earth?\n 3.18 Many weak decay processes produce neutrinos with a spectrum of energies. Assume electron \nneutrinos are produced with a uniform distribution from 4 MeV to 8 MeV. By averaging the \nprobability over the energy spectrum, calculate and plot, as a function of the travel distance L, \nthe probability that electron neutrinos are measured at the detector. Compare the result with the \nprobability for monoenergetic neutrinos at 8 MeV. The integral required for the averaging does \nnot yield an elementary expression, so a computer is advisable. Assume the neutrino mixing \nparameters given in the text.\nRESOURCES\nActivities\nThis activity is available at\nwww.physics.oregonstate.edu/qmactivities\nSpins Lab 4: Students design experiments to study spin precession in a magnetic ﬁeld.\nFurther Reading\nPedagogical articles on neutrino oscillations:\nW. C. Haxton and B. R. Holstein, “Neutrino physics,” Am. J. Phys. 68, 15–32 (2000).\nW. C. Haxton and B. R. Holstein, “Neutrino physics: An update,” Am. J. Phys. 72, 18–24 (2004).\nE. Sassaroli, “Neutrino oscillations: A relativistic example of a two-level system,” Am. J. Phys. \n67, 869–875 (1999).","page_start":120,"page_end":120,"token_count":646,"section_type":"other","chapter_number":5,"chapter_title":"Quantized Energies: Particle in a Box","chunk_index":155}
{"chunk_id":"aa97b1d0360b5b74","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"W. C. Haxton and B. R. Holstein, “Neutrino physics: An update,” Am. J. Phys. 72, 18–24 (2004).\nE. Sassaroli, “Neutrino oscillations: A relativistic example of a two-level system,” Am. J. Phys. \n67, 869–875 (1999).\nC. Waltham, “Teaching neutrino oscillations,” Am. J. Phys. 72, 742–752 (2004).\nThe application of Rabi oscillations to atomic physics is the main focus of this book:\nL. Allen and J. H. Eberly, Optical Resonance and Two-Level Atoms, New York: Dover \nPublications, Inc., 1987.","page_start":120,"page_end":120,"token_count":166,"section_type":"other","chapter_number":5,"chapter_title":"Quantized Energies: Particle in a Box","chunk_index":156}
{"chunk_id":"4c443e8dcd1f6ee2","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":" \n97\nC H A P T E R \n4\nQuantum Spookiness\nAs we have seen in the previous chapters, many aspects of quantum mechanics run counter to our \nphysical intuition, which is formed from our experience living in the classical world. The probabilistic \nnature of quantum mechanics does not agree with the certainty of the classical world—we have no \ndoubt that the sun will rise tomorrow. Moreover, the disturbance of a quantum mechanical system \nthrough the action of measurement makes us part of the system, rather than an independent observer. \nThese issues and others make us wonder what is really going on in the quantum world. As quantum \nmechanics was being developed in the early twentieth century, many of the world’s greatest physicists \ndebated the “true meaning” of quantum mechanics. They often developed gedanken experiments or \nthought experiments to illustrate their ideas. Some of these gedanken experiments have now actually \nbeen performed and some are still being pursued.\nIn this chapter, we present a few of the gedanken and real experiments that demonstrate the \nspookiness of quantum mechanics. We present enough details to give a ﬂavor of the spookiness and \nprovide references for further readings on these topics at the end of the chapter.\n4.1 \u0002  EINSTEIN-PODOLSKY-ROSEN PARADOX\nAlbert Einstein was never comfortable with quantum mechanics. He is famously quoted as saying \n“Gott würfelt nicht” or “God does not play dice,” to express his displeasure with the probabilistic \nnature of quantum mechanics. But his opposition to quantum mechanics ran deeper than that. He felt \nthat properties of physical objects have an objective reality independent of their measurement, much \nas Erwin felt that his socks were black or white, or long or short, independent of his pulling them out \nof the drawer. In quantum mechanics, we cannot say that a particle whose spin is measured to be up \nhad that property before the measurement. It may well have been in a superposition state. Moreover, \nwe can only know one spin component of a particle, because measurement of one component disturbs \nour knowledge of the other components. Because of these apparent deﬁciencies, Einstein believed that \nquantum mechanics was an incomplete description of reality.\nIn 1935, Einstein, Boris Podolsky, and Nathan Rosen published a paper presenting a gedan-\nken experiment designed to expose the shortcomings of quantum mechanics. The EPR Paradox \n(Einstein-Podolsky-Rosen) tries to paint quantum mechanics into a corner and expose the “absurd” \nbehavior of the theory. The essence of the argument is that if you believe that measurements on two \nwidely separated particles cannot inﬂuence each other, then the quantum mechanics of an ingeniously \nprepared two-particle system leads you to conclude that the physical properties of each particle are \nreally there—they are elements of reality in the authors’ words.\n","page_start":121,"page_end":121,"token_count":613,"section_type":"other","chapter_number":5,"chapter_title":"Quantized Energies: Particle in a Box","chunk_index":157}
{"chunk_id":"075e68e21d974fa1","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"98 \nQuantum Spookiness\nThe experimental situation is depicted in Fig. 4.1 (this version of the EPR experiment is due to \nDavid Bohm and has been updated by N. David Mermin). An unstable particle with spin 0 decays into \ntwo spin-1/2 particles, which by conservation of angular momentum must have opposite spin compo-\nnents and by conservation of linear momentum must travel in opposite directions. For example, a neu-\ntral pi meson decays into an electron and a positron: p0 S e- + e+. Observers A and B are on opposite \nsides of the decaying particle and each has a Stern-Gerlach apparatus to measure the spin component \nof the particle headed in its direction. Whenever one observer measures spin up along a given direc-\ntion, then the other observer measures spin down along that same direction. The quantum state of this \ntwo-particle system is\n0\n c9 =\n1\n12 10  +91 0  -92 - 0  -91 0  +922 , \n(4.1)\nwhere the subscripts label the particles and the relative minus sign ensures that this is a spin-0 state \n(as we’ll discover in Chapter 11). The use of a product of kets 1e.g., 0  +91 0  -922 is required here to \ndescribe the two-particle system (Problem 4.1). The kets and operators for the two particles are inde-\npendent, so, for example, operators act only on their own kets\nS1z0  +91 0  -92 = 1S1z0  +912 0  -92 = + U\n2\n 0  +91 0  -92, \n(4.2)\nand inner products behave as\n118+ 0 2 8-  0210  +91 0  -922 = 118+\n 0  +912128-  0  -922 = 1. \n(4.3)\nAs shown in Fig. 4.1, observer A measures the spin component of particle 1 and observer B mea-\nsures the spin component of particle 2. The probability that observer A measures particle 1 to be spin \nup is 50% and the probability for spin down is 50%. The 50-50 split is the same for observer B. For a \nlarge ensemble of decays, each observer records a random sequence of spin up and spin down results, \nwith a 50>50 ratio. But, because of the correlation between the spin components of the two particles, \nif observer A measures spin up (i.e., S1z = +U>2), then we can predict with 100% certainty that the \nresult of observer B’s measurement will be spin down (S2z = -U>2). The result is that even though \neach observer records a random sequence of ups and downs, the two sets of results are perfectly anticor-\nrelated. The state 0","page_start":122,"page_end":122,"token_count":650,"section_type":"other","chapter_number":5,"chapter_title":"Quantized Energies: Particle in a Box","chunk_index":158}
{"chunk_id":"7a46c31daa81a98b","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"if observer A measures spin up (i.e., S1z = +U>2), then we can predict with 100% certainty that the \nresult of observer B’s measurement will be spin down (S2z = -U>2). The result is that even though \neach observer records a random sequence of ups and downs, the two sets of results are perfectly anticor-\nrelated. The state 0\n c9 in Eq. (4.1) that produces this strange mixture of random and correlated measure-\nment results is known as an entangled state. The spins of the two particles are entangled with each \nother and produce this perfect correlation between the measurements of observer A and observer B.\nImagine that the two observers are separated by a large distance, with observer B slightly farther \nfrom the decay source than observer A. Once observer A has made the measurement S1z = +U>2, we \nknow that the measurement by observer B in the next instant will be spin down 1S2 z = -U>22. We con-\nclude that the state 0\n c9 in Eq. (4.1) instantaneously collapses onto the state 0  +91 0  -92 , and the measure-\nment by observer A has somehow determined the measurement result of observer B. Einstein referred \nto this as “spooky action at a distance” (spukhafte Fernwirkungen). The result that observer B records is \nstill random, it is just that its randomness is perfectly anticorrelated with observer A’s random result. \nA\nB\nParticle 1 \nParticle 2 \nSpin 0\nSource \nS2z\nS1z\nFIGURE 4.1 Einstein-Podolsky-Rosen gedanken experiment.","page_start":122,"page_end":122,"token_count":368,"section_type":"other","chapter_number":5,"chapter_title":"Quantized Energies: Particle in a Box","chunk_index":159}
{"chunk_id":"239215493feb0563","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"4.1 Einstein-Podolsky-Rosen Paradox \n99\nHence, there is no problem with faster-than-light communication here because there is no information \ntransmitted between the two observers.\nThe EPR argument contends that because we can predict a measurement result with 100% cer-\ntainty 1e.g., S2z = -U>22, then that result must be a “real” property of the particle—it must be an ele-\nment of reality. Because the particles are widely separated, this element of reality must be independent \nof what observer A does, and hence, must have existed all along. The independence of the elements of \nreality of the two  particles is called Einstein’s locality principle, and is a fundamental assumption of \nthe EPR argument.\nThe correlation of spin measurements of the two observers is independent of the choice of mea-\nsurement direction, assuming the same direction for both observers. That is, if observer A measures \nthe x-component of spin and records S1x = +U>2, then we know with 100% certainty that observer B \nwill measure S2x = -U>2. Observer A is free to choose to measure S1x, S1y, or S1z, so EPR argue that \nS2x, S2y, and S2z must all be elements of reality for particle 2. However, quantum mechanics maintains \nthat we can know only one spin component at a time for a single particle. EPR conclude that quantum \nmechanics is an incomplete description of physical reality because it does not describe all the elements \nof reality of the particle.\nIf the EPR argument is correct, then the elements of reality, which are also called hidden vari-\nables or instruction sets, are really there, but for some reason we cannot know all of them at once. \nThus, one can imagine constructing a local hidden variable theory wherein there are different types of \nparticles with different instruction sets that determine the results of measurements. The theory is local \nbecause the instruction sets are local to each particle so that measurements by the two observers are \nindependent. The populations or probabilities of the different instruction sets can be properly adjusted \nin a local hidden variable theory to produce results consistent with quantum mechanics. Because quan-\ntum mechanics and a local hidden variable theory cannot be distinguished by experiment, the question \nof which is correct is then left to the realm of metaphysics. For many years, this was what many physi-\ncists believed. After all, it doesn’t seem unreasonable to believe that there are things we cannot know!\nHowever, in 1964, John Bell showed that the hidden variables that we cannot know cannot even \nbe there! Bell showed that there are speciﬁc measurements that can be made to distinguish between a \nlocal hidden variable theory and quantum mechanics. The results of these quantum mechanics experi-\nments are not compatible with any local hidden variable theory. Bell derived a very general relation, \nbut we present a speciﬁc one here for simplicity.\nBell’s argument relies on observers A and B making measurements along a set of different direc-","page_start":123,"page_end":123,"token_count":651,"section_type":"other","chapter_number":5,"chapter_title":"Quantized Energies: Particle in a Box","chunk_index":160}
{"chunk_id":"66a5a74d20eb3611","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"be there! Bell showed that there are speciﬁc measurements that can be made to distinguish between a \nlocal hidden variable theory and quantum mechanics. The results of these quantum mechanics experi-\nments are not compatible with any local hidden variable theory. Bell derived a very general relation, \nbut we present a speciﬁc one here for simplicity.\nBell’s argument relies on observers A and B making measurements along a set of different direc-\ntions. Consider three directions an, bn, cn in a plane as shown in Fig. 4.2, each 120° from any of the other \ntwo. Each observer makes measurements of the spin projection along one of these three directions, \nchosen randomly. Any single observer’s result can be only spin up or spin down along that direction, \nbut we record the results independent of the direction of the Stern-Gerlach analyzers, so we denote \none observer’s result simply as  + or  -, without noting the axis of measurement. The results of the pair \nParticle 1 \nParticle 2 \na∧\nb\n∧\nc∧\nA\nB\nSpin 0\nSource \na∧\nb\n∧\nc∧\nFIGURE 4.2 Measurement of spin components along three directions as proposed by Bell.","page_start":123,"page_end":123,"token_count":273,"section_type":"other","chapter_number":5,"chapter_title":"Quantized Energies: Particle in a Box","chunk_index":161}
{"chunk_id":"c695efc0989075a2","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"100 \nQuantum Spookiness\nof measurements from one correlated pair of particles (i.e., one decay from the source) are denoted \n+ -, for example, which means observer A recorded a + and observer B recorded a -. There are only \nfour possible system results: + +,  + -,  - +, or  - -. Even more simply, we classify the results as \neither the same, + + or  - -, or opposite, + - or  - +.\nA local hidden variable theory needs a set of instructions for each particle that speciﬁes ahead \nof time what the results of measurements along the three directions an, bn, cn will be. For example, the \ninstruction set 1an  +, bn  +, cn +2 means that a measurement along any one of the three directions will \nproduce a spin up result. For the entangled state of the system given by Eq. (4.1), measurements by the \ntwo observers along the same direction can yield only the results + - or  - +. To reproduce this aspect \nof the data, a local hidden variable theory would need the eight instruction sets shown in Table 4.1. For \nexample, the instruction set 1an  +, bn  -, cn +2 for particle 1 must be paired with the set 1an  -, bn  +, cn -2 for \nparticle 2 in order to produce the proper correlations of the entangled state. Beyond that requirement, \nwe allow the proponent of the local hidden variable theory freedom to adjust the populations Ni (or \nprobabilities) of the different instruction sets as needed to make sure that the hidden variable theory \nagrees with the quantum mechanical results.\nNow use the instruction sets (i.e., the local hidden variable theory) to calculate the prob-\nability that the results of the spin component measurements are the same 1Psame = P+ + + P- -2 \nand the probability that the results are opposite 1Popp = P+ - + P+ -2, considering all possible \norientations of the spin measurement devices. There are nine different combinations of measure-\nment directions for the pair of observers: anan, anbn, ancn, bnan, bnbn, bncn, cnan, cnbn, cncn. If we consider particles \nof type 1 (i.e., instruction set 1), then for each of these nine possibilities, the results are opposite \n(+ -). The results are never the same for particles of type 1. The same argument holds for type \n8 particles. For type 2 particles, the instruction sets 1an  +, bn  +, cn -2 and 1an  -, bn  -, cn +2 yield the\nnine possible results + -,  + -,  + +,  + -,  + -,  + +,  - -,  - -,  - + with four possibilities of \nrecording the same results and ﬁve possibilities for recording opposite results. Thus, we arrive at the \nfollowing probabilities for the different particle types:\nPopp = 1\nPsame = 0 r types 1 & 8 \nPopp = 5\n9","page_start":124,"page_end":124,"token_count":669,"section_type":"other","chapter_number":5,"chapter_title":"Quantized Energies: Particle in a Box","chunk_index":162}
{"chunk_id":"d1373322cf99817a","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"nine possible results + -,  + -,  + +,  + -,  + -,  + +,  - -,  - -,  - + with four possibilities of \nrecording the same results and ﬁve possibilities for recording opposite results. Thus, we arrive at the \nfollowing probabilities for the different particle types:\nPopp = 1\nPsame = 0 r types 1 & 8 \nPopp = 5\n9\nPsame = 4\n9\nt types 2 S 7 . \n(4.4)\nTable 4.1 Instruction Sets (Hidden Variables)\nPopulation\nParticle 1\nParticle 2\nN1\nN2\nN3\nN4\nN5\nN6\nN7\nN8\n1an\n  +, bn\n +, cn\n +2\n1an\n  +, bn\n +, cn\n -2\n1an\n  +, bn\n -, cn\n +2\n1an\n  +, bn\n -, cn\n -2\n1an\n  -, bn\n +, cn\n +2\n1an\n  -, bn\n +, cn\n -2\n1an\n  -, bn\n -, cn\n +2\n1an\n  -, bn\n -, cn\n -2\n1an\n  -, bn\n -, cn\n -2\n1an\n  -, bn\n -, cn\n +2\n1an\n  -, bn\n +, cn\n -2\n1an\n  -, bn\n +, cn\n +2\n1an\n  +, bn\n -, cn\n -2\n1an\n  +, bn\n -, cn\n +2\n1an\n  +, bn\n +, cn\n -2\n1an\n  +, bn\n +, cn\n +2","page_start":124,"page_end":124,"token_count":383,"section_type":"other","chapter_number":5,"chapter_title":"Quantized Energies: Particle in a Box","chunk_index":163}
{"chunk_id":"c6e09f1b50a447e0","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"4.1 Einstein-Podolsky-Rosen Paradox \n101\nTo ﬁnd the probabilities of recording the same or opposite results in all the measurements, we \nperform a weighted average over all the possible particle types. The weight of any particular particle \ntype, for example type 1, is simply N1  \u0006aNi (recall we will adjust the actual values later as needed). \nThus, the averaged probabilities are:\n Psame =\n1\na\ni\nNi\n 4\n9\n 1N2 + N3 + N4 + N5 + N6 + N72 … 4\n9\n Popp =\n1\na\ni\nNi\n aN1 + N8 + 5\n9\n 1N2 + N3 + N4 + N5 + N6 + N72b Ú 5\n9\n ,  \n(4.5)\nwhere the inequalities follow because the sum of all the weights for the different particle types must \nbe unity. In summary, we can adjust the populations all we want, but that will always produce prob-\nabilities of the same or opposite measurements that are bound by the above inequalities. That is what \nis meant by a Bell inequality.\nWhat does quantum mechanics predict for these probabilities? For this system of two spin-1/2 \nparticles, we can calculate the probabilities using the concepts from the previous chapters. Assume \nthat observer A records a “+” along some direction (of the three). Deﬁne that direction as the z-axis \n(no law against that). Observer B measures along a direction nn at some angle u with respect to the \nz-axis. The probability that observer A records a “+” along the z-axis and observer B records a “+” \nalong the nn direction is\nP+ + = 0118+ 0   n   \n2n 8+ 02 0\n c9 0\n2 . \n(4.6)\nSubstituting the entangled state 0\n c9 and the direction eigenstate 0  +9nn  gives\nP+ + = 2 18+ 0 ¢cos u\n2  28+ 0 + e-if sin u\n2  28- 0 ≤ 1\n12 10  +91 0  -92 - 0  -91 0  +922 2\n2\n= 2 1\n12 ¢cos u\n2  28+ 0 + e-if sin u\n2  28- 0 ≤10  -922 2\n2\n= 1\n2\n sin2  u\n2\n . \n(4.7)\nThe same result is obtained for the probability that observer A records a “-” along the z-axis and \nobserver B records a “-” along the nn direction. Hence, the result for the same measurements is\nPsame = P+ + + P- - = sin2 u\n2\n . \n(4.8)\nThe probability that observer B records a “-” along the direction nn, when A records a “+” is\nP+ - = 0118+ 0     n ","page_start":125,"page_end":125,"token_count":667,"section_type":"other","chapter_number":5,"chapter_title":"Quantized Energies: Particle in a Box","chunk_index":164}
{"chunk_id":"5f6f57316a8a7dbf","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"observer B records a “-” along the nn direction. Hence, the result for the same measurements is\nPsame = P+ + + P- - = sin2 u\n2\n . \n(4.8)\nThe probability that observer B records a “-” along the direction nn, when A records a “+” is\nP+ - = 0118+ 0     n \n2n 8- 02 0\n c9 0\n2 \n= 2 18+ 0 ¢sin u\n2  28+ 0 - e-if cos u\n2  28- 0 ≤ 1\n12 10  +91 0  -92 - 0  -91 0  +922 2\n2\n= 2 1\n12 ¢sin u\n2  28+ 0 - e-if cos u\n2  28- 0 ≤ 1 0  -922 2\n2\n= 1\n2\n  cos2  u\n2\n , \n(4.9)","page_start":125,"page_end":125,"token_count":230,"section_type":"other","chapter_number":5,"chapter_title":"Quantized Energies: Particle in a Box","chunk_index":165}
{"chunk_id":"736c8d9a842f74e2","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"102 \nQuantum Spookiness\nand the probability for opposite results is\nPopp = P+  - + P-  + = cos2 u\n2\n . \n(4.10)\nThe angle u between the measurement directions of observers A and B is 0° in 1>3 of the mea-\nsurements and 120° in 2>3 of the measurements, so the average probabilities are\nPsame = 1\n3 ~ sin2 0\b\n2 + 2\n3 ~ sin2 120\b\n2\n= 1\n3 ~ 0 + 2\n3 ~ 3\n4 = 1\n2  \nPopp = 1\n3 ~ cos2 0\b\n2 + 2\n3 ~ cos2 120\b\n2\n= 1\n3 ~ 1 + 2\n3 ~ 1\n4 = 1\n2\n . \n(4.11)\nThese predictions of quantum mechanics are inconsistent with the range of possibilities that we \nderived for local hidden variable theories in Eq. (4.5). Because these probabilities can be measured, \nwe can do experiments to test whether local hidden variable theories are possible. The results of exper-\niments performed on systems that produce entangled quantum states have consistently agreed with \nquantum mechanics and hence, exclude the possibility of local hidden variable theories. We are forced \nto conclude that quantum mechanics is an inherently nonlocal theory.\nThe EPR paradox also raises issues regarding the collapse of the quantum state and how a mea-\nsurement by A can instantaneously alter the quantum state at B. However, there is no information \ntransmitted instantaneously and so there is no violation of relativity. What observer B measures is not \naffected by any measurements that A makes. The two observers notice only when they get together \nand compare results that some of the measurements (along the same axes) are correlated.\nThe entangled states of the EPR paradox have truly nonclassical behavior and so appear spooky \nto our classically trained minds. But when you are given lemons, make lemonade. Modern quantum \nresearchers are now using the spookiness of the entangled states to enable new technologies that take \nadvantage of the way that quantum mechanics stores information in these correlated systems. Quan-\ntum computers, quantum communication, and quantum information processing in general are active \nareas of research and promise to enable a new revolution in information technology.\n 4.2 \u0002 SCHRÖDINGER CAT PARADOX\nThe Schrödinger cat paradox is a gedanken experiment designed by Schrödinger to illustrate some of \nthe problems of quantum measurement, particularly in the extension of quantum mechanics to classi-\ncal systems. The apparatus of Schrödinger’s gedanken experiment consists of a radioactive nucleus, a \nGeiger counter, a hammer, a bottle of cyanide gas, a cat, and a box, as shown in Fig. 4.3. The nucleus \nhas a 50% probability of decaying in one hour. The components are assembled such that when the ","page_start":126,"page_end":126,"token_count":649,"section_type":"other","chapter_number":5,"chapter_title":"Quantized Energies: Particle in a Box","chunk_index":166}
{"chunk_id":"1257d0c9c3294c18","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"the problems of quantum measurement, particularly in the extension of quantum mechanics to classi-\ncal systems. The apparatus of Schrödinger’s gedanken experiment consists of a radioactive nucleus, a \nGeiger counter, a hammer, a bottle of cyanide gas, a cat, and a box, as shown in Fig. 4.3. The nucleus \nhas a 50% probability of decaying in one hour. The components are assembled such that when the \nnucleus decays, it triggers the Geiger counter, which causes the hammer to break the bottle and release \nthe poisonous gas, killing the cat. Thus, after one hour there is a 50% probability that the cat is dead.\nAfter the one hour, the nucleus is in an equal superposition of undecayed and decayed states:\n0 cnucleus9 =\n1\n12 10 cundecayed9 + 0\n cdecayed92. \n(4.12)\nThe apparatus is designed such that there is a one-to-one correspondence between the undecayed \nnuclear state and the live-cat state and a one-to-one correspondence between the decayed nuclear state \nand the dead-cat state. Though the cat is macroscopic, it is made up of microscopic particles and so \nshould be describable by a quantum state, albeit a complicated one. Thus, we expect that the quantum \nstate of the cat after one hour is\n0 ccat9 =\n1\n12 10 calive9 + 0 cdead92. \n(4.13)","page_start":126,"page_end":126,"token_count":319,"section_type":"other","chapter_number":5,"chapter_title":"Quantized Energies: Particle in a Box","chunk_index":167}
{"chunk_id":"cfb86e4b1c740768","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"4.2 Schrödinger Cat Paradox \n103\nBoth quantum calculations and classical reasoning would predict 50>50 probabilities of observ-\ning an alive or a dead cat when we open the box. However, quantum mechanics would lead us to \nbelieve that the cat was neither dead nor alive before we opened the box, but rather was in a super-\nposition of states, and the quantum state collapses to the alive state 0 calive9 or dead state 0 cdead9 only \nwhen we open the box and make the measurement by observing the cat. But our classical experiences \nclearly run counter to this. We would say that the cat really was dead or alive, we just did not know \nit yet. (Imagine that the cat is wearing a cyanide sensitive watch—the time will tell us when the cat \nwas killed, if it is dead!)\nWhy are we so troubled by a cat in a superposition state? After all, we have just ﬁnished three \nchapters of electrons in superposition states! What is so inherently different about cats and electrons? \nExperiment 4 that we studied in Chapters 1 and 2 provides a clue. The superposition state in that \nexperiment exhibits a clear interference effect that relies on the coherent phase relationship between \nthe two parts of the superposition state vector for the spin-1/2 particle. No one has ever observed such \nan interference effect with cats, so our gut feeling that cats and electrons are different appears justiﬁed.\nThe main issues raised by the Schrödinger cat gedanken experiment are (1) Can we describe mac-\nroscopic states quantum mechanically? and (2) What causes the collapse of the wave function?\nThe Copenhagen interpretation of quantum mechanics championed by Bohr and Heisenberg \nmaintains that there is a boundary between the classical and quantum worlds. We describe micro-\nscopic systems (the nucleus) with quantum states and macroscopic systems (the cat, or even the Gei-\nger counter) with classical rules. The measurement apparatus causes the quantum state to collapse and \nto produce the single classical or meter result. The actual mechanism for the collapse of the wave func-\ntion is not speciﬁed in the Copenhagen interpretation, and where to draw the line between the classical \nand the quantum world is not clear. Others have argued that the human consciousness is responsible \nfor collapsing the wave function, while some have argued that there is no collapse, just bifurcation into \nalternate, independent universes. Many of these different points of view are untestable experimentally \nand thus raise more metaphysical than physical questions.\nThese debates about the interpretation of quantum mechanics arise when we use words, which \nare based on our classical experiences, to describe the quantum world. The mathematics of quantum \nNucleus\nCyanide\nGeiger Counter\nCat\nFIGURE 4.3 Schrödinger cat gedanken experiment.\n","page_start":127,"page_end":127,"token_count":607,"section_type":"other","chapter_number":5,"chapter_title":"Quantized Energies: Particle in a Box","chunk_index":168}
{"chunk_id":"658064e88ea370c3","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"104 \nQuantum Spookiness\nmechanics is clear and allows us to calculate precisely. No one is disagreeing about the probability \nthat the cat will live or die. The disagreement is all about “what it really means!” To steer us toward \nthe clear mathematics, Richard Feynman admonished us to “Shut up and calculate!” Two physicists \nwho disagree on the words they use to describe a quantum mechanical experiment generally agree on \nthe mathematical description of the results.\nRecent advances in experimental techniques have allowed experiments to probe the boundary \nbetween the classical and quantum worlds and address the quantum measurement issues raised by \nthe Schrödinger cat paradox. The coupling between the microscopic nucleus and the macroscopic \ncat is representative of a quantum measurement whereby a classical meter (the cat) provides a clear \nand unambiguous measurement of the state of the quantum system (the nucleus). In this case, the two \npossible states of the nucleus (undecayed or decayed) are measured by the two possible positions on \nthe meter (cat alive or cat dead). The quantum mechanical description of this complete system is the \nentangled state\n0 csystem9 =\n1\n12 10 cundecayed9 0 calive9 + 0 cdecayed9 0 cdead92. \n(4.14)\nThe main issue to be addressed by experiment is whether Eq. (4.14) is the proper quantum mechanical \ndescription of the system. That is, is the system in a coherent quantum mechanical superposition, as \ndescribed by Eq. (4.14), or is the system in a 50>50 statistical mixed state of the two possibilities? As \ndiscussed above, we can distinguish these two cases by looking for interference between the two states \nof the system.\nTo build a Schrödinger cat experiment, researchers use a two-state atom as the quantum system \nand an electromagnetic ﬁeld in a cavity as the classical meter (or cat). The atom can either be in the \nground 0\n g9 or excited 0\n e9 state. The cavity is engineered to be in a coherent state 0\n a9 described \nby the complex number a, whose magnitude is equal to the square root of the average number of \nphotons in the cavity. For large a, the coherent state is equivalent to a classical electromagnetic \nﬁeld, but for small a, the ﬁeld appears more quantum mechanical. The beauty of this experiment is \nthat the experimenters can tune the value of a between these limits to study the region between the \nmicroscopic and macroscopic descriptions of the meter (cat). In this intermediate range, the meter is \na mesoscopic system.\nAtoms travel through the cavity and disturb the electromagnetic ﬁeld in the cavity. Each atom is \nmodeled as having an index of refraction that alters the phase of the electromagnetic ﬁeld. The sys-\ntem is engineered such that the ground and excited atomic states produce opposite phase shifts {f. \nBefore the atom enters the cavity, it undergoes a p-pulse that places it in an equal superposition of \nground and excited states\n0 catom9 =\n1\n12 10","page_start":128,"page_end":128,"token_count":661,"section_type":"other","chapter_number":5,"chapter_title":"Quantized Energies: Particle in a Box","chunk_index":169}
{"chunk_id":"711c1dc348c255b4","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"Atoms travel through the cavity and disturb the electromagnetic ﬁeld in the cavity. Each atom is \nmodeled as having an index of refraction that alters the phase of the electromagnetic ﬁeld. The sys-\ntem is engineered such that the ground and excited atomic states produce opposite phase shifts {f. \nBefore the atom enters the cavity, it undergoes a p-pulse that places it in an equal superposition of \nground and excited states\n0 catom9 =\n1\n12 10\n e9 + 0\n g92, \n(4.15)\nas shown in Fig. 4.4. Each component of this superposition produces a different phase shift in the \ncavity ﬁeld such that after the atom passes through the cavity, the atom-cavity system is in the entan-\ngled state\n0 catom +cavity9 =\n1\n12 10\n e9 0 ae if9 + 0\n g9 0 ae -if92 \n(4.16)\nthat mirrors the Schrödinger cat state in Eq. (4.14). The state of the cavity ﬁeld is probed by sending \na second atom into the cavity and looking for interference effects in the atom that are produced by the \ntwo components of the ﬁeld. In this experiment, the two ﬁeld states are classically distinguishable, \nakin to the alive and dead cat states. For small values of the phase difference 2f between the two ﬁeld \ncomponents, the interference effect is evident. However, for large values of the phase difference 2f ","page_start":128,"page_end":128,"token_count":334,"section_type":"other","chapter_number":5,"chapter_title":"Quantized Energies: Particle in a Box","chunk_index":170}
{"chunk_id":"54a65eca08df9d73","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"Problems \n105\nbetween the two ﬁeld components, the interference effect vanishes, indicating that the superposition \nstate in Eq. (4.16) has lost the ﬁxed phase relationship between the two parts of the entangled state and \ncan no longer produce interference effects. The system has undergone decoherence due to its interac-\ntion with the random aspects of the environment. The decoherence effect also increases as the number \nof photons in the cavity ﬁeld increases, which makes the cavity ﬁeld more like a classical state. Hence, \nthe experiment demonstrates that the quantum coherence of a superposition state is rapidly lost when \nthe state becomes complex enough to be considered classical. Further details on this recent experiment \nare available in the references below (Brune et al.).\nPROBLEMS\n 4.1 Show that the quantum state vector of a two-particle system must be a product 0\n c910\n f92 of \ntwo single-particle state vectors rather than a sum 0\n c91 + 0\n f92. Hint: consider the action of a \nsingle-particle state operator on the two-particle state vector.\n 4.2 Consider the two-particle entangled state\n0 c9 =\n1\n12 10  +91 0  -92 - 0  -91 0  +922.\na) Show that 0\n c9 is not an eigenstate of the spin component operator S1z for particle 1.\nb) Show that 0\n c9 is properly normalized.\n 4.3 Consider the two-particle entangled state\n0 c9 =\n1\n12 10  +91 0  -92 - 0  -91 0  +922.\n \n Show that the probability of observer A measuring particle 1 to have spin up is 50% for any \norientation of the Stern-Gerlach detector used by observer A. To ﬁnd this probability, sum over \nall the joint probabilities for observer A to measure spin up and observer B to measure anything.\n 4.4 Show that the state\n0 ca9 =\n1\n12 10  +91 0  -92 - 0  -91 0  +922\n \n is equivalent to the state\n0 cb9 =\n1\n12 10  +91x 0  -92  x - 0  -91x 0  +92  x2.\n \n That is, the two observers record perfect anticorrelations independent of the orientation of their \ndetectors, as long as both are aligned along the same direction.\nAtom Source\nΠ\u00062 Pulse\nCavity\n1\n2 \u0002g\u0003+\u0002e\u0003\n\u0002g\u0003\nFIGURE 4.4 Schrödinger cat experiment with atoms in a cavity.\n","page_start":129,"page_end":129,"token_count":590,"section_type":"other","chapter_number":5,"chapter_title":"Quantized Energies: Particle in a Box","chunk_index":171}
{"chunk_id":"a4f64e4676dc38ae","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"106 \nQuantum Spookiness\n 4.5 Calculate the quantum mechanical probabilities in Eqs. (4.7) and (4.9) without assuming that \nobserver A’s Stern-Gerlach device is aligned with the z-axis. Let the direction of observer A’s \nmeasurements be described by the angle u1 and the direction of observer B’s measurements be \ndescribed by the angle u2. Show that the averaged results in Eq. (4.11) are still obtained.\nRESOURCES\nFurther Reading\nThe EPR Paradox and Bell’s theorem are discussed in these articles:\nF. Laloe, “Do we really understand quantum mechanics? Strange correlations, paradoxes, \nand  theorems,” Am. J. Phys. 69, 655–701 (2001); “Erratum: Do we really understand \nquantum mechanics? Strange correlations, paradoxes, and theorems,” Am. J. Phys. 70, \n556 (2002).\nN. D. Mermin, “Bringing home the atomic world: Quantum mysteries for anybody,” Am. J. \nPhys. 49, 940–943 (1981).\nN. D. Mermin, “Is the moon there when nobody looks? Reality and the quantum theory,” \nPhys. Today 38(5), 38–47 (1985).\nN. D. Mermin, “Quantum mysteries revisited,” Am. J. Phys. 58, 731–734 (1990).\nN. D. Mermin, “Not quite so simply no hidden variables,” Am. J. Phys. 60, 25–27 (1992).\nN. D. Mermin, “Quantum mysteries reﬁned,” Am. J. Phys. 62, 880–887 (1994).\nN. D. Mermin, “Nonlocal character of quantum theory?” Am. J. Phys. 66, 920–924 (1998).\nN. D. Mermin, “What is quantum mechanics trying to tell us?” Am. J. Phys. 66, 753–767 \n(1998).\nSchrödinger’s cat is discussed in these references:\nT. J. Axon, “Introducing Schrodinger’s cat in the laboratory,” Am. J. Phys. 57, 317–321 (1989).\nM. Brune, E. Hagley, J. Dreyer, X. MaÓtre, A. Maali, C. Wunderlich, J. M. Raimond, and  \nS. Haroche, “Observing the progressive decoherence of the ‘meter’ in a quantum \nmeasurement,” Phys. Rev. Lett. 77, 4887–4890 (1996).\nB. S. DeWitt, “Quantum mechanics and reality,” Phys. Today 23(9), 30–35 (1970).\nA. J. Legett, “Schrodinger’s cat and her laboratory cousins,” Contemp. Phys. 25, 583–598 \n(1984). ","page_start":130,"page_end":130,"token_count":651,"section_type":"other","chapter_number":5,"chapter_title":"Quantized Energies: Particle in a Box","chunk_index":172}
{"chunk_id":"347a23ba65a3cc9c","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"measurement,” Phys. Rev. Lett. 77, 4887–4890 (1996).\nB. S. DeWitt, “Quantum mechanics and reality,” Phys. Today 23(9), 30–35 (1970).\nA. J. Legett, “Schrodinger’s cat and her laboratory cousins,” Contemp. Phys. 25, 583–598 \n(1984). \nJ. G. Loeser, “Three perspectives on Schrodinger’s cat,” Am. J. Phys. 52, 1089–1093 (1984).\nW. H. Zurek, “Decoherence and the transition from quantum to classical,” Phys. Today \n44(10), 36–44 (1991).\nRichard Feynman’s directive to “Shut up and calculate!” is discussed in: \nN. D. Mermin, “What’s wrong with this pillow?” Phys. Today 42(4), 9–11 (1989).\nN. D. Mermin, “Could Feynman have said this?” Phys. Today 57(5), 10–11 (2004).","page_start":130,"page_end":130,"token_count":244,"section_type":"other","chapter_number":5,"chapter_title":"Quantized Energies: Particle in a Box","chunk_index":173}
{"chunk_id":"585ca114410e4a85","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":" \n107\nC H A P T E R \n5\nQuantized Energies:  \nParticle in a Box\nIn the ﬁrst part of this book we used the spin system to illustrate the basic concepts and tools of quan-\ntum mechanics. With a ﬁrm foundation in how quantum mechanics works, we are ready to address the \ncentral question that quantum mechanics was designed to answer: How do we explain the structure of \nthe microscopic world? All around us are nuclei, atoms, molecules, and solids with unique properties \nthat cannot be explained with classical physics but require quantum mechanics. For example, quantum \nmechanics can tell us why sodium lamps are yellow, why laser diodes have a unique color, and why \nuranium is radioactive.\nThe key to understanding the structure of microscopic systems lies in the energy states that the \nsystems are allowed to have. Each microscopic system has a unique set of energy levels that gives that \nsystem a “ﬁngerprint” that sets it apart from other systems. With the tools of quantum mechanics, we \ncan build a theoretical model for the system, predict that ﬁngerprint, and compare it to the experimen-\ntal measurement. Our goal in this chapter and the ones that follow is to learn how to predict this energy \nﬁngerprint. In this chapter we will study a particularly simple model system that exhibits most of the \nimportant features that are shared by all microscopic systems.\n5.1 \u0002 SPECTROSCOPY\nThe energy ﬁngerprint of a system not only identiﬁes that system uniquely, but the allowed energies \ndetermine the time evolution of the system through the Schrödinger equation, as we learned in Chapter 3. \nOne of the primary experimental techniques for measuring the energy ﬁngerprint of a system is spectros-\ncopy. We saw a hint of this in the magnetic resonance example of Section 3.4: absorption and emission of \nphotons causes transitions between quantized energy levels of the system only when the photon energy \nmatches the spacing between the energy eigenstates. Historically, the spectrum of hydrogen was a key \ningredient in the development of quantum mechanics, and spectroscopy continues to play an important \nrole in characterizing new quantum systems and in verifying the rules of quantum mechanics.\nIn the magnetic resonance example of Section 3.4, the two quantized energy levels arose from the \ntwo possible spin components (up or down) and their different interactions with an applied magnetic \nﬁeld. The more common situation that gives rise to quantized energy levels is where two or more \nparticles interact in a way that limits their spatial motion and binds them together into a compos-\nite system. Bound systems such as nuclei, atoms, molecules, and solids are everyday examples that \nare characterized by distinct spectral lines associated with quantized energy states, (i.e., eigenstates \nof the Hamiltonian with discrete energy eigenvalues). For example, the hydrogen atom energy levels \n","page_start":131,"page_end":131,"token_count":614,"section_type":"other","chapter_number":5,"chapter_title":"Quantized Energies: Particle in a Box","chunk_index":174}
{"chunk_id":"58d720a124ba870f","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"108 \nQuantized Energies: Particle in a Box\nand the corresponding optical spectrum are shown in Fig. 5.1. The spectral lines appear when elec-\ntrons make transitions between energy levels. Downward transitions emit photons and give rise to an \nemission spectrum, while upward transitions absorb photons and yield an absorption spectrum. For \nevery pair of energy eigenvalues Ei and Ej  , there is a possible spectral line with photon energy Ei - Ej\n , \nand photon frequency fij and wavelength \nij given by\n \nfij =\nvij\nU =\nEi - Ej\nh\n \n \nlij = c\nfij\n=\nhc\nEi - Ej\n , \n(5.1)\nassuming that Ei 7 Ej\n . The set of spectral lines of atomic hydrogen that share a common lower level \nforms a series that is named after its discoverer. The ﬁrst three series in hydrogen are shown in Fig. 5.1 \nand listed in Table 5.1. The lowest energy state (n \u0003 1 for hydrogen) is called the ground state, and \nthe levels above that are called excited states. Though the word spectrum often refers to the observed \noptical lines, the set of quantized energy states is also commonly referred to as the energy spectrum \nof the system.\n1\n2\n3\n4\n5\nn\nLyman\nBalmer\nPaschen\n0\n\u00051\n\u00052\n\u00053\n\u00054\n\u00055\n\u00056\n\u00057\n\u00058\n\u00059\n\u000510\n\u000511\n\u000512\n\u000513\n\u000514\nE\nf\nΛ\n\b\nEnergy (eV)\nFIGURE 5.1 Hydrogen energy levels and the corresponding optical spectrum as a function \nof energy,  frequency, and wavelength (the wavelength scale is not a linear scale).\n","page_start":132,"page_end":132,"token_count":392,"section_type":"other","chapter_number":5,"chapter_title":"Quantized Energies: Particle in a Box","chunk_index":175}
{"chunk_id":"9d44005f589e51c3","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"5.1 Spectroscopy \n109\nA spectroscopy experiment can be considered to be a measurement of the energy of a quantum \nstate. A spectroscopic energy measurement is depicted in Fig. 5.2(a) in a simpliﬁed schematic that is \nanalogous to the Stern-Gerlach spin measurement we discussed earlier. A system is prepared in an \n initial state 0 c9, and we measure the probability that the state is measured to have a particular energy \nEi. If we write the energy eigenstates as 0\n Ei9, then the probability of a particular energy measurement is\n \nPEi = 08Ei0 c90\n2. \n(5.2)\nAs we did in the spins problem, we represent the collection of measurements on an ensemble of iden-\ntical states as a histogram, as shown in Fig. 5.2(b). In a real spectroscopy experiment, the measured \nenergies are really energy differences between levels, so it can be a bit of a puzzle to decode the energy \nlevels from the observed spectrum. We assume that this decoding process can be done and we assume \nthat the histogram in Fig. 5.2(b) faithfully represents the energy levels of the system. The energy levels \nEi and the eigenstates 0\n Ei9 are solutions to the energy eigenvalue equation\n \nHn  0 Ei9 = Ei0\n Ei9, \n(5.3)\nso the spectroscopic measurement is how the theoretical Hamiltonian is compared with experiment. \nOur task in this chapter is to learn how to predict the allowed energy eigenstates of a particular system \ngiven the Hamiltonian of the system.\n)\nb\n(\n)\na\n(\nPE1\nE1\n2\nPEi\nPE2\nPE3\nPE4\nPE5\nE5\n2\nE\nH\nE1\nE2\nE3\nE4\nE5\nE1\n2\nE4\n2\nE5\n2\nE1 E2\nE3\nE4\nE5\nE3\n2\nE2\n2\nE4\n2\nE2\n2\nE3\n2\nFIGURE 5.2 (a) Energy measurement and (b) histogram of results.\nTable 5.1 Hydrogen Transition Wavelengths\nFinal state\nInitial state\nSeries\n2\n3\n4\n5\n1\n122 nm\n103 nm\n97 nm\n95 nm\nLyman\n2\n656 nm\n486 nm\n434 nm\nBalmer\n3\n1875 nm\n1282 nm\nPaschen\n","page_start":133,"page_end":133,"token_count":554,"section_type":"other","chapter_number":5,"chapter_title":"Quantized Energies: Particle in a Box","chunk_index":176}
{"chunk_id":"e806ae70fe64ddb0","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"110 \nQuantized Energies: Particle in a Box\n5.2 \u0002 ENERGY EIGENVALUE EQUATION\nIn classical mechanics, we often solve problems by using Newton’s second law F = ma to predict the \nposition r1t2 of a particle subject to some known forces. Another common method is the energy method, \nwhereby we use conservation of energy and the relation E = T + V between the total energy (E ) \nand the kinetic (T ) and potential (V ) energies to predict the motion. Of course, the two methods are \nrelated because the force is related to the potential energy by\n \nFx = -  dV\ndx  \n(5.4)\nin one dimension. Hence the potential energy function V(x) is what determines the classical motion of \na particle.\nThe potential energy is also the key element in quantum mechanics, because of the important role \nit plays in the Hamiltonian of the system in question. The Hamiltonian determines the energy states \nthrough the energy eigenvalue equation\n \nHn 0\n Ei9 = Ei0\n Ei9. \n(5.5)\nNote that many other textbooks refer to Eq. (5.5) as the time-independent Schrödinger equation \nbecause it can be derived from the Schrödinger equation by separating the time and space parts; how-\never, we refer to it always as the energy eigenvalue equation. The prescription for ﬁnding a quantum \nmechanical Hamiltonian operator is to ﬁnd the classical form of the energy and replace the physical \nobservables with their quantum mechanical operators. For a moving particle, the classical mechanical \nenergy is the sum of the kinetic energy and the potential energy, which in one dimension is\n \nE =\np2\nx\n2m + V1x2. \n(5.6)\nWe use the position x and momentum p as the primary physical observables in quantum mechanics, \nfollowing the Hamiltonian approach to classical mechanics. Hence the quantum mechanical Hamilto-\nnian operator for a particle moving in one dimension is\n \nHn =\npn 2\nx\n2m + V1xn2. \n(5.7)\nWe use carets or hats on operators on occasion to distinguish them from the same symbol used as a \nvariable. If the distinction is clear from the context, then that notation may be dropped.\nSo now what? What are these new operators xn and pn for position and momentum? And how do \nwe use them to solve the energy eigenvalue equation? In the spins chapters, we learned much of the \nmachinery of quantum mechanics and would rightly expect to be able to use it in this new problem \non particle motion. However, position and momentum are different enough from spin that we need to \nredevelop some of the mathematical machinery we have already learned.\nWhen we discussed spin quantum states, we either used abstract kets, such as 0  +9 or 0  -9x, or we \nused column vectors to represent the abstract kets in a particular basis of eigenstates. For example, we \noften used the eigenstates of the Sz operator as the preferred basis, in which case the abstract kets 0  +9 \nand 0  -9x are expressed as\n \n0  +9 \u0003 a1\n0b \n(5.8)\n","page_start":134,"page_end":134,"token_count":699,"section_type":"other","chapter_number":5,"chapter_title":"Quantized Energies: Particle in a Box","chunk_index":177}
{"chunk_id":"fa80611768d4cd22","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"5.2 Energy Eigenvalue Equation \n111\nand\n \n0  -9x \u0003\n1\n12\n a 1\n-1b. \n(5.9)\nIn fact, there are very few quantum mechanical problems that can be solved using abstract kets. It is \ngenerally necessary to use a representation of the kets that is convenient for solving the problem. In \nthe problems that we wish to address now, it is most convenient to represent abstract quantum states as \nspatial functions, so we need to explain what that means.\nThe spatial functions we use to represent quantum states are called wave functions and are gener-\nally written using the Greek letter c as\n \nc 1x2. \n(5.10)\nThe wave function is a representation of the abstract quantum state, so we can use our representation \nnotation to write\n \n0\n c9 \u0003 c 1x2. \n(5.11)\nWe call this representation the position representation, which means that we are using the position \neigenstates as the preferred basis (more on these eigenstates later). For clarity, we will use the Greek \nletter c when referring to generic quantum states and other Greek letters to denote speciﬁc eigenstates. \nFor example, in the case of the energy eigenstates, we write the wave functions representing them as\n \n0\n Ei9 \u0003 wEi1x2 \n(5.12)\nto distinguish them as speciﬁc eigenstates.\nUsing this new wave function notation, the energy eigenvalue equation Eq. (5.5) becomes\n \nHnwEi1x2 = Ei\n wEi1x2. \n(5.13)\nTo solve this equation, we must know how to represent the operators in the Hamiltonian of Eq. (5.7) \nusing the position representation. It turns out that in the position representation, the action of the posi-\ntion operator xn is represented by multiplication by the position variable x, while the action of the \nmomentum operator pn is represented by application of a derivative with respect to position (see an \nadvanced text for justiﬁcation or take these as postulates). Using our representation notation, these two \nstatements are\n \n xn \u0003 x\n \n \n pn \u0003 -iU d\ndx  . \n \n(5.14)\nThe momentum operator has a factor of -iU to get the dimensions correct and to ensure that the mea-\nsurable results are real (not imaginary).\nWith these representations of the position and momentum operators, we now begin to solve the \nenergy eigenvalue equation. Inserting Eq. (5.14) into the energy eigenvalue equation gives\n \n HnwEi1x2 = Ei\n wEi1x2  \n \n a pn 2\n2m + V 1xn2\n b wEi1x2 = Ei\n wEi1x2  \n(5.15)\n \n a 1\n2m a-iU d\ndxb\n2\n+ V 1x2\n b wEi1x2 = Ei\n wEi1x2.\n","page_start":135,"page_end":135,"token_count":656,"section_type":"other","chapter_number":5,"chapter_title":"Quantized Energies: Particle in a Box","chunk_index":178}
{"chunk_id":"9cad12fca86c53d2","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"112 \nQuantized Energies: Particle in a Box\nThe result is that the energy eigenvalue equation becomes a differential equation\n \na-  U2\n2m\n d 2\ndx2 + V1x2\n b wE1x2 = EwE1x2  . \n(5.16)\nThis differential equation is a big change from the matrix eigenvalue equations we encountered in the \nspin problems. This result is a common occurrence when using the wave function approach: operator \nequations turn into differential equations. Hence, when we use the wave function approach to ﬁnd \nthe allowed energy eigenstates of a system, we typically solve differential equations. We will solve \nthis differential equation for several different potential energy functions V1x2 in the remainder of this \nbook, but ﬁrst we pause to examine the wave function idea more carefully.\n5.3 \u0002 THE WAVE FUNCTION\nTo better understand the new concept of a wave function c1x2, let’s see how it relates to the quantum \nstate vector 0\n c9 we used in spins. In the spin case, we found that a useful way to represent a state vec-\ntor was as a column vector of numbers, with each number being the probability amplitude for the state \n0\n c9 to be measured in a particular spin eigenstate. For example, we could write the state 0\n c9 using the \nSz representation as\n \n0\n c9 \u0003 ¢8+ 0\n c9\n8- 0\n c9≤ d Sz = +U>2\n d Sz = -U>2. \n(5.17)\nThe numbers 8{0\n c9 in the column vector are the projections of the state vector 0\n c9 onto the Sz \neigenstates 0{9, corresponding to the two possible eigenvalues. If we measure the spin projection, as \ndepicted in Fig. 5.3(a), then the amplitudes 8{0\n c9 are used to calculate the probabilities\n \nP{ = 08{ 0\n c90\n2 \n(5.18)\nshown in the histogram in Fig. 5.3(b).\nIf we now consider an energy measurement, such as depicted in Fig. 5.2(a), then the basis of \nenergy eigenstates is the appropriate basis for representing the state vector:\n \n0\n c9 \u0003 •\n8E1@ c9\n8E2@ c9\n8E3@c9\nf\nμ \nd E = E1\nd E = E2\nd E = E3.\nf\n  \n(5.19)\nP\n2\n2\n(a)\n(b)\n1\nP\nZ\n2\n2\nSz\nP\n2\n2\nFIGURE 5.3 (a) Spin measurement and (b) probability histogram.\n","page_start":136,"page_end":136,"token_count":603,"section_type":"other","chapter_number":5,"chapter_title":"Quantized Energies: Particle in a Box","chunk_index":179}
{"chunk_id":"01661bd2edeefc16","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"In such an energy measurement, the probabilities shown in Fig. 5.2(b) are calculated using the pro-\njections 8Ei0\n c9 of the state 0\n c9 onto the energy eigenstates 0\n Ei9. The probabilities of measuring the \nquantized energies are\nPEi = 08Ei 0\n c90\n2\n . \n(5.20)\nIn analogy to these two examples, the wave function is a representation of a quantum state using \nthe eigenstates of the position operator xn as the basis states. If we call the position eigenstates 0\n xi9, \nthen the analog to Eqs. (5.17) and (5.19) would be\n0\n c9 \u0003 •\n8x1@ c9\n8x2@ c9\n8x3@ c9\nf\nμ \nd x1\nd x2\nd x3 ,\nf\n(5.21)\nwhere the projection 8xi0 c9 is  the probability amplitude for the state 0 c9 to be measured in the posi-\ntion eigenstate 0\n xi9. However, experiment tells us that the physical observable x is not quantized. \nRather, all values of position x are allowed. This is in stark contrast to the case of the spin component \nSz, where only two results were possible. We say that the spectrum of eigenvalues of position is con-\ntinuous and the spectrum of eigenvalues of spin is discrete. Future experiments may shed new light on \nthis, but to date, space appears to be continuous. “Discrete vs. continuous” is an important distinction \nthat affects how we use and interpret the quantum state vector, the probability amplitudes, and the \nprobabilities when position is the relevant quantum mechanical observable.\nFor a continuous variable like position, the column vector representation of Eq. (5.21) is not con-\nvenient because we cannot write down the inﬁnite number of components. Even if the number were \nﬁnite but large, say 100, then we would ﬁnd a column vector cumbersome. Instead, we might choose to \nrepresent the 100 discrete numbers 8xi0 c9 as points in a graph, such as shown in Fig. 5.4(a). However, \nbecause the position spectrum is continuous, there is an inﬁnite continuum of the probability ampli-\ntudes 8x0 c9, and the natural way to represent such a continuous set of numbers is as a continuous func-\ntion, as shown in Fig. 5.4(b). This function is what we call the quantum mechanical wave  function c1x2. \nThe wave function is the collection of numbers that represents the quantum state vector in terms of the \nposition eigenstates, in the same way that the column vector used to represent a general spin state is a \ncollection of numbers that represents the quantum state vector in terms of the spin eigenstates. Whether \nyou write the wave function as c1x2 or as 8x0 c9 is ultimately a matter of taste. It is more common to \n(a)\n(b)\nx\nx","page_start":137,"page_end":137,"token_count":662,"section_type":"other","chapter_number":5,"chapter_title":"Quantized Energies: Particle in a Box","chunk_index":180}
{"chunk_id":"7dd35ff9927313c2","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"The wave function is the collection of numbers that represents the quantum state vector in terms of the \nposition eigenstates, in the same way that the column vector used to represent a general spin state is a \ncollection of numbers that represents the quantum state vector in terms of the spin eigenstates. Whether \nyou write the wave function as c1x2 or as 8x0 c9 is ultimately a matter of taste. It is more common to \n(a)\n(b)\nx\nx\n\u0004x1\u0002Ψ\u0003\n\u0004x2\u0002Ψ\u0003\n\u0004x3\u0002Ψ\u0003\n\u0004x\u0002Ψ\u0003\nΨ(x)\nΨ(x)\n\u0004x4\u0002Ψ\u0003\u0004x5\u0002Ψ\u0003\n\u0004x6\u0002Ψ\u0003\n\u0004x7\u0002Ψ\u0003\n\u0004x8\u0002Ψ\u0003\n\u0004x9\u0002Ψ\u0003\n\u0004x10\u0002Ψ\u0003\nx1 x2 x3 x4 x5 x6 x7 x8 x9 x10\nFIGURE 5.4 (a) Discrete basis representation and (b) continuous basis representation.\n5.3 The Wave Function \n113","page_start":137,"page_end":137,"token_count":243,"section_type":"other","chapter_number":5,"chapter_title":"Quantized Energies: Particle in a Box","chunk_index":181}
{"chunk_id":"c7ddac3131fd5a66","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"114 \nQuantized Energies: Particle in a Box\nsee the form c1x2 used as the wave function, and we will follow that convention mostly, using the \nDirac notation when convenient. But it is important to remember both forms, so we repeat them here:\n \nc1x2 = 8x0 c9  . \n(5.22)\nIn words, we say that the wave function c1x2 is the probability amplitude for the quantum state 0 c9 to be \nmeasured in the position eigenstate 0 x9. We will say more about the position eigenstates in Chapter 6 and \nthen also make more connections between the wave function language and the Dirac bra-ket notation.\nContinuing with the analogy to the spin and energy examples above, we expect that the prob-\nability of measuring a particular value of position is obtained by taking the absolute square of the \nprojection 8x0 c9, as was done in Eqs. (5.18) and (5.20) for spin and energy representations. However, \nbecause the projection 8x0 c9 is the continuous wave function c1x2, the absolute square yields a con-\ntinuous probability function (actually a probability density, as we’ll ﬁnd in a moment), which we write \nas P1x2 so as to distinguish it from the discrete case Ae.g. PSz=+U>2B by making x an argument rather than \na subscript. In wave function notation, this new probability function is\n \nP1x2 = 0 c1x20\n2  . \n(5.23)\nThus, given a wave function c1x2, such as shown in Fig. 5.5(a), we use Eq. (5.23) to calculate the prob-\nability function P1x2, which is shown in Fig. 5.5(b). The probability function in Fig. 5.5(b) is analogous \nto the histograms of discrete probabilities in Figs. 5.2(b) and 5.3(b). We must stress that measuring the \nprobability function P1x2 does not allow us to infer the wave function c1x2. We saw in the spin measure-\nments of Chapters 1 and 2 that measurements of three different observables, Sx, Sy, and Sz, were required \nto deduce the state vector 0 c9 because the probability amplitudes are complex numbers. The relative \nphases between the probability amplitudes are not accessible from measurement of a single observable.\nHaving a continuous function for the probability rather than a set of discrete values raises some \nimportant issues. In quantum mechanics we require that the sum of all possible probabilities be equal \nto unity (i.e., the state vector must be normalized). In the discrete spins case this meant that:\n \na\n{\nP{ = a\n{\n08{0 c90\n2 = 1. \n(5.24)\nIf position were discrete instead of continuous, then the normalization condition would be:\n \na\nn\nPxn = a\nn\n08xn0 c90\n2 = 1. \n(5.25)\n(a)\n(b)\nx\nP(x)\nΨ(x)\nx\nFIGURE 5.5 (a) Wave function and (b) corresponding probability density.\n","page_start":138,"page_end":138,"token_count":699,"section_type":"other","chapter_number":5,"chapter_title":"Quantized Energies: Particle in a Box","chunk_index":182}
{"chunk_id":"3598e23d69e52e39","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"5.3 The Wave Function \n115\nHowever, because the spectrum of position eigenvalues is continuous rather than discrete, the sum \nover discrete probabilities must be changed to an integral over the continuous probability function \nP1x2, with the requisite differential term dx added. For now, we restrict the discussion to one spatial \ndimension. Thus the normalization condition is\n \nL\n\u0005\n- \u0005\nP1x2dx =\n \nL\n\u0005\n- \u0005\n0 c1x20\n2\n dx = 1. \n(5.26)\nThe differential dx has dimensions of length and the total integrated probability must be dimension-\nless, so the probability function P1x2 must have dimensions of inverse length. This means that P1x2 is \na probability density (in one dimension a probability per unit length) rather than a probability. Hence \nwe interpret the quantity\n \nP1x2dx \n(5.27)\nas the inﬁnitesimal probability of detecting a particle at position x within an inﬁnitesimal region of \nwidth dx [i.e., between x and x + dx, as shown in Fig. 5.6(a)]. To calculate the probability that a par-\nticle is measured to be in a ﬁnite interval a 6 x 6 b, we add all the inﬁnitesimal probabilities in that \ninterval, which is the integral\n \nPa6x6b =\n \nL\nb\na\n0 c1x20\n2\n dx \n(5.28)\nas depicted in Fig. 5.6(b). Equation (5.28) is an incredibly important formula. We use it, for example, \nto ﬁnd the probability that an electron is in a certain region of an atom (extended to three dimensions, \nof course).\nTo calculate other experimental quantities, such as expectation values, we must learn how to trans-\nlate bra-ket rules for discrete basis systems to wave function rules for continuous basis systems. We can \nlearn some rules for this translation by comparing the new wave function form of the normalization \ncondition in Eq. (5.26) to the bra-ket normalization condition. In Dirac notation, the requirement of \nprobability normalization is expressed in terms of the inner product of the state vector with itself:\n \n8c0 c9 = 1. \n(5.29)\nRewrite the wave function normalization condition Eq. (5.26) to make it look more like the bra-ket form:\n \nL\n\u0005\n- \u0005\nc*1x2c1x2dx = 1. \n(5.30)\n(a)\n(b)\nx x + dx\na\nb\nP(x)\nP(x)\nx\nx\nFIGURE 5.6 Probability for measuring a particle to be in the position range (a) x to x + dx, and (b) a to b.\n","page_start":139,"page_end":139,"token_count":607,"section_type":"other","chapter_number":5,"chapter_title":"Quantized Energies: Particle in a Box","chunk_index":183}
{"chunk_id":"41803c273bc2a442","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"116 \nQuantized Energies: Particle in a Box\nComparing Eq. (5.29) and Eq. (5.30), we postulate the following rules for translating bra-ket formulae \nto wave function formulae:\n 1) Replace ket with wave function \n0 c9 S c1x2\n 2) Replace bra with wave function conjugate \n8c 0 S c*1x2\n 3) Replace bracket with integral over all space \n8 0 9 S\nL\n\u0005\n- \u0005\n dx\n 4) Replace operator with position representation An S A1x2\nwhere we have added a rule about operators that will become obvious in a moment.\nExample 5.1 Normalize the wave function\n \nc1x2 = Ce-a0 x -  20. \n(5.31)\nUse Eq. (5.26) for the normalization condition and integrate over all space\n \n 1 =\n \nL\n\u0005\n- \u0005\n0 c1x20\n2\n dx\n \n \n =\n \nL\n\u0005\n- \u0005\n@ Ce-a0 x -  2@ 0\n2\n dx\n \n \n =\n \nL\n\u0005\n- \u0005\n0 C0\n2 e-2a0 x -  20  dx. \n(5.32)\nBreak the integral into two pieces to remove the absolute value:\n \n 1 =\n \nL\n2\n- \u0005\n0 C0\n2 e2a1x -  22 dx +\n \nL\n\u0005\n2\n0 C0\n2 e-2a1x -  22 dx \n \n = J 0 C0 2\n2a\n e2a 1x -  22 R\n2\n- \u0005\n+ J 0 C0 2\n-2a\n e-2a 1x  -22 R\n\u0005\n2\n \n \n = 0 C0\n2\na\n .\n \n(5.33)\nOnce again, we have freedom to choose the overall phase, so we let C be real and positive:\n \nC = 1a \n(5.34)\ngiving the normalized wave function\n \nc1x2 = 1a e\n -  a0 x -  2 0 . \n(5.35)\nUsing the rules for translating bra-ket notation to wave function notation, a general state vector \nprojection or probability amplitude expressed in wave function language is\n \n8f0 c9 =\n \nL\n\u0005\n- \u0005\nf*1x2c1x2dx . \n(5.36)\n","page_start":140,"page_end":140,"token_count":553,"section_type":"other","chapter_number":5,"chapter_title":"Quantized Energies: Particle in a Box","chunk_index":184}
{"chunk_id":"c910a5f64ef1681a","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"5.3 The Wave Function \n117\nThe square of this probability amplitude is the probability that the state c1x2 is measured to be in the \nstate f1x2\n \nPcSw = 08w0 c90\n2 = 2\nL\n\u0005\n- \u0005\nw*1x2cx1x2dx 2\n2   \n . \n(5.37)\nTechnically, we should say that this is the probability that the system prepared in state c1x2 is measured \nto have the physical observable for which f1x2 is the eigenstate, because we measure observables, not \nstates. But the looser language is common and does not create any ambiguity in the calculation. If we \nmeasure the energy, for example, then the probability of obtaining the result En is\n \nPEn = 08En0 c90\n2 = 2\nL\n\u0005\n- \u0005\nw*\nn1x2c1x2dx 2\n2\n, \n(5.38)\nwhere wn1x2 is the energy eigenstate with energy En. Note that Eq. (5.28) and Eq. (5.37) look simi-\nlar but have important differences. In Eq. (5.28) we integrate the probability density (wave function \ncomplex squared) over a ﬁnite range of position in order to sum the probabilities of measuring many \ndifferent positions. In Eq. (5.37) we integrate the product of two wave functions over all space to deter-\nmine their mutual overlap, and then we complex square that result to get the probability of measuring \na single result.\nTo transform an expectation value to wave function language, we must consider the operator. The \nexpectation value of an observable A is the matrix element of the operator\n \n8An9 = 8c0 An 0 c9. \n(5.39)\nIf we rewrite the expectation value as\n \n8An9 = 8c 05An0 c96, \n(5.40)\nwe see that it is an inner product where one ket has been transformed by the operator An. To write this \nin terms of wave functions, we must make sure to use the position representation form of the operator. \nFor example, the position operator xn in the position representation is simply multiplication by the sca-\nlar position x. Using the translation rules to write the expectation value of the position in wave function \nnotation yields\n \n 8xn9 = 8c0 xn 0 c9\n \n \n =\n \nL\n\u0005\n- \u0005\nc*1x2x c1x2dx \n \n =\n \nL\n\u0005\n- \u0005\nx0 c1x20\n2 dx,\n \n \n(5.41)\nwhere we have used the fact that scalar multiplication is commutative. For the expectation value of the \nmomentum, we ﬁnd\n \n 8pn9 = 8c0 pn 0 c9\n \n \n =\n \nL\n\u0005\n- \u0005\nc*1x2a-iU d\ndxb c1x2dx, \n \n(5.42)\n","page_start":141,"page_end":141,"token_count":653,"section_type":"other","chapter_number":5,"chapter_title":"Quantized Energies: Particle in a Box","chunk_index":185}
{"chunk_id":"52ced6543113baf6","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"118 \nQuantized Energies: Particle in a Box\nwhich cannot be simpliﬁed more without knowing the wave function. In the next section, we will solve \nthe energy eigenvalue equation for a speciﬁc potential energy to allow us to calculate these expectation \nvalues explicitly.\nExample 5.2 Consider the wave function from Example 5.1:\n \nc1x2 = 1a e\n -  a0 x -  2 0 . \n(5.43)\nCalculate the expectation value of the position and the probability that the particle is measured to \nbe in the interval 4 6 x 6 6.\nThe expectation value of position is given by Eq. (5.41)\n \n 8xn9 =\n \nL\n\u0005\n- \u0005\nx0 c1x20\n2\n dx\n \n \n =\n \nL\n\u0005\n- \u0005\nx 11ae -a 0 x -  202\n2\n dx\n \n \n = a\nL\n\u0005\n- \u0005\nxe -2a 0 x-\n 20  dx\n \n \n = a\nL\n2\n- \u0005\nxe2a 1x-22 dx + a\nL\n\u0005\n2\nxe-2a 1x-22 dx\n \n(5.44)\n \n = a Je2a 1x-22 1-1 + 2ax2\n4a2\nR\n2\n- \u0005\n+ a Je-2a 1x-22 1-1 - 2ax2\n4a2\nR\n\u0005\n2\n \n \n = a J1-1 + 4a2\n4a2\n- 0 + 0 - 1-1 - 4a2\n4a2\nR\n \n \n = 2.\n \nThis is what you expect based upon the plot of wave function shown in Fig. 5.7(a) and the probabil-\nity density in Fig. 5.7(b), which are symmetric about the point x = 2.\n(a)\n(b)\n\u00022\n0\n2\n4\n6\n\u00022\n0\n2\n4\n6\nP(x)\n(x)\nx\nx\nFIGURE 5.7 (a) Wave function and (b) corresponding probability density. The hatched region \nin (b) represents the probability for the particle to be measured in the region 4 6 x 6 6.\n","page_start":142,"page_end":142,"token_count":521,"section_type":"other","chapter_number":5,"chapter_title":"Quantized Energies: Particle in a Box","chunk_index":186}
{"chunk_id":"92e4195cfe29e791","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"5.4 Inﬁnite Square Well \n119\nTo calculate the probability of ﬁnding the particle in the interval, use Eq. (5.28)\n \n P46x66 =\n \nL\n6\n4\n2 1a e -a 0 x -\n 20 2\n2\n dx \n \n =\n \nL\n6\n4\nae -2a1x-22 dx\n \n(5.45)\n \n = c a\n-2a\n e -2a 1x-22 d\n6\n4\n \n \n = e -4a\n2\n 31 - e -4a4 .\n \nThis probability is shown as the hatched region in Fig. 5.7(b). The actual value of the probability \ndepends on the value of the parameter a.\n5.4 \u0002 INFINITE SQUARE WELL\nOur task now is to solve the energy eigenvalue equation, which we found to be a differential equation\n \na-  U2\n2m d 2\ndx2 + V 1x2\n b wE 1x2 = E wE 1x2. \n(5.46)\nAs you might expect, the solutions to this differential equation depend critically on the functional \ndependence of the potential energy V1x2. A generic potential energy function is depicted in Fig. 5.8 \nin a potential energy diagram that illustrates some important aspects of the motion of the particle. \nMost of the interesting systems to which we will apply Eq. (5.46) resemble the potential energy func-\ntion depicted in Fig. 5.8 in that V1x2 has a minimum, so we refer to the potential energy function as a \nx\nE1\nX1\nX2\nEnergy\nT \u0002\u0003E \u0004\u0003V(x)\nV(x)\nClassical\nturning points\nClassically allowed region\nClassically\nforbidden region\nClassically\nforbidden region\nFIGURE 5.8 A generic potential energy well.\n","page_start":143,"page_end":143,"token_count":420,"section_type":"other","chapter_number":5,"chapter_title":"Quantized Energies: Particle in a Box","chunk_index":187}
{"chunk_id":"b266b9030cb4726c","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"120 \nQuantized Energies: Particle in a Box\npotential well. The particle energy is conserved, so the kinetic energy T1x2 = E - V1x2 is illustrated \nin the potential energy diagram by the vertical arrow between the ﬁxed energy E1 and the potential \nenergy V1x2. For a classical particle, the kinetic energy cannot be negative, so a classical particle with \nthe energy E1 chosen in Fig. 5.8 has its motion constrained to the region between x1 and x2. These \nextreme points of the classical motion are called classical turning points and the region within the \nturning points is called the classically allowed region, while the regions beyond are called classically \nforbidden regions. Particles that have their motion constrained by the potential well are said to be \nin bound states. Particles with energies above the top of the potential well do not have their motion \nconstrained and so are in unbound states. Note that the extent of the classically forbidden and allowed \nregions depends on the speciﬁc value of the energy, E1, for a particular bound state.\nSolving Eq. (5.46) for various important potential energy functions is the subject of this and later \nchapters. In this chapter, our goal is to study a simple potential energy system and learn the mathemat-\nics required for this new wave function approach.\nWe begin our journey to energy quantization with the simplest example of a particle that is con-\nﬁned to a region of space. The classical picture is a super ball bouncing between two perfectly elastic \nwalls. We call this system a particle in a box. We observe three important characteristics of this \nclassical system: (1) the ball ﬂies freely between the walls, (2) the ball is reﬂected perfectly at each \nbounce, and (3) the ball remains in the box no matter how large its energy. These three observations \nare consistent with (1) zero force on the ball when it is between the walls, (2) inﬁnite force on the ball \nat the walls, and (3) inﬁnite potential energy outside the box.\nThe mathematical model that is consistent with these three observations of the motion of a par-\nticle in a box is given by the potential energy function shown in Fig. 5.9. The potential energy is zero \nwithin the well (any constant would sufﬁce, but we choose zero for simplicity), and it is inﬁnite out-\nside the well. The discontinuity at the sides of the well requires us to write the potential energy func-\ntion in a piecewise fashion\n \nV1x2 = •\n\u0005,\n0 ,\n\u0005,   \nx 6 0\n0 6 x 6 L\nx 7 L.\n \n(5.47)\nBecause of the shape of the potential energy in Fig. 5.9, this system is also referred to as an inﬁnite \nsquare well. Though this model is too simple to accurately represent any real quantum mechanical \nsystem, it does illustrate most of the important features of a particle bound to a limited region of space.\n0\nL/2\nL\nx\nV(x)\n\u0005\nFIGURE 5.9 Inﬁnite square potential energy well.\n","page_start":144,"page_end":144,"token_count":694,"section_type":"other","chapter_number":5,"chapter_title":"Quantized Energies: Particle in a Box","chunk_index":188}
{"chunk_id":"47b860090d95f53b","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"5.4 Inﬁnite Square Well \n121\nOur goal is to ﬁnd the energy eigenstates and eigenvalues of the system by solving the energy \neigenvalue equation using the potential energy in Eq. (5.47). The potential energy is piecewise, so we \nmust solve the differential equation (5.46) separately inside and outside the box. Outside the box, the \npotential energy is inﬁnite and the energy eigenvalue equation is\na-  U2\n2m d 2\ndx2 + \u0005b wE 1x2 = E wE 1x2,   outside box. \n(5.48)\nWe are looking for solutions with ﬁnite energy E, so Eq. (5.48) is satisﬁed only if the energy eigenstate \nwave function wE1x2 is zero everywhere outside the box. This means that the quantum mechanical \nparticle is excluded from the classically forbidden regions in this example. This correspondence with \nthe classical situation holds only for the case of inﬁnite potential energy walls on the potential well.\nInside the box, the potential energy is zero and the energy eigenvalue equation is\na-  U2\n2m\n d 2\ndx2 + 0b wE1x2 = EwE1x2,   inside box. \n(5.49)\nThus our task reduces to solving the differential equation inside the box:\n-  U2\n2m\n d 2\ndx2 wE1x2 = EwE1x2. \n(5.50)\nIt is worth reminding ourselves at this point what is known and what is not. The particle has a mass \nm and is conﬁned to a box of size L. These quantities are known, as is U, a fundamental constant. The \nunknowns that we need to ﬁnd are the energy E and the wave function wE1x2, which is what it means to \nsolve an eigenvalue problem (now posing as a differential equation).\nIt is convenient to rewrite the differential equation (5.50) as\n d 2\ndx2 wE1x2 = -  2mE\nU2  wE1x2 \n = -k2wE1x2,\n(5.51)\nwhere we have deﬁned a new parameter\nk2 = 2mE\nU2 , \n(5.52)\nwhich is positive because the energy E is positive in this problem. The parameter k is called the wave \nvector, and its physical interpretation will be evident in Eq. (5.67). Equation (5.51) says that the \nenergy eigenstate wE1x2 is a function whose second derivative is equal to that function itself times a \nnegative constant. We can write the solution either in terms of complex exponential functions\nwE1x2 = A\u0004e ikx + B\u0004e -ikx \n(5.53)\nor in terms of sine and cosine functions\nwE1x2 = A sin kx + B cos kx. \n(5.54)","page_start":145,"page_end":145,"token_count":660,"section_type":"other","chapter_number":5,"chapter_title":"Quantized Energies: Particle in a Box","chunk_index":189}
{"chunk_id":"17655a45d301aa27","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"energy eigenstate wE1x2 is a function whose second derivative is equal to that function itself times a \nnegative constant. We can write the solution either in terms of complex exponential functions\nwE1x2 = A\u0004e ikx + B\u0004e -ikx \n(5.53)\nor in terms of sine and cosine functions\nwE1x2 = A sin kx + B cos kx. \n(5.54)\nEither solution includes two as yet unknown constants, as you would expect for a second-order differ-\nential equation. It turns out that bound state energy eigenstates can always be written as real functions, \nso we choose to work with the sine and cosine form of the general solution (if you choose the complex ","page_start":145,"page_end":145,"token_count":156,"section_type":"other","chapter_number":5,"chapter_title":"Quantized Energies: Particle in a Box","chunk_index":190}
{"chunk_id":"01ae9c06ed6d93b2","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"122 \nQuantized Energies: Particle in a Box\nexponential form, you will arrive at the sine and cosine solutions at the end of the problem anyway: \nProblem 5.3). Hence the energy eigenstate wave function throughout space is\n \nwE 1x2 = •\n0 ,\nA sin kx + B cos kx ,\n0 ,\n   \nx 6 0\n0 6 x 6 L\nx 7 L.\n \n(5.55)\nWe now need some more information to reach the ﬁnal solution. There are three unknowns in \nthe problem: A, B, and k [which contains the energy E through Eq. (5.52)], so we expect to need three \npieces of information to solve for the three unknowns. We get two of these pieces of information from \nimposing boundary conditions on the wave function. To make sure that the mathematical solutions \nproperly represent real physical systems, we require that the wave function be continuous across each \nboundary between different regions of space where different solutions exist. Applying this require-\nment on the continuity of the wave function at the sides of the box x = 0 and L yields two boundary \ncondition equations:\n \n wE102: A sin102 + B cos102 = 0 \n \n wE1L2: A sin kL + B cos kL = 0.  \n(5.56)\nThe boundary condition at the left side of the box yields\n \nB = 0. \n(5.57)\nThis tells us that the cosine part of the general solution is not allowed because the cosine solution is not \nzero at the edge of the box and so does not match the wave function outside the box. The exclusion of \nthe cosine part of the solution arises because we chose to locate our box with one side at x \u0003 0; if the \nbox is located differently, then both sine and cosine solutions may be allowed. Given that the allowed \nwave functions must be sine functions, the boundary condition at the right side of the box yields\n \nA sin kL = 0. \n(5.58)\nThis equation is satisﬁed if A \u0003 0, but that yields a wave function that is zero everywhere, so it is unin-\nteresting. The more interesting possibility is that\n \nsin kL = 0. \n(5.59)\nThis is a transcendental equation that places limitations on the allowed values of the wave vector k. We \nwill ﬁnd other transcendental equations when we study other potentials. This transcendental equation \nhas solutions when the sinusoid function is zero. Hence the wave vectors that satisfy this equation are\n \n kL = np\n \n \n kn = n p\nL\n ,   n = 1, 2, 3, ... . \n(5.60)\nOnly discrete wave vectors are allowed, so this is termed the quantization condition. The index n is \nthe quantum number, which we use to label the quantized states and energies. The value n = 0 is \nexcluded because that would yield a wave function equal to zero, which is uninteresting. The nega-\ntive values of n are excluded because they yield the same states as the corresponding positive n values, \n","page_start":146,"page_end":146,"token_count":673,"section_type":"other","chapter_number":5,"chapter_title":"Quantized Energies: Particle in a Box","chunk_index":191}
{"chunk_id":"5c352e7f48445e10","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"5.4 Inﬁnite Square Well \n123\nrecalling that an overall phase A-1 = eip in this caseB does not change the physical state. Using the deﬁ-\nnition of the wave vector in Eq. (5.52), we relate the quantized wave vectors to the quantized energies\n \nEn = U2k 2\nn\n2m . \n(5.61)\nHence, the wave vector quantization condition in Eq. (5.60) results directly in the energy quantization \nfor this system:\n \nEn = n2p2U2\n2mL2 ,   n = 1, 2, 3, ...  . \n(5.62)\nThese allowed energies scale with the square of the quantum number n and produce the set of energy \nlevels shown in Fig. 5.10. The ground state is the n \u0003 1 level.\nThe allowed energy eigenstate wave functions are:\n \nwn1x2 = A sin npx\nL ,   n = 1, 2, 3, ...  . \n(5.63)\nThe constant A was not determined by the boundary conditions. To determine A, we need the third \npiece of information, which is that the wave function is normalized to unity:\n \n1 = 8En 0\n En9 =\n \nL\n\u0005\n- \u0005\nw*\nn1x2wn1x2dx =\n \nL\n\u0005\n- \u0005\n0 wn1x20\n2\n dx. \n(5.64)\n0\n5\n10\n15\n20\n25\nE /E1\nn \u0002\u00031\nn \u0002\u00032\nn \u0002\u00033\nn \u0002\u00034\nn \u0002\u00035\nE1 \u0002 1E1\nE2 \u0002 4E1\nE3 \u0002 9E1\nE4 \u0002 16E1\nE5 \u0002 25 E1\nFIGURE 5.10 Energy spectrum of the inﬁnite square potential energy well.\n","page_start":147,"page_end":147,"token_count":440,"section_type":"other","chapter_number":5,"chapter_title":"Quantized Energies: Particle in a Box","chunk_index":192}
{"chunk_id":"5c23949082326672","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"124 \nQuantized Energies: Particle in a Box\nSubstitute the wave function from Eq. (5.63) and note that the wave function is zero for x 6 0 and \nx 6 L to limit the range of integration, resulting in\n \n1 =\n \nL\nL\n0\n0 A0\n2 sin2 kn\n x dx = 0 A0\n2 L\n2 . \n(5.65)\nWe are free to choose the normalization constant to be real and positive, because an overall phase is \nnot measurable. Thus the normalization constant is A = 12>L and the properly normalized energy \neigenstates are\n \nwn1x2 = A\n2\nL sin npx\nL ,   n = 1, 2, 3, ...  . \n(5.66)\nThe ﬁrst few allowed energy states are shown in Fig. 5.11. From these plots, it is now clear why \nwe call c1x2 the wave function. These energy eigenstates have a “wavy” spatial dependence, much \nlike the modes on a guitar string. For the inﬁnite square well, the waves “ﬁt” into the potential well \nsuch that there are an integer number of half wavelengths within the well. If we relate the wave vector \nk to a wavelength l through the relation\n \nk = 2p\nl , \n(5.67)\nthen we can rewrite the quantization condition in terms of the wavelength\n \n kn = n p\nL  \n \n 2p\nln\n= n p\nL  \n \n ln = 2L\nn\n \n(5.68)\n \n L = n ln\n2 . \nIn words, the well must contain an integer number of half wavelengths. This is the sense in which the \nwaves must “ﬁt” into the well. This is the same as the classical result for the allowed standing waves \non a vibrating string, such as a guitar string. The distinction between the classical wave and the quan-\ntum wave is that the classical wave does not have a quantized energy. The energy of a vibrating guitar \nn \u0002\u00031\nL/2\nL\nx\nΨ(x)\n(a)\nn \u0002\u00032\nL/2\nL\nx\nΨ(x)\n(b)\nn \u0002\u00033\nL/2\nL\nx\nΨ(x)\n(c)\nFIGURE 5.11 Wave functions of the ﬁrst three energy eigenstates of the inﬁnite \nsquare potential energy well.\n","page_start":148,"page_end":148,"token_count":537,"section_type":"other","chapter_number":5,"chapter_title":"Quantized Energies: Particle in a Box","chunk_index":193}
{"chunk_id":"cced6d2e4f2c4d89","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"5.4 Inﬁnite Square Well \n125\nstring depends on the amplitude of oscillation, not on the wavelength or wave vector, and so it can have \nany energy value. The amplitude of the quantum wave function is determined by the normalization \ncondition and is independent of the energy for the inﬁnite square well.\nThe wave properties of this quantum system are a new aspect that is not evident in the classical \ndescription of a particle. In classical mechanics, waves and particles are clearly distinct, whereas in \nquantum mechanics a system exhibits properties that remind us of classical particles but also exhibits \nproperties of classical waves. This is often referred to as wave-particle duality. We will see more of \nthis in the next chapter when we discuss free particles.\nExample 5.3 It is useful to put some numbers into these expressions to get a sense of scale. For \nexample, if we conﬁne an electron 1me = 511 k eV>c22 in a box of size 0.2 nm (about the size of an \natom), the ground state (n \u0003 1) energy is\n \n E1 =\np2U2\n2me L2\n \n \n =\np216.58 * 10-16 eV s2\n2\n210.511 * 106 eV>c2210.2 * 10-9 m2\n2 \n(5.69)\n \n = 9.4 eV. \nThis is comparable to typical atomic binding energies.\nThe spectrum of this system will include the transition between the ground state and the ﬁrst excited \nstate. The ﬁrst excited state has energy E2 = 22E1 = 4E1, so the wavelength of light for this transition is\n \n l21 =\nhc\nE2 - E1\n= hc\n3E1\n \n \n = 1240 eV nm\n319.4 eV2\n= 44 nm . \n(5.70)\nNote that l21 is the wavelength of the photon emitted or absorbed in the transition, not the wave-\nlength of the bound particle that is associated with the wave vector of the wave function, which is \n0.4 nm for the ground state and 0.2 nm for the excited state, in agreement with Eq. (5.68).\nNow that we have found the energy eigenstates, we have what we need to calculate probabilities \nand expectation values to compare with experiments. The square of the wave function gives us the \nprobability density\n \n Pn1x2 = 0 wn1x2 0\n2\n \n \n = 2\nL sin2 npx\nL , \n(5.71)\nwhich is shown in Fig. 5.12 for the ﬁrst three states. Note that the probability density is zero outside \nthe well, so the probability of ﬁnding the particle anywhere outside the well is zero, just as in the clas-\nsical case. However, in the quantum system there are positions within the well where the probability \nof ﬁnding the particle is zero, which does not happen in the classical case. These positions are at the \nnodes of the wave function and hence are characteristic of the wave nature of the particle.\n","page_start":149,"page_end":149,"token_count":671,"section_type":"other","chapter_number":5,"chapter_title":"Quantized Energies: Particle in a Box","chunk_index":194}
{"chunk_id":"02020ff5ed03109d","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"126 \nQuantized Energies: Particle in a Box\nExample 5.4 Find the expectation value of the position for a particle in the ground state of an \ninﬁnite square potential energy well.\nThe expectation value of position is given by Eq. (5.41)\n \n 8xn9 = 8E10\n xn  0 E19 =\n \nL\n\u0005\n- \u0005\nw*\n11x2xw11x2dx =\n \nL\n\u0005\n- \u0005\nx  0\n w11x20\n2\n dx \n \n = 2\nL L\nL\n0\nx sin2a px\nL b dx = 2\nL\n a L\npb\n2\nL\np\n0\ny sin21y2dy\n \n \n = 2\nL\n a L\npb\n2\n c y2\n4 - y sin 2y\n4\n-\n cos 2y\n8\nd\np\n0\n \n(5.72)\n \n = 2\nL\n a L\npb\n2\n c p2\n4 -\np sin12p2\n4\n-\n cos12p2\n8\n+ 1\n8 d\n \n \n = 2\nL\n a L\npb\n2\n c p2\n4 d\n \n \n = L\n2 .\n \nThis is what we would expect to get given the symmetry of the problem. There is no preference for \nthe left or right side of the well, so the average value of a set of position measurements must be the \nmidpoint of the well. We get the same result for any energy eigenstate of the system.\nTo summarize, we have solved the problem of a particle bound in an inﬁnitely deep square poten-\ntial energy well, which means we have found the energy eigenvalues and eigenstates. The well is \ndepicted in Fig. 5.13(a), the spectrum of allowed energies is depicted in Fig. 5.13(b), and the wave \nfunctions of the energy eigenstates are depicted in Fig. 5.13(c). It is common practice to unify the three \ndiagrams of Fig. 5.13 in a single diagram, shown in Fig. 5.14, that represents the quantum mechani-\ncal potential energy well problem and its solution. The well, the energies, and the wave functions are \nsuperimposed on each other, such that different aspects of the diagram have different vertical axes. \nThe wave function for each energy eigenstate has its vertical coordinate origin located at the energy of \nthat state.\nn \u0002\u00033\n0\n(c)\nL/2\nL\nx\n\u0002Ψ\u00022\nn \u0002\u00031\n0\n(a)\nL/2\nL\nx\n\u0002Ψ\u00022\nn \u0002\u00032\n0\n(b)\nL/2\nL\nx\n\u0002Ψ\u00022\nFIGURE 5.12 Probability densities of the ﬁrst three energy eigenstates of the \ninﬁnite square potential energy well.\n","page_start":150,"page_end":150,"token_count":645,"section_type":"other","chapter_number":5,"chapter_title":"Quantized Energies: Particle in a Box","chunk_index":195}
{"chunk_id":"7638960e10662abc","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"5.4 Inﬁnite Square Well \n127\n0\nL\nx\nV(x)\n(a)\n\u0005\n0\n5\n10\n15\n20\n25\n(b)\nE /E1\nn \u0002\u00031\nn \u0002\u00032\nn \u0002\u00033\nn \u0002\u00034\nn \u0002\u00035\nL\nx\nn \u0002\u00035\nL\nx\nn \u0002\u00034\nL\nx\nn \u0002\u00033\nL\nx\nn \u0002\u00032\nL\n(c)\nx\nn \u0002\u00031\nΨ(x)\nFIGURE 5.13 (a) Inﬁnite square potential energy well, (b) spectrum of allowed energies, and \n(c) energy eigenstate wave functions.\n0\nL\nx\nn \u0002\u00031\nn \u0002\u00032\nn \u0002\u00033\nn \u0002\u00034\nn \u0002\u00035\nFIGURE 5.14 Uniﬁed schematic diagram of inﬁnite square well problem and solution. \nNote that two vertical scales are implied. For the potential energy well and the energy  \nspectrum, the vertical scale is energy with the origin at the bottom of the well. For the  \nwave functions, the vertical scale is probability amplitude 11>length1>22 with the \nc = 0 origin for each state centered on the energy of that state.\n","page_start":151,"page_end":151,"token_count":299,"section_type":"other","chapter_number":5,"chapter_title":"Quantized Energies: Particle in a Box","chunk_index":196}
{"chunk_id":"ba5c77e9ca16db3a","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"128 \nQuantized Energies: Particle in a Box\nThe take home message of this problem is that the imposition of boundary conditions on the \nwave function limits the possible states that can “ﬁt” into the well and directly leads to the quantiza-\ntion of energy. This is a general result that we will return to time and again as we study other potential \nwell landscapes.\n5.5 \u0002 FINITE SQUARE WELL\nNow let’s make the problem a little more realistic by having the potential energy outside the well be ﬁnite \ninstead of inﬁnite. We still assume that the well is square, which still results in an inﬁnite force at the \nwalls. However, this new problem illustrates several important features of bound energy states that were \nnot evident in the inﬁnite well. A ﬁnite well can be used to model many real systems, such as an electron \nin a thin semiconductor. In Section 5.8, we use this model to discuss quantum well semiconductor lasers.\nThe ﬁnite square well potential energy is shown in Fig. 5.15 and is written as\n \nV1x2 = •\nV0,\nx 6 -a\n  0,\n-a 6 x 6 a\nV0,  \nx 7 a,\n \n(5.73)\nwhere we have deliberately chosen a different position origin from the inﬁnite well case in order to \ngive you practice and also for convenience. For now, we look for bound state solutions, that is, for \nenergies below the potential V0. Energies above V0 correspond to unbound states that we will discuss \nin the next chapter.\nWith this new potential energy function, the energy eigenvalue equation is\n \n a-  U2\n2m d 2\ndx 2 + 0b wE1x2 = EwE1x2,    inside box  \n \n a-  U2\n2m d 2\ndx 2 + V0b wE1x2 = EwE1x2,          outside box . \n(5.74)\n0\n\u0004a\na\nx\nV(x)\nV0\nFIGURE 5.15 Finite square potential energy well.\n","page_start":152,"page_end":152,"token_count":468,"section_type":"other","chapter_number":5,"chapter_title":"Quantized Energies: Particle in a Box","chunk_index":197}
{"chunk_id":"39dc986f878c1572","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"5.5 Finite Square Well \n129\nIn the inﬁnite well problem, we found it useful to use the wave vector k\n \nk = A\n2mE\nU2 . \n(5.75)\nIn this case, it is also useful to deﬁne a similar constant outside the well\n \nq = A\n2m\nU2 1V0 - E2. \n(5.76)\nFor bound states, 0 6 E 6 V0, and therefore both k and q are real. We use these two constants to \nrewrite the energy eigenvalue equation:\n \n \nd 2wE1x2\ndx2\n= -k2wE1x2,    inside box  \n \n \nd 2wE1x2\ndx 2\n= q 2wE1x2,       outside box . \n(5.77)\nThe energy eigenvalue equation inside the box is identical to the one we solved for the inﬁnite well poten-\ntial. The differential equation outside the box is similar except the constant is positive instead of negative, \ngiving real exponential solutions rather than complex exponentials. Thus the solution outside the box is\n \nwE1x2 = Aeqx + Be-qx. \n(5.78)\nThis solution in the classically forbidden region is exponentially decaying, or growing, with a decay \nlength, or growth length, of 1Nq.\nThe energy eigenstate must be constructed by connecting solutions in the three regions shown in \nFig. 5.15. We write the general solution as\n \nwE1x2 = •\nAeqx + Be-qx,\nC sin kx + D cos kx,\nFeqx + Ge-qx,    x 6 -a\n -a 6 x 6 a\n x 7 a.\n \n(5.79)\nAs we discussed in the inﬁnite well problem, the solutions in the three regions must satisfy bound-\nary conditions where the regions connect. In constructing the inﬁnite well solutions, we used the \ncondition that the wave function must be continuous across a boundary. We now introduce a second \nrequirement that the slope of the wave function be continuous across a boundary. If the slope were \ndiscontinuous, that would imply an inﬁnite kinetic energy. However, this requirement has one excep-\ntion: it does not apply if the potential is inﬁnite (Problem 5.24), which is why we did not use it in the \ninﬁnite well problem. You can see in Fig. 5.14 that the inﬁnite well solutions have a change in slope \nat the edges of the box where the potential energy becomes inﬁnite. We now summarize these two \nboundary conditions:\n 1) wE1x2 is continuous\n 2) dwE1x2\ndx\n is continuous unless V = \u0005.\nBefore we impose the boundary conditions, we make two immediate simpliﬁcations to the gen-\neral solutions in Eq. (5.79). In the regions outside the well, the wave function must be a decaying \n","page_start":153,"page_end":153,"token_count":664,"section_type":"other","chapter_number":5,"chapter_title":"Quantized Energies: Particle in a Box","chunk_index":198}
{"chunk_id":"82e097f01cd3b4a6","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"130 \nQuantized Energies: Particle in a Box\nexponential because a growing exponential term all the way out to inﬁnity would not permit the wave \nfunction to be normalized. This normalization condition, which can also be termed a boundary condi-\ntion at inﬁnity, requires that B = F = 0 in Eq. (5.79). The second simpliﬁcation comes from recog-\nnizing that the potential energy is symmetric with respect to the origin 3V1x2 = V1-x24. This means \nthat the energy eigenstates will either be symmetric or antisymmetric (even or odd). This symmetry \nis evident in the inﬁnite well solutions shown in Fig. 5.14. (This can also be discussed in terms of the \ncommutation of the Hamiltonian and the parity operator, which we discuss in Section 7.6.4) We can \nthus solve for the two sets of solutions independently. If you don’t impose this symmetry condition \nnow, it will come out naturally after some algebra on the general solutions anyway (Problem 5.14). \nWith these two simpliﬁcations, the even solutions reduce to\nweven1x2 = •\nAeqx,\nD cos1kx2,\nAe-qx,\nx 6 -a\n-a … x … a\nx 7 a.\n(5.80)\nThe odd solutions are\nwodd1x2 = •\nAeqx,\nC sin1kx2,\n-Ae-qx,\nx 6 -a\n-a … x … a\nx 7 a.\n(5.81)\nLet’s ﬁrst do the even solutions. The boundary conditions at the right side of the well 1x = a2 give\n weven1a2: D cos1ka2 = Ae-qa\ndweven1x2\ndx\n`\nx=a \n: -kD sin1ka2 = -qAe-qa. \n(5.82)\nThe boundary conditions at the left side of the well 1x = -a2 yield the same equations, which must be \ntrue because of the symmetry. The two equations above have three unknowns: the amplitudes A and D \nand the energy E, which is contained in the parameters k and q. The normalization condition provides \nthe third equation required to solve for all three unknowns. We ﬁnd the energy condition rather simply \nby dividing the two equations, which eliminates the amplitudes and yields\nk tan1ka2 = q. \n(5.83)\nBecause both k and q are functions of the energy, this equation gives us a formula to ﬁnd the allowed \nenergies. It is independent of the constants A and D, which are found by applying the normalization \ncondition and using Eq. (5.82) again. As usual with these types of problems, the eigenvalue condi-\ntion is obtained ﬁrst, and then the eigenfunctions are obtained later. To make the energy dependence ","page_start":154,"page_end":154,"token_count":639,"section_type":"other","chapter_number":5,"chapter_title":"Quantized Energies: Particle in a Box","chunk_index":199}
{"chunk_id":"62a292f65e5e0380","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"(5.83)\nBecause both k and q are functions of the energy, this equation gives us a formula to ﬁnd the allowed \nenergies. It is independent of the constants A and D, which are found by applying the normalization \ncondition and using Eq. (5.82) again. As usual with these types of problems, the eigenvalue condi-\ntion is obtained ﬁrst, and then the eigenfunctions are obtained later. To make the energy dependence \nexplicit, we use Eqs. (5.75) and (5.76) to write Eq. (5.83) as\nA\n2m\nU2  E tana A\n2m\nU2  E ab = A\n2m\nU2  1V0 - E2. \n(5.84)\nThe next step is to solve this transcendental equation for the energy E.\nFor the odd solutions, a similar argument leads to the transcendental equation (Problem 5.15)\n-k cot1ka2 = q. \n(5.85)","page_start":154,"page_end":154,"token_count":220,"section_type":"other","chapter_number":5,"chapter_title":"Quantized Energies: Particle in a Box","chunk_index":200}
{"chunk_id":"a84034bf84b8df2e","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"5.5 Finite Square Well \n131\nA graphical solution for the allowed energies using these two transcendental equations is most useful \nhere. There are many ways of doing this. One way involves deﬁning some new dimensionless parameters:\n \n z = ka = B\n2mEa2\nU2\n \n \n z0 = B\n2mV0a2\nU2\n \n \n qa = B\n2m1V0 - E2a2\nU2\n, \n \n(5.86)\nwhere the variable z parameterizes the energy of the state and the constant z0 characterizes the strength \nof the potential energy well. These deﬁnitions lead to the convenient expressions\n \n 1ka2\n2 + 1qa2\n2 = z 2\n0\n \n \n 1qa2\n2 = z 2\n0 - 1ka2\n2 = z 2\n0 - z 2. \n \n(5.87)\nThis allows us to write the transcendental equations in this form:\n \n ka tan1ka2 = qa  S  z tan1z2 = 4z 2\n0 - z 2\n \n \n -ka cot1ka2 = qa  S  -z cot1z2 = 4z 2\n0 - z 2. \n \n(5.88)\nIn each of these new transcendental equations, the left side is a modiﬁed trig function, while the right \nside is a circle with radius z 0. These functions are plotted in Fig. 5.16 as a function of the parameter \nz. The intersection points of these curves determine the allowed values of z and hence the allowed \nenergies En through Eq. (5.86). Because the constant z 0 is the radius of the circle, there are a limited \nnumber of allowed energies, and that number grows as z 0 gets larger. Wells that are deeper and wider \nhave more allowed bound energy states. \nThat’s it for the energies. There is no simple formula—the transcendental equations must be \nsolved graphically or numerically for each different well. For example, the curves in Fig. 5.16 corre-\nspond to a well with z 0 = 6, which results in four intersection points and hence four bound states. The \nintersection points and four allowed energies are\n \n z1 = 1.34 S E1 = 1.81 U2\n2ma2\n \n \n z2 = 2.68 S E2 = 7.18 U2\n2ma2\n \n \n z3 = 3.99 S E3 = 15.89 U2\n2ma2  \n \n z4 = 5.23 S E4 = 27.31 U2\n2ma2 . \n \n(5.89)\nThe energy eigenstate wave functions are characterized by the allowed values of the parameters \nk and q from Eq. (5.86). All that remains to do is normalize the wave function, which is straightfor-\nward but tedious (Problem 5.16). Once again, we use a uniﬁed diagram to show the potential energy \nwell, the allowed energies, and the allowed eigenstate wave functions superimposed in Fig. 5.17. \n","page_start":155,"page_end":155,"token_count":687,"section_type":"other","chapter_number":5,"chapter_title":"Quantized Energies: Particle in a Box","chunk_index":201}
{"chunk_id":"f20e4bd475f45f26","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"132 \nQuantized Energies: Particle in a Box\n0\n\u0004a\na\nx\nn \u0002\u00031\nn \u0002\u00032\nn \u0002\u00034\nn \u0002\u00033\nFIGURE 5.17 Uniﬁed schematic diagram of the ﬁnite potential energy well and the bound state \nsolutions, showing the well, the allowed energies, and the energy eigenstate wave functions.\n0\n\u000b\n2\n\u000b\n3\u000b\n2\nz\n\u000b\n2\n\u000b\n3\u000b\n2\n2\u000b\nf(z)\nz tanz\n_z cotz\nz02\u000b\nz0\nz2\n0 \n_ z 2\nFIGURE 5.16 Graphical solution of the transcendental equations for the allowed energies of a ﬁnite \nsquare well 1z0 = 62.\n","page_start":156,"page_end":156,"token_count":180,"section_type":"other","chapter_number":5,"chapter_title":"Quantized Energies: Particle in a Box","chunk_index":202}
{"chunk_id":"0a00540f3dc6c5d5","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"5.6 Compare and Contrast \n133\nNote that the ﬁnite well eigenstates share many features with the inﬁnite well states, with one major \nexception—they extend into the classically forbidden region. Quantum mechanical particles have a \nﬁnite probability of being found where classical particles may not exist! This is a purely quantum \nmechanical effect and is commonly referred to as barrier penetration. The ability of the particle \nto penetrate the potential energy barrier leads to the phenomenon of tunneling, an example of which \nis radioactive decay. We’ll say more about these wave functions in a bit, but let’s ﬁrst check that our \nsolution is consistent with the solution we derived earlier for the inﬁnite energy well case.\nThe limit of an inﬁnitely deep well corresponds to the radius z0 in Fig. 5.16 going to inﬁnity, in \nwhich case the allowed values of z become the asymptotes of the modiﬁed trig functions, shown by the \ndashed lines in Fig. 5.16. These limits are the same as for the simple trig functions and yield\n zn = n p\n2 1 kna = n p\n2 \n kn = np\n2a ,\n(5.90)\nfrom which we recover the inﬁnite well energy eigenvalues:\nEn =\nn2p2 U2\n2m12a2\n2 . \n(5.91)\nNote that the width of the well is 2a here, whereas we called the width L in the inﬁnite well case. The \ninﬁnite well eigenstate wave functions for this symmetric well position are\n wn1x2 = A\n2\n2a\n cos npx\n2a ,    n = 1, 3, 5, ...  \n wn1x2 = A\n2\n2a\n sin npx\n2a ,    n = 2, 4, 6, ... . \n(5.92)\nThere are two sets of solutions because we chose a different coordinate system to solve the problem. \nIn the limit z0 S \u0005, the decay length q becomes zero and the energy eigenstates are zero outside the \nwell, as expected. The inﬁnite well eigenstates are shown in Fig. 5.18(a) for this new choice of coor-\ndinates. Comparing the wave functions in Fig. 5.18(a) with those from Fig. 5.14, though, we see that \nthese are the same eigenstate wave functions that we found before. In Fig. 5.18(b) we show the ﬁnite \nwell states for comparison.\n5.6 \u0002 COMPARE AND CONTRAST\nNow that we have solved two similar problems, the inﬁnite and ﬁnite square wells, let’s discuss some \nof the important features of these solutions and see which features are common to both problems and \nothers, and which are distinct.\n 5.6.1 \u0002 Wave Function Curvature\nThe ﬁrst common feature is that the wave function is oscillatory 1sin kx or cos kx2 inside the well and ","page_start":157,"page_end":157,"token_count":667,"section_type":"other","chapter_number":5,"chapter_title":"Quantized Energies: Particle in a Box","chunk_index":203}
{"chunk_id":"ce795933eb24e80d","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"Now that we have solved two similar problems, the inﬁnite and ﬁnite square wells, let’s discuss some \nof the important features of these solutions and see which features are common to both problems and \nothers, and which are distinct.\n 5.6.1 \u0002 Wave Function Curvature\nThe ﬁrst common feature is that the wave function is oscillatory 1sin kx or cos kx2 inside the well and \nexponentially decaying (e-qx or eqx) outside the well. This aspect is explained by examining the curvature \n(i.e., second derivative) of the wave function. To see this, we rewrite the energy eigenvalue equation\nd 2wE 1x2\ndx2\n= -  2m\nU2  3E - V 1x24wE 1x2, \n(5.93)","page_start":157,"page_end":157,"token_count":187,"section_type":"other","chapter_number":5,"chapter_title":"Quantized Energies: Particle in a Box","chunk_index":204}
{"chunk_id":"3d1223adb4041e9f","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"134 \nQuantized Energies: Particle in a Box\nwhich then directly relates the wave function curvature to the difference between the energy E and \nthe potential energy V(x). Thus, inside the well, in the classically allowed region, we have E 7 V1x2 \nand the differential equation admits only sinusoidal solutions characterized by the wave vector k or \nwavelength l = 2p>k. Outside the well, in the classically forbidden region, we have E 6 V1x2 and \nthe differential equation admits only real exponential solutions with a decay length of 1>q, which is \nzero for the inﬁnite square well. The growing exponential terms in these problems are excluded by the \nnormalization requirement (i.e., the boundary condition at inﬁnity).\nThese comments can be generalized as shown in Fig. 5.19. Equation (5.93) tells us that in a clas-\nsically allowed region where E 7 V, the curvature has the opposite sign to the wavefunction, and in \nthe classically forbidden region where E 6 V, the curvature has the same sign as the wavefunction. \nThis means that in the classically allowed region the wave function is concave toward the axis, while \nin the classically forbidden region the wave function is convex toward the axis, as shown in Fig. 5.19.\nWe can also make some general observations regarding the length scales of the wave functions. In \na general potential well, the wave vector is given by\n \nk =\n22m 1E - V2\nU\n. \n(5.94)\nHence, the oscillatory part of the wave function (inside the well) has a characteristic wavelength\n \nl = 2p\nk\n=\nh\n22m 1E - V2\n\f\n1\n2T\n. \n(5.95)\nSo the larger the energy difference between the eigenvalue and the potential energy (i.e., the larger \nthe kinetic energy), the smaller the wavelength. That relationship is evident in the eigenstates shown \nin Fig. 5.18; the higher the energy, the more “wiggly” the wave function. In the forbidden region, the \ndecay constant \n \nq =\n22m 1V - E2\nU\n \n(5.96)\n\u0004a\n0\na\nx\n0\n\u0004a\na\nx\n(a)\n(b)\nFIGURE 5.18 (a) Inﬁnite and (b) ﬁnite well energy eigenstates.\n","page_start":158,"page_end":158,"token_count":530,"section_type":"other","chapter_number":5,"chapter_title":"Quantized Energies: Particle in a Box","chunk_index":205}
{"chunk_id":"54132aa94f3c07d0","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"5.6 Compare and Contrast \n135\ndecreases as the energy increases toward V, which means that the decay length becomes larger. Hence, \nfor higher energy states the wave function penetrates further into the classically forbidden region \n(Problem 5.17). This increasing penetration with increasing energy is evident in the ﬁnite well states \nof Fig. 5.17.\nIn comparing the ﬁnite and inﬁnite well energies in Fig. 5.18, we also note that a given ﬁnite well \nenergy eigenvalue En lies below the corresponding inﬁnite well energy eigenvalue. This is consistent \nwith the longer wavelength of the ﬁnite well eigenstate compared to the corresponding inﬁnite well \nstate. For the ﬁnite well eigenstate to “ﬁt” in the well, the wavelength can be longer because part of the \nwave function is outside the well. The increasing penetration of the wave function into the classically \nforbidden region with increasing energy implies that the difference in energies between the ﬁnite and \ninﬁnite wells is larger for higher energies, as is also evident in Fig. 5.18 (Problem 5.19).\n 5.6.2 \u0002 Nodes\nThe ground state has a single antinode in the wave function, with each subsequent higher state acquiring \nan extra antinode. Thus the nth energy level has n antinodes and 1n - 12 nodes. This is a general char-\nacteristic of the energy eigenstates of any potential energy well. In the inﬁnite well we found an inﬁnite \nnumber of states. In the ﬁnite well we found a ﬁnite number of states, but we looked only for bound \nstates. We will see later that there are an inﬁnite number of unbound states with E 7 V0, which means \nthat there are an inﬁnite number of total allowed energy states. The inﬁnite number of states is a common \nfeature of potential energy wells. In the ﬁnite well, if the well is small enough (small V0 and/or small a), \nthen there might be only one bound state, but there is always at least one bound state. This is generally \ntrue for any well shape. The delta-function potential is an extreme case (Problem 5.25).\n 5.6.3 \u0002 Barrier Penetration\nIn the ﬁnite potential well, the wave function is nonzero in the classically forbidden region. This \nimplies a ﬁnite probability that the quantum mechanical particle can be found where the classical \nparticle cannot. As mentioned above, this penetration of the wave function into the potential energy \nx\nE0\nE, Ψ\nExponential\nOscillatory\nAllowed\nForbidden\nV(x)\nΨ > 0, Ψ\" < 0\nΨ < 0, Ψ\" > 0\nΨ > 0, Ψ\" > 0\nΨ < 0, Ψ\" < 0\nFIGURE 5.19 Curvature of the energy eigenstate wave functions in the allowed and forbidden regions.\n","page_start":159,"page_end":159,"token_count":665,"section_type":"other","chapter_number":5,"chapter_title":"Quantized Energies: Particle in a Box","chunk_index":206}
{"chunk_id":"6c7adcb14f19317a","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"136 \nQuantized Energies: Particle in a Box\nbarrier leads to the phenomenon of tunneling, which we explore in the next chapter. The wave function \nplots in Fig. 5.18 indicate that the barrier penetration is more pronounced for higher energy levels and \ncan become quite large for energies close to the top of the well. This aspect is clear quantitatively if we \nnote that the decay constant q in the forbidden region decreases as the energy increases, which means \nthat the decay length becomes larger, so more of the wave function is outside the well.\n 5.6.4 \u0002 Inversion Symmetry and Parity\nIn both square well problems, the allowed wave functions are either symmetric (even) or antisym-\nmetric (odd) with respect to the center of the well. In both cases, the potential energy well, and hence \nthe Hamiltonian, is symmetric with respect to the well center. We say that the Hamiltonian is invariant \nunder the parity operation x S -x. Because the Hamiltonian is invariant under the parity operation, \nit must commute with the parity operator, and hence the energy eigenstates are also eigenstates of \nthe parity operator. The symmetric states satisfy wn1x2 = +wn1-x2, have a parity eigenvalue +1, \nand are called even parity states. The antisymmetric states satisfy wn1x2 = -wn1-x2, have a parity \neigenvalue -1, and are called odd parity states. Identifying the parity of an energy eigenstate is useful \nbecause the parity of the state often indicates whether a particular matrix element involving that state \nis zero or not. For example, the probability of a transition between two energy eigenstates caused by \nincident laser light is proportional to the matrix element of the electric dipole operator (-ex in one \ndimension) between the two states:\n8wm 0\n -ex 0\n wn9 = -\nL\n\u0005\n- \u0005\nwm1x2ex wm1x2d 3r. \n(5.97)\nThis integral is zero if the integrand has odd parity. The electric dipole operator has odd parity, so the \nenergy eigenstates must have different parity for the transition to be allowed. If the integral is zero, then \nthe transition is a forbidden transition. Many of the selection rules that determine which transitions \nare allowed and which are forbidden come from these types of parity arguments. More complete dis-\ncussion of electric dipole transitions must wait until we discuss time-dependent perturbation theory in \nChapter 14.\n 5.6.5 \u0002 Orthonormality\nThe energy eigenstates form an orthonormal set, as we have found for other sets of eigenstates, such \nas spin states. The normalization is not an intrinsic property of the solutions but rather something that \nwe impose so that the total probability of ﬁnding the particle somewhere is unity. The orthogonality is \na fundamental trait of eigenstates of Hermitian operators. The orthonormality condition is expressed \nin Dirac notation as\n8En0 Em9 = dnm \n(5.98)\nand in wave function language as\nL\n\u0005","page_start":160,"page_end":160,"token_count":664,"section_type":"other","chapter_number":5,"chapter_title":"Quantized Energies: Particle in a Box","chunk_index":207}
{"chunk_id":"08c3ddd6bb7c6257","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"as spin states. The normalization is not an intrinsic property of the solutions but rather something that \nwe impose so that the total probability of ﬁnding the particle somewhere is unity. The orthogonality is \na fundamental trait of eigenstates of Hermitian operators. The orthonormality condition is expressed \nin Dirac notation as\n8En0 Em9 = dnm \n(5.98)\nand in wave function language as\nL\n\u0005\n- \u0005\nw*\nn 1x2wm1x2dx = dnm. \n(5.99)\nThis condition is straightforward to show for the inﬁnite well states (Problem 5.12) but is a little tedious \nfor the ﬁnite well states because of the lack of a general expression for the allowed wave vectors.","page_start":160,"page_end":160,"token_count":170,"section_type":"other","chapter_number":5,"chapter_title":"Quantized Energies: Particle in a Box","chunk_index":208}
{"chunk_id":"04f89f0b195545a7","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"5.7 Superposition States and Time Dependence \n137\n 5.6.6 \u0002 Completeness\nThe energy eigenstates form a complete basis, as we have found for other sets of basis states. Com-\npleteness is also a fundamental trait of eigenstates of Hermitian operators. Completeness means \nthat we can use these basis functions to construct all possible solutions to the Schrödinger equation \nH0 c9 = iU d 0 c9>dt for this problem. The wave function of a general superposition state is\n \nc1x2 = a\nn\ncn\n wn1x2. \n(5.100)\nNote that the energy eigenvalue equation Hwn1x2 = En\n wn1x2 is satisﬁed by each particular energy \neigenstate in turn but is not satisﬁed by general superposition states. For the inﬁnite well, Eq. (5.100) \nis exact, while for the ﬁnite well we must also include unbound energy states above the well in the sum \nover basis states. Obviously, for a well that is so small that there is only one bound state, we would \nexpect to need more states to form a complete basis. The completeness relation is also called the clo-\nsure relation and, as we saw in the spins problem, is expressed as a sum of all the projection operators\n \na\nn\n0 En98En0 = 1, \n(5.101)\nwhere the right-hand side is understood to be the identity operator\n 5.7 \u0002 SUPERPOSITION STATES AND TIME DEPENDENCE\nSolving for the energy eigenvalues and eigenstates is an important aspect of any problem, but it is not \nthe only goal. As physicists, our aim is to predict the future of a physical system. In quantum mechan-\nics, we do this through the Schrödinger equation\n \nH0 c9 = iU d\ndt\n 0 c9 \n(5.102)\nthat governs the time evolution of any quantum system. Though different systems clearly have differ-\nent Hamiltonians, we need not solve the Schrödinger equation for the time evolution separately for \neach system. We have already solved it in Chapter 3 for a time-independent Hamiltonian, where we \nfound that the most general time-dependent solution to the Schrödinger equation is\n \n0 c1t29 = a\nn\ncn\n e-iEnt>U0 En9. \n(5.103)\nThat is, the energy eigenstates form the preferred basis in which to expand a general quantum state \nvector, with the time evolution determined by phase factors dependent on the energy of each compo-\nnent state. In a general superposition, each energy eigenstate acquires a different phase. It is critical \nto remember that one must use the energy basis in order to use this simple recipe for time evolu-\ntion. This is why we spend much of our time ﬁnding energy eigenstates.\nTo use Eq. (5.103) we need to know the expansion coefﬁcients cn for the particular state in ques-\ntion. The quantum state at time t = 0 is\n \n0 c 1029 = a\nn\ncn0 En9, \n(5.104)\n","page_start":161,"page_end":161,"token_count":695,"section_type":"other","chapter_number":6,"chapter_title":"Unbound States","chunk_index":209}
{"chunk_id":"4195261998151c75","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"138 \nQuantized Energies: Particle in a Box\nso the expansion coefﬁcients cn are determined by the initial state of the system. The coefﬁcients cn are \nthe probability amplitudes for the state 0 c1029 to be in the energy eigenstates 0 En9\n \ncn = 8En0 c1029. \n(5.105)\nTo show this again, we perform a manipulation with the closure relation in Eq. (5.101). The identity \noperator does not change the state vector, so we act on the state vector to obtain\n \n 0 c1029 = 10 c1029\n \n \n = e a\nn\n0 En98En0f 0 c1029 \n \n = a\nn\n0 En98En0 c1029\n \n \n = a\nn\n8En0 c1029 0 En9\n \n \n(5.106)\nand hence identify the coefﬁcients cn as given in Eq. (5.105).\nOf course, once we know the probability amplitudes, we can calculate the probabilities for mea-\nsuring the system to have one of the energy eigenvalues:\n \nPEn = 08En0 c1029 0\n2 = 0 cn0\n2. \n(5.107)\nWe showed in Chapter 3 that the probabilities of energy measurements are time independent, but let’s \ndo it again here, using the time-dependent state vector in Eq. (5.103)\n \nP En = 08En0 c1t29 0\n2 \n \n = `8En0 a\nm\ncm0 Em9e-iEmt>U `\n2\n= ` a\nm\ncm8En0 Em9e-iEmt>U `\n2\n \n \n = ` a\nm\ncmdmne-iEmt>U `\n2\n= 0 cne-iEnt>U0\n2 \n \n = 0 cn0\n2.\n \n \n(5.108)\nThe Kronecker delta from the energy eigenstate orthonormality condition collapses the sum to a single \nterm. Time independence of the energy probabilities implies that the expectation value of the energy is \nalso time independent:\n \n8H9 = a\nn\nPEnEn = a\nn\n0 cn0\n2En. \n(5.109)\n","page_start":162,"page_end":162,"token_count":492,"section_type":"other","chapter_number":6,"chapter_title":"Unbound States","chunk_index":210}
{"chunk_id":"1ffdffebafce97b3","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"5.7 Superposition States and Time Dependence \n139\nWe can also show this by explicit calculation with the time-dependent states:\n \n 8H9 = 8c1t2 0 H0 c1t29\n \n \n = a\nm\nc*\nm8Em0 eiEmt>UHa\nn\ncn0 En9e-iEnt>U \n \n = a\nm,n\nc*\nmcneiEmt>Ue-iEnt>U8Em0 H0 En9\n \n \n = a\nm,n\nc*\nmcnei 1Em-En2 t>U En8Em0 En9\n \n \n = a\nm,n\nc*\nmcnei 1Em-En2 t>U Endmn\n \n \n = a\nn\nc*\nncnEn\n \n \n = a\nn\n0 cn0\n2\n En.\n \n \n(5.110)\nNote that we had no need to use wave function notation in these calculations. Wave function calcula-\ntions of Eqs. (5.108) and (5.110) would require spatial integrals that would also yield the Kronecker \ndelta from the energy eigenstate orthonormality condition that collapses the sums. The results would \nclearly be the same, so the message is: if you can avoid integrals by using Dirac notation instead of \nwave function notation, do so.\nWe need to use wave function language to answer questions about the spatial distribution of the \nparticle, so let’s use the rules we developed in Section 5.3 to translate the Dirac notation equations \nto wave function notation. The time evolution of the state vector [Eq. (5.103)], in wave function \nlanguage, is\n \nc1x, t2 = a\nn\ncn\n wn1x2e-iEnt>U. \n(5.111)\nTo ﬁnd the expansion coefﬁcients cn (i.e., the probability amplitudes), we translate Eq. (5.105) to wave \nfunction language:\n \ncn =\n \nL\n\u0005\n- \u0005\nw*\nn1x2c1x, 02dx. \n(5.112)\nSo, given the initial wave function of the system c1x, 02, the expansion coefﬁcients are overlap inte-\ngrals between each energy eigenstate and the initial wave function. These overlap integrals are analo-\ngous to the integrals used to ﬁnd Fourier expansion coefﬁcients. Let’s brieﬂy illustrate the Fourier \napproach for calculating the coefﬁcients cn. Set the time equal to zero in Eq. (5.111) to ﬁnd the initial \nwave function superposition:\n \nc1x, 02 = a\nn\ncn\n wn1x2. \n(5.113)\n","page_start":163,"page_end":163,"token_count":604,"section_type":"other","chapter_number":6,"chapter_title":"Unbound States","chunk_index":211}
{"chunk_id":"0efdc43e28379542","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"140 \nQuantized Energies: Particle in a Box\nProject both sides of Eq. (5.113) onto the energy eigenstates by multiplying each side by w*\nm1x2 and \nintegrating over all space:\n \n \nL\n\u0005\n- \u0005\nw*\nm1x2c1x, 02dx =\n \nL\n\u0005\n- \u0005\nw*\nm1x2 a\nn\ncn\n wn1x2dx  \n \n = a\nn\ncn L\n\u0005\n- \u0005\nw*\nm1x2wn1x2dx \n(5.114)\n \n = a\nn\ncndnm\n \n \n = cm,\n \n \nyielding\n \ncm =\n \nL\n\u0005\n- \u0005\nw*\nm1x2c1x, 02dx \n(5.115)\nas we expected from Eq. (5.112). Once we have the wave function expansion coefﬁcients in the energy \nbasis, we can predict the future time evolution of the system. Then we can calculate any physical quan-\ntities we need to, such as probabilities and expectation values.\nExample 5.4 Consider a particle in an inﬁnite square well with the initial wave function\n \nc 1x, 02 = A J a x\nLb\n3\n- 11\n7\n a x\nLb\n2\n+ 4\n7\n a x\nLb R  \n(5.116)\nin the interval 0 6 x 6 L and zero elsewhere, as shown in Fig. 5.20. Find (i) the wave function at a \nlater time, (ii) the probabilities of energy measurements, and (iii) the expectation value of the energy.\n(i) First we must normalize the state to ﬁnd the constant A:\n \n 8c0 c9 = 1 =\n \nL\nL\n0\n0 c 1x, 020\n2\n dx\n \n \n = 0 A0\n2\nL\nL\n0\n J a x\nLb\n3\n- 11\n7\n a x\nLb\n2\n+ 4\n7\n a x\nLb R\n2\n dx = 0 A0\n2\n L\n735. \n(5.117)\nWe choose the constant to be real and positive and the normalized wave function is\n \nc1x, 02 = B\n735\nL  J a x\nLb\n3\n- 11\n7\n a x\nLb\n2\n+ 4\n7\n a x\nLb R. \n(5.118)\nNow perform the overlap integral to ﬁnd the expansion coefﬁcients:\n \n cn = 8En0 c9 =\n \nL\n\u0005\n- \u0005\nw*\nn 1x2  c 1x, 02dx\n \n \n =\n \nL\nL\n0 B\n2\nL\n sin anpx\nL b B\n735\nL  J a x\nLb\n3\n- 11\n7\n a x\nLb\n2\n+ 4\n7\n a x\nLb Rdx . \n(5.119)\n","page_start":164,"page_end":164,"token_count":681,"section_type":"other","chapter_number":6,"chapter_title":"Unbound States","chunk_index":212}
{"chunk_id":"81279d68b25569d3","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"5.7 Superposition States and Time Dependence \n141\nDo the integral\n \n cn = 7230\nL\n b c3L \n1npx>L2\n2 - 2\n1np24\n sin anpx\nL b - L \n1npx>L2\n3 - 61npx>L2\n1np24\n cos anpx\nL bd\nL\n0\n \n \n -   11\n7\n c 2L \n1npx>L2\n1np23\n sin anpx\nL b - L \n1npx>L2\n2 - 2\n1np23\n cos anpx\nL b d\nL\n0\n \n(5.120)\n \n + 4\n7\n c L \n1\n1np22 sin anpx\nL b - L \n1npx>L2\n1np22\n cos anpx\nL b d\nL\n0\nr .\nEvaluate the limits and simplify:\n \n cn = 322 + 201-12\nn4230\n1np23\n \n \n = e\n2230\n1np2\n3  , if n is odd\n42230\n1np2\n3\n , if n is even .\n \n(5.121)\nThe ﬁrst few coefﬁcients are\n \nc1 = 0.3533  \n \nc2 = 0.9274  \n \nc3 = 0.0131  \n \nc4 = 0.1159 , \n(5.122)\nso the state is composed mostly of the ﬁrst excited state, which is evident from the shape of the \nwave function in Fig. 5.20.\nL/2\nL\nx\nΨ(x)\nFIGURE 5.20 An initial state wave function [Eq. (5.116)] in the inﬁnite square well.\n","page_start":165,"page_end":165,"token_count":391,"section_type":"other","chapter_number":6,"chapter_title":"Unbound States","chunk_index":213}
{"chunk_id":"785cd8ba51cf859a","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"142 \nQuantized Energies: Particle in a Box\nThe wave function at later times is the superposition with each energy state evolved at its pre-\nscribed frequency\n \n c 1x, t2 = a\n\u0005\nn=1\ncn\n wn 1x2  e-iEnt = a\n\u0005\nn=1\ncnA\n2\nL\n sin npx\nL\n e-i n2p2Ut>2mL2 \n \n = A\n60\nL a\n\u0005\nn=1\n322 + 201-12\nn4\n1np2\n3\n sin npx\nL\n e-i n2p2Ut>2mL2.\n \n(5.123)\n(ii)  The probabilities of measuring the energy eigenvalues are the squares of the expansion \ncoefﬁcients:\n \n PEn = 08En0 c\n 1t290\n2 = 0 cn0\n2\n \n \n =\n30\n1np26 322 + 201-12\nn4\n2\n \n \n =\n120\n1np26 3221 + 2201-12\nn4. \n(5.124)\nThe energy probabilities are shown in the histogram in Fig. 5.21, reﬂecting the predominance of the \nsecond state.\n(iii) The expectation value of the energy is\n \n 8H9 = a\nn\nPEnEn = a\nn\n0 cn0\n2\n En\n \n \n = a\n\u0005\nn=1\n120\n1np26 1221 + 2201-12\nn2an2p2  U2\n2mL2 b\n \n \n =\na\n\u0005\nn=1,3,5...\n120\n1np26 an2p2U2\n2mL2 b +\na\n\u0005\nn=2,4,6...\n12014412\n 1np26\n an2p2U2\n2mL2 b \n \n =\n60U2\np4mL2 c\na\n\u0005\nn=1,3,5...\n 1\nn4 + 441 \na\n\u0005\nn=2,4,6...\n 1\nn4 d\n \n \n =\n60U2\np4mL2 c p4\n96 + 441 p4\n1440 d\n \n \n = 19 U2\nmL2 = 38\np2 E1 \u0002 3.85E1 ,\n \n(5.125)\nwhich is slightly smaller than the energy (E2 = 4E1) of the ﬁrst excited state, as expected from the \nhistogram in Fig. 5.21.\n","page_start":166,"page_end":166,"token_count":569,"section_type":"other","chapter_number":6,"chapter_title":"Unbound States","chunk_index":214}
{"chunk_id":"cc3695dc4a69d179","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"5.7 Superposition States and Time Dependence \n143\nNotice that the energy expectation value, such as we calculated in Eq. (5.125), is time inde-\npendent regardless of whether the system is in an energy eigenstate or a general superposition of \nenergy eigenstates. On the other hand, the expectation values of position or momentum are time \nindependent when the system is in an energy eigenstate, but they are time dependent for a general \nsuperposition state. Let’s demonstrate this in the inﬁnite square well where the time dependence of \na general state is\n \nc 1x, t2 = a\nn\ncnA\n2\nL\n sin npx\nL\n e-i n2p2Ut>2mL2 . \n(5.126)\nConsider a simple superposition of two states in an inﬁnite well. If the initial state is\n \n0 c 1029 =\n1\n12 0 E19 +\n1\n12 0 E29, \n(5.127)\nthen the time-evolved state is\n \n0 c 1t29 =\n1\n12 0 E19e-iE1t>U +\n1\n12 0 E29e-iE2t>U. \n(5.128)\nThe wave function representation is\n \n c 1x, t2 =\n1\n12 w11x2e-iE1t>U +\n1\n12 w21x2e-iE2t>U\n \n \n = A\n1\nL\n c sin px\nL\n e-iE1t>U + sin 2px\nL\n e-iE2t>U d . \n \n(5.129)\nNow ﬁnd the expectation value of the position:\n \n 8x9 = 8c 1t2 0 x0 c 1t29\n \n \n = E 1\n12 8E10 eiE1t>U +\n1\n12 8E20 eiE2t>UF\n \nx E 1\n12 0 E19e-iE1t>U +\n1\n12 0 E29e-iE2t>UF\n (5.130)\n \n = 1\n2 38E10 x0 E19 + 8E20 x0 E29 + 8E10 x0 E29ei1E1-E22t>U + 8E20 x0 E19e-i1E1-E22t>U4. \nE1\nE2\nE3\nE4\nE\n0.5\n1.0\nP\nPE1\nPE2\nPE3\nPE4\nFIGURE 5.21 Histogram of the probabilities of energy measurements.\n","page_start":167,"page_end":167,"token_count":573,"section_type":"other","chapter_number":6,"chapter_title":"Unbound States","chunk_index":215}
{"chunk_id":"376be84ff9a4c7a9","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"144 \nQuantized Energies: Particle in a Box\nAgain notice that we are using Dirac notation to simplify the calculation. However, at this point we \nneed to use integrals to calculate the matrix elements. Let’s deﬁne them in general:\n \n 8x9n = 8En0 x0 En9 =\n \nL\nL\n0\nw*\nn1x2  x wn1x2dx =\n \nL\nL\n0\nx0 wn1x2 0 2 dx \n \n 8x9nk = 8En0 x0 Ek9 =\n \nL\nL\n0\nw*\nn1x2  x wk1x2dx . \n \n(5.131)\nWe calculated the ﬁrst matrix element, which is the expectation value of position in an energy eigen-\nstate, in Example 5.3. We saw that the answer is the midpoint of the well L>2. The second integral \ncomes from the cross term in the superposition:\n \n 8x9nk =\n \nL\nL\n0\nw*\nn1x2  x wk1x2dx\n \n \n = 2\nL L\nL\n0\n sin anpx\nL b x sin akpx\nL b dx \n \n = 2\nL\n a L\npb\n2\nL\np\n0\ny sin1ny2 sin1k y2 dy . \n \n(5.132)\nSimplify with a trig identity and integrate\n \n 8x9nk = 2\nL\n a L\npb\n2\nL\np\n0\ny 1\n2 3 cos1n - k2y -  cos1n + k2y4dy\n \n \n = 1\nL\n a L\npb\n2\n c\n cos1n - k2y\n1n - k22\n+\ny sin1n - k2y\n1n - k2\n-\n cos1n + k2y\n1n + k22\n-\ny sin1n + k2y\n1n + k2\nd\np\n0\n \n \n = 1\nL\n a L\npb\n2\n c\n cos1n - k2p\n1n - k22\n-\n cos1n + k2p\n1n + k22\n-\n1\n1n - k22 +\n1\n1n + k22d ,\n \n(5.133)\nyielding\n \n8x9nk =\n-4Lnk\np21n2 - k222 C1 - 1-12\nn+kD . \n(5.134)\nThis result is zero for states where n + k is even (i.e., if the states have the same parity). The results for \nthe two-state example are\n \n 8x91 = 8x92 = L\n2\n \n \n 8x912 = 8x921 = -  16L\n9p2 , \n \n(5.135)\n","page_start":168,"page_end":168,"token_count":627,"section_type":"other","chapter_number":6,"chapter_title":"Unbound States","chunk_index":216}
{"chunk_id":"dfc4a6e03f13a0a9","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"5.7 Superposition States and Time Dependence \n145\ngiving the ﬁnal result\n \n 8x9 = 8c1t2 0 x0 c1t29\n \n \n = 1\n2\n c L\n2 + L\n2 - 16L\n9p2 ei 1E1-E22 t>U - 16L\n9p2 e-i 1E1-E22 t>U d  \n \n = L\n2\n c 1 - 32\n9p2 cos a 3p2U\n2mL2 tb d .\n \n(5.136)\nThe position of this two-state superposition oscillates at the Bohr frequency 1E2 - E12>U.\nThe time-dependent position is also evident in the spatial probability density:\n \n P1x, t2 = 08x0 c1t290\n2 = 0 c1x, t20\n2\n \n \n = ` A\n1\nL\n c  sin px\nL\n e-iE1t>U +  sin 2px\nL\n e-iE2t>U d `\n2\n \n \n = 1\nL\n csin2 px\nL +  sin2 2px\nL\n+ 2 sin px\nL\n sin 2px\nL\n cos 1E2 - E12t\nU\nd . \n(5.137)\nThe oscillation of the probability density is depicted in the animation frames shown in Fig. 5.22, \nwhere the constant t is the oscillation period t = 2p>vBohr (see activity on time evolution of inﬁnite \nwell solutions). The superposition probability distribution “sloshes back and forth” in the well at the \nBohr frequency. This motion of the superposition state provides a model for how atoms and other \nbound systems radiate light. An electron undergoing this oscillatory motion accelerates and hence \nradiates electromagnetic energy. So far, our model does not account for the energy loss from this \nradiation, but we will address that in Chapter 14.\n0\nL/2\nL\nt/\u0004 = 0.0\nt/\u0004 = 0.1\nt/\u0004 = 0.2\nt/\u0004 = 0.3\nt/\u0004 = 0.4\nt/\u0004 = 0.5\nFIGURE 5.22 Time dependence of the probability distribution of a superposition state.\n","page_start":169,"page_end":169,"token_count":527,"section_type":"other","chapter_number":6,"chapter_title":"Unbound States","chunk_index":217}
{"chunk_id":"5c0a1050cb817f98","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"146 \nQuantized Energies: Particle in a Box\nA calculation of the momentum expectation value (Problem 5.27) also yields a time-dependent result:\n \n 8  p9 = 8c1t20 p0 c1t29\n \n \n =\n \nL\nL\n0\nc*1x, t2aU\ni\n  d\ndxb c 1x, t2dx \n \n = 8\n3 U\nL\n sin a 3p2U\n2mL2 tb.\n \n(5.138)\nIf we compare Eqs. (5.136) and (5.138), we notice that the quantum mechanical position and momen-\ntum obey the classical relation p = mv, provided we restrict the relation to expectation values:\n \n8p1t29 = m \nd 8x1t29\ndt\n. \n(5.139)\nThis is another example of Ehrenfest’s theorem, which says that quantum mechanical expectation \nvalues obey classical laws.\n 5.8 \u0002 MODERN APPLICATION: QUANTUM WELLS AND DOTS\nThe square well potential problem has been a staple of quantum mechanics textbooks since the early \ndays. However, for many years it was only a textbook problem because no systems in nature could be \nmodeled accurately as a square well. The progress of semiconductor fabrication technology has changed \nthat, as we are now able to make artiﬁcial systems of square potential energy wells. Semiconductor \nquantum wells are now routinely used to fabricate diode lasers and other semiconductor devices.\nThe key advance that allowed fabrication of quantum well devices was the ability to grow pure \ncrystals of semiconductors using techniques such as molecular beam epitaxy (MBE) and metal-\norganic chemical vapor deposition (MOCVD). With these techniques, layers of semiconductors can be \ngrown with atomic scale precision, yielding structures with layers thin enough (several nm or less) for \nquantum effects to be important.\nA typical quantum well structure is shown in Fig. 5.23(a). Alternate layers of GaAs and AlGaAs \nare grown epitaxially on a GaAs substrate. GaAs and AlGaAs have similar crystal unit cell sizes that \npermit dislocation-free crystals to be grown. This lattice-matched growth is crucial to obtaining reli-\nGaAs substrate\nAlGaAs\nGaAs\nAlGaAs\nGaAs\nsubstrate\nAlGaAs\nGaAs\nAlGaAs\nconduction band\nvalence band\nEg\nGaAs\nEg\nAlGaAs\nVc(x)\nVv(x)\n(b)\n(a)\nFIGURE 5.23 (a) Structure and (b) potential energy diagram of a GaAs quantum well.\n","page_start":170,"page_end":170,"token_count":578,"section_type":"other","chapter_number":6,"chapter_title":"Unbound States","chunk_index":218}
{"chunk_id":"74ceefd3fe15102e","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"5.9 Asymmetric Square Well: Sneak Peek at Perturbations \n147\nable devices. The band gap of GaAs (1.42 eV) is smaller than the band gap of AlGaAs (2.67 eV), so the \nelectrons in the conduction band and the holes in the valence band experience the different potentials \nshown in Fig. 5.23(b). Because the layers change on the atomic scale, this is as close to a square well \nas nature allows.\nWe can calculate the energy levels in the well using the same analysis we used for the ﬁnite square \nwell. Figure 5.24 shows the energy levels and how they vary with changes in the GaAs layer thickness. \nNote that there are only two or three bound states in the well for the range of thickness shown.\nFor making practical devices with quantum wells, there are two important features. First, the \nenergy levels can be adjusted, or “tuned,” by changing the thickness of the quantum well layer, as \nshown in Fig. 5.24, or by changing the stoichiometry of the surrounding AlxGa1 -  xAs layers to adjust \nthe band gap and hence the potential energy depth of the well. Second, the quantization of the electron \nenergy in the conﬁned well increases the number of electrons with speciﬁc energies (compared to the \ncontinuum of energies of unconﬁned electrons), which in turn increases the probability of creating \nphotons with the corresponding wavelengths. Hence, a semiconductor diode laser made with quantum \nwells is more efﬁcient than one made with bulk material, so quantum well diode lasers are now the \nmost common type of diode lasers in use.\nThe quantum well structure shown in Fig. 5.23 conﬁnes the electron in one dimension, but the \nelectrons are not conﬁned in the plane of the thin well. Further conﬁnement leads to quantum wires \n(2D conﬁnement) and quantum dots (3D conﬁnement). Quantum dots are semiconductor nanocrys-\ntals with a typical size range of 2–20 nm. The size of the dot determines the conﬁnement size and \nhence the wavelength of light emitted by the dot. A simple Web search reveals beautiful pictures of \nquantum dots glowing in a rainbow of colors.\n 5.9 \u0002 ASYMMETRIC SQUARE WELL: SNEAK PEEK AT PERTURBATIONS\nWhile the square potential wells we have studied in this chapter illustrate many of the ideas of bound \nstate wave functions, there is one important aspect that we have not encountered. All the square well \nsolutions have a constant wave vector and a constant wave function amplitude throughout the well, \nbecause the potential is constant throughout the well. To see how the wave vector and amplitude of \n5\n10\n15\n20 Well width (nm)\n20\n40\n60\n80\n100\nEnergy (meV)\n\u00021\u0003\n\u00022\u0003\n\u00023\u0003\nFIGURE 5.24 Energy levels in a GaAs quantum well as the thickness of the GaAs layer is changed.\n","page_start":171,"page_end":171,"token_count":668,"section_type":"other","chapter_number":6,"chapter_title":"Unbound States","chunk_index":219}
{"chunk_id":"7896553282c87157","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"148 \nQuantized Energies: Particle in a Box\nan eigenstate can vary within the well, let’s make a slight modiﬁcation to the inﬁnite square well. \nConsider the well shown in Fig. 5.25, which is commonly referred to as the asymmetric square \nwell. By adding a “shelf” within the well, we now have two regions of constant but different poten-\ntial energy.\nThe potential energy for this asymmetric square well is\n \nV1x2 = μ\n\u0005,\n0,\nV0,\n\u0005,\n      \nx 6 0\n0 6 x 6 L>2\nL>2 6 x 6 L\nx 7 L.\n  \n(5.140)\nWe know that the inﬁnite potential outside the well demands that the energy eigenstates are zero outside \nthe well. Inside the well, we now have different energy eigenvalue equations in the left and right halves:\n \n a-  U2\n2m d 2\ndx2 + 0b wE 1x2 = EwE 1x2,    left half\n \n \n a-  U2\n2m d 2\ndx2 + V0b wE 1x2 = EwE 1x2, \n right half. \n \n(5.141)\nFor this discussion, let’s assume that the energy E is greater than the potential V0 so that the \nsolutions in each half of the well are sinusoidal. We then have different wave vectors in each half, \ndeﬁned by\n \n k1 = B\n2mE\nU2 , \n left half\n \n \n k2 = B\n2m 1E - V02\nU2\n,    right half, \n \n(5.142)\nwhich yields a smaller wave vector 1k2 6 k12 and hence larger wavelength of the wave in the right \nhalf. We know that the left-half solution must be a sine function in order to match the zero wave func-\ntion outside the well, so the general solution is\n \nwE 1x2 = e\nA sin k1x ,\nB sin k2x + C cos k2x ,   0 6 x 6 L>2\nL>2 6 x 6 L. \n(5.143)\n0\nL/2\nL\nV0\nx\nV(x)\n\u0002\nFIGURE 5.25 Asymmetric square well.\n","page_start":172,"page_end":172,"token_count":520,"section_type":"other","chapter_number":6,"chapter_title":"Unbound States","chunk_index":220}
{"chunk_id":"eb245049cc0eeec6","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"5.9 Asymmetric Square Well: Sneak Peek at Perturbations \n149\nNow we apply the boundary condition on the wave function continuity at the middle and right side of \nthe well and the boundary condition on the continuity of the ﬁrst derivative of the wave function at the \nmiddle of the well (recall that the inﬁnite potential on the right means that the derivative condition is \nnot applicable). The three boundary conditions are\n wE 1L>22: A sin1k1L>22 = B sin1k2L>22 + C cos1k2L>22\n dwE1x2\ndx\n2\nx=L>2\n: k1A cos1k1L>22 = k2B cos1k2L>22 - k2C sin1k2L>22 \n wE 1L2: B sin k2L + C cos k2L = 0.\n(5.144)\nThese three equations contain four unknowns: the amplitudes A, B, and C, and the energy E through \nthe wave vectors k1 and k2. The normalization condition supplies the fourth equation required to solve \nfor all unknowns. By eliminating the amplitude coefﬁcients from the three boundary condition equa-\ntions, we arrive at a transcendental equation for the energy eigenvalues (Problem 5.28):\nk1 cos1k1L>22sin1k2L>22 + k2 cos1k2L>22sin1k1L>22 = 0. \n(5.145)\nThis looks a bit intimidating, so how do we know it’s correct? Well, we know what the solutions are \nfor the inﬁnite (symmetric) square well, which is the case where V0 = 0; so we can check to see if our \nsolution agrees with the inﬁnite square well solutions. This won’t tell us whether our solution is cor-\nrect, but we can at least make sure that it is not obviously wrong. If V0 = 0, then the two wave vectors \nare equal and the transcendental equation becomes:\n k1cos1k1L>22sin1k1L>22 + k1 cos1k1L>22sin1k1L>22 = 0 \n k1 sin31k1L>22 + 1k1L>224 = 0\n k1 sin k1L = 0.\n(5.146)\nIf we divide this result by k1, then we have the same equation  sin k1L = 0 that we had for the inﬁnite \nsquare well. So our intimidating result may well be correct.\nIn order to compare the asymmetric square well with the inﬁnite square well, it is useful to divide \neach transcendental equation by the factor k1 and plot the energy eigenvalue equations for the asym-\nmetric square well\ncos1k1L>22sin1k2L>22 + k2\nk1\n cos1k2L>22sin1k1L>22 = 0 \n(5.147)\nand for the inﬁnite square well:","page_start":173,"page_end":173,"token_count":671,"section_type":"other","chapter_number":6,"chapter_title":"Unbound States","chunk_index":221}
{"chunk_id":"4402122c7d341943","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"In order to compare the asymmetric square well with the inﬁnite square well, it is useful to divide \neach transcendental equation by the factor k1 and plot the energy eigenvalue equations for the asym-\nmetric square well\ncos1k1L>22sin1k2L>22 + k2\nk1\n cos1k2L>22sin1k1L>22 = 0 \n(5.147)\nand for the inﬁnite square well:\nsin1k1L2 = 0. \n(5.148)\nA plot of the two equations as a function of k1L is shown in Fig. 5.26 for the case where the potential \nstep height is 0.75 times the energy of the ground state in the inﬁnite well case. The inﬁnite square well \neigenstates occur at the values k1L = np marked on the axis. The eigenstates for the asymmetric well \nare each slightly larger, with the difference decreasing as the energy increases. This is a sneak preview \nof perturbation theory that we will study in Chapter 10.\nLet’s now use these solutions to draw the energy eigenstates. A plot of a typical energy eigen-\nstate is shown in Fig. 5.27. The wavelength and the amplitude of the wave in the right half are larger, \nmeaning that the probability to ﬁnd the particle in the right half is larger than in the left half. This is \nconsistent with our classical expectation, because a classical particle moves more slowly in the right \nhalf where its kinetic energy is lower, and so it spends more time in the right half with an increased \nprobability to ﬁnd it there.","page_start":173,"page_end":173,"token_count":355,"section_type":"other","chapter_number":6,"chapter_title":"Unbound States","chunk_index":222}
{"chunk_id":"cbfc6e377850dca3","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"150 \nQuantized Energies: Particle in a Box\n 5.10 \u0002 FITTING ENERGY EIGENSTATES BY EYE OR BY COMPUTER\n 5.10.1 \u0002 Qualitative (Eyeball) Solutions\nThe problems we have solved in this chapter illustrate most of the important features of bound states in \npotential wells. Using these common traits allows us to make qualititative estimates of energy eigen-\nstate solutions to other potential well problems. The important features are\n 1(a). Oscillatory wave solution inside well\n 1(b). Wavelength proportional to 1> 2E - V1x2\n 2(a). Exponentially decaying solution outside well\n 2(b). Decay length proportional to 1> 2V1x2 - E\n3.  Amplitude inside well related to wavelength\n4.  Match wE1x2 and dwE1x2>dx at boundaries.\nUsing these rules of thumb, we can get a very good idea of the wave function before we tackle the dif-\nferential equation that gives us the exact solution.\nConsider the potential shown in Fig. 5.28. It has an inﬁnite wall, a ﬂat potential region, a sloped \npotential region, and a ﬁnite wall. Given our rules, we draw the approximate wave function. From left \nx\nE7\n0\nL/2\nL\nV0\nFIGURE 5.27 An energy eigenstate of the asymmetric square well.\nΠ\n2Π\n3Π\n4Π\nk1L\nF(k1L)\nFIGURE 5.26 Transcendental equations for the energy eigenvalues of \nthe asymmetric square well (solid) and the inﬁnite square well (dashed).\n","page_start":174,"page_end":174,"token_count":380,"section_type":"other","chapter_number":6,"chapter_title":"Unbound States","chunk_index":223}
{"chunk_id":"2c42e3559ed17132","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"5.10 Fitting Energy Eigenstates by Eye or by Computer \n151\nto right, starting at zero at the inﬁnite wall, the wave function oscillates with a constant wavelength and \nhas a constant amplitude over the ﬂat potential region; it oscillates with an increasing wavelength and \nhas an increasing amplitude over the sloped potential region; and then it exponentially decays in the \nclassically forbidden region. The wave function is drawn qualitatively and the main features are indi-\ncated. This wave function represents the 17th energy state because there are 17 antinodes in the wave \nfunction. Remember that the wave function oscillates about the value zero in the well and decays to \nzero outside the well. The ﬁgure shows the wave function c1x2 drawn superimposed on the potential \nwell, so you have to imagine a “c axis” with its zero as indicated by the dashed line.\n 5.10.2 \u0002 Numerical Solutions\nWe can be more quantitative by using a computer to help us “draw” the wave functions. Rather than \nfollow the rules listed above, we directly solve the energy eigenvalue equation by numerical integra-\ntion, which is a common technique for solving differential equations and is easily accomplished in \ncommon mathematical packages like Matlab, Mathematica, and Maple, and even in a spreadsheet. The \nenergy eigenvalue equation is\n \nd 2wE1x2\ndx2\n= -  2m\nU2  3E - V1x24wE1x2. \n(5.149)\nYou may not yet know how to solve such a differential equation, but you do know how to solve a very \nsimilar one—Newton’s second law, F = ma, which yields the differential equation\n \nd 2x\ndt 2 = F\nm. \n(5.150)\nIn the case where the acceleration a = F>m is constant, one integral of Eq. (5.150) gives\n \nv = dx\ndt = v0 + at, \n(5.151)\nE,Ψ\nMatch Ψ\nMatch Ψ,dΨ\u0005dx\nOscillating wave\nExponential decay\nConstant Λ,\namplitude\nIncreasing Λ,\namplitude\nΨ\u0007\b\u0007\t\n0\nL/2\nL\nV0\nV0/2\nx\nFIGURE 5.28 Drawing approximate energy eigenstate solutions.\n","page_start":175,"page_end":175,"token_count":517,"section_type":"other","chapter_number":6,"chapter_title":"Unbound States","chunk_index":224}
{"chunk_id":"8390d9d4239035d2","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"152 \nQuantized Energies: Particle in a Box\nand a second integration gives\nx = x0 + v0\n t + 1\n2\n at 2, \n(5.152)\nwhich are the equations of motion you learned in introductory physics. With these equations, one can \npredict the future if one knows the initial position x0, the initial velocity v0, and the acceleration a.\nIn the Newtonian case, the motion function x(t) is determined by its curvature d 2x>dt 2, which is \nthe acceleration a. In the quantum case, the wave function is determined by its curvature d 2c>dx 2, which \ndepends on the energy, the potential, and the wave function itself. The potential and the wave function \nboth depend on position, so the wave function curvature is not constant and the simple integrations in \nEqs. (5.151) and (5.152) cannot be used. However, if the acceleration in the Newtonian example is not \nconstant, then we can modify Eqs. (5.151) and (5.152) for use on a computer by using them to predict \nmotion only in the very near future, say from t to t + \u0006t:\n x1t + \u0006t2 = x1t2 + v1t2\u0006t + 1\n2\n a1t21\u0006t2\n2 \n v1t + \u0006t2 = v1t2 + a1t2\u0006t.\n(5.153)\nAs long as we choose the time steps \u0006t small enough that the acceleration does not vary appreciably from \none time step to the next, then these equations can be used to reliably update the position and velocity at \neach time step. These update equations produce estimates of the full motion by iterating from step to step.\nThis method works well but suffers from one failing: the update equations use “old” information \nabout the velocity and the acceleration. We can improve this slightly by using the new acceleration in \nthe velocity update equation:\n x1t + \u0006t2 = x1t2 + v1t2\u0006t + 1\n2\n a1t21\u0006t2\n2\n v1t + \u0006t2 = v1t2 + 1\n2 3a1t2 + a1t + \u0006t24\u0006t. \n(5.154)\nWe can’t use the new acceleration in the position update equation because the acceleration typically \ndepends on position (through the potential), so we do the position update ﬁrst and then the modiﬁed \nvelocity update. This method is known as the velocity Verlet algorithm and yields more reliable \nresults than Eq. (5.153).\nTo solve the energy eigenvalue equation, we use the wave function and its spatial derivatives \nrather than the position and its time derivatives used in the Newtonian case. Thus, we generalize the \nposition and velocity update equations (5.154) to\n wE1x + \u0006x2 = wE1x2 + adwE\ndx b\nx  \n\u0006x + 1\n2","page_start":176,"page_end":176,"token_count":665,"section_type":"other","chapter_number":6,"chapter_title":"Unbound States","chunk_index":225}
{"chunk_id":"2f2ef5f454d71d94","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"results than Eq. (5.153).\nTo solve the energy eigenvalue equation, we use the wave function and its spatial derivatives \nrather than the position and its time derivatives used in the Newtonian case. Thus, we generalize the \nposition and velocity update equations (5.154) to\n wE1x + \u0006x2 = wE1x2 + adwE\ndx b\nx  \n\u0006x + 1\n2\n ad 2wE\ndx2 b\nx\n1\u0006x2\n2\n adwE\ndx b\nx+\u0006x\n= adwE\ndx b\nx\n+ 1\n2\n c a d 2wE\ndx2 b\nx\n+ ad 2wE\ndx2 b\nx+\u0006x\nd \u0006x. \n(5.155)\nSo, given the wave function (analogous to “position”), the slope of the wave function (“velocity”), and \nthe curvature of the wave function (“acceleration”) at any position x (“time”), we can predict the wave \nfunction and its slope at the next position x + \u0006x. At each step we calculate the wave function curva-\nture using the energy eigenvalue equation\nd 2wE1x2\ndx2\n= -  2m\nU2  3E - V1x24wE1x2. \n(5.156)","page_start":176,"page_end":176,"token_count":304,"section_type":"other","chapter_number":6,"chapter_title":"Unbound States","chunk_index":226}
{"chunk_id":"fd122f9bac8ad576","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"5.10 Fitting Energy Eigenstates by Eye or by Computer \n153\nWe don’t have to impose the continuity conditions on wE1x2 and dwE1x2>dx at boundaries; the \nupdate equations guarantee that they are met. What we do need are initial values of the wave function \nand the ﬁrst derivative to get the update equations started. In principle, we should start at x = - \u0005 \nand integrate (i.e., update) all the way to x = + \u0005. In practice, it sufﬁces to start a reasonable way \ninto the left-hand forbidden region, integrate into and through the potential well, and then integrate \na reasonable way into the right-hand forbidden region. The wave function in the forbidden region \nshould be decaying toward zero as it approaches x = { \u0005, which indicates how we should choose \nthe initial values of the wave function and the ﬁrst derivative. Recall, however, that the energy eigen-\nvalue equation is linear in the wave function wE1x2, so we can scale the wave function by any factor \nand it will still solve the differential equation. This means that we can choose the initial wave function \narbitrarily, but the resultant wave function will not be normalized. In principle, the initial wave func-\ntion slope should be chosen to have the appropriate decay length. In practice, the method is insensitive \nto this choice.\nNotice that the calculation of the wave function curvature from the energy eigenvalue equation \n(5.156) requires us to know the energy. But we don’t know the energy—we are trying to ﬁnd it! So we \nguess a value of the energy and then we solve for the resultant wave function and see if it “ﬁts” into the \npotential well. From the problems above we have plenty of practice recognizing wave functions that \nﬁt, so it should be clear. And it is, as you will see.\nAs an example of how this numerical technique works, let’s try it out on the ﬁnite square well \nand compare to the results in Eq. (5.89). We choose an energy and start integrating with Eq. (5.155). \nThis is well suited to a spreadsheet, and the results shown in Fig. 5.29 are from an Excel worksheet. \nThe trademark results of this technique are illustrated in Fig. 5.29(a). If the chosen energy does not \nmatch an energy eigenstate solution, then as we integrate toward x = + \u0005 the wave function solution \nthat should decay starts to grow exponentially, because as the integration crossed the boundary into \nthe classically forbidden region (at x = a) there was a small component of the growing exponential \nsolution contained in the numerical wave function. Only by choosing the energy exactly equal to one \nof the allowed energies can this “bad” component be eliminated from the integration. Because of the \nseverity of exponential growth, combined with the discreteness of computer calculations, it is impos-\nsible to ﬁnd the energy solution exactly. However, as Fig. 5.29 illustrates, you can ﬁnd nearby energies ","page_start":177,"page_end":177,"token_count":655,"section_type":"other","chapter_number":6,"chapter_title":"Unbound States","chunk_index":227}
{"chunk_id":"fa300c4602d231ab","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"solution contained in the numerical wave function. Only by choosing the energy exactly equal to one \nof the allowed energies can this “bad” component be eliminated from the integration. Because of the \nseverity of exponential growth, combined with the discreteness of computer calculations, it is impos-\nsible to ﬁnd the energy solution exactly. However, as Fig. 5.29 illustrates, you can ﬁnd nearby energies \nthat cause the wave function to grow either negatively [Fig. 5.29(a)] or positively [Fig. 5.29(c)]. These \nsolutions then bracket the approximate solution [Fig. 5.29(b)]. The ﬁnite square well used for the cal-\nculation in Fig. 5.29 is the same as the well used for Fig. 5.16, and the resultant energy eigenvalue of \nthis fourth energy level matches well with the result in Eq. (5.89). To obtain a more accurate value, one \nhas to be more careful about the initial conditions.\nΨ(x)\nΨ(x)\nΨ(x)\n(a)\n(b)\n(c)","page_start":177,"page_end":177,"token_count":231,"section_type":"other","chapter_number":6,"chapter_title":"Unbound States","chunk_index":228}
{"chunk_id":"b7c79df2b3974b28","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"a\na\nx\n\na\na\nx\n\na\na\nx\nE = 27.30454\nE = 27.30455\nE = 27.30456\nFIGURE 5.29 Numerical integration for solution of the ﬁnite square well eigenvalue equation.\n","page_start":177,"page_end":177,"token_count":64,"section_type":"other","chapter_number":6,"chapter_title":"Unbound States","chunk_index":229}
{"chunk_id":"53e488ecc42c1494","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"154 \nQuantized Energies: Particle in a Box\n 5.10.3 \u0002 General Potential Wells\nGiven our approximate and numerical techniques, we can solve for the bound states in any potential \nwell, in principle. A typical bound state solution is shown in Fig. 5.30. It exhibits the key features that \nwe have mentioned above for bound state solutions:\n• Oscillatory in allowed region\n• Exponential decay in forbidden region\n• Oscillatory wave becomes less wiggly near classical turning point as kinetic energy \ndecreases\n• Amplitude becomes larger near classical turning points\nThus, though potential energy wells may appear quite different at ﬁrst glance, they all can be \ncalled “particle-in-a-box” systems, albeit with differently shaped boxes. Some common boxes are \nshown in Fig. 5.31: (a) inﬁnite square well, (b) ﬁnite square well, (c) harmonic oscillator (mass on a \nspring), and (d) linear potential (bouncing ball potential).\nSUMMARY\nIn this chapter we learned the language of the wave function, which is the representation of the quan-\ntum state vector in position space. We express this as\n \n 0 c9 \u0003 c1x2  \n \n c1x2 = 8x0 c9. \n(5.157)\nThe complex square of the wave function yields the spatial probability density\n \nP1x2 = 0 c1x20\n2. \n(5.158)\nThe normalization condition is\n \n1 = 8c@ c9 =\n \nL\n\u0005\n- \u0005\n@ c1x2@\n2 dx = 1. \n(5.159)\nThe rules for translating bra-ket formulae to wave function formulae are:\n1) Replace ket with wave function \n0 c9 S c1x2\n2) Replace bra with wave function conjugate \n8c0 S c*1x2\n3) Replace bracket with integral over all space \n8@ 9 S\n \nL\n\u0005\n- \u0005\n dx\n4) Replace operator with position representation \nAn S A1x2.\nThe probability of measuring the position of a particle to be in a ﬁnite spatial region is\n \nPa6x6b =\n \nL\nb\na\n0 c1x20\n2 dx. \n(5.160)\n","page_start":178,"page_end":178,"token_count":502,"section_type":"other","chapter_number":6,"chapter_title":"Unbound States","chunk_index":230}
{"chunk_id":"c797d96f6512c313","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"Summary \n155\nx\nE,Ψ\nFIGURE 5.30 Bound state in a generic potential energy well.\n0\n(a)\nL/2\nL\nx\n0\n(b)\n\na\na\nx\nx\n(c)\nx\n(d)\nFIGURE 5.31 Different versions of the particle-in-a-box: (a) inﬁnite square well, \n(b) ﬁnite square well, (c) harmonic oscillator (quadratic potential), and (d) linear potential.\n","page_start":179,"page_end":179,"token_count":107,"section_type":"other","chapter_number":6,"chapter_title":"Unbound States","chunk_index":231}
{"chunk_id":"0407603f9c1a067c","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"156 \nQuantized Energies: Particle in a Box\nThe probability of measuring the energy to be En is\n \nPEn = @8En@ c9@\n2 = 2\nL\n\u0005\n- \u0005\nw*\nn1x2c1x2dx 2\n2\n, \n(5.161)\nwhere wn1x2 = 8x0 En9 is the wave function representation of the energy eigenstate.\nPosition and momentum operators in the position representation are\n \n xn \u0003 x\n \n \n pn \u0003 -iU d\ndx \n(5.162)\nand lead to the energy eigenvalue equation becoming a differential equation:\n \na-  U2\n2m d 2\ndx2 + V1x2\n b wE1x2 = EwE1x2. \n(5.163)\nIn solving the energy eigenvalue equation, two boundary conditions are imposed upon the wave function:\n1) wE1x2 is continuous\n2) \ndwE1x2\ndx\n is continuous unless V = \u0005.\nIn an inﬁnite square potential energy well, the allowed energies are\n \nEn = n2p2\n U2\n2mL2\n ,   n = 1, 2, 3, ..., \n(5.164)\nand the allowed energy eigenstates are\n \nwn1x2 = A\n2\nL\n sin  npx\nL ,   n = 1, 2, 3, ... . \n(5.165)\nThe energy eigenstates obey the following properties:\nProperty\nDirac notation\nWave function notation\nNormalization\n8En0En9 = 1\nL\n\u0005\n- \u0005\n0wn1x20\n2dx = 1\nOrthogonality\n8En0Em9 = dnm\nL\n\u0005\n- \u0005\nw*\nn1x2wm1x2dx = dnm\nCompleteness\n0c9 = a\nn\ncn0En9\nc1x2 = a\nn\ncnwn1x2\nPROBLEMS\n 5.1 Show that the operators xn and pn do not commute.\n 5.2 A particle in an inﬁnite square well potential has an initial state vector \n0 c1t = 029 = A10 w19- 0 w29 + i0 w392 where 0 wn9 are the energy eigenstates.\n","page_start":180,"page_end":180,"token_count":512,"section_type":"other","chapter_number":6,"chapter_title":"Unbound States","chunk_index":232}
{"chunk_id":"da7fd1179731fbec","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"Problems \n157\na) Normalize the state vector.\nb)  What are the possible outcomes of a measurement of the energy, and with what probabilities \nwould they occur?\nc) What is the average value of the energy?\nd) Find the state vector at some later time, t.\ne)  At time t = U>E1, what are the possible outcomes of a measurement of the energy, and with \nwhat probabilities would they occur?\n 5.3 Solve the inﬁnite square well problem using the complex exponential form of the general solu-\ntion in Eq. (5.53) as the assumed form of the wave function inside the well. Assume that the \npotential well boundaries are at x = 0 and x = L.\n 5.4 Solve the inﬁnite square well problem with the well boundaries at x = {a. Comment on the \ndifferences and similarities with the solution in the text.\n 5.5 Calculate the expectation values and the uncertainties of position and momentum for the inﬁ-\nnite square well energy eigenstates.\n 5.6 For a particle in an inﬁnite square well, calculate the probability of ﬁnding the particle in the \nrange 3L>4 6 x 6 L for each of the ﬁrst three energy eigenstates.\n 5.7 A particle in an inﬁnite square well potential has an initial state vector \n0 c1t = 029 = 10 w19 - 2i0 w292> 15 where the 0 wn9 are the eigenfunctions of the Hamiltonian \noperator. Find the time evolution of the state vector.\n 5.8 A particle in an inﬁnite square well potential has an initial wave function \nc1x, t =\n 02 = Ax1L - x2. Find the time evolution of the state vector. Find the expectation \nvalue of the position as a function of time.\n 5.9 A particle in an inﬁnite square well has the initial wave function\nc1x, 02 = A c a x\nLb\n3\n-\n 3\n2\n a x\nLb\n2\n+ 1\n2\n a x\nLbd \n in the interval 0 6 x 6 L and zero elsewhere. Find (a) the wave function at a later time, (b) the \nprobabilities of energy measurements, and (c) the expectation value of the energy.\n 5.10 A particle at t = 0 is known to be in the right half of an inﬁnite square well with a probability \ndensity that is uniform in the right half of the well. What is the initial wave function of the par-\nticle? Calculate the expectation value of the energy. Find the probabilities that the particle is \nmeasured to have energy E1, E2, or E3.\n 5.11 A particle is in the ground state of an inﬁnite square well. The potential wall at x = L suddenly \nmoves to x = 3L such that the well is now three times its original size. Find the probabilities ","page_start":181,"page_end":181,"token_count":654,"section_type":"other","chapter_number":6,"chapter_title":"Unbound States","chunk_index":233}
{"chunk_id":"7d656860dc33947a","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"ticle? Calculate the expectation value of the energy. Find the probabilities that the particle is \nmeasured to have energy E1, E2, or E3.\n 5.11 A particle is in the ground state of an inﬁnite square well. The potential wall at x = L suddenly \nmoves to x = 3L such that the well is now three times its original size. Find the probabilities \nthat the particle is measured to have the ground state energy or the ﬁrst excited state energy of \nthe new well.\n 5.12 Show that the energy eigenstates of the inﬁnite square well are orthogonal.\n 5.13 Use the closure relation in Eq. (5.101) to show that the normalization condition is\n1 = 8c@ c9 = a\nn\n@8En@ c9@\n2. \n 5.14 Solve the energy eigenvalue problem for the ﬁnite square well without using the symmetry \nassumption and show that the energy eigenstates must be either even or odd.","page_start":181,"page_end":181,"token_count":217,"section_type":"other","chapter_number":6,"chapter_title":"Unbound States","chunk_index":234}
{"chunk_id":"67761990e19f11b1","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"158 \nQuantized Energies: Particle in a Box\n 5.15 Derive the transcendental equation (5.85) for the energy eigenvalues of the odd states in the \nﬁnite square well.\n 5.16 Normalize the energy eigenstates of the ﬁnite square well.\n 5.17 Find the probability that a particle in the ground state of a ﬁnite square well is measured to \nhave a position outside of the well. Derive a general relation involving only the parameters z \nand z0 deﬁned in Eqs. (5.86). Show that the probability increases as the energy increases.\n 5.18 An electron is bound in a ﬁnite square well of depth V0 = 5 eV and width 2a = 1.5 nm. Find \nthe allowed energies of the bound states in the well using the transcendental equations (5.88).\n 5.19 Give a qualitative, graphical argument that the difference in energy eigenvalues between the \nﬁnite and inﬁnite square wells is larger for higher energy states.\n 5.20 Find the bound energy eigenstates and eigenvalues of a “half-inﬁnite” square well (i.e., a \nsquare well with inﬁnite potential for x 6 0 and ﬁnite potential with value V0 for x 7 L).\n 5.21 Consider a quantum system with a set of energy eigenstates 0 Ei9. The system is in the state\n0 c9 =\n1\n130 0 E19 +\n2\n130 0 E29 +\n3\n130 0 E39 +\n4\n130 0 E49, \n where the energies are given by En = nE1. Find the probabilities for measuring the energy \neigenvalues and make a histogram similar to Fig. 5.2(b). Find the expectation value of the \nenergy. Find the uncertainty of the energy.\n 5.22 Consider a quantum system with a set of energy eigenstates 0 En9 where the energies are given \nby En = 1n + 1\n22U v for n = 0, 1, 2, ... . The system is in the state\n0 a9 = a\n\u0005\nn=0\nane-a2>2\n2n!\n0 En9, \n where a is a positive real number. Find the probabilities for measuring the energy eigenvalues \nand make a histogram similar to Fig. 5.2(b). Find the expectation value of the energy. Find the \nuncertainty of the energy.\n 5.23 Consider the following wave functions\n c1x2 = Ae-x2>3\n c1x2 = B \n1\nx2 + 2\n c1x2 = C secha x\n5b.\n In each case, normalize the wave function, plot the wave function, and ﬁnd the probability that \nthe particle is measured to be in the range 0 6 x 6 1.\n 5.24 Demonstrate the requirement that the ﬁrst derivative of the wave function be continuous, ","page_start":182,"page_end":182,"token_count":650,"section_type":"other","chapter_number":6,"chapter_title":"Unbound States","chunk_index":235}
{"chunk_id":"e6c6943208fcb487","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":" c1x2 = Ae-x2>3\n c1x2 = B \n1\nx2 + 2\n c1x2 = C secha x\n5b.\n In each case, normalize the wave function, plot the wave function, and ﬁnd the probability that \nthe particle is measured to be in the range 0 6 x 6 1.\n 5.24 Demonstrate the requirement that the ﬁrst derivative of the wave function be continuous, \nunless the potential is inﬁnite. To do this, integrate the energy eigenvalue equation from -e \nto +e and take the limit as e S 0 to derive a condition on the difference of the wave function \nderivatives between two adjacent points.\n 5.25 Find the energy eigenstates and eigenvalues of a particle conﬁned to a delta function potential \nV1x2 = -b d1x2, where b is a positive real constant. Note that you will need to follow the \napproach in the previous problem to properly address how the inﬁnite potential at the origin affects \nthe wave function derivative. How many bound energy states exist in this potential energy well?","page_start":182,"page_end":182,"token_count":248,"section_type":"other","chapter_number":6,"chapter_title":"Unbound States","chunk_index":236}
{"chunk_id":"f75c850570e32f9a","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"Resources \n159\n 5.26 Find the energy eigenstates and eigenvalues of a particle conﬁned to a double delta function \npotential V1x2 = -b 1d1x - a2 + d1x + a22, where b is a positive real constant. How many \nbound energy states exist in this potential energy well?\n 5.27 Calculate the expectation value of the momentum for the two-state superposition in Eq. (5.128) \nand verify Eq. (5.138).\n 5.28 Solve the boundary condition equations (5.144) for the asymmetric square well and verify \nEq. (5.145).\n 5.29 Find the transcendental equation that determines the energy eigenvalues in an asymmetric \nsquare well for the case E 6 V0. Compare with Eq. (5.145) for the E 7 V0 case and comment.\n 5.30 Implement the update equations (5.155) using a spreadsheet or other computer program and \nﬁnd the numerical solutions for the energy eigenvalues of a ﬁnite square well with a well \nparameter z0 = 6. Compare your results with Eq. (5.89).\n 5.31 Use a spreadsheet or other computer program to ﬁnd the numerical solution of the ground \nstate and ﬁrst excited state energy eigenvalues and wave functions for a ﬁnite square well with \nparameters V0 = 5 eV, 2a = 1.5 nm, and m = me. Compare your results with the transcen-\ndental equations (5.88).\n 5.32 Reproduce the results for the GaAs quantum well states shown in Fig. 5.24 using the transcen-\ndental equations (5.88). The relevant GaAs parameters are V0 = 0.1 eV and m = 0.067 me.\n 5.33 For each of the potential wells shown in Fig. 5.32, make a qualitative sketch of the two energy \neigenstate wave functions whose energies are indicated. For each energy state, identify the clas-\nsically allowed and forbidden regions. Discuss the important qualitative features of each state.\n 5.34 Sketch a copy of Fig. 5.30 and identify the classically allowed and forbidden regions. Which \nenergy eigenstate is drawn in Fig. 5.30? Make a similar plot for the next lower energy eigenstate.\nRESOURCES\nActivities\nThe bulleted activities are available at\nwww.physics.oregonstate.edu/qmactivities\n• Operators and Functions: Students investigate the differential forms of quantum mechanical \noperators and identify eigenfunctions and eigenvalues of quantum mechanical operators.\n• Solving the Energy Eigenvalue Equation for the Finite Well: Students solve the energy eigenvalue \nequation for different regions of the ﬁnite well and make their solutions match at the boundaries.\nE,Ψ\nx\nE11\nE4\nE,Ψ\nx\nE10\nE5\nFIGURE 5.32 Potential wells for Problem 5.33.\n","page_start":183,"page_end":183,"token_count":640,"section_type":"other","chapter_number":6,"chapter_title":"Unbound States","chunk_index":237}
{"chunk_id":"ad8497183bcc0a1d","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"160 \nQuantized Energies: Particle in a Box\n• Time Evolution of Inﬁnite Well Solutions: Students animate wave functions consisting of linear \ncombinations of eigenstates.\nQuantum Bound States: This simulation experiment from the PHET group at the \nUniversity of Colorado animates wave function superpositions in bound states: \nhttp://phet.colorado.edu/en/simulation/bound-states\nShooting Method Model: This program from the Open Source Physics group implements \nthe shooting method to numerically solve the energy eigenvalue equation: \nhttp://www.compadre.org/osp/items/detail.cfm?ID=6987\nFurther Reading\nQuantum wells are discussed in these Physics Today articles:\nD. Chemla, “Quantum wells for photonics,” Phys. Today 38(5), 57–64 (1985): \nhttp://dx.doi.org/10.1063/1.880974\nD. Gammon, D. Steel, “Optical studies of single quantum dots,” Phys. Today 55(10), 36–41 (2002): \nhttp://dx.doi.org/10.1063/1.1522165\nFurther details on numerical solutions of the energy eigenvalue equation are available in these \nreferences:\nR. H. Landau, M. J. Páez and C. C. Bordeianu, A Survey of Computational Physics: Introductory \nComputational Science, Princeton, NJ: Princeton University Press, 2008.\nH. Gould, J. Tobochnik, and W. Christian, An Introduction to Computer Simulation Methods: \n Applications to Physical Systems (3rd edition), San Francisco, CA: Addison-Wesley, 2007.\n","page_start":184,"page_end":184,"token_count":356,"section_type":"other","chapter_number":6,"chapter_title":"Unbound States","chunk_index":238}
{"chunk_id":"148fa99709172489","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":" \n161\nC H A P T E R \n6\nUnbound States\nIn the last chapter we learned how to use the new concept of wave functions to describe the motion of \na particle in a potential well. We found that states corresponding to particles conﬁned within the poten-\ntial well had quantized energies. We now turn our attention to unbound states, and we will ﬁnd that the \nenergies are no longer quantized. The simplest case is that of the free particle with no potential affect-\ning the particle motion at all. The free particle states help us better understand the wave-particle dual-\nity of quantum mechanics. We then consider the case of particles that are affected by potentials but are \nnot bound. This includes potential wells where the energy is larger than the well depth and cases where \nthe potential has no localized minimum. Studying these unbound states is important in understanding \nscanning tunneling microscopy, nuclear alpha decay, and the scattering of particles.\nIn all cases, we are still charged with solving the energy eigenvalue equation\n \nHn 0 E9 = E0 E9 \n(6.1)\nwith the Hamiltonian operator\n \nHn = pn2\n2m\n + V 1xn2. \n(6.2)\nAs we did in the last chapter, we work in wave function language (i.e., in the position representation), \nand so the energy eigenvalue equation becomes a differential equation:\n \n HnwE 1x2 = EwE 1x2  \n \n a-  U2\n2m\n d 2\ndx 2 + V  1x2b  wE 1x2 = EwE 1x2  \n \n -  U2\n2m\n d 2\ndx2 wE 1x2 + V 1x2wE 1x2 = EwE 1x2. \n \n(6.3)\n6.1 \u0002 FREE PARTICLE EIGENSTATES\n6.1.1 \u0002 Energy Eigenstates\nFor a free particle, the potential energy function V1x2 is zero everywhere and the energy eigenvalue \ndifferential equation is\n \nd 2\ndx2 wE 1x2 =  -  2mE\nU2  wE 1x2. \n(6.4)\n","page_start":185,"page_end":185,"token_count":497,"section_type":"other","chapter_number":6,"chapter_title":"Unbound States","chunk_index":239}
{"chunk_id":"cd82ed240652ffb9","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"162 \nUnbound States\nThis is the same differential equation we solved in Chapter 5 inside the square potential energy well. \nAgain, it is convenient to deﬁne a wave vector\nk2 = 2mE\nU2  \n(6.5)\nand write the differential equation as\nd 2\ndx2 wE 1x2 =  -k2wE 1x2. \n(6.6)\nThe solutions to this differential equation are the familiar sinusoidal functions, which we can \nexpress either as the trigonometric functions sin kx and cos kx or the complex exponential functions \ne+ikx and e-ikx. Note that the energy E must be positive, so the wave vector is real for this problem. It \nis more convenient in this problem to use the complex exponential functions, so we write the general \nsolution to the energy eigenvalue equation as\nwE 1x2 = Ae+ikx + Be-ikx, \n(6.7)\nwhere we need to account for both possible signs of the wave vector and A and B are normalization \nconstants.\nThe critical physical difference between a free particle 1with V1x2 = 02 and a bound particle is \nthe lack of a conﬁning potential. Because the wave function of the free particle is not required to “ﬁt” \ninto the potential energy well, there are no limitations on the wave functions and hence no quantization \nof the energy. Mathematically, there are not enough constraints on the two normalization constants A \nand B and the energy E (through the wave vector k). There are three unknowns in Eq. (6.7), but the \nnormalization condition is the only constraining equation. The result is that the energy is a continuous \nvariable, not quantized, in contrast to the bound-state solutions in Chapter 5. The continuous nature of \nthe energy has important ramiﬁcations, which we will explore. But ﬁrst, let’s look more closely at the \nphysics of quantum wave motion.\nTo understand free particle wave motion, let’s look at the time evolution of the energy eigenstates \nof Eq. (6.7). The time dependence of this state is obtained by applying the recipe for Schrödinger time \nevolution that we learned in Chapter 3. Because the state is already written in the energy basis, the \nSchrödinger time-evolution recipe says to multiply by a phase factor dependent on the energy of the \nstate, giving\n cE1x, t2 = wE1x2e-i Et>U\n = 1Aeikx + Be-ikx2e-i Et>U. \n(6.8)\nIf we use the Einstein energy relation E = U v, we can rewrite Eq. (6.8) in a suggestive way:\n cE1x, t2 = 1Aeikx + Be-ikx2e-ivt\n = Aei1kx-vt2 + Be-i1kx+vt2\n = Aeik1x-vt>k2 + Be-ik1x+vt>k2. ","page_start":186,"page_end":186,"token_count":668,"section_type":"other","chapter_number":6,"chapter_title":"Unbound States","chunk_index":240}
{"chunk_id":"cfa0849b0855e9e6","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"(6.8)\nIf we use the Einstein energy relation E = U v, we can rewrite Eq. (6.8) in a suggestive way:\n cE1x, t2 = 1Aeikx + Be-ikx2e-ivt\n = Aei1kx-vt2 + Be-i1kx+vt2\n = Aeik1x-vt>k2 + Be-ik1x+vt>k2. \n(6.9)\nThis quantum wave function has the same form we know from classical waves—a function f  1x { vt2 \nwith the argument 1x { vt2. This functional form represents a wave that retains its shape as it moves, \nand any given point on that shape moves with a speed determined by the parameter \r, which in this \ncase yields 0 v0 = v>k. For the sinusoidal waves of this free particle state, such points of constant \nphase move at the phase velocity. The energy eigenstate has two parts—the ei1kx-vt2 part moving in \nthe positive x-direction and the e-i1kx+vt2 part moving in the negative x-direction. So now we know ","page_start":186,"page_end":186,"token_count":252,"section_type":"other","chapter_number":6,"chapter_title":"Unbound States","chunk_index":241}
{"chunk_id":"5b3521a8307a9876","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"6.1 Free Particle Eigenstates \n163\nthat whenever we see a wave function with spatial dependence e{ikx, the sign of the wave vector in the \nexponent indicates the direction of motion. It is convenient to work with the wave  vector eigenstates\n \nwk1x2 = Aeikx \n(6.10)\nas long as we remember that we must use both positive and negative k values to make a general energy \neigenstate.\n6.1.2 \u0002 Momentum Eigenstates\nTo learn more about the phase velocity of the wave vector eigenstates, it is useful to study the momen-\ntum of these wave functions. Let’s operate on one of the states with the momentum operator, which is \na differential operator in the position representation:\n \n pnwk1x2 = a-iU d\ndxb Aeikx \n \n = -iU1ik2Aeikx\n \n \n = Ukwk1x2.\n \n \n(6.11)\nThus the action of the momentum operator on a wave vector eigenstate yields the same state with \na constant multiplier. Well, that is an eigenvalue equation! So the wave vector eigenstates are also \nmomentum eigenstates. The momentum eigenvalue equation is\n \npnwp1x2 =  pwp1x2 \n(6.12)\n 1 pn 0  p9 = p0  p9 in bra@ket notation2, so we have identiﬁed\n \np = Uk \n(6.13)\nas the momentum eigenvalue and\n \nwp1x2 = Aei px>U \n(6.14)\nas the momentum eigenstate. The momentum eigenstate wave function wp1x2 is a function of position \nand not of momentum—x is a variable and p is the particular momentum eigenvalue. The wave \nvector is related to the wavelength through k = 2p>l, so we can rewrite Eq. (6.13) as\n \np = h\nl  . \n(6.15)\nThis equation was introduced in the early days of quantum mechanics by Louis de Broglie and pro-\nvides the connection between the particle properties (momentum) and the wave properties (wave-\nlength) of a system. The de Broglie relation between momentum and wavelength is at the heart of \nthe wave-particle duality of quantum mechanics. We can turn Eq. (6.15) around to write an equation \ndeﬁning the de Broglie wavelength of a particle with momentum p:\n \nlde Broglie = h\np  . \n(6.16)\nThe momentum eigenstates are also energy eigenstates for the free particle, with energy [Eq. (6.5)]\n \nE = p2\n2m. \n(6.17)\n","page_start":187,"page_end":187,"token_count":581,"section_type":"other","chapter_number":6,"chapter_title":"Unbound States","chunk_index":242}
{"chunk_id":"cc29a5dfe7be7bef","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"164 \nUnbound States\nThe fact that the momentum and energy operators share eigenstates is an important aspect of the free \nparticle problem and is a consequence of the general rule we discussed in Section 2.4 that commuting \noperators have common eigenstates 1like Sz and S2 sharing 0{9 states2 (Problem 6.5). A given momen-\ntum eigenstate has a deﬁnite energy given by Eq. (6.17), but a given energy state does not necessarily \nhave a deﬁnite momentum, because a general energy eigenstate is a superposition of the two momentum \nstates 0  p9 \u0003 wp1x2 and 0  -p9 \u0003 w-p1x2 with opposite momenta, as in Eq. (6.7). Because a given \nenergy state corresponds to multiple momentum states, we say that the energy state is degenerate with \nrespect to momentum. In the free particle case, the energy states are two-fold degenerate. This is our \nﬁrst example of degeneracy, but it will be more common once we address two- and three-dimensional \nsystems in Chapter 7.\nThe wave nature of the quantum mechanical description of the free particle is evident in Fig. 6.1, \nwhich shows the wave function of a momentum eigenstate. It is evident that a single wavelength char-\nacterizes the wave function, consistent with the single momentum of the eigenstate and the de Broglie \nrelation between wavelength and momentum. The wave function is complex, so we must plot both the \nreal and imaginary parts to completely describe the state.\nLet’s now return to the question of the phase velocity of the free particle eigenstates. A momentum \neigenstate has time dependence\n \n cp1x, t2 = wp1x2e-i Ept>U\n \n \n = Aei px>U e-i p2t>2m U \n \n = Aei p>U1x-pt>2m2.  \n \n(6.18)\nThis wave is moving at a speed of v = p>2m, which is half the speed of a classical particle \nvclassical = p>m. This apparent contradiction exists because we are using the phase velocity of the \nwave. As we will see in Section 6.2, the proper way to use a wave to describe a particle leads us to the \nconcept of “group velocity of a wave packet” as the more appropriate velocity.\nA more serious problem with the momentum eigenstates becomes evident if we examine the prob-\nability density of the state. Taking the complex square of the wave function yields the probability density\n \nP1x2 = 0 wp1x20\n2\n \n \n = w*\np1x2wp1x2\n \n \n = A*e-i px>U Aei px>U \n \n = 0 A0\n2.\n \n \n(6.19)\nx\nRe \u000bp\u0007x\b\nx\nIm \u000bp\u0007x\b\n(a)\n(b)\nFIGURE 6.1 Momentum eigenstate. Both the (a) real and (b) imaginary parts of the wave \nfunction extend to {\u0005. A single wavelength characterizes the momentum eigenstate.\n","page_start":188,"page_end":188,"token_count":671,"section_type":"other","chapter_number":6,"chapter_title":"Unbound States","chunk_index":243}
{"chunk_id":"ce03589e7b3d06c8","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"6.1 Free Particle Eigenstates \n165\nAs shown in Fig. 6.2, the probability density of a momentum eigenstate is a constant independent of \nposition, extending to inﬁnity. This presents us with two problems. Conceptually, we expect a particle \nto be localized to a small region of space, not spread out over an inﬁnite region. Mathematically, we \ncannot normalize the momentum eigenstates because the integral of the probability density over all \nspace is inﬁnite. This is a new and quite serious problem. All previous basis states we have encoun-\ntered have been normalizable. This lack of normalizability is a pathology of all continuous bases—\nthis one being our ﬁrst example. Fortunately, there is a solution to this mathematical problem that \nalso solves our conceptual problem. By constructing superpositions of momentum eigenstates to make \nwave packets, we get wave functions that are normalizable and are localized to ﬁnite regions of space. \nBefore we construct wave packets, it is useful to discuss some of the mathematical properties of the \nmomentum eigenstates.\nWe expect a set of basis states to exhibit three important properties. The states should be: (1) nor-\nmalized, (2) orthogonal, and (3) complete. All the discrete basis sets we have encountered have satisﬁed \nthese conditions, which we express in Dirac notation as\n \n 8ai0 aj\u0002i9 = 0   orthogonality \n \n 8ai0 ai9 = 1   normalization \n \n a\ni\n0 ai98ai0 = 1   completeness, \n \n(6.20)\nassuming a set of discrete eigenstates 0 ai9. The orthogonality and normalization conditions are com-\nbined into one orthonormality equation by using the Kronecker delta:\n \n8ai0 aj9 = dij. \n(6.21)\nTo adapt this orthonormality equation to a continuous basis, we need to use the continuous analog \nof the discrete Kronecker delta, which is the Dirac delta function. The Dirac delta function, writ-\nten d1x - x02, is a function that is zero at every value of x, except at x = x0, where it is inﬁnite (not \nunity). This inﬁnity means that the Dirac delta function does not strictly represent the normalization \ncondition, but it is consistent with the inﬁnite norm we found for the momentum eigenstates above. \nThus, we expect that the “orthonormality” condition for a continuous basis set of momentum states is\n \n8p\u000e 0\n p\u00049 = d1 p\u000e - p\u00042 \n(6.22)\nx\n\u0002\u000bp(x)\u00022\nFIGURE 6.2 Position probability distribution for a momentum eigenstate.\n","page_start":189,"page_end":189,"token_count":602,"section_type":"other","chapter_number":6,"chapter_title":"Unbound States","chunk_index":244}
{"chunk_id":"cd6fcc6b94ccebea","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"166 \nUnbound States\nin Dirac notation. Using the rules developed in Chapter 5 for translating bra-ket notation to wave \n function notation, we express the inner product in Eq. (6.22) as an overlap integral\nL\n\u0005\n- \u0005\nw*\np\u000e1x2wp\u00041x2dx = d1 p\u000e - p\u00042. \n(6.23)\nThe momentum eigenstates deﬁned in Eq. (6.14) satisfy this new form of the  orthonormality \n equation, as long as we deﬁne the normalization constant A for the momentum eigenstates as \n (Problem 6.7)\nA =  \n1\n22pU\n. \n(6.24)\nAlthough continuous basis sets, such as the momentum basis, do not strictly satisfy the normalization \ncondition required by quantum mechanics, it is still practical to use Eqs. (6.22) and (6.23) to “normalize” \na basis, and we refer to this process as Dirac normalization. We thus write the “normalized” momen-\ntum eigenstates as\nwp1x2 =  \n1\n22pU\n ei px>U    . \n(6.25)\nIt is worth thinking about dimensions at this point. With the normalization of the momentum eigen-\nstates in Eq. (6.25), we see that the dimensions of the left hand side of Eq. (6.23) are 3length4>3U4, \nwhich from Eq. (6.16) are equivalent to 1>3p4 or inverse momentum. Thus, the Dirac delta function \nhas dimensions of the inverse of its argument. This is another difference from the Kronecker delta that \nwe have to live with.\nThe completeness of a basis implies that any function (relevant to the problem at hand) can \nbe written as a superposition of the basis states. Completeness is difﬁcult to prove mathematically, so we \ngenerally just assume that it is satisﬁed. In the discrete basis case, the completeness condition (closure \nrelation) in Eq. (6.20) is a sum of the projection operators over the discrete basis set. To change to a con-\ntinuous basis, we change the sum over the discrete label to an integral over the continuous label. For the \nmomentum eigenstates, the completeness condition is\nL\n\u0005\n- \u0005\n0  p98p0 dp = 1, \n(6.26)\nwhere we understand that the right hand side is the identity operator. To demonstrate how complete-\nness allows us to express any general state as a superposition of the basis states, insert Eq. (6.26) into \nthe Dirac expression for a wave function\n c1x2 = 8x0 c9\n = 8x0 b\nL\n\u0005\n- \u0005\n0  p98p0 dpr 0 c9 \n =\nL\n\u0005\n- \u0005\n8x0  p98p0 c9dp.\n(6.27)","page_start":190,"page_end":190,"token_count":652,"section_type":"other","chapter_number":6,"chapter_title":"Unbound States","chunk_index":245}
{"chunk_id":"fb26285c3518a6d6","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"ness allows us to express any general state as a superposition of the basis states, insert Eq. (6.26) into \nthe Dirac expression for a wave function\n c1x2 = 8x0 c9\n = 8x0 b\nL\n\u0005\n- \u0005\n0  p98p0 dpr 0 c9 \n =\nL\n\u0005\n- \u0005\n8x0  p98p0 c9dp.\n(6.27)\nThe ﬁrst term 8x0 p9 in the integrand is the projection of the momentum eigenstate 0  p9 onto the posi-\ntion basis, which is the wave function representation wp1x2 of the momentum eigenstate. The second \nterm 8p0 c9 in the integrand is the projection of the general state 0 c9 onto the momentum basis 0  p9 \n(i.e., the probability amplitude for the general state 0 c9 to have momentum p). Given the rules of Dirac ","page_start":190,"page_end":190,"token_count":214,"section_type":"other","chapter_number":6,"chapter_title":"Unbound States","chunk_index":246}
{"chunk_id":"c71b8deb974cc205","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"6.1 Free Particle Eigenstates \n167\nnotation, you might expect the probability amplitude 8p0 c9 to be written as 8p0 c9 = c 1 p2. However, \nthere is risk of confusion here with the wave function c1x2 because c1 p2 and c1x2 are not the same \nmathematical function with different arguments, but rather are different mathematical functions. To \navoid this possible confusion, it is common to use a different symbol for the momentum probability \namplitude, such as\nf1 p2 = 8p0 c9, \n(6.28)\nalthough such notation brings its own confusion between the different Greek symbols. The function \nf1 p2 is known as the momentum space wave function. As in the position case, the probability ampli-\ntude f1 p2 = 8p0 c9 is a continuous function that is the collection of numbers that represents the quan-\ntum state vector in terms of the momentum eigenstates. The wave function c1x2 and the momentum \nspace wave function f1 p2 are both representations of the state 0 c9, but they are representing that \nstate in different bases. Which basis we should use is up to us and is generally a matter of convenience \ndecided by what we wish to calculate. Using this deﬁnition of the momentum space wave function, we \nwrite Eq. (6.27) as\nc1x2 =\nL\n\u0005\n- \u0005\nwp1x2f1 p2dp, \n(6.29)\nwhich, in words, says that a general state 0 c9 \u0003 c1x2 can be decomposed into an integral (i.e., super-\nposition) over all momentum eigenstates 0  p9 \u0003 wp1x2 with a proportionality coefﬁcient given by the \nprobability amplitude f1p2 = 8p0 c9 for the general state to be measured in that particular momentum \nbasis state.\nIf we put the explicit form of the momentum eigenstates wp1x2 into Eq. (6.29), then the superposi-\ntion becomes\nc1x2 =  \n1\n22pU L\n\u0005\n- \u0005\nf1 p2ei px>U dp   . \n(6.30)\nThis should look familiar! It is the Fourier transform of the function f1 p2. Thus, quantum mechani-\ncal superpositions behave much like classical wave superpositions. In both cases, the Fourier trans-\nform represents a superposition of sinusoidal waves that combine to make a wave packet. We thus \nexpect that the connection in the opposite direction (i.e., writing the momentum space wave function \nin terms of the position space wave function) would be an inverse Fourier transform. We can show that \nthis is so by using our prescription for writing a probability amplitude in wave function language as an \noverlap integral. The momentum space wave function f1 p2 is a probability amplitude f1 p2 = 8p0 c9, \nand the rule for converting a Dirac bra-ket projection to wave function overlap integral is to convert the ","page_start":191,"page_end":191,"token_count":666,"section_type":"other","chapter_number":6,"chapter_title":"Unbound States","chunk_index":247}
{"chunk_id":"0451232cb668951d","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"in terms of the position space wave function) would be an inverse Fourier transform. We can show that \nthis is so by using our prescription for writing a probability amplitude in wave function language as an \noverlap integral. The momentum space wave function f1 p2 is a probability amplitude f1 p2 = 8p0 c9, \nand the rule for converting a Dirac bra-ket projection to wave function overlap integral is to convert the \nket 0 c9 to a wave function c1x2, the bra 8p0  to a wave function conjugate w*\np1x2 = e-i px>U> 12pU, and \nthen integrate over all space. Thus, we get\nf1 p2 =  \n1\n22pU L\n\u0005\n- \u0005\nc1x2e-i px>U dx   , \n(6.31)\nwhich we recognize as an inverse Fourier transform. Thus, we see that the connection between the \nmomentum space wave function f1 p2 and the (position space) wave function c1x2 is the Fourier \ntransform. As we saw in the spins case, we are free to use whichever representation of a quantum state \nvector that we ﬁnd most convenient. The position and momentum representations are similarly equally \nvalid representations. We focus on the position representation because it is generally the most useful.","page_start":191,"page_end":191,"token_count":287,"section_type":"other","chapter_number":6,"chapter_title":"Unbound States","chunk_index":248}
{"chunk_id":"462d7afbaf20b26a","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"168 \nUnbound States\n6.2 \u0002 WAVE PACKETS\nThe key result from the previous section is that Fourier superpositions of momentum eigenstates are \nrequired for proper representation of free particle states. Let’s ﬁrst consider a discrete Fourier series \nexample that illustrates many of the important features of wave packets, and then we’ll make a real \nwave packet using continuous Fourier transforms.\n6.2.1 \u0002 Discrete Superposition\nIn this example, we add just three momentum eigenstates together. We choose one “central” state \nwith momentum p0 to have twice the amplitude of two “side mode” states that are equally spaced at \np = p0 { dp about the central state, as shown in the momentum state distribution in Fig. 6.3. As the \ndashed line hints, we are using this three-mode superposition as a model of a continuous momentum \ndistribution characterized by a center momentum p0 and a momentum distribution width dp that we \nwill discuss in Section 6.2.2.\nA graphical representation of this three-state superposition of sinusoidal waves and the resultant \nwave is shown in Fig. 6.4. The different wavelengths of the three components lead to constructive and \ndestructive interference, as indicated in the plots. The resultant wave is localized to a region of space \nand hence is referred to as a wave packet. The wave packet shown in Fig. 6.4 has a characteristic \nwavelength determined by the central momentum, so it resembles a wave, but it also has a limited spa-\ntial extent, and so it also resembles a particle. In this case, we are using a discrete Fourier sum, so this \nlocalization is repeated periodically. For the more realistic continuum distribution, only one localized \nregion exists and a true wave packet is realized. The coexisting particle and wave characteristics of a \nwave packet are the essence of the wave-particle duality of quantum mechanics.\nTo understand the motion of the wave packet, we must study the time evolution. The wave func-\ntion at time t = 0 is given by the weighted superposition of the three momentum eigenstates\n \n c1x, 02 = a\nj\ncj wpj1x2\n \n \n c1x, 02 = a\nj\ncj \n1\n22pU\n ei pj\n x>U\n \n \n c1x, 02 =\n1\n22pU\n 31\n2 ei1 p0-dp2x>U + ei p0\n x>U + 1\n2 ei1 p0+dp2x>U4. \n \n(6.32)\np0 \n Δp\np0 \r Δp\np0\np\nΦ\u0007p\b\nFIGURE 6.3 Discrete momentum distribution used to model continuous distributions \nand to build a discrete wave packet.\n","page_start":192,"page_end":192,"token_count":595,"section_type":"other","chapter_number":6,"chapter_title":"Unbound States","chunk_index":249}
{"chunk_id":"dfdd07f4539f08b0","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"6.2 Wave Packets \n169\nThe time-dependent wave function representing this wave packet is obtained by following the Schrödinger \ntime-evolution recipe. Momentum eigenstates are also energy eigenstates of free particles, so the \nsuperposition is already written in the energy basis and we multiply each energy eigenstate by its own \nenergy-dependent phase factor:\n \nc1x, t2 = a\nj\ncj wpj1x2e-i Ej\n t>U. \n(6.33)\nThe energy of each momentum eigenstate is given by the free particle energy\n \nEj =\np2\nj\n2m, \n(6.34)\nwhich for the three states yields\n \n Ep0 =\np2\n0\n2m\n \n \n Ep0{dp = 1p0 { dp2\n2\n2m\n=\np2\n0 { 2p0dp + 1dp2\n2\n2m\n. \n \n(6.35)\nWe assume that the width of the momentum distribution is narrow enough that dp V p0 and so we \nneglect the small 1dp22 term in the energies. Hence, the time-evolved wave packet state is\n \nc1x, t2 =\n1\n22pU\n 31\n2\n ei1 p0-dp2x>U e-i1p2\n0 -2p0dp2t>2m  U + ei p0\n x>U e-i p2\n0\n t>2m  U + 1\n2\n ei1 p0+dp2x>U e-i1p2\n0 +2p0dp2t>2m  U4\n \nc1x, t2 =\n1\n22pU\n  ei p0\n x>U e-i p2\n0\n \n t>2m  U 31\n2\n e-idpx>U ei p0dpt>m  U + 1 + 1\n2\n eidpx>U e-i p0dpt>m  U4\n \nc1x, t2 =\n1\n22pU\n ei p0\n x>U e-i p2\n0\n \n t>2m U c 1 + cosadp\nU\n x - p0dp\nm U\n tb d , \n \n(6.36)\nDestructive Interference\nDestructive Interference\nConstructive Interference\n\r\n\r\n\b\nx\n0\nΔx\n\nΔx\nFIGURE 6.4 Discrete wave packet with three components.\n","page_start":193,"page_end":193,"token_count":536,"section_type":"other","chapter_number":6,"chapter_title":"Unbound States","chunk_index":250}
{"chunk_id":"100245987bfee4de","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"170 \nUnbound States\nwhich yields\n \nc1x, t2 =\n1\n22pU\n eip01x-p0t>2m2>UJ1 + cos adp\nU\n c x - p0\nm\n td b R. \n(6.37)\nThis wave packet contains the expected form f  1x { vt2 of a wave, but it has two such parts with \ndifferent arguments. The ﬁrst part of Eq. (6.37) (in curly brackets) is characterized by the momentum \np0 and hence wavelength l0 = h>p0 of the single harmonic wave. This part is called the carrier wave, \nand from its argument we ﬁnd that it moves at the phase velocity vph = p0>2m, as we discussed above. \nThe second part of the wave packet (in square brackets) is characterized by the momentum width dp \nand hence a wavelength lenv = h>dp that is much longer than l0 1because dp V p02. This second \npart is known as the envelope of the wave packet because it modulates the carrier wave, as shown in \nFig. 6.5. Because of the different arguments of the two parts, the envelope moves at a different  velocity \nvgp = p0>m from the carrier. This velocity is called the group velocity because it characterizes the \nvelocity of the group of waves together.\nThe different velocities are evident if the plot of the wave packet in Fig. 6.5 is animated \n( Problem 6.8). Several frames from such an animation are shown in Fig. 6.6, where you can see that \nthe velocity of the envelope—the group velocity—is twice the velocity of the wiggles within the \n envelope—the phase velocity. Notice that the group velocity is equal to the classical velocity of a par-\nticle with momentum p0. This is the sense in which this wave packet can properly represent the motion \nof a particle. This discrete superposition is a good starting point, but it still suffers from the pathologies \nof harmonic waves—it is not normalizable and it therefore cannot predict expectation values—so we \nmust use a continuous momentum distribution to model real experiments. Moreover, the “localiza-\ntion” of the discrete Fourier series superposition is repeated periodically, and so cannot represent a \nsingle particle.\nx\nΨ(x)\nEnvelope\nCarrier\nFIGURE 6.5 Wave packet showing the carrier wave and the modulation envelope.\n","page_start":194,"page_end":194,"token_count":521,"section_type":"other","chapter_number":6,"chapter_title":"Unbound States","chunk_index":251}
{"chunk_id":"32bcbeef3422569e","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"6.2 Wave Packets \n171\n6.2.2 \u0002 Continuous Superposition\nTo go from the discrete case to the continuous case, we change the superposition sum in Eq. (6.32) to \na superposition integral (i.e., we change the Fourier series to a Fourier integral or Fourier transform). \nWhile this may seem like a trivial extension, there are important differences. As we did in the dis-\ncrete case, we perform the expansion using the momentum eigenstate basis wp1x2 because these states \nare also energy eigenstates in the free particle example, which then sets us up to use the Schrödinger \ntime-evolution recipe. In the integral superposition, we specify the amplitudes of the momentum \neigenstate as a continuous distribution f1 p2 rather than specifying discrete amplitudes. Thus, we \nwrite the initial superposition state as\n \n c1x, 02 =\n \nL\n\u0005\n- \u0005\nf1 p2wp1x2dp\n \n \n =\n \nL\n\u0005\n- \u0005\nf1 p2 \n1\n22pU\n ei px>U dp, \n \n(6.38)\nwhere f1p2 is also called the momentum space wave function. The time-evolved state is found by fol-\nlowing the recipe for Schrödinger time evolution and including the energy dependent phase factors:\n \nc1x, t2 =\n \nL\n\u0005\n- \u0005\nf1 p2wp1x2e-iEp\n t>U dp. \n(6.39)\nFIGURE 6.6 Discrete wave packet animation with time increasing from top to bottom. \nOpen circles identify a point of constant phase, which moves at the phase velocity. Filled \ncircles identify the peak of the envelope, which moves at the group velocity.\n","page_start":195,"page_end":195,"token_count":387,"section_type":"other","chapter_number":6,"chapter_title":"Unbound States","chunk_index":252}
{"chunk_id":"38174318672f628d","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"172 \nUnbound States\nPutting in the explicit momentum eigenstate wave functions and the expression for the free particle \nenergy results in\nc1x, t2 =  \n1\n22pU L\n\u0005\n- \u0005\nf1 p2ei px>U e-i p2t>2m U dp, \n(6.40)\nwhich simpliﬁes to\nc1 x , t2 =  \n1\n22pU L\n\u0005\n- \u0005\nf1 p2ei p1x  - pt>2m2>U dp. \n(6.41)\nThis is the time-dependent generalization of the Fourier transform in Eq. (6.30) for the case of a free \nparticle. The time-dependent generalization of the inverse Fourier transform in Eq. (6.31) is\nf1 p, t2 =  \n1\n22pU L\n\u0005\n- \u0005\nc1x, t2e-i px>U dx. \n(6.42)\nTo evaluate the Fourier integral in Eq. (6.41) and determine the wave function for any particular case, \nwe need to know the particular momentum distribution f1p2, which may be speciﬁed as an initial \ncondition, or can be determined from the initial wave function c1x, 02 via the Fourier transform in \nEq. (6.31) that relates the spatial and momentum space wave functions.\nAs an example, consider the case of a Gaussian momentum distribution. This is a very common \nexample because Gaussian functions are easy to integrate—you get another Gaussian in the Fourier \nspace. In addition, the Gaussian distribution is a very good representation of many real experimental \nsituations. The Gaussian function is one of the standard classical probability distributions and is com-\nmonly written as\nf 1z2 =  e-1z-m2\n2>2s2\ns22p\n, \n(6.43)\nwhere m is the mean value or average of the distribution and s is the standard deviation of the distribu-\ntion. Relating these deﬁnitions to the quantum mechanical quantities, the mean value is the expectation \nvalue 8z9 and the standard deviation is the uncertainty \u0006z. The probability distribution in Eq. (6.43) is \nnormalized to unity:\nL\n\u0005\n- \u0005\nf 1z2dz = 1. \n(6.44)\nNotice that the function f 1z2 is not squared in the normalization integral in Eq. (6.44), contrary to \nthe normalization of quantum mechanical wave functions to which you have become accustomed. In \nquantum mechanics, we have to square the wave function to get the probability density, which is then \nnormalized, analogous to Eq. (6.44). So, technically speaking, the phrase “normalize the quantum \nmechanical wave function” is not correct, because we actually normalize the probability distribution, \nnot the wave function. But that phrase is ingrained into all practicing physicists, so we are stuck with it.","page_start":196,"page_end":196,"token_count":643,"section_type":"other","chapter_number":6,"chapter_title":"Unbound States","chunk_index":253}
{"chunk_id":"bd75d2dd480d5b70","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"quantum mechanics, we have to square the wave function to get the probability density, which is then \nnormalized, analogous to Eq. (6.44). So, technically speaking, the phrase “normalize the quantum \nmechanical wave function” is not correct, because we actually normalize the probability distribution, \nnot the wave function. But that phrase is ingrained into all practicing physicists, so we are stuck with it.\nJust as we did in the discrete case, let’s assume that the momentum distribution is peaked at p0 and \nhas a width characterized by a parameter b. The Gaussian momentum space wave function is\nf1 p2 = ¢\n1\n2pb2 ≤\n1>4\n e-1p-p02\n2>4b2, \n(6.45)","page_start":196,"page_end":196,"token_count":164,"section_type":"other","chapter_number":6,"chapter_title":"Unbound States","chunk_index":254}
{"chunk_id":"04c55216d2b54682","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"6.2 Wave Packets \n173\nwhere the scale factor ensures proper normalization. This momentum space wave function is shown in \nFig. 6.7, with the previous discrete case for comparison. The momentum probability distribution (per \nunit momentum) is the absolute square of the momentum space wave function:\n \nP1 p2 = 0 f1p20\n2 = e-1p-p02\n2>2b2\nb22p\n. \n(6.46)\nComparison of this quantum mechanical momentum probability distribution with the standard \n Gaussian probability function in Eq. (6.43) allows us to determine the momentum expectation value \n8p9 and momentum uncertainty \u0006p by inspection as\n \n 8p9 = p0 \n \n \u0006p = b . \n \n(6.47)\nThe time-evolved spatial wave function for this Gaussian wave packet is obtained by substituting \nEq. (6.45) into the Fourier transform in Eq. (6.41):\n \nc1x, t2 =\n1\n22pU L\n\u0005\n- \u0005\n¢\n1\n2pb2 ≤\n1>4\n e-1 p-p022>4b2 ei px>U e-i p2t>2m U dp. \n(6.48)\nThis integral can be performed using the standard Gaussian integral shown in Appendix F, Eq. (F.23): \n(Problem 6.9). The result is\n \nc1x, t2 =\n22b\n3Ug22p\n ei p01x-p0t>2m2>U e-1x-p0t>m2\n2b2>U2g, \n(6.49)\nwhere the new parameters are\n \n g = 1 +  it\nt\n \n t =  m U\n2b2 .  \n(6.50)\np\nΦ(p)\n2Β\np0 \u0004 Δp \np0 \u0006 Δp\np0\nFIGURE 6.7 Gaussian momentum space wave function.\n","page_start":197,"page_end":197,"token_count":426,"section_type":"other","chapter_number":6,"chapter_title":"Unbound States","chunk_index":255}
{"chunk_id":"6cce1386afef1f4e","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"174 \nUnbound States\nIf we deﬁne\n \na =\nU\n2b , \n(6.51)\nthen we can express the wave function as\n \nc1x, t2 = a\n1\n2pa2b\n1>4 1\n1g\n  ei p01x-p0t>2m2>U e-1x-p0t>m2\n2>4a2g, \n(6.52)\nwhere a is useful later as a measure of the width in position space.\nJust as in Eq. (6.37) for the discrete momentum distribution, this wave packet has a carrier wave \npart (in curly brackets) that is characterized by p0 and propagates at the phase velocity p0>2m, and \nan envelope part (in square brackets) that is characterized by the momentum width b (through the a \nparameter) and propagates at the group velocity p0>m. As we expected, the envelope is a Gaussian \nfunction. To isolate the envelope propagation, calculate the spatial probability density by taking the \nsquare modulus of the wave function:\n \nP1x, t2 = 0 c1x, t20\n2 =  \n1\n22pa\u000f\n e-1x -p0t>m2\n2>2a2\u000f2, \n(6.53)\nwhere we have deﬁned a new parameter\n \n\u000f = 30 g0\n2 = B1 + t2\nt2 . \n(6.54)\nThe only velocity that appears in the probability density is the group velocity p0>m, which agrees \nwith our classical expectation that the particle propagates at this velocity. This Gaussian wave packet \nis shown in Fig. 6.8(a) and the probability density is shown in Fig. 6.8(b). This wave packet is truly \nlocalized; the probability density decays to zero away from the central peak in Fig. 6.8(b) with none \nof the secondary peaks that were evident in the discrete superposition in Fig. 6.4. The continuum of \nmomentum states used in this superposition ensures that the destructive interference of the constituent \nwaves away from the central peak is effective in truly localizing the wave/particle. This localization \nthrough interference means that this wave packet superposition is normalizable even though the indi-\nvidual waves used are not themselves normalizable.\nThe experimental parameters that one would like to measure in order to fully characterize a wave \npacket are the position and momentum. The expectation value of the position is, formally,\n \n8x9 =\n \nL\n\u0005\n- \u0005\nx  P1x, t2dx =\n \nL\n\u0005\n- \u0005\nx 0 c1x, t20\n2 dx, \n(6.55)\nx\nRe\tΨ\u0007x\b\n2\u0003x\nx\nP\u0007x\b\n2\u0003x\n(a)\n(b)\nFIGURE 6.8 Gaussian wave packet (a) wave function and (b) probability density.\n","page_start":198,"page_end":198,"token_count":638,"section_type":"other","chapter_number":6,"chapter_title":"Unbound States","chunk_index":256}
{"chunk_id":"d25d7066b3b3178a","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"6.2 Wave Packets \n175\nbut it can also be obtained by inspection of the Gaussian probability density [compare Eq. (6.53) with \nEq. (6.43)]:\n \n8x9 =  p0\nm\n t. \n(6.56)\nThis result again shows that the wave packet moves with the group velocity p0>m.\nThe expectation value of the momentum can be calculated either with a spatial integral\n \n8p9 =\n \nL\n\u0005\n- \u0005\nc*1x, t2 pn  \n c1x, t2dx \n(6.57)\nor a momentum integral\n \n8p9 =\n \nL\n\u0005\n- \u0005\np P1p, t2dp =\n \nL\n\u0005\n- \u0005\np 0 f1p, t20\n2 dp. \n(6.58)\nEither way, we get the result found by inspection previously in Eq. (6.47):\n \n8p9 = p0. \n(6.59)\nThe uncertainties of position and momentum are (again by inspection)\n \n \u0006x = a\u000f =\nU\n2b\n B\n1 + a2b2t\nm U b\n2\n \n \n \u0006p = b.\n \n \n(6.60)\nThe wave packet momentum width remains constant, which is consistent with the conservation of \nmomentum. The position width grows in time because the different momentum components used to \nconstruct the wave packet all move with different phase velocities. The spatial spreading of the quan-\ntum mechanical wave packet agrees with our classical ideas about waves. It could be considered analo-\ngous to a short laser pulse propagating through glass with dispersion in the index of refraction such \nthat different colors in the pulse travel at different speeds. However, the wave packet spreading is not \nwhat we expect for a classical particle, and we have uncovered one of the counterintuitive realities of \nthe quantum world—quantum particles do not stay intact.\nAs we did for the discrete wave packet, we visualize the motion of the continuous Gaussian wave \npacket with frames of an animation in Fig. 6.9. Again, we note that the carrier wave moves at the phase \nvelocity, which in this case is half of the group velocity of the envelope motion. From previous study \nof optics or waves, you may recall that the formal deﬁnitions of the phase and group velocities that \nwork for any wave packet are\n \n vphase = v\nk\n \n \n vgroup = dv\ndk `\nk0\n, \n \n(6.61)\nwhere the derivative in the group velocity is evaluated at the peak of the distribution of wave vector \nstates comprising the group. Applying these wave relations to the quantum mechanical free particle, \nwe ﬁnd that the phase velocity of the wave is\n \nvphase = v\nk = U v\nUk = E\np =\np2>2m\np\n=\np\n2m = vclassical\n2\n, \n(6.62)\n","page_start":199,"page_end":199,"token_count":631,"section_type":"other","chapter_number":6,"chapter_title":"Unbound States","chunk_index":257}
{"chunk_id":"e9839f12d8c90f0d","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"176 \nUnbound States\nwhich is half the classical particle velocity. The group velocity is\n \nvgroup = dv\ndk `\nk0\n=\nd1U v2\nd1Uk2 `\nk0\n= dE\ndp `\np0\n=\nd1 p2>2m2\ndp\n`\np0\n= p0\nm = vclassical, \n(6.63)\nwhich is equal to the classical particle velocity. Both results agree with the results we obtained by \ninspection of the Gaussian wave packet for a free particle.\n6.3 \u0002 UNCERTAINTY PRINCIPLE\nThe Fourier connection between position space and momentum space is also important for under-\nstanding the Heisenberg uncertainty principle as it applies to position and momentum. We learned \nin Chapter 2 that spin projection measurements along different axes are incompatible, meaning that \nwe cannot simultaneously measure both observables. We saw that, in general, two observables cannot \nbe measured simultaneously if they do not commute. We expressed this incompatibility in terms of the \nproduct of the measurement uncertainties of the two observables\n \n\u0006A\u0006B Ú 1\n2 083A, B49 0 , \n(6.64)\nwhere the uncertainty is deﬁned as the standard deviation\n \n\u0006A = 481A - 8A9229 = 48A29 - 8A92. \n(6.65)\nWe can now ask whether position and momentum measurements are compatible. Because we \nknow how to represent the position and momentum operators, we can calculate their commutator to \nanswer this question. The answer is that position and momentum do not commute (Problem 6.6). Their \ncommutator is\n \n3xn,  pn4 = i U. \n(6.66)\nFIGURE 6.9 Gaussian wave packet animation with time increasing from top to bottom. \nOpen circles identify a point of constant phase, which moves at the phase velocity. Filled \ncircles identify the peak of the envelope, which moves at the group velocity.\n","page_start":200,"page_end":200,"token_count":430,"section_type":"other","chapter_number":6,"chapter_title":"Unbound States","chunk_index":258}
{"chunk_id":"fa8f3aba016c90fb","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"6.3 Uncertainty Principle \n177\nThus, the Heisenberg uncertainty principle as applied to position and momentum is\n\u0006x\u0006p Ú U\n2  . \n(6.67)\nThis condition limits the product of the uncertainties of position and momentum to a minimum value. \nThe Heisenberg uncertainty principle represents a tradeoff between our knowledge of position and \nour knowledge of momentum. The Fourier connection between position and momentum helps us to \nunderstand this limitation.\nConsider the Fourier wave packet constructed from discrete momentum components. The uncer-\ntainty in momentum \u0006p is approximately the spacing \u0010p of the side modes from the central mode, as \nshown in the momentum distribution of Fig. 6.3. We estimate the uncertainty in position \u0006x as the \nseparation \u0010x of the two destructive interference minima from the central maximum of the correspond-\ning spatial wave function in Fig. 6.4. The minima are located where the phases of the side mode waves \nare p out of phase with the central sinusoid. These phases are determined by the arguments of the \nei pj x>U terms in Eq. (6.32). If we assume that the wave packet maximum, where the three waves are in \nphase, is at x = 0, then the destructive interference minimum on the right is at x = dx, as indicated in \nFig. 6.4. To calculate \u0010x, set the phase difference between the upper side mode 1 p = p0 + dp2 and \nthe central mode 1p = p02 equal to p and solve:\n 1p0 + dp2dx\nU\n- p0dx\nU\n= p  \n dpdx\nU\n= p. \n(6.68)\nThe uncertainty product for this discrete wave packet is approximately\n\u0006x\u0006p \u0003 pU. \n(6.69)\nHence, there is an inverse relationship between the width \u0006x of the position distribution and the \nwidth \u0006p of the momentum distribution. A wave packet that is well localized in space 1small \u0006x2 \nrequires a broad distribution \u0006p of momentum states, while a broad spatial distribution requires a \nnarrow momentum distribution. While this wave packet of discrete momentum components (i.e., a \nFourier series) does not strictly obey Eq. (6.69) because the “localization” is repeated out to inﬁnity, \nthe inverse relation between the position and momentum widths is a hallmark of Fourier transforms of \ncontinuous distributions.\nWe learned in the last section that a Gaussian momentum distribution leads to a Gaussian posi-\ntion distribution because the Fourier transform of a Gaussian function is itself a Gaussian function. In \nFig. 6.10 we plot these Fourier transform pairs for a range of widths; the inverse relation between the \nposition and momentum spaces is graphically evident. Using the position and momentum uncertain-\nties in Eq. (6.60), we calculate the uncertainty product of a Gaussian wave packet:\n\u0006x\u0006p = U\n2\n D1 + a2b2t\nm U b\n2\n. \n(6.70)","page_start":201,"page_end":201,"token_count":659,"section_type":"other","chapter_number":6,"chapter_title":"Unbound States","chunk_index":259}
{"chunk_id":"4be3725ec8c790c3","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"Fig. 6.10 we plot these Fourier transform pairs for a range of widths; the inverse relation between the \nposition and momentum spaces is graphically evident. Using the position and momentum uncertain-\nties in Eq. (6.60), we calculate the uncertainty product of a Gaussian wave packet:\n\u0006x\u0006p = U\n2\n D1 + a2b2t\nm U b\n2\n. \n(6.70)\nAt time t = 0 the Gaussian wave packet obeys the equality of the Heisenberg uncertainty relation \n\u0006x\u0006p = U>2. For this reason, a Gaussian wave function 1at t = 02 is a minimum uncertainty state. \nAs the wave packet evolves in time, it broadens in position space and the uncertainty product increases \n(Problem 6.12).","page_start":201,"page_end":201,"token_count":171,"section_type":"other","chapter_number":6,"chapter_title":"Unbound States","chunk_index":260}
{"chunk_id":"d81f6b05243444d0","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"178 \nUnbound States\n(a)\n\"Wave\"\nx\nRe\tΨ\u0007x\b\n2\u0003x\n2\u0003x\n2\u0003x\np0\np0\np0\np\nΦ\u0007p\b\n\"Wave/Particle\"\nx\nRe\tΨ\u0007x\b\np\nΦ\u0007p\b\n\"Particle\"\nx\nRe\tΨ\u0007x\b\np\nΦ\u0007p\b\n2\u0003p\n2\u0003p\n2\u0003p\n(b)\n(c)\nFIGURE 6.10 Gaussian wave packets with decreasing spatial widths and the \ncorresponding momentum space wave functions obtained by Fourier transform.\nThe wave packet in Fig. 6.10(a) extends spatially over many wavelengths, so the “wave” nature \nof the packet is evident. In contrast, the wave packet in Fig. 6.10(c) extends only over one wavelength \nand so is more representative of a well-localized “particle.” If we take this wave-particle duality to its \nlogical extremes, we get the states shown in Fig. 6.11. A pure “wave” has an inﬁnite spatial extent, \nwhich corresponds to an inﬁnitesimal momentum width, as shown in Fig. 6.11(a). The pure wave state \nis the momentum eigenstate wave function 0  p09 \u0003 wp01x2 = ei p0\n x>U> 12pU, and the corresponding \nmomentum space wave function must be a Dirac delta function because there is only one momentum \nvalue. This is consistent with the Fourier connection between position and momentum because the \nFourier transform of a pure sinusoid is a delta function:\n \n fp01p2 =\n1\n12pU L\n\u0005\n- \u0005\nwp01x2e-i px>U dx\n \n \n =\n1\n12pU L\n\u0005\n- \u0005\n \n1\n12pU ei p0\n x>U e-i p x>U dx \n \n =\n1\n2pU L\n\u0005\n- \u0005\nei 1p0\n -\n p2x>U dx\n \n \n = d1p - p02.\n \n \n(6.71)\n","page_start":202,"page_end":202,"token_count":469,"section_type":"other","chapter_number":7,"chapter_title":"Angular Momentum","chunk_index":261}
{"chunk_id":"fb281a6b936ed52f","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"6.3 Uncertainty Principle \n179\nA pure “particle” state has an inﬁnitesimally narrow spatial extent, which corresponds to an inﬁ-\nnite momentum width, as shown in Fig. 6.11(b). This state represents a particle that is measured to be \nat a unique position, x0 for example. A state with a unique value of the position observable is a position \neigenstate 0\n x09. In analogy with the momentum space representation of the momentum eigenstate above, \nthe position representation (i.e., spatial wave function) of a position eigenstate is the Dirac delta function\n \n0\n x09 \u0003 wx01x2 = d1x - x02. \n(6.72)\nThis state satisﬁes the position eigenvalue equation\n \n xn 0 x09 = x00 x09\n \n \n xn d1x - x02 = x0 d1x - x02. \n \n(6.73)\nSo we have ﬁnally found the wave function for the position eigenstate we introduced in the last chap-\nter. The inﬁnite extent of the momentum space representation of this state is now clear, because the \nFourier transform of a delta function is a pure sinusoid:\n \n fx01 p2 =\n1\n12pU L\n\u0005\n- \u0005\nwx01x2e-i px>U dx\n \n \n =\n1\n12pU L\n\u0005\n- \u0005\nd1x - x02e-i px>U dx \n \n =\n1\n12pU e-i px0>U.\n \n \n(6.74)\nThe position eigenstates have the same pathologies as the momentum eigenstates—they cannot be \nnormalized and so they cannot truly represent physical states.\nx\nRe\t\u0005p0(x)\nRe\tΦx0(p)\nx\n\u0005x0(x)\np\nΦp0(p) \np\n(a)\n(b)\np0\nx0\nFIGURE 6.11 (a) Momentum eigenstate wave function and its corresponding delta-function \nmomentum distribution, and (b) position eigenstate wave function and its corresponding inﬁnite \nextent momentum distribution.\n","page_start":203,"page_end":203,"token_count":459,"section_type":"other","chapter_number":7,"chapter_title":"Angular Momentum","chunk_index":262}
{"chunk_id":"eee3da47783cf3c3","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"180 \nUnbound States\nIn summary, the eigenstates of position and momentum in the two representations\n \n \n \nPosition space \nMomentum space \n \nPosition eigenstate \n0  x09 \u0003 d1x - x02 \n0  x09 \u0003\n1\n12pU e-i p0 x>U \n \nMomentum eigenstate 0  p09 \u0003\n1\n12pU ei p0 x>U 0  p09 \u0003 d1 p - p02  \n(6.75)\ndemonstrate an appealing parallel between position and momentum. This parallel is also evident in the \nposition and momentum operators. In the position representation, the position operator is simple mul-\ntiplication, while the momentum operator is a derivative with respect to position. Similar to the cor-\nrespondence of the wave functions in Eq. (6.75), it turns out that in the momentum representation, the \nmomentum operator is simple multiplication, while the position operator is a derivative with respect to \nmomentum:\n \nPosition space Momentum space \n \n xn \u0003 x\n \n xn \u0003 iU d\ndp\n  \n \n pn \u0003 -iU d\ndx\n \n pn \u0003 p     . \n(6.76)\nThe incompatibility of position and momentum measurements inherent in the Heisenberg uncer-\ntainty principle is in stark contrast to the classical notion that position and momentum are independent \nquantities that can each be measured with precision limited only by experimental technique. In quan-\ntum mechanics, position and momentum are complementary rather than independent quantities. The \nresult is that we cannot know the trajectory of a particle in quantum mechanics. We can make predic-\ntions of the probability that the particle is in a region of space, but we cannot know the trajectory as we \ndo in classical physics.\n6.3.1 \u0002 Energy Estimation\nWe can also use the uncertainty principle to estimate the minimum energy of a particle. If we know \nthat a particle is localized to a ﬁnite region \u0006x of space, then the uncertainty principle tells us that the \nmomentum distribution required to produce that localization must satisfy\n \n\u0006p Ú\n U\n2\u0006x . \n(6.77)\nIf the momentum distribution has this minimum width, then we can use this width as a rough estimate \nof the minimum momentum\n \npmin \u0005\nU\n2\u0006x . \n(6.78)\nIgnoring the potential energy for the moment, we can then estimate the minimum energy of the particle\n \n Emin =  p2\nmin\n2m\n \n \n Emin \u0005  \nU2\n8m1\u0006x2\n2 . \n \n(6.79)\nThis approach is a common “back-of-the-envelope” calculation used to get a rough estimate of bound-\nstate energies.\n","page_start":204,"page_end":204,"token_count":577,"section_type":"other","chapter_number":7,"chapter_title":"Angular Momentum","chunk_index":263}
{"chunk_id":"c333eb465c2a48e2","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"6.4 Unbound States And Scattering \n181\nConsider a particle bound in a square well potential. The potential energy well by its nature con-\nﬁnes the particle to a spatial region \u0006x approximately the size L of the box. We then use the uncertainty \nprinciple to ﬁnd the corresponding uncertainty in the particle momentum:\n \n \u0006p\u0006x Ú  U\n2 \n \n \u0006p Ú  U\n2\u0006x \n \n \u0006p Ú  U\n2L.  \n \n(6.80)\nIf the particle momentum is uncertain to this degree, then the value of the particle momentum must be \nat least this big, and possibly much larger:\n \npmin =  U\n2L . \n(6.81)\nNow use this estimate of the minimum momentum to estimate the minimum energy that the bound \nparticle can have:\n \n Emin =  p2\nmin\n2m\n \n \n =  U2\n8mL2 . \n \n(6.82)\nCompare this with the ground-state energy in the inﬁnite well:\n \nE\u0005, n=1 =  p2U2\n2mL2 \u0002 5 U2\nmL2 . \n(6.83)\nWhile not a great match, the energy estimate from the Heisenberg uncertainty principle does predict \nthe correct dependence of the energy on the well size. As the well gets smaller the energy levels go up, \nwhich is a general feature of bound energy states. The proportionality depends on the well width and \nis 1>L2 for the square well.\nThe actual ground-state energy in the inﬁnite square well [Eq. (6.83)] is about 40 times larger than \nthe uncertainty principle estimate in Eq. (6.82). There are two reasons for this poor agreement. (1) We \noverestimated the position spread of the particle; a particle conﬁned to a well of size L has a position \nuncertainty less than L (Problem 6.20). (2) The minimum energy estimate comes from assuming that \nthe uncertainty product is a minimum \u0006x\u0006p = U>2, which is true only for Gaussian wave functions. \nBoth of these factors lead to an underestimate of the minimum momentum, which leads to an even big-\nger underestimate of the energy because it depends on the square of the momentum. This method of \nestimating energies with the Heisenberg uncertainty principle must be taken with a grain of salt, as this \nexample shows.\n6.4 \u0002 UNBOUND STATES AND SCATTERING\nWe have discussed bound states in potential wells and free particle states in ﬂat potentials. To com-\nplete our introduction to the quantum mechanics of particle motion, we now discuss unbound states \nin potential energy wells. Unbound states have an energy that is greater than the potential energy at \n","page_start":205,"page_end":205,"token_count":599,"section_type":"other","chapter_number":7,"chapter_title":"Angular Momentum","chunk_index":264}
{"chunk_id":"f14a76b66a9a7d52","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"182 \nUnbound States\nx\nE1\nE2\nE3\nE4\nE5\nE6\nEnergy\nV(x)\nBound states\nUnbound States\nFIGURE 6.12 Bound 1E 6 E1\u000522 and unbound 1E 7 E1\u000522 states in a generic potential energy well.\ninﬁnity, in contrast to bound states, which have an energy that is less than the potential energy at inﬁn-\nity, as illustrated in Fig. 6.12. Bound states must “ﬁt” into the potential well, which leads to energy \nquantization, while unbound states “lie” above the well with sinusoidal wave functions that extend to \ninﬁnity, “and beyond!” Unbound states are similar to free particle states in that there are not enough \nconstraints to fully determine the wave function, with the result that there is no energy quantization \nfor unbound states. However, the unbound states are not simply free particle states with a well-deﬁned \nmomentum. Unbound states are affected by the potential energy proﬁle, which causes the states to \n“scatter.” We often use the term scattering states in this context.\nTo begin our study of unbound states, we return to the ﬁnite square well potential. For the study of \nscattering states, it is more convenient to choose the zero of potential energy to be the energy at inﬁn-\nity, rather than the energy at the bottom of the well as we did for bound states. Hence, we deﬁne the \npotential energy shown in Fig. 6.13 as\n \nV1x2 = •\n  0,\n-V0,\n  0,    \n   x 6 -a\n-a 6 x 6 a\n   x 7 a.\n \n(6.84)\nWith this choice of potential energy origin, bound states have E 6 0 and scattering states have E 7 0. \nIt turns out that we are also able to use the solutions to this problem to study an inverted well (a barrier) \nby changing the sign of V0.\nWe follow the same approach we have used in all previous wave function problems—we ﬁrst \nsolve the energy eigenvalue equation. As in the previous well problems, we get separate equations in \nthe different regions:\n \n a-  U2\n2m\n d 2\ndx 2 - V0bwE1x2 = EwE1x2,   0 x 0 6 a  \n \n a-  U2\n2m\n d 2\ndx 2 + 0b wE1x2 = EwE1x2,   0 x 0 7 a. \n \n(6.85)\n","page_start":206,"page_end":206,"token_count":594,"section_type":"other","chapter_number":7,"chapter_title":"Angular Momentum","chunk_index":265}
{"chunk_id":"a241b15776213426","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"6.4 Unbound States And Scattering \n183\nScattering states have E 7 0 and so we expect sinusoidal solutions in both regions. Hence, it is useful \nto deﬁne two wave vectors\n \n k1 = A\n2mE\nU2\n \n \n k2 = B\n2m1E + V02\nU2\n. \n \n(6.86)\nThese two parameters are used to rewrite the energy eigenvalue equations as\n \n \nd 2wE1x2\ndx2\n= -k2\n2wE1x2,   0 x0 6 a \n \n \nd 2wE1x2\ndx2\n= -k2\n1wE1x2,   0 x0 7 a. \n \n(6.87)\nThe solutions to these differential equations are sinusoids or complex exponentials. Which form \nwe choose to start with is a matter of convenience; the solution dictates the ﬁnal form. It turns out \nthat bound-state wave functions are real, as we found in Chapter 5, and unbound state wave func-\ntions are complex, so the complex exponentials are more convenient here. We write the general \nsolutions as\n \nwE1x2 = •\nAeik1x + Be-ik1x,\nCeik2x + De-ik2x,\nFeik1x + Ge-ik1x,   \n    x 6 -a\n -a 6 x 6 a\n    x 7 a .\n \n(6.88)\nIn principle, we should now proceed as we did in the bound-state problems earlier. That is, \nwe should impose the boundary conditions and solve for the allowed energies and wave function \nx\nV(x)\n\u0006a\n\u0006V0\n0\na\nFIGURE 6.13 Finite square potential energy well.\n","page_start":207,"page_end":207,"token_count":395,"section_type":"other","chapter_number":7,"chapter_title":"Angular Momentum","chunk_index":266}
{"chunk_id":"d29d31f0df5e16ec","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"184 \nUnbound States\namplitudes. However, that road quickly becomes a heavy slog. So it is instructive to focus on speciﬁc \nphysical problems of interest and consider what we can actually measure.\nFirst, observe that there are seven unknowns (coefﬁcients A, B, C, D, F, G, and energy E) in this \nproblem. To solve for all seven unknowns, we need seven equations, or seven pieces of information. \nWhen we impose the boundary conditions of wave function amplitude and derivative continuity at \nthe two sides of the well, we get four pieces of information. For bound-state systems, the remaining \nthree pieces of information come from the normalization condition, resulting in energy quantization. \nWe saw this explicitly in the discussion of numerical solutions of energy eigenvalue equations; only by \nchoosing the energy perfectly could we achieve a wave function that decayed to zero as it approached \ninﬁnity. Unbound or scattering states need not decay to zero at inﬁnity, so we cannot and do not need \nto impose the normalization condition. However, the absence of the normalization condition implies \nthat the energy is not quantized and any energy is allowed for a scattering state. So our ﬁrst conclusion \nis that scattering states have a continuous energy spectrum; therefore, we treat the energy E as an ini-\ntial condition rather than as an unknown.\nIn a typical scattering experiment, we shoot particles at each other and ask how their motion is \naffected by their interactions. We usually consider one particle as ﬁxed—the target—and the other \nas moving—the projectile. The potential energy well represents the interaction between them. The \nwave function we solve for then represents the motion of the projectile. In an experiment, projectile \nparticles originate from a source, which we assume is at negative inﬁnity. In the general solution then, \nthe Aeik1x term represents the incoming projectile particles, as illustrated in Fig. 6.14. These incoming \nprojectile particles can interact with the well (target) in two possible ways: they might reﬂect and head \nback to the left, which would be the Be-ik1x term, or they might continue to the right, which would be \nthe Feik1x term after passing the well region. In this scenario, there are no particles on the right side of \nthe barrier that are moving to the left—the Ge-ik1x term. That term could come about only if there were \na source of particles at positive inﬁnity headed back toward the origin, or if another potential energy \nchange occurred to the right of the well that could reﬂect the original particles back to the left. Hence, \nthe typical scattering experiment is consistent with setting G = 0. Using this viewpoint and treating \nthe energy E as an initial condition rather than as an unknown, we have now reduced the number of \nunknowns in the problem from seven to ﬁve.\nx\nE\na\n\u0002a\n\u0002V0\nE\nBe\u0002ik1 x\nDe\u0002ik2 x\nAeik1 x\nCeik2 x\nFeik1 x\nFIGURE 6.14 Waves incident upon, reﬂected from, and transmitted through \na square potential energy well.\n","page_start":208,"page_end":208,"token_count":698,"section_type":"other","chapter_number":7,"chapter_title":"Angular Momentum","chunk_index":267}
{"chunk_id":"bd4da67ac5ee8cea","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"6.4 Unbound States And Scattering \n185\nUnfortunately, we still have one more unknown than we can solve for because we have only four \nequations or pieces of information from the boundary conditions. We get that one extra piece of infor-\nmation by using a new way to normalize the wave function. The coefﬁcient A represents the amplitude \nof the incoming wave, B the amplitude of the reﬂected wave, and F the amplitude of the transmitted \nwave, all of which are things we can measure. But we only expect our theory to predict the amplitudes \nof the reﬂected and transmitted waves. The amplitude of the incident wave is something we control \nin the experiment. Moreover, we expect that more incoming wave amplitude (input particle ﬂux) will \nlead to more reﬂected and transmitted wave amplitude (output particle ﬂux), so we really want to \npredict the ratios B>A and F>A of the reﬂected and transmitted waves, respectively, to the incoming \nwave. In this sense, we are normalizing our solutions to the amplitude of the incoming wave. In prac-\ntice, we divide the boundary condition equations by A, which effectively gives us four equations with \nfour unknowns. C and D represent the amplitudes of the wave function inside the potential well and \nare typically not amenable to measurement, so we try to eliminate those in favor of the measurables.\nIn light of this new way of approaching the problem, the general solution is\nwE1x2 = •\nAeik1x + Be-ik1x,\nCeik2x + De-ik2x,\nFeik1x,\n    x 6 -a\n -a 6 x 6 a\n    x 7 a.\n(6.89)\nNow apply the boundary conditions of wave function amplitude and derivative continuity at the two \nsides of the well:\n wE1-a2:   Ae-ik1a + Beik1a = Ce-ik2a + Deik2a \n dwE1x2\ndx\n`\nx=-a\n:   ik1Ae-ik1a - ik1Beik1a = ik2Ce-ik2a - ik2Deik2a \n wE1a2:   Ceik2a + De-ik2a = Feik1a\ndwE1x2\ndx\n`\nx =a\n:   ik2Ceik2a - ik2De-ik2a = ik1Feik1a.\n(6.90)\nSolve the last two equations for C and D in terms of F and then substitute into the ﬁrst two equations \nto eliminate C and D, which are not so interesting. Then solve the ﬁrst two equations for the ratios B>A \nand F>A (Problem 6.24):\n F\nA =\ne-2ik1a\ncos12k2a2 - i \nk 2\n1 + k 2\n2\n2k1k 2\n sin12k2a2\n B\nA = i F\nA ","page_start":209,"page_end":209,"token_count":664,"section_type":"other","chapter_number":7,"chapter_title":"Angular Momentum","chunk_index":268}
{"chunk_id":"c1fd90afaf6ef955","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"to eliminate C and D, which are not so interesting. Then solve the ﬁrst two equations for the ratios B>A \nand F>A (Problem 6.24):\n F\nA =\ne-2ik1a\ncos12k2a2 - i \nk 2\n1 + k 2\n2\n2k1k 2\n sin12k2a2\n B\nA = i F\nA \nk 2\n2 - k 2\n1\n2k1k2\n sin12k2a2.\n(6.91)\nThe ratio F>A is the ratio of the amplitude of the transmitted wave to the amplitude of the incom-\ning wave. The absolute square of this ratio gives the relative probability T that an incident particle is \ntransmitted through the potential well, which we call the transmission coefﬁcient. The transmission \ncoefﬁcient for a ﬁnite square well is\nT = 0 F0 2\n0 A0 2 =\n1\n1 + 1k 2\n1 - k 2\n22\n2\n4k 2\n1k 2\n2\n sin212k2a2\n. \n(6.92)","page_start":209,"page_end":209,"token_count":256,"section_type":"other","chapter_number":7,"chapter_title":"Angular Momentum","chunk_index":269}
{"chunk_id":"f11daeb39f24cc73","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"186 \nUnbound States\nExpressed in terms of the energy E and the potential well depth V0, the transmission coefﬁcient is\n \nT =\n1\n1 +\nV 2\n0\n4E1E + V02\n sin2 a2a\nU 42m1E + V02b\n. \n(6.93)\nThis is the probability that a particle with an incoming energy E is transmitted through the potential \nregion.\nThe reﬂection coefﬁcient R is the probability that an incident particle is reﬂected from the poten-\ntial well and is given by the absolute square of the ratio B>A of the amplitude of the reﬂected wave to \nthe amplitude of the incoming wave:\n \nR = 0 B0 2\n0 A0 2 =\n1\n1 +\n4k 2\n1k 2\n2\n1k 2\n1 - k 2\n22\n2 sin212k 2a2\n. \n(6.94)\nIn this ﬁnite square well problem, there is no absorption of particles by the well, so the reﬂection and \ntransmission coefﬁcients add up to unity:\n \nT + R = 1 \n(6.95)\nand the reﬂection coefﬁcient is simply R = 1 - T. In contrast to quantum mechanical particles, \n classical particles do not reﬂect from potential wells. They merely speed up and then slow down as \nthey traverse the well. The reﬂection of quantum mechanical particles is thus further evidence of the \nwave nature of particle motion. It is analogous to classical wave motion through different media. For \nexample, a light wave incident on a slab of glass is also partially reﬂected and partially transmitted.\nThe transmission and reﬂection coefﬁcients for a ﬁnite square well are plotted in Fig. 6.15 as \na function of the incident energy E. For large energy, the transmission goes to unity, which is to be \nexpected because the potential well becomes insigniﬁcant. The transmission is also unity for particular \nenergies, commonly called resonances. These resonances occur whenever the sine term in the trans-\nmission coefﬁcient is zero, which occurs if\n \n2k2a = np. \n(6.96)\n1\n2\nE/V0\n0.2\n0.4\n0.6\n0.8\n1.0\nT,R\nR\nT\nFIGURE 6.15 Reﬂection and transmission coefﬁcients for scattering from a ﬁnite square well. \nThe vertical lines indicate resonances where the transmission is unity.\n","page_start":210,"page_end":210,"token_count":582,"section_type":"other","chapter_number":7,"chapter_title":"Angular Momentum","chunk_index":270}
{"chunk_id":"2dab1754f49f1720","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"6.4 Unbound States And Scattering \n187\nThe reason for these resonances is evident if we rewrite this expression in terms of the wavelength \nl2 = 2p>k2 inside the potential well:\n \n 2a2p\nl2\nb  a = np \n \n 2a = n l2\n2 .\n \n(6.97)\nWhen the width of the potential well (2a) contains an integer number of half wavelengths, the trans-\nmission is unity and the reﬂection is zero. This effect is well known in physical optics, where light \nundergoes multiple reﬂections from the front and back surfaces of a glass slab, as shown in Fig. 6.16. \nForward-going waves all interfere constructively and backward-going waves all interfere destructively \nwhen the thickness of the glass slab contains an integer number of half wavelengths. In the optics case, \nthe changes in transmission and reﬂectivity that come from changing the wavelength (or the slab thick-\nness) are known as interference fringes. One of the most common manifestations of this effect is the \nappearance of colored bands in a thin ﬁlm of oil on water, as in the street after a rainstorm. In the optics \ncase, the transmission and reﬂection are found by explicitly adding up all the interfering waves shown \nin Fig. 6.16. In the quantum case, we solved the energy eigenvalue equation and imposed the boundary \nconditions to achieve the same result. In both cases, the waves look like those shown in Fig. 6.17.\n\u0002a\na\nx\nE,Ψ\nIncident\nReflected\nTotal\nFIGURE 6.17 Waves incident upon, reﬂected from, and transmitted through a ﬁnite square well. \nNote that there are two vertical axes, energy and wave function, with different zeroes.\nΛ1\nΛ1\nΛ2\nFIGURE 6.16 Optics interference analogy.\n","page_start":211,"page_end":211,"token_count":423,"section_type":"other","chapter_number":7,"chapter_title":"Angular Momentum","chunk_index":271}
{"chunk_id":"c8e92e5e5e7dfd86","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"188 \nUnbound States\n\u0002a\na\nx\nE\nE \u0003 V0\nV0\nFIGURE 6.18 A ﬁnite square barrier with the incident particle energy above \nthe barrier height.\nIf we write the resonance condition in terms of the energy, we get\n \na2a\nU b\n2\n2m1E + V02 = n2p2 \n \nE =  -V0 +\nn2p2\n U2\n2m12a2\n2 .\n \n(6.98)\nThus, the energies of the transmission resonances (with respect to the bottom of the well) correspond \nto the bound-state eigenenergies of the inﬁnite well. A similar effect is seen in atomic physics, where it \nis called the Ramsauer-Townsend effect.\nWe can use these same solutions to solve the problem of a barrier potential, as shown in Fig. 6.18, \nas long as the energy is above the barrier height. We simply change the well depth from V0 to \u0011V0 in \nall the formulae above. The results are the same; there are still resonances at the same energy levels. \nThe only difference is that now the wavelength in the potential region is longer rather than shorter than \nthe wavelength outside. This corresponds to the classical optics case where light from glass is incident \non a slab of air.\n6.5 \u0002 TUNNELING THROUGH BARRIERS\nIf the energy of the particle is below the barrier height, then the barrier region is classically forbid-\nden and a classical particle reﬂects perfectly from the barrier. In the quantum mechanical treatment \nthere is a possibility that the particle can penetrate the barrier and come out on the other side! This is \nbecause the quantum mechanical wave function penetrates into the classically forbidden region. This \nphenomenon is called quantum mechanical tunneling, and it is responsible for radioactive decay and \nthe current in high frequency semiconductor diodes, for example. Quantum tunneling has an optical \nanalogue where a light wave penetrates into air while being totally internally reﬂected from inside a \nglass prism. This penetrating wave is called an evanescent wave.\n","page_start":212,"page_end":212,"token_count":463,"section_type":"other","chapter_number":7,"chapter_title":"Angular Momentum","chunk_index":272}
{"chunk_id":"99fd3978e3127068","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"6.5 Tunneling Through Barriers \n189\nA square potential energy barrier is shown in Fig. 6.19. The potential energy is described as\n \nV1x2 = •\n0,\nV0,\n0,   \n   x 6 -a\n-a 6 x 6 a\n   x 7 a.\n \n(6.99)\nIf the energy E of the incident particle beam is less than the well height V0, then the region \n-a 6 x 6 a is classically forbidden. As in the previous well problems, there are separate eigenvalue \nequations in the different regions:\n \n a-  U2\n2m d 2\ndx 2 + V0bwE1x2 = EwE1x2,   0 x 0 6 a  \n \n a-  U2\n2m d 2\ndx 2 + 0b wE1x2 = EwE1x2,   0 x 0 7 a. \n(6.100)\nThe energy E is less than the potential barrier height V0, so the interior solutions must be real expo-\nnentials and the exterior solutions must be complex exponentials. It is useful to deﬁne a wave vector k \noutside the well and a decay constant q inside the well:\n \n k = A\n2mE\nU2\n \n \n q = C\n2m1V0 - E2\nU2\n . \n(6.101)\nUse these two constants to rewrite the energy eigenvalue equations as\n \n \nd 2wE1x2\ndx 2\n= q2wE1x2,       0 x 0 6 a  \n \n \nd 2wE1x2\ndx 2\n= -k 2wE1x2,   0 x 0 7 a. \n(6.102)\n\u0002a\na\nx\nE\nE \u0004 V0\nV0\nFIGURE 6.19 A ﬁnite square barrier with the incident particle energy below the barrier height.\n","page_start":213,"page_end":213,"token_count":442,"section_type":"other","chapter_number":7,"chapter_title":"Angular Momentum","chunk_index":273}
{"chunk_id":"73e365bc12719b4e","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"190 \nUnbound States\nThe general solutions to these equations are\n \nwE1x2 = •\nAeikx + Be-ikx,\nCeqx + De-qx,\nFeikx,\n   \n   x 6 -a\n-a 6 x 6 a\n   x 7 a,\n \n(6.103)\nwhere we have again assumed that there are particles incident from the left, but not from the right. \nIt is important that the wave function in the classically forbidden region contains both the exponen-\ntially decreasing and the exponentially growing terms. The growing term cannot vanish as it did in the \ncase where the classically forbidden region extended to inﬁnity (Section 5.5). The boundary condition \nequations for continuity of the wave function and of the derivative of the wave function are\n \n w1-a2:   Ae-ika + Beika = Ce-qa + Deqa \n \n \ndw1x2\ndx\n`\nx=-a\n:   ikAe-ika - ikBeika = qCe-qa - qDeqa \n \n w1a2:   Ceqa + De-qa = Feika\n \n \n \ndw1x2\ndx\n`\nx =a\n:   qCeqa - qDe-qa = ikFeika.\n \n(6.104)\nAs before, we solve for the ratios of the amplitudes to get the transmission probability:\n \n T = 0 F0\n2\n0 A0 2 =\n1\n1 + 1k 2 + q 22\n2\n4k 2q 2\n sin h212qa2\n \n \n =\n1\n1 +\nV 2\n0\n4E1V0 - E2\n sin h2a2a\nU\n 42m1V0 - E2b\n. \n(6.105)\nThis transmission probability for quantum mechanical tunneling quantiﬁes the probability for a par-\nticle incident upon the barrier to penetrate the barrier and come out the other side. Remember that the \nclassical result would be zero—a classical particle only reﬂects from such a barrier.\nThe reﬂection coefﬁcient for the incident beam is\n \n R = 0 B0\n2\n0 A0 2 = 1 - T =\n1\n1 +\n4k 2q 2\n1k 2 + q 22\n2sin h212qa2\n \n \n =\n1\n1 +\n4E1V0 - E2\nV 2\n0 sin h2a2a\nU\n 42m1V0 - E2b\n.\n \n(6.106)\n","page_start":214,"page_end":214,"token_count":567,"section_type":"other","chapter_number":7,"chapter_title":"Angular Momentum","chunk_index":274}
{"chunk_id":"abde571d67ee991a","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"6.5 Tunneling Through Barriers \n191\nThe reﬂection and transmission coefﬁcients are plotted in Fig. 6.20 for the tunneling situation \n1E>V0 6 12, along with the coefﬁcients for the “over the barrier” situation 1E>V0 7 12, using \nEqs. (6.93) and (6.94) with V0 replaced by \u0011V0. In the tunneling case, the transmission is nearly \nzero except near the top of the barrier, where the tunneling probability increases exponentially. As the \nenergy of the incident particle exceeds the barrier height, the transmission becomes large and exhibits \nthe same resonances seen in the ﬁnite well problem. For large energy, the transmission goes to unity, \nwhich is to be expected because the potential barrier becomes insigniﬁcant.\nThe wave function of a particle that tunnels through a barrier is shown in Fig. 6.21. On the left \nside of the potential barrier are the incident and transmitted oscillatory waves. On the right side is \nthe transmitted oscillatory wave. Inside the barrier there is an exponentially damped wave function \n(the evanescent wave of optics). The growing exponential term is part of the interior wave function \n[see Eq. (6.103)], but the decaying term dominates (Problem 6.32).\n\u0002a\na\nx\nE,Ψ\nIncident\nReflected\nTotal\nFIGURE 6.21 Wave function (real part) of a particle tunneling through a square barrier. \nNote that there are two vertical axes, energy and wave function, with different zeroes.\n1\n2\n3\nE /V0\n0.2\n0.4\n0.6\n0.8\n1.0\nT,R\nR\nR\nT\nT\nFIGURE 6.20 Reﬂection and transmission coefﬁcients for scattering from a square barrier.\n","page_start":215,"page_end":215,"token_count":420,"section_type":"other","chapter_number":7,"chapter_title":"Angular Momentum","chunk_index":275}
{"chunk_id":"93df3823bba6d4da","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"192 \nUnbound States\ntip\nair\nsample\nV0\nd\nV\u0007x\b\nx\nFIGURE 6.22 Schematic diagram of the scanning tunneling microscope, and the \nrepresentation in terms of a potential energy diagram.\nA beautiful example of quantum mechanical tunneling is the scanning tunneling microscope, \nwhich was invented by Gerd Binnig and Heinrich Rohrer in 1981 and earned them the Nobel Prize in \nphysics in 1986. This imaging device employs a small sharp conducting tip that is brought up close to \na sample, as shown in Fig. 6.22. The air (or vacuum) region between the tip and sample is a potential \nenergy barrier because the electrons inside the two materials have lower potential energy than they \nwould in the free space between them due to the work functions of the materials. The probability that \nan electron can tunnel from the tip to the sample (or vice versa) is given by Eq. (6.105) and can be \napproximated as (Problem 6.33)\n \nT \f e-2qd, \n(6.107)\nwhere d is the separation of the tip and sample. In the microscope, a small bias voltage is applied \nbetween the tip and sample to create a preferential direction for current ﬂow. The tip and sample do not \n“touch” so the current is due only to tunneling and is proportional to the tunneling probability:\n \nI = I0 e-2qd. \n(6.108)\nThe exponential dependence makes the current extremely sensitive to the tip-sample separation, which \nis typically in the nanometer range to produce measurable currents. As the tip is moved laterally above \nand parallel to the sample surface, the current provides a measure of the surface topology. A scanning \ntunneling microscope produces images with typical lateral resolution of 0.1 nm and depth resolution \nof 0.01 nm, sufﬁcient to image individual atoms on the surface. A Web image search of “scanning \ntunneling microscope” reveals many beautiful pictures of natural and man-made atomic scale objects.\n6.6 \u0002 ATOM INTERFEROMETRY\nMany of the examples we have discussed in the last two chapters have clearly demonstrated the inher-\nent wave nature of particle motion in quantum mechanics. So can some of the classical light experi-\nments like diffraction and interference be translated to electrons, or even to bigger particles like atoms \nand molecules? Yes! Electron diffraction experiments have been used for a long time and have played \nan important role in studying the atomic level structure of solid state crystals and DNA molecules. In \nrecent years, the advent of laser cooling and trapping of atoms (see Chapter 16) has made it possible to \n","page_start":216,"page_end":216,"token_count":572,"section_type":"other","chapter_number":7,"chapter_title":"Angular Momentum","chunk_index":276}
{"chunk_id":"fea7aba812de32c9","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"6.6 Atom Interferometry \n193\nperform interference experiments with atoms and molecules. This new ﬁeld of atom interferometry \nis leading to new ways to measure a variety of phenomena with unprecedented precision and to probe \nthe mysteries of quantum measurement theory.\nLet’s discuss how an atom interferometer works by starting with the canonical double-slit inter-\nference experiment, as depicted in Fig. 6.23. You may have already seen this experiment when you \nstudied optics, where it is commonly referred to as Young’s double-slit experiment. The beauty is that \nthe experiment can be performed with light or with particles such as electrons, neutrons, or atoms. \nMoreover, we can use it to discuss the wave-particle duality of quantum mechanics.\nLet’s ﬁrst explain how the double-slit experiment works with light and then extend that to other \nparticles. A source of light illuminates two narrow slits and the light passing through the slits lands on a \ndistant screen. Each slit by itself produces on the screen a diffraction pattern whose spatial extent depends \ninversely on the width of the slit. We assume that the slits are narrow enough that these two diffraction pat-\nterns overlap substantially. If both slits are open, the overlapping diffraction patterns exhibit an additional \ninterference pattern on the screen, within the overall single-slit diffraction pattern, as shown in Fig. 6.23. \nThese interference fringes are comfortably explained by using our notions about waves. The important \nwave idea is that the measured pattern of light cannot be explained by adding intensities, but rather we \nmust add amplitudes and then square the result to ﬁnd the total intensity, as discussed in Section 1.1.4. The \ntotal ﬁeld at the screen is thus the sum of the ﬁelds from each of the two slits:\n \n E1x2 = E11x2 + E21x2  \n \n = E0eikr1 + E0eikr2, \n(6.109)\nwhere the distances r1 and r2 depend on the transverse position x of the observation point, the wave \nvector k = 2p>l, and l is the wavelength of light. The intensity at the screen is proportional to the \ncomplex square of the electric ﬁeld\n \n I1x2 \f 0 E1x20\n2\n \n \n \f 0 E0eikr1 + E0eikr20\n2 \n \n = I00 eikr1 + eikr20\n2.\n \n(6.110)\nSource\nr1\nr2\nx\nFIGURE 6.23 Double-slit interference experiment and resulting interference intensity pattern \non the screen.\n","page_start":217,"page_end":217,"token_count":578,"section_type":"other","chapter_number":7,"chapter_title":"Angular Momentum","chunk_index":277}
{"chunk_id":"3c1f2d03d8e3085b","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"194 \nUnbound States\nThe interference comes from the cross term in the complex square in Eq. (6.110):\n \n I1x2 = 2I011 + cos k1r2 - r122\n \n \n = 2I0 a1 + cos 2p 1r2 - r12\nl\nb. \n(6.111)\nAs you move the observation point up and down on the screen, the path length difference r2 - r1 \n varies, resulting in the sinusoidal intensity pattern characteristic of two interfering waves. The maxima \nin the interference pattern occur when the path length difference r2 - r1 is an integer multiple of the \n wavelength l.\nThis same wave-optics analysis applies to the wave function analysis of a quantum mechanics \nparticle, using the de Broglie wavelength to characterize the wave nature of the particle. A beam of \nparticles directed toward the double slits of Young’s experiment results in interference fringes at the \ndistant screen. The wave function at the screen resulting from equal contributions from the two slits is \nanalogous to the electric ﬁeld of the light above\n \nc = A1ei pr1>U + ei pr2>U2. \n(6.112)\nThe probability density for detecting a particle on the screen is\n \n P1x2 = 0 c1x20\n2 = 0 A0\n2\n 0 ei pr1>U + ei pr2>U0\n2 \n \n = 20 A0\n2\n a1 + cos  p\nU\n 1r2 - r12b\n \n,\n \n(6.113)\nwhich we rewrite in terms of the de Broglie wavelength using p = h>ldB:\n \nP1x2 = 20 A0\n2\n a1 + cos2p 1r2 - r12\nldB\nb. \n(6.114)\nThis has the same form as Eq. (6.111) and gives rise to the same interference pattern.\nYoung performed the original double-slit experiment with sunlight in 1801. Soon after de \n Broglie’s hypothesis in 1923 that matter can be described as a wave, diffraction experiments were \n performed with particles such as electrons, atoms, molecules, and neutrons to demonstrate matter \nwaves. Since then, Young’s double-slit interference experiment has been performed with electrons \n(1961), neutrons (1988), helium atoms (1991), and even with C60 buckyballs (1999). How about \n baseballs? Could we see interference fringes from something so large? Probably not. As we discussed \nin Section 4.2, a macroscopic object interacts strongly with the environment and its wave function \n suffers decoherence, which washes out the interference fringes.\nThe double-slit experiment is entirely consistent with the wave picture of light or matter, and so \nwould not appear to include any particle-like behavior. However, if we can control the source well \nenough to turn down the incident intensity so low that only one particle per second leaves the source, \nthen we can observe particle behavior with our own eyes. In the case of the light beam, the particles of \nlight are photons. Given that the screen is sensitive enough, the low intensity source produces individual \n","page_start":218,"page_end":218,"token_count":689,"section_type":"other","chapter_number":7,"chapter_title":"Angular Momentum","chunk_index":278}
{"chunk_id":"ddafd2f7b176c1c2","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"6.6 Atom Interferometry \n195\nblips on the screen corresponding to the arrivals of the individual particles. At ﬁrst, these blips appear at \nseemingly random places on the screen, as shown in Fig. 6.24(a). However, as more blips are recorded \n[Figs. 6.24(b) and (c)] we begin to see that the density of blips coincides with the interference pattern \n[Fig. 6.24(d)] from the wave model, as described by Eq. (6.114). The individual blips are consistent with \nour notion of a particle and its spatial localization, but they are inconsistent with our notion of a wave \nbecause they do not individually exhibit the interference pattern predicted above. On the other hand, the \ninterference pattern that builds up after many particles is consistent with our wave interference model, \nbut is inconsistent with our idea that particles travel in straight lines such that each particle from the \nsource should go through one slit and arrive at the corresponding upper or lower spot on the screen.\nThus, we appear to arrive at a paradox. Some aspects of the experiment are consistent with a \nparticle model, while others are consistent with a wave model. The quantum mechanical resolution is \nto say that we use the wave model to predict the probabilities of detecting individual particles. This \nis consistent with the interpretation we used in the spins sections where the quantum state vector was \nused to predict the probability that a spin projection was measured to be up or down. So what we called \nthe light intensity in the classical wave description is now transformed into a probability of detecting \nphotons at particular places on the screen. Any given photon arrival occurs randomly on the screen and \nthe pattern builds up only after many arrivals. This is what we mean by wave-particle duality. (More \ncomplete discussions of this example can be found in Feynman and Cohen-Tannoudji et al.)\nIf you are not a little confused at this point, try this: What if you could measure which slit the par-\nticle went through? That is, which path did the particle take to arrive at the screen? Well, if you knew \nwhich slit the particle went though, then the wave description wouldn’t be right, because it requires \nthat the wave goes through both slits in order to deﬁne the path length difference in Eqs. (6.111) and \n(6.114). If the wave picture isn’t right, then the interference pattern shouldn’t be present. As it turns \nout, the interference pattern does indeed disappear if you know which slit the particle went through. \n(a)\n(b)\n(c)\n(d)\nFIGURE 6.24 A computer simulation of the arrival of particles at the detection screen in a double-slit \nexperiment, showing (a) random early arrivals, (b) and (c) the buildup of an interference pattern, and  \n(d) a plot of the predicted interference intensity distribution.\n","page_start":219,"page_end":219,"token_count":615,"section_type":"other","chapter_number":7,"chapter_title":"Angular Momentum","chunk_index":279}
{"chunk_id":"b313669c809f6af2","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"196 \nUnbound States\nSource\nr2\nr1\nV2\nV1\nFIGURE 6.25 Double-slit atom interferometer for measuring potential energy differences.\nThe answer to this conundrum lies at the heart of quantum mechanical measurement theory. As hard as \nyou might try, you cannot measure, and therefore cannot know, which slit the “particle” goes through \nwithout disturbing it just a little bit. The simplest way to measure which slit the particle goes through \nis to watch, but you need some light to watch. If you see the particle, then at least one photon must \nhave scattered from the particle toward your eye, and the change in momentum of that photon in the \nscattering process will (through conservation of momentum) impart an equal and opposite change to \nthe particle’s momentum. This change is enough to alter the phase of the particle’s wave function and \ndestroy the interference fringes. In the early days of quantum mechanics, such “which path” experi-\nments were merely “thought” experiments or gedanken experiments because they were too hard to \nperform. However, in recent years careful experiments have demonstrated these effects beyond doubt.\nOne of the important features of an atom interferometer is its ability to measure extremely small \nchanges in potential energy. This ability arises from the dependence of the de Broglie wavelength of \nthe particle on the potential energy. If the potential energy varies, then the kinetic energy and hence the \nmomentum varies because the energy is conserved. The de Broglie wavelength depends on the particle \nmomentum, so a varying potential gives rises to a varying wavelength\n \n ldB = h\np\n \n \n =\nh\n22m1E - V2\n . \n(6.115)\nA measurement of the potential energy with an atom interferometer proceeds as shown in Fig. 6.25. \nDifferent regions of potential energy are placed behind slit 1 and behind slit 2. A difference in the two \npotential energies produces a phase shift between the two wave functions that interfere at the distant \nscreen. Hence, a measurement of the fringe shift in the interference pattern is a measurement of the \npotential energy difference. The different regions might, for example, have different electric ﬁelds, \nwhich produce different energies in atomic states (see Section 10.7.2). Or, if the atom interferometer \nis oriented vertically (or at an angle) instead of horizontally, then the two paths experience different \ngravitational potential energies. Recent experiments have been precise enough to test features of Ein-\nstein’s general theory of relativity. Atom interferometers can also measure rotation and acceleration, \nsimilar to ﬁber optic gyroscopes that are commonly used for navigation.\n","page_start":220,"page_end":220,"token_count":560,"section_type":"other","chapter_number":7,"chapter_title":"Angular Momentum","chunk_index":280}
{"chunk_id":"14e65f0359fca54c","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"Problems \n197\nSUMMARY\nIn this chapter, we learned about the unbound states of quantum particles. The momentum eigenstate \nwave functions are\n \n0  p9 \u0003 wp1x2 =\n1\n12pU ei px>U. \n(6.116)\nFor a free particle 3V1x2 = 04, the momentum eigenstates are also energy eigenstates with energy\n \nE = p2\n2m. \n(6.117)\nA free particle has a characteristic wavelength given by the de Broglie relation\n \nlde Broglie = h\np. \n(6.118)\nA more realistic representation of particle motion is obtained by superposing momentum \n eigenstates in a wave packet. The amplitude of each momentum component is f1 p2 and the resultant \nsuperposition is\n \nc1x2 =\n1\n12pU L\n\u0005\n- \u0005\nf1 p2ei px>U dp, \n(6.119)\nwhich has the form of a Fourier transform. The momentum amplitudes are related to the position space \nwave function through the inverse Fourier transform\n \nf1p2 =\n1\n12pU L\n\u0005\n- \u0005\nc1x2e-i px>U dx. \n(6.120)\nThe Heisenberg uncertainty relation between position and momentum is\n \n\u0006x\u0006p Ú U\n2 \n(6.121)\nand tells us that tight spatial localization requires a broad range of momenta, and a particle with a \nwell-deﬁned momentum is spread over a large spatial region. The Gaussian wave packet is the only \nwave packet that satisﬁes the equality of the uncertainty relation and so is referred to as a minimum \nuncertainty state.\nIf a potential energy is present, the unbound states are scattering states. A particle incident on \na potential well is partially transmitted and partially reﬂected, except at certain resonance energies \nwhere there is no reﬂection. A particle with energy below the height of a potential barrier can tunnel \nthrough the barrier, a phenomenon that is not observed classically.\nPROBLEMS\n 6.1 Calculate the de Broglie wavelengths of the following items:\na) an electron with a kinetic energy of 3 eV\nb) a proton with a kinetic energy of 7 MeV\nc) a buckyball 1C602 with a speed of 200 m>s\nd) an oxygen molecule at room temperature\n","page_start":221,"page_end":221,"token_count":519,"section_type":"other","chapter_number":7,"chapter_title":"Angular Momentum","chunk_index":281}
{"chunk_id":"4ebadd7eb9b910ab","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"198 \nUnbound States\ne) a raindrop\nf) yourself walking to class\nIn which of the above cases might you expect quantum mechanics to play an important role  \nand why?\n 6.2 The wave function for a particle in one dimension is\n(i)  \nc1x2 = Ae-x 2>a2.\na) Normalize the wave function.\nb) Calculate the expectation value 8x9 of the position.\nc) Calculate the uncertainty \u0006x of the position.\nd) Calculate the probability that the particle is found in the region 0 6 x 6 a.\ne)  Plot the wave function and the probability density and indicate the results to (b), (c), and \n(d) on the plot.\nf) Calculate the expectation value 8p9 of the momentum.\ng) Calculate the uncertainty \u0006p of the momentum.\nh) Does this state satisfy the uncertainty principle?\nRepeat for other wave functions:\n(ii)  \nc1x2 = Axe-x 2>a2\n(iii)  \nc1x2 = A \n1\nx 2 + a2\n 6.3 A beam of particles is prepared in a momentum eigenstate 0  p09. The beam is directed to a \n shutter that is open for a ﬁnite time t.\na) Find the wave function of the system immediately after passing through the shutter.\nb) Find the momentum probability distribution of the beam after the shutter.\n 6.4 Calculate the momentum space wave function for a particle in an energy eigenstate of the \ninﬁnite square well. Plot the momentum probability densities for the n \u0003 1, 2, and 10 energy \neigenstates. Discuss your results.\n 6.5 Show that the momentum and Hamiltonian operators commute for a free particle. Do this two \nways, using both the differential form (position representation) of the operators and the abstract \nform.\n 6.6 Calculate the commutator of the position and momentum operators. Do this two ways, using \nboth the position representation of the operators and the momentum representation.\n 6.7 Show that the momentum eigenstates wp1x2 = Aei px>U satisfy the Dirac orthogonality condition \nin Eq. (6.23) and that the normalization constant is A = 1> 12pU. Use the Dirac orthogonality \ncondition to normalize the wave vector eigenstates wk1x2 = Aeikx\n  and explain why the result \ndiffers from that for the momentum eigenstates.\n 6.8 Use your favorite computational plotting tool to create and plot a wave packet comprising \nthree sinusoidal waves, as done in Section 6.2.1. Vary the separation dp of the side modes \nfrom the  central mode and notice the effect upon the spatial extent dx of the “localized” wave \npacket. Quantify the relationship between the momentum spread dp and the position spread dx. \n Animate your plots and distinguish the motion of the wave packet envelope and the motion of \nthe sinusoidal waves inside the envelope.\n 6.9 Perform the Gaussian integral in Eq. (6.48) and verify the result in Eq. (6.49).\n","page_start":222,"page_end":222,"token_count":670,"section_type":"other","chapter_number":7,"chapter_title":"Angular Momentum","chunk_index":282}
{"chunk_id":"98962e36a7081127","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"Problems \n199\n 6.10 Calculate the expectation values of position and momentum for a Gaussian wave packet by \ndirect integration and verify Eqs. (6.56) and (6.59).\n 6.11 Use your favorite computational plotting tool to create and plot a Gaussian wave packet. Vary \nthe width b of the momentum distribution and notice the effect upon the spatial extent \u0006x of \nthe wave packet. Quantify the relationship between the momentum spread and the position \nspread. Animate your plots and distinguish the motion of the wave packet envelope and the \nmotion of the sinusoidal waves inside the envelope.\n 6.12 Show that a propagating Gaussian wave packet broadens in position space but not in \n momentum space. Plot the position-momentum uncertainty product as a function of  \ntime and show that the Gaussian wave packet is a minimum uncertainty state. Discuss  \nyour results.\n 6.13 Discuss each step in the calculation of the phase and group velocities in Eqs. (6.62) and (6.63).\n 6.14 Consider a particle whose wave function is c1x2 = Asin1 p0  x>U2. Is this wave function an \neigenstate of momentum? Find the expectation value 8p9 of the momentum and the momentum \nprobability distribution. Calculate the uncertainty \u0006p of the momentum. What are the possible \nresults of a measurement of the momentum?\n 6.15 Use the uncertainty principle to estimate the ground state energy of a particle of mass m \n conﬁned to a box with a size of a. Calculate the energy in electron volts for an electron \n conﬁned in a box with a = 0.1 nm, which is roughly the size of an atom.\n 6.16 Use the uncertainty principle to estimate the ground-state energy of a particle of mass m bound \nin the harmonic oscillator potential V1x2 = 1\n2\n kx 2.\n 6.17 Use the uncertainty principle to estimate the ground-state energy of a particle of mass m bound \nin the potential V1x2 = a0 x0 .\n 6.18 Use the uncertainty principle to estimate the ground-state energy of a particle of mass m bound \nin the potential V1x2 = bx4.\n 6.19 Use the uncertainty principle to estimate the ground-state energy of the hydrogen atom.\n 6.20 Calculate the position uncertainty for a particle bound to an inﬁnite square well of width L \nif (a) the particle is in the ground state, and (b) if the probability density is uniform across \nthe well.\n 6.21 A beam of particles is described by the wave function\nc1x2 = Aei p0>Ux e-x2>4a2.\na) Calculate the expectation value 8p9 of the momentum by working in the position \nrepresentation.\nb) Calculate the expectation value 8p9 of the momentum by working in the momentum \nrepresentation.\n 6.22 A beam of particles is described by the wave function\nc1x2 = eAei p0 x>U1b - 0 x02,\n0,\n   0 x0 6 b\n0 x0 7 b.\na) Normalize the wave function. \nb) Plot the wave function.\nc) Calculate and plot the momentum probability distribution.\n","page_start":223,"page_end":223,"token_count":699,"section_type":"other","chapter_number":7,"chapter_title":"Angular Momentum","chunk_index":283}
{"chunk_id":"515aec4189f6504a","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"200 \nUnbound States\n0\nV(x)\nV0\nx\nFIGURE 6.26 Step potential.\n 6.23 Some radioactive nuclei emit electrons (beta radiation), so you might speculate that electrons \ncan exist within a nucleus. Use the uncertainty principle to estimate the minimum kinetic \nenergy (beware of relativity) of an electron conﬁned within a nucleus of size 2 fm. Compare \nthat with the Coulomb potential energy of the electron and comment on the possibility of \n electron conﬁnement within the nucleus.\n 6.24 Solve the boundary condition equations (6.90) to ﬁnd the amplitudes for transmission and \nreﬂection in Eq. (6.91).\n 6.25 Electrons incident upon a ﬁnite square well of depth 12 eV are transmitted with unit probabil-\nity when their kinetic energy is 20 eV. What is the minimum width of the well? Assuming this \nminimum width, for what other kinetic energies are the electrons also transmitted completely? \nDoes this well have any bound states?\n 6.26 A ﬁnite square well of depth 8 eV has 5 bound states. Electrons incident upon the well are \ntransmitted with unit probability when their kinetic energy is 11 eV. What is the width of the \nwell? For what other kinetic energies are the electrons also transmitted completely?\n 6.27 A ﬁnite square well has depth 5 eV and width 0.5 nm. What are the bound-state energies of this \nwell? Find the kinetic energies of electrons incident upon the well that are transmitted with unit \nprobability.\n 6.28 A ﬁnite square barrier has height 5 eV and width 1 nm. Find the kinetic energies of electrons \nincident upon the well that are transmitted with unit probability.\n 6.29 Consider a potential energy step as shown in Fig. 6.26 with a beam of particles incident from \nthe left.\na) Calculate the reﬂection coefﬁcient for the case where the energy of the incident particles is \nless than the height of the potential energy step.\nb) Calculate the reﬂection coefﬁcient for the case where the energy of the incident particles is \ngreater than the height of the step.\nc) Plot your results as a function of the incident energy and comment.\n 6.30 Show that a double step potential can be designed such that particles of particular energies are \ntransmitted with unit probability. The optical analogue is an antireﬂection coating.\n 6.31 Calculate the probability of transmission of an electron with kinetic energy 5 eV through a \n barrier of height 10 eV and width 1 nm.\n","page_start":224,"page_end":224,"token_count":571,"section_type":"other","chapter_number":7,"chapter_title":"Angular Momentum","chunk_index":284}
{"chunk_id":"21e39fdbc493e865","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"Resources \n201\n 6.32 Consider a particle incident upon a potential energy barrier with a barrier height larger than the \nkinetic energy. Show that the growing exponential wave inside the barrier is always less than or \nequal to the decaying exponential term.\n 6.33 Show that the tunneling probability through a barrier of width d is proportional to e-2qd for \nqd W 1.\n 6.34 If the tunneling current in a scanning tunneling microscope is 1 nA at 1 nm tip-surface \n separation, how much current will ﬂow at tip-surface separations of 0.8 nm, 1.2 nm, or 2 nm? \nAssume that the work functions of the metals are 5 eV and that the bias voltage is minimal.\nRESOURCES\nActivities\nThe bulleted activity is available at\nwww.physics.oregonstate.edu/qmactivities\n•  Time Evolution of a Gaussian Wave Packet: Students predict and study the time evolution of a \nGaussian wave packet.\nQuantum Tunneling and Wave Packets: This simulation experiment from the PHET group at the \nUniversity of Colorado animates wave functions tunneling through barriers: \nhttp://phet.colorado.edu/en/simulation/quantum-tunneling\nFurther Reading\nInterference experiments with particles are discussed in these articles:\nA. Tonomura, J. Endo, T. Matsuda, T. Kawasaki, and H. Ezawa, “Demonstration of single- \nelectron buildup of an interference pattern,” Am. J. Phys. 57, 117–120 (1989).\nO. Nairz, M. Arndt, and A. Zeilinger, “Quantum interference experiments with large molecules,” \nAm. J. Phys. 71, 319–325 (2003).\nD. E. Pritchard, A. D. Cronin, S. Gupta, D. A. Kokorowski, “Atom optics: Old ideas, current \n technology, and new results,” Ann. Phys. (Leipzig) 10, 35–54 (2001).\nThe Nobel Prize for scanning tunneling microscopy is described here: \nnobelprize.org/nobel_prizes/physics/laureates/1986/\n","page_start":225,"page_end":225,"token_count":475,"section_type":"other","chapter_number":7,"chapter_title":"Angular Momentum","chunk_index":285}
{"chunk_id":"f255def23a737c7d","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"C H A P T E R  \n7\nAngular Momentum\nIn the last two chapters, we learned the fundamentals of solving quantum mechanical problems with \nthe wave function approach. We studied particles bound in idealized square potential energy wells \nand free particles. We are now ready to attack the most important problem in the history of quan-\ntum mechanics—the hydrogen atom. The ability to solve this problem and compare it with precision \nexperiments has played a central role in making quantum mechanics the best proven theory in physics.\nThe hydrogen atom is the bound state of a positively charged proton and a negatively charged \nelectron that are attracted to each other by the Coulomb force. Classically, we expect the electron \n(me = 9.11 * 10-31 kg) to orbit around the more massive proton (mp = 1.67 * 10-27 kg), in the \nsame manner that the earth orbits around the sun, as depicted in Fig. 7.1(a). However, the uncertainty \nprinciple dictates that we cannot know the position of the electron well enough for Fig. 7.1(a) to be a \nvalid representation, but rather, the electron is represented by a probability cloud as in Fig. 7.1(b). By \nthe end of the next chapter, we will be able to predict the details of the many different possible shapes \nof the electron cloud.\nAs always in quantum mechanics, we begin by identifying the Hamiltonian of the system of inter-\nest because of its role in determining the dynamics of the system through the Schrödinger equation\n \niU d\ndt 0 c9 = H0 c9. \n(7.1)\nFIGURE 7.1 (a) A classical atom and (b) a quantum atom.\n","page_start":226,"page_end":226,"token_count":367,"section_type":"other","chapter_number":7,"chapter_title":"Angular Momentum","chunk_index":286}
{"chunk_id":"9818cacd4b312dc5","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"7.1 Separating Center-of-Mass and Relative Motion \n203\nHsysΨsys(R,r) \u0004 EsysΨsys(R,r)\nΨsys(R,r) \u0004 ΨCM(R)Ψrel(r)\n7.30\n7.24, 7.27\n7.20\n7.21\nHCMΨCM(R)\u0004 ECMΨCM(R)\n7.24, 7.28\nHrelΨrel(r) \u0004 ErelΨrel(r)\nΨCM(X,Y,Z)\nr\nΘ\nΦ\nΨsys(R,r) \u0004 ΨCM(X,Y,Z)Ψrel(r,Θ,Φ)\nΨrel(r,Θ,Φ)\u0004R(r)Θ(Θ)Φ(Φ)\n8.69\nFIGURE 7.2 Flowchart for solving the hydrogen atom energy eigenvalue problem by reducing the \ntwo-body problem to a one-body problem and by separation of the spherical coordinate variables.  \nThe numbers in the corners of the boxes refer to the relevant equation numbers in the text.\nOnce we know the Hamiltonian, we ﬁnd the energy eigenstates by solving the energy eigenvalue equation\n \nH0 E9 = E0 E9. \n(7.2)\nThe energy eigenstates form the preferred basis for expanding any initial state and applying the \nSchrödinger time evolution recipe, so solving the energy eigenvalue equation is the primary task \nrequired to solve most quantum mechanical problems.\nCompared to the problems in the last two chapters, the hydrogen atom system presents us with \ntwo major complications: two particles and three dimensions. The goal of this chapter is to simplify \nboth these aspects of the problem. Analogous to the approach taken in classical mechanics, we reduce \nthe two-body problem to a ﬁctitious one-body problem and we separate the three spatial degrees of \nfreedom in a way that each spherical coordinate can be treated independently. A ﬂowchart depicting \nthese two simpliﬁcations is shown in Fig. 7.2. In this chapter, we perform all the steps of Fig. 7.2 except \nthe radial coordinate part. In particular, we focus on the two angular degrees of freedom because they \nrelate to the angular momentum, which is a conserved quantity. In the next chapter, we solve the radial \naspect of the problem for a 1>r Coulomb potential energy, which leads to the quantized energy levels \nof the hydrogen atom. The journey through the next two chapters requires some mathematics that may \nappear daunting; we provide the roadmaps in Figs. 7.2 and 7.6 so you can see the forest for the trees.\n","page_start":227,"page_end":227,"token_count":579,"section_type":"other","chapter_number":7,"chapter_title":"Angular Momentum","chunk_index":287}
{"chunk_id":"c447ddca7ee5bd79","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"204 \nAngular Momentum\nFor a three-dimensional system of two particles, the Hamiltonian is the sum of the kinetic energies \nof the two individual particles and the potential energy that describes the interaction between them:\n \nHsys =\np2\n1\n2m1\n+\np2\n2\n2m2\n+ V1r1, r22. \n(7.3)\nParticle 1 has mass m1, position r1, and momentum p1; particle 2 has mass m2, position r2, and \nmomentum p2, and the interaction of the two particles is characterized by the potential energy \nV1r1, r22. We assume that the potential energy depends only on the magnitude of the separation of \nthe two particles\n \nV1r1, r22 = V10 r1 - r202, \n(7.4)\nwhich we refer to as a central potential. In this chapter, we do not need to know the actual form of \nthe central potential. In fact, the quantum mechanical angular wave functions we ﬁnd in this chapter \nare valid for any central potential, which is a very powerful result. We introduce the Coulomb potential \nenergy for the hydrogen atom system in the next chapter.\n 7.1 \u0002 SEPARATING CENTER-OF-MASS AND RELATIVE MOTION\nIn classical mechanics, we simplify the motion of a system of particles by separating the motion of the \ncomposite system into the motion of the center of mass and the motion about the center of mass. We \ntake this same approach to simplify the quantum mechanical description of the hydrogen atom. We will \nwork this through in some detail because the procedure of separating the motion is very common and \nneeds to be understood, but, in fact, we will not pursue the motion of the center of mass beyond this \nsection. In the next section, we’ll begin the discussion of the motion about the center of mass, which is \nwhere many treatments of the hydrogen atom start.\nAs illustrated in Fig. 7.3, we deﬁne the center-of-mass coordinate position vector for this two-\nbody system as\n \nR = m1r1 + m2r2\nm1 + m2\n \n(7.5)\nand the relative position vector as\n \nr = r2 - r1. \n(7.6)\nIn classical mechanics, we typically use velocities, which are obtained by differentiation of position \nwith respect to time. In quantum mechanics, we use momentum as the preferred quantity, so the appro-\npriate quantities to separate the two-body motion are the momentum of the center of mass\n \nP = p1 + p2 \n(7.7)\nand the relative momentum\n \nprel = m1p2 - m2p1\nm1 + m2\n. \n(7.8)\n","page_start":228,"page_end":228,"token_count":586,"section_type":"other","chapter_number":7,"chapter_title":"Angular Momentum","chunk_index":288}
{"chunk_id":"0ed29a7bd15895d7","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"7.1 Separating Center-of-Mass and Relative Motion \n205\nThe relative momentum takes the simpler form that looks like a relative velocity\n \nprel\nm\n= p2\nm2\n- p1\nm1\n \n(7.9)\nif we deﬁne the reduced mass m:\n \n 1\nm =\n1\nm1\n+ 1\nm2\n \n \n m =\nm1m2\nm1 + m2\n . \n \n(7.10)\nWith the deﬁnitions in Eqs. (7.7) and (7.8), the two-body Hamiltonian in Eq. (7.3) becomes \n(Problem 7.1)\n \nHsys = P 2\n2M +\np 2\nrel\n2m + V1r2, \n(7.11)\nwhere the relative particle separation r is the magnitude 0 r2 - r10 . This procedure has separated the \nsystem Hamiltonian into two independent parts:\n \nHsys = HCM + Hrel, \n(7.12)\nwith a center-of-mass term\n \nHCM = P2\n2M \n(7.13)\nrepresenting the motion of a particle of mass M = m1 + m2 located at position R with momentum \nP = p1 + p2, and a relative term\n \nHrel =\np 2\nrel\n2m + V1r2 \n(7.14)\nx\ny\nr \u0004 r2 \u0002 r1\nz\nm2 (x2,y2,z2)\nm1 (x1,y1,z1)\nR\u000b\n\u000b\n\u000b\n\u000b\n\u000b\n\u000b\n(X,Y,Z)\nr1\nr2\nFIGURE 7.3 The center-of-mass and relative coordinates for a two-body system.\n","page_start":229,"page_end":229,"token_count":384,"section_type":"other","chapter_number":7,"chapter_title":"Angular Momentum","chunk_index":289}
{"chunk_id":"118897dd289d0623","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"206 \nAngular Momentum\nrepresenting the motion of a single ﬁctitious particle of mass m located at position r = r2 - r1 with \nmomentum prel subject to a potential energy V1r2 created by a force-center that is ﬁxed at the origin. \nNotice that the center-of-mass Hamiltonian HCM does not depend on the relative motion variables prel \nand r, and the relative Hamiltonian Hrel does not depend on the center-of-mass motion variables P \nand R; this is what we mean by “separable.” In contrast, Eq. (7.3) presents the same Hamiltonian in \nterms of p1 and r1 and p2 and r2, but the potential energy V contains both r1 and r2, so H is not sepa-\nrable in those coordinates. Notice also that the center-of-mass position vector R does not appear in \nthe Hamiltonian at all, which, classically, is a reﬂection of the fact that the momentum of the center \nof mass is conserved because there are no external forces. For the hydrogen atom system, the reduced \nmass is m = 0.9995me and the center of mass is located very near the proton.\nThe separation of the Hamiltonian into center-of-mass motion and relative motion can also be \ndone using the explicit position representation of the momentum operators as differentials. In the posi-\ntion representation, the one-dimensional momentum operator is\np \u0003 -i U d\ndx . \n(7.15)\nIn three dimensions, the momentum operator is cast in terms of the gradient operator \u0002:\np \u0003 -i U a 0\n0x\n in +\n0\n0y\n jn +\n0\n0z\n kn b = -i U\u0002. \n(7.16)\nFor a two-particle system, the momentum operators for the two particles are\n p1 \u0003 -i U ¢ 0\n0x1\n in +\n0\n0 y1\n jn +\n0\n0 z1\n kn ≤= -i U\u00021  \n p2 \u0003 -i U ¢ 0\n0x2\n in +\n0\n0 y2\n jn +\n0\n0z2\n kn ≤= -i U\u00022. \n(7.17)\nSubstituting these position representations into the Hamiltonian in Eq. (7.3) leads to the same separa-\ntion as in Eq. (7.11), where the center-of-mass momentum operator has the position representation \n(Problem 7.1)\nP \u0003 -i U a 0\n0X\n in +\n0\n0Y\n jn +\n0\n0Z\n kn b = -i U\u0002R. \n(7.18)\nX, Y, and Z are the Cartesian coordinates of the center-of-mass vector R, and \u0002R is the gradient opera-\ntor corresponding to the center-of-mass coordinates. The relative momentum operator has the position \nrepresentation\nprel \u0003 -i U a 0\n0x\n in +\n0\n0 y\n jn +","page_start":230,"page_end":230,"token_count":661,"section_type":"other","chapter_number":7,"chapter_title":"Angular Momentum","chunk_index":290}
{"chunk_id":"b7c5ce0c2fe29242","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"0X\n in +\n0\n0Y\n jn +\n0\n0Z\n kn b = -i U\u0002R. \n(7.18)\nX, Y, and Z are the Cartesian coordinates of the center-of-mass vector R, and \u0002R is the gradient opera-\ntor corresponding to the center-of-mass coordinates. The relative momentum operator has the position \nrepresentation\nprel \u0003 -i U a 0\n0x\n in +\n0\n0 y\n jn +\n0\n0z\n kn b = -i U\u0002r, \n(7.19)\nwhere x, y, and z are the Cartesian coordinates of the relative position vector r = r2 - r1 and \u0002r is the \ngradient operator corresponding to the relative coordinates.\nWith the Hamiltonian separated into center-of-mass motion and relative motion, we expect that \nthe quantum state vector can also be separated. This is not always the case, as we saw in the discussion \nof entanglement in Chapter 4, but it is a valid assumption for the hydrogen atom problem we want to \nsolve because the potential energy is a function only of the relative coordinate r. Hence, we write the \nwave function for the system as\ncsys1R, r2 = cCM1R2 crel1r2. \n(7.20)","page_start":230,"page_end":230,"token_count":282,"section_type":"other","chapter_number":7,"chapter_title":"Angular Momentum","chunk_index":291}
{"chunk_id":"44cc0aeace895768","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"7.1 Separating Center-of-Mass and Relative Motion \n207\nThe energy eigenvalue equation for the system is\nHsys csys1R, r2 = Esys  csys1R, r2, \n(7.21)\nand substituting the separated Hamiltonian [Eq. (7.12)] and separated wave function [Eq. (7.20)] gives\n1HCM + Hrel2cCM1R2 crel1r2 = Esys  cCM1R2 crel1r2. \n(7.22)\nThe separate center-of-mass and relative Hamiltonians act only on their respective wave functions \nbecause the gradients \u0002R and \u0002r are independent, so Eq. (7.22) becomes\ncrel1r2HCM cCM1R2 + cCM1R2Hrel crel1r2 = Esys  cCM1R2 crel1r2. \n(7.23)\nWe assert that the separate center-of-mass and relative Hamiltonians satisfy their own energy eigen-\nvalue equations (Problem 7.2)\n HCM cCM1R2 = ECM cCM1R2 \n Hrel crel1r2 = Erel crel1r2 \n(7.24)\nand arrive at the energy eigenvalue equation for the system \nHsys cCM1R2 crel1r2 = 1ECM + Erel2cCM1R2 crel1r2, \n(7.25)\nwhich demonstrates that the system energy is the additive energy of the two parts\nEsys = ECM + Erel. \n(7.26)\nUsing the separate Hamiltonians in Eqs. (7.13) and (7.14), the separated energy eigenvalue \nequations are\nP 2\n2M\n cCM1R2 = ECM cCM1R2 \n(7.27)\nand\na\np 2\nrel\n2m + V1r2b  crel1r2 = Erel crel1r2. \n(7.28)\nThe center-of-mass energy eigenvalue equation (7.27) is the free particle eigenvalue equation we \nencountered in Chapter 6, while the relative motion energy eigenvalue equation (7.28) contains the \ninteraction potential and so has the interesting physics of the hydrogen atom. Using the position rep-\nresentation of the momentum operator in Eq. (7.18), the center-of-mass energy eigenvalue equation is\n-  U2\n2M\n a 0 2\n0X 2 + 0 2\n0Y 2 + 0 2\n0Z 2b cCM1X, Y, Z2 = ECM cCM1X, Y, Z2. \n(7.29)\nThe solution to Eq. (7.29) is the three-dimensional extension of the free-particle eigenstates we stud-\nied in Chapter 6\ncCM1X, Y, Z2 =\n1\n12pU2\n3>2 e i1PXX+PYY+PZZ2>U ","page_start":231,"page_end":231,"token_count":664,"section_type":"other","chapter_number":7,"chapter_title":"Angular Momentum","chunk_index":292}
{"chunk_id":"4e0a99b472102c96","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"0Z 2b cCM1X, Y, Z2 = ECM cCM1X, Y, Z2. \n(7.29)\nThe solution to Eq. (7.29) is the three-dimensional extension of the free-particle eigenstates we stud-\nied in Chapter 6\ncCM1X, Y, Z2 =\n1\n12pU2\n3>2 e i1PXX+PYY+PZZ2>U \n(7.30)\nwith energy eigenvalues\nECM =\n1\n2M AP 2\nX + P 2\nY + P 2\nZB. \n(7.31)","page_start":231,"page_end":231,"token_count":140,"section_type":"other","chapter_number":7,"chapter_title":"Angular Momentum","chunk_index":293}
{"chunk_id":"556b7e1078ad2ab1","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"208 \nAngular Momentum\nFor measurements of observables associated with the relative motion, the center-of-mass wave func-\ntion contributes only an overall phase to the system wave function and so has no effect on calculat-\ning probabilities of relative motion quantities. We can therefore leave the center-of-mass motion and \nconcentrate only on the relative motion dictated by the energy eigenvalue equation (7.28). That is the \nproblem we want to solve for the hydrogen atom. Remember that the angular momentum discusssion \nthat will follow in this chapter is valid for any central potential. In Chapter 8, we will insert the speciﬁc \nform of the potential for the hydrogen atom.\n7.2 \u0002 ENERGY EIGENVALUE EQUATION IN SPHERICAL COORDINATES\nThe relative motion Hamiltonian that governs the hydrogen atom is\n \nH = p 2\n2m + V1r2, \n(7.32)\nwhere we drop the “relative” subscripts because we are now focusing exclusively on the relative \nmotion and ignoring the center-of-mass motion. Using the position representation of the momentum \noperator from Eq. (7.19), the Hamiltonian is represented by\n \nH \u0003 -  U2\n2m\n \u00022 + V1r2 \n(7.33)\nand the energy eigenvalue equation is the differential equation\n \na-  U2\n2m\u00022 + V1r2b c1r2 = Ec1r2. \n(7.34)\nBecause the potential energy in Eq. (7.34) depends on the parameter r only, this problem is clearly \nasking for the use of spherical coordinates centered at the origin of the central potential. The system of \nspherical coordinates is shown in Fig. 7.4(a) and the relations between the spherical coordinates r, u, f \nand the Cartesian coordinates x, y, z are\n \n x = r sin u cos f \n \n y = r sin u sin f  \n \n(7.35)\n \n z = r cos u.\n \nThe differential volume element dV = dx dy dz expressed in spherical coordinates is\n \ndV = r2 sin u d u d f dr. \n(7.36)\nThis volume element is shown in Fig. 7.4(b), leading one to consider the grouping\n \ndV = 1r d u21r sin u d f21dr2. \n(7.37)\nHowever, for calculating the normalization of wave functions, we will group the terms as\n \ndV = 1sin u d u21d f21r2 dr2 \n(7.38)\n","page_start":232,"page_end":232,"token_count":552,"section_type":"other","chapter_number":7,"chapter_title":"Angular Momentum","chunk_index":294}
{"chunk_id":"be92cbbfd925d3a0","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"7.2 Energy Eigenvalue Equation in Spherical Coordinates \n209\nand normalize each coordinate piece of the wave function separately. It is also convenient to express \nthe volume element as\n \ndV = r2 dr d\t, \n(7.39)\nwhere\n \nd\t = sin u d u d f \n(7.40)\nis the differential solid angle element.\nIn spherical coordinates, the gradient operator is\n \n\u0002 = rn 0\n0r + un 1\nr\n  0\n0 u + fn \n1\nr sin u\n  0\n0 f \n(7.41)\nand the Laplacian operator \u00022 = \u0002~\u0002 is\n \n\u00022 = 1\nr2  0\n0r\n ar2\n 0\n0r b +\n1\nr2 sin u\n  0\n0 u\n asin u 0\n0 u b +\n1\nr2 sin2 u\n  0 2\n0 f2 . \n(7.42)\nUsing this spherical coordinate representation, the energy eigenvalue equation (7.34) becomes the dif-\nferential equation\n \n-  U2\n2m\n c 1\nr2  0\n0r\n ar2\n 0\n0r b +\n1\nr2 sin u\n  0\n0 u\n asin u 0\n0 u b +\n1\nr2 sin2 u\n  0 2\n0 f2 d c1r, u, f2 \n \n+ V1r2c1r, u, f2 = Ec1r, u, f2 .  \n(7.43)\nThis looks formidable, so it is worth remembering that this is just the position representation of the \nenergy eigenvalue equation\n \nH0 E9 = E0 E9. \n(7.44)\nSolving Eq. (7.43) for the energy E and the eigenstates 0 E9 \u0003 c1r, u, f2 is our primary task, but ﬁrst \nlet’s discuss the important role that angular momentum plays in this equation.\n(a)\nx\ny\nz\nr\u0002\nΘ\nΦ\ndΘ\ndΦ\ndr\nx\ny\nz\n(b)\nFIGURE 7.4 (a) Spherical coordinates and (b) the differential volume element.\n","page_start":233,"page_end":233,"token_count":502,"section_type":"other","chapter_number":7,"chapter_title":"Angular Momentum","chunk_index":295}
{"chunk_id":"e3adf8cf2b95f598","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"210 \nAngular Momentum\n7.3 \u0002 ANGULAR MOMENTUM\n 7.3.1 \u0002 Classical Angular Momentum\nThe classical angular momentum is deﬁned as\nL = r * p. \n(7.45)\nIn the case of central forces, the torque r * F is zero and angular momentum is a conserved quantity:\nt = d L\ndt = 0  1   L = constant. \n(7.46)\nA central force F1r2 depends only on the distance of the reduced mass from the center of force \n(i.e., the separation of the two particles) and not on the angular orientation of the system. Therefore, \nthe system is spherically symmetric; it is invariant (unchanged) under rotations. Noether’s theorem \nstates that whenever the laws of physics are invariant under a particular motion or other operation, \nthere will be a corresponding conserved quantity. In this case, the conservation of angular momentum \nis related to the invariance of the physical system under rotations.\n 7.3.2 \u0002 Quantum Mechanical Angular Momentum\nIn quantum mechanics, the Cartesian components of the angular momentum operator L = r * p in \nthe position representation are\n Lx = ypz - zpy \u0003 -i U ay 0\n0z - z 0\n0y b  \n Ly = zpx - xpz \u0003 -i U az 0\n0x - x 0\n0z b  \n(7.47)\n Lz = xpy - ypx \u0003 -i U ax 0\n0y - y 0\n0x b. \nPosition and momentum operators for a given axis do not commute 13x, px4 = iU, etc.2, whereas posi-\ntion and momentum operators for different axes do commute 13x, py4 = 0, etc.2. We can use these \ncommutators to calculate the commutators of the components of the angular momentum operator. For \nexample,\n 3Lx, Ly4 = 3ypz - zpy, zpx - xpz4\n = ypz  z px - ypz  x pz - z py \n z px + z py \n x pz - z px  ypz + z px  z py + x pz  ypz - x pz\n z py\n . \n(7.48)\nNow use the commutation relations to move commuting operators through each other (e.g., \nypz  z px = ypx pz z) and cancel terms:\n3Lx, Ly4 = ypx  pz\n z - x ypz  pz - zz px py + x py z pz - ypx  z pz + zz px py + x ypz  pz - x py  pz\n z \n= ypx pzz + x py  z pz - ypx  z pz - x py  pz\n z . \n(7.49)\nFinally, collect terms and use the commutator relation 3z, pz4 = iU :\n 3Lx, Ly4 = x py1z pz - pz\n z2 - ypx1z pz - pz\n z2 ","page_start":234,"page_end":234,"token_count":667,"section_type":"other","chapter_number":7,"chapter_title":"Angular Momentum","chunk_index":296}
{"chunk_id":"a3c395691be73735","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":" z \n= ypx pzz + x py  z pz - ypx  z pz - x py  pz\n z . \n(7.49)\nFinally, collect terms and use the commutator relation 3z, pz4 = iU :\n 3Lx, Ly4 = x py1z pz - pz\n z2 - ypx1z pz - pz\n z2 \n = x py3z, pz4 - ypx3z, pz4\n(7.50)\n = i U1xpy - ypx2\n = i ULz .","page_start":234,"page_end":234,"token_count":122,"section_type":"other","chapter_number":7,"chapter_title":"Angular Momentum","chunk_index":297}
{"chunk_id":"7ffc34e6ab796f77","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"7.3 Angular Momentum \n211\nCyclic permutations of this identity give the three commutation relations\n 3Lx, Ly4 = i ULz \n 3Ly, Lz4 = i ULx  \n(7.51)\n 3Lz, Lx4 = i ULy  . \nThese are exactly the same commutation relations that spin angular momentum obeys (Section 2.4)! \nSo orbital and spin angular momentum appear to have something in common, as you might expect. \nIndeed, this is why the physical property of spin angular momentum was given this name.\nWhen we studied spin, we found it useful to consider the S2 = S~S operator. The corresponding \noperator for orbital angular momentum is\nL 2 = L~L = L2\nx + L2\ny + L2\nz . \n(7.52)\nIn the spin case, the operator S2 commutes with all three component operators. Let’s try the same with \norbital angular momentum. For example,\n 3L 2, Lx4 = 3L2\nx + L2\ny + L2\nz , Lx4\n = 3L2\nx, Lx4 + 3L2\ny, Lx4 + 3L2\nz , Lx4  \n(7.53)\n = L2\ny Lx - Lx L2\ny + L2\nzLx - Lx L2\nz . \nAdd zero to this equation, but choose the terms that sum to zero cleverly so they help:\n 3L 2, Lx4 = Ly Ly Lx - Ly Lx Ly + Ly Lx Ly - Lx Ly Ly + Lz Lz Lx - Lz Lx Lz + Lz Lx Lz - Lx Lz Lz \n=0\n=0\n = Ly3Ly, Lx4 + 3Ly, Lx4Ly + Lz3Lz, Lx4 + 3Lz, Lx4Lz \n(7.54)\n = -i ULy Lz - i ULz Ly + i ULz Ly + i ULy Lz\n = 0.\nThe other two components also commute with L 2 (Problem 7.4):\n 3L 2, Lx4 = 0  \n 3L 2, Ly4 = 0  \n(7.55)\n 3L 2, Lz4 = 0  . \nSo orbital and spin angular momentum obey all the same commutation relations.\nThough we did not do it that way in Chapter 1, the eigenvalues and the eigenstates of spin angular \nmomentum can be derived solely from the commutation relations of the operators (see Section 11.3). \nThe spin eigenvalue equations are\n S20 sms9 = s1s + 12U20 sms9 \n(7.56)\n Sz0 sms9 = ms U0 sms9.\nThe states 0 sms9 are simultaneously eigenstates of S2 and Sz, which is possible because the two opera-","page_start":235,"page_end":235,"token_count":656,"section_type":"other","chapter_number":7,"chapter_title":"Angular Momentum","chunk_index":298}
{"chunk_id":"65865e01731de7cf","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"momentum can be derived solely from the commutation relations of the operators (see Section 11.3). \nThe spin eigenvalue equations are\n S20 sms9 = s1s + 12U20 sms9 \n(7.56)\n Sz0 sms9 = ms U0 sms9.\nThe states 0 sms9 are simultaneously eigenstates of S2 and Sz, which is possible because the two opera-\ntors commute with each other. Because orbital angular momentum obeys the same commutation rela-\ntions as spin, the eigenvalue equations for L 2 and Lz have the same form:\n L 20 /m/9 = /1/ + 12U20 /m/9 \n Lz0 /m/9 = m/ U0 /m/9\n(7.57)","page_start":235,"page_end":235,"token_count":169,"section_type":"other","chapter_number":7,"chapter_title":"Angular Momentum","chunk_index":299}
{"chunk_id":"136e2bd34d46436b","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"212 \nAngular Momentum\nand the states 0 /m/9 are simultaneously eigenstates of L 2 and Lz. Hence, we can draw on all the work \nwe did in the spins chapters to help us understand orbital angular momentum. The quantum number / \nis the orbital angular momentum quantum number and gives a measure of the “size” of the angular \nmomentum vector in that the magnitude is 2/1/ + 12U. The quantum number m/ is the orbital magnetic \nquantum number and indicates that the magnitude of the z-component of the angular momentum is m/ U.\nThere is one crucial difference between spin angular momentum and orbital angular momentum. \nIn the spin case, the allowed quantized values of the spin angular momentum quantum number s are \nthe integers and half integers:\ns = 0, 1\n2, 1, 3\n2, 2, 5\n2, 3, 7\n2, 4, ... . \n(7.58)\nIn Chapters 1–3 we studied spin-1/2 and spin-1 systems. In the case of orbital angular momentum, the \nquantum number / is allowed to take on only integer values\n/ = 0, 1, 2, 3, 4, ...  . \n(7.59)\nOther than this important distinction, spin and orbital angular momentum behave the same in quantum \nmechanical calculations of probabilities, expectation values, etc. The spin magnetic quantum number \nms spans the range from -s S +s in integer steps. The orbital magnetic quantum number m/ is similarly \nrestricted to the 2/ + 1 values\nm/ = -/, -/ + 1, ..., -1, 0, 1, ..., / - 1, /  . \n(7.60)\nIn the spin-1/2 system, we represent the spin operators as matrices:\n S2 \u0003 3\n4\n U2 a1\n0\n0\n1b  Sz \u0003 U\n2\n a1\n0\n0\n-1b  \n Sx \u0003 U\n2\n a0\n1\n1\n0b   Sy \u0003 U\n2\n a0\n-i\ni\n0 b  ,\n(7.61)\nwhere the basis states of the representation are the eigenstates of S2 and Sz as deﬁned in Eq. (7.56). For \norbital angular momentum, we also represent the operators as matrices, with the exception that only \ninteger values of / are allowed. For example, the matrix representations of the orbital angular momen-\ntum operators for / = 1 are\n L 2 \u0003 2U2 °\n1\n0\n0\n0\n1\n0\n0\n0\n1\n¢  L z \u0003 U\n  °\n1\n0\n0\n0\n0\n0\n0\n0\n-1\n¢\n Lx \u0003\nU\n22\n °\n0\n1\n0\n1\n0\n1\n0\n1\n0\n¢    Ly \u0003\nU\n22\n °\n0\n-i\n0\ni\n0","page_start":236,"page_end":236,"token_count":672,"section_type":"other","chapter_number":7,"chapter_title":"Angular Momentum","chunk_index":300}
{"chunk_id":"e0916eccf9202163","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"integer values of / are allowed. For example, the matrix representations of the orbital angular momen-\ntum operators for / = 1 are\n L 2 \u0003 2U2 °\n1\n0\n0\n0\n1\n0\n0\n0\n1\n¢  L z \u0003 U\n  °\n1\n0\n0\n0\n0\n0\n0\n0\n-1\n¢\n Lx \u0003\nU\n22\n °\n0\n1\n0\n1\n0\n1\n0\n1\n0\n¢    Ly \u0003\nU\n22\n °\n0\n-i\n0\ni\n0\n-i\n0\ni\n0\n¢  , \n(7.62)\nwhere the basis states of the representation are the eigenstates of L 2 and Lz as deﬁned in Eq. (7.57). \nThese matrices are exactly the same as the spin-1 matrices we deﬁned in Chapter 2.7.","page_start":236,"page_end":236,"token_count":215,"section_type":"other","chapter_number":7,"chapter_title":"Angular Momentum","chunk_index":301}
{"chunk_id":"63b6364cc66908e2","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"7.3 Angular Momentum \n213\nExample 7.1 A particle with orbital angular momentum / = 1 is in the state\n \n0 c9 = 4\n1\n3 0119 + 4\n2\n3 0109. \n(7.63)\nFind the probability that a measurement of Lz yields the value U for this state and calculate the \nexpectation value of Lz.\nThe eigenstate of Lz with eigenvalue Lz = +U Aand eigenvalue L 2 = 2U2B is \n0 / = 1, m/ = 19 = 0 119, so the probability of measuring Lz = +U is\n \n PU = 08110 c90\n2\n \n \n = @  8110  A4\n1\n3 0119 + 4\n2\n3 0109B @\n2\n \n(7.64)\n \n = @4\n1\n3 8110119 + 4\n2\n3 8110109@\n2\n. \nThe states 0 /m/9 form an orthonormal basis, so 8110119 = 1 and 8110109 = 0, and the probability is\n \n PU = @4\n1\n3\n @\n2\n \n(7.65)\n \n = 1\n3.\n \nThe expectation value of Lz is\n \n8Lz9 = 8c0 Lz0 c9. \n(7.66)\nLet’s calculate this with matrices. Using the matrix (column) representation of 0 c9:\n \n0 c9 \u0003\n1\n23\n °\n1\n22\n0\n¢ , \n(7.67)\nwe get\n \n 8Lz9 =\n1\n23\n 11\n \n22\n02 U °\n1\n0\n0\n0\n0\n0\n0\n0\n-1\n¢ 1\n23\n °\n1\n22\n0\n¢\n \n(7.68)\n \n = U\n3\n 11\n \n22\n02°\n1\n0\n0\n¢\n \n \n = U\n3.\n \nThese calculations are no different than if this were a spin-1 problem.\nSo it looks like we can solve orbital angular momentum problems using our spin knowledge, and \nyou may well ask: Is that all there is to it? Yes and no! If you can solve a problem like Example 7.1 \nusing the bra-ket or matrix notation we developed in the spins chapters, then do that. But there are \nproblems where we need to do more.\n","page_start":237,"page_end":237,"token_count":543,"section_type":"other","chapter_number":7,"chapter_title":"Angular Momentum","chunk_index":302}
{"chunk_id":"8aadca16385631b3","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"214 \nAngular Momentum\nIn Chapters 1–3 we never discussed a position representation of spin operators or eigenstates, \nbecause it is not possible to describe spin angular momentum using the wave function language we \ndeveloped in Chapter 5. In contrast, it is possible to represent orbital angular momentum operators and \neigenstates in the position representation. We have already presented the position representation of the \norbital angular momentum operators Lx, Ly, and Lz in Eq. (7.47), and the end result of this chapter is a \nposition representation of the angular momentum eigenstates 0 /m/9. In solving for the allowed spatial \nwave functions, we will prove that the orbital angular momentum is quantized according to Eqs. (7.59) \nand (7.60).\nArmed with wave functions detailing the spatial dependence of orbital angular momentum, we \nwill then be able to visualize the angular probability distribution of the electron around the proton \nin the hydrogen atom. We will be able to understand why two hydrogen atoms form a molecule and \nwhy the carbon bonds in a diamond lattice are oriented in such a way to make diamond so unique. For \nexample, Fig. 7.5 shows the angular orientation of the four tetrahedral bonds that one carbon atom \nmakes within the diamond lattice.\nTo see the importance of orbital angular momentum in solving the hydrogen atom energy eigen-\nvalue equation, we change the angular momentum operators in Eq. (7.47) to spherical coordinates. \nUsing the relations in Eq. (7.35), one can show that the angular momentum operator Lz has the spheri-\ncal coordinate representation (Problem 7.8)\nLz \u0003 -i U 0\n0 f \n(7.69)\nand depends on f alone. Likewise, we convert Lx and Ly to spherical coordinates (Problem 7.8) and \nobtain the operator L 2 = L~L = L 2\nx + L 2\ny + L 2\nz:\nL2 \u0003 -U2 c\n1\n sin u\n  0\n0 u\n asin u 0\n0 u b +\n1\nsin2u\n  0 2\n0 f2d  , \n(7.70)\nwhich depends on u and f, and not on r. We now have the expressions for the two operators L 2 and Lz \nthat we need to express the angular momentum eigenvalue equations (7.57) in the spherical coordinate \nrepresentation, which we do later in this chapter.\nNow compare the L 2 operator in Eq. (7.70) with the energy eigenvalue equation (7.43). You \nnotice that the L 2 operator is part of the differential operator in the energy eigenvalue equation. Hence, \nwe can rewrite the energy eigenvalue equation H0 c9 = E0 c9 with the L 2 operator\n-  U2\n2m\n c 1\nr2 0\n0r\n ar2\n 0\n0r b -\n1","page_start":238,"page_end":238,"token_count":639,"section_type":"other","chapter_number":7,"chapter_title":"Angular Momentum","chunk_index":303}
{"chunk_id":"169941e18921a172","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"Now compare the L 2 operator in Eq. (7.70) with the energy eigenvalue equation (7.43). You \nnotice that the L 2 operator is part of the differential operator in the energy eigenvalue equation. Hence, \nwe can rewrite the energy eigenvalue equation H0 c9 = E0 c9 with the L 2 operator\n-  U2\n2m\n c 1\nr2 0\n0r\n ar2\n 0\n0r b -\n1\nU2r2 L2 d c1r, u, f2 + V1r2c1r, u, f2 =  Ec1r, u, f2  . \n(7.71)\nAll of the angular part of the Hamiltonian is contained in the L 2 angular momentum operator. In this \nform, it is clear that the central force Hamiltonian commutes with the orbital angular momentum oper-\nators L 2 and Lz (Problem 7.9)\n 3H, L 24 = 0 \n 3H, Lz4 = 0, \n(7.72)\nwhich implies that we can ﬁnd simultaneous eigenstates of all three operators.","page_start":238,"page_end":238,"token_count":254,"section_type":"other","chapter_number":7,"chapter_title":"Angular Momentum","chunk_index":304}
{"chunk_id":"2cb974d361cd7181","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"7.4 Separation of Variables: Spherical Coordinates \n215\nFIGURE 7.5 Angular dependence of the four sp3 hybrid orbitals in a diamond lattice.\n7.4 \u0002 SEPARATION OF VARIABLES: SPHERICAL COORDINATES\nWe have already simpliﬁed the two-body nature of the hydrogen atom problem to an effective one-\nbody problem by separating the relative motion (interesting) from the center-of-mass motion (not so \ninteresting). We now proceed to simplify the three-dimensional aspect of the problem by separating \nthe three spherical coordinate dimensions from each other. To do this, we apply the standard tech-\nnique of separation of variables to the energy eigenvalue differential equation (7.71). This technique \nis reviewed in Appendix E, where six steps detail the process in its general form. The ﬂowchart in \nFig. 7.6 shows how the separation and recombination process will progress over the remainder of this \nchapter and through the next chapter.\nIn the ﬁrst instance, we apply the six steps of the separation of variables procedure to isolate the \nradial r dependence and the angular u, f dependence into two separate equations.\nStep 1: Write the partial differential equation in the appropriate coordinate system. We have done \nthis already in Eq. (7.71)\n \n-  U2\n2m\n c 1\nr2 0\n0r\n ar2\n 0\n0r b -\n1\nU2r2 L2 d c1r, u, f2 + V1r2c1r, u, f2 =  Ec1r, u, f2. (7.73)\nStep 2:  Assume that the solution c1r, u, f2 can be written as the product of functions, at least one of \nwhich depends on only one variable, in this case r. The other function(s) must not depend at \nall on this variable, that is, assume\n \nc1r, u, f2 = R1r2Y1u, f2. \n(7.74)\n \n Plug this assumed solution into the partial differential equation (7.73) from Step 1. Because \nof the special form of c, the partial derivatives each act on only one of the functions in c. Any \n","page_start":239,"page_end":239,"token_count":486,"section_type":"other","chapter_number":7,"chapter_title":"Angular Momentum","chunk_index":305}
{"chunk_id":"4d9bd3cb7478f88c","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"216 \nAngular Momentum\npartial derivatives that act only on a function of a single variable may be rewritten as total \nderivatives, yielding\n \n-  U2\n2m\n c Y 1\nr2 d\ndr\n ar2 dR\ndr b -\n1\nU2r2 R1L2Y2d + V1r2RY = ERY. \n(7.75)\nY(Θ,Φ) \u0004 Θ(Θ)Φ(Φ)\nΦm(Φ)\nHΨnlm(r,Θ,Φ) \u0004 EnΨnlm(r,Θ,Φ)\nLzΦm(Φ) = mhΦm(Φ)\nB(m)\nA(l)\nHΨ(r,Θ,φ) \u0004 EΨ(r,Θ,Φ)\nΨ(r,Θ,Φ) \u0004 R(r)Y(Θ,Φ)\nΘl\nm(cosΘ)\nL2Yl\nm(Θ,Φ) \u0004 l(l+1)h2Yl\nm(Θ,Φ) \nYl\nm(Θ,Φ) \nΨnlm(r,Θ,Φ) \u0004 Rnl(r )Yl\nm(Θ,Φ)\nRnl(r)\n7.83\n7.100\n7.82\n7.79\n8.67\n7.156\n7.161\n8.69\n7.81\n7.74\n7.43\nd\ndΦ eqn \u0004 BΦ\nd\ndΘ eqn \u0004 AΘ\nd\ndr eqn \u0004 ER\nFIGURE 7.6 Flowchart of the separation of variables procedure applied to the hydrogen atom. \nThe numbers in the corners of the boxes refer to the relevant equation numbers in the text.\n","page_start":240,"page_end":240,"token_count":417,"section_type":"other","chapter_number":7,"chapter_title":"Angular Momentum","chunk_index":306}
{"chunk_id":"2e0cedd7d30bd681","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"7.4 Separation of Variables: Spherical Coordinates \n217\n Note that the orbital angular momentum operator L2 acts only on angular spatial functions \n[Eq. (7.70)].\n Step 3: Divide both sides of the equation by c = RY:\n-  U2\n2m\n c 1\nR 1\nr2 d\ndr\n ar2 dR\ndr b - 1\nY 1\nU2r2 1L2Y2d + V1r2 = E. \n(7.76)\n Step 4: Isolate all of the dependence on one coordinate on one side of the equation. To isolate the r \ndependence, we multiply Eq. (7.76) by r 2 to clear the r dependence from the denominator \nof the angular term (involving angular derivatives in L 2 and angular functions in Y). Further \nrearranging Eq. (7.76) to get all of the r dependence on the left-hand side, we obtain:\n1\nR1r2 d\ndr\n ar2 \ndR1r2\ndr\nb - 2m\nU2  1E - V1r22r2 = 1\nU2 \n1\nY1u, f2 L2Y1u, f2. \n(7.77)\nfunction of r only\nfunction of u, f only\n The left-hand side of Eq. (7.77) is a function of r only, while the right-hand side is a function \nof u, f only.\n Step 5: Now imagine changing the isolated variable r by a small amount. In principle, the left-hand \nside of Eq. (7.77) could change, but nothing on the right-hand side would. Therefore, if the \nequation is to be true for all values of r, the particular combination of r dependences on the \nleft-hand side must result in no overall dependence on r—the left-hand side must be a con-\nstant. We thus deﬁne a separation constant, which we call A in this case:\n1\nR1r2 d\ndr\n ar2 \ndR1r2\ndr\nb - 2m\nU2  1E - V1r22r2 = 1\nU2 \n1\nY1u, f2\n L2Y1u, f2 K A. \n(7.78)\n Step 6: Write each equation in standard form by multiplying each equation by its unknown function \nto clear it from the denominator. Rearranging Eq. (7.78) slightly, we obtain the radial and \nangular equations in the more standard forms:\nc -  U2\n2mr2 d\ndr ar2 d\ndr\n b + V1r2 + A U2\n2mr2 d R1r2 = ER1r2 \n(7.79)\nL2Y1u, f2 = A U2 Y1u, f2. \n(7.80)\nNotice that the only place that the central potential V1r2 enters the set of differential equations is in ","page_start":241,"page_end":241,"token_count":661,"section_type":"other","chapter_number":7,"chapter_title":"Angular Momentum","chunk_index":307}
{"chunk_id":"0f6364ea1f358fa2","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"angular equations in the more standard forms:\nc -  U2\n2mr2 d\ndr ar2 d\ndr\n b + V1r2 + A U2\n2mr2 d R1r2 = ER1r2 \n(7.79)\nL2Y1u, f2 = A U2 Y1u, f2. \n(7.80)\nNotice that the only place that the central potential V1r2 enters the set of differential equations is in \nthe radial equation (7.79), which is not yet in the form of an eigenvalue equation because it contains \ntwo unknown constants, E and A. Equation (7.80) is an eigenvalue equation for the orbital angular \nmomentum operator L 2 with eigenvalue AU2. It has the same form as Eq. (7.57), so we fully expect \nthat the separation constant A = /1/ + 12, which we will prove shortly. The angular momentum \neigenvalue equation is independent of the central potential V1r2, so once we have solved for the \norbital angular momentum eigenstates, we will have solved that aspect of the problem for all central \npotentials. Only the radial equation need be solved again for different potentials.\nThe separation of variables procedure can be applied again to separate the u dependence from the \nf dependence in the angular equation (7.80). If we let\nY1u, f2 = \u00121u2\u00131f2, \n(7.81)","page_start":241,"page_end":241,"token_count":317,"section_type":"other","chapter_number":7,"chapter_title":"Angular Momentum","chunk_index":308}
{"chunk_id":"a507e5b7896edb28","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"218 \nAngular Momentum\nthen the separated equations are (Problem 7.10)\nc\n1\nsin u d\nd u\n asin u d\nd ub - B \n1\n sin2 u d \u00121u2 = -A \u00121u2 \n(7.82)\nd2\n \u00131f2\ndf2\n= -B \u0013(f), \n(7.83)\nwhere we have deﬁned the new separation constant as B. Equation (7.83) is an eigenvalue equation for \nthe operator d2>df2 with eigenvalue -B. Equation (7.82) is not yet in the form of an eigenvalue equa-\ntion because it contains two unknown constants A and B.\nWe started with a partial differential equation in three variables and we ended up with three ordi-\nnary differential equations by introducing two separation constants A and B. You should always get \none fewer separation constant than the number of variables you started with; each separation constant \nshould appear in two equations of the ﬁnal set.\nSo in turn we have identiﬁed a radial differential equation for R1r2, a polar angle differential \nequation for \u00121u2, and an azimuthal differential equation for \u00131f2. But note that the radial equation \ncontains the polar separation constant A and the polar equation contains the azimuthal separation \nconstant B. So we must solve the azimuthal equation ﬁrst, then the polar equation, and ﬁnally the \nradial equation. The azimuthal solution to Eq. (7.83) determines the constant B, which then goes \ninto Eq. (7.82) to determine the polar angle solution and the constant A. The combined azimuthal and \npolar solutions also satisfy the eigenvalue equation (7.80) for the orbital angular momentum operator L2. \nFinally, the constant A goes into the radial equation (7.79) and the energy eigenvalues are determined.\nRather than simply solving these mathematical equations, we will place each of these three \neigenvalue equations in some physical context by identifying situations that isolate the different equa-\ntions from the original energy eigenvalue equation H0 E9 = E0 E9. In this chapter, we focus on the two \nangular equations, which are independent of the central potential energy V1r2. In the next chapter, we \nsolve the radial equation for the special case of the hydrogen atom with the Coulomb potential energy \nfunction.\n7.5 \u0002 MOTION OF A PARTICLE ON A RING\nTo isolate the azimuthal eigenvalue problem in Eq. (7.83), we consider a system with no radial or \npolar angle dependence. This system comprises a particle of mass m conﬁned to move on a ring of \nconstant radius r0, as shown in Fig. 7.7. We assume that the ring lies in the x, y plane, so that in spheri-\ncal coordinates u = p>2. Thus, the motion takes place at constant r and constant u, with the azimuthal ","page_start":242,"page_end":242,"token_count":652,"section_type":"other","chapter_number":7,"chapter_title":"Angular Momentum","chunk_index":309}
{"chunk_id":"094b254b084215fd","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"polar angle dependence. This system comprises a particle of mass m conﬁned to move on a ring of \nconstant radius r0, as shown in Fig. 7.7. We assume that the ring lies in the x, y plane, so that in spheri-\ncal coordinates u = p>2. Thus, the motion takes place at constant r and constant u, with the azimuthal \nangle f as the sole degree of freedom. The wave function c is independent of r and u, so derivatives \nwith respect to those variables are zero. Hence, the energy eigenvalue equation [Eq. (7.43)] reduces to\n-U2\n2m  1\nr2\n0\n 0 2\n0 f2 c + V1r02c = Eringc, \n(7.84)\nwhich is the position representation of\nHring0 Ering9 = Ering0 Ering9. \n(7.85)","page_start":242,"page_end":242,"token_count":201,"section_type":"other","chapter_number":7,"chapter_title":"Angular Momentum","chunk_index":310}
{"chunk_id":"9d3870dc5d9082a3","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"7.5 Motion of a Particle on a Ring \n219\nFollowing our notation in the previous section, we call the wave function \u00131f2 and we change the \npartial derivative in Eq. (7.84) to a total derivative because there is only one variable. For this simpli-\nﬁed ring problem, the potential energy is a constant V1r02, which we choose to be zero, but we have to \nremember that we cannot make this choice when we are working on the full hydrogen atom problem. \nWe also identify mr2\n0 = I as the moment of inertia of a classical particle of mass m traveling in a ring \nabout the origin. With these choices, the energy eigenvalue equation becomes\n \n-  U2\n2I d2\ndf2 \u00131f2 = Ering\u00131f2. \n(7.86)\nThis is the same eigenvalue equation we found in Eq. (7.83) for the azimuthal function \u00131f2 as long \nas we identify the separation constant B as\n \nB = 2I\nU2 Ering \n(7.87)\nin this problem of a particle on a ring. Thus, this idealized particle-on-a-ring example has the same dif-\nferential equation, and hence the same wave function solutions, as the separated azimuthal equation in \nthe three-dimensional hydrogen atom problem.\nIf we compare the azimuthal differential equation (7.86) with the orbital angular momentum \noperator in Eq. (7.69), we note that the energy eigenvalue equation can be expressed as\n \nL2\nz\n2I\n \u00131f2 = Ering\u00131f2, \n(7.88)\nwhich again emphasizes the importance of angular momentum. This energy eigenvalue equation is \nwhat you would expect for a classical particle rotating in a circular path in the x, y plane with kinetic \nenergy T = Iv2>2 = L2\nz >2I and resultant Hamiltonian\n \nHring = T =\nL2\nz\n2I , \n(7.89)\nx\ny\nΦ\nr0\nΜ\nKnown quantities\nΜ, r0, I, \u0002\nParameters\nΦ\nUnknown quantities\nEring,\u0007Ψ\nFIGURE 7.7 Particle conﬁned to move on a ring.\n","page_start":243,"page_end":243,"token_count":493,"section_type":"other","chapter_number":7,"chapter_title":"Angular Momentum","chunk_index":311}
{"chunk_id":"59cab3a3f739f275","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"220 \nAngular Momentum\nassuming zero potential energy. We noted earlier that eigenstates of Lz obey an eigenvalue equation\n \nLz0 m9 = m U0 m9, \n(7.90)\nwhere we suppress the / quantum number (for the moment) because it is not applicable to this ideal-\nized one-dimensional particle-on-a-ring problem. The 0 m9 states are also eigenstates of L2\nz:\n \nL2\nz 0 m9 = m2U20 m9 \n(7.91)\nand hence of the Hamiltonian of the particle on a ring:\n \n Hring0 m9 = Ering0 m9  \n \n \nL2\nz\n2I 0 m9 = m2 U2\n2I 0 m9. \n \n(7.92)\nSo it looks like we already know the answer; that the energy eigenvalues are E = m2 U2>2I and the \nseparation constant is B = m2. However, we know the properties of the 0 m9 states in the abstract only; \nwe do not know their spatial representation. That comes from solving the differential equation (7.86), \nwhich is the position representation of the abstract equation (7.92). Let’s solve it and conﬁrm our \nexpectations about the energy eigenvalues.\n 7.5.1 \u0002 Azimuthal Solution\nThe azimuthal differential equation written in terms of the separation constant is\n \nd2\u00131f2\ndf2\n= -B\u00131f2. \n(7.93)\nThe solutions to this differential equation are the complex exponentials\n \n\u00131f2 = Ne{i2Bf, \n(7.94)\nwhere N is the normalization constant. Mathematically B could have any value, but the physics \nimposes some constraints.\nThere is no “boundary” on the ring, so we cannot impose boundary conditions like we did for the \npotential energy well problems in Chapter 5. However, there is one very important property of the wave \nfunction that we can invoke: it must be single-valued. The variable f is the azimuthal angle around the \nring, so that f + 2p is physically the same point as f. If we go once around the ring and return to our \nstarting point, the value of the wave function must remain the same. Therefore, the solutions must sat-\nisfy the periodicity condition \u00131f + 2p2 = \u00131f2. In order for the eigenstate wave function \u00131f2 \nto be periodic, the value of 1B must be real (complex 1B would result in real exponential solutions). \nFurthermore, the solutions must have the correct period, which requires that 1B be an integer:\n \nm = 0, {1, {2, ... . \n(7.95)\nSo we see that there are many solutions, each corresponding to a different integer (which can be zero, \npositive, or negative). We write the solutions as\n \n\u0013m1f2 = Neimf. \n(7.96)\n","page_start":244,"page_end":244,"token_count":651,"section_type":"other","chapter_number":7,"chapter_title":"Angular Momentum","chunk_index":312}
{"chunk_id":"f759669a5977f1d8","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"7.5 Motion of a Particle on a Ring \n221\nThe quantum number m is the orbital magnetic quantum number we introduced in Section 7.3. We \ndon’t use a subscript on m here because there is no need to distinguish it from spin for now.\nIf we operate on the eigenstate wave function \u0013m1f2 with the derivative form of the Lz operator, \nwe obtain\n \n Lz\u0013m1f2 = -i U 0\n0 f\n 1Neimf2  \n \n = -i U1im21Neimf2 \n \n = m U1Neimf2\n \n \n = m U\u0013m1f2.\n \n \n(7.97)\nAs expected, we have found that the energy eigenstates for the particle on a ring are the states 0 m9 that \nsatisfy the Lz eigenvalue equation (7.90).\nAs usual, we ﬁnd the normalization constant N in Eq. (7.94) by requiring that the probability of \nﬁnding the particle somewhere on the ring is unity:\n \n1 =\n \nL\n2p\n0\n\u0013*\nm1f2\u0013m1f2df =\n \nL\n2p\n0\nN*e-imf Neimf df = 2p0 N0\n2. \n(7.98)\nWe are free to choose the constant to be real and positive:\n \nN =\n1\n22p\n. \n(7.99)\nWe have thus found the position representation \u0013m1f2 = 8f0 m9 of the 0 m9 states:\n \n0 m9 \u0003 \u0013m1f2 =\n1\n22p\n eimf   . \n(7.100)\nThe eigenfunctions of the ring form an orthonormal set (Problem 7.11):\n \nL\n2p\n0\n\u0013*\nk1f2\u0013m1f2df = dkm. \n(7.101)\nTo reiterate, these functions are eigenstates of the ring Hamiltonian\n \n Hring0 m9 = Ering0 m9\n \n \n Hring\u0013m1f2 = Ering\u0013m1f2 \n \n(7.102)\nas well as eigenstates of the z-component of orbital angular momentum\n \n Lz0 m9 = m U0 m9\n \n \n Lz\u0013m1f2 = m U\u0013m1f2  . \n \n(7.103)\n","page_start":245,"page_end":245,"token_count":514,"section_type":"other","chapter_number":7,"chapter_title":"Angular Momentum","chunk_index":313}
{"chunk_id":"bf18923958eebfb2","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"222 \nAngular Momentum\nThe allowed values of the separation constant B are B = m2, so the possible energy eigenvalues \nusing Eq. (7.87) are\n \nE0m0 = m2 U2\n2I, \n(7.104)\nwhich is exactly what we expected from Eq. (7.92). The spectrum of allowed energies is shown in \nFig. 7.8. The eigenstates corresponding to + 0 m0  and - 0 m0  states have the same energy, so there are \ntwo energy states at every allowed energy except for the one corresponding to m = 0. Thus the \nparticle-on-a-ring system exhibits degeneracy, which we ﬁrst encountered in the free-particle system \nin Section 6.1.1. For the particle-on-a-ring system, all states are two-fold degenerate except for m = 0, \nwhich is nondegenerate. The {m degeneracy of the energy eigenstates corresponds to the angular \nmomentum states with Lz = +mU and Lz = -mU. That is, the two degenerate energy states represent \nstates with opposite components of the angular momentum along the z-axis. The energy is the same \nregardless of the direction of rotation, which is analogous to the free particle in one dimension where \nthe energy is independent of the direction of travel.\nThe particle on a ring is a one-dimensional system even though it exists in a two-dimensional \nspace. This is because there is only one degree of freedom f, similar to the particle-in-a-box system \nwe studied in Chapter 5, where the single degree of freedom was x. The solutions to both problems \nhave the same oscillatory form. As in the particle-in-a-box problem, the energy eigenvalues of the par-\nticle-on-a-ring system are discrete because of a boundary condition. The difference is that the bound-\nary condition appropriate to the ring problem is periodicity because f is a physical angle, rather than \nc1x2 = 0 at the boundaries, which is appropriate to an inﬁnite potential.\n0\n5\n10\n15\nE/E1\n\u0002m\u0002 =\u00074\n\u0002m\u0002 =\u00073\n\u0002m\u0002 =\u00072\n\u0002m\u0002 =\u00071\nm =\u00070\nFIGURE 7.8 Energy spectrum for a particle on a ring.\n","page_start":246,"page_end":246,"token_count":500,"section_type":"other","chapter_number":7,"chapter_title":"Angular Momentum","chunk_index":314}
{"chunk_id":"e2753d37188312ba","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"7.5 Motion of a Particle on a Ring \n223\n 7.5.2 \u0002 Quantum Measurements on a Particle Conﬁned to a Ring\nMany of the aspects of quantum measurement applied to this new system are similar to the spin and \nparticle-in-a-box examples we studied previously (e.g., Examples 2.3, 5.5, and 7.1). However, the \ndegeneracy of energy levels presents a new aspect. Because the states 0 m9 and 0 -m9 have the same \nenergy, the probability of measuring the energy E0m0 is the sum\n \nPE0m0 = 08m0 c90\n2 + 08-m0 c90\n2, \n(7.105)\nexcept for the m = 0 state. On the other hand, the state 0 m9 uniquely speciﬁes the orbital angular \nmomentum component along the z-direction, so the probability of measuring the angular momentum \ncomponent is\n \nPLz=m U = 08m0 c90\n2. \n(7.106)\nExample 7.2 A particle on a ring is in the superposition state\n \n0 c9 =\n1\n17 10 09 + 20 19 + 0\n -19 + 0 292. \n(7.107)\nIf we measure the energy, what is the probability of measuring the value E1 = U2>2I and what is \nthe state of the system after measuring that value?\nThe probability of measuring the value E1 = U2>2I is obtained using Eq. (7.105):\n \n PE1 = 0810 c90\n2 + 08-10 c90\n2\n \n \n = @ H1@  1\n17  A @  0I + 2@  1I + @  -1I + @  2IB @\n2\n+ @ H-1@  1\n17  A @  0I + 2@  1I + @  -1I + @2IB @\n2\n \n \n = @  2\n17\n @\n2\n+ @  1\n17\n @\n2\n \n(7.108)\n \n = 5\n7.\n \nAfter the measurement, the new state vector is the normalized projection of the input state onto the \nkets corresponding to the result of the measurement (postulate 5, Chapter 2):\n \n@cafter E0m09 = 0 m98m0 + 0 -m98-m0\n2PE0m0\n0 c9, \n(7.109)\nwhich in this case is\n \n @cafter E19 = 0 19810 + 0  -198-10\n2PE1\n 1\n17 10 09 + 20 19 + 0  -19 + 0 292 \n(7.110)\n \n =\n1\n15 120 19 + 0  -192.\n \nUsing Stern-Gerlach analyzers, measurements of the angular momentum component Lz could \nbe made after the energy measurement, and would yield the results shown in Fig. 7.9 (Problem 7.12).\n","page_start":247,"page_end":247,"token_count":682,"section_type":"other","chapter_number":7,"chapter_title":"Angular Momentum","chunk_index":315}
{"chunk_id":"57534f2b47b24bbd","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"224 \nAngular Momentum\n 7.5.3 \u0002 Superposition States\nThe eigenstate wave functions for the particle on a ring are complex, so we must plot both the real \nand imaginary components for a proper graphical representation of the wave function. Plots of three \n\u0013m1f2 eigenstates are shown in Fig. 7.10. The probability density of an eigenstate is\n \nPm1f2 = 0 \u0013m1f20\n2. \n(7.111)\nSubstituting in the eigenstate wave function from Eq. (7.100), we obtain\n \nPm1f2 = 2\n1\n12p eimf 2\n2\n=\n1\n2p , \n(7.112)\nwhich is a constant independent of the quantum number m. So there is no measurable spatial depen-\ndence of the 0 m9 eigenstates.\nHowever, there is spatial dependence in the probability density for superposition states. For \nexample, consider a state of the system with an initial wave function comprising two eigenstates:\n \nc1f, 02 = c1\u0013m11f2 + c2eiu\u0013m21f2. \n(7.113)\nm \u0004\u00070\nΠ\n2Π\nΦ\n\t(Φ)\n1\n2Π\n\n1\n\u000b\n2Π\n\u000b\nΦ\nm \u0004\u00071\nΠ\n2Π\n\t(Φ)\n1\n2Π\n\n1\n\u000b\n2Π\n\u000b\nΦ\nm \u0004\u00072\nΠ\n2Π\n\t(Φ)\n1\n2Π\n\n1\n\u000b\n2Π\n\u000b\nFIGURE 7.10 Eigenstate wave functions for a particle on a ring. The real part of the wave function is the solid \nline and the imaginary part is the dashed line.\n14\nH\n2\n1\n0\n\n1\n\n2\n2\nLz\nLz\n1\n0\n\n1\n\n2\n2\n1\n0\n\n1\n\n2\n58\n14\n14\nLz\n\u0002Ψ\u0003\nE2\nE1\nE0\nFIGURE 7.9 Energy measurement and orbital angular momentum component measurements.\n","page_start":248,"page_end":248,"token_count":484,"section_type":"other","chapter_number":7,"chapter_title":"Angular Momentum","chunk_index":316}
{"chunk_id":"d243282edb415ee7","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"7.5 Motion of a Particle on a Ring \n225\nWe assume that this function is already properly normalized Aso that c2\n1 + c2\n2 = 1B, and we assume \nthat the constants c1 and c2 are real. An overall phase has no physical meaning (cannot be measured), \nso we can always choose one coefﬁcient to be real. Relative phases play a crucial role in measurement, \nso we have made the relative phase explicit by separating the phase eiu from the coefﬁcient of the sec-\nond term. Using the Schrödinger time-evolution recipe from Chapter 3, the initial state in Eq. (7.113) \nbecomes\n c1f, t2 = c1\u0013m11f2e-iE0m10t>U + c2eiu\u0013m21f2e-iE0m20t>U\n = c1 \n1\n12p eim1fe-iE0m10t>U + c2eiu\n1\n12p eim2fe-iE0m20t>U.\n(7.114)\nFor this state, the probability density for measuring the position of the particle on the ring is\n P1f, t2 = 0 c1f, t20\n2 = c*1f, t2c1f, t2\n =\n1\n2p\n 1c1e-im1fe+iE0m10t>U + c2e-iue-im2fe+iE0m20t>U21c1eim1fe-iE0m10t>U + c2eiueim2fe-iE0m20t>U2\n =\n1\n2p\n 3c2\n1 + c2\n2 + c1c21e-im1fe+iE 0\n  m10\n t>Ueiueim2fe-iE 0\n  m20\n t>U + eim1fe-iE 0\n  m10\n t>Ue-iue-im2fe+iE 0\n  m20\n t>U24 \n=\n1\n2p\n 31 + 2c1c2 cos 51m1 - m22f - u - 1E0m10 - E0m202t>U64. \n(7.115)\nThis probability density exhibits spatial dependence and time dependence in the form of a wave mov-\ning around the ring. There are four measurable properties of this probability density wave: the spatial \nfrequency, the temporal frequency, the amplitude, and the phase of the wave. These four quantities are \ndetermined by the factors 1m1 - m22, 1E0m10 - E0m202, c1c2, and u, respectively, in Eq. (7.115). Using \nthe measured values for these four quantities, the direction of the wave, and the normalization condi-\ntion c2\n1 + c2\n2 = 1 allows us to determine the ﬁve constants c1, c2, m1, m2, and u that specify the wave ","page_start":249,"page_end":249,"token_count":666,"section_type":"other","chapter_number":7,"chapter_title":"Angular Momentum","chunk_index":317}
{"chunk_id":"e9c3ba2ec6a0e44e","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"the measured values for these four quantities, the direction of the wave, and the normalization condi-\ntion c2\n1 + c2\n2 = 1 allows us to determine the ﬁve constants c1, c2, m1, m2, and u that specify the wave \nfunction superposition in Eq. (7.113) (Problem 7.17).\nExample 7.3 Calculate and plot the probability density for the initial superposition state\nc1f, 02 = 4\n1\n3 \u001331f2 + i 4\n2\n3 \u0013-11f2. \n(7.116)\nThe time-evolved wave function is\nc1f, t2 =\n1\n12p\n  4\n1\n3\n ei3f e-i9Ut>2I + i \n1\n12p\n  4\n2\n3\n e-if e-iUt>2I \n(7.117)\nand the probability density is\n P1f, t2 =\n1\n2p\n c 1 + 222\n3  cos a4f - p\n2 - 8U\n2I\n tb d  \n(7.118)\n =\n1\n2p\n c 1 + 222\n3   sin a4f - 4U\nI\n tb d .","page_start":249,"page_end":249,"token_count":283,"section_type":"other","chapter_number":7,"chapter_title":"Angular Momentum","chunk_index":318}
{"chunk_id":"add9b6468e432c92","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"226 \nAngular Momentum\nThe probability density varies around the ring and at t = 0 is a maximum where  sin 4f = +1, or \nf = p>8, 5p>8, 9p>8, and 13p>8. The spatial dependence of the probability density is plotted in \nFig. 7.11 in three different graphical representations. The traditional plot in Fig. 7.11(a) is similar \nto the particle-in-a-box plots and conveys the idea of a varying density, but the single dimension \nfails to make it clear that the left and right ends are connected on the ring and must have the same \ndensity. The plot in Fig. 7.11(b) makes the connection between f = 0 and f = 2p clear by \nplotting the probability density using grayscale (color) as a parameter along the ring. The plot in \nFig. 7.11(c) combines the ideas of the previous two plots by using both the vertical scale and gray-\nscale to represent the probability density. Because the probability density varies with time, each of \nthe plots in Fig. 7.11 moves (toward increasing f in this example) when they are animated. (See the \nactivity on a particle conﬁned to a ring.)\nFIGURE 7.11 Probability density of a superposition state for a particle on a ring displayed as \n(a) a linear plot, (b) grayscale around the ring, and (c) height and grayscale around the ring.\n","page_start":250,"page_end":250,"token_count":321,"section_type":"other","chapter_number":8,"chapter_title":"Hydrogen Atom","chunk_index":319}
{"chunk_id":"9521b7bb9dd4849a","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"7.6 Motion on a Sphere \n227\nFIGURE 7.12 Particle conﬁned to move on the surface of a sphere.\nWe have now completed our investigation of the particle on a ring. We have identiﬁed the Hamil-\ntonian, found the energy spectrum, found the position representation of the eigenstates, and studied the \nprobability distributions, including the time dependence. These eigenstates are the same ones we will \nuse as the azimuthal part of the three-dimensional wave function to solve the hydrogen atom problem.\n7.6 \u0002 MOTION ON A SPHERE\nWe have now solved for the azimuthal part of the hydrogen atom wave function, so we turn our atten-\ntion to the polar angle part of the wave function. This is best done in the context of a system that \ninvolves both angular variables u and f, so that we ﬁnd the solutions \u00121u2 to Eq. (7.82) and then com-\nbine them with the azimuthal states \u0013m1f2 to form the solutions Y1u, f2 to the angular momentum \neigenvalue equation (7.80). The system we choose to discuss angular wave functions is that of a par-\nticle of mass m conﬁned to the surface of a sphere of radius r0, as shown in Fig. 7.12, which is a natural \nextension of the ring problem. The results of this analysis yield predictions that can be successfully \ncompared with experiments on molecules and nuclei that rotate more than they vibrate. For this reason, \nthe problem of a mass conﬁned to a sphere is often called the rigid rotor problem. Furthermore, the \nsolutions Y1u, f2 that we ﬁnd, called spherical harmonics, occur whenever one solves a partial dif-\nferential equation that involves spherical symmetry.\nFor a particle conﬁned to a sphere, the wave function c is independent of r, so derivatives with \nrespect to r are zero and the energy eigenvalue equation (7.43) reduces to\n \n-  U2\n2mr 2\n0\n c\n1\n sin u 0\n0 u\n asin u 0\n0 u b +\n1\nsin2 u 0 2\n0 f 2 d c + V1r02c = Esphere c, \n(7.119)\nwhich is the position representation of\n \nHsphere0 Esphere9 = Esphere0 Esphere9. \n(7.120)\n","page_start":251,"page_end":251,"token_count":527,"section_type":"other","chapter_number":8,"chapter_title":"Hydrogen Atom","chunk_index":320}
{"chunk_id":"8fd1f9d88e2e74f0","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"228 \nAngular Momentum\nFollowing our previous notation, we call the wave function Y1u, f2 = \u00121u2\u00131f2. For this simpliﬁed \nsphere problem, we choose the potential energy V1r02 to be zero, as in the ring problem. We identify \nmr 2\n0 = I as the moment of inertia of a classical particle of mass m moving on a sphere. With these \nchanges, the energy eigenvalue equation is\n-  U2\n2I\n c\n1\n sin u 0\n0 u\n asin u 0\n0 u b +\n1\nsin2 u 0 2\n0 f2 d Y1u, f2 = EsphereY1u, f2. \n(7.121)\nUsing Eq. (7.70), we identify the angular differential operator as the position representation of the \nangular momentum operator L2 and write the energy eigenvalue equation in operator form:\nL2\n2I\n Y1u, f2 = EsphereY1u, f2. \n(7.122)\nThis eigenvalue equation appears similar to the ring problem but is actually very different, because \nnow the particle can move anywhere on the sphere and so the angular momentum is no longer con-\nﬁned to the z-direction. Equation (7.122) is the same eigenvalue equation we obtained in Eq. (7.80) \nthrough separation of variables for the angular function Y1u, f2 = \u00121u2\u00131f2, as long as we identify \nthe separation constant A as\nA = 2I\nU2 Esphere. \n(7.123)\nAs noted above, we expect that the separation constant A is equal to /1/ + 12 because the L2 oper-\nator obeys the eigenvalue equation (7.57). Now that we know that this sphere problem is equiva-\nlent to the angular momentum eigenvalue equation, we proceed to solve for the polar angle function \n\u00121u2 that we identiﬁed in the differential equation (7.82). We have already solved for the azimuthal \nangle wave function \u0013m1f2, so at the end we combine \u00121u2 and \u0013m1f2 to yield the eigenstates \nY1u, f2 = \u00121u2\u0013m1f2 for the particle on the sphere. In due course, we’ll ﬁnd that the \u00121u2 eigen-\nstates have their own quantum numbers, and so we’ll label the polar angle states as \u0012m\n/ 1u2 and the \nspherical harmonics as Y m\n/ 1u, f2 (the m label is a superscipt, not an exponent).\n 7.6.1 \u0002 Series Solution of Legendre’s Equation\nThe polar angle equation (7.82) is our ﬁrst encounter with a differential equation that requires a \nsophisticated solution method. The next two sections detail the series solution method and arrive at \nthe Legendre and associated Legendre functions that solve the polar angle equation. If you are already ","page_start":252,"page_end":252,"token_count":666,"section_type":"other","chapter_number":8,"chapter_title":"Hydrogen Atom","chunk_index":321}
{"chunk_id":"61c3e7ddd196034b","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"/ 1u, f2 (the m label is a superscipt, not an exponent).\n 7.6.1 \u0002 Series Solution of Legendre’s Equation\nThe polar angle equation (7.82) is our ﬁrst encounter with a differential equation that requires a \nsophisticated solution method. The next two sections detail the series solution method and arrive at \nthe Legendre and associated Legendre functions that solve the polar angle equation. If you are already \nexperienced with this method and are knowledgeable about the Legendre functions, you may safely \nskip these two sections.\nThe solutions \u0013m1f2 to the f equation (7.83) that we found in the ring problem told us the pos-\nsible values of the separation constant B = m2, where m is any integer. We now substitute these \nknown values into the polar angle differential equation (7.82). The u equation becomes an eigenvalue \nequation for the unknown function \u00121u2 and the separation constant A:\nc\n1\nsin u d\ndu\n asin u d\ndub -\nm2\nsin2 u d \u00121u2 = -A\u00121u2. \n(7.124)\nTo solve this differential equation, we start with a change of independent variable z = cos u, where \nz is the rectangular coordinate for the particle, assuming a unit sphere. We also introduce a new function\nP1z2 = \u00121u2. \n(7.125)","page_start":252,"page_end":252,"token_count":316,"section_type":"other","chapter_number":8,"chapter_title":"Hydrogen Atom","chunk_index":322}
{"chunk_id":"77475293d1544580","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"7.6 Motion on a Sphere \n229\nThis step is not mathematically necessary but resolves the difference between the required normaliza-\ntion properties of quantum mechanial wave functions [\u0012(u)] and the standard normalization used for \nthe solutions [P(z)] to Eq. (7.124). As u ranges from 0 to p, z ranges from 1 to -1. Using the chain \nrule for derivatives and  sin u = 21 - z2, the differential term becomes\n \nd\ndu = dz\ndu\n  d\ndz = -sin u d\ndz = - 21 - z2 d\ndz . \n(7.126)\nNotice, particularly, the last equality: we are trying to change variables from u to z, so it is important to \nmake sure we change all the u’s to z’s. Multiplying by sin u, we obtain:\n \n sin u d\ndu = -11 - z22 d\ndz . \n(7.127)\nBe careful ﬁnding the second derivative; it involves a product rule:\n \n 1\nsin u d\ndu\n asin u d\ndub = d\ndz\n a11 - z22 d\ndzb\n \n \n = 11 - z22 d 2\ndz2 - 2z d\ndz\n .\n \n \n(7.128)\nInserting Eq. (7.128) into Eq. (7.124), we obtain a standard form of the associated Legendre \nequation:\n \na11 - z22 d 2\ndz2 - 2z d\ndz + A -\nm2\n11 - z22b P1z2 = 0. \n(7.129)\nOnce we solve this equation for the eigenfunctions P1z2, we substitute z = cos u everywhere to ﬁnd \nthe quantum mechanical eigenfunctions \u00121u2 of the original equation (7.124).\nIt is easiest to begin the solution of Eq. (7.129) with the m = 0 case, which corresponds to the \nsimplest possible f dependence: \u001301f2 = 1> 12p. Setting m = 0 in equation (7.129) gives us the \nspecial case known as Legendre’s equation:\n \n¢11 - z22 d 2\ndz2 - 2z d\ndz + A≤ P1z2 = 0. \n(7.130)\nBy dividing this equation by 11 - z22, we express it as\n \na d 2\ndz2 -\n2z\n11 - z22\n d\ndz +\nA\n11 - z22\nb P1z2 = 0, \n(7.131)\nwhich emphasizes the mathematical singularities at z = {1.\nWe use the series method to ﬁnd a solution of Legendre’s equation; that is, we assume that the \nsolution can be written as a series\n \nP1z2 = a\n\u0005\nn=0\na n zn \n(7.132)\n","page_start":253,"page_end":253,"token_count":637,"section_type":"other","chapter_number":8,"chapter_title":"Hydrogen Atom","chunk_index":323}
{"chunk_id":"51151ebd963becf1","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"230 \nAngular Momentum\nand solve for the coefﬁcients an. The differentials\n dP\ndz = a\n\u0005\nn=0\na n nz n-1\n(7.133)\n d 2P\ndz2 = a\n\u0005\nn=0\na n n1n - 12z n-2 \n(7.134)\nsubstituted into Eq. (7.130) yield\n 0 = a\n\u0005\nn=0\na n n1n - 12z n-2 - z 2 a\n\u0005\nn=0\na n n1n - 12z n-2 - 2z a\n\u0005\nn=0\na n nz n-1 + Aa\n\u0005\nn=0\na n z n \n = a\n\u0005\nn=0\na n n1n - 12z n-2 - a\n\u0005\nn=0\na n n1n - 12z n - 2a\n\u0005\nn=0\na n nz n + Aa\n\u0005\nn=0\na n z n.\n(7.135)\nTo combine the sums, we must collect terms of the same powers. To do this, we note that the ﬁrst two \nterms of the ﬁrst sum are zero:\na01021-12z-2 + a1112102z-1 = 0 + 0, \n(7.136)\nso we shift the dummy variable n S n + 2 in the ﬁrst sum, giving\n a\n\u0005\nn=0\nan n1n - 12z n-2 =\na\n\u0005\nn=-2\nan+21n + 221n + 12z n \n = a\n\u0005\nn=0\nan+21n + 221n + 12z n.\n(7.137)\nNow all the sums in Eq. (7.135) have the same power and we group the sums together to yield\na\n\u0005\nn=0\n3an+21n + 221n + 12 - an n1n - 12 - 2an n + Aan4z n = 0. \n(7.138)\nNow comes the magic part. Because Eq. (7.138) is true for all values of z, the coefﬁcient of zn for \neach term in the sum must separately be zero:\nan+21n + 221n + 12 - an n1n - 12 - 2an n + Aan = 0. \n(7.139)\nTherefore, we can solve Eq. (7.139) for the recurrence relation, giving the later coefﬁcient an+2 in \nterms of the earlier coefﬁcient an:\nan+2 =\nn1n + 12 - A\n1n + 221n + 12\n an. \n(7.140)\nPlugging successive even values of n into the recurrence relation Eq. (7.140) allows us to ﬁnd a2, a4, ","page_start":254,"page_end":254,"token_count":657,"section_type":"other","chapter_number":8,"chapter_title":"Hydrogen Atom","chunk_index":324}
{"chunk_id":"c68652f9612d1150","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"Therefore, we can solve Eq. (7.139) for the recurrence relation, giving the later coefﬁcient an+2 in \nterms of the earlier coefﬁcient an:\nan+2 =\nn1n + 12 - A\n1n + 221n + 12\n an. \n(7.140)\nPlugging successive even values of n into the recurrence relation Eq. (7.140) allows us to ﬁnd a2, a4, \netc. in terms of the arbitrary constant a0, and successive odd values of n allow us to ﬁnd a3, a5, etc. in \nterms of the arbitrary constant a1. Thus, for the second-order differential equation (7.130), we obtain \ntwo solutions as expected. The coefﬁcient a0 becomes the normalization constant for a solution with ","page_start":254,"page_end":254,"token_count":179,"section_type":"other","chapter_number":8,"chapter_title":"Hydrogen Atom","chunk_index":325}
{"chunk_id":"fabb92e439e44b27","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"7.6 Motion on a Sphere \n231\nonly even powers of z, and a1 becomes the normalization constant for a solution with only odd powers \nof z. For example, some even coefﬁcients are\n a2 = -  A\n2\n a0\n a4 = 6 - A\n12\n a2 = - a6 - A\n12\nba A\n2 b a0 \n(7.141)\nand some odd coefﬁcients are\n a3 = 2 - A\n6\n a1\n a5 = 12 - A\n20\n a3 = a 12 - A\n20\nba2 - A\n6\nb a1 \n(7.142)\nso that\nP1z2 = a0 c z0 - aA\n2 b z 2 + ...d + a1c z1 + a2 - A\n6\nb z 3 + ...d . \n(7.143)\nWe seek solutions that are normalizable, so we must address the convergence of the series solu-\ntion. Note that for large n, the recurrence relation gives\nan+2\nan\n\u0002 1, \n(7.144)\nwhich implies that the series solution we have assumed does not converge at the end points where \nz = {1. This is to be expected because the coefﬁcients of Eq. (7.131) are singular at z = {1, which \ncorrespond to the north and south poles u = 0, p. But there is nothing special about the physics at \nthese points, only the choice of coordinates is special here. This is an important example of a problem \nwhere the choice of coordinates for a partial differential equation ends up imposing boundary con-\nditions on the ordinary differential equation which comes from it. To ensure convergence, we thus \nrequire that the series not be inﬁnite, but rather that it terminate at some ﬁnite power nmax. Inspection \nof the recurrence relation in Eq. (7.140) tells us that the series terminates if we choose\nA = nmax1nmax + 12, \n(7.145)\nwhere nmax is a non-negative integer. When we started this problem, we expected the separation con-\nstant to be A = /1/ + 12 and we have found just that, as long as we identify the termination index \nnmax with the orbital angular momentum quantum number /. We have now succeeded in ﬁnding the \nquantization condition for orbital angular momentum, and it is just as we expected from our work \nwith spin angular momentum. But we came to it from a very different perspective, which is one of the \nbeautiful aspects of physics. We have now found that the orbital angular momentum quantum number \n/ must be a non-negative integer:\n/ = 0, 1, 2, 3, 4, ...  . \n(7.146)\nThe solutions to Eq. (7.130) for these special values of A are polynomials of degree /, denoted P/1z2, \nand are called Legendre polynomials.","page_start":255,"page_end":255,"token_count":655,"section_type":"other","chapter_number":8,"chapter_title":"Hydrogen Atom","chunk_index":326}
{"chunk_id":"cf590e93286a196f","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"beautiful aspects of physics. We have now found that the orbital angular momentum quantum number \n/ must be a non-negative integer:\n/ = 0, 1, 2, 3, 4, ...  . \n(7.146)\nThe solutions to Eq. (7.130) for these special values of A are polynomials of degree /, denoted P/1z2, \nand are called Legendre polynomials.\nThe Legendre polynomials can also be calculated using Rodrigues’ formula:\nP/1z2 =\n1\n2//! d /\ndz/ 1z 2 - 12/. \n(7.147)","page_start":255,"page_end":255,"token_count":135,"section_type":"other","chapter_number":8,"chapter_title":"Hydrogen Atom","chunk_index":327}
{"chunk_id":"2961d9d0ff0386ff","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"232 \nAngular Momentum\nThe ﬁrst few Legendre polynomials are shown in Table 7.1 and are plotted in Fig. 7.13. There are \nseveral useful patterns to the Legendre polynomials:\n• The overall coefﬁcient for each solution is conventionally chosen so that P/112 = 1. As \ndiscussed in the next section, this is an inconvenient convention that we are stuck with.\n• P/1z2 is a polynomial of degree /.\n• Each P/1z2 contains only odd or only even powers of z, depending on whether / is even \nor odd. Therefore, each P/1z2 is either an even or an odd function.\n• Because the differential operator in Eq. (7.130) is Hermitian, we are guaranteed that \nthe Legendre polynomials are orthogonal for different values of / ( just as with Fourier \nseries), that is,\n \nL\n1\n-1\nP*\nk 1z2P/1z2dz =\n2\n2/ + 1 dk/. \n(7.148)\nNote that the Legendre polynomials are not normalized to unity, rather the “squared norm” of P/ is \n2>12/ + 12.\nNotice that when we substitute the separation constant A = /1/ + 12 back into the original dif-\nferential equation (7.130)\n \n11 - z 22 d 2P\ndz 2 - 2z dP\ndz + /1/ + 12P = 0, \n(7.149)\nTable 7.1 Legendre Polynomials\nP01z2 = 1\nP11z2 = z\nP21z2 = 1\n2 13z  2 - 12\nP31z2 = 1\n2 15z  3 - 3z2\nP41z2 = 1\n8 135z  4 - 30z  2 + 32\nP51z2 = 1\n8 163z  5 - 70z  3 + 15z2\n\n1\n1\nz\n\n1\n\n0.5\n0.5\nPl(z)\n1\nl\u00040\nl\u00041\nl\u00042\nl\u00043\nl\u00044\nFIGURE 7.13 Legendre polynomials.\n","page_start":256,"page_end":256,"token_count":504,"section_type":"other","chapter_number":8,"chapter_title":"Hydrogen Atom","chunk_index":328}
{"chunk_id":"84afc9fa987b741a","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"7.6 Motion on a Sphere \n233\nthe result is a different equation for different values of /. For a given value of /, you should expect \ntwo solutions of Eq. (7.149), but we have only given one. The “other” solution for each value of / is \nnot regular (i.e., it blows up) at z = {1. In cases where the separation constant A does not have the \nspecial value /1/ + 12 for non-negative integer values of /, it turns out that both solutions blow up. \nWe discard these irregular solutions as unphysical for the problem we are solving.\n 7.6.2 \u0002 Associated Legendre Functions\nWe now return to Eq. (7.129) to consider the cases with m \u0002 0. We need a slightly more sophisticated \nversion of the series technique from the m = 0 case, and we do not detail this here. We again ﬁnd solu-\ntions that are regular at z = {1 whenever we choose A = /1/ + 12 for / \u0002 50, 1, 2, 3, ...6. With \nthese values for A, we obtain the standard form of the associated Legendre equation, namely\na11 - z 22 d 2\ndz 2 - 2z d\ndz + /1/ + 12 -\nm2\n11 - z 22b P1z2 = 0. \n(7.150)\nSolutions of this equation that are regular at z = {1 are called associated Legendre functions, and \nare calculated from the Legendre functions by differentiation:\n P m\n/ 1z2 = P -m\n/ 1z2 = 11 - z 22\nm>2\n d m\ndz m P/1z2  \n =\n1\n2//!\n 11 - z 22\nm>2\n d m+/\ndz m+/ 1z 2 - 12/,\n(7.151)\nwhere m Ú 0. In Eq. (7.151), the integer m is a superscript label—not an exponent—on the associated \nLegendre function Pm\n/ 1z2, but m is an exponent on the right hand side of the equation. The associated \nLegendre equation (7.150) is independent of the sign of the integer m, so\nP-m\n/ 1z2 = Pm\n/ 1z2. \n(7.152)\nThe Legendre function P/1z2 is a polynomial of order /, so the mth derivative in Eq. (7.151), and hence \nthe associated Legendre function Pm\n/ 1z2, vanishes if m 7 /. In the ring problem, we learned that m \nmust be an integer, but there was no limit on the possible values of those integers. Now we have dis-\ncovered an additional constraint on the magnetic quantum number for the sphere problem\nm = -/, -/ + 1, ..., -1, 0, 1, ..., / - 1, /  . \n(7.153)","page_start":257,"page_end":257,"token_count":662,"section_type":"other","chapter_number":8,"chapter_title":"Hydrogen Atom","chunk_index":329}
{"chunk_id":"165afa45f38eafc0","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"/ 1z2, vanishes if m 7 /. In the ring problem, we learned that m \nmust be an integer, but there was no limit on the possible values of those integers. Now we have dis-\ncovered an additional constraint on the magnetic quantum number for the sphere problem\nm = -/, -/ + 1, ..., -1, 0, 1, ..., / - 1, /  . \n(7.153)\nAgain, this is consistent with our expectations from the spin problem.\nIt is more useful for us to express the Legendre polynomials and the associated Legendre functions \nin terms of the polar angle u rather than the variable z, so we substitute z = cos u into the functions. \nThe Legendre polynomial P/1cos u2 is a polynomial in cos u, while the associated Legendre function \nP m\n/ 1cos u2 is a polynomial in cos u times a factor of sinm u because of the additional term\n11 - z 22\nm>2 = 1sin2 u2\nm>2 =  sinm u \n(7.154)","page_start":257,"page_end":257,"token_count":236,"section_type":"other","chapter_number":8,"chapter_title":"Hydrogen Atom","chunk_index":330}
{"chunk_id":"e17c2b0de7fdcffb","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"234 \nAngular Momentum\nin Eq. (7.151). Some of the associated Legendre functions are shown in Table 7.2 and are plotted in \nFig. 7.14. The plots in Fig. 7.14 are polar plots where the “radius” r at each angle u is the absolute \nvalue of the function P m\n/ 1cos u2, as illustrated further in Fig. 7.15. The associated Legendre functions \nare deﬁned over the interval 0 … u … p, but the convention is to plot the functions reﬂected in the \nz-axis in anticipation of their application to the full three-dimensional hydrogen atom.\nSome useful properties of the associated Legendre functions are:\n• P m\n/ 1z2 = 0 if 0m0 7 /\n• P -m\n/ 1z2 = P m\n/ 1z2\n• P m\n/ 1{12 = 0 for m \u0002 0 Acf. factor of 11 - z 22\nm>2B\n• P m\n/ 1-z2 = 1-12\n/-m P m\n/ 1z2 (behavior under parity)\n• \nL\n1\n-1\nP m\n/ 1z2P m\nq1z2dz =\n2\n12/ + 12 1/ + m2!\n1/ - m2! d/q.\nP0\n0\nP1\n0\nP1\n1\nP2\n0\nP2\n1\nP2\n2\nP3\n0\nP3\n1\nP3\n2\nP3\n3\nFIGURE 7.14 Polar plots of associated Legendre functions.\n","page_start":258,"page_end":258,"token_count":372,"section_type":"other","chapter_number":8,"chapter_title":"Hydrogen Atom","chunk_index":331}
{"chunk_id":"ecd96fd75a20f6b7","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"7.6 Motion on a Sphere \n235\n\n1\n\n0.5\n0.5\n1\n\n0.5\n0.5\nz\nr \u0004 Pl\nm(Θ)\u0002\nΘ\nP1\n1 (Θ)\n\u0002\nFIGURE 7.15 Polar plot of an associated Legendre function.\nTable 7.2 Associated Legendre Functions\nP 0\n0 = 1 \nP 0\n1 = cos u \nP 0\n3 = 1\n2 15 cos3 u - 3 cos u2\nP 1\n1 = sin u \nP 1\n3 = 3\n2 sin u15 cos2 u - 12\nP 0\n2 = 1\n2 13 cos2 u - 12 \nP 2\n3 = 15 sin2 u cos u\nP 1\n2 = 3 sin u cos u \nP 3\n3 = 15 sin3 u\nP 2\n2 = 3 sin2 u\nThe last property shows that for each given value of m, the associated Legendre functions form an \northogonal basis on the interval -1 … z … 1. Any function on this interval can be expanded in terms \nof any one of these bases. The associated Legendre functions are not normalized to unity, but by multi-\nplying by the appropriate factor we construct the eigenstates \u0012 m\n/ 1u2 that solve the eigenvalue equation \n(7.124) and are normalized to unity over the interval 0 … u … p:\n \nL\np\n0\n\u0012 m\n/ 1u2\u0012 m\nq1u2sin u du = d/q. \n(7.155)\nThese eigenstates are\n \n\u0012m\n/ 1u2 = 1-12\nm\n 12/ + 12\n2\n 1/ - m2!\n1/ + m2!\n P m\n/ 1cos u2, m Ú 0, \n(7.156)\nwith the negative m states deﬁned by\n \n\u0012 -m\n/ 1u2 = 1-12\nm \u0012 m\n/ 1u2, m Ú 0. \n(7.157)\n","page_start":259,"page_end":259,"token_count":484,"section_type":"other","chapter_number":8,"chapter_title":"Hydrogen Atom","chunk_index":332}
{"chunk_id":"32f760728f2d3386","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"236 \nAngular Momentum\n 7.6.3 \u0002 Energy Eigenvalues of a Rigid Rotor\nWe now know the separation constant A in Eq. (7.124), which determines the energy of the parti-\ncle bound to the sphere through Eq. (7.123). Substituting A = /1/ + 12 into Eq. (7.123) gives the \nallowed energy eigenvalues\n \nE/ = U2\n2I\n  /1/ + 12. \n(7.158)\nThe energy is independent of the magnetic quantum number m, so each energy level is degenerate, \nwith 12/ + 12 possible m states for a given /. The free particle and the particle on a ring both exhib-\nited degeneracy because the kinetic energy was independent of the direction of the motion. Similarly, \nthe rotational kinetic energy of the particle on a sphere is independent of the orientation of the angular \nmomentum. The spectrum of energy levels is shown in Fig. 7.16. The selection rule for transitions \nbetween these levels is \u0006/ = {1, yielding the emission lines in Fig. 7.16. The transition energies are\n \n \u0006E = E/+1 - E/\n \n \n = U2\n2I\n  1/ + 121/ + 22 - U2\n2I\n /1/ + 12 \n \n = U2\n2I\n  21/ + 12\n \n \n(7.159)\n \n = U2\n2I\n  52, 4, 6, 8, 10, ...6.\n \n0\n1\n2\n3\n4\n5\nEnergy (\u00022/2l\u0007)\nE (\u00022/2l\u0007)\n0\n2\n4\n6\n8\n10\n12\n14\n16\n18\n20\n22\n24\n26\n28\n30\n0\n2\n4\n6\n8\n10\nl\nFIGURE 7.16 Energy spectrum and transitions of a rigid rotor.\n","page_start":260,"page_end":260,"token_count":429,"section_type":"other","chapter_number":8,"chapter_title":"Hydrogen Atom","chunk_index":333}
{"chunk_id":"ebc99c980833c412","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"7.6 Motion on a Sphere \n237\nz\nm1\nm2\nr1\n\u0002\nr2\n\u0002\nL\u0002\nFIGURE 7.17 A diatomic molecule is the simplest example of a rigid rotor. The two-atom \nsystem rotates around an axis perpendicular to the symmetry axis of the molecule.\nA physical example of this particle-on-a-sphere model is the rigid rotor. The simplest rigid rotor is \na diatomic molecule, as illustrated in Fig. 7.17. The two atoms with a separation r0 have a moment \nof inertia about the center of mass of I = mr2\n0, just as we have assumed in our particle-on-a-sphere \nmodel. Molecular spectroscopists call the energy U2>2I the rotational constant of the molecule.\nFor example, consider the diatomic molecule hydrogen chloride HCl. The equilibrium bond \nlength is r0 = 0.127 nm, which gives a rotational constant\n \nU2\n2I `\nHCl\n= 1.32 meV = 10.7 cm-1. \n(7.160)\nThe experimentally measured value is 10.4 cm-1. That seems close, but is in fact a clue that something \nis missing from the model. It turns out that the coupling of the vibrational motion (Chapter 9) to the \nrotational motion changes the energy levels of a real molecule. Reﬁning simple models leads to better \nunderstanding; our job here is to gain basic understanding.\n 7.6.4 \u0002 Spherical Harmonics\nWe have in hand the eigenfunctions of the two angular equations, so we can construct the energy \neigenstates of the particle on the sphere. The normalized solutions of the f equation (7.83) that satisfy \nperiodic boundary conditions are the \u0013m1f2 states in Eq. (7.100) with the restriction that the magnetic \nquantum number m be an integer. The normalized solutions of the u equation (7.82) that are regular at \nthe poles are the \u0012 m\n/ 1u2 states in Eq. (7.156) with the restriction that / = 0, 1, 2, ... and m = -/, ..., / \nin integer steps. The product \u0012 m\n/ 1u2\u0013m1f2 of the two solutions yields the function Y m\n/ 1u, f2 that we \nassumed when we applied the separation of variables procedure to the angular equation (7.80). These \nangular functions are the spherical harmonics\n \nY m\n/ 1u, f2 = 1-12\n1m+ 0m02>2\nC\n12/ + 12\n4p\n \n1/ - 0 m02!\n1/ + 0 m02! P m\n/ 1cos u2eimf, \n(7.161)\nthe ﬁrst few of which are listed in Table 7.3. The somewhat peculiar choice of sign is conventional and \ngives the useful result\n \nY -m\n/ 1u, f2 = 1-12\nm Y m*\n/ 1u, f2. \n(7.162)\n","page_start":261,"page_end":261,"token_count":684,"section_type":"other","chapter_number":8,"chapter_title":"Hydrogen Atom","chunk_index":334}
{"chunk_id":"060c101c338e253c","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"238 \nAngular Momentum\nLet’s now discuss the important properties of the spherical harmonics.\n• Orthonormality\nThe spherical harmonics are orthonormal on the unit sphere\n \n8/1m10 /2m29 =\n \nL\n2p\n0\nL\np\n0\nY m1*\n/1 1u, f2 Y m2\n/2 1u, f2 sin u du df = d/1/2dm1m2  , \n(7.163)\nwhich means that two wave functions must have the same angular momentum (/1 = /2) and the \nsame z-component (m1 = m2) or else the overlap integral is zero. The / orthogonality comes from the \nassociated Legendre u functions and the m orthogonality comes from the complex exponential f func-\ntions. The orthonormality condition is also written compactly as an integral over the full solid angle\n \nL\nY m1*\n/1 1u, f2Y m2\n/2 1u, f2d\t = d/1/2dm1m2 \n(7.164)\nfor those common occasions when there is no need to consider separate angular integrals.\n• Completeness\nThe spherical harmonics are complete in the sense that any sufﬁciently smooth function c1u, f2 \non the unit sphere can be expanded in a Laplace series as\n \nc1u, f2 = a\n\u0005\n/=0\n a\n/\nm=-/\nc/mY m\n/ 1u, f2. \n(7.165)\nThe c/m expansion coefﬁcients are found by projecting the superposition wave function onto the \n0 /m9 eigenstates:\n \nc/m = 8/m0 c9 =\n \nL\n2p\n0\nL\np\n0\nY m*\n/ 1u, f2c1u, f2sin u du df. \n(7.166)\nTable 7.3 Spherical Harmonics\n/ \nm \nY  m\n/ 1u, f2\n0 \n0 \nY  0\n0 = 4\n1\n4p\n1 \n0 \nY  0\n1 = 4\n3\n4p cos u\n \n{1 \nY {1\n1\n= <4\n3\n8p sin ue{if\n2 \n0 \nY  0\n2 = 4\n5\n16p 13 cos2 u - 12\n \n{1 \nY {1\n2\n= <4\n15\n8p sin u cos ue{if\n \n{2 \nY {2\n2\n= 4\n15\n32p sin2 ue{i2f\n3 \n0 \nY  0\n3 = 4\n7\n16p 15 cos3 u - 3 cos u2\n \n{1 \nY {1\n3\n= <4\n21\n64p sin u15 cos 2 u - 12e{i f\n \n{2 \nY {2\n3\n= 4\n105\n32p sin2 u cos ue{i2f\n \n{3 \nY {3\n3\n= 4\n35\n64p sin3 ue{i3f\n","page_start":262,"page_end":262,"token_count":695,"section_type":"other","chapter_number":8,"chapter_title":"Hydrogen Atom","chunk_index":335}
{"chunk_id":"b2e5bb39532d6d97","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"7.6 Motion on a Sphere \n239\n• Parity\nThe behavior of the spherical harmonics under the parity operation r S -r is determined by the \nangular momentum quantum number /. Spherical harmonics with even / have even parity and \nthose with odd / have odd parity:\nY m\n/ 1p - u, f + p2 = 1-12\n/\n Y m\n/ 1u, f2. \n(7.167)\nTo summarize, we have found that the spherical harmonics Y m\n/ 1u, f2 are eigenstates of the Ham-\niltonian for the particle on a sphere [Eq. (7.121)]. Because the Hamiltonian for this problem is pro-\nportional to the L2 orbital angular momentum operator [Eq. (7.122)], the spherical harmonics are also \neigenstates of L2 [Eq. (7.80)]. The spherical harmonics contain the \u0013m1f2 eigenstates, so they are also \neigenstates of the Lz operator (Problem 7.24). These three eigenvalue equations are\nHsphereY m\n/ 1u, f2 = U2\n2I\n /1/ + 12Y m\n/ 1u, f2\nL 2Y m\n/ 1u, f2 = /1/ + 12U2Y m\n/ 1u, f2 \n.\n(7.168)\nLzY m\n/ 1u, f2 = m UY m\n/ 1u, f2\nThese three operators share eigenstates because they commute with each other (Problem 7.9).\nFor a particle on a sphere, the measurement probabilities are complicated by the degeneracy, \njust as we saw in the particle on a ring [Eq. (7.105)]. For a state 0 c9, the probability of measuring the \nenergy E/ is a sum over all the degenerate states:\nPE/ =\na\n/\nm=-/\n08/m0 c90\n2. \n(7.169)\nThe probability of measuring the L2 angular momentum observable to be /1/ + 12U2 is also given by \nEq. (7.169) because the energy eigenstates and the L2 eigenstates exhibit the same degeneracy. The \nprobability of measuring the Lz angular momentum observable to be m U is the sum over all the / states \nfor which that value of m is allowed:\nPLz=m U = a\n\u0005\n/=m\n08/m0 c90\n2. \n(7.170)\nLet’s practice using the spherical harmonics.\nExample 7.4 A particle on a sphere is in the state\nc1u, f2 = 4\n15\n16p sin 2 u cos f. \n(7.171)\nWhat are the probabilities of energy (H) and angular momentum AL2 and LzB measurements?\nThis wave function looks almost like a spherical harmonic eigenstate, so we try to do this \nproblem by inspection. Using trigonometric identities, rewrite the wave function as\n c1u, f2 = 4\n15","page_start":263,"page_end":263,"token_count":665,"section_type":"other","chapter_number":8,"chapter_title":"Hydrogen Atom","chunk_index":336}
{"chunk_id":"34d47c4b1777cb09","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"c1u, f2 = 4\n15\n16p sin 2 u cos f. \n(7.171)\nWhat are the probabilities of energy (H) and angular momentum AL2 and LzB measurements?\nThis wave function looks almost like a spherical harmonic eigenstate, so we try to do this \nproblem by inspection. Using trigonometric identities, rewrite the wave function as\n c1u, f2 = 4\n15\n16p 12 sin u cos u2aeif + e-if\n2\nb\n = 4\n15\n16p sin u cos ueif + 4\n15\n16p sin u cos ue-if\n(7.172)\n = -  1\n12 A-4\n15\n8p sin u cos ueifB +\n1\n12 A4\n15\n8p sin u cos ue-ifB, ","page_start":263,"page_end":263,"token_count":185,"section_type":"other","chapter_number":8,"chapter_title":"Hydrogen Atom","chunk_index":337}
{"chunk_id":"a9bda57b02696f99","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"240 \nAngular Momentum\nwhich we recognize from Table 7.3 of spherical harmonics as the superposition\n \nc1u, f2 = -  1\n12 Y 1\n11u, f2 +\n1\n12 Y \n -1\n1 1u, f2. \n(7.173)\nIn Dirac notation, this state is\n \n0 c9 = -  1\n12 0 119 +\n1\n12 0 1, -19. \n(7.174)\nSo, without doing any integrals, we obtain the expansion coefﬁcients\n \nc/m = 8/m0 c9 = - 1\n12 d/1dm1 +\n1\n12 d/1dm,-1 \n(7.175)\nand the energy measurement probabilities\n \n PE/ =\na\n/\nm=-/\n08/m0 c90\n2\n \n \n = A-  1\n12 d/1B\n2\n+ A 1\n12 d/1B\n2\n \n \n(7.176)\n \n = d/1.\n \nThe probability of measuring the energy to be E1 = U2>I is 100%, as is the probability for measur-\ning L2 = 2U2.\nThe probability of measuring Lz = U is\n \n PL z=\n U = a\n\u0005\n/=m\n08/10 c90\n2 \n \n = A-  1\n12B\n2\n \n \n(7.177)\n \n = 1\n2.\n \nSimilarly PL z=-U = 1>2.\nSolution by inspection is nice when it works, but sometimes we must bite the bullet and integrate, \nas we’ll see in the example in the next section.\n 7.6.5 \u0002 Visualization of Spherical Harmonics\nVisualization of spherical harmonics is a challenge because of the two-dimensional structure of the \nwave functions and the fact that they are represented by complex numbers. To overcome the com-\nplex problem, it is common to plot the complex square, which is the probability density, or to plot \nthe absolute value. In either case, the azimuthal dependence vanishes as we saw with the ring prob-\nlem earlier. A two-dimensional polar plot, like we used for the Legendre polynomials, is therefore \nsufﬁcient to display the polar angle dependence, as shown in Fig. 7.18(a). To convey the uniform \nazimuthal dependence, one should visualize the polar plot as rotated around the vertical z-axis, as \ndisplayed in the three-dimensional polar plot in Fig. 7.18(b). In this plot, the “radius” at each angle \nu, f is the complex square of the spherical harmonic function. In the ring case, we also displayed the \nprobability density as a grayscale on the ring itself, which suggests plotting the spherical harmonic \n","page_start":264,"page_end":264,"token_count":596,"section_type":"other","chapter_number":8,"chapter_title":"Hydrogen Atom","chunk_index":338}
{"chunk_id":"242d7e883851b8d2","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"7.6 Motion on a Sphere \n241\nFIGURE 7.18 Spherical harmonic 0 Y 1\n31u, f20\n2 displayed as (a) a two-dimensional polar plot, \n(b) a three-dimensional polar plot, (c) grayscale on a sphere, (d) grayscale on a ﬂat rectangular  \nprojection, and (e) grayscale on a ﬂat Mollweide projection.\nprobability density as grayscale (or color) on the sphere, as shown in Fig. 7.18(c). The grayscale \nsphere can then also be projected onto a ﬂat surface, as mapmakers do, yielding the two-dimensional \nrepresentations in Figs. 7.18(d) and (e). Note that these plots do not yet give the three-dimensional \nelectron probability density because the  spherical harmonics are not functions of the radius r. We \nstill have to learn about the radial wave function in the next chapter.\nThe three-dimensional polar plots for the ﬁrst four sets of spherical harmonics are shown in \nFig. 7.19. The standard convention is to label the spherical harmonics, or orbitals, with a letter \n corresponding to the value of the orbital angular momentum quantum number /:\n \n / = 0   1   2   3   4   5   6   7  ...  \n \n(7.178)\n \n letter = s   p   d    f    g    h    i    k  ... . \nThe plots in Fig. 7.19 show angular momentum eigenstate wave functions. In many cases, such as the \ncarbon atom in Fig. 7.5, the actual orbitals are superpositions, or hybrids, of the angular momentum \neigenstates.\n","page_start":265,"page_end":265,"token_count":373,"section_type":"other","chapter_number":8,"chapter_title":"Hydrogen Atom","chunk_index":339}
{"chunk_id":"fea8bd080147c187","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"242 \nAngular Momentum\nExample 7.5 Given the angular wave function for a particle on a sphere\n \nc1u, f2 = 4\n60060\n139301p a 1\n4 + cos3 2 u + sin2 fb, \n(7.179)\ngenerate the histogram of possible energy measurements.\nTo ﬁnd the probabilities of energy measurements\n \nPE/ =\na\n/\nm=-/\n08/m0 c90\n2, \n(7.180)\nFIGURE 7.19 Three-dimensional polar plots of some spherical harmonics.\n","page_start":266,"page_end":266,"token_count":117,"section_type":"other","chapter_number":8,"chapter_title":"Hydrogen Atom","chunk_index":340}
{"chunk_id":"6924a0e2024a5687","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"7.6 Motion on a Sphere \n243\nwe must ﬁnd the overlap integrals\nc/m = 8/m0 c9 =\nL\n2p\n0\nL\np\n0\nY m*\n/ 1u, f2c1u, f2sin u d u d f. \n(7.181)\nThis wave function looks like it could be a ﬁnite sum of spherical harmonics, but the wild nor-\nmalization constant is a clue that an inﬁnite sum is required. You could try to calculate the c/m \n coefﬁcients by hand, but this problem is a good chance to explore the power of mathematical pack-\nages such as Mathematica, Maple, or Matlab. Mathematica, for example, has the spherical harmon-\nics built into its system and the overlap integral requires one command line\nTable3Integrate3Conjugate3SphericalHarmonicY3l,m,u,f44 \nc3u,f4Sin3u4,5u,0,p6,5f,0,2p64,5l,0,76,5m,-l,l64, \n(7.182)\nwhich generates a table of the c/m coefﬁcients for / = 0 S 7 and m = -/ S /, assuming c1u, f2 \nhas been deﬁned previously. A subset of the results is presented in Table 7.4. The last column of \nthe table is the probability of measuring the energy E/. From the explicit square roots in the results, \nit is evident that Mathematica does the integral analytically, not numerically. The results also indi-\ncate the symmetries of the wave function. Only m = -2, 0, 2 states contribute nonzero terms to \nthe expansion because of the symmetry of the azimuthal dependence of the wave function:\n  sin2 f = 31eif - e-if2>2i4\n2\n = 1\n4 1ei 2f + e-i 2f - 22. \n(7.183)\nFor m = 0, the coefﬁcients beyond / = 6 are zero because the polar angle term cos3 2 u has no \ncos/ u or  sin/ u terms beyond / = 6. The m = {2 coefﬁcients extend to / = \u0005.\nTable 7.4 Coefﬁcients of Spherical Harmonic Expansion\nc/m\nm =\na\n/\nm=-/\n0 c/m0\n2\n-3\n-2\n-1\n0\n1\n2\n3\n0\n1\n2\n3\nO = 4\n5\n6\n7\n0\n0\n0\n0\n0\n-5 4\n1001\n278602\n0\n4\n3003\n278602\n0\n-  13\n2  4\n11\n139301\n0\n0\n0\n0\n0\n0\n0\n0\n69 4\n429\n4875535\n0\n80 4\n143\n2925321\n0\n-128 4\n39","page_start":267,"page_end":267,"token_count":674,"section_type":"other","chapter_number":8,"chapter_title":"Hydrogen Atom","chunk_index":341}
{"chunk_id":"475d91df7ba1810a","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"c/m\nm =\na\n/\nm=-/\n0 c/m0\n2\n-3\n-2\n-1\n0\n1\n2\n3\n0\n1\n2\n3\nO = 4\n5\n6\n7\n0\n0\n0\n0\n0\n-5 4\n1001\n278602\n0\n4\n3003\n278602\n0\n-  13\n2  4\n11\n139301\n0\n0\n0\n0\n0\n0\n0\n0\n69 4\n429\n4875535\n0\n80 4\n143\n2925321\n0\n-128 4\n39\n53630885\n0\n512 4\n5\n32178531\n0\n0\n0\n0\n0\n0\n0\n0\n5 4\n1001\n278602\n0\n4\n3003\n278602\n0\n 13\n2  4\n11\n139301\n0\n0\n0\n0\n0\n0\n2042469\n4875535\n0\n1440725\n2925321\n0\n1795131\n5360885\n0\n3050869\n64357062\n0","page_start":267,"page_end":267,"token_count":267,"section_type":"other","chapter_number":8,"chapter_title":"Hydrogen Atom","chunk_index":342}
{"chunk_id":"00ab7b63864d5960","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"244 \nAngular Momentum\nA partial histogram of energy measurement probabilities is shown in Fig. 7.20. The energy \nprobabilities for the states up to / = 6 shown in Table 7.4 and Fig. 7.20 sum to 0.9923, so we \nexpect that the ﬁnite spherical harmonic expansion\n \ncfinite1u, f2 = a\n6\n/=0\n a\n/\nm=-/\nc/mY m\n/ 1u, f2 \n(7.184)\nshould be a good approximation to the actual wave function. The original wave function and the \nﬁnite spherical harmonic expansion are shown in Fig. 7.21. The match between the two is good, \nexcept at the endpoints u = 0,p, which is a phenomenon similar to that seen in Fourier series \nexpansions. Note that this wave function exhibits azimuthal dependence because it is a superposi-\ntion of different m states.\nFIGURE 7.21 (a) Original wave function and (b) 6-term spherical harmonic expansion.\nE0 E1 E2\nE3\nE4\nE5\nE6\nE\n0.5\nPEi\n\u0002\u0004E2\u0002Ψ\u0003\u00022\n\u0002\u0004E4\u0002Ψ\u0003\u00022\n\u0002\u0004E6\u0002Ψ\u0003\u00022\n\u0002\u0004E0\u0002Ψ\u0003\u00022\nFIGURE 7.20 Histogram of energy measurements.\n","page_start":268,"page_end":268,"token_count":308,"section_type":"other","chapter_number":8,"chapter_title":"Hydrogen Atom","chunk_index":343}
{"chunk_id":"9cc55d5a48fc2adc","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"Problems \n245\nSUMMARY\nIn this chapter, we introduced the idea of orbital angular momentum and illustrated its importance in \nsolving the three-dimensional differential equation that is the energy eigenvalue equation for the hydro-\ngen atom. By separating variables in the eigenvalue equation H0 E9 = E0 E9, we isolated the differential \nequations for the angular variables u and f from the differential equation for the radial variable r. Only \nthe radial differential equation includes the potential energy, so the solutions to the angular equations are \nvalid for all central potentials. The f equation yielded the azimuthal wave functions\n \n\u0013m1f2 =\n1\n22p\n eimf \n(7.185)\nand the u equation yielded the polar wave functions\n \n\u0012 m\n/ 1u2 = C\n12/ + 12\n2\n \n1/ - 0 m02!\n1/ + 0 m02! P m\n/ 1cos u2. \n(7.186)\nThe products of these two are the total angular wave functions, which are the spherical harmonics\n \n0 /m9 \u0003 Y m\n/ 1u, f2 = 1-121m+ 0  m 02>2\nC\n12/ + 12\n4p\n \n1/ - 0 m02!\n1/ + 0 m02! P m\n/ 1cos u2eimf. \n(7.187)\nThe spherical harmonics are eigenstates of the angular momentum operators L2 and Lz. In Dirac nota-\ntion, the eigenvalue equations are\n \n L 20 /m9 = /1/ + 12U20 /m9 \n \n Lz0 /m9 = m U0 /m9.\n \n(7.188)\nIn wave function notation, the eigenvalue equations are\n \n L 2Y m\n/ 1u, f2 = /1/ + 12U2Y m\n/ 1u, f2 \n \n LzY m\n/ 1u, f2 = m UY m\n/ 1u, f2.\n \n \n(7.189)\nThe limitations on the quantum numbers m and / arise from requiring the wave function to be periodic \nin f and ﬁnite at u = 0, p, respectively. The quantum numbers m and / must be integers with the \nlimitations\n \n m = -/, -/ + 1, ... 0, ..., / - 1, / \n \n / = 0, 1, 2, 3, ...\u0005.\n \n(7.190)\nPROBLEMS\n 7.1 Show that the two-body Hamiltonian in Eq. (7.3) can be separated into center-of-mass and \nrelative Hamiltonians, as in Eq. (7.11). Do this in two ways: (a) with momentum operators in \nthe abstract, and (b) momentum operators in the position representation.\n 7.2 Use the separation of variables procedure in Appendix E to separate the two-body energy eigen-\nvalue equation into the center-of-mass and relative energy eigenvalue equations in Eq. (7.24).\n 7.3 Use the separation of variables procedure in Appendix E to separate equation Eq. (7.29) into \nthree ordinary differential equations for each Cartesian coordinate.\n","page_start":269,"page_end":269,"token_count":694,"section_type":"other","chapter_number":8,"chapter_title":"Hydrogen Atom","chunk_index":344}
{"chunk_id":"047649f20529bed9","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"246 \nAngular Momentum\n 7.4 Verify the angular momentum commutation relations in Eqs. (7.51) and (7.55).\n 7.5 An angular momentum system with / = 1 is prepared in the state\n0 c9 =\n2\n129 0 119 + i 3\n129 0 109 -\n4\n129 0 1, -19.\na) What are the possible results of a measurement of the angular momentum component Lz, \nand with what probabilities would they occur?\nb) What are the possible results of a measurement of the angular momentum component Lx, \nand with what probabilities would they occur?\nc) Plot histograms of the predicted measurement results from parts (a) and (b).\n 7.6 An angular momentum system with / = 1 is prepared in the state\n0 c9 =\n1\n114 0 119 -\n3\n114 0 109 + i 2\n114 0 1, -19.\na) What are the possible results of a measurement of the angular momentum component Lz, \nand with what probabilities would they occur?\nb) Suppose that the Lz measurement on the system yields the result Lz = -U. Subsequent to \nthat result, a second measurement is performed to measure the angular momentum com-\nponent Lx. What are the possible results of that measurement, and with what probabilities \nwould they occur?\nc) Draw a schematic diagram depicting the successive measurements in parts (a) and (b).\n 7.7 An angular momentum system is prepared in the state\n0 c9 =\n1\n110 0 119 -\n2\n110 0 109 + i 2\n110 0 229 + i 1\n110 0 209.\na) What are the possible results of a measurement of the angular momentum observable L2, \nand with what probabilities would they occur?\nb) What are the possible results of a measurement of the angular momentum component Lz, \nand with what probabilities would they occur?\nc) Plot histograms of the predicted measurement results from parts (a) and (b).\n 7.8 Using Eqs. (7.35) and (7.47), show that the orbital angular momentum operators Lx, Ly, and Lz \nare represented in spherical coordinates as\n \n Lx \u0003 i U asin f 0\n0 u + cos f cot u 0\n0 fb\n \n \n Ly \u0003 i U a-cos f 0\n0 u + sin f cot u 0\n0 fb \n \n Lz \u0003 -i U 0\n0 f\n \n \n and verify that the operator L 2 = L~L = L 2\nx + L 2\ny + L 2\nz is represented in spherical coordi-\nnates as in Eq. (7.70).\n 7.9 Verify that the angular momentum operators L 2 and Lz commute with the central force \nHamiltonian.\n 7.10 Use the separation of variables procedure in Appendix E on the angular equation (7.80) to obtain \nEq. (7.82) and Eq. (7.83) for the polar and azimuthal angles.\n","page_start":270,"page_end":270,"token_count":668,"section_type":"other","chapter_number":8,"chapter_title":"Hydrogen Atom","chunk_index":345}
{"chunk_id":"99a542ad65df1b76","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"Problems \n247\n 7.11 Show by direct integration that the azimuthal eigenstates \u0013m1f2 are orthonormal.\n 7.12 Consider the particle-on-a-ring state in Example 7.2. What are the possible values of a mea-\nsurement of the observable Lz? Calculate the measurement probabilities and show that they \nagree with the results indicated in Fig. 7.9.\n 7.13 Consider the normalized state 0 c9 for a quantum mechanical particle of mass m constrained to \nmove on a circle of radius r0, given by:\n0 c9 = 23\n2 0 39 + i\n2 0 -29.\na) What is the probability that a measurement of Lz will yield 2U? 3U?\nb) What is the probability that a measurement of the energy yields E = 2U2>I?\nc) What is the expectation value of Lz in this state?\nd) What is the expectation value of the energy in this state?\n 7.14 A particle on a ring is in the normalized state\n0 c9 =\n1\n115\n 1 0 09 + i0 19 - 2i0 29 + 30 -292.\na) What are the possible results of an energy measurement and what are the corresponding \nprobabilities? Calculate the expectation value of the energy.\nb) What are the possible results of an Lz measurement and what are the corresponding prob-\nabilities? Calculate the expectation value of Lz.\n 7.15 Consider the normalized state 0 c9 for a quantum mechanical particle of mass m constrained to \nmove on a circle of radius r0, given by\n0 c9 \u0003\nN\n2 + cos 13f2 ,\n \n where N is the normalization constant.\na) Find the normalization constant N.\nb) Plot the wave function.\nc) What is the expectation value of Lz in this state?\n 7.16 A particle on a ring is prepared in the initial state\n0 c9 = 4\n1\n5 0 29 - i  4\n4\n5\n 0 -19.\n \n Find the probability density as a function of time.\n 7.17 The time-dependent probability density for a particle on a ring is measured to be\nP1f, t2 =\n1\n2p\n c 1 - 22223\n13\n sin a3f + 3U\n2I\n tb d .\n \n Determine the initial state of the particle.\n 7.18 Calculate the moment of inertia of a diatomic molecule, as depicted in Fig. 7.17. Express the \nmoment two ways: (1) in terms of the individual masses m1 and m2 and the coordinates r1 and r2, \nand (2) in terms of the reduced mass m and the atom-atom separation r0.\n 7.19 Calculate the rotational constant for the hydrogen iodide (HI) molecule.\n","page_start":271,"page_end":271,"token_count":623,"section_type":"other","chapter_number":8,"chapter_title":"Hydrogen Atom","chunk_index":346}
{"chunk_id":"bdde67e5769932d5","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"248 \nAngular Momentum\n 7.20 In each of the following sums, shift the dummy index n S n + 2. Don’t forget to shift the lim-\nits of the sum as well. Then write out all of the terms in the sum (if the sum has a ﬁnite number \nof terms) or the ﬁrst ﬁve terms in the sum (if the sum has an inﬁnite number of terms) and con-\nvince yourself that the two different expressions for each sum are the same:\na) a\n3\nn=0\nn\nb) a\n5\nn=1\neinf\nc) a\n\u0005\nn=0\nan n1n - 12zn-2\n 7.21 Use Rodrigues’ formula, by hand, to generate the ﬁrst ﬁve Legendre polynomials. Show by \ndirect integration that P21cos u2 is orthogonal to P41cos u2, and that P21cos u2 is normalized \naccording to Eq. (7.148).\n 7.22 Generate the associated Legendre functions P 1\n21z2 and P 3\n31z2 by hand. Express each function \nboth as a function of the argument z and as a function of u.\n 7.23 Use the deﬁnitions in Eqs. (7.151) and (7.161) to generate the spherical harmonics Y 0\n11u, f2 \nand Y \n -2\n2 1u, f2. Ensure that they are normalized and orthogonal by direct integration.\n 7.24 Verify that the spherical harmonics are eigenstates of the orbital angular momentum component \noperator Lz by direct application of the position representation of Lz. What are the eigenvalues?\n 7.25 Verify that the spherical harmonics are eigenstates of the orbital angular momentum operator \nL2. What are the eigenvalues?\n 7.26 Consider the new operators L+ and L- deﬁned by L{ = Lx { iLy. Use the results of Problem 7.8 \nto show that the position representations of these operators in spherical coordinates are\nL{ = U e{i f a{ 0\n0 u + i cot u 0\n0 f b.\n Act with these new operators on all the / = 1 spherical harmonic wave functions and sum-\nmarize your results in Dirac notation. Based on your results, postulate the names of these new \noperators. This is a preview of Chapter 11.\n 7.27 Express the / = 1 spherical harmonics in Cartesian coordinates. Combine the m = {1 func-\ntions in two possible ways to make real functions that closely resemble the m = 0 function.\n 7.28 Use your favorite tool (e.g., Maple, Mathematica, Matlab, pencil) to generate the Legendre \npolynomial expansion of the function f 1z2 = sin 1pz2. How many terms do you need to \ninclude in a partial sum to get a “good” approximation to f 1z2 for -1 6 z 6 1? What do you ","page_start":272,"page_end":272,"token_count":663,"section_type":"other","chapter_number":8,"chapter_title":"Hydrogen Atom","chunk_index":347}
{"chunk_id":"ec25fde5a321aa7e","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":" 7.28 Use your favorite tool (e.g., Maple, Mathematica, Matlab, pencil) to generate the Legendre \npolynomial expansion of the function f 1z2 = sin 1pz2. How many terms do you need to \ninclude in a partial sum to get a “good” approximation to f 1z2 for -1 6 z 6 1? What do you \nmean by a “good” approximation? How about the interval -2 6 z 6 2? How good is your \napproximation then? Discuss your answers. Answer the same set of questions for the function \ng1z2 = sin 13pz2.\n 7.29 Consider the normalized state of a particle on a sphere given by:\n0 c9 =\n1\n12 0 1, -19 +\n1\n13 0 109 +\ni\n16 0 009.\na) What is the probability that a measurement of Lz will yield 2U? -U? 0 U?\nb) What is the expectation value of Lz in this state?\nc) What is the expectation value of L 2 in this state?","page_start":272,"page_end":272,"token_count":244,"section_type":"other","chapter_number":8,"chapter_title":"Hydrogen Atom","chunk_index":348}
{"chunk_id":"ea26572fb525a2d6","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"Resources \n249\nd) What is the expectation value of the energy in this state?\ne) What is the expectation value of Ly in this state?\n 7.30 A particle conﬁned to the surface of a sphere is in the state\nc1u, f2 = μ\nN ap2\n4 - u2b,\n   0 6 u 6 p\n2\n0,\n     p\n2 6 u 6 p,\n \n where the normalization constant is\nN =\n1\nB\np5\n8 + 2p3 - 24p2 + 48p\n.\na) Find the coefﬁcients for the 0 /m9 = 0 009, 0 1, -19, 0 109, and 0 119 terms in a spherical \nharmonics expansion of c1u, f2.\nb) What is the probability that a measurement of the square of the total angular momentum \nwill yield 2U2? 0 U2?\nc) What is the probability that the particle can be found in the region 0 6 u 6 p>6 and \n0 6 f 6 p>6? Repeat the question for the region 5p>6 6 u 6 p and 0 6 f 6 p>6. \nPlot your approximation from part (a) above on and check to see if your answers seem \nreasonable. (The activity on linear combinations of spherical harmonics has a Maple  \nworksheet ylmcombo.mws for plotting.)\nRESOURCES\nActivities\nThese activities are available at\nwww.physics.oregonstate.edu/qmactivities\nEigenstates of a Particle Conﬁned to a Ring: Students investigate eigenstates of a quantum particle \nconﬁned to a ring.\nGuessing the Legendre Polynomial Expansion of a Function: Students try to ﬁt a given function \nwith a linear combination of Legendre polynomials using the guess and check method.\nFinding Legendre Coefﬁcients: Students use Maple to ﬁnd the ﬁrst few coefﬁcients of a Legendre \nseries to approximate a function.\nParticle Conﬁned to a Ring: Students visualize linear combinations of eigenstates and study anima-\ntions of time evolution of the probability density.\nParticle Conﬁned to a Sphere: Students visualize the spherical harmonics.\nLinear Combinations of Spherical Harmonics: Students visualize states that are made up of linear \ncombinations of spherical harmonics.\n","page_start":273,"page_end":273,"token_count":527,"section_type":"other","chapter_number":8,"chapter_title":"Hydrogen Atom","chunk_index":349}
{"chunk_id":"c07df5c4c10c1047","file_id":"a4850aad-b76a-4fb8-946f-4fc91c415bbb","filename":"David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf","text":"C H A P T E R \n8\nHydrogen Atom\nThe angular wave functions we found in the last chapter are independent of the particular form of \nthe central potential that binds the system. The remaining radial part of the wave function, however, \ndepends critically on the central potential you choose. The radial part of the problem determines the \nallowed energies of the system and hence the spectroscopic ﬁngerprint of the system that we observe \nin experiments. In this chapter, we solve for the quantized energies and the radial wave functions of \nthe bound states of the hydrogen atom, which is the simplest atomic system, comprising one electron \nbound to one proton in the nucleus. The electron and proton are bound together by the Coulomb poten-\ntial, which underlies the bonding in all atoms, molecules, liquids, and solids.\n8.1 \u0002 THE RADIAL EIGENVALUE EQUATION\nIn Chapter 7, we separated the three-dimensional energy eigenvalue equation into differential equa-\ntions for each of the spherical coordinates r, u, and f. We solved the f eigenvalue equation (7.83) and \nfound the azimuthal eigenstates \u0013m1f2 and eigenvalues m, which determined the separation constant \nB = m2. We then used the separation constant B to make the u differential equation (7.82) into an \neigenvalue equation and solved for the polar eigenstates \u0012 m\n/ 1u2 and the eigenvalues /1/ + 12, which \ndetermined the separation constant A = /1/ + 12. We now use the separation constant A to make the \nradial differential equation (7.79) into an eigenvalue equation for the energy E:\n \nc-  U2\n2mr 2 d\ndr\n ar 2 d\ndrb + V1r2 + /1/ + 12 U2\n2mr 2d R1r2 = ER1r2. \n(8.1)\nSolving this differential equation will give us the radial eigenstates R1r2 and the allowed ener-\ngies E. We then combine the three separated eigenstates into the three-dimensional eigenstate \nc1r, u, f2 = R1r2Y m\n/ 1u, f2, where the spherical harmonics Y m\n/ 1u, f2 = \u0012 m\n/ 1u2\u0013m1f2 are the prod-\nucts of the azimuthal and polar eigenstates that we found in Chapter 7.\nBefore we begin the solution, notice that the radial eigenvalue equation (8.1) resembles a one-\ndimensional eigenvalue equation with an effective potential energy Veff:\n \nVeff 1r2 = V1r2 +\nU2/1/ + 12\n2mr 2\n. \n(8.2)\nThe term U2/1/ + 12>2mr 2 in the effective potential energy is called the centrifugal barrier. It \nbehaves like a repulsive potential, and it increases with / in exact analogy with classical mechanics. In \nthis viewpoint, the effective potential energy that determines the radial motion of the electron is differ-\nent for each state with a different angular momentum quantum number /, as shown in Fig. 8.1.\n \n","page_start":274,"page_end":274,"token_count":698,"section_type":"other","chapter_number":8,"chapter_title":"Hydrogen Atom","chunk_index":350}
{"chunk_id":"1de0b89be5a80892","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"McGraw-Hill Higher Education \nA Division of f i e  McGraw-Hill Companies \nBUSINESS DYNAMICS \nSYSTEMS THINKING AND MOOELING \nFOR A COMPLEX WORLD \nCopyright 0 \n2000 by The McGraw-Hill Companies, Inc. AU rights reserved. Printcd in the United ' \nStates of America. Except as permitted under the United States Copyright Act of 1976, no part of \nthis publication may be reproduced or dismbuted in any form or by m y  means, or stored in a \ndatabase or retrieval system, without the prior written permission of the publisher. \nThis book is printed on acid-free paper. \n.h \n4 5 6 7 8 9 0 KGPiKGP 0 9 8 7 6 5 4 3 2 \nISBN 0-07-231135-5 \nPublisher: Jeffrey J. Shelsfud \nSenior sponsoring editor: Scott Isenberg \nMarketing manager: Zina Cra3 \nSenior project manager: Gladys True \nSenior production supervisor: Lori Koetters \nFreelance design coordinator: A4av L. Christianson \nFreelance cover designer: The Wsrrul \nCover image: 0 \nSonia Delaumy/L & M Services, Amsterdaflute Gulleo, LondodArt Resource, NY \nCompositor: GAChdianapolis \nTypeface: 11/13 Ernes Roman \nPrinter: Quebecor Printing Book Group/Kingsport \nLibrary of Congress Cataloging-in-Publication Data \nSterman, John. \nBusiness dynamics : systems thinking and modeling for a complex world I John D. Sterman. \nIncludes hibliographical references and index. \nISBN 0-07-231135-5 (alk. paper) \n1. Indusmal management. \n2. System theory. 3. Management information systems. I. \np. cm. \nTitle. \nHD30.2.S7835 2000 \n658.4'038'011Ldc21 \n99-056030 \nhttp://www.mhhe.com \n","page_start":3,"page_end":3,"token_count":451,"section_type":"other","chapter_number":1,"chapter_title":"Learning in and about Complex Systems","chunk_index":0}
{"chunk_id":"e107313036425cd9","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"For Cindy \n","page_start":4,"page_end":4,"token_count":3,"section_type":"other","chapter_number":1,"chapter_title":"Learning in and about Complex Systems","chunk_index":1}
{"chunk_id":"150386818a8c7805","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"ABOUT THE AUTHOR \nJohn D. Sterman is J. Spencer Standish Professor of Management at the Sloan \nSchool of Management of the Massachusetts Institute of Technology and Director \nof MIT’s System Dynamics Group. His research centers on the development of \npractical methods for systems thinking and dynamic modeling of complex sys- \ntems, with applications to organizational learning and change, operations manage- \nment, corporate strategy, and nonlinear dynamics in a wide range of systems, from \nsupply chains to scientific revolutions. He has pioneered the development of man- \nagement flight simulators of corporate and economic systems. These flight simu- \nlators are used in research to understand and improve managerial decision making \nin complex dynamic systems; more importantly, they are now widely used by cor- \nporations and universities around the world for teaching, problem solving, and pol- \nicy design. Professor Sterman discovered system dynamics modeling in high \nschool, studied it as an undergraduate at Dartmouth College, and received his PhD \nfrom MIT. He has been awarded the Jay W. Forrester Prize, given for the best pub- \nlished work in the field of system dynamics over the prior five years, and has four \ntimes won awards for teaching excellence from the students of the Sloan School. \nvi \n","page_start":5,"page_end":5,"token_count":262,"section_type":"other","chapter_number":1,"chapter_title":"Learning in and about Complex Systems","chunk_index":2}
{"chunk_id":"3b4a154a6c2e3bd7","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"Preface \nAccelerating economic, technological, social, and environmental change challenge \nmanagers and policy makers to learn at increasing rates, while at the same time the \ncomplexity of the systems in which we live is growing. Many of the problems we \nnow face arise as unanticipated side effects of our own past actions. All too often \nthe policies we implement to solve important problems fail, make the problem \nworse, or create new problems. \nEffective decision making and learning in a world of growing dynamic com- \nplexity requires us to become systems thinkers-to expand the boundaries of our \nmental models and develop tools to understand how the structure of complex sys- \ntems creates their behavior. \nThis book introduces you to system dynamics modeling for the analysis of pol- \nicy and strategy, with a focus on business and public policy applications. System \ndynamics is a perspective and set of conceptual tools that enable us to understand \nthe structure and dynamics of complex systems. System dynamics is also a rigor- \nous modeling method that enables us to build formal computer simulations of com- \nplex systems and use them to design more effective policies and organizations. \nTogether, these tools allow us to create management flight simulators-micro- \nworlds where space and time can be compressed and slowed so we can experience \nthe long-term side effects of decisions, speed learning, develop our understanding \nof complex systems, and design structures and strategies for greater success. \nThe field of system dynamics is thriving. Over the past decade, many top com- \npanies, consulting firms, and governmental organizations have used system dy- \nnamics to address critical issues. More innovative universities and business \nschools are teaching system dynamics and finding enthusiastic and growing en- \nrollments. Hundreds of primary and secondary schools, from kindergarten to high \nschool, are integrating systems thinking, system dynamics, and computer simula- \ntion into their curricula. Tools and methods for system dynamics modeling, the li- \nbrary of successful applications, and insights into the effective use of the tools with \nexecutives and organizations are all expanding rapidly. \nvii \n","page_start":6,"page_end":6,"token_count":434,"section_type":"other","chapter_number":1,"chapter_title":"Learning in and about Complex Systems","chunk_index":3}
{"chunk_id":"7a792dfdba663e58","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"viii \nPreface \nFEATURES AND CONTENT \nUniversity and graduate-level texts, particularly those focused on business and \npublic policy applications, have not kept pace with the growth of the field. This \nbook is designed to provide thorough coverage of the field of system dynamics to- \nday, by examining \nSystems thinking and the system dynamics worldview; \nTools for systems thinking, including methods to elicit and map the \nstructure of complex systems and relate those structures to their dynamics; \nTools for modeling and simulation of complex systems; \nProcedures for testing and improving models; \nGuidelines for working with client teams and successful implementation. \nYou will learn about the dynamics of complex systems, including the structures \nthat create growth, goal-seeking behavior, oscillation and instability, S-shaped \ngrowth, overshoot and collapse, path dependence, and other nonlinear dynamics. \nExamples and applications include \nCorporate growth and stagnation, \nThe diffusion of new technologies, \nThe dynamics of infectious disease such as HIV/AIDS, \nBusiness cycles, \nSpeculative bubbles, \nThe use and reliability of forecasts, \nThe design of supply chains in business and other organizations, \nService quality management, \nTransportation policy and traffic congestion, \nProject management and product development, \nand many others. \nThe goal of systems thinking and system dynamics modeling is to improve our \nunderstanding of the ways in which an organization’s performance is related to its \ninternal structure and operating policies, including those of customers, competi- \ntors, and suppliers and then to use that understanding to design high leverage poli- \ncies for success. To do so this book utilizes \nProcess Points that provide practical advice for the successful application \nof the tools in real organizations. \nCase studies of System Dynamics in Action that present successful \napplications ranging from global warming and the war on drugs to \nreengineering the supply chain of a major computer firm, marketing \nstrategy in the automobile industry, and process improvement in the \npetrochemicals industry. \nSystem dynamics is not a spectator sport. Developing systems thinking and mod- \neling skills requires the active participation of you, the reader, via \n","page_start":7,"page_end":7,"token_count":436,"section_type":"other","chapter_number":1,"chapter_title":"Learning in and about Complex Systems","chunk_index":4}
{"chunk_id":"e0372f7d58eb1b04","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"Preface \nix \nChallenges. The challenges, placed throughout the text, give you practice \nwith the tools and techniques presented in the book and will stimulate your \noriginal thinking about important real world issues. The challenges range \nfrom simple thought experiments to full-scale modeling projects. \nSimulation software and models. The accompanying CD-ROM and web \nsite (http://www.mhhe.com/sterman) \ninclude all the models developed in \nthe text along with state-of-the-art simulation software to run them. There \nare several excellent software packages designed to support system \ndynamics modeling. These include ithink, Powersim, and Vensim. The CD \nand website include the models for the text in all three software formats. \nThe disk also includes fully functional versions of the ithink, Powersim, and \nVensim software so you can run the models using any of these packages \nwithout having to purchase any additional software. \nAdditionally, the Instructor’s Manual and instructor’s section of the \nweb site include suggested solutions for the challenges, additional \nassignments, Powerpoint files with the diagrams and figures from the text \nsuitable for transparencies, suggested course sequences and syllabi, and \nother materials. \nINTENDED AUDIENCE \nThe book can be used as a text in courses on systems thinking, simulation model- \ning, complexity, strategic thinking, operations, and industrial engineering, among \nothers. It can be used in full or half-semester courses, executive education, and \nself-study. The book also serves as a reference for managers, engineers, consul- \ntants, and others interested in developing their systems thinking skills or using sys- \ntem dynamics in their organizations. \nA NOTE ON MATHEMATICS \nSystem dynamics is grounded in control theory and the modern theory of nonlin- \near dynamics. There is an elegant and rigorous mathematical foundation for the \ntheory and models we develop. System dynamics is also designed to be a practical \ntool that policy makers can use to help them solve the pressing problems they con- \nfront in their organizations. Most managers have not studied nonlinear differential \nequations or even calculus, or have forgotten it if they did. To be useful, system dy- \nnamics modeling must be accessible to the widest range of students and practicing \nmanagers without becoming a vague set of qualitative tools and unreliable gener- \nalizations. That tension is compounded by the diversity of backgrounds within the \ncommunity of managers, students, and scholars interested in system dynamics, \nbackgrounds ranging from people with no mathematics education beyond high \nschool to those with doctorates in physics. \n","page_start":8,"page_end":8,"token_count":539,"section_type":"other","chapter_number":1,"chapter_title":"Learning in and about Complex Systems","chunk_index":5}
{"chunk_id":"785a7db575b81f89","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"X \nPreface \nIF YOU DON’T HAVE A STRONG MATHEMATICS BACKGROUND, \nFEAR NOT \nThis book presents system dynamics with a minimum of mathematical formalism. \nThe goal is to develop your intuition and conceptual understanding, without sacri- \nficing the rigor of the scientific method. You do not need calculus or differential \nequations to understand the material. Indeed, the concepts are presented using only \ntext, graphs, and basic algebra. Mathematical details and references to more ad- \nvanced material are set aside in separate sections and footnotes. Higher mathemat- \nics, though useful, is not as important as the critical thinking skills developed here. \nIF YOU HAVE A STRONG MATHEMATICS BACKGROUND, FEAR NOT \nRealistic and useful models are almost always of such complexity and nonlinearity \nthat there are no known analytic solutions, and many of the mathematical tools you \nhave studied have limited applicability. This book will help you use your strong \ntechnical background to develop your intuition and conceptual understanding of \ncomplexity and dynamics. Modeling human behavior differs from modeling phy s- \nical systems in engineering and the sciences. We cannot put managers up on the lab \nbench and run experiments to determine their transfer function or frequency re- \nsponse. We believe all electrons follow the same laws of physics, but we cannot \nassume all people behave in the same way. Besides a solid grounding in the mathe- \nmatics of dynamic systems, modeling human systems requires us to develop our \nknowledge of psychology, decision malung, and organizational behavior. Finally, \nmathematical analysis, while necessary, is far from sufficient for successful sys- \ntems thinlung and modeling. For your work to have impact in the real world you \nmust learn how to develop and implement models of human behavior in organiza- \ntions, with all their ambiguity, time pressure, personalities, and politics. Through- \nout the book I have sought to illustrate how the technical tools and mathematical \nconcepts you may have studied in the sciences or engineering can be applied to the \nmessy world of the policy maker. \n~ \nFEEDBACK \nI welcome your comments, criticisms, and suggestions. Suggestions for additional \nexamples, cases, theory, models, flight simulators, and so on, to make the book \nmore relevant and useful to you are especially invited. I will update the website \nto incorporate user feedback and new materials. Email comments to <BusDyn@ \nmit .edu > . \nACKNOWLEDGMENTS \nThis work benefited immensely from the advice, criticism, and encouragement of \nmany colleagues, students, and friends. I owe an immeasurable debt to my first \nsystem dynamics teachers, Dana Meadows, Dennis Meadows, and Jay Forrester, \nfor their integrity, high standards, and passionate commitment. I’m particularly \nindebted to the exceptional students of the MIT Sloan School of Management. \nThey constantly challenge me to make the discipline of system dynamics relevant, \n","page_start":9,"page_end":9,"token_count":617,"section_type":"other","chapter_number":1,"chapter_title":"Learning in and about Complex Systems","chunk_index":6}
{"chunk_id":"c9c19d9375bf821e","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"Preface \nxi \nuseful, and exciting; I hope they’ve learned as much from me as I’ve learned from \nthem. In addition, I thank my colleagues at the Sloan School and in the system \ndynamics community around the world, who helped by providing data and exam- \nples, reviewing the draft, testing early versions in their courses, and in countless \nother ways. This group includes (but is not limited to) the following folks and \ninstitutions: \nTarek Abdel-Hamid (Naval Postgraduate School); David Andersen, George \nRichardson (SUNY Albany); Ed Anderson (Univ. of Texas); Carlos Ariza, Sharon \nEls, Ken Cooper, Jim Lyneis, Hank Taylor (Pugh-Roberts Associates); George \nBackus (Policy Assessment Corporation); Bent Bakken (Norwegian Defense Re- \nsearch Establishment); Yaman Barlas (Bogazici University, Istanbul); Michael \nBean (Powersim Corp.); Eric Beinhocker, Damon Beyer, Andrew Doman, Usman \nGhani, Maurice Glucksman, Paul Langley, Norman Marshall (McKinsey and \nCompany); Laura Black, John Carroll, Vanessa Colella, Ernst Diehl, Steve Ep- \npinger, Charlie Fine, Mila Getmansky, Paulo Goncalves, Janet Gould Wilkinson, \nJim Hines, Nan Lux, Brad Morrison, Tim Nugent, Nelson Repenning, Ed Roberts, \nScott Rockart, George Roth, Ed Schein, Peter Senge (MIT); Allen and Jane \nBoorstein; Steve Cavaleri (Central Connecticut State Univ.); Geoff Coyle (Royal \nMilitary College of Science, UK, retired); Brian Dangerfield (Univ. of Salford); \nPi1 Davidsen (Univ. of Bergen); Jim Doyle, Mike Radzicki, Khalid Saeed \n(Worcester Polytechnic Institute); Bob Eberlein, Tom Fiddaman, Dan Goldner, \nDavid Peterson, Laura Peterson (Ventana Systems); David Foley and Judy Berk; \nAndy Ford (Washington State Univ.); David Ford (Texas A&M University); \nNathan Forrester (A. T. Kearney); Rich Goldbach (Metro Machine Corp.); Chris- \ntian Haxholdt, Heather Hazard (Copenhagen Business School); Jack Homer \n(Homer Consulting); Jody House (Oregon Graduate Institute); Bill Isaacs (Dia- \nlogos); Sam Israelit (Arthur Andersen); Nitin Joglekar (Boston Univ. School \nof Management); Drew Jones (Sustainability Institute); Christian Kampmann, \nErik Mosekilde (Technical Univ. of Denmark); Daniel Kim, Virginia Wiley \n(Pegasus Communications); Craig Kirkwood (Arizona State Univ.); Elizabeth \nKrahmer Keating (Northwestern Univ.); Don Kleinmuntz (Univ. of Illinois, \nUrbana-Champaign); David Kreutzer (GKA, Inc.); Robert Landel (Darden School \nof Business, Univ. of Virginia); David Lane (London School of Economics); Erik ","page_start":10,"page_end":10,"token_count":655,"section_type":"other","chapter_number":1,"chapter_title":"Learning in and about Complex Systems","chunk_index":7}
{"chunk_id":"6f1158863223963c","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"Erik Mosekilde (Technical Univ. of Denmark); Daniel Kim, Virginia Wiley \n(Pegasus Communications); Craig Kirkwood (Arizona State Univ.); Elizabeth \nKrahmer Keating (Northwestern Univ.); Don Kleinmuntz (Univ. of Illinois, \nUrbana-Champaign); David Kreutzer (GKA, Inc.); Robert Landel (Darden School \nof Business, Univ. of Virginia); David Lane (London School of Economics); Erik \nLarsen (City University, London); Winston J. Ledet, Winston P. Ledet (The Man- \nufacturing Game, Inc.); Ralph Levine (Michigan State Univ.); Angela Lipinski \n(Society for Organizational Learning); Martin GroBmann, Frank Maier, Peter \nMilling (Univ. of Mannheim, Germany); Ali Mashayekhi (Sharif Univ. of Tech- \nnology, Teheran); Nathaniel Mass (GenCorp); Paul Monus (BP/Amoco), John \nMorecroft, Ann van Ackere, Kim Warren (London Business School); Erling \nMoxnes (Norwegian School of Economics and Business Administration); Rogelio \nOliva (Harvard Business School); Mark Paich (Colorado College); Steve Peterson, \nBarry Richmond (High Performance Systems); Greg Petsch (Compaq Computer); \nNick Pudar (General Motors); Jack Pugh, Julia Pugh, Roberta Spencer (System \nDynamics Society), JQrgen Randers (World Wildlife Fund International); Nancy \nRoberts (Leslie College); Jenny Rudolph (Boston College); Jorge Rufat-Latre \n(Strategos); Anjali Sastry, Marshall van Alstyne (University of Michigan); Bob \nStearns; Susan Sterman; Jim Thompson (Global Prospectus, LLC); John Voyer ","page_start":10,"page_end":10,"token_count":388,"section_type":"other","chapter_number":1,"chapter_title":"Learning in and about Complex Systems","chunk_index":8}
{"chunk_id":"0cebcf6be88ad5eb","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"xii \nPreface \n(Univ. of Southern Maine); Lyle Wallis (Decisio, Inc.); Jim Waters (Waters Busi- \nness Systems); Jason Wittenberg (Harvard Univ.); Eric Wolstenholme (Leeds Busi- \nness School, UK); Pave1 Zamudio Ramirez (Monitor Company); the Copenhagen \nBusiness School, The International Network of Resource Information Centers \n(aka the Balaton Group), McKinsey and Company, the Norwegian School of \nManagement, Pugh-Roberts Associates, the Society for Organizational Learning, \nthe Technical University of Denmark, and, of course, the MIT Sloan School of \nManagement. \nSpecial thanks to High Performance Systems, Powersim, SA, and Ventana \nSystems-and their great people-for providing their simulation software and \ntranslations of the models for the CD and website. \nThe team at IrwidMcGraw-Hill deserves special mention for their enthusiasm, \npatience, and editorial help, particularly Scott Isenberg, Carol Rose, Jeff Shelstad, \nand Gladys True. \nCara Barber and Kelley Donovan provided important secretarial support. \nKathy Sullivan went beyond the call of duty on library research, data collec- \nFinally, the love and support of my family have been constant and essential. \ntion, editorial changes, and graphics. \nThanks, Cindy, David, and Sarah. \n","page_start":11,"page_end":11,"token_count":291,"section_type":"other","chapter_number":1,"chapter_title":"Learning in and about Complex Systems","chunk_index":9}
{"chunk_id":"0e353e12139626bc","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"Table of Contents \nPreface vii \nPART I PERSPECTIVE AND PROCESS 1 \n1 Learning in and about Complex Systems 3 \n1.1 \nIntroduction 3 \n1.1.1 \n1.1.2 \nCauses of Policy Resistance \n10 \n1.1.3 \nFeedback \n12 \n1.1.4 \nProcess Point: The Meaning of Feedback \n14 \nChallenge: Dynamics of Multiple-Loop Systems \nPolicy Resistance, the Law of Unintended Consequences, \nand the Counterintuitive Behavior of Social Systems \n5 \n14 \n1.2 \nLearning Is a Feedback Process 14 \n1.3 \nBarriers to Learning 19 \n1.3.1 \nDynamic Complexity 21 \n1.3.2 \nLimited Information 23 \n1.3.3 \nConfounding Variables and Ambiguity 25 \n1.3.4 \nBounded Rationality and the Misperceptions \nof Feedback 26 \n1.3.5 \nFlawed Cognitive Maps 28 \n1.3.6 \nErroneous Inferences about Dynamics 29 \n1.3.7 \nUnscientific Reasoning: Judgmental Errors \nandBiases 30 \nChallenge: Hypothesis Testing 30 \n1.3.8 \nDefensive Routines and Interpersonal Impediments \nto Learning \n32 \n1.3.9 \nImplementation Failure 33 \n1.4.1 \nImproving the Learning Process: Virtues \nof Virtual Worlds 34 \n1.4.2 \nPitfalls of Virtual Worlds 35 \n1.4.3 \nWhy Simulation Is Essential \n37 \n1.4 \nRequirements for Successful Learning in Complex Systems 33 \n1.5 \nSummary 39 \nxiii \n","page_start":12,"page_end":12,"token_count":369,"section_type":"other","chapter_number":1,"chapter_title":"Learning in and about Complex Systems","chunk_index":10}
{"chunk_id":"89b45530cd2a6479","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"xiv \nContents \n2 System Dynamics in Action 41 \n2.1 \n2.2 \n2.3 \n2.4 \n2.5 \nApplications of System Dynamics 41 \nAutomobile Leasing Strategy: Gone Today, Here Tomorrow \n2.2.1 \nDynamic Hypothesis 44 \n2.2.2 \nElaborating the Model 48 \n2.2.3 \nPolicy Analysis 5 1 \n2.2.4 \nImpact and Follow-up 54 \nOn Time and Under Budget: The Dynamics \nof Project Management 55 \n2.3.1 \nThe Claim 56 \n2.3.2 \nInitial Model Development \n57 \n2.3.3 \nDynamic Hypothesis 58 \n2.3.4 \nThe Modeling Process 61 \n2.3.5 \nContinuing Impact 64 \nPlaying the Maintenance Game 66 \n2.4.1 \nDynamic Hypothesis \n67 \n2.4.2 \nThe Implementation Challenge 74 \n2.4.3 \nResults 76 \n2.4.4 \nTransferring the Learning: The Lima Experience 77 \n42 \nSummary: Principles for Successful Use of System Dynamics 79 \n3.1 \nThe Purpose of Modeling: Managers as Organization Designers 84 \n3.2 \nThe Client and the Modeler 84 \n3.3 \nSteps of the Modeling Process 85 \n3.4 \nModeling Is Iterative 87 \n3.5 \nOverview of the Modeling Process 89 \n3 The Modeling Process 83 \n3.5.1 \nProblem Articulation: The Importance of Purpose \n89 \n3.5.2 \nFormulating a Dynamic Hypothesis \n94 \n3.5.3 \nFormulating a Simulation Model \n102 \n3.5.4 \nTesting 103 \n3.5.5 \nPolicy Design and Evaluation \n103 \n4 Structure and Behavior of Dynamic Systems 107 \n3.6 \nSummary \n104 \n4.1 \n4.2 \n4.3 \nFundamental Modes of Dynamic Behavior \n4.1.1 \nExponential Growth 108 \n4.1.2 \nGoal Seeking \n11 1 \n4.1.3 \nOscillation \n114 \n4.1.4 \nProcess Point \n116 \nChallenge: Identifying Feedback Structure \nfrom System Behavior \n117 \nInteractions of the Fundamental Modes \n4.2.1 \nS-Shaped Growth 118 \n4.2.2 \nS-Shaped Growth with Overshoot \n121 \nChallenge: Identifying the Limits to Growth \n4.2.3 \nOvershoot and Collapse \n123 \nOther Modes of Behavior \n127 \n4.3.1 \nStasis, or Equilibrium 127 \n108 \n11 8 \n121 \n","page_start":13,"page_end":13,"token_count":584,"section_type":"other","chapter_number":1,"chapter_title":"Learning in and about Complex Systems","chunk_index":11}
{"chunk_id":"406ee63355f219dd","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"Contents \nxv \n4.3.2 \nRandomness 127 \n4.3.3 \nChaos 129 \n4.4 \nSummary 133 \nPART I1 TOOLS FOR SYSTEMS THINKING 135 \n5 Causal Loop Diagrams 137 \n5.1 \n5.2 \n5.3 \n5.4 \n5.5 \n5.6 \nCausal Diagram Notation 137 \nGuidelines for Causal Loop Diagrams \n5.2.1 \nCausation versus Correlation 141 \n5.2.2 \nLabeling Link Polarity \n142 \nChallenge: Assigning Link Polarities 143 \n5.2.3 \nDetermining Loop Polarity \n143 \nChallenge: Identifying Link and Loop Polarity \nChallenge: Employee Motivation 147 \n5.2.4 \nName YourLoops 148 \n5.2.5 \nIndicate Important Delays in Causal Links \n150 \n5.2.6 \nVariable Names \n152 \n5.2.7 \nTips for Causal Loop Diagram Layout \n153 \n5.2.8 \nChoose the Right Level ofAggregation 154 \n5.2.9 \nDon’t Put All the Loops into One Large Diagram \n5.2.10 \nMake the Goals of Negative Loops Explicit \n155 \n5.2.11 \nDistinguish between Actual \nProcess Point: Developing Causal Diagrams \nfrom Interview Data 157 \nChallenge: Process Improvement 158 \nConceptualization Case Study: Managing Your Workload \n5.4.1 \nProblem Definition \n159 \n5.4.2 \nIdentiJLing Key Variables 160 \n5.4.3 \nDeveloping the Reference Mode \n160 \n5.4.4 \nDeveloping the Causal Diagrams \n163 \n5.4.5 \nLimitations of the Causal Diagram \n166 \nChallenge: Policy Analysis with Causal Diagrams \nAdam Smith’s Invisible Hand and the \nFeedback Structure of Markets 169 \nChallenge: The Oil Crises of the 1970s 172 \nChallenge: Speculative Bubbles 173 \nChallenge: The Thoroughbred Horse Market \n5.5.1 \nMarket Failure, Adverse Selection, \nChallenge: The Medigap Death Spiral 176 \nExplaining Policy Resistance: Traffic Congestion \n5.6.1 \nMental Models of the Traffic Problem \n178 \n5.6.2 \nCompensating Feedback: The Response \nto Decreased Congestion \n18 1 \n5.6.3 \nThe Mass Transit Death Spiral \n185 \n5.6.4 \nPolicy Analysis: The Impact of Technology 188 \n5.6.5 \nCompensating Feedback: The Source \nof Policy Resistance \n189 \n141 \n145 \n154 \nand Perceived Conditions 156 \n159 \n168 \n174 \nand the Death Spiral \n174 \n177 \n","page_start":14,"page_end":14,"token_count":605,"section_type":"other","chapter_number":1,"chapter_title":"Learning in and about Complex Systems","chunk_index":12}
{"chunk_id":"d7a8bf8f7dcf1c5c","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"xvi \nContents \nChallenge: Identifying the Feedback Structure \nof Policy Resistance 190 \n5.7 \nSummary \n190 \n6.1 \nStocks, Flows, and Accumulation \n191 \n6 Stocks and Flows 191 \n6.1.1 \nDiagramming Notation for Stocks and Flows \n192 \n6.1.2 \nMathematical Representation of Stocks and Flows \n193 \n6.1.3 \nThe Contribution of Stocks to Dynamics \n195 \n6.2.1 \nUnits of Measure in Stock and Flow Networks \n198 \n6.2.2 \nThe Snapshot Test 199 \nChallenge: Identifying Stocks and Flows 201 \n6.2.3 \nConservation of Material in \nStock and Flow Networks 201 \n6.2.4 \nState-Determined Systems 202 \n6.2.5 \nAuxiliary Variables 202 \n6.2.6 \nStocks Change Only through Their Rates 204 \n6.2.7 \nContinuous Time and Instantaneous Flows 206 \n6.2.8 \nContinuously Divisible versus Quantized Flows 207 \n6.2.9 \nWhich Modeling Approach Should You Use? 208 \n6.2.10 \nProcess Point: Portraying Stocks and Flows \nin Practice 209 \nWhen Should Causal Loop Diagrams Show \nStock and Flow Structure? 210 \n6.2 \nIdentifying Stocks and Flows \n197 \n6.3 \nMapping Stocks and Flows 210 \n6.3.1 \nChallenge: Adding Stock and Flow Structure \nto Causal Diagrams 2 11 \nChallenge: Linking Stock and Flow Structure with Feedback \n6.3.2 \nAggregation in Stock and Flow Mapping \n213 \nChallenge: Modifying Stock and Flow Maps \nChallenge: Disaggregation 214 \n6.3.3 \nGuidelines for Aggregation \n216 \n6.3.4 \nSystem Dynamics in Action: \n6.3.5 \nSetting the Model Boundary: \n6.3.6 \nSystem Dynamics in Action: Automobile Recycling \n225 \n212 \n213 \nModeling Large-Scale Construction Projects \n“Challenging the Clouds’’ 222 \n2 18 \n6.4 \nSummary 229 \n7.1 \nRelationship between Stocks and Flows 232 \n7 Dynamics of Stocks and Flows 231 \n7.1.1 \nStatic and Dynamic Equilibrium 232 \n7.1.2 \nCalculus without Mathematics 232 \n7.1.3 \nGraphical Integration \n234 \nChallenge: Graphical Integration 239 \n7.1.4 \nGraphical Diflerentiation 239 \nChallenge: Graphical Differentiation 24 1 \n7.2 \nSystem Dynamics in Action: Global Warming 241 \n","page_start":15,"page_end":15,"token_count":586,"section_type":"other","chapter_number":1,"chapter_title":"Learning in and about Complex Systems","chunk_index":13}
{"chunk_id":"bdfd73dc95613887","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"Contents \nxvii \n7.3 \nSystem Dynamics in Action: The War on Drugs 250 \n7.4 \nSummary 262 \nDynamics of Simple Structures 263 \n7.3.1 \nThe Cocaine Epidemic after 1990 258 \n8 Closing the Loop: \n8.1 \n8.2 \n8.3 \n8.4 \n8.5 \n8.6 \nFirst-Order Systems 263 \nPositive Feedback and Exponential Growth \n8.2.1 \nAnalytic Solution for the Linear First-Order System 265 \n8.2.2 \nGraphical Solution of the Linear First-Order \nPositive Feedback System 266 \n8.2.3 \nThe Power of Positive Feedback: Doubling Times 268 \nChallenge: Paper Folding 268 \n8.2.4 \nMisperceptions of Exponential Growth 269 \n8.2.5 \nProcess Point: Overcoming Overconfidence 272 \nNegative Feedback and Exponential Decay \n8.3.1 \nTime Constants and Half-Lives \n279 \nChallenge: Goal-Seeking Behavior 281 \nMultiple-Loop Systems 282 \nNonlinear First-Order Systems: S-Shaped Growth \nChallenge: Nonlinear Birth and Death Rates \n8.5.1 \nFormal Definition of Loop Dominance \n288 \n8.5.2 \nFirst-Order Systems Cannot Oscillate 290 \nSummary 290 \n264 \n274 \n285 \n286 \nPART I11 THE DYNAMICS OF GROWTH 293 \n9 S-Shaped Growth: Epidemics, Innovation Diffusion, and the Growth of \nNew Products 295 \n9.1 \nModeling S-Shaped Growth 296 \n9.1.1 \nLogistic Growth 296 \n9.1.2 \nAnalytic Solution of the Logistic Equation 297 \n9.1.3 \nOther Common Growth Models 299 \n9.1.4 \nTesting the Logistic Model \n300 \n9.2 \nDynamics of Disease: Modeling Epidemics 300 \n9.2.1 \nA Simple Model of Infectious Disease 300 \n9.2.2 \nModeling Acute Infection: The SIR Model \n303 \n9.2.3 \nModel Behavior: The Tipping Point 305 \nChallenge: Exploring the SIR Model \n9.2.4 \nImmunization and the Eradication of Smallpox 309 \nChallenge: The Efficacy of Immunization Programs \n9.2.5 \nHerd Immunity 3 12 \n9.2.6 \nMoving Past the Tipping Point: Mad Cow Disease \n314 \nChallenge: Extending the SIR Model \n9.2.7 \nModeling the HIV/AIDS Epidemic 319 \nChallenge: Modeling HIV/AIDS 321 \nModeling New Ideas and New Products \n9.3.1 \n308 \n3 SO \n3 16 \n9.3 \nInnovation Diffusion as Infection: \n323 \nThe Logistic Model of Innovation DiJj’usion: \nExamples 325 \n","page_start":16,"page_end":16,"token_count":636,"section_type":"other","chapter_number":1,"chapter_title":"Learning in and about Complex Systems","chunk_index":14}
{"chunk_id":"0b21246a6ea1be2f","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"xviii \nContents \n9.3.2 \nProcess Point: Historical Fit and Model Validity 328 \n9.3.3 \nThe Bass Dijfusion Model \n332 \nChallenge: Phase Space of the Bass Diffusion Model 333 \n9.3.4 \nBehavior of the Bass Model \n334 \nChallenge: Critiquing the Bass Diffusion Model 334 \nChallenge: Extending the Bass Model 335 \n9.3.5 \nFad and Fashion: \nChallenge: Modeling Fads 341 \n9.3.6 \nReplacement Purchases 342 \nChallenge: Modeling the Life Cycle of Durable Products \nModeling the Abandonment of an Innovation \n339 \n345 \n9.4 \nSummary 346 \n10.1 Path Dependence 349 \nChallenge: Identifying Path Dependence 353 \n10.2 A Simple Model of Path Dependence: The Polya Process 354 \n10.2.1 \nGeneralizing the Model: Nonlinear Polya Processes 357 \n10.3 Path Dependence in the Economy: VHS versus Betamax 359 \nChallenge: Formulating a Dynamic Hypothesis \nfor the VCR Industry \n364 \n10.4.1 \nProduct Awareness 365 \n10.4.2 \nUnit Development Costs 367 \n10.4.3 \nPrice and Production Cost 368 \n10.4.4 \nNetwork Effects and Complementary Goods 370 \n10.4.5 \nProduct Differentiation 371 \n10.4.6 \nNew Product Development \n373 \n10.4.7 \nMarket Power 374 \n10.4.8 \nMergers and Acquisitions 375 \n10.4.9 \nWorkforce Quality and Loyalty \n376 \n10.4.10 The Cost of Capital 378 \n10.4.11 The Rules of the Game 380 \n10.4.12 Ambition and Aspirations 380 \n10.4.13 Creating Synergy for Corporate Growth 382 \n10 Path Dependence and Positive Feedback 349 \n10.4 Positive Feedback: The Engine of Corporate Growth 364 \n10.5 Positive Feedback, Increasing Returns, and Economic Growth 385 \n10.6 Does the Economy Lock in to Inferior Technologies? \n387 \n10.7 Limits to Lock In 389 \n10.8 Modeling Path Dependence and Standards Formation 391 \n10.8.1 \nModel Structure 392 \n10.8.2 \nModel Behavior \n396 \n10.8.3 \nPolicy Implications 402 \nChallenge: Policy Analysis 403 \nChallenge: Extending the Model 404 \n10.9 Summary 406 \nPART IV TOOLS FOR MODELING DYNAMIC SYSTEMS 407 \n11 Delays 409 \n11.1 Delays: An Introduction 409 \n","page_start":17,"page_end":17,"token_count":581,"section_type":"other","chapter_number":1,"chapter_title":"Learning in and about Complex Systems","chunk_index":15}
{"chunk_id":"ca97ea0e5a14f144","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"Contents \nxix \nChallenge: Duration and Dynamics of Delays \n11.1.1 \nDefining Delays 4 1 1 \n11.2 Material Delays: Structure and Behavior 412 \n11.2.1 \nWhat Is the Average Length of the Delay? 413 \n11.2.2 \n11.2.3 \nPipeline Delay 415 \n11.2.4 \nFirst-Order Material Delay 415 \n11.2.5 \nHigher-Order Material Delays 417 \n11.2.6 \nHow Much Is in the Delay? Little’s Law 421 \nChallenge: Response of Material Delays to \nSteps, Ramps, and Cycles 425 \n11.3 Information Delays: Structure and Behavior 426 \n11.3.1 \nModeling Perceptions: Adaptive Expectations and \nExponential Smoothing 428 \n11.3.2 \nHigher-Order Information Delays 432 \nChallenge: Response of Delays to Changing Delay Times \n11.4.1 \nNonlinear Adjustment Times: \n409 \nWhat Is the Distribution of the Output around the Average \nDelay Time? 413 \n11.4 Response to Variable Delay Times 434 \n435 \nModeling Ratchet Effects 436 \n11.5 Estimating the Duration and Distribution of Delays 437 \n11.5.1 \nEstimating Delays When Numerical Data \nAre Available 437 \n11.5.2 \nEstimating Delays When Numerical Data \nAre Not Available 445 \n11.5.3 \nProcess Point: Walk the Line 449 \nForecasting Semiconductor Demand 449 \n11.7.1 \nGeneral Formulation for Delays 462 \n11.7.2 \nFirst-Order Delay 464 \n11.7.3 \nHigher-Order Delays 465 \n11.7.4 \nRelation of Material and Information Delays 466 \n11.6 System Dynamics in Action: \n11.7 Mathematics of Delays: Koyck Lags and Erlang Distributions 462 \n11.8 Summary 466 \n12.1 Aging Chains 470 \n12 Coflows and Aging Chains 469 \n12.1.1 \nGeneral Structure of Aging Chains 470 \n12.1.2 \nExample: Population and Infrastructure in Urban \nDynamics 472 \n12.1.3 \nExample: The Population Pyramid and the Demographic \nTransition 474 \n12.1.4 \nAging Chains and Population Inertia 480 \n12.1.5 \nSystem Dynamics in Action: \n12.1.6 \nCase Study: \n12.1.7 \nPromotion Chains and the Learning Curve 490 \nWorld Population and Economic Development \nGrowth and the Age Structure of Organizations \n48 1 \n485 \n","page_start":18,"page_end":18,"token_count":581,"section_type":"other","chapter_number":1,"chapter_title":"Learning in and about Complex Systems","chunk_index":16}
{"chunk_id":"d355199a21707953","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"xx \nContents \n12.2 \n12.3 \n12.1.8 \nMentoring and On-The-Job Training 493 \nChallenge: The Interactions of Training Delays and Growth 495 \nCoflows: Modeling the Attributes of a Stock 497 \nChallenge: Coflows 503 \n12.2.1 \nCofzows with Nonconsewed Flows 504 \nChallenge: The Dynamics of Experience and Learning 508 \n12.2.2 \nIntegrating Cofzows and Aging Chains 509 \nChallenge: Modeling Design Wins in the \nSemiconductor Industry 5 11 \nSummary 511 \n13 Modeling Decision Making 513 \n13.1 Principles for Modeling Decision Making 5 13 \n13.1.1 \nDecisions and Decision Rules 5 14 \n13.1.2 \nFive Formulation Fundamentals 516 \nChallenge: Finding Formulation Flaws 520 \n13.2.1 \nFractional Increase Rate 522 \n13.2.2 \nFractional Decrease Rate 523 \n13.2.3 \nAdjustment to a Goal 523 \n13.2.4 \nThe Stock Management Structure: \nRate = Normal Rate + Adjustments \n13.2.5 \nFlow = Resource * Productivity 524 \n13.2.6 \nY = Y* * Effect of X I  on Y * Effect of X2 on Y * . . . * Effect \nofX,on Y 525 \n13.2.7 \nY = Y* + Effect ofX, on Y + Effect 0 f X 2  on Y + . . . + \nEffect of X ,  on Y 527 \nChallenge: Multiple Nonlinear Effects 529 \n13.2.8 \nFuzzy MIN Function 529 \n13.2.9 \nFuzzy MAX Function 530 \n13.2.10 Floating Goals 532 \nChallenge: Floating Goals 533 \nChallenge: Goal Formation with Internal and External Inputs 535 \n13.2.11 Nonlinear Weighted Average \n535 \n13.2.12 Modeling Search: Hill-Climbing Optimization 537 \nChallenge: Finding the Optimal Mix of Capital and Labor \n13.2.13 Resource Allocation 544 \n13.3.1 \nAll Outflows Require First-Order Control 545 \nChallenge: Preventing Negative Stocks 547 \n13.3.2 \n13.3.3 \nDisaggregate Net Flows 547 \n13.2 Formulating Rate Equations 522 \n524 \n543 \n13.3 Common Pitfalls 545 \nAvoid I F .  . . THEN. . . ELSE Formulations \n547 \n13.4 Summary 549 \n14.1 Table Functions 552 \n14 Formulating Nonlinear Relationships 551 \n14.1.1 \nSpeciJLing Table Functions 552 \n14.1.2 \nExample: Building a Nonlinear Function 552 \n","page_start":19,"page_end":19,"token_count":614,"section_type":"other","chapter_number":1,"chapter_title":"Learning in and about Complex Systems","chunk_index":17}
{"chunk_id":"a527492be24c9e9e","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"Contents \nxxi \n14.2 \n14.3 \n14.4 \n14.5 \n14.6 \n14.1.3 \nProcess Point: Table Functions versus \nAnalytic Functions 562 \nCase Study: Cutting Corners versus Overtime 563 \nChallenge: Formulating Nonlinear Functions 566 \n14.2.1 \nWorking Overtime: \n14.2.2 \nCutting Corners: \n568 \nCase Study: Estimating Nonlinear Functions with Qualitative and \nNumerical Data 569 \nChallenge: Refining Table Functions with Qualitative Data 569 \nCommon Pitfalls 573 \n14.4.1 \nUsing the Wrong Input 573 \nChallenge: Critiquing Nonlinear Functions 575 \n14.4.2 \nImproper Normalization \n576 \n14.4.3 \nAvoid Hump-Shaped Functions 577 \nChallenge: Formulating the Error Rate \nChallenge: Testing the Full Model \nEliciting Model Relationships Interactively 585 \n14.5.1 \nCase Study: Estimating Precedence Relationships in \nProduct Development 587 \nSummary 595 \nThe Effect of Schedule Pressure on Workweek 567 \nThe Effect of Schedule Pressure on Time per Task \n583 \n585 \n15 Modeling Human Behavior: Bounded Rationality or \nRational Expectations? 597 \n15.1 \n15.2 Cognitive Limitations 599 \n15.3 \nHuman Decision Making: Bounded Rationality or \nRational Expectations? 598 \nIndividual and Organizational Responses to \nBounded Rationality 601 \n15.3.1 \nHabit, Routines, and Rules of Thumb 601 \n15.3.2 \nManaging Attention 601 \n15.3.3 \nGoal Formation and Satisficing 601 \n15.3.4 \nProblem Decomposition and Decentralized \nDecision Making \n602 \n15.4 Intended Rationality 603 \n15.5 Case Study: Modeling High-Tech Growth Firms 605 \n15.4.1 \nTesting for Intended Rationality: Partial Model Tests 605 \n15.5.1 \nModel Structure: Overview 606 \n15.5.2 \nOrder Fulfillment 607 \n15.5.3 \nCapacity Acquisition 609 \nChallenge: Hill Climbing 6 15 \n15.5.4 \nThe Sales Force 615 \n15.5.5 \nThe Market 619 \n15.5.6 \nBehavior of the Full System 621 \nChallenge: Policy Design in the Market Growth Model 624 \n15.6 Summary 629 \n","page_start":20,"page_end":20,"token_count":537,"section_type":"other","chapter_number":1,"chapter_title":"Learning in and about Complex Systems","chunk_index":18}
{"chunk_id":"54075277620a56ca","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"xxii \nContents \n16 Forecasts and Fudge Factors: Modeling Expectation Formation 631 \n16.1 Modeling Expectation Formation 63 1 \n16.1.1 \nModeling Growth Expectations: \nThe TREND Function 634 \n16.1.2 \nBehavior of the TREND Function 638 \n16.2 Case Study: Energy Consumption 638 \n16.3 Case Study: Commodity Prices 643 \n16.4 Case Study: Inflation 645 \n16.5 Implications for Forecast Consumers 655 \nChallenge: Extrapolation and Stability 656 \n16.6 Initialization and Steady State Response of \nthe TREND Function 658 \n16.7 Summary 660 \nPART V INSTABILITY AND OSCILLATION 661 \n17 Supply Chains and the Origin of Oscillations 663 \n17.1 Supply Chains in Business and Beyond 664 \n17.2 The Stock Management Problem 666 \n17.1,l \nOscillation, Amplification, and Phase Lag \n664 \n17.2.1 \nManaging a Stock: Structure 668 \n17.2.2 \nSteady State Error 671 \n17.2.3 \nManaging a Stock: Behavior \n672 \nChallenge: Exploring Amplification 674 \n17.3.1 \nBehavior of the Stock Management Structure 680 \nChallenge: Exploring the Stock Management Structure 683 \n17.4.1 \nMismanaging the Supply Line: \n17.4.2 \nWhy Do We Ignore the Supply Line? 695 \n17.4.3 \nChallenge: Expanding the Real Estate Model 707 \n17.3 The Stock Management Structure 675 \n17.4 The Origin of Oscillations 684 \nThe Beer Distribution Game 684 \nCase Study: Boom and Bust in Real Estate Markets 698 \n17.5 Summary 707 \n18.1 The Policy Structure of Inventory and Production 710 \n18 The Manufacturing Supply Chain 709 \n18.1.1 \nOrder Fulfillment 7 11 \n18.1.2 \nProduction 7 13 \n18.1.3 \nProduction Starts 714 \n18.1.4 \nDemand Forecasting 7 16 \n18.1.5 \nProcess Point: Initializing a Model in Equilibrium \n7 16 \nChallenge: Simultaneous Initial Conditions 7 18 \n18.1.6 \nBehavior of the Production Model \n720 \n18.1.7 \nEnriching the Model: Adding Order Backlogs 723 \n18.1.8 \nBehavior of the Firm with Order Backlogs 725 \n18.1.9 \nAdding Raw Materials Inventory 725 \n18.2 Interactions among Supply Chain Partners 729 \n18.2.1 \nInstability and Trust in Supply Chains 735 \n","page_start":21,"page_end":21,"token_count":581,"section_type":"other","chapter_number":1,"chapter_title":"Learning in and about Complex Systems","chunk_index":19}
{"chunk_id":"c341fa1333f342a2","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"Contents \nxxiii \n18.2.2 \nChallenge: Reengineering the Supply Chain \nSystem Dynamics in Action: Reengineering the Supply Chain in a \nHigh-Velocity Industry 743 \n18.3.1 \nInitial Problem Definition 743 \n18.3.2 \nReference Mode and Dynamic Hypothesis 746 \n18.3.3 \nModel Formulation 749 \n18.3.4 \nTesting the Model 749 \n18.3.5 \nPolicy Analysis 75 1 \n18.3.6 \nImplementation: Sequential Debottlenecking 753 \n18.3.7 \nResults 755 \nFrom Functional Silos to Integrated Supply Chain \nManagement \n740 \n74 1 \n18.3 \n18.4 Summary 755 \nThe Labor Supply Chain and the Origin of Business Cycles \n19.1 The Labor Supply Chain 758 \n19 \n757 \n19.1.1 \nStructure of Labor and Hiring 758 \n19.1.2 \nBehavior of the Labor Supply Chain 760 \nChallenge: Mental Simulation of \nInventory Management with Labor 766 \n19.2.1 \nInventory-Workforce Interactions: Behavior 766 \n19.2.2 \nProcess Point: Explaining Model Behavior 767 \nChallenge: Explaining Oscillations 767 \n19.2.3 \nUnderstanding the Sources of Oscillation 771 \nChallenge: Policy Design to Enhance Stability \n19.2.4 \nAdding Overtime 774 \n19.2.5 \nResponse to Flexible Workweeks 776 \nChallenge: Reengineering a Manufacturing Firm \nfor Enhanced Stability 778 \n19.2.6 \nThe Costs of Instability 779 \nChallenge: The Costs of Instability 780 \nChallenge: Adding Training and Experience \n19.3.1 \nIs the Business Cycle Dead? 785 \n19.2 Interactions of Labor and Inventory Management 764 \n773 \n780 \n19.3 Inventory-Workforce Interactions and the Business Cycle 782 \n19.4 Summary 788 \n20.1 \nCommodity Cycles: From Aircraft to Zinc 792 \n20.2 \nA Generic Commodity Market Model 798 \n20.2.1 \nProduction and Inventory \n801 \n20.2.2 \nCapacity Utilization 802 \n20.2.3 \nProduction Capacity 805 \n20.2.4 \nDesired Capacity 807 \nChallenge: Intended Rationality of the Investment Process \n20.2.5 \nDemand \n8 11 \n20.2.6 \nThe Price-Setting Process 813 \nChallenge: Sensitivity to Uncertainty in Parameters \n20 The Invisible Hand Sometimes Shakes: Commodity Cycles 791 \n8 10 \n20.3 Application: Cycles in the Pulp and Paper Industry 824 \n828 \n","page_start":22,"page_end":22,"token_count":580,"section_type":"other","chapter_number":1,"chapter_title":"Learning in and about Complex Systems","chunk_index":20}
{"chunk_id":"009f3701a0f49057","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"xxiv \nContents \nChallenge: Sensitivity to Structural Changes \nChallenge: Implementing Structural Changes- \nModeling Livestock Markets 836 \nChallenge: Policy Analysis 840 \n83 1 \n20.4 \nSummary 841 \nPART VI MODEL TESTING 843 \n21 Truth and Beauty: Validation and Model Testing 845 \n21.1 Validation and Verification Are Impossible 846 \n21.2 Questions Model Users Should Ask-But Usually Don’t 85 1 \n21.3 Pragmatics and Politics of Model Use 85 1 \n21.3.1 \nTypes ofData 853 \n21.3.2 \nDocumentation \n855 \n21.3.3 \nReplicability \n855 \n21.3.4 \nProtective versus Reflective Modeling \n858 \n2 1.4.1 \nBoundary Adequacy Tests 861 \n21.4.2 \nStructure Assessment Tests 863 \n21.4.3 \nDimensional Consistency 866 \n21.4.4 \nParameter Assessment 866 \n2 1.4.5 \nExtreme Condition Tests 869 \nChallenge: Extreme Condition Tests \n21.4.6 \nIntegration Error Tests 872 \n21.4.7 \nBehavior Reproduction Tests 874 \n21.4.8 \nBehavior Anomaly Tests 880 \n21.4.9 \nFamily Member Tests 88 1 \n21.4.10 \nSurprise Behavior Tests 882 \n21.4.11 \nSensitivity Analysis 883 \n21.4.12 System Improvement Tests 887 \nChallenge: Model Testing 889 \n21.4 Model Testing in Practice 858 \n87 1 \n21.5 \nSummary 890 \nPART VI1 COMMENCEMENT 893 \n22 Challenges for the Future 895 \n22.1 Theory 895 \n22.2 Technology 896 \n22.3 Implementation 899 \n22.4 Education 900 \n22.5 Applications 901 \nChallenge: Putting System Dynamics into Action \nAPPENDIX A NUMERICAL INTEGRATION 903 \nChallenge: Choosing a Time Step 910 \nAPPENDIXB \nNOISE 913 \nChallenge: Exploring Noise 922 \nREFERENCES 925 \nINDEX 947 \n901 \n","page_start":23,"page_end":23,"token_count":462,"section_type":"other","chapter_number":1,"chapter_title":"Learning in and about Complex Systems","chunk_index":21}
{"chunk_id":"43165da7e956a700","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"List of Challenges \nDynamics of Multiple-Loop Systems 14 \nHypothesis Testing 30 \nIdentifying Feedback Structure from System Behavior \nIdentifying the Limits to Growth \nAssigning Link Polarities 143 \nIdentifying Link and Loop Polarity \nEmployee Motivation \n147 \nProcess Improvement 158 \nPolicy Analysis with Causal Diagrams \nThe Oil Crises of the 1970s \nSpeculative Bubbles \n173 \nThe Thoroughbred Horse Market 174 \nThe Medigap Death Spiral 176 \nIdentifying the Feedback Structure of Policy Resistance \nIdentifying Stocks and Flows 201 \nAdding Stock and Flow Structure to Causal Diagrams \nLinking Stock and Flow Structure with Feedback 212 \nModifying Stock and Flow Maps \nDisaggregation 214 \nGraphical Integration 239 \nGraphical Differentiation 241 \nPaper Folding 268 \nGoal-Seeking Behavior 28 1 \nNonlinear Birth and Death Rates \nExploring the SIR Model 308 \nThe Efficacy of Immunization Programs \nExtending the SIR Model 3 16 \nModeling HIV/AIDS 321 \nPhase Space of the Bass Diffusion Model \nCritiquing the Bass Diffusion Model \nExtending the Bass Model 335 \nModeling Fads 341 \n117 \n122 \n145 \n168 \n172 \n190 \n211 \n213 \n286 \n3 10 \n333 \n334 \nxxv \n","page_start":24,"page_end":24,"token_count":293,"section_type":"other","chapter_number":1,"chapter_title":"Learning in and about Complex Systems","chunk_index":22}
{"chunk_id":"2accb2928dc7b389","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"xxvi \nList of Challenges \nModeling the Life Cycle of Durable Products 345 \nIdentifying Path Dependence 353 \nFormulating a Dynamic Hypothesis for the VCR Industry 364 \nPolicy Analysis 403 \nExtending the Model 404 \nDuration and Dynamics of Delays 409 \nResponse of Material Delays to Steps, Ramps, and Cycles 425 \nResponse of Delays to Changing Delay Times 435 \nThe Interactions of Training Delays and Growth 495 \nCoflows 503 \nThe Dynamics of Experience and Learning \nModeling Design Wins in the Semiconductor Industry \nFinding Formulation Flaws 520 \nMultiple Nonlinear Effects 529 \nFloating Goals 533 \nGoal Formation with Internal and External Inputs \nFinding the Optimal Mix of Capital and Labor 543 \nPreventing Negative Stocks 547 \nFormulating Nonlinear Functions 566 \nRefining Table Functions with Qualitative Data \nCritiquing Nonlinear Functions 575 \nFormulating the Error Rate 583 \nTesting the Full Model 585 \nHill Climbing 615 \nPolicy Design in the Market Growth Model \nExtrapolation and Stability 656 \nExploring Amplification 674 \nExploring the Stock Management Structure 683 \nExpanding the Real Estate Model \nSimultaneous Initial Conditions 7 18 \nReengineering the Supply Chain 74 1 \nMental Simulation of Inventory Management with Labor \nExplaining Oscillations 767 \nPolicy Design to Enhance Stability \nReengineering a Manufacturing Firm for Enhanced Stability \nThe Costs of Instability 780 \nAdding Training and Experience 780 \nIntended Rationality of the Investment Process \nSensitivity to Uncertainty in Parameters 828 \nSensitivity to Structural Changes \nImplementing Structural Changes-Modeling Livestock Markets \nPolicy Analysis 840 \nExtreme Condition Tests 871 \nModel Testing 889 \nhtting System Dynamics Into Action \nChoosing a Time Step 910 \nExploring Noise 922 \n508 \n5 11 \n535 \n569 \n624 \n707 \n766 \n773 \n778 \n8 10 \n83 1 \n836 \n901 \n","page_start":25,"page_end":25,"token_count":434,"section_type":"other","chapter_number":1,"chapter_title":"Learning in and about Complex Systems","chunk_index":23}
{"chunk_id":"1197cbdf337fc74f","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"Learning in and about \nComplex Systems \nExperience is an expensive school. \n-Benjamin Franklin \nExperience is something you get just after you need it. \n-Anonymous \n1 .I \nINTRODUCTION \nThe greatest constant of modern times is change. Accelerating changes in tech- \nnology, population, and economic activity are transforming our world, from the \nprosaic-the effect of information technology on the way we use the telephone- \nto the profound-the effect of greenhouse gases on the global climate. Some of the \nchanges are wonderful; others defile the planet, impoverish the human spirit, and \nthreaten our survival. All challenge traditional institutions, practices, and beliefs. \nMost important, most of the changes we now struggle to comprehend arise as \nconsequences, intended and unintended, of humanity itself. All too often, well- \nintentioned efforts to solve pressing problems lead to policy resistance, where our \npolicies are delayed, diluted, or defeated by the unforeseen reactions of other \npeople or of nature. Many times our best efforts to solve a problem actually make \nit worse. \nThe dizzying effects of accelerating change are not new. Henry Adams, a \nperceptive observer of the great changes wrought by the industrial revolution, \n3 \n","page_start":28,"page_end":28,"token_count":261,"section_type":"other","chapter_number":1,"chapter_title":"Learning in and about Complex Systems","chunk_index":24}
{"chunk_id":"02132828b5595d5b","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"4 \nPart I Perspective and Process \nformulated the Law of Acceleration to describe the exponential growth of tech- \nnology, production, and population that made the legacy of colonial America he \ninherited irrelevant: \nSince 1800, scores of new forces had been discovered; old forces had been raised \nto higher powers . . . Complexity had extended itself on immense horizons, \nand arithmetical ratios were useless for any attempt at accuracy. \nIf science were to go on doubling or quadrupling its complexities every \n10 years, even mathematics should soon succumb. An average mind had suc- \ncumbed already in 1850; it could no longer understand the problem in 1900. \n(Adams 1918, pp. 490,496) \nAdams believed the radical changes in society induced by these forces “would \nrequire a new social mind.” With uncharacteristic, and perhaps ironic, optimism, \nhe concluded, “Thus far, since 5 or 10 thousand years, the mind had successfully \nreacted, and nothing yet proved that it would fail to react-but it would need \nto jump.” \nA steady stream of philosophers, scientists, and management gurus have since \nechoed Adams, lamenting the acceleration and calling for similar leaps to funda- \nmental new ways of thinking and acting. Many advocate the development of sys- \ntems thinking-the ability to see the world as a complex system, in which we \nunderstand that “you can’t just do one thing” and that “everything is connected to \neverything else.” If people had a holistic worldview, it is argued, they would then \nact in consonance with the long-term best interests of the system as a whole, iden- \ntify the high leverage points in systems, and avoid policy resistance. Indeed, for \nsome, the development of systems thinking is crucial for the survival of humanity. \nThe challenge facing us all is how to move from generalizations about accel- \nerating learning and systems thinking to tools and processes that help us under- \nstand complexity, design better operating policies, and guide change in systems \nfrom the smallest business to the planet as a whole. However, learning about com- \nplex systems when you also live in them is difficult. We are all passengers on an \naircraft we must not only fly but redesign in flight. \nSystem dynamics is a method to enhance learning in complex systems. Just as \nan airline uses flight simulators to help pilots learn, system dynamics is, partly, a \nmethod for developing management flight simulators, often computer simulation \nmodels, to help us learn about dynamic complexity, understand the sources of pol- \nicy resistance, and design more effective policies. \nBut learning about complex dynamic systems requires more than technical \ntools to create mathematical models. System dynamics is fundamentally interdis- \nciplinary. Because we are concerned with the behavior of complex systems, system \n‘There are many schools of systems thinking (for surveys, see Richardson 1991 and Lane \n1994). Some emphasize qualitative methods; others stress formal modeling. As sources of method ","page_start":29,"page_end":29,"token_count":646,"section_type":"other","chapter_number":1,"chapter_title":"Learning in and about Complex Systems","chunk_index":25}
{"chunk_id":"ced94d07336feafc","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"icy resistance, and design more effective policies. \nBut learning about complex dynamic systems requires more than technical \ntools to create mathematical models. System dynamics is fundamentally interdis- \nciplinary. Because we are concerned with the behavior of complex systems, system \n‘There are many schools of systems thinking (for surveys, see Richardson 1991 and Lane \n1994). Some emphasize qualitative methods; others stress formal modeling. As sources of method \nand metaphor they draw on fields as diverse as anthropology, biology. engineering, linguistics, psy- \nchology, physics, and Taoism and seek applications in fields still more diverse. All agree, however, \nthat a systems view of the world is still rare. Jay Forrester developed system dynamics in the 1950s \nat MIT. Richardson (1991) traces the history of the field and relates system dynamics to other sys- \ntems approaches. ","page_start":29,"page_end":29,"token_count":186,"section_type":"other","chapter_number":1,"chapter_title":"Learning in and about Complex Systems","chunk_index":26}
{"chunk_id":"a54966d9baca978d","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"Chapter 1 Learning in and about Complex Systems \n5 \ndynamics is grounded in the theory of nonlinear dynamics and feedback control \ndeveloped in mathematics, physics, and engineering. Because we apply these tools \nto the behavior of human as well as physical and technical systems, system \ndynamics draws on cognitive and social psychology, economics, and other social \nsciences. Because we build system dynamics models to solve important real world \nproblems, we must learn how to work effectively with groups of busy policy \nmakers and how to catalyze sustained change in organizations. \nThis chapter discusses the skills required to develop your systems thinking ca- \npabilities, how to create an effective learning process in dynamically complex sys- \ntems, and how to use system dynamics in organizations to address important \nproblems. I first review what we know about how people learn in and about com- \nplex dynamic systems. Such learning is difficult and rare because a variety of \nstructural impediments thwart the feedback processes required for learning to oc- \ncur. Successful approaches to learning about complex dynamic systems require \n(1) tools to elicit and represent the mental models we hold about the nature of dif- \nficult problems; (2) formal models and simulation methods to test and improve our \nmental models, design new policies, and practice new skills; and (3) methods to \nsharpen scientific reasoning skills, improve group processes, and overcome defen- \nsive routines for individuals and teams. \n1 .I .I \nPolicy Resistance, the Law of Unintended \nConsequences, and the Counterintuitive \nBehavior of Social Systems \nAnd it will fall out as in a complication of diseases, that by applying a \nremedy to one sore, you will provoke another; and that which removes the \none ill symptom produces others . . . \n-Sir Thomas More \nThe best-laid schemes o’ mice an ’men/ Gang a@ a-gley. \n-Robert Burns \nAnything that can go wrong will go wrong. \n--“Murphy” \nWe have met the enemy and he is us. \n-Pogo \nFrom Thomas More in 15 16 to Pogo in the mid 20th century it has long been ac- \nknowledged that people seeking to solve a problem often make it worse. Our poli- \ncies may create unanticipated side effects. Our attempts to stabilize the system may \ndestabilize it. Our decisions may provoke reactions by others seehng to restore the \nbalance we upset. Forrester (1971a) calls such phenomena the “counterintuitive \nbehavior of social systems.” These unexpected dynamics often lead to policy re- \nsistance, the tendency for interventions to be delayed, diluted, or defeated by the \nresponse of the system to the intervention itself (Meadows 1982). \n","page_start":30,"page_end":30,"token_count":585,"section_type":"other","chapter_number":1,"chapter_title":"Learning in and about Complex Systems","chunk_index":27}
{"chunk_id":"3120d06db06c627f","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"6 \nPart I Perspective and Process \nFIGURE 1-1 \nPolicy resistance: \nRomanian birth \nrates \nThe crude birth \nrate in Romania \nshowing the effect \nof restricting abor- \ntion beginning in \n1966 \n1971 \n1994 \nStatistical Yearbook 1995, \nAs an example, consider the birth rate in Romania in the late 1960s. The crude \nbirth rate (births per year per 1000 people) was extremely low-about 15 per \nthousand (Figure 1- 1). For various reasons, including national pride and ethnic \nidentity, the low birth rate was considered to be a grave problem by the govern- \nment, including the dictator Nicolau CeausesCu. The Ceausesp regime responded \nby imposing policies designed to stimulate the birth rate. Importation of contra- \nceptive devices was outlawed; propaganda campaigns extolling the virtues of large \nfamilies and the patriotic (matriotic would be more accurate) duty to have more \nchildren were introduced, along with some modest tax incentives for larger fami- \nlies. Perhaps most important, abortion-freely available on demand since 1957 \nthrough the state health care system-was banned in October 1966 (David and \nWright 197 1). \nThe result was immediate and dramatic. The birth rate rose sharply to nearly \n40 per 1000 per year, rivaling those of the fastest growing nations. The policy ap- \npeared to be a sensational success. However, within months the birth rate began to \nfall. By the end of 1970, only 4 years after the policy was implemented, the birth \nrate had dropped below 20 per thousand, close to the low levels seen prior to the \nintervention. Though the policy continued in force, the birth rate continued to fall, \nreaching 16 per thousand by 1989-about the same low rate that led to the impo- \nsition of the policy. What happened? \nThe system responded to the intervention in ways the regime did not antici- \npate. The people of Romania found ways around the policy. They practiced alter- \nnative methods of birth control. They smuggled contraceptive pills and devices in \nfrom other countries. Desperate women sought and found back-alley abortions. \nMany of these were unsanitary or botched, leading to a near tripling of deaths due \n","page_start":31,"page_end":31,"token_count":511,"section_type":"other","chapter_number":1,"chapter_title":"Learning in and about Complex Systems","chunk_index":28}
{"chunk_id":"9ed9904e38523f59","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"Chapter 1 Learning in and about Complex Systems \n7 \nto complications of abortion from 1965 to 1967. Most horribly, the number of \nneonatal deaths rose by more than 300% between 1966 and 1967, a 20% increase \nin the infant mortality rate (David and Wright 1971). The result: the policy was \nrendered completely ineffective almost immediately after implementation. \nBut the unanticipated consequences didn’t end with the failure of the popu- \nlation policy. The people of Romania, among the poorest in Europe, were having \nsmall families because they couldn’t afford larger ones. Child care was unavail- \nable for some. Many others lived with their extended families in small, crowded \napartments. Jobs were scarce; income was low. Many people gave children they \ncouldn’t support to state-run orphanages. The government’s policy didn’t prevent \nthe people of Romania from controlling their own fertility, but it did breed intense \nresentment against the intrusive policies of the regime. In 1989, when the Berlin \nwall fell and the totalitarian regimes of Eastern Europe toppled, Romania was the \nonly nation where the velvet revolution was violent. The hated Ceausesp and his \nequally hated wife were summarily executed by firing squad. Their bloody bodies \nwere left in the courtyard of the presidential palace while the scene was broadcast \non national television. The law banning abortion was the first overturned by the \nnew government. The birth rate, already low, fell further. By the mid 1990s, the \npopulation of Romania was actually declining as births dropped below deaths. \nThe children of Romania suffered the most from the population policy. During \nthe years of the population policy thousands of children were placed in the care of \nstate orphanages, where they were kept like animals in cribs (cages, really) with- \nout attention to basic needs, much less the love that all of us need and deserve. \nFood was so scarce that blood transfusions were routinely given as nutritional sup- \nplements. Because needles were used repeatedly, an epidemic of AIDS spread \nrapidly among the children. The side effects of the failed population policy cast a \nshadow on the health and happiness of an entire nation, a shadow stretching over \ngenerations. \nPolicy resistance is not limited to dictators. It doesn’t respect national borders, \npolitical ideology, or historical epoch. Consider the US government’s fight against \ninflation in the early 1970s. Figure 1-2 shows the Consumer Price Index (CPI) for \nthe United States between 1968 and 1976. In the early 1970s inflation had acceler- \nated and the Nixon administration felt action had to be taken. Though a Republi- \ncan, Nixon chose to implement wage and price controls. The policy was expensive: \nA new federal bureaucracy, the Council on Wage and Price Stability, was created \nto oversee the controls and enforce compliance. Wage and price controls were \nviewed by many in Nixon’s own party as verging on socialism, costing Nixon ","page_start":32,"page_end":32,"token_count":645,"section_type":"other","chapter_number":1,"chapter_title":"Learning in and about Complex Systems","chunk_index":29}
{"chunk_id":"a5910428df9592ff","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"ated and the Nixon administration felt action had to be taken. Though a Republi- \ncan, Nixon chose to implement wage and price controls. The policy was expensive: \nA new federal bureaucracy, the Council on Wage and Price Stability, was created \nto oversee the controls and enforce compliance. Wage and price controls were \nviewed by many in Nixon’s own party as verging on socialism, costing Nixon \nvaluable political capital. At first, the policy seemed to work, although imperfectly. \nDuring so-called Phase I of the controls, the rate of inflation fell by about half. The \nadministration decided the controls could be relaxed. In Phase 11, President Ford \n(who inherited the program from Nixon) launched a jawboning campaign, com- \nplete with campaign-style buttons labeled “WIN!” for “Whip Inflation Now!”. \nFew observers expected WIN! buttons to have any effect, and most felt inflation \nwould return to its rate prior to the start of controls. Instead, inflation actually ac- \ncelerated until, by 1975, the CPI had returned to the trajectory it was on prior to the \nimposition of the price controls. Less than 4 years after the intervention there was ","page_start":32,"page_end":32,"token_count":253,"section_type":"other","chapter_number":1,"chapter_title":"Learning in and about Complex Systems","chunk_index":30}
{"chunk_id":"8192ba10adc160cf","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"8 \nPart I Perspective and Process \nFIGURE 1-2 \nThe US Consumer Price Index (CPI) showing the Nixon/Ford wage and price \ncontrols \nPolicy resistance in the fight against inflation \n60 \nh \n0 \n2 50 \n30 \n1968 \n1969 \n1970 \n1971 \n1972 \n1973 \n1974 \n1975 \n1976 \nno residue of benefit. Other examples of policy resistance can be found nearly \nevery day in the newspaper. Table 1-1 lists a few.’ \nMachiavelli, a keen observer of human systems, discussed policy resistance at \nlength, observing in the Discourses that \nWhen a problem arises either from within a republic or outside it, one brought \nabout either by internal or external reasons, one that has become so great that it \nbegins to make everyone afraid, the safest policy is to delay dealing with it rather \nthan trying to do away with it, because those who try to do away with it almost \nalways increase its strength and accelerate the harm which they feared might come \nfrom it. (Machiavelli 1979, pp. 240-241). \nI find Machiavelli’s view too cynical but can sympathize with his frustration in ob- \nserving his client princes (the CEOs of Renaissance Italy) take actions that only \nmade their problems worse. A more reflective view is offered by the late biologist \nand essayist Lewis Thomas (1974, p. 90): \nWhen you are confronted by any complex social system, such as an urban center or \na hamster, with things about it that you’re dissatisfied with and anxious to fix, you \ncannot just step in and set about fixing with much hope of helping. This realization \nis one of the sore discouragements of our century . . . You cannot meddle with one \npart of a complex system from the outside without the almost certain risk of setting \noff disastrous events that you hadn’t counted on in other, remote parts. If you want \nto fix something you are first obliged to understand. . . the whole system. . . \nIntervening is a way of causing trouble. \n2Further reading: John McPhee (1989) offers a wonderful description of policy resistance in the \nrelationship of people with nature. McPhee brilliantly describes the unanticipated side effects and \npolicy resistance arising from attempts to defeat three elemental forces of nature: volcanism, flood, \nand fire. Edward Tenner (1996) also identifies many examples of policy resistance. \n","page_start":33,"page_end":33,"token_count":530,"section_type":"other","chapter_number":1,"chapter_title":"Learning in and about Complex Systems","chunk_index":31}
{"chunk_id":"6cb65b68f8cd163f","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"Chapter 1 Learning in and about Complex Systems \n9 \n“Use of Cheaper Drugs Pushes Costs Up, Not Down, Study Finds: Limiting \nwhat is prescribed, as managed-care systems do, has unintended effect of \nincreasing costs, results show” (Headline in LA Times, 3/20/96, p. 1, report- \ning Univ. of Utah study of 13,000 patients in various HMOs). \nsoil out of cultivation for a decade to combat erosion and help the environ- \nment, is a waste of money, so says a new study of the 11-year-old \nprogram . . . For every eroding acre a farmer idles, another farmer-or \nsometimes the same one-simply plows up nearly as much additional \nerosion-prone land . . . In the Great Plains, for instance, farmers set aside \n17 million acres, yet the total cultivated land dropped by only 2 million acres” \n(Business Week, 3/18/96, p. 6, reporting a Univ. of Minnesota study). \nLow tar and nicotine cigarettes actually increase intake of carcinogens, CO, \netc. as smokers compensate for the low nicotine content by smoking more \ncigarettes per day, by taking longer, more frequent drags, and by holding the \nsmoke in their lungs longer. \nAntilock brakes and other automotive safety devices cause some people to \ndrive more aggressively, offsetting some of their benefits. \nInformation technology has not enabled the “paperless off ice”-paper con- \nsumption per capita is up. \nRoad building programs designed to reduce congestion have increased traf- \nfic, delays, and pollution. \nDespite widespread use of labor-saving appliances, Americans have less \nleisure today than 50 years ago. \nThe US government’s war on drugs, focusing on interdiction and supply dis- \nruption (particularly cocaine production in South America), with a cost in the \nbillions, has had only a small impact on cocaine cultivation, production, or \nsmuggling. Drug use in America and elsewhere remains high. \nThe US policy of fire suppression has increased the size and severity of \nforest fires. Rather than frequent, small fires, fire suppression leads to the \naccumulation of dead wood and other fuels leading to larger, hotter, and \nmore dangerous fires, often consuming the oldest and largest trees which \npreviously survived smaller fires unharmed. \nFlood control efforts such as levee and dam construction have led to more \nsevere floods by preventing the natural dissipation of excess water in flood \nplains. The cost of flood damage has increased as the flood plains were de- \nveloped by people who believed they were safe. \nImposing 200-mile territorial limits and quotas to protect fish stocks did \nnot prevent the collapse of the Georges Bank fishery off the coast of North \nAmerica. Once the world’s richest, by the mid 1990s many species were \ncommercially extinct, the fishery was shut down, the fleets were idled, \nand the local economies were in depression. ","page_start":34,"page_end":34,"token_count":647,"section_type":"other","chapter_number":1,"chapter_title":"Learning in and about Complex Systems","chunk_index":32}
{"chunk_id":"0efd585c78e2ff91","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"veloped by people who believed they were safe. \nImposing 200-mile territorial limits and quotas to protect fish stocks did \nnot prevent the collapse of the Georges Bank fishery off the coast of North \nAmerica. Once the world’s richest, by the mid 1990s many species were \ncommercially extinct, the fishery was shut down, the fleets were idled, \nand the local economies were in depression. \nDeregulation of the US Savings and Loan industry, designed to save the \nindustry from financial problems, led to a wave of speculation followed by \ncollapse, at a cost to taxpayers in the hundreds of billions of dollars. \nAntibiotics have stimulated the evolution of drug-resistant pathogens, \nincluding virulent strains of TB, strep, staph, and sexually transmitted \ndiseases. \nand weeds, killed off natural predators, and accumulated up the food chain \nto poison fish, birds, and possibly humans. \nTABLE 1-1 \nExamples Of policy \nresistance \n“Washington’s biggest conservation program, which pays farmers to take \nPesticides and herbicides have stimulated the evolution of resistant pests ","page_start":34,"page_end":34,"token_count":235,"section_type":"other","chapter_number":1,"chapter_title":"Learning in and about Complex Systems","chunk_index":33}
{"chunk_id":"c0a275e8425e1f27","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"10 \nPart I Perspective and Process \nFIGURE 1-3 \nEvent-oriented \nview of the world \nBut how can one come to understand the whole system? How does policy resis- \ntance arise? How can we learn to avoid it, to find the high leverage policies that \ncan produce sustainable benefit? \n1 .I .2 \nCauses of Policy Resistance \nOne cause of policy resistance is our tendency to interpret experience as a series of \nevents, for example, “inventory is too high,” or “sales fell this month.” Accounts \nof who did what to whom are the most common mode of discourse, from the mail- \nroom to the boardroom, from headlines to history books. We are taught from an \nearly age that every event has a cause, which in turn is an effect of some still ear- \nlier cause: “Inventory is too high because sales unexpectedly fell. Sales fell be- \ncause the competitors lowered their price. The competitors lowered their price \nbecause. . .,’ Such event-level explanations can be extended indefinitely, in an un- \nbroken Aristotelian chain of causes and effects, until we arrive at some First Cause, \nor more likely, lose interest along the way. \nThe event-oriented worldview leads to an event-oriented approach to problem \nsolving. Figure 1-3 shows how we often try to solve problems. We assess the state \nof affairs and compare it to our goals. The gap between the situation we desire and \nthe situation we perceive defines our problem. For example, suppose sales of your \norganization were $80 million last quarter, but your sales goal was $100 million. \nThe problem is that sales are 20% less than you desired. You then consider various \noptions to correct the problem. You might cut prices to stimulate demand and in- \ncrease market share, replace the vice president of sales with someone more ag- \ngressive, or take other actions. You select the option you deem best and implement \nit, leading (you hope) to a better result. You might observe your sales increase: \nproblem solved. Or so it seems. \nThe system reacts to your solution: As your sales rise, competitors cut prices, \nand sales fall again. Yesterday’s solution becomes today’s problem. We are not \npuppet masters influencing a system out there-we are embedded in the system. \nThe puppet master’s movements respond to the position of the marionette on the \nstrings. There is feedback The results of our actions define the situation we face in \nthe future. The new situation alters our assessment of the problem and the deci- \nsions we take tomorrow (see the top of Figure 1-4). \nPolicy resistance arises because we often do not understand the full range of \nfeedbacks operating in the system (Figure 1-4). As our actions alter the state of the \nsystem, other people react to restore the balance we have upset. Our actions may \nalso trigger side effects. \nGoals \\ \nProblem -b \nDecision -b \nResults \n7 \nSituation \n","page_start":35,"page_end":35,"token_count":634,"section_type":"other","chapter_number":1,"chapter_title":"Learning in and about Complex Systems","chunk_index":34}
{"chunk_id":"7c776df7719f2e72","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"Chapter 1 Learning in and about Complex Systems \n11 \nFIGURE 1-4 \nThe feedback view \nWe frequently talk about side effects as if they were a feature of reality. Not so. \nIn reality, there are no side effects, there are just effects. When we take action, there \nare various effects. The effects we thought of in advance, or were beneficial, we \ncall the main, or intended effects. The effects we didn’t anticipate, the effects \nwhich fed back to undercut our policy, the effects which harmed the system-these \nare the ones we claim to be side effects. Side effects are not a feature of reality but \na sign that our understanding of the system is narrow and flawed. \nUnanticipated side effects arise because we too often act as if cause and effect \nwere always closely linked in time and space. But in complex systems such as an \nurban center or a hamster (or a business, society, or ecosystem) cause and effect are \noften distant in time and space. Narrow model boundaries often lead to beliefs that \nviolate the laws of physics: in the mid 1990s California and the automobile indus- \ntry debated the introduction of so-called zero emission vehicles (ZEVs) to reduce \nair pollution. True, the ZEVs-electric cars-would have no tailpipe. But the \npower plants required to make the electricity to run them do generate pollution. In \nreality, California was promoting the adoption of DEVs-displaced \nemission ve- \nhicles-cars whose wastes would blow downwind to other states or accumulate in \nnuclear waste dumps outside its borders. Electric cars may turn out to be an envi- \nronmental boon compared to internal combustion. The technology is improving \nrapidly, and air pollution is a major health problem in many cities. But no mode of \n/ \nDecisions \nJ \nEnvironment \nOur decisions alter our environment, leading to new decisions, \nEnvironment \nGoals<( \nOther \nAgents LAct;t;;sof \nbut also triggering side effects, delayed reactions, changes \nin goals and interventions by others. These feedbacks may \nlead to unanticipated results and ineffective policies. \n","page_start":36,"page_end":36,"token_count":455,"section_type":"other","chapter_number":1,"chapter_title":"Learning in and about Complex Systems","chunk_index":35}
{"chunk_id":"2536901848eb3178","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"12 \nPart I Perspective and Process \ntransport or energy conversion process is free of environmental impact, and no \nlegislature can repeal the second law of  thermodynamic^.^ \nTo avoid policy resistance and find high leverage policies requires us to ex- \npand the boundaries of our mental models so that we become aware of and under- \nstand the implications of the feedbacks created by the decisions we make. That is, \nwe must learn about the structure and dynamics of the increasingly complex sys- \ntems in which we are embedded. \n1 .I -3 Feedback \nMuch of the art of system dynamics modeling is discovering and representing the \nfeedback processes, which, along with stock and flow structures, time delays, and \nnonlinearities, determine the dynamics of a system. You might imagine that there \nis an immense range of different feedback processes and other structures to be \nmastered before one can understand the dynamics of complex systems. In fact, the \nmost complex behaviors usually arise from the interactions (feedbacks) among the \ncomponents of the system, not from the complexity of the components themselves. \nAll dynamics arise from the interaction of just two types of feedback loops, \npositive (or self-reinforcing) and negative (or self-correcting) loops (Figure 1-5). \nPositive loops tend to reinforce or amplify whatever is happening in the system: \nThe more nuclear weapons NATO deployed during the Cold War, the more the So- \nviet Union built, leading NATO to build still more. If a firm lowers its price to gain \nmarket share, its competitors may respond in kind, forcing the firm to lower its \nprice still more. The larger the installed base of Microsoft software and Intel ma- \nchines, the more attractive the “Wintel” architecture became as developers sought \nthe largest market for their software and customers sought systems compatible \nwith the most software; the more Wintel computers sold, the larger the installed \nbase. These positive loops are all processes that generate their own growth, lead- \ning to arms races, price wars, and the phenomenal growth of Microsoft and Intel, \nrespectively. \nNegative loops counteract and oppose change. The less nicotine in a cigarette, \nthe more smokers must consume to get the dose they need. The more attractive a \nneighborhood or city, the greater the inmigration from surrounding areas will be, \nincreasing unemployment, housing prices, crowding in the schools, and traffic \ncongestion until it is no more attractive than other places people might live. The \nhigher the price of a commodity, the lower the demand and the greater the pro- \nduction, leading to inventory accumulation and pressure for lower prices to elimi- \nnate the excess stock. The larger the market share of dominant firms, the more \nlikely is government antitrust action to limit their monopoly power. These loops \nall describe processes that tend to be self-limiting, processes that seek balance and \nequilibrium. \n3Even scientists suffer from these problems. I once heard a distinguished physicist argue that the \nsolution to the energy problem was to build hundreds of huge offshore nuclear power stations, to be \ncooled by seawater. The warm wastewater would be pumped back in the ocean where, he said, \n“The waste heat would disappear.” Out of sight, out of mind. \n","page_start":37,"page_end":37,"token_count":686,"section_type":"other","chapter_number":1,"chapter_title":"Learning in and about Complex Systems","chunk_index":36}
{"chunk_id":"65a69effeb83247f","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"Chapter 1 Learning in and about Complex Systems \n13 \nFIGURE 1-5 \nPositive and negative feedback loops \nPositive feedback: Positive loops are self-reinforcing. \nIn this case, more chickens lay more eggs, which hatch \nand add to the chicken population, leading to still more \neggs, and so on. A Causal Loop Diagram or CLD (chap- \nter 5) captures the feedback dependency of chickens \nand eggs. The arrows indicate the causal relationships. \nThe + signs at the arrowheads indicate that the effect is \npositively related to the cause: an increase in the \nchicken population causes the number of eggs laid each \nday to rise above what it would have been (and vice \nversa: a decrease in the chicken population causes egg \nlaying to fall below what it would have been). The loop is \nself-reinforcing, hence the loop polarity identifier R. If \nthis loop were the only one operating, the chicken and \negg population would both grow exponentially. \nOf course, no real quantity can grow forever. There must \nbe limits to growth. These limits are created by negative \nfeedback. \nNegative feedback: Negative loops are self-correcting. \nThey counteract change. As the chicken population \ngrows, various negative loops will act to balance the \nchicken population with its carrying capacity. One clas- \nsic feedback is shown here: The more chickens, the \nmore road crossings they will attempt. If there is any \ntraffic, more road crossings will lead to fewer chickens \n(hence the negative - polarity for the link from road \ncrossings to chickens). An increase in the chicken popu- \nlation causes more risky road crossings, which then \nbring the chicken population back down. The B in the \ncenter of a loop denotes a balancing feedback. If the \nroad-crossing loop was the only one operating (say be- \ncause the farmer sells all the eggs), the number of \nchickens would gradually decline until none remained. \nAll systems, no matter how complex, consist of net- \nworks of positive and negative feedbacks, and all \ndynamics arise from the interaction of these loops \nwith one another. \nEggs \nChickens \n+u\nA system’s feedback structure \nU \ngenerates its dynamics \nI\nTime \nStructure: n+\nChickens @ cr:Z:gs \n-u\nU I\nBehavior: \nChickens \nTime \n","page_start":38,"page_end":38,"token_count":514,"section_type":"other","chapter_number":1,"chapter_title":"Learning in and about Complex Systems","chunk_index":37}
{"chunk_id":"23f670c5825631d6","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"14 \nPart I Perspective and Process \n1 .I .4 Process Point: The Meaning of Feedback \nIn common parlance the term “feedback” has come to serve as a euphemism for \ncriticizing others, as in “the boss gave me feedback on my presentation.” This use \nof feedback is not what we mean in system dynamics. Further, “positive feedback” \ndoes not mean “praise” and “negative feedback” does not mean “criticism.” Posi- \ntive feedback denotes a self-reinforcing process, and negative feedback denotes a \nself-correcting one. Either type of loop can be good or bad, depending on which \nway it is operating and of course on your values. Reserve the terms positive and \nnegative feedback for self-reinforcing and self-correcting processes, and avoid de- \nscribing the criticism you give or receive to others as feedback. Telling someone \nyour opinion does not constitute feedback unless they act on your suggestions and \nthus lead you to revise your view. \nThough there are only two types of feedback loop, models may easily contain \nthousands of loops, of both types, coupled to one another with multiple time de- \nlays, nonlinearities, and accumulations. The dynamics of all systems arise from the \ninteractions of these networks of feedbacks. Intuition may enable us to infer the \ndynamics of isolated loops such as those shown in Figure 1-5. But when multiple \nloops interact, it is not so easy to determine what the dynamics will be. Before con- \ntinuing, try the challenge shown in Figure 1-6. When intuition fails, we usually \nturn to computer simulation to deduce the behavior of our models. \n1.2 \nLEARNING Is A FEEDBACK PROCESS \nJust as dynamics arise from feedback, so too all learning depends on feedback. We \nmake decisions that alter the real world; we gather information feedback about the \nreal world, and using the new information we revise our understanding of the \nworld and the decisions we make to bring our perception of the state of the system \ncloser to our goals (Figure 1-7). \nThe feedback loop in Figure 1-7 appears in many guises throughout the social \nsciences. George Richardson (1991), in his history of feedback concepts in the \nsocial sciences, shows how beginning in the 1940s leading thinkers in economics, \n","page_start":39,"page_end":39,"token_count":504,"section_type":"other","chapter_number":1,"chapter_title":"Learning in and about Complex Systems","chunk_index":38}
{"chunk_id":"14a51483ca36d65a","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"Chapter 1 Learning in and about Complex Systems \n15 \nFIGURE 1-7 \nLearning is a \nfeedback process. \nFeedback from the \nreal world to the \ndecision maker \nincludes all forms \nof information, \nboth quantitative \nand qualitative. \npsychology, sociology, anthropology, and other fields recognized that the con- \ncept of feedback developed in physics and engineering applied not only to servo- \nmechanisms but to human decision making and social settings as well. By 1961, \nForrester, in Industrial Dynamics, asserted that all decisions (including learning) \ntake place in the context of feedback loops. Later, the psychologist Powers (1973, \np. 351) wrote: \nFeedback is such an all-pervasive and fundamental aspect of behavior that it is as \ninvisible as the air that we breathe. Quite literally it is behavior-we know nothing \nof our own behavior but the feedback effects of our own outputs. \nThese feedback thinkers followed in the footsteps of John Dewey, who recognized \nthe feedback loop character of learning around the beginning of the 20th century \nwhen he described learning as an iterative cycle of invention, observation, reflec- \ntion, and action (Schon 1992). Feedback accounts of behavior and learning have \nnow permeated most of the social and management sciences. Learning as an ex- \nplicit feedback process has even appeared in practical management tools such as \nTotal Quality Management, where the so-called Shewhart-Deming PDCA cycle \n(Plan-Do-Check-Act) lies at the heart of the improvement process in the quality \nimprovement literature (Shewhart 1939; Shiba, Graham, and Walden 1993). \nThe single feedback loop shown in Figure 1-7 describes the most basic type of \nlearning. The loop is a classical negative feedback whereby decision makers com- \npare information about the state of the real world to various goals, perceive dis- \ncrepancies between desired and actual states, and take actions that (they believe) \nwill cause the real world to move towards the desired state. Even if the initial \nchoices of the decision makers do not close the gaps between desired and actual \nstates, the system might eventually reach the desired state as subsequent decisions \nare revised in light of the information received (see Hogarth 1981). When driving, \nI may turn the steering wheel too little to bring the car back to the center of my \nlane, but as visual feedback reveals the error, I continue to turn the wheel until the \ncar returns to the straight and narrow. If the current price for products of my firm \nis too low to balance orders with production, depleted inventories and long deliv- \nery delays may cause me to gradually raise price until I discover a price that clears \nthe market.4 \nI \nt \nInformation \nDecisions uFe\n4Depending on the time delays and other elements of dynamic complexity in the system, these \nexamples may not converge. It takes but little ice, fog, fatigue, or alcohol to cause an accident, and \nequilibrium eludes many industries that experience chronic business cycles. \n","page_start":40,"page_end":40,"token_count":655,"section_type":"other","chapter_number":1,"chapter_title":"Learning in and about Complex Systems","chunk_index":39}
{"chunk_id":"1b31318c0f556822","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"16 \nPart I Perspective and Process \nFIGURE 1-8 \nSingle-loop \nlearning: \ninformation \nfeedback is \ninterpreted by \nexisting mental \nmodels. \nThe learning \nfeedback operates \nin the context of \nexisting decision \nrules, strategies, \nculture, and \ninstitutions which \nin turn are derived \nfrom our mental \nmodels. \nThe feedback loop shown in Figure 1-7 obscures an important aspect of the \nlearning process. Information feedback about the real world is not the only input \nto our decisions. Decisions are the result of applying a decision rule or policy to \ninformation about the world as we perceive it (see Forrester 1961, 1992). The poli- \ncies are themselves conditioned by institutional structures, organizational strate- \ngies, and cultural norms. These, in turn, are governed by our mental models \n(Figure 1-8). As long as the mental models remain unchanged, the feedback loop \nshown in the figure represents what Argyris (1985) calls single-loop learning, a \nprocess whereby we learn to reach our current goals in the context of our existing \nmental models. Single-loop learning does not result in deep change to our mental \nmodels-our understanding of the causal structure of the system, the boundary we \ndraw around the system, the time horizon we consider relevant-nor our goals and \nvalues. Single-loop learning does not alter our worldview. \nMental models are widely discussed in psychology and philosophy. Different \ntheorists describe mental models as collections of routines or standard operating \nprocedures, scripts for selecting possible actions, cognitive maps of a domain, ty- \npologies for categorizing experience, logical structures for the interpretation of \nlanguage, or attributions about individuals we encounter in daily life (Axelrod \n1976; Bower and Morrow 1990; Cheng and Nisbett 1985; Doyle and Ford 1998; \nGentner and Stevens 1983; Halford 1993; Johnson-Laird 1983; Schank and Abel- \nson 1977; Vennix 1990). The concept of the mental model has been central to sys- \ntem dynamics from the beginning of the field. Forrester (1961) stresses that all \ndecisions are based on models, usually mental models. In system dynamics, the \nterm “mental model” includes our beliefs about the networks of causes and effects \nthat describe how a system operates, along with the boundary of the model (which \nvariables are included and which are excluded) and the time horizon we consider \nrelevant-ur framing or articulation of a problem. \nMost of us do not appreciate the ubiquity and invisibility of mental models, \ninstead believing naively that our senses reveal the world as it is. On the contrary, \nI \nDecis ions \nt \nInformation \nFeedback \nStrategy, Structure, \nMental Models \nDecision Rules \nof Real World \nu \n","page_start":41,"page_end":41,"token_count":620,"section_type":"other","chapter_number":2,"chapter_title":"System Dynamics in Action","chunk_index":40}
{"chunk_id":"12020cf3624a4640","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"Chapter 1 Learning in and about Complex Systems \n17 \nFIGURE 1-9 \nKanizsa triangle \nDo you see the \nbright white \ntriangle lying on \ntop of the three \ndark circles and a \nsecond triangle? \nour world is actively constructed (modeled) by our senses and brain. Figure 1-9 \nshows an image developed by psychologist Gaetano Kanizsa. The vast majority of \npeople see a bright white triangle resting on top of three circles and a second tri- \nangle with black edges. The illusion is extremely powerful (try to look at the fig- \nure and “not see” the two triangles!). Research shows that the neural structures \nresponsible for the ability to see illusory contours such as the white triangle exist \nbetween the optic nerve and the areas of the brain responsible for processing visual \ninf~rmation.~ \nActive modeling occurs well before sensory information reaches the \nareas of the brain responsible for conscious thought.6 Powerful evolutionary pres- \nsures are responsible: Our survival depends so completely on the ability to rapidly \ninterpret our environment that we (and other species) long ago evolved structures \nto build these models automatically. Usually we are completely unaware these \nmental models even exist. It is only when a construction such as the Kanizsa tri- \nangle reveals the illusion that we become aware of our mental models. \nThe Kanizsa triangle illustrates the necessity of active and unconscious mental \nmodeling or construction of “reality” at the level of visual perception. Modeling of \nhigher-level knowledge is likewise unavoidable and often equally unconscious. \nFigure 1-10 shows a mental model elicited during a meeting between my colleague \nFred Kofman and a team from a large global corporation. The company worked \nwith the Organizational Learning Center at MIT in the early 1990s to reduce \nthe total cycle time for their supply chain. At that time the cycle time was 182 days \nand they sought to cut it in half. The company viewed reductions in cycle time as \nessential for continued competitiveness and even corporate survival. With the \nG \n%ee Science, 256, (12 June 1992), pp. 1520-1521. \n6Even more obviously, our ability to see a three-dimensional world is the result of extensive \nmodeling by the visual processing system, since the retina images a planar projection of the visual \nfield. \n","page_start":42,"page_end":42,"token_count":503,"section_type":"other","chapter_number":2,"chapter_title":"System Dynamics in Action","chunk_index":41}
{"chunk_id":"966bf1f553418a67","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"18 \nFIGURE 1-10 \nMental model \nrevealed by \na diagram of a \ncompany’s \nsupply chain \nThe figure has \nbeen simplified \ncompared to the \nactual chart to \nprotect company- \nconfidential \ninformation but is \ndrawn to scale. \nPart I Perspective and Process \nCurrent supply chain cycle time, 182 days; \ngoal, 50% reduction. \nManufacturing \nLead Time \nOrder Fulfillment \nLead Time \nCustomer \nAcceptance \nLead Time \nsupport of senior management, they assembled a team to address these issues. \nAt the first meeting the team presented background information, including \nFigure 1-10. \nThe figure shows the current cycle time divided into three intervals along a \nline: manufacturing lead time, order fulfillment lead time, and customer accep- \ntance lead time. Order fulfillment, which then required 22 days, occupies more \nthan half of the total length of the line, while the manufacturing lead time, then re- \nquiring 75 days (70 days due to suppliers), receives about one-fourth of the length. \nCustomer acceptance, then requiring 85 days, occupies only about one-eighth of \nthe total length. What the figure reveals is the prominence of order fulfillment op- \nerations in the mental models of the people on the team and the insignificance in \ntheir minds of suppliers and customers. It will come as no surprise that the mem- \nbers of the team all worked in functions contributing to order fulfillment. There \nwas not a single person at the meeting representing procurement, nor a single sup- \nplier representative, nor anyone from accounting, nor a single customer. Until Fred \npointed out this distortion, the members of the group were as unaware of the illu- \nsory character of their image of the supply line as we normally are of the illusory \ncontours our brains project onto the data transmitted by our optic nerves. The dis- \ntorted mental model of the supply chain significantly constrained the company’s \nability to reduce cycle time: Even if order fulfillment could be accomplished in- \nstantly the organization would fall well short of its goal. \nThe type of reframing stimulated by Fred’s intervention, denoted double-loop \nlearning by Argyris (1985), is illustrated in Figure 1 - 11. Here information feed- \nback about the real world not only alters our decisions within the context of exist- \ning frames and decision rules but also feeds back to alter our mental models. As \nour mental models change we change the structure of our systems, creating differ- \nent decision rules and new strategies. The same information, processed and inter- \npreted by a different decision rule, now yields a different decision. Altering the \nstructure of our systems then alters their patterns of behavior. The development of \nsystems thinking is a double-loop learning process in which we replace a reduc- \ntionist, narrow, short-run, static view of the world with a holistic, broad, long-term, \ndynamic view and then redesign our policies and institutions accordingly. \n","page_start":43,"page_end":43,"token_count":642,"section_type":"other","chapter_number":2,"chapter_title":"System Dynamics in Action","chunk_index":42}
{"chunk_id":"24a9ee4c5c5bdcd2","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"Chapter 1 Learning in and about Complex Systems \n19 \nFIGURE 1-11 \nDouble-loop \nlearning \nFeedback from the \nreal world can also \nstimulate changes \nin mental models. \nSuch learning \ninvolves new \nunderstanding \nor reframing of \na situation and \nleads to new goids \nand new decision \nrules, not just \nnew decisions. \nf \nInformation \nFeedback \nI \nDecisions \nStrategy, ( Structure, \n-( \nMental Models :I \nDecision Rules \nof Real World \nv \n1.3 \nBARRIERS TO LEARNING \nFor learning to occur each link in the two feedback loops shown in Figure 1-11 \nmust work effectively and we must be able to cycle around the loops quickly \nrelative to the rate at which changes in the real world render existing knowledge \nobsolete. Yet in the real world, particularly the world of social action, these feed- \nbacks often do not operate well. More than two and a half centuries elapsed from \nthe first experiments showing that lemon juice could prevent and cure scurvy until \ncitrus use was mandated in the British merchant marine (Table 1-2). Learning in \nthis case was terribly slow, despite the enormous importance of the problem and \nTABLE 1-2 \nTeaching scurvy \ndogs new tricks \nTotal delay \nin learning: \n264 years. \nrn \nrn \nrn \nPrior to the 16OOs, scurvy (vitamin C deficiency) was the greatest killer of \nseafarers-more than battle deaths, storms, accidents, and all others \ncombined. \n1601 : Lancaster conducts a controlled experiment during an East India \nCompany voyage: \nThe crew on one ship received 3 tsp. of lemon juice daily; the crew on three \nother ships did not. \nResults: At the Cape of Good Hope 11 0 out of 278 sailors had died, most \nfrom scurvy. The crew receiving lemon juice remained largely healthy. \n1747: Dr. James Lind conducts a controlled experiment in which scurvy \npatients were treated with a variety of elixirs. Those receiving citrus were \ncured in a few days; none of the other treatments worked. \n1795: The British Royal Navy begins using citrus on a regular basis. Scurvy \nwiped out. \n1865: The British Board of Trade mandates citrus use. Scurvy wiped out in \nthe merchant marine. \n~~ \nSource: Mosteller (1981). \n","page_start":44,"page_end":44,"token_count":526,"section_type":"other","chapter_number":2,"chapter_title":"System Dynamics in Action","chunk_index":43}
{"chunk_id":"49555d4fb24cc16e","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"20 \nSelective perception \nMissing feedback \nDelay \nBias, distortion, error \nAmbiguity \nImplementation failure \nGame playing \nInconsistency \nPerformance is goal \nPart I Perspective and Process \nStrategy, Structure, \nDecision Rules \nfrom mental models \nInability to infer dynamics \nFIGURE 1-12 \nImpediments \nto learning \nthe decisive evidence supplied by controlled experiments throughout the years. \nYou may reply that today we are much smarter and learn faster. Perhaps. Yet the \nrate of corporate and organizational failure remains high (for example, over one- \nthird of the Fortune 500 largest industrial firms in 1970 had disappeared by 1983 \n[de Geus 19971). Today the rate of change in our systems is much faster, and their \ncomplexity is much greater. The delays in learning for many pressing problems \nremain woefully long. In most settings we lack the ability to run experiments, \nand the delays between interventions and outcomes are much longer. As the \nrate of change accelerates throughout society, learning remains slow, uneven, and \ninadequate. \nFigure 1-12 shows the main ways in which each link in the learning feedbacks \ncan fail. These include dynamic complexity, imperfect information about the state \nof the real world, confounding and ambiguous variables, poor scientific reasoning \nskills, defensive routines, and other barriers to effective group processes, imple- \nmentation failure, and the misperceptions of feedback that hinder our ability to un- \nderstand the structure and dynamics of complex systems. \nMental Models \nMisperceptions of feedback \nUnscientific reasoning \nJudgmental biases \nDefensive routines \n","page_start":45,"page_end":45,"token_count":345,"section_type":"other","chapter_number":2,"chapter_title":"System Dynamics in Action","chunk_index":44}
{"chunk_id":"daad77aed78c44f9","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"Chapter 1 Learning in and about Complex Systems \n21 \n1.3.1 \nDynamic Complexity \nMuch of the literature in psychology, economics, and other fields suggests learn- \ning proceeds via the simple negative feedback loops described in Figure 1- 11. Im- \nplicitly, the loops are seen as swift, linear, negative feedbacks that produce stable \nconvergence to an equilibrium or optimal outcome, just as immediate visual feed- \nback allows you to fill a glass of water without spilling. The real world is not so \nsimple. From the beginning, system dynamics emphasized the multiloop, multi- \nstate, nonlinear character of the feedback systems in which we live (Forrester \n1961). The decisions of any one agent form but one of many feedback loops that \noperate in any given system. These loops react to the decision maker’s actions in \nways both anticipated and unanticipated; there may be positive as well as negative \nfeedback loops, and these loops will contain many stocks (state variables) and \nmany nonlinearities. Natural and human systems have high levels of dynamic com- \nplexity. Table 1-3 shows some of the characteristics of systems that give rise to \ndynamic complexity. \nMost people think of complexity in terms of the number of components in a \nsystem or the number of combinations one must consider in making a decision. \nThe problem of optimally scheduling an airline’s flights and crews is highly com- \nplex, but the complexity lies in finding the best solution out of an astronomical \nnumber of possibilities. Such needle-in-a-haystack problems have high levels of \ncombinatorial complexity (also known as detail complexity). Dynamic complex- \nity, in contrast, can arise even in simple systems with low combinatorial complex- \nity. The Beer Distribution Game (Sterman 1989b, chap. 17.4) provides an example: \nComplex and dysfunctional behavior arises from a very simple system whose rules \ncan be explained in 15 minutes. Dynamic complexity arises from the interactions \namong the agents over time. \nTime delays between taking a decision and its effects on the state of the system \nare common and particularly troublesome. Most obviously, delays reduce the num- \nber of times one can cycle around the learning loop, slowing the ability to accu- \nmulate experience, test hypotheses, and improve. Schneiderman (1988) estimated \nthe improvement half life-the time required to cut defects in half-in a wide \nrange of manufacturing firms. He found improvement half lives as short as a few \nmonths for processes with short delays, for example reducing operator error in a \njob shop, while complex processes with long time delays such as product develop- \nment had improvement half lives of several years or more.7 \nDynamic complexity not only slows the learning loop; it also reduces the \nlearning gained on each cycle. In many cases controlled experiments are prohibi- \ntively costly or unethical. More often, it is simply impossible to conduct controlled \nexperiments. Complex systems are in disequilibrium and evolve. Many actions \nyield irreversible consequences. The past cannot be compared well to current cir- ","page_start":46,"page_end":46,"token_count":651,"section_type":"other","chapter_number":2,"chapter_title":"System Dynamics in Action","chunk_index":45}
{"chunk_id":"c5ff88be51640ee2","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"ment had improvement half lives of several years or more.7 \nDynamic complexity not only slows the learning loop; it also reduces the \nlearning gained on each cycle. In many cases controlled experiments are prohibi- \ntively costly or unethical. More often, it is simply impossible to conduct controlled \nexperiments. Complex systems are in disequilibrium and evolve. Many actions \nyield irreversible consequences. The past cannot be compared well to current cir- \ncumstance. The existence of multiple interacting feedbacks means it is difficult to \nhold other aspects of the system constant to isolate the effect of the variable of \ninterest. Many variables change simultaneously, confounding the interpretation \n7Sterman, Repenning, and Kofman (1997) show how these differential improvement rates led to \ndifficulty at a leading semiconductor manufacturer. ","page_start":46,"page_end":46,"token_count":168,"section_type":"other","chapter_number":2,"chapter_title":"System Dynamics in Action","chunk_index":46}
{"chunk_id":"07a023bbfe18887d","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"22 \nPart I Perspective and Process \nTABLE 1-3 \nDynamic \ncomplexity \nDynamic complexity arises because systems are \nDynamic: Heraclitus said, “All is change.” What appears to be unchanging is, over a \nlonger time horizon, seen to vary. Change in systems occurs at many time scales, \nand these different scales sometimes interact. A star evolves over billions of years as \nit burns its hydrogen fuel, then can explode as a supernova in seconds. Bull markets \ncan go on for years, then crash in a matter of hours. \nTightly coupled: The actors in the system interact strongly with one another and \nwith the natural world. Everything is connected to everything else. As a famous \nbumper sticker from the 1960s proclaimed, “You can’t do just one thing.” \nGoverned by feedback: Because of the tight couplings among actors, our actions \nfeed back on themselves. Our decisions alter the state of the world, causing changes \nin nature and triggering others to act, thus giving rise to a new situation which then \ninfluences our next decisions. Dynamics arise from these feedbacks. \nNonlinear: Effect is rarely proportional to cause, and what happens locally in a sys- \nI \ntem (near the current operating point) often does not apply in distant regions (other \nstates of the system). Nonlinearity often arises from the basic physics of systems: In- \nsufficient inventory may cause you to boost production, but production can never fall \nbelow zero no matter how much excess inventory you have. Nonlinearity also arises \nas multiple factors interact in decision making: Pressure from the boss for greater \nachievement increases your motivation and effort-up to the point where you per- \nceive the goal to be impossible. Frustration then dominates motivation and you give \nup or get a new boss. \nHistory-dependent: Taking one road often precludes taking others and determines \nwhere you end up (path dependence). Many actions are irreversible: You can’t un- \nscramble an egg (the second law of thermodynamics). Stocks and flows (accumu- \nlations) and long time delays often mean doing and undoing have fundamentally \ndifferent time constants: During the 50 years of the Cold War arms race the nuclear \nnations generated more than 250 tons of weapons-grade plutonium (239Pu). The half \nlife of 239Pu is about 24,000 years. \nstructure. Often, small, random perturbations are amplified and molded by the feed- \nback structure, generating patterns in space and time and creating path dependence. \nThe pattern of stripes on a zebra, the rhythmic contraction of your heart, the persis- \ntent cycles in the real estate market, and structures such as sea shells and markets \nall emerge spontaneously from the feedbacks among the agents and elements of the \nsystem. \nchange over time. Evolution leads to selection and proliferation of some agents while \nothers become extinct. Adaptation also occurs as people learn from experience, es- \npecially as they learn new ways to achieve their goals in the face of obstacles. Learn- ","page_start":47,"page_end":47,"token_count":648,"section_type":"other","chapter_number":2,"chapter_title":"System Dynamics in Action","chunk_index":47}
{"chunk_id":"83a1948a56f47837","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"tent cycles in the real estate market, and structures such as sea shells and markets \nall emerge spontaneously from the feedbacks among the agents and elements of the \nsystem. \nchange over time. Evolution leads to selection and proliferation of some agents while \nothers become extinct. Adaptation also occurs as people learn from experience, es- \npecially as they learn new ways to achieve their goals in the face of obstacles. Learn- \ning is not always beneficial, however. \nCounterintuitive: In complex systems cause and effect are distant in time and space \nwhile we tend to look for causes near the events we seek to explain. Our attention is \ndrawn to the symptoms of difficulty rather than the underlying cause. High leverage \npolicies are often not obvious. \nwhelms our ability to understand them. The result: Many seemingly obvious solutions \nto problems fail or actually worsen the situation. \nCharacterized by trade-offs: Time delays in feedback channels mean the long-run \nresponse of a system to an intervention is often different from its short-run response. \nHigh leverage policies often cause worse-before-better behavior, while low leverage \npolicies often generate transitory improvement before the problem grows worse. \nSelf-organizing: The dynamics of systems arise spontaneously from their internal \nAdaptive: The capabilities and decision rules of the agents in complex systems \nPolicy resistant: The complexity of the systems in which we are embedded over- ","page_start":47,"page_end":47,"token_count":290,"section_type":"other","chapter_number":2,"chapter_title":"System Dynamics in Action","chunk_index":48}
{"chunk_id":"c251c2a69308acd0","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"Chapter 1 Learning in and about Complex Systems \n23 \nof system behavior and reducing the effectiveness of each cycle around the learn- \ning loop. \nDelays also create instability in dynamic systems. Adding time delays to \nnegative feedback loops increases the tendency for the system to oscillate.8 Sys- \ntems from driving a car, to drinking alcohol, to raising hogs, to construction of \noffice buildings all involve time delays between the initiation of a control action \n(acceleratinghraking, deciding to “have another,” choosing to breed more hogs, \ndeveloping a new building) and its effects on the state of the system. As a result, \ndecision makers often continue to intervene to correct apparent discrepancies \nbetween the desired and actual state of the system even after sufficient corrective \nactions have been taken to restore the system to equilibrium. The result is over- \nshoot and oscillation: stop-and-go traffic, drunkenness, commodity cycles, and real \nestate boom-and-bust cycles (see chapter 17.4). Oscillation and instability reduce \nour ability to control for confounding variables and discern cause and effect, fur- \nther slowing the rate of learning. \n1.3.2 \nLimited Information \nWe experience the real world through filters. No one knows the current sales rate \nof their company, the current rate of production, or the true value of the order back- \nlog at any given time. Instead we receive estimates of these data based on sampled, \naveraged, and delayed measurements. The act of measurement introduces distor- \ntions, delays, biases, errors, and other imperfections, some known, others unknown \nand unknowable. \nAbove all, measurement is an act of selection. Our senses and information sys- \ntems select but a tiny fraction of possible experience. Some of the selection is hard- \nwired (we cannot see in the infrared or hear ultrasound). Some results from our \nown decisions. We define gross domestic product (GDP) so that extraction of non- \nrenewable resources counts as production rather than depletion of natural capital \nstocks and so that medical care and funeral expenses caused by pollution-induced \ndisease add to the GDP while the production of the pollution itself does not reduce \nit. Because the prices of most goods in our economic system do not include the \ncosts of resource depletion or environmental degradation, these externalities re- \nceive little weight in decision making (see Cobb and Daly 1989 for thoughtful dis- \ncussion of alternative measures of economic welfare). \nOf course, the information systems governing the feedback we receive can \nchange as we learn. They are part of the feedback structure of our systems. \nThrough our mental models we define constructs such as GDP or scientific re- \nsearch, create metrics for these ideas, and design information systems to evaluate \nand report them. These then condition the perceptions we form. Changes in our \nmental models are constrained by what we previously chose to define, measure, \n8Technically, negative loops with no time delays are first-order; the eigenvalue of the linearized ","page_start":48,"page_end":48,"token_count":638,"section_type":"other","chapter_number":2,"chapter_title":"System Dynamics in Action","chunk_index":49}
{"chunk_id":"6e345dc51d765ae3","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"change as we learn. They are part of the feedback structure of our systems. \nThrough our mental models we define constructs such as GDP or scientific re- \nsearch, create metrics for these ideas, and design information systems to evaluate \nand report them. These then condition the perceptions we form. Changes in our \nmental models are constrained by what we previously chose to define, measure, \n8Technically, negative loops with no time delays are first-order; the eigenvalue of the linearized \nsystem can only be real and oscillation is impossible. Adding delays (state variables) allows the \neigenvalues to become complex conjugates, yielding oscillatory solutions. Whether the oscillations \nof the linearized system are damped or expanding depends on the parameters. All else equal, the \nmore phase lag in a control loop, the less stable the system will be. ","page_start":48,"page_end":48,"token_count":177,"section_type":"other","chapter_number":2,"chapter_title":"System Dynamics in Action","chunk_index":50}
{"chunk_id":"d5560868e9cf063a","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"24 \nPart I Perspective and Process \nand attend to. Seeing is believing and believing is seeing. They feed back on one \nanother. \nIn a famous experiment, Bruner and Postman (1949) showed playing cards to \npeople using a tachistoscope to control exposure time to the stimuli. Most could \nidentify the cards rapidly and accurately. They also included some anomalous \ncards, such as a black three of hearts or a red ten of spades. People took on average \nfour times as long to judge the anomalous cards. Many misidentified them \n(e.g., they said three of spades or three of hearts when shown a black three of \nhearts). Some could not identify the card at all, even with very long exposure \ntimes, and grew anxious and confused. Only a small minority correctly identified \nthe cards. Bruner and Postman concluded, “Perceptual organization is powerfully \ndetermined by expectations built upon past commerce with the environment.” \nHenri Bergson put it more succinctly: “The eye sees only what the mind is pre- \npared to comprehend.” \nThe self-reinforcing feedback between expectations and perceptions has been \nrepeatedly demonstrated in a wide variety of experimental studies (see Plous 1993 \nfor excellent discussion). Sometimes the positive feedback assists learning by \nsharpening our ability to perceive features of the environment, as when an experi- \nenced naturalist identifies a bird in a distant bush where the novice birder sees only \na tangled thicket. Often, however, the mutual feedback of expectations and per- \nception limits learning by blinding us to the anomalies that might challenge our \nmental models. Thomas Kuhn (1970) cited the Bruner-Postman study to argue that \na scientific paradigm suppresses the perception of data inconsistent with the para- \ndigm, makmg it hard for scientists to perceive anomalies that might lead to scien- \ntific revol~tion.~ \nAs one of many examples, the history of ozone depletion by chlorofluoro- \ncarbons (CFCs) shows the mutual dependence of expectation and perception is no \nlaboratory artifact but a phenomenon with potentially grave consequences for \nhumanity. \nThe first scientific papers describing the ability of CFCs to destroy atmos- \npheric ozone were published in 1974 (Molina and Rowland 1974; Stolarski and \nCicerone 1974). Yet much of the scientific community remained skeptical, and \ndespite a ban on CFCs as aerosol propellants, global production of CFCs remained \nnear its all time high. It was not until 1985 that evidence of a deep ozone hole in \nthe Antarctic was published (Farman, Gardiner, and Shanklin 1985). As described \nby Meadows, Meadows, and Randers (1992, pp. 151-152): \nThe news reverberated around the scientific world. Scientists at [NASA] . . . scram- \nbled to check readings on atmospheric ozone made by the Nimbus 7 satellite, mea- ","page_start":49,"page_end":49,"token_count":646,"section_type":"other","chapter_number":2,"chapter_title":"System Dynamics in Action","chunk_index":51}
{"chunk_id":"6a36125d76928972","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"the Antarctic was published (Farman, Gardiner, and Shanklin 1985). As described \nby Meadows, Meadows, and Randers (1992, pp. 151-152): \nThe news reverberated around the scientific world. Scientists at [NASA] . . . scram- \nbled to check readings on atmospheric ozone made by the Nimbus 7 satellite, mea- \nsurements that had been taken routinely since 1978. Nimbus 7 had never indicated \nan ozone hole. \n9Sterman (1985a) developed a formal model of Kuhn’s theory, which showed that the positive \nfeedback between expectations and perceptions suppressed the recognition of anomalies and the \nemergence of new paradigms. Sterman and Wittenberg (1999) extended the model to simulate \nthe competition among rival theories. ","page_start":49,"page_end":49,"token_count":174,"section_type":"other","chapter_number":2,"chapter_title":"System Dynamics in Action","chunk_index":52}
{"chunk_id":"c49534ecf360e5a1","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"Chapter 1 Learning in and about Complex Systems \n25 \nChecking back, NASA scientists found that their computers had been pro- \ngrammed to reject very low ozone readings on the assumption that such low \nreadings must indicate instrument error. \nThe NASA scientists’ belief that low ozone readings must be erroneous led them \nto design a measurement system that made it impossible to detect low readings that \nmight have shown their belief to be wrong. Fortunately, NASA had saved the orig- \ninal, unfiltered data and later confirmed that ozone concentrations had indeed been \nfalling since the launch of Nimbus 7. Because NASA created a measurement sys- \ntem immune to disconfirmation the discovery of the ozone hole and resulting \nglobal agreements to cease CFC production were delayed by as much as 7 years. \nThose 7 years could be significant: ozone levels in Antarctica dropped to less than \none-third of normal in 1993, and current models show that even with full compli- \nance with the ban (there is a thriving black market in CFCs), atmospheric chlorine \nwill not begin to fall until the first decade of the 21st century, and then only slowly. \nData collected near Toronto in the early 1990s showed a 5% increase in cancer- \ncausing UV-B ultraviolet radiation at ground level, indicating that ozone depletion \nalready affects the heavily populated and agriculturally vital northern hemisphere \n(Culotta and Koshland 1993). The thinning of the ozone layer is a global phenom- \nenon, not just a problem for penguins. \n1.3.3 \nConfounding Variables and Ambiguity \nTo learn we must use the limited and imperfect information available to us to un- \nderstand the effects of our own decisions, so we can adjust our decisions to align \nthe state of the system with our goals (single-loop learning) and so we can revise \nour mental models and redesign the system itself (double-loop learning). Yet much \nof the information we receive is ambiguous. Ambiguity arises because changes in \nthe state of the system resulting from our own decisions are confounded with si- \nmultaneous changes in a host of other variables. The number of variables that \nmight affect the system vastly overwhelms the data available to rule out alternative \ntheories and competing interpretations. This identification problem plagues both \nqualitative and quantitative approaches. In the qualitative realm, ambiguity arises \nfrom the ability of language to support multiple meanings. In the opening solilo- \nquy of Richard ZZZ, the hump-backed Richard laments his deformity: \nAnd therefore, since I cannot prove a lover \nTo entertain these fair well-spoken days, \nI am determinbd to prove a villain \nAnd hate the idle pleasures of these days. \n(I, i, 28-31) \nDoes Richard celebrate his free choice to be evil or resign himself to a predestined \nfate? Did Shakespeare intend the double meaning? Rich, ambiguous texts, with \nmultiple layers of meaning often make for beautiful and profound art, along with \nemployment for literary critics, but also make it hard to know the minds of others, \nrule out competing hypotheses, and evaluate the impact of our past actions so we \ncan decide how to act in the future. \n","page_start":50,"page_end":50,"token_count":681,"section_type":"other","chapter_number":2,"chapter_title":"System Dynamics in Action","chunk_index":53}
{"chunk_id":"2cb184c06be3ba96","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"26 \nPart I Perspective and Process \nIn the quantitative realm, engineers and econometricians have long struggled \nwith the problem of uniquely identifying the structure and parameters of a system \nfrom its observed behavior. Elegant and sophisticated theory exists to delimit the \nconditions in which one can identify a system from its behavior alone. In practice \nthe data are too scarce and the plausible alternative specifications are too numer- \nous for statistical methods to discriminate among competing theories. The same \ndata often support wildly divergent models equally well, and conclusions based on \nsuch models are not robust. As Learner (1983) put it in an article entitled “Let’s \nTake the ‘Con’ Out of Econometrics”: \nIn order to draw inferences from data as described by econometric texts, it is neces- \nsary to make whimsical assumptions . . . The haphazard way we individually and \ncollectively study the fragility of inferences leaves most of us unconvinced that any \ninference is believable.’O \n1.3.4 \nBounded Rationality and the Misperceptions \nof Feedback \nDynamic complexity and limited information reduce the potential for learning and \nperformance by limiting our knowledge of the real world. But how wisely do we \nuse the knowledge we do have? Do we process the information we do get in the \nbest way and make the best decisions we can? Unfortunately, the answer is no. \nHumans are not only rational beings, coolly weighing the possibilities and \njudging the probabilities. Emotions, reflex, unconscious motivations, and other \nnonrational or irrational factors all play a large role in our judgments and behavior. \nBut even when we find the time to reflect and deliberate we cannot behave in a \nfully rational manner (that is, make the best decisions possible given the informa- \ntion available to us). As marvelous as the human mind is, the complexity of the real \nworld dwarfs our cognitive capabilities. Herbert Simon has best articulated the \nlimits on human decision-making ability in his famous “principle of bounded ra- \ntionality,” for which he won the Nobel Memorial Prize in economics in 1979: \nThe capacity of the human mind for formulating and solving complex problems is \nvery small compared with the size of the problem whose solution is required for ob- \njectively rational behavior in the real world or even for a reasonable approximation \nto such objective rationality. (Simon 1957, p. 198) \nFaced with the overwhelming complexity of the real world, time pressure, and lim- \nited cognitive capabilities, we are forced to fall back on rote procedures, habits, \nrules of thumb, and simple mental models to make decisions. Though we some- \ntimes strive to make the best decisions we can, bounded rationality means we of- \nten systematically fall short, limiting our ability to learn from experience. \nWhile bounded rationality affects all decision contexts, it is particularly acute \nin dynamic systems. Indeed, experimental studies show that people do quite poorly \nl0I am not arguing that econometrics should be abandoned, despite its difficulties. On the con- \ntrary, wise use of numerical data and statistical estimation is central to good system dynamics prac- \ntice, and more effort should be devoted to the use of these tools in simulation model development \nand testing. See chap. 2 1. \n","page_start":51,"page_end":51,"token_count":697,"section_type":"other","chapter_number":2,"chapter_title":"System Dynamics in Action","chunk_index":54}
{"chunk_id":"52f6c87b32797ff5","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"Chapter 1 Learning in and about Complex Systems \n27 \nTABLE 1-4 \nMisperceptions \nof feedback \nhave been \ndocumented \nin many \nexperimental \nstudies. \nin systems with even modest levels of dynamic complexity (Table 1-4). These \nstudies led me to suggest that the observed dysfunction in dynamically complex \nsettings arises from misperceptions offeedback. The mental models people use \nto guide their decisions are dynamically deficient. As discussed above, people \ngenerally adopt an event-based, open-loop view of causality, ignore feedback \nprocesses, fail to appreciate time delays between action and response and in the \nreporting of information, do not understand stocks and flows and are insensitive to \nnonlinearities that may alter the strengths of different feedback loops as a system \nevolves. \nSubsequent experiments show that the greater the dynamic complexity of the \nenvironment the worse people do relative to potential. Further, the experiments \nshow the misperceptions of feedback are robust to experience, financial incentives, \nexperience, and the presence of market institutions (see, e.g., Diehl and Sterman \n1993; Paich and Sterman 1993; Kampmann and Sterman 1998). \nThe robustness of the misperceptions of feedback and the poor performance \nthey cause are due to two basic and related deficiencies in our mental model. First, \nour cognitive maps of the causal structure of systems are vastly simplified com- \npared to the complexity of the systems themselves. Second, we are unable to infer \ncorrectly the dynamics of all but the simplest causal maps. Both are direct conse- \nquences of bounded rationality, that is, the many limitations of attention, memory, \nrecall, information processing capability, and time that constrain human decision \nmaking. \ne \ne \ne \ne \nIn a simple production-distribution system (the Beer Distribution Game), \npeople, from high school students to CEOs, generate costly fluctuations \n(business cycles). Average costs were more than 10 times greater than \noptimal (Sterman 1989b). \nSubjects responsible for capital investment in a simple multiplier-accelerator \nmodel of the economy generate large amplitude cycles even though con- \nsumer demand is constant. Average costs were more than 30 times greater \nthan optimal (Sterman 1989a). \nSubjects managing a firm in a simulated consumer product market generate \nthe boom and bust, price war, and shake-out characteristic of industries from \nvideo games to chain saws (Paich and Sterman 1993). \nParticipants in experimental asset markets repeatedly bid prices well above \nfundamental value, only to see them plummet when a “greater fool” can no \nlonger be found to buy. These speculative bubbles do not disappear when \nthe participants are investment professionals, when monetary incentives are \nprovided, or when short-selling is allowed (Smith, Suchanek, and Williams \n1988). \nIn a forest fire simulation, many people allow their headquarters to burn \ndown despite their best efforts to put out the fire (Brehmer 1989). \nIn a medical setting, subjects playing the role of doctors order more tests \nwhile the (simulated) patients sicken and die (Kleinmuntz and Thomas \n1987). \n","page_start":52,"page_end":52,"token_count":680,"section_type":"other","chapter_number":2,"chapter_title":"System Dynamics in Action","chunk_index":55}
{"chunk_id":"69c91275cba31250","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"28 \nPart I Perspective and Process \n1.3.5 \nFlawed Cognitive Maps \nCausal attributions are a central feature of mental models. We all create and update \ncognitive maps of causal connections among entities and actors, from the pro- \nsaic-if I touch a flame I will be burned-to the grand-the larger the government \ndeficit, the higher interest rates will be. Studies of cognitive maps show that few \nincorporate any feedback loops. Axelrod (1976) found virtually no feedback \nprocesses in studies of the cognitive maps of political leaders; rather, people tended \nto formulate intuitive decision trees relating possible actions to probable conse- \nquences-an event-level representation. Hall (1976) reports similar open-loop \nmental maps in a study of the publishing industry. Dorner (1980, 1996) found that \npeople tend to think in single strand causal series and had difficulty in systems with \nside effects and multiple causal pathways (much less feedback loops). Similarly, \nexperiments in causal attribution show people tend to assume each effect has a sin- \ngle cause and often cease their search for explanations when the first sufficient \ncause is found (see the discussion in PIOUS 1993). \nThe heuristics we use to judge causal relations lead systematically to cognitive \nmaps that ignore feedbacks, multiple interconnections, nonlinearities, time delays, \nand the other elements of dynamic complexity. The causal field or mental model of \nthe stage on which the action occurs is crucial in framing people’s judgments of \ncausation (Einhorn and Hogarth 1986). Within a causal field, people use various \ncues to causality including temporal and spatial proximity of cause and effect, tem- \nporal precedence of causes, covariation, and similarity of cause and effect. These \nheuristics lead to difficulty in complex systems where cause and effect are often \ndistant in time and space, where actions have multiple effects, and where the de- \nlayed and distant consequences are different from and less salient than proximate \neffects (or simply unknown). The multiple feedbacks in complex systems cause \nmany variables to be correlated with one another, confounding the task of judging \ncause. However, people are poor judges of correlation. Experiments show people \ncan generally detect linear, positive correlations among variables if they are given \nenough trials and if the outcome feedback is accurate enough. However, we have \ngreat difficulty in the presence of random error, nonlinearity, and negative correla- \ntions, often never discovering the true relationship (Brehmer 1980). \nA fundamental principle of system dynamics states that the structure of the \nsystem gives rise to its behavior. However, people have a strong tendency to at- \ntribute the behavior of others to dispositional rather than situational factors, that is, \nto character and especially character flaws rather than the system in which these \npeople are acting. The tendency to blame the person rather than the system is so \nstrong psychologists call it the “fundamental attribution error” (Ross 1977). In \ncomplex systems different people placed in the same structure tend to behave in ","page_start":53,"page_end":53,"token_count":658,"section_type":"other","chapter_number":2,"chapter_title":"System Dynamics in Action","chunk_index":56}
{"chunk_id":"6fed58d3b632f221","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"system gives rise to its behavior. However, people have a strong tendency to at- \ntribute the behavior of others to dispositional rather than situational factors, that is, \nto character and especially character flaws rather than the system in which these \npeople are acting. The tendency to blame the person rather than the system is so \nstrong psychologists call it the “fundamental attribution error” (Ross 1977). In \ncomplex systems different people placed in the same structure tend to behave in \nsimilar ways. When we attribute behavior to personality we lose sight of how the \nstructure of the system shaped our choices. The attribution of behavior to individ- \nuals and special circumstances rather than system structure diverts our attention \nfrom the high leverage points where redesigning the system or governing policy \ncan have significant, sustained, beneficial effects on performance (Forrester 1969, \nchap. 6; Meadows 1982). When we attribute behavior to people rather than system \nstructure the focus of management becomes scapegoating and blame rather than ","page_start":53,"page_end":53,"token_count":213,"section_type":"other","chapter_number":2,"chapter_title":"System Dynamics in Action","chunk_index":57}
{"chunk_id":"0e9ac2086b9e7569","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"Chapter 1 Learning in and about Complex Systems \n29 \nthe design of organizations in which ordinary people can achieve extraordinary \nresults. l1 \n1.3.6 \nErroneous Inferences about Dynamics \nEven if our cognitive maps of causal structure were perfect, learning, especially \ndouble-loop learning, would still be difficult. To use a mental model to design a \nnew strategy or organization we must make inferences about the consequences of \ndecision rules that have never been tried and for which we have no data. To do so \nrequires intuitive solution of high-order nonlinear differential equations, a task far \nexceeding human cognitive capabilities in all but the simplest systems (Forrester \n1971a; Simon 1982). In many experimental studies, including Diehl and Sterman \n(1995) and Sterman (1989a), the participants were given complete knowledge of \nall structural relationships and parameters, along with perfect, comprehensive, and \nimmediate knowledge of all variables. Further, the systems were simple enough \nthat the number of variables to consider was small. Yet performance was poor and \nlearning was slow. Poor performance in these tasks is due to our inability to make \nreasonable inferences about the dynamics of the system despite perfect and com- \nplete knowledge of the system structure. \nPeople cannot simulate mentally even the simplest possible feedback system, \nthe first-order linear positive feedback 10op.l~ Such positive feedback processes are \ncommonplace, from the compounding of interest to the growth of populations. \nWagenaar and Sagaria (1975) and Wagenaar and Timmers (1978, 1979) showed \nthat people significantly underestimate exponential growth, tending to extrapolate \nlinearly rather than exponentially. Using more data points or graphing the data did \nnot help, and mathematical training did not improve performance. \nBounded rationality simultaneously constrains the complexity of our cognitive \nmaps and our ability to use them to anticipate the system dynamics. Mental mod- \nels in which the world is seen as a sequence of events and in which feedback, non- \nlinearity, time delays, and multiple consequences are lacking lead to poor \nperformance when these elements of dynamic complexity are present. Dysfunction \nin complex systems can arise from the misperception of the feedback structure of \nthe environment. But rich mental models that capture these sources of complexity \ncannot be used reliably to understand the dynamics. Dysfunction in complex sys- \ntems can arise from faulty mental simulation-the misperception of feedback \ndynamics. These two different bounds on rationality must both be overcome for \neffective learning to occur. Perfect mental models without a simulation capability \nyield little insight; a calculus for reliable inferences about dynamics yields sys- \ntematically erroneous results when applied to simplistic models. \n\"Repenning and Sterman (1999) show how the fundamental attribution error arose in a \nmajor manufacturing organization, thwarting their efforts to improve operations and product \ndevelopment. \nyields pure exponential growth, x = x,exp(gt); see chap. 8. \n12The first-order linear positive loop is represented by the differential equation dddt = gx and \n","page_start":54,"page_end":54,"token_count":651,"section_type":"other","chapter_number":2,"chapter_title":"System Dynamics in Action","chunk_index":58}
{"chunk_id":"da091c87ab495a35","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"30 \nPart I Perspective and Process \n1.3.7 \nUnscientific Reasoning: \nJudgmental Errors and Biases \nTo learn effectively in a world of dynamic complexity and imperfect information \npeople must develop what Davis and Hogarth (1992) call “insight skills”-the \nskills that help people learn when feedback is ambiguous: \n[Tlhe interpretation of feedback . . . needs to be an active and disciplined task gov- \nerned by the rigorous rules of scientific inference. Beliefs must be actively chal- \nlenged by seeking possible disconfirming evidence and asking whether alternative \nbeliefs could not account for the facts (emphasis in original). \nUnfortunately, people are poor intuitive scientists, generally failing to reason in ac- \ncordance with the principles of scientific method. For example, people do not gen- \nerate sufficient alternative explanations or consider enough rival hypotheses. \nPeople generally do not adequately control for confounding variables when they \nexplore a novel environment. People’s judgments are strongly affected by the \nframe in which the information is presented, even when the objective information \nis unchanged. People suffer from overconfidence in their judgments (under- \nestimating uncertainty), wishful thinking (assessing desired outcomes as more \nlikely than undesired outcomes), and the illusion of control (believing one can pre- \ndict or influence the outcome of random events). People violate basic rules of \nprobability, do not understand basic statistical concepts such as regression to the \nmean, and do not update beliefs according to Bayes’ rule. Memory is distorted by \nhindsight, the availability and salience of examples, and the desirability of out- \ncomes. And so on. Hogarth (1987) discusses 30 different biases and errors docu- \nmented in decision-making research and provides a good guide to the literature \n(see also Kahneman, Slovic, and Tversky 1982). The research convincingly shows \nthat scientists and professionals, not only “ordinary” people, suffer from many of \nthese judgmental biases. \nAmong the failures of scientific reasoning most inimical to learning is the ten- \ndency to seek evidence consistent with current beliefs rather than potential discon- \nfirmation (Einhorn and Hogarth 1978; Klayman and Ha 1987). In a famous series \nof experiments, Wason and colleagues presented people tasks of the sort shown in \nFigure 1-13.13 Before continuing, try the challenge shown in the figure. \n13The summary of the Wason test is drawn from PIOUS (1993, chap. 20). \n","page_start":55,"page_end":55,"token_count":547,"section_type":"other","chapter_number":2,"chapter_title":"System Dynamics in Action","chunk_index":59}
{"chunk_id":"7d21a860d89d49e1","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"Chapter 1 Learning in and about Complex Systems \n31 \nIn one version you are shown one side of four cards, each with a letter on one \nside and a number on the other, say E, K, 4, and 7. You are told that if a card has a \nvowel on it, then it has an even number on the other side. You must then identify \nthe smallest set of cards to turn over to see if the proposed rule is correct. \nWason and Johnson-Laird (1972) found that the vast majority of subjects se- \nlected E or E and 4 as the answers. Less than 4% gave the correct answer: E and 7. \nThe rule has the logical form ifp, then q. Falsification requires observation of \np and not-q. The only card showing p is the E card, so it must be examined (the \nback of the E card must be an even number for the rule to hold). The only card \nshowing not-q is the 7, so it too must be examined. The K and 4 cards are irrele- \nvant. Yet people consistently choose the card showing q, a choice that can only \nprovide data consistent with the theory, but cannot test it; if the back of the 4 is a \nconsonant, you have learned nothing, since the rule is silent about the numbers as- \nsociated with consonants. Experiments show the tendency to seek confirmation is \nrobust in the face of training in logic, mathematics, and statistics. Search strategies \nthat focus only on confirmation of current beliefs slow the generation and recogni- \ntion of anomalies that might lead to learning, particularly double-loop learning. \nSome argue that while people err in applying the principles of logic, at least \npeople are rational in the sense that they appreciate the desirability of scientific ex- \nplanation. Unfortunately, the situation is far worse. The rational, scientific world- \nview is a recent development in human history and remains rare. Many people \nplace their faith in what Dostoyevsky’s Grand Inquisitor called “miracle, mystery, \nand authority,” for example, astrology, ESP, UFOs, creationism, conspiracy theo- \nries of history, channeling of past lives, cult leaders promising Armageddon, and \nElvis sightings. The persistence of such superstitious beliefs depends partly on the \nbias towards confirming evidence. Wade Boggs, former Boston Red Sox batting \nchampion, ate chicken every day for years because he once had a particularly good \nday at the plate after a dinner of lemon chicken (Shaughnessy 1987). During this \ntime Boggs won five batting championships, proving the wisdom of the “chicken \ntheory.” Consider the continued popularity of astrology, psychics, and economic \nforecasters, who publicize their successes and suppress their (more numerous) \nfailures. Remember that the 40th president of the United States and first lady man- \naged affairs of state on the basis of astrology (Robinson 1988). And it worked: He \nwas reelected in a landslide. ","page_start":56,"page_end":56,"token_count":661,"section_type":"other","chapter_number":2,"chapter_title":"System Dynamics in Action","chunk_index":60}
{"chunk_id":"cf25f4a68c0f85ff","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"time Boggs won five batting championships, proving the wisdom of the “chicken \ntheory.” Consider the continued popularity of astrology, psychics, and economic \nforecasters, who publicize their successes and suppress their (more numerous) \nfailures. Remember that the 40th president of the United States and first lady man- \naged affairs of state on the basis of astrology (Robinson 1988). And it worked: He \nwas reelected in a landslide. \nSuch lunacy aside, there are deeper and more disturbing reasons for the preva- \nlence of these learning failures and the superstitions they engender. Human beings \nare more than cognitive information processors. We have a deep need for emo- \ntional and spiritual sustenance. But from Copernican heliocentrism through evolu- \ntion, relativity, quantum mechanics, and Godelian uncertainty, science has stripped \naway ancient and comforting beliefs placing humanity at the center of a rational \nuniverse designed for us by a supreme authority. For many people scientific \nthought leads not to enlightenment and empowerment but to existential angst and \nthe absurdity of human insignificance in an incomprehensibly vast universe. \nOthers believe science and technology were the shock troops for the triumph of \nmaterialism and instrumentalism over the sacred and spiritual. These antiscientific \nreactions are powerful forces. In many ways they are important truths. They have \nled to many of the most profound works of art and literature. But they can also lead \nto mindless new-age psychobabble. ","page_start":56,"page_end":56,"token_count":324,"section_type":"other","chapter_number":2,"chapter_title":"System Dynamics in Action","chunk_index":61}
{"chunk_id":"68a193b308f903d4","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"32 \nPart I Perspective and Process \nThe reader should not conclude from this discussion that I am a naive defender \nof science as it is practiced nor an apologist for the real and continuing damage \ndone to the environment and to our cultural, moral, and spiritual lives in the name \nof rationality and progress. On the contrary, I have stressed the research showing \nthat scientists are often as prone to the judgmental errors and biases discussed \nabove as laypeople. It is precisely because scientists are subject to the same cog- \nnitive limitations and moral failures as others that we experience abominations \nsuch as the US government funded research in which plutonium was injected into \nseriously ill patients, and in which radioactive calcium was fed to retarded chil- \ndren, all without their knowledge or consent (Mann 1994). A central principle of \nsystem dynamics is to examine issues from multiple perspectives; to expand the \nboundaries of our mental models to consider the long-term con.sequences and “side \neffects” of our actions, including their environmental, cultural, and moral implica- \ntions (Meadows, Richardson, and Bruckmann 1982). \n1.3.8 \nDefensive Routines and Interpersonal \nImpediments to Learning \nLearning by groups, whether system dynamics is used or not, can be thwarted even \nif participants receive excellent information feedback and reason well as individu- \nals. We rely on our mental models to interpret the language and acts of others, con- \nstruct meaning, and infer motives. However, as Forrester (1971) argues, \nThe mental model is fuzzy. It is incomplete. It is imprecisely stated. Furthermore, \nwithin one individual, a mental model changes with time and even during the flow \nof a single conversation. The human mind assembles a few relationships to fit the \ncontext of a discussion. As the subject shifts so does the model . . . [Elach partici- \npant in a conversation employs a different mental model to interpret the subject. \nFundamental assumptions differ but are never brought into the open. \nArgyris (1985), Argyris and Schon (1978), Janis (1982), Schein (1969, 1985, \n1987), and others document the defensive routines and cultural assumptions peo- \nple rely on, often unknowingly, to interact with and interpret their experience of \nothers. We use defensive routines to save face, assert dominance over others, make \nuntested inferences seem like facts, and advocate our positions while appearing to \nbe neutral. We make conflicting, unstated attributions about the data we receive. \nWe fail to distinguish between the sense-data of experience and the attributions and \ngeneralizations we readily form from them. We avoid publicly testing our hy- \npotheses and beliefs and avoid threatening issues. Above all, defensive behavior \ninvolves covering up the defensiveness and making these issues undiscussable, \neven when all parties are aware they exist. \nDefensive routines are subtle. They often arrive cloaked in apparent concern ","page_start":57,"page_end":57,"token_count":652,"section_type":"other","chapter_number":2,"chapter_title":"System Dynamics in Action","chunk_index":62}
{"chunk_id":"096927c269cd9558","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"We fail to distinguish between the sense-data of experience and the attributions and \ngeneralizations we readily form from them. We avoid publicly testing our hy- \npotheses and beliefs and avoid threatening issues. Above all, defensive behavior \ninvolves covering up the defensiveness and making these issues undiscussable, \neven when all parties are aware they exist. \nDefensive routines are subtle. They often arrive cloaked in apparent concern \nand respect for others. Consider the strategy called “easing-in:” \nIf you are about to criticize someone who might become defensive and you want \nhim to see the point without undue resistance, do not state the criticism openly; in- \nstead, ask questions such that if he answers them correctly, he will figure out what \nyou are not saying (Argyris, Putnam, and Smith 1985, p. 83). ","page_start":57,"page_end":57,"token_count":183,"section_type":"other","chapter_number":2,"chapter_title":"System Dynamics in Action","chunk_index":63}
{"chunk_id":"77e347a4c4825d37","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"Chapter 1 Learning in and about Complex Systems \n33 \nBut easing-in often \nCreates the very defensiveness that it is intended to avoid, because the recipient \ntypically understands that the actor is easing-in. Indeed, easing-in can be successful \nonly if the recipient understands that he is supposed to answer the questions in a \nparticular way, and this entails the understanding that the actor is negatively evalu- \nating the recipient and acting as if this were not the case (Argyris, Putnam, and \nSmith 1985, p. 85). \nDefensive behavior, in which the espoused theories we offer to others differ from \nour theories in use, prevents learning by hiding important information from others, \navoiding public testing of important hypotheses, and tacitly communicating that \nwe are not open to having our mental models challenged. Defensive routines often \nyield groupthink (Janis 1982), where members of a group mutually reinforce their \ncurrent beliefs, suppress dissent, and seal themselves off from those with different \nviews or possible disconfirming evidence. Defensive routines ensure that the men- \ntal models of team members remain ill formed, ambiguous, and hidden. Thus \nlearning by groups can suffer even beyond the impediments to individual learning. \n1.3.9 Implementation Failure \nIn the real world decisions are often implemented imperfectly, further hindering \nlearning. Even if a team agreed on the proper course of action, the implementation \nof these decisions can be delayed and distorted as the actual organization responds. \nLocal incentives, asymmetric information, and private agendas can lead to game \nplaying by agents throughout a system. Obviously implementation failures can \nhurt the organization. Imperfect implementation can defeat the learning process as \nwell, because the management team evaluating the outcomes of their decisions \nmay not know the ways in which the decisions they thought they were implement- \ning were distorted. \nFinally, in the real world of irreversible actions and high stakes the need to \nmaintain performance often overrides the need to learn by suppressing new strate- \ngies for fear they would cause present harm even though they might yield great in- \nsight and prevent future harm. \nREQUIREMENTS FOR SUCCESSFUL LEARNING IN \nCOMPLEX SYSTEMS \nWe face grave impediments to learning in complex systems like a nation, firm, or \nfamily. Every link in the feedback loops by which we might learn can be weakened \nor cut by a variety of structures. Some of these are physical or institutional features \nof the environment-the elements of dynamic complexity that reduce opportuni- \nties for controlled experimentation, prevent us from learning the consequences of \nour actions, and distort the outcome feedback we do receive. Some are conse- \nquences of our culture, group process, and inquiry skills. Still others are funda- \nmental bounds on human cognition, particularly the poor quality of our mental \nmaps and our inability to make correct inferences about the dynamics of complex \nnonlinear systems. \n","page_start":58,"page_end":58,"token_count":611,"section_type":"other","chapter_number":2,"chapter_title":"System Dynamics in Action","chunk_index":64}
{"chunk_id":"96d96fe77a1193ea","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"34 \nDecision Rules \nSimulation used to infer \ndynamics of mental \nPart I Perspective and Process \nMapping of feedback structure \nDisciplined application of \nscientific reasoning \nDiscussability of group \nFIGURE 1-14 \nIdealized learning \nprocess \nEffective learning \ninvolves \ncontinuous \nexperimentation \nin both the virtual \nworld and real \nworld. Feedback \nfrom both informs \nthe development \nof mental \nmodels, formal \nmodels, and \nthe design of \nexperiments for \nthe next iteration. \n1.4.1 \nImproving the Learning Process: \nVirtues of Virtual Worlds \nWhat then are the requirements for successful learning in complex systems? If we \nare to create useful protocols and tools for learning effectively in a world of dy- \nnamic complexity we must attend to all of the impediments to learning. Figure \n1-14 shows how the learning feedbacks would operate when all the impediments \nto learning are addressed. The diagram features a new feedback loop created by the \nuse of virtual worlds. Virtual worlds (the term is Schon’s [ 19831) are formal mod- \nels, simulations, or “microworlds” (Papert 1980), in which decision makers can re- \nfresh decision-making skills, conduct experiments, and play. They can be physical \nmodels, role plays, or computer simulations. In systems with significant dynamic \ncomplexity, computer simulation will typically be needed (though there are notable \nexceptions, such as the Beer Distribution Game (Sterman 1989b) and the Mainte- \nnance Game described in section 2.4, along with role-playkomputer hybrids such \nUnknown structure \nDynamic complexity \nInability to conduct controlled \n\\ \nVirtual World \nKnown structure \nVariable level of complexity \nControlled experiments \nI \nI \nr \nDecisions \n\\ \n/ \nComplete, \nSelective perception \n[=]‘-\naccurate, \nMissing feedback \nfeedback \nBias, distortion, error \nInformation Feedback \nVirtual World: \nReal World: \nAmbiguity \n\\ \n","page_start":59,"page_end":59,"token_count":435,"section_type":"other","chapter_number":2,"chapter_title":"System Dynamics in Action","chunk_index":65}
{"chunk_id":"cff494328743e1c0","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"Chapter 1 Learning in and about Complex Systems \n35 \nas Fish Banks, Ltd. (Meadows, Fiddaman, and Shannon 1993). Many of the tools \nof system dynamics are designed to help you develop useful, reliable, and effective \nmodels to serve as virtual worlds to aid learning and policy design. \nVirtual worlds have several virtues. First, they provide low-cost laboratories \nfor learning. The virtual world allows time and space to be compressed or dilated. \nActions can be repeated under the same or different conditions. One can stop the \naction to reflect. Decisions that are dangerous, infeasible, or unethical in the real \nsystem can be taken in the virtual world. Thus controlled experimentation becomes \npossible, and the time delays in the learning loop through the real world are dra- \nmatically reduced. In the real world the irreversibility of many actions and the need \nto maintain high performance often override the goal of learning by preventing ex- \nperiments with untried possibilities (“If it ain’t broke, don’t fix it”). In the virtual \nworld you can try strategies that you suspect will lead to poor performance or even \n(simulated) catastrophe. Often pushing a system into extreme conditions reveals \nmore about its structure and dynamics than incremental adjustments to successful \nstrategies. Virtual worlds are the only practical way to experience catastrophe \nin advance of the real thing. Thus a great deal of the time pilots spend in flight \nsimulators is devoted to extreme conditions such as engine failure or explosive \ndecompression. \nVirtual worlds provide high-quality outcome feedback. In the People Express \nManagement Flight Simulator (Sterman 1988a), for example, and similar system \ndynamics simulations, players receive perfect, immediate, undistorted, and com- \nplete outcome feedback. In an afternoon one can gain years of simulated experi- \nence. The degree of random variation in the virtual world can be controlled. Virtual \nworlds offer the learner greater control over strategy, lead to more consistent deci- \nsion making, and deter implementation failure and game playing. In contrast to the \nreal world, which, like a black box, has a poorly resolved structure, virtual worlds \ncan be open boxes whose assumptions are fully known and can even be modified \nby the learner. \nVirtual worlds for learning and training are commonplace in the military, in \npilot training, in power plant operations, and in many other real time tasks where \nhuman operators interact with complex technical systems. Virtual worlds are also \ncommon in professions such as architecture and engineering that lend themselves \nto the use of physical models (Schon 1983). The use of virtual worlds in man- \nagerial tasks, where the simulation compresses into minutes or hours dynamics ex- \ntending over years or decades, is more recent and less widely adopted. Yet these \nare precisely the settings where dynamic complexity is most problematic, where \nthe learning feedbacks described above are least effective, and where the stakes are \nhighest. \n1.4.2 \nPitfalls of Virtual Worlds \nVirtual worlds are effective when they engage people in what Dewey called “re- ","page_start":60,"page_end":60,"token_count":649,"section_type":"other","chapter_number":2,"chapter_title":"System Dynamics in Action","chunk_index":66}
{"chunk_id":"83aa5afed715bded","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"agerial tasks, where the simulation compresses into minutes or hours dynamics ex- \ntending over years or decades, is more recent and less widely adopted. Yet these \nare precisely the settings where dynamic complexity is most problematic, where \nthe learning feedbacks described above are least effective, and where the stakes are \nhighest. \n1.4.2 \nPitfalls of Virtual Worlds \nVirtual worlds are effective when they engage people in what Dewey called “re- \nflective thought” and what Schon (1992) calls “reflective conversation with the \nsituation.” Though simulation models and virtual worlds may be necessary for \neffective learning in dynamically complex systems, they are not sufficient to over- \ncome the flaws in our mental models, scientific reasoning skills, and group \nprocesses. ","page_start":60,"page_end":60,"token_count":166,"section_type":"other","chapter_number":2,"chapter_title":"System Dynamics in Action","chunk_index":67}
{"chunk_id":"1f3bd8614797c962","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"36 \nPart I Perspective and Process \nObviously, while the virtual world enables controlled experimentation, it does \nnot require the learner to apply the principles of scientific method. Many partici- \npants in system dynamics projects lack training in scientific method and awareness \nof the pitfalls in the design and interpretation of experiments. A commonly ob- \nserved behavior among modelers and in workshops using management flight sim- \nulators is the video game syndrome in which people play too much and think too \nlittle. People often do not take time to reflect on the outcome of a simulation, iden- \ntify discrepancies between the outcomes and their expectations, formulate hy- \npotheses to explain the discrepancies, and then devise experiments to discriminate \namong the competing alternatives. Effective learning using system dynamics will \noften require training for participants in scientific method. Protocols for the use of \nsimulations should be structured to encourage proper procedure, such as keeping \nlaboratory notebooks, explicitly formulating hypotheses and presenting them to the \ngroup, and so on. \nDefensive routines and groupthink can operate in the learning laboratory just \nas in the real organization. Indeed, protocols for effective learning in virtual worlds \nsuch as public testing of hypotheses, accountability, and comparison of different \nstrategies can be highly threatening, inducing defensive reactions that prevent \nlearning (Isaacs and Senge 1992). The use of system dynamics to stimulate learn- \ning in organizations often requires members of the client team to spend time ad- \ndressing their own defensive behavior. Managers unaccustomed to disciplined \nscientific reasoning and an open, trusting environment with learning as its goal will \nhave to build these basic skills before a system dynamics model-or indeed, any \nmodel-can prove useful. Developing these skills takes effort and practice. \nStill, settings with high dynamic complexity can garble the reflective conver- \nsation between the learner and the situation. Long time delays, causes and effects \nthat are distant in time and space, and the confounding effects of multiple nonlin- \near feedbacks can slow learning even for people with good insight and group \nprocess skills. Learning in virtual worlds can be accelerated when the modeling \nprocess also helps people learn how to represent complex feedback structures and \nunderstand their implications rather than simply presenting the results of an analy- \nsis. To learn in dynamically complex systems participants must have confidence \nthat the model is an appropriate representation of the problem they care about. \nThey must believe it mimics the relevant parts of the real world well enough that \nthe lessons emerging from the virtual world apply to the real one. To develop such \nconfidence the virtual world must be an open box whose assumptions can be in- \nspected, criticized, and changed. To learn, participants must become modelers, not \nmerely players in a simulation game. \nIn practice, effective learning from models occurs best, and perhaps only, \nwhen the decision makers participate actively in the development of the model. \nModeling here includes the elicitation of the participants’ existing mental models, \nincluding articulating the issues (problem structuring), selecting the model bound- ","page_start":61,"page_end":61,"token_count":640,"section_type":"other","chapter_number":2,"chapter_title":"System Dynamics in Action","chunk_index":68}
{"chunk_id":"af2d1b4e4361ca84","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"spected, criticized, and changed. To learn, participants must become modelers, not \nmerely players in a simulation game. \nIn practice, effective learning from models occurs best, and perhaps only, \nwhen the decision makers participate actively in the development of the model. \nModeling here includes the elicitation of the participants’ existing mental models, \nincluding articulating the issues (problem structuring), selecting the model bound- \nary and time horizon, and mapping the causal structure of the relevant system. \nAlong with techniques developed in system dynamics, many tools and protocols \nfor group model-building are now available, including causal loop diagrams, \npolicy structure diagrams, interactive computer mapping, and various problem \nstructuring and soft systems methods (see, e.g., Checkland 1981; Eden, Jones and ","page_start":61,"page_end":61,"token_count":166,"section_type":"other","chapter_number":2,"chapter_title":"System Dynamics in Action","chunk_index":69}
{"chunk_id":"e6ed83be2f233118","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"Chapter 1 Learning in and about Complex Systems \n37 \nSims 1983; Lane 1994; Morecroft 1982; Morecroft and Sterman 1994; Reagan- \nCirincione et al. 1991; Richmond 1987, 1993; Rosenhead 1989; Senge and \nSterman 1992; and Wolstenholme 1990). \n1.4.3 \nWhy Simulation Is Essential \nEliciting and mapping the participants’ mental models, while necessary, is far from \nsufficient. As discussed above, the temporal and spatial boundaries of our mental \nmodels tend to be too narrow. They are dynamically deficient, omitting feedbacks, \ntime delays, accumulations, and nonlinearities. The great virtue of many protocols \nand tools for elicitation is their ability to improve our models by encouraging peo- \nple to identify the elements of dynamic complexity normally absent from mental \nmodels. However, most problem structuring methods yield qualitative models \nshowing causal relationships but omitting the parameters, functional forms, exter- \nnal inputs, and initial conditions needed to fully specify and test the model. Re- \ngardless of the form of the model or technique used, the result of the elicitation and \nmapping process is never more than a set of causal attributions, initial hypotheses \nabout the structure of a system, which must then be tested. \nSimulation is the only practical way to test these models. The complexity of \nour mental models vastly exceeds our capacity to understand their implications. \nTypical conceptual models such as the type of causal diagram shown in Figure 1-6 \nare too large and complex to simulate mentally. Without simulation, even the best \nconceptual models can only be tested and improved by relying on the learning \nfeedback through the real world. As we have seen, this feedback is very slow and \noften rendered ineffective by dynamic complexity, time delays, inadequate and \nambiguous feedback, poor reasoning skills, defensive reactions, and the costs of \nexperimentation. In these circumstances simulation becomes the only reliable way \nto test hypotheses and evaluate the likely effects of policies. \nSome scholars argue that formal modeling can at best provide quantitative \nprecision within preexisting problem definitions but cannot lead to fundamentally \nnew conceptions (for various views see Dreyfus and Dreyfus 1986 and the discus- \nsion in Lane 1994). On the contrary, formalizing qualitative models and testing \nthem via simulation often leads to radical changes in the way we understand real- \nity. Simulation speeds and strengthens the learning feedbacks. Discrepancies \nbetween formal and mental models stimulate improvements in both, including \nchanges in basic assumptions such as model boundary, time horizon, and dynamic \nhypotheses (see Forrester 1985 and Homer 1996 for philosophy and examples). \nWithout the discipline and constraint imposed by the rigorous testing enabled by \nsimulation, it becomes all too easy for mental models to be driven by ideology or \nunconscious bias. \nSome argue that formalization forces the modeler to omit important aspects of ","page_start":62,"page_end":62,"token_count":644,"section_type":"other","chapter_number":2,"chapter_title":"System Dynamics in Action","chunk_index":70}
{"chunk_id":"163f0081a900f76c","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"between formal and mental models stimulate improvements in both, including \nchanges in basic assumptions such as model boundary, time horizon, and dynamic \nhypotheses (see Forrester 1985 and Homer 1996 for philosophy and examples). \nWithout the discipline and constraint imposed by the rigorous testing enabled by \nsimulation, it becomes all too easy for mental models to be driven by ideology or \nunconscious bias. \nSome argue that formalization forces the modeler to omit important aspects of \nthe problem to preserve tractability and enable theorems to be proved or to omit \nsoft variables for which no numerical data exist. These are indeed dangers. The lit- \nerature of the social sciences is replete with models in which elegant theorems are \nderived from questionable axioms, where simplicity dominates utility, and where \nvariables known to be important are ignored because data to estimate parameters \nare unavailable. System dynamics was designed specifically to overcome these ","page_start":62,"page_end":62,"token_count":193,"section_type":"other","chapter_number":2,"chapter_title":"System Dynamics in Action","chunk_index":71}
{"chunk_id":"ffbea834b618db2e","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"38 \nPart I Perspective and Process \nlimitations and from the beginning stressed the development of useful models; \nmodels unconstrained by the demands of analytic tractability, based on realistic as- \nsumptions about human behavior, grounded in field study of decision making, and \nutilizing the full range of available data, not only numerical data, to specify and es- \ntimate relationships (see Forrester 1961, 1987). \nSome people don’t believe that models of human behavior can be developed. \nSimulations of natural and technical systems such as the climate or an oil refinery \nare based on well-understood laws of physics, but, it is argued, there are no com- \nparably reliable laws of human behavior. This view overestimates our understand- \ning of nature and underestimates the regularities in human decision making. As \nKenneth Boulding points out, “Anything that exists is possible.” You will see many \nexamples of models of human systems throughout this book (see also the models \nin Levine and Fitzgerald 1992; Roberts 1978; Langley et al. 1987; Sterman 1985a; \nHomer 1985; and many of the models cited in Sastry and Sterman 1993). \nIs it possible to learn effectively in complex settings without simulation? Can \nthe use of problem structuring methods, elicitation techniques, and other qualita- \ntive systems methods overcome the impediments to learning? If intuition is devel- \noped highly enough, if systems thinking is incorporated in precollege education \nearly enough, or if we are taught how to recognize a set of “system archetypes” \n(Senge 1990), will we be able to improve our intuition about complex dynamics \nenough to render simulation unnecessary? \nThe answer is clearly no. It is true that systems thinkmg techniques, including \nsystem dynamics and qualitative methods such as soft systems analysis, can en- \nhance our intuition about complex situations, just as studying physics can improve \nour intuition about the natural w0r1d.I~ As Wolstenholme (1990) argues, qualitative \nsystems tools should be made widely available so that those with limited mathe- \nmatical background can benefit from them. I am a strong advocate for the intro- \nduction of system dynamics and related methods at all levels of the educational \nsystem. Yet even if we all began serious study of physics in kindergarten and con- \ntinued it through a Ph.D., it is ludicrous to suggest that we could predict the track \nof a hurricane or understand by intuition alone what happens when two galaxies \ncollide. Many human systems are at least as complex. Even if children learn to \nthink in systems terms-a goal I believe is vitally important-it will still be nec- \nessary to develop formal models, solved by simulation, to learn about such sys- \ntems. \nMost important, when experimentation in real systems is infeasible, simulation \nbecomes the main, and perhaps the only, way you can discover for yourself how \ncomplex systems work. The alternative is rote learning based on the authority of ","page_start":63,"page_end":63,"token_count":654,"section_type":"other","chapter_number":2,"chapter_title":"System Dynamics in Action","chunk_index":72}
{"chunk_id":"59b5a1e745c08a01","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"think in systems terms-a goal I believe is vitally important-it will still be nec- \nessary to develop formal models, solved by simulation, to learn about such sys- \ntems. \nMost important, when experimentation in real systems is infeasible, simulation \nbecomes the main, and perhaps the only, way you can discover for yourself how \ncomplex systems work. The alternative is rote learning based on the authority of \nthe teacher and textbook, a method that dulls creativity and stunts the development \nof the scientific reasoning skills needed to learn about complexity. \n14Such knowledge of basic physics is desperately needed. When asked the question “If a pen is \ndropped on the moon, will it (a) float away; (b) float where it is; (c) fall to the surface of the \nmoon?” 48 out of 168 students in physics courses at Iowa State University gave incorrect answers. \nTypical student explanations were “The gravity of the moon can be said to be negligible” and “The \nmoon’s a vacuum, there is no external force on the pen. Therefore it will float where it is.” (Partee, \npersonal communication, 1992). ","page_start":63,"page_end":63,"token_count":248,"section_type":"other","chapter_number":2,"chapter_title":"System Dynamics in Action","chunk_index":73}
{"chunk_id":"cd45f3fc37325789","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"Chapter 1 Learning in and about Complex Systems \n39 \n1.5 \nThe implications for this book are clear. System dynamics is not a spectator \nsport: Throughout the book I have tried to encourage the active participation of \nyou, the reader. You will find Challenges in each chapter-examples for you to \nconsider and work through yourself, such as the chicken and egg causal loop dia- \ngram in Figure 1-6 and the Wason card puzzle in Figure 1-13. Some of these are \nfollowed by a suggested response. Others are not. As you work through the book, \nextend the examples. Build the models. Experiment with them. Apply your skills \nto new problems and new issues. And, most of all, have fun.I5 \nS u NI MARY \nComplex dynamic systems present multiple barriers to learning. The challenge of \nbettering the way we learn about these systems is itself a classic systems problem. \nSystem dynamics is a powerful method to gain useful insight into situations of \ndynamic complexity and policy resistance. It is increasingly used to design more \nsuccessful policies in companies and public policy settings. However, no one \nmethod is a panacea. Overcoming the barriers to learning requires a synthesis of \nmany methods and disciplines, from mathematics and computer science to \npsychology and organizational theory. Theoretical studies must be integrated with \nfield work. Interventions in real organizations must be subjected to rigorous \nfollow-up research. \nThe field of system dynamics is itself dynamic. Recent advances in interactive \nmodeling, tools for representation of feedback structure, and simulation software \nmake it possible for anyone to engage in the modeling process. Corporations, uni- \nversities, and schools are experimenting vigorously. The library of successful in- \nterventions and insightful research is growing. Much further work is needed to test \nthe utility of the tools and protocols, evaluate their impact on individual and orga- \nnizational learning, and develop effective ways to train others to use them. Never \nbefore have the challenges of our increasingly dynamic world been more daunting. \nNever before have the opportunities been greater. It’s an exciting time to be learn- \ning in and about complex systems. \nl5The accompanying CD-ROM and website (http://www.mhhe.com/sterman) \ninclude the models \ndeveloped in the text and simulation software you can use to run and extend them. \n","page_start":64,"page_end":64,"token_count":496,"section_type":"other","chapter_number":2,"chapter_title":"System Dynamics in Action","chunk_index":74}
{"chunk_id":"8ee2d07097115471","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"2 \nSystem Dynamics in Action \n[System dynamics] is an approach that should help in important top- \nmanagement problems . . . The solutions to small problems yield small \nrewards. Very often the most important problems are but little more difficult to \nhandle than the unimportant. Many [people] predetermine mediocre results by \nsetting initial goals too low. The attitude must be one of enterprise design. The \nexpectation should be for major improvement. . . The attitude that the goal is \nto explain behaviol; which is fairly common in academic circles, is not \nsufficient. The goal should be to find management policies and organizational \nstructures that lead to greater success. \n-Jay W. Forrester (Industrial Dynamics, 1961, p. 449). \nThis chapter presents three case studies of the successful application of system dy- \nnamics to solve important real world problems. The cases span a range of indus- \ntries and issues. They illustrate different contexts for the use of system dynamics \nand different modeling processes, from large, data intensive models to small mod- \nels, interactive management flight simulators, and role-playing games. The cases \nillustrate how system dynamics can be used to help solve high-stakes problems in \nreal time. The cases illustrate the principles discussed in chapter 1 and preview \nmany of the tools and methods discussed in subsequent chapters. \n2.1 \nAPPL-ICATIONS \nOF SYSTEM DYNAMICS \nSystem dynamics has been applied to issues ranging from corporate strategy to the \ndynamics of diabetes, from the cold war arms race between the US and USSR to \nthe combat between HIV and the human immune system. System dynamics can be \n41 \n","page_start":66,"page_end":66,"token_count":351,"section_type":"other","chapter_number":2,"chapter_title":"System Dynamics in Action","chunk_index":75}
{"chunk_id":"534f718b780bcd6e","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"42 \nPart I Perspective and Process \napplied to any dynamic system, with any time and spatial scale. In the world of \nbusiness and public policy, system dynamics has been applied to industries from \naircraft to zinc and issues from AIDS to welfare reform.’ \nDeveloping an insightful model is difficult enough; using modeling to help \nchange organizations and implement new policies is even harder. The greatest po- \ntential for improvement comes when the modeling process changes deeply held \nmental models. Yet the more fundamental the mental model you challenge, the \nmore defensive the client may be. To resolve the dilemma the clients must discover \nthe insights for themselves by active participation in the modeling process. \nThis chapter presents three case studies illustrating the process. Each ad- \ndressed an important real world issue. Each involved a different context and there- \nfore used a different approach. Yet each also succeeded in involving the clients as \npartners in the modeling process, in changing long-established mental models, and \nin generating significant benefit. \n2.2 \nAUTOMOBILE LEASING STRATEGY: \nGONE TODAY, HERE TOMORROW* \nIn the 1990s a new way to buy cars emerged in the United States-the used car \nsuperstore. National chains like CarMax and AutoNation offered a large selection \nof clean, low mileage late model cars with warranties, roadside assistance plans, \nand other amenities traditionally available only to new car buyers. Superstore sales \ngrew from nothing in 1992 to more than $13 billion in 1998. Internet car vendors \nbegan to spring up as well. Many analysts believed the combination of superstores \nand internet sales heralded a revolution in the retail auto market. \nIn 1995 some senior managers at General Motors were concerned about the \nimpact of the superstores on new car sales. Would they cut into GM’s core market? \nWould they force prices down? How could GM respond? Ron Zarella, then vice \npresident and group executive for North American vehicle sales, service, and mar- \nketing (VSSM) and later promoted to president of GM’s North American region, \nneeded a way to examine these issues. \nThere was little research on the used car market available to help. For many \ndecades the new and used car markets were only loosely coupled because people \ntended to keep their cars a long time. Market research in the early 1990s showed \nnew car buyers were keeping their cars an average of more than 6 years. The bulk \nof used cars offered for sale were 4 or more years old and were poor substitutes for \nnew cars. The prevailing mental model in the auto industry, including GM, was \n‘Richardson (1996), Roberts (1978), and Morecroft and Sterman (1994), among others, provide \nexamples of the application of system dynamics to important problems in a wide range of industries \nand public policy issues. Mosekilde (1996) describes applications in physics and biology. Ford \n(1999) describes environmental applications. \n*This case is based on the work of the General Motors Strategy Support Center, led by Nick \nPudar. I’m grateful to Nick and GM for permission to present the case and to Nick and Mark Paich \nfor help in its preparation. \n","page_start":67,"page_end":67,"token_count":688,"section_type":"other","chapter_number":2,"chapter_title":"System Dynamics in Action","chunk_index":76}
{"chunk_id":"0798faea9e7fd4b1","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"Chapter 2 System Dynamics in Action \n43 \nthat auto companies were in the business of selling new cars; the vehicles people \ntraded in were old and effectively disappeared into a separate system, the used car \nmarket. “There are really two markets-new and used,” the executive director of \nsales operations at Ford told The Wall Street Journal in 1994 (3 June, p. B 1). \nZarella contacted Vince Barabba, then general manager of corporate strategy \nand knowledge development in the VSSM organization, and described his con- \ncerns. Barabba, former head of the US Census Bureau, also headed up the Decision \nSupport Center (DSC) and asked Nick Pudar, then a senior business analyst in the \nDSC, to work on the superstore issue. The DSC is an internal group GM formed to \nhelp business units and project teams throughout the company develop and imple- \nment strategy. The DSC uses a variety of analytical tools, including system dy- \nnamics. More than simply a group of analytical modelers, the DSC developed a \nsophisticated approach, the dialogue decision process, designed to build consensus \nthat leads to action, not merely analysis and reports. Barabba and Pudar (1996) de- \nscribe the dialogue decision process as \na disciplined decision making process which involves a series of structured dia- \nlogues between two groups responsible for reaching a decision and implementing \nthe resulting action plan. The first group (Decision Review Board) consists of the \ndecision-makers, who generally represent different functions. What they have in \ncommon is the authority to allocate resources: people, capital, materials, time, and \nequipment . . . The second group (Core Team), consists of. . . those with a stake in \nthe implementation. \nThe dialogue between the two groups, which involves sharing and learning for \nboth, takes place in four sequential stages: 1) framing the problem; 2) developing \nalternatives; 3) conducting the analysis; and 4) establishing connection. Each of \nthese four steps is completed by the Core Team and supported by facilitators \nequipped with decision analytic tools. At the end of each phase, they have a dia- \nlogue session with the Decision Review Board where they jointly review the \nprogress. In an atmosphere of inquiry . . . senior leadership converses with a cross- \nfunctional team of managers on a topic of mutual strategic importance. \nPudar told Zarella he would need to commit to a several hour meeting each week \nfor a month “to be sure we are working on the right problem.” While Zarella’s \nschedule was extremely tight he offered to meet with Barabba and Pudar the \nnext day. \nPudar, working with Mark Paich, an external system dynamics consultant and \nprofessor of economics at Colorado College, Darren Post of the DSC, and Tom Pa- \nterson (another consultant to the DSC) scrambled to develop an initial model of the \nissue. That afternoon they developed a simple diagram representing the stocks and ","page_start":68,"page_end":68,"token_count":647,"section_type":"other","chapter_number":2,"chapter_title":"System Dynamics in Action","chunk_index":77}
{"chunk_id":"e271bdc12c566178","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"schedule was extremely tight he offered to meet with Barabba and Pudar the \nnext day. \nPudar, working with Mark Paich, an external system dynamics consultant and \nprofessor of economics at Colorado College, Darren Post of the DSC, and Tom Pa- \nterson (another consultant to the DSC) scrambled to develop an initial model of the \nissue. That afternoon they developed a simple diagram representing the stocks and \nflows of cars through the new and used markets and some of the feedbacks that \nmight couple them. They deliberately kept it very simple, both to be sure they \ncould complete it in time and so they could explain it clearly. \nThat night Pudar developed a simple, working simulation model of the inter- \nactions between the new and used markets. The model included sectors for \nnew and used cars (divided into GM and non-GM vehicles) and tracked vehicles \nfrom production through initial sale or lease, trade-in, the used car market, and, ","page_start":68,"page_end":68,"token_count":209,"section_type":"other","chapter_number":2,"chapter_title":"System Dynamics in Action","chunk_index":78}
{"chunk_id":"4cdbe5e258a8b1b8","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"44 \nPart I Perspective and Process \nultimately, scrapping. It also tracked the flows of customers moving into and out \nof the market and included a simple consumer choice model for the newhsed pur- \nchase decision. Pudar used data at hand and his judgment to estimate parameters. \nFigure 2-lshows a simplified diagram of the initial model. The structure in \nblack captures the prevailing mental model focused on the new car market. The left \nside tracks the stocks and flows of vehicles. Starting at the top, the inventory of \nunsold new cars is increased by production and drained by new car sales. New car \nsales add to the stock of late model cars on the road. People sell or trade in their car \nand buy a new one with a frequency defined by the average trade-in time. \nFigure 2-1 also shows the main feedbacks operating in the new car market. \nManufacturers and dealers pay close attention to the stock of new cars. Inventory \ncoverage of about 45 days provides a good balance between the selection available \non dealer lots and carrying costs. Low coverage hurts sales because cars aren’t \navailable; high inventories slash dealer and automaker profits as carrying costs bal- \nloon. If inventory coverage rises above normal, carmakers cut production, which \nhelps reduce inventories back to normal. The response of production to inventories \nforms the negative (balancing) Production Control feedback loop, B 1. However, \nautomakers are reluctant to cut production and in any case, it takes time. The delay \nin adjusting production means inventories tend to fluctuate around desired levels \nas demand varies. \nThe second main response to excess inventories is lower prices. When inven- \ntory coverage is high, dealers are more willing to cut their margins and manu- \nfacturers offer incentives such as cash-back and low annual percentage rates \n(APRs) on loans financed through their credit divisions. Lower prices make new \ncars more attractive relative to the cars people already own. People trade in their \nold cars sooner, boosting new car sales until inventories fall back to normal (the \nnegative Pricing loop, B2). \n2.2.1 \nDynamic Hypothesis \nChallenging the conventional wisdom, the team expanded the stock and flow struc- \nture to include late model used cars. Instead of disappearing, trade-ins add to in- \nventories of late model used cars on dealer lots or available for auction. When \nthese cars are purchased, they reenter the stock of late model cars on the road. The \nsum of the cars on the road and cars on dealer lots is the total stock of late model \nvehicles (shown by the large rectangle in Figure 2- 1); these cars gradually age into \nthe population of older cars and are eventually scrapped. The model used an “aging \nchain” to keep track of the cars on the road and in used car inventories by 1-year \ncohorts. The aging chain (chapter 12) allowed the team to examine how the \nnumber of 1-, 2-, and 3-year-old cars on the road and for sale changed in response ","page_start":69,"page_end":69,"token_count":659,"section_type":"other","chapter_number":2,"chapter_title":"System Dynamics in Action","chunk_index":79}
{"chunk_id":"808b3498d3f064ca","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"the population of older cars and are eventually scrapped. The model used an “aging \nchain” to keep track of the cars on the road and in used car inventories by 1-year \ncohorts. The aging chain (chapter 12) allowed the team to examine how the \nnumber of 1-, 2-, and 3-year-old cars on the road and for sale changed in response \nto sales. \nThe stock and flow perspective motivated the modeling team to ask where the \nsuperstores got the large inventories of attractive late model cars they required. \nPart of the answer was the growing quality of new cars. Stimulated by the high \nquality of foreign cars, particularly the Japanese imports, all manufacturers had ","page_start":69,"page_end":69,"token_count":148,"section_type":"other","chapter_number":2,"chapter_title":"System Dynamics in Action","chunk_index":80}
{"chunk_id":"705033ded2ce58d4","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"Chapter 2 System Dynamics in Action \n45 \nFIGURE 2-1 \nA simple model of the automobile market \nProduction \nControl \nq \nReinforcing \nBalancing \nFeedback \nRectangles represent stocks of cars; pipes and valves represent flows between \ncategories (chapter 6). Arrows and polarities (+ or -) indicate causal influences: \nAn increase in New Car Inventory leads to an increase in Inventory Coverage (and a \ndecrease leads to a decrease); an increase (decrease) in Inventory Coverage causes \nnew car prices to decrease (increase); see chapter 5. Gray structure was not captured \nin the prevailing industry mental model in which new and used car markets do not \ninteract. \nPrice & APR \n-Late Model C \nLease \nTerm \nLease \nLease ’ Subveytion \nSubvention \nRelative \nAttractiveness \nof New Cars \nAverage \nTrade-In Time / \nv \nk \n","page_start":70,"page_end":70,"token_count":196,"section_type":"other","chapter_number":2,"chapter_title":"System Dynamics in Action","chunk_index":81}
{"chunk_id":"91dacc4e47df81dc","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"46 \nPart I Perspective and Process \ninvested in major quality programs. Though there was still room for improvement, \nby the 1990s the quality and durability of new cars was significantly higher than in \nthe 1980s. \nBut quality improvement alone could not explain the rise of the superstores. \nBy the time most cars are traded in they are too old to compete against new cars \nand are unsuitable for the superstores. Quality improvements might even lengthen \nthe trade-in cycle time, reducing the supply of late model used cars. \nThe answer was leasing. In the early 1990s leasing was the hot new marketing \ntool in the automobile industry. Leasing offered what seemed to be a sure-fire way \nto boost sales. Rising quality meant the market value of 2-, 3-, and 4-year-old cars \nwas much higher relative to new cars than in the past. The higher the residual value \nat the end of a lease, the lower the lease payments. Leases also give customers the \noption to buy the car when the lease expires at the specified residual value, trans- \nferring the risk of fluctuations in the market value of used vehicles from the cus- \ntomer to the carmaker. Most important to the manufacturers, typical lease terms are \n2 to 4 years, stimulating sales by cutting the trade-in cycle time. Leasing increased \nfrom 4.1% of all new car sales in 1990 to more than 22% in 1997. \nFrom the perspective of the prevailing mental model, leasing was a boon. First, \nit stimulated sales. Whenever inventories rise carmakers could increase incentives \nfor leasing through lease subvention. Subvention lowers lease payments by as- \nsuming higher residuals, lower interest rates, or lower initial capitalization; typi- \ncally carmakers would raise residual values above guidebook values for used cars. \nLower lease payments boost the attractiveness of new cars and induce some people \nto trade their current car for a new leased vehicle (forming the balancing Lease \nIncentive loop B3 in Figure 2-1). Second, the shorter the average lease term, the \nshorter the trade-in time and the greater the sales (the balancing Lease Term loop \nB4). If all new car buyers switched to leases with an average term of 3 years, the \ntrade-in cycle time would be cut in half and new car sales would double-all else \nequal. \nThe modeling team quickly challenged the assumption that all else was equal. \nWhile a 6-year old car is a poor substitute for a new car, a 1- to 3-year-old car with \nlow mileage might be attractive to many people. As the growing volume of leases \nexpired the used car market could be flooded with high-quality nearly new cars. \nUsed car prices might plummet. Some people who might have traded their current \ncars for new ones opt instead for off-lease vehicles, raising the average trade-in \ntime and returning more late model used cars to the stock of cars on the road (the \nbalancing Used Car Market loop, B5). Leasing also shortens the average trade-in ","page_start":71,"page_end":71,"token_count":658,"section_type":"other","chapter_number":2,"chapter_title":"System Dynamics in Action","chunk_index":82}
{"chunk_id":"330479fed923c07b","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"expired the used car market could be flooded with high-quality nearly new cars. \nUsed car prices might plummet. Some people who might have traded their current \ncars for new ones opt instead for off-lease vehicles, raising the average trade-in \ntime and returning more late model used cars to the stock of cars on the road (the \nbalancing Used Car Market loop, B5). Leasing also shortens the average trade-in \ncycle time, raising the average quality of used cars for sale. More people opt for \noff-lease vehicles instead of buying new. The average trade-in time for the popula- \ntion as a whole rises, forming the balancing Used Car Quality loop, B6. Even more \ninteresting, the used market could feed back to affect the fraction of customers who \nchoose to buy their car when their lease expires. If, at lease end, used car prices are \nhigher than the residual value written into the lease, the customer can purchase the \ncar below market value. The customer retention fraction would rise. If, however, \nused car prices dropped below residual values, the retention fraction would fall as \nmore customers turned their cars back to the lessor. The inventory of late model ","page_start":71,"page_end":71,"token_count":248,"section_type":"other","chapter_number":2,"chapter_title":"System Dynamics in Action","chunk_index":83}
{"chunk_id":"a30258f60795b325","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"Chapter 2 System Dynamics in Action \n47 \ncars would rise and used car prices would drop still more, in a vicious cycle, the \npositive (self-reinforcing) Purchase Option loop, R1 .3 \nHowever, the feedbacks shown in gray operate with a long delay (roughly \nequal to the average lease term) and were poorly understood in the industry. Leas- \ning stimulates sales in the short-run. Unaware of the structure shown in gray in \nFigure 2-1, the experience of the early 1990s taught carmakers that leasing \nworks-and they diverted still more marketing dollars to subvention and shorter \nterms. \nInitial results suggested, however, that leasing would eventually create a glut \nof high-quality nearly new cars, depressing late model used car prices. New car \nsales would suffer as more consumers opted for cheap off-lease vehicles. The car- \nmakers’ credit companies (General Motors Acceptance Corporation [GMAC], \nFord Credit Corporation, and Chrysler Credit Corporation) would face losses as \nmarket values fell short of the residual value they had booked and as fewer con- \nsumers exercised their option to buy, turning the car back to the lessors instead. \nThe following day Pudar and his team presented these results to Zarella, in- \ncluding the structure of the initial model and simulations showing the problems ag- \ngressive leasing could cause. By shortening trade-in cycle times through leasing \nand fleet sales, carmakers were creating a glut of high-quality used cars at attrac- \ntive prices. Superstores were simply the market response to the opportunity the \nmanufacturers themselves had created. \nUsed car superstores were only the symptom of a deeper problem-the leasing \npolicies of the carmakers. Leasing increased sales in the short run but set in motion \nfeedbacks that caused sales to slump when the leased vehicles reentered the mar- \nket. In the old days, people kept their cars long enough that trade-ins effectively \ndisappeared from concern. But in a world of short-term leases, new cars are gone \ntoday, here tomorrow. \nThe realization that superstores were an endogenous consequence of the car- \nmakers’ own actions dramatically redefined the focus of the work. Initial model \nanalysis suggested GM should de-emphasize leasing, exactly counter to industry \ntrends. \nThese effects may seem obvious (especially now that you have read the de- \nscription of the model above), and auto industry executives did know that some \noff-lease cars would reenter the market. However, most discounted the possibility \nof any problems. In 1994, USA Today quoted a General Motors leasing executive \nwho said, “The demand for cars coming off leases is triple the supply. Lease-end \ncars have ‘not created a bottleneck in the industry”’ (2 November). A Detroit-area \n3The Purchase Option loop is partially offset because customers turning their cars back to \nlessors purchase another vehicle. If lease customers used their purchase option to make a pure arbi- \ntrage play when used car prices fell below residual values by turning their cars in and immediately ","page_start":72,"page_end":72,"token_count":649,"section_type":"other","chapter_number":2,"chapter_title":"System Dynamics in Action","chunk_index":84}
{"chunk_id":"62159d9e096a5c45","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"who said, “The demand for cars coming off leases is triple the supply. Lease-end \ncars have ‘not created a bottleneck in the industry”’ (2 November). A Detroit-area \n3The Purchase Option loop is partially offset because customers turning their cars back to \nlessors purchase another vehicle. If lease customers used their purchase option to make a pure arbi- \ntrage play when used car prices fell below residual values by turning their cars in and immediately \nbuying identical ones at the lower market price, then the net effect of changes in the retention frac- \ntion would be zero. However, some customers turning their cars back to lessors will buy a new car \nor different used car, possibly from a competitor. On net a lower retention fraction for a given make \nand model will tend to push prices for that car down still more, triggering even lower retention. \nThese effects were captured in the full model but for clarity are not shown in Figure 2-1. ","page_start":72,"page_end":72,"token_count":202,"section_type":"other","chapter_number":2,"chapter_title":"System Dynamics in Action","chunk_index":85}
{"chunk_id":"a906a27b29852195","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"Part I Perspective and Process \nCadillac dealer dismissed any linkage between the new and used markets for high- \nend cars, scoffing, “You’ll never get a luxury buyer to take a car with 30,000 miles \non it” (The Wall Street Journal, 3 June 1994). In the same article, The Journal went \non to note that Ford’s executive director of sales operations \nargues that the industry has had a chronic shortage of good two-year-old cars to \nsell . . . “This [short-term leasing] brings the cars back at just the right time, when \ndemand is highest,” he says. Moreover, the used-car market is at least twice as big \nas the new-car market and can easily absorb the projected volumes. \nThe underlying strength in used-car demand will safely absorb the volume of \nused vehicles coming off lease, without cannibalizing new-car sales,” predicts . . . \n[an] auto securities analyst at Salomon Bros. \nThere appeared to be ample evidence to support these views. Used car sales grew \nfrom 37.5 million in 1990 to nearly 42 million in 1995 while 1995 new car sales \nwere about 15 million, a rise of only about a million vehicledyear since 1990. \nUsed car prices rose more than 6%/year between 1990 and 1995, much faster than \ninflation. With rising used car prices, more and more people opted to keep their ve- \nhicle when their lease expired. Many in the industry, including GM, argued that \nstrong demand and rising used car values justified even higher residual values, al- \nlowing lower lease payments and boosting new car sales still more. \nWhile the initial results were intriguing, more work was needed before credi- \nble policy recommendations could be made, much less any action taken. Even if \nleasing was a devil’s bargain, every carmaker felt strong pressure to match the \nterms and prices of its competitors. Once all major manufacturers were offering \nshort lease terms with aggressive subvention, unilaterally backing away from leas- \ning might risk too much market share. Zarella asked the team to continue the mod- \neling to address these questions. The DSC formed a decision review board, chaired \nby Zarella and Barabba, to oversee the project and the modeling team then began \nto refine the model and gather the data needed to calibrate it. They had 20 days. \n2.2.2 \nElaborating the Model \nThe modeling team interviewed people throughout the organization to understand \nthe issues and gather data. Through the meetings of the core and modeling teams \nthey opened up the model to critical review and presented interim results for \ndiscussion. \nOne area for improvement was the treatment of the competition and segmen- \ntation of the market into different vehicle types. Some argued for explicit treatment \nof every major manufacturer and market segment. Brand loyalty is important: \nPeople who bought GM cars last time are more likely to buy another GM car than \nnon-GM owners. They also argued that GM customers were different from Ford or ","page_start":73,"page_end":73,"token_count":653,"section_type":"other","chapter_number":2,"chapter_title":"System Dynamics in Action","chunk_index":86}
{"chunk_id":"4a99e4aff720cc9c","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"they opened up the model to critical review and presented interim results for \ndiscussion. \nOne area for improvement was the treatment of the competition and segmen- \ntation of the market into different vehicle types. Some argued for explicit treatment \nof every major manufacturer and market segment. Brand loyalty is important: \nPeople who bought GM cars last time are more likely to buy another GM car than \nnon-GM owners. They also argued that GM customers were different from Ford or \nHonda customers and that markets for luxury cars, family sedans, sport utility ve- \nhicles, and so on were all different. The team countered that the data requirements \nfor such a detailed model would be enormous and would delay development of a \nuseful model. They preferred an iterative approach, with more limited disaggrega- \ntion; if sensitivity analysis showed that further segmentation was needed they \ncould then revise the model to include more detail. The team agreed to separate the ","page_start":73,"page_end":73,"token_count":195,"section_type":"other","chapter_number":2,"chapter_title":"System Dynamics in Action","chunk_index":87}
{"chunk_id":"9ebf5ffd5f98cba0","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"Chapter 2 System Dynamics in Action \n49 \nFIGURE 2-2 \nThe matrix shows \nthe probability \np(i, j) that cus- \ntomers in each \ncategory shown \nin row i will, on \ntrade-in, move \nto the category \nin column j. \nThe transition \nprobabilities in \nthe full model \nare variable and \ndepend on relative \nprices. The full \nmatrix disaggre- \ngates GM and \nnon-GM vehicles. \nmarket into GM and non-GM vehicles but to represent only a single aggregate \nvehicle type. \nAnother important area of discussion was disaggregation of the customer base. \nParallel to the flow of cars between the “on the road” and “for sale” stocks are \nstocks and flows of drivers. Every car traded in moves a customer from “on the \nroad” to “in the market;” every new or used car sold puts a driver on the road \nagain. Changes in the relative attractiveness of new and used cars shift the propor- \ntion of drivers in the market opting for a new car. The choice between new and \nused vehicles also depends on their past behavior. The chance a customer will \nlease, buy new, or buy used depends on whether he or she leased, bought new, or \nbought used last time. Some members of the organization pointed out that the com- \npany, through extensive market research, already knew a lot about consumer be- \nhavior in the new car market. They insisted that the dynamic model incorporate \nthese data so the DSC could speak with one voice and avoid the need to reconcile \nconflicting models. \nTo address the brand loyalty and consumer behavior issues the modeling team \ndisaggregated the customer base into several categories: those who leased a new \ncar, purchased a new car, or purchased used cars of various ages. Figure 2-2 shows \na simplified representation of the resulting transition matrix. Each entry in the ma- \ntrix is the probability that buyers coming from a particular category shown in a row \nwill, when they next trade in, move to the categories shown in the columns. The \nactual matrix had twice as many categories as it included probabilities for each \npurchase option for both GM and non-GM vehicles. \nThe transition probabilities in the matrix were not constant but changed as \nthe prices of new and used cars changed. Lower payments on GM leases increase \nNew Car Purchase \nNew Car Lease \n1 -Yr-Old Used Car \n2-Yr-Old Used Car \n3-Yr-Old Used Car \n4-Yr-Old Used Car \nSource: Adapted from GM Decision Support Center diagram. Used with \npermission. \n","page_start":74,"page_end":74,"token_count":557,"section_type":"other","chapter_number":2,"chapter_title":"System Dynamics in Action","chunk_index":88}
{"chunk_id":"8805d7fa8cf6c4b9","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"50 \nPart I Perspective and Process \nthe proportion opting for a GM lease, while lower used car prices increase the \nshare of people buying used cars at the expense of new purchases and leases. The \nresponse to such changes differed for each category of customer. \nThe disaggregation of the model was not accomplished in one step but in sev- \neral iterations. At each stage modeling team members made sure they understood \nthe structure and behavior of the model and presented it to Zarella and his team for \ncomment and review. Each iteration they incorporated the criticisms and sugges- \ntions they received. Even with the limited disaggregation of the model the data \nchallenges were formidable. Given the 20-day deadline, the team had to use data \nalready available in various parts of the organization. The market research data for \nnew cars were excellent. Data on leasing, a relatively new phenomenon, were \nsketchy. And consistent with the prevailing mental model that downplayed the \nused car market, there was almost no research describing how people traded off \nnew and late model used vehicles. They drew on the best data sources available \nand used judgment and qualitative data where numerical data were not available. \nAt the end of the 20 days the team met again with Zarella and his team. Instead \nof presenting the model and results, they configured the model as an interactive \nmanagement flight simulator. A “dashboard” contained dials and gauges reporting \nstandard accounting information such as inventory levels, sales volumes, prices, \nmarket share, and profitability. Players set production targets, incentives, lease \nterms, and so on. By clicking a button on the screen players could get additional in- \nformation including the structure and assumptions of the model. \nBy playing the game instead of listening to a presentation, Zarella and his team \nexplored the dynamics of leasing for themselves. They could try various strategies, \nfrom aggressive subvention of leases to pulling out of the lease market altogether, \nand see the impact on sales and profits in the short run and the long run. They dis- \ncovered that the full impact of leasing decisions took up to 5 years to play out. \nWhile leasing did provide a lift to sales in the short run, it often caused problems \nwhen the off-lease cars returned to the market. \nAfter 20 days the modeling process revealed the challenges leasing posed for \nthe company and indicated preliminary policy recommendations. However, before \nany consensus for action could be developed, the process had to be broadened to \ninclude other key decision makers throughout North American Operations (NAO). \nThe modeling team began to work with the Leasing Strategy Implementation \nTeam, a task force including people from marketing, finance, and other functions. \nTheir mandate was to boost market share and profitability. They didn’t think a \nmodel was necessary, didn’t trust the modeling approach, and opposed the initial \nrecommendations. Viewed through the lens of their mental model, this posi- \ntion was entirely rational. The success of leasing and strength of the used car \nmarket provided ample evidence that competitive leasing was essential to GM’s \nstrategy. ","page_start":75,"page_end":75,"token_count":646,"section_type":"other","chapter_number":2,"chapter_title":"System Dynamics in Action","chunk_index":89}
{"chunk_id":"451fa5998c8564e1","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"Team, a task force including people from marketing, finance, and other functions. \nTheir mandate was to boost market share and profitability. They didn’t think a \nmodel was necessary, didn’t trust the modeling approach, and opposed the initial \nrecommendations. Viewed through the lens of their mental model, this posi- \ntion was entirely rational. The success of leasing and strength of the used car \nmarket provided ample evidence that competitive leasing was essential to GM’s \nstrategy. \nWorking with your critics is often the best way to improve your understanding \nof complex issues. Over the next few months the modeling team refined the model \nstructure, improved the data and calibration, and tested the model over a wide \nrange of conditions. They met with the leasing team about once a month to present \ninterim results and listen to critiques. ","page_start":75,"page_end":75,"token_count":170,"section_type":"other","chapter_number":2,"chapter_title":"System Dynamics in Action","chunk_index":90}
{"chunk_id":"03591aad9a62971b","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"Chapter 2 System Dynamics in Action \n51 \n2.2.3 \nPolicy Analysis \nFIGURE 2-3 \nPolicy analysis \nThe policy matrix \nshows the \nsiinulated net \npresent value \n(NPV) of GM \nprofits as a \nfunction of GM’s \nlensing policy \n(no leasing or 2- to \n4-year terms) for \neach combination \nof economic \nscenario and \ncompetitor \nstrategy. \nAs their confidence in the formulations and calibration of the model grew, the team \nturned to policy analysis. Policy levers include lease terms and subvention levels, \nalong with purchase incentives, fleet sales, and various decision rules for produc- \ntion, The impact of each policy combination depended on the policies of the com- \npetitors and a host of market uncertainties, from changes in the economy, \ndemographics, gasoline prices, and interest rates to changes in the unit costs of \neach carmaker, car quality, and brand loyalty. \nThe combination of policies and market scenarios define a policy matrix. The \nteam used the model to find the optimal lease policies for each cell in the matrix. \nFigure 2-3 shows a sample illustrating the net present value of GM profits as a \nfunction of leasing policy (no leasing vs. 2-, 3-, or 4-year terms) for each combi- \nnation of competitor lease terms and economic growth scenario (stable, boom, or \nrecession). \nThe policy analysis showed that there was no going back: Profits without leas- \ning were consistently negative, reflecting the attractiveness of leasing to consumers \nand the prisoner’s dilemma that unilaterally stopping leasing while competitors \ncontinued to offer it dramatically reduced GM sales. \nThe analysis also showed that GM’s profits were consistently higher with 4- \nyear lease terms. Four-year terms were superior over a wide range of competitor \nstrategies and uncertainties. Longer terms have two main beneficial effects. First, \nthough shorter terms do shorten the trade-in cycle, the resulting glut of nearly new \ncars depresses used prices so much that the substitution of used for new purchases \noffsets their benefit. In terms of Figure 2-1, the Used Car Market, Used Car Qual- \nity, and Purchase Option loops overwhelm the benefit of the Lease Term and Lease \nCompetitor Lease Term \n2 year \nh \nz \n3 year \n~ \nh \nz \n4 year \nh \nz \nh \nz \nSource: Adapted from GM DSC diagram. Used with permission \n","page_start":76,"page_end":76,"token_count":524,"section_type":"other","chapter_number":2,"chapter_title":"System Dynamics in Action","chunk_index":91}
{"chunk_id":"08c440421bef9554","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"52 \nFIGURE 2-4 \nBathtub \ndiagram to \nillustrate \nthe impact \nof leasing \nPart I Perspective and Process \nIncentive loops. Four-year terms mean the cars coming off lease are less attractive \nsubstitutes for new cars, while still speeding the trade-in cycle somewhat. \nThe second benefit of longer terms is a more subtle, disequilibrium effect. By \nincreasing the substitutability between new and nearly new used cars, short-term \nleases increased the vulnerability of earnings to industry downturns. Rather than \nshowing complex diagrams such as Figure 2-1 to explain why, Pudar developed \nFigure 2-4, showing the stock of late model vehicles as a bathtub. The bathtub di- \nagram uses a simple metaphor to illustrate the dynamics of leasing. The stock of \nnew and new-car substitutes is increased by production and the flow of late model \nused cars coming off lease (and out of rental car fleets). Sales drain the tub. \nDuring recessions, auto sales drop. The water level in the tub rises. Carmakers \ncome under pressure to cut prices and subsidize leases to drain cars out of the tub \nfaster and also cut production to stop the inflow. However, the flow of new car sub- \nstitutes into the market from expiring leases cannot be turned off. When a recession \nhits, leases sold during the preceding boom continue to expire, boosting the level \nin the tub. Lower used car prices and concerns over future income lead more peo- \nple to turn their off-lease cars back to the lessor rather than exercising their option \nto buy. The larger the share of new cars sold through leasing, the larger the un- \nstoppable flow of returning vehicles. Prices are forced down even farther, and pro- \nduction cuts must be even deeper, significantly eroding profits. \nThe team used the bathtub diagram in presentations to senior managers \nthroughout the firm, including all brand managers. Of course the formal analysis, \nmodel structure, and other details were presented, but the bathtub provided a pow- \nerful metaphor to communicate an important dynamic insight and helped in the \ndifficult process of changing mental models. \nWhy do short-term leases make us more vulnerable \nduring an economic downturn? \nProduction \nNew Car Substitutes \nWhen industry demand falls, the flow of returning lease cars cannot be stopped: \n- Prices of used cars will be driven down; \n- New car transaction prices will be forced down; \n- Some returning lessees will opt for cheap used cars. \nPrice does not alter the supply of new car substitutes \nSource: GM Decision Support Center. Used with permission. \n","page_start":77,"page_end":77,"token_count":558,"section_type":"other","chapter_number":2,"chapter_title":"System Dynamics in Action","chunk_index":92}
{"chunk_id":"21492f4b3742d2a7","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"Chapter 2 System Dynamics in Action \n53 \nPudar and his team made two main recommendations to Zarella and other \nsenior managers in NAO. First, GM should shift incentives to favor longer leases \nand move the mix of the leasing portfolio toward a higher average term. Second, \nthey recommended that all proposals for new pricing and marketing programs for- \nmally include analysis of their impact on the used car market and its feedback to \nthe new car market. They recommended the market research organization create \nnew clinics to assess new/used/lease consumer choice behavior so that up-to-date \ndata would be available on an ongoing basis. They also supported changing the \nincentives and metrics for managers of the car groups to include the profit or loss \nGMAC realized as a result of leasing. \nMany brand managers and brand analysts were initially opposed to these rec- \nommendations. They argued that consumers had been conditioned to prefer short- \nterm leases. Competition was intense and GM’s market share had been slipping. \nFord, in particular, was aggressively pushing 2-year leases with significant sub- \nvention; unless GM responded in kind, they argued, market share would suffer \nmore. Given the tremendous pressure they faced to stay competitive, they were not \nwilling to sacrifice market share and profits today to avoid the possibility that leas- \ning might lead to problems in a few years. Brand managers and the sales organiza- \ntion put strong pressure on the senior management of NAO to increase residual \nlevels. They pointed to strong used car demand and rising used car prices to justify \nincreased residuals. They also argued that subvention levels should be increased \neven further above the higher residuals they were recommending. Finally, they ar- \ngued for a decrease in the fraction of off-lease vehicles GM predicted it would \nhave to take back at lease end. The costs of subvention are deferred because they \nare only realized when cars come off lease. Accounting rules require carmakers to \nset aside reserves to cover the expected cost of subvention; these reserves reduce \ncurrent period earnings. The amount set aside in reserves depends on the fraction \nof cars they expect to be returned. If customers exercise their option to buy when \ntheir lease expires then GMAC never has to pay the difference between the sub- \nvented residual and market value. Many brand managers believed that the strong \nused car market meant reserves were too high and could safely be cut, allowing the \ncar divisions to show higher current period profits while increasing market share. \nThey supported their case with spreadsheets in which recent trends toward higher \nused car prices and higher customer retention of off-lease vehicles were assumed \nto continue, that is, in which all feedbacks between the new and used markets \nwere cut. \nThe dynamic model, in contrast, suggested that used car prices would soon de- \ncline as the large volume of leased and fleet vehicles sold in the last few years \nreentered the market. The team’s analysis suggested some of the surge in used car \nprices was a temporary blip generated by the used car superstores as they bought ","page_start":78,"page_end":78,"token_count":643,"section_type":"other","chapter_number":2,"chapter_title":"System Dynamics in Action","chunk_index":93}
{"chunk_id":"71480fe722ae4e32","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"to continue, that is, in which all feedbacks between the new and used markets \nwere cut. \nThe dynamic model, in contrast, suggested that used car prices would soon de- \ncline as the large volume of leased and fleet vehicles sold in the last few years \nreentered the market. The team’s analysis suggested some of the surge in used car \nprices was a temporary blip generated by the used car superstores as they bought \nheavily to stock their lots. When that period of inventory building ended, used car \nsales would slump while the flow of cars coming off lease continued. As used \nprices fell below the contracted residuals, more customers would terminate their \nleases early and fewer would exercise their option to buy, decreasing the retention \nfraction and boosting the supply of late model used cars still more. GM would have \nto take a significant charge against earnings for residual reconciliation, and new car \nsales would suffer as customers opted for late model off-lease vehicles. ","page_start":78,"page_end":78,"token_count":201,"section_type":"other","chapter_number":2,"chapter_title":"System Dynamics in Action","chunk_index":94}
{"chunk_id":"3fc1e7e694799ece","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"54 \nFIGURE 2-5 \nUsed car prices, \n1989-1999 \nIndex shows the \nused car and truck \ncomponent of the \nUS Consumer \nPrice Index, \nseasonally \nadjusted. \nPart I Perspective and Process \nSenior managers at NAO decided to focus on 36- to 48-month terms and elim-\ninated 2-year leases. They also chose not to increase residual values and moved to \nfull accrual of residual risk in calculating reserves. These decisions made subven-\ntion much more expensive to brand managers and raised lease payments. \n2.2.4 \nImpact and Follow-up \nIn 1997 a flood of off-lease vehicles inundated the market. Used car prices fell sig-\nnificantly (Figure 2-5). The data show the aggregate for all used cars; the drop for \nlate model vehicles was much steeper and was most severe in the segments in \nwhich leasing had grown most rapidly. \nAs prices fell, fewer customers opted to keep their cars. The Consumer Bank-\ning Association reported that the fraction of vehicles from expiring full-term leases \nreturned to lessors jumped from 29% in 1997 to 39% in 1998. About three-quarters \nof all off-lease vehicles returned to lessors incurred losses; the average loss in 1998 \nwas $1878 per vehicle, 220% more than the average for 1993. \nGM's early action helped it avoid these losses, while other carmakers found \nthemselves facing huge reconciliation charges. Profits at Ford Credit Corporation \nfell $410 million in 1997 compared to 1996, a 28% drop, largely due to losses on \noff-lease vehicles. At GMAC, net income from automotive financing operations \nfell only $36 million, less than 4%, and overall GMAC profits rose more than 6%. \nIn 1997 several carmakers, including Ford and Nissan USA, attempted to prop \nup wholesale prices for their cars by paying dealers to keep off-lease cars instead \nof returning them to the manufacturer for sale at auction. Ford paid dealers $700 to \n$6000 (depending on the model) for each 2-year old off-lease vehicle the dealer \nagreed to keep, dipping into its residual reserves for the first time to do so. This \npolicy reduced the number of 2-year-old cars sold at auction, but of course, since \nretention of these cars added to dealer inventories, the number of these cars dealers \nbought at auction fell by the same amount, so wholesale prices continued to slide. \nIn 1998 GE Capital dropped its partnership with Chrysler to finance leases be-\ncause, as Automotive News (24 August, p. 1) reported, \nI \n150 \n0 \n0 \nII \n\"2' \nco \n1 \nN \nco \n0') \n, \n110 i , , \ni \ni \ni , \ni \n1988 \n1990 \n1992 \n1994 \n1996 \n1998 \n2000 \nSource: US Bureau of Labor Statistics, series CUSROOOSETA02. \n","page_start":79,"page_end":79,"token_count":657,"section_type":"other","chapter_number":2,"chapter_title":"System Dynamics in Action","chunk_index":95}
{"chunk_id":"b70a61985d4974d6","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"Chapter 2 System Dynamics in Action \n55 \nGE Capital Auto Financial Services got burned on residual-value losses in 1997. \nMuch of that was due to off-lease products from Chrysler . . . GE Capital cited \nresidual losses as one reason for the decline in operating profits for Consumer \nServices, the GE unit that includes Auto Financial Services. Profits fell from \n$1.3 billion in 1996 to $563 million [in 19971. \nIn 1998 net income at Ford Credit rose $53 million over the depressed level of \n1997 but remained 25% below the net for 1996.4 GMAC’s net on auto financing \nrose $74 million over 1997, a rise of 4% over 1996, and total GMAC profit for \n1998 rose $181 million over 1996, a gain of 15%. In 1998 Ford and other car- \nmakers belatedly followed GM’s lead and began to move away from short-term \nleasing. \nSince 1996 the leasing model has been updated several times, disaggregated \nfurther to separate the car and light truck segments, and used to examine issues \nsuch as sales of fleet vehicles. The model is now used on an ongoing basis by \nNAO’s Portfolio Pricing Team, the group responsible for review and approval of \nall pricing and incentive programs in North America. \nPudar, now Director of the DSC (renamed the Strategy Support Center [SSC]), \nreports that the SSC continues to apply system dynamics, in combination with \nother analytic methods, to a wide range of issues, from negotiating joint ventures \nwith foreign governments to designing business plans for new products, services, \nand business units. \nO N  ’TIME AND UNDER BUDGET: \nTHE DYNAMICS OF PROJECT MANAGEMENT5 \nIn 1970, Ingalls Shipbuilding of Pascagoula, Mississippi, won a major contract to \nbuild a fleet of 30 new destroyers for the US Navy. Combined with its 1969 con- \ntract for 9 LHAs (an amphibious assauWaircraft carrier), Ingalls found itself in the \nhappy position of landing two of the largest shipbuilding programs in the world \nand looked forward to healthy sales and profits for years to come. By the mid- \n1970s, however, Ingalls was in deep trouble, facing cost overruns projected to ex- \nceed $500 million. With annual sales in the mid-1970s of $500-800 million, the \noverrun threatened to sink Ingalls, and its parent Litton Industries, altogether. Ad- \njusted for inflation the overrun would exceed $1.5 billion in 1999 dollars. \nBoth contracts were awarded as total package procurement projects with a firm \nfixed-price contract structure in which Ingalls “was provided only with the perfor- \nmance specifications, and was thereafter solely responsible for all system design, \ndetailed design, materials procurement, planning, testing, and construction” \n(Cooper 1980, p. 22). \nBoth programs involved innovative and technically sophisticated new designs. ","page_start":80,"page_end":80,"token_count":657,"section_type":"other","chapter_number":2,"chapter_title":"System Dynamics in Action","chunk_index":96}
{"chunk_id":"e61445e8c141881d","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"Both contracts were awarded as total package procurement projects with a firm \nfixed-price contract structure in which Ingalls “was provided only with the perfor- \nmance specifications, and was thereafter solely responsible for all system design, \ndetailed design, materials procurement, planning, testing, and construction” \n(Cooper 1980, p. 22). \nBoth programs involved innovative and technically sophisticated new designs. \nThe DD class multimission destroyers were twice as large as earlier “tin cans.” The \n4Excluding one-time income from asset sales. \n5This section is based on Cooper (1980) and personal communication with Ken Cooper \n(president, Pugh-Roberts Associates), Rich Goldbach (formerly with IngallsLitton Industries and \ncurrently president, Metro Machine Corporation), and many others at hgh-Roberts Associates. \nI’m grateful for their help. ","page_start":80,"page_end":80,"token_count":182,"section_type":"other","chapter_number":2,"chapter_title":"System Dynamics in Action","chunk_index":97}
{"chunk_id":"e3fae5774d5fe5f5","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"56 \nPart I Perspective and Process \nLHA was also an entirely new design. More than 20 stories high and three football \nfields long, each LHA carries a complement of 2000 battle-ready Marines and 200 \ncombat vehicles that can be deployed by landing craft and several dozen heli- \ncopters. The DD and LHA contracts required a massive mobilization of Ingalls’ re- \nsources. Already one of the largest shipyards in the world, Ingalls doubled its \nworkforce to more than 20,000. During this time there were shortages of some \nskilled trades and critical materials. Ingalls also had to create new organizational \nstructures to manage the two programs. \nLarge-scale projects are among the most important and consistently misman- \naged endeavors in modern society. Large-scale projects include the design and con- \nstruction of civil works and infrastructure (e.g., bridges, tunnels, power plants, and \ntelecommunications networks), military systems (e.g., aircraft, ships, and weapons \nsystems), and new products in every industry (e.g., software, automobiles, semi- \nconductor chip design, and wafer fab construction). \nProjects of all types routinely experience cost overruns, delays, and quality \nproblems. Cooper and Mullen (1993) examined a sample of large civilian and mil- \nitary projects (averaging 130,000 person-hours of planned work over about a year \nfor the civilian projects and 170,000 person-hours of planned work over more than \n2 years for the military projects). They found commercial projects cost 140% and \ntook 190% as long as originally scheduled, while defense projects cost 310% of the \noriginal estimates and took 460% as long to complete. \nDelays, cost overruns, and quality problems in commercial new product de- \nvelopment can kill a company, particularly in high-velocity industries such as soft- \nware and high technology. Overruns and delays in civil works and military projects \ncan affect the economic vitality of a region and the ability of a nation to defend \nitself. \n2.3.1 \nThe Claim \nThe Navy and Ingalls disagreed sharply over the causes of the delays and cost \noverrun. Ingalls believed the majority of the cost overrun was caused by the ac- \ntions of the Navy. As is common in large, lengthy projects, the technologies and \nsystems to be used in the DD and LHA ships were not mature at the time the con- \ntracts were awarded. Technologies for navigation, intelligence, communications, \nand weapons systems, for example, were advancing rapidly, and the Navy natu- \nrally sought to incorporate the most up-to-date systems in the ships. Rich Gold- \nbach, then a senior manager at Ingalls and one of the key participants in the claim, \ncommented that “Ingalls was convinced that the government interfered with the \ndesign for the LHA from the start by micro-managing the design pro~ess.~’ \nAs \nhigh-level design, detailed design, and even construction proceeded, Ingalls re- ","page_start":81,"page_end":81,"token_count":646,"section_type":"other","chapter_number":2,"chapter_title":"System Dynamics in Action","chunk_index":98}
{"chunk_id":"9f39edef02d1f1da","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"rally sought to incorporate the most up-to-date systems in the ships. Rich Gold- \nbach, then a senior manager at Ingalls and one of the key participants in the claim, \ncommented that “Ingalls was convinced that the government interfered with the \ndesign for the LHA from the start by micro-managing the design pro~ess.~’ \nAs \nhigh-level design, detailed design, and even construction proceeded, Ingalls re- \nceived many thousands of design changes from the Navy. Ingalls believed that \nmuch of the overrun was caused by the imposition of these design changes. After \nthe Navy repeatedly refused to compensate Ingalls for these costs, Ingalls brought \na claim against the Navy to recover the $500 million in losses it expected. \nSuing your customers is always tricky. In the case of Ingalls it was particularly \ndelicate. Ingalls brought the claim early, while the two programs still had many \nyears to run. Ingalls had to continue to manage the two programs and maintain a ","page_start":81,"page_end":81,"token_count":213,"section_type":"other","chapter_number":2,"chapter_title":"System Dynamics in Action","chunk_index":99}
{"chunk_id":"2051930463ccc93b","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"Chapter 2 System Dynamics in Action \n57 \ngood working relationship with the Navy while simultaneously pursuing the claim. \nFurther, since commercial shipbuilding was in decline in the US, the Navy was \nIngalls’ most important customer and would be for the indefinite future.6 \nThe Navy conceded that it had generated the design changes but argued that \ntheir impact was limited to the direct cost of reissuing the specifications and re- \nworking the affected engineering drawings. The total cost of these direct impacts \nwas a small fraction of the total claim. Ingalls countered that a design change could \ncreate much larger costs, for example, by altering the sequence of tasks and re- \nquiring overtime and unscheduled hiring that interfered with other phases of the \nwork, diluted experience, and reduced productivity even in work phases not di- \nrectly affected by change orders. Ingalls believed such ripple effects could multi- \nply the direct impact of a change notice many times, leading to significant overall \n“delay and disruption.” \nThe Navy countered that the supposed delay and disruption were actually the \nresult of contractor mismanagement or deliberate underbidding to win the contract. \nDisputes over the delay and disruption component of prior claims throughout the \ndefense industry often dragged out over many years. The Navy had never paid a \nsignificant delay and disruption claim. \n2.3.2 \nInitial Model Development \nIngalls spent several years pursuing the claim, but traditional project management \ntools did not provide a means to quantify the ripple effects. Ingalls turned to \nsystem dynamics to quantify the delay and disruption created by Navy design \nchanges. The model, developed by Pugh-Roberts Associates of Cambridge, \nMassachusetts, simulated all phases of the DD and LHA projects, from the award \nof the contract to the delivery of the last ship, then 5 years in the future. \nThe model ultimately contained many thousands of equations, a very large \nmodel indeed (especially considering the state of computer technology at the time). \nIt began, however, as a much smaller model designed to illuminate the basic feed- \nbacks that might be responsible for ripple effects. The modeling team worked \nclosely with Ingalls’ claim management organization, including managers from all \nmajor phases of each program and key attorneys. Lead modeler Ken Cooper de- \nscribed the process this way (1980, pp. 26-27): \nThe Ingalls project team guided and reviewed the decision of what elements \nto include in the model, and with what measures and in what detail to include \nthem . . . [Dlozens of individuals in all stages of shipbuilding, from workers \nthrough vice presidents, were interviewed. They offered qualitative and quantitative \nobservations on ship design and construction. As the design of the model began to \ngel, the numerical data requirements were clarified; a massive data collection ef- \nfort, in concert with other elements of the claim, was undertaken. These data and \ninformation provided enough material to assemble a preliminary mathematical \nmodel of a single work phase. The equations, parameters, and detailed output \nwere reviewed by the project team, and several model modifications made. ","page_start":82,"page_end":82,"token_count":648,"section_type":"other","chapter_number":2,"chapter_title":"System Dynamics in Action","chunk_index":100}
{"chunk_id":"c4b67893e2967305","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"observations on ship design and construction. As the design of the model began to \ngel, the numerical data requirements were clarified; a massive data collection ef- \nfort, in concert with other elements of the claim, was undertaken. These data and \ninformation provided enough material to assemble a preliminary mathematical \nmodel of a single work phase. The equations, parameters, and detailed output \nwere reviewed by the project team, and several model modifications made. \n6Due in part to the problems encountered in the program, the number of LHAs utlimately \nbuilt was cut to 5. LHA5, the USS Peleliu, was completed in mid 1980, as was the last DD class \ndestroyer, USS Fletcher. ","page_start":82,"page_end":82,"token_count":151,"section_type":"other","chapter_number":2,"chapter_title":"System Dynamics in Action","chunk_index":101}
{"chunk_id":"76cb2fe79b23004f","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"58 \nBe Done \nPart I Perspective and Process \nReally Done \n2.3.3 \nDynamic Hypothesis \nWork Being \nDone \nFIGURE 2-6 \nStock and flow \nstructure of a \nproject phase \nRectangles \nrepresent the \nstock of tasks, \nstraight lines and \nvalves represent \nflows of tasks \nbetween \ncategories \n(chapter 6). \nQuality is the \nfraction of tasks \ndone correctly. \nThe diagram is \nhighly simplified \nand omits several \ntask categories \nand flows included \nin the full model. \nKnown \nv \nRework \nRework \nA full description of the feedback structure of the model is beyond the scope of this \ndiscussion; this section provides only a few illustrations of the type of ripple ef- \nfects the model addressed. \nFigure 2-6 shows a highly simplified stock and flow structure for the flow of \nwork within a single project phase. The tasks could be high-level systems design \ntasks, preparation of detailed engineering drawings, or construction of a vessel. \nThe rectangles and valves represent the stock and flow structure of the ~ y s t e m . ~  \nThe stocks represent the accumulations of work in different categories; the valves \nrepresent the flow of tasks through the system. Initially all tasks are in the stock of \nWork to be Done. Completing a task requires resources such as a productive labor \nforce with appropriate skills; the number and productivity of the labor force vary \nover time as project conditions change. Tasks can be done correctly or incorrectly, \ndepending on the quality of the work. Tasks done correctly add to the stock of \nWork Really Done while tasks containing errors of various types add to the stock \nof Undiscovered Rework. Work quality is often quite low, as new-product devel- \nopment and large-scale projects usually involve new technologies, materials, and \nsystems and often involve unique new circumstances. Cooper and Mullen (1993) \nUndiscovered \nRework \nPeople \nProductivity \nQuality \nDiscovery \nObsolescence \nRate t \nCustomer \nChanges \nSource: Adapted from a diagram developed by Pugh-Roberts Associates, Cambridge, MA. Used with \npermission. \n7Mathematically, each stock is the integral of the flows in less the flows out. Stocks and flows \nare discussed in chapters 6 and 7. \n","page_start":83,"page_end":83,"token_count":492,"section_type":"other","chapter_number":3,"chapter_title":"The Modeling Process","chunk_index":102}
{"chunk_id":"8d688a0ca2e7723b","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"Chapter 2 System Dynamics in Action \n59 \nfound the average fraction of work done correctly the first time in their sample to \nbe 68% for commercial projects and just 34% for defense projects. \nUncovering errors takes time and resources. Often, errors are only detected by \na downstream phase, as when a design flaw is discovered during the construction \nphase. Tasks in the stock of undiscovered rework are therefore perceived to be \ncomplete and are treated as done by the organization. Discovery of errors by qual- \nity assurance, testing, or a downstream phase moves the imperfectly done tasks to \nthe stock of Known Rework. Cooper and Mullen (1993) found average rework dis- \ncovery delays of about 9 months for both civil and military projects, a significant \nfraction of scheduled project duration. \nChanges in customer specifications have effects similar to the discovery of \nerrors. Specification changes make some work previously done correctly obsolete, \nmoving those tasks from the stock of Work Really Done to the stock of Known \nRework. The affected phase must recall work it previously released to other phases \nand upon which those downstream phases have based their own work. The or- \nganization must then increase the resources and attention devoted to rework, slow- \ning completion of remaining basework tasks and potentially disrupting the entire \nproject. * \nObviously customer changes that make completed design work obsolete are \ncostly because the affected tasks must be reworked; these are the direct impacts of \nchanges the Navy was willing to pay for. But the indirect effects can be many times \nlarger. Figure 2-7 shows a few of the feedbacks that explain how the indirect ef- \nfects of customer changes could be amplified. \nAs a project falls behind contractors have only a few choices. They can put the \nexisting workforce on overtime, thus increasing the effective number of people \nworking on the project. This negative or balancing feedback is the intended effect \nof overtime and is shown in the diagram by solid lines. However, excessive or ex- \ntended overtime causes fatigue and burnout. Productivity and quality fall, reducing \nprogress and increasing the stock of undiscovered rework. Burnout also leads to \nabsenteeism and attrition as employees request transfers or quit, reducing the num- \nber of people on the project. These unintended effects, shown as dashed lines, form \npositive (self-reinforcing) feedbacks that act as vicious cycles to undercut the \nprogress-enhancing effect of overtime. To avoid the side effects of overtime more \npeople can be hired (another balancing loop). But rapid hiring dilutes the experi- \nence base of the employees. If the pool of qualified workers in the region is small \nrelative to hiring needs, accelerated hiring lowers the average quality of available \ncandidates. Recruiting standards often erode so vacancies can be filled quickly. All \nthese effects lower productivity and quality and slow progress even as manage- \nment seeks to boost headcount and speed progress. \n‘Most large military and civilian projects specify deadlines for delivery. Failure to meet the ","page_start":84,"page_end":84,"token_count":636,"section_type":"other","chapter_number":3,"chapter_title":"The Modeling Process","chunk_index":103}
{"chunk_id":"bf3b4864a21b14c4","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"ence base of the employees. If the pool of qualified workers in the region is small \nrelative to hiring needs, accelerated hiring lowers the average quality of available \ncandidates. Recruiting standards often erode so vacancies can be filled quickly. All \nthese effects lower productivity and quality and slow progress even as manage- \nment seeks to boost headcount and speed progress. \n‘Most large military and civilian projects specify deadlines for delivery. Failure to meet the \ndeadline leads to penalties, known as liquidated damages (LDs), for every day the project is late; \nLDs can rapidly mount to many millions. In disputes such as discussed here the LDs form the \nprimary basis for the customer’s counterclaim against the contractor. In several cases for which \nsystem dynamics models have been used the difference between the contractor delay and disruption \nclaim and the customer’s counterclaim was several billion dollars. Even when LDs do not apply, as \nfor in-house commercial product development projects, every day the project is late erodes the \ncompetitiveness of the product and the sales and profits it can generate. ","page_start":84,"page_end":84,"token_count":224,"section_type":"other","chapter_number":3,"chapter_title":"The Modeling Process","chunk_index":104}
{"chunk_id":"fc50c1526eaf6d86","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"60 \nI \nI \nf \n\\ \n\\ \n/ \n1 \nPart I \nand Process \nSide effects of corrective measures lead to vicious cycles \nAs customer \ncause a project to fall \ncan accelerate the \nschedule, use \nand hire more people, forming negative feedbacks designed \nto get the \nback on track (solid lines). However, each of these ne(]aIIVe \ngers side effects that undercut the intended \nforming vicious \nbacks, shown by the dashed lines). \n/' ,,-\n\" \n/' \n-\n......... \n\" \n.... \n'-\n/' \n/ \n/' \n/ \n/ \nSkill, Quality ___ _ \nA \n_-\n....... \n'\\ '< / \n\\ / '\\ 1 \n\\1 \nI \nWork, \nWorksite Congestion, \nCoordination Problems, \nMorale Problems \n/ \n.,,-\n/,-r \n/ \nApparent \nObsolescence \nRate \nCustomer \nChanges \n, \n\\ \n\\ \nI \nJ \nI \nI \n/ \nAcceleration \nSource: Adapted from a diagram developed by \nInn--H(',nAI1<'lAssociates, Cambridge, MA. Used with permission. \nAs a project falls behind .,,,,,,,,\", ..... ,,,u,, management often \nemployees to \nwork harder and compresses \nby overlapping \nthat should be \nin \nApparent \nrises, but there are also unanticipated side \nvu,\",,,,,,,. Schedule compression \npeople to do work out \nsequence, meaning \ninformation or \nfrom upstream \nare not available. \nmay start before \ndesign is mature and stable. Prototype \nbuilds may \nbefore \nspecifications are \n9 Schedule com-\nnrC'\",,,,>\" also leads to work site \nbe it overloaded CAD/CAM facilities \nIVlanal';ers and \nfind their \ntoday havc \nto shorten \ncycle times. Successful \nand even in \nconcurrent programs the \nbetween different \ncan be too aggressive, \nto excessive rework. See Ford and Sterman (l998a) and (l998b) for \ndynamics \nof concurrent engineering, with \nto semiconductor \nalso section 14.5. \n","page_start":85,"page_end":85,"token_count":455,"section_type":"other","chapter_number":3,"chapter_title":"The Modeling Process","chunk_index":105}
{"chunk_id":"df7f191e47542f54","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"Chapter 2 System Dynamics in Action \n61 \ntime is increasingly consumed by meetings to work out conflicts arising from the \naccelerated schedule and ad hoc, last-minute coordination of out-of-sequence ac- \ntivities. Stress from work pressure, increased fire fighting, and constant changes in \nschedules can lead to morale problems that cut productivity and quality and in- \ncrease absenteeism and attrition. These effects are further multiplied by the rework \ncycle. Lower quality means more tasks contain errors. Because many errors are not \ndiscovered immediately, subsequent work begins using designs, materials, and in- \nformation that appear to be correct at the time but are later recalled for rework. \nThus customer changes can disrupt and delay upstream activities such as sys- \ntem design. These phases must then recall some previously released work, so de- \nlays and quality problems cascade to downstream phases such as detailed design, \nmaterials procurement, and construction. The downstream phases must then redo \nmuch of their job, often at great expense (particularly when construction has al- \nready begun). To the extent different projects such as the DD and LHA programs \nshare resources such as work sites, workers, support infrastructure, and manage- \nment, problems in one can spill over to another. \nThe diagrams above are highly simplified, and many other important feed- \nbacks captured in the full model are omitted (how many other such effects can you \nidentify from your own experience?). But they illustrate how apparently small \nchanges in customer specifications can snowball into much larger delay and dis- \nruption despite management’s best efforts to get the project back on track. The \nmodel augmented traditional project analysis through the explicit recognition of \nthe rework cycle, variable staff productivity and quality, and the bane of most de- \nvelopment projects-undiscovered rework. Conventionally, any indirect effects \nwere viewed as a small additional percentage over the direct costs. Explicit recog- \nnition of the feedback structure described here helped explain how the indirect ef- \nfects of customer changes could be many times larger than the direct effects. \n2.3.4 The Modeling Process \nThe modeling team assembled the full model by replicating the generic project \nphase module to represent each phase for each ship in each program. The major ac- \ntivities (system design, detailed design, procurement, construction, etc.) were dis- \naggregated further where necessary; for example, construction was divided into \nseveral major activities (e.g., hull, piping, electrical, etc.) and the construction \nworkforce was disaggregated by major crafts (e.g., steelworkers, electricians, etc.). \nConstruction progress for each ship was represented separately. Each instance of \nthe generic phase module was calibrated to the particular activity it represented. \nThe individual activities, phases, and programs were linked by additional structure \nrepresenting overall program management, progress monitoring, scheduling, hir- \ning, resource allocation, and so on. \nA model of this scope could never be built, calibrated, maintained, or under- \nstood if such a modular architecture were not used. To represent such a diverse ar- ","page_start":86,"page_end":86,"token_count":651,"section_type":"other","chapter_number":3,"chapter_title":"The Modeling Process","chunk_index":106}
{"chunk_id":"d6f4ed6c5101b62a","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"the generic phase module was calibrated to the particular activity it represented. \nThe individual activities, phases, and programs were linked by additional structure \nrepresenting overall program management, progress monitoring, scheduling, hir- \ning, resource allocation, and so on. \nA model of this scope could never be built, calibrated, maintained, or under- \nstood if such a modular architecture were not used. To represent such a diverse ar- \nray of activities the generic module had to be extremely robust. Considerable effort \nwent into extreme conditions tests to ensure that the model behaved appropriately \nunder any conceivable combination of inputs or conditions (see chapter 21). The \nteam worked to ensure the model was consistent with all available information, ","page_start":86,"page_end":86,"token_count":148,"section_type":"other","chapter_number":3,"chapter_title":"The Modeling Process","chunk_index":107}
{"chunk_id":"15cb5eae768c927f","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"62 \nPart I Perspective and Process \nincluding the qualitative assessments gleaned from interviews and observations in \nthe field, not only the numerical data. \nEarly on the team compared the output of the model to the history of the pro- \njects to date. The purpose of the comparison to historical behavior was not to prove \nto Ingalls that the model was right, but rather to identify areas where the model \nrequired improvement. These comparisons sometimes identified omissions and \nproblems, leading to revisions in model structure and parameters. Other times, \ndiscrepancies between model and data suggested the data were inconsistent or \nincomplete, leading to additional data collection, interviews, and refinement of the \nvalues and justification for parameters. This process led to three major and many \nminor iterations in the model. \nThe model ultimately replicated the historical performance of the projects \nquite well. But, as discussed in chapter 21, it is quite easy to fit a model to a set of \ndata. It is also necessary that the model replicate the data for the right reasons, rea- \nsons the modelers and Ingalls’ management understand and can explain in plain \nlanguage. While particularly important in the adversarial setting of a large lawsuit, \nthese are important in any modeling project. Ultimately the clients for any model- \ning project will take action only to the extent their mental models have changed. In \nturn, the clients’ mental models are unlikely to change unless they have confidence \nin the integrity and appropriateness of the formal model. Developing that confi- \ndence requires a modeling process that gives the clients the opportunity to delve as \ndeeply into the details as they want, to question any assumption, and to challenge \nany result. Opening the model to review by the clients is also essential for the mod- \nelers to ensure it addresses the issues the client cares most deeply about and to gen- \nerate the best model for that purpose. \nTo uncover model flaws and create opportunities for the Ingalls team to chal- \nlenge the model the modeling team used several other procedures. Cooper (1980, \np. 27) explains: \nFirst, we established at the outset explicit limits of reasonableness for each numeri- \ncal parameter in the model; these would not be violated in order to achieve a more \n“accurate” simulation. Further, the numerical parameters in different sections of the \nmodel were required to be consistent with one another in terms of relative magni- \ntude. These guidelines . . . were never violated. The model was also subjected to a \nseries of “shock tests” to assess robustness in responding as the company would to \nradically different circumstances. Finally, several different plausible combinations \nof equations and parameters were tested to explore “alternative models” that might \naccurately represent Ingalls operations. \nAs time passed the model-generated projections for schedule and costs turned out \nto be quite close to what actually happened, further boosting confidence in the abil- \nity of the model to capture the underlying structure of the projects. \nThe modeling team assessed the systemwide effects of the Navy’s design ","page_start":87,"page_end":87,"token_count":648,"section_type":"other","chapter_number":3,"chapter_title":"The Modeling Process","chunk_index":108}
{"chunk_id":"4478efb6c467ac79","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"radically different circumstances. Finally, several different plausible combinations \nof equations and parameters were tested to explore “alternative models” that might \naccurately represent Ingalls operations. \nAs time passed the model-generated projections for schedule and costs turned out \nto be quite close to what actually happened, further boosting confidence in the abil- \nity of the model to capture the underlying structure of the projects. \nThe modeling team assessed the systemwide effects of the Navy’s design \nchanges by comparing two simulations. The “as-built’’ case was the historical sim- \nulation including all the Navy design changes; this was compared to the “would \nhave” case in which the design changes were removed. The difference in total costs \nand completion times represented the cumulative impact of the design changes. \nSensitivity analysis then placed confidence bounds around the estimated cost of the \ndelay and disruption. ","page_start":87,"page_end":87,"token_count":179,"section_type":"other","chapter_number":3,"chapter_title":"The Modeling Process","chunk_index":109}
{"chunk_id":"06078fd5e5139198","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"Chapter 2 System Dynamics in Action \n63 \nThe model also allowed Ingalls to estimate the role of its own management de- \ncisions in the overrun. Simulations of alternative policies showed how much lower \nproject costs and duration might have been if Ingalls had managed the project more \neffectively. The ability to quantify the contribution of customer interference and \ncontractor mismanagement to the delays and cost overrun was a critical part of the \nprocess. Goldbach (personal communication, 1999) described the dispute resolu- \ntion process prior to the development of the system dynamics model as \njust a bunch of finger-pointing. A contractor would say “Here’s what the govern- \nment did wrong” and blame all their problems on that. Then the government would \nsend the GAO [General Accounting Office] in to find all the things the contractor \ndid wrong. It went nowhere. \nat the time there was no way to separate the impact of government and contractor \nproblems or examine the synergy between them. In the end we had to have the \nability to say “here are the things the contractor didn’t do well and here are the \nthings the government didn’t do well, and here’s how much each contributed to \ncosts and time.” \nThe problem was that with the [project management] technologies available \nThe adversarial setting of a large dispute accentuates the need for a robust, well- \nunderstood model whose parameters and assumptions can be justified with inde- \npendent data. As part of the discovery process in the lawsuit Ingalls had to turn the \nmodel, documentation, analysis, and supporting data over to the Navy, which hired \nits own experts to try to debunk it. A common criticism of such models, and one \nused by the Navy, is that the parameters and assumptions are “cooked” to achieve \na preselected outcome. “Garbage in, garbage out,” they would say, and argued that \nthe model was merely a complicated ruse designed to impress the court. \nThe Navy’s outside experts examined and criticized the model. After they de- \nlivered their reports, the modeling team, along with Ingalls management and their \nattorneys, Navy officials, the government’s attorneys, and the Navy’s outside ex- \nperts met for several days in a large conference room to discuss the critique. Each \nissue was discussed in detail, from high-level issues of modeling methodology and \nmodel architecture to specific equations and parameters. Ingalls and the modeling \nteam then had a chance to respond. They revised the model to address the criti- \ncisms leveled by the Navy’s experts. In the next round of meetings, they showed \nthe Navy team how they had modified the model to incorporate the changes the \nNavy’s experts wanted. Repeating the comparison of the as-built to would have \ncases, the modeling team found that the fraction of the overrun and delay caused \nby the Navy’s design changes had actually increased.’O \nThe Navy clearly expected that incorporating the critiques and parameter esti- \nmates of its experts into the model would show more of the overrun was due ","page_start":88,"page_end":88,"token_count":644,"section_type":"other","chapter_number":3,"chapter_title":"The Modeling Process","chunk_index":110}
{"chunk_id":"8403bc6570b3829d","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"the Navy team how they had modified the model to incorporate the changes the \nNavy’s experts wanted. Repeating the comparison of the as-built to would have \ncases, the modeling team found that the fraction of the overrun and delay caused \nby the Navy’s design changes had actually increased.’O \nThe Navy clearly expected that incorporating the critiques and parameter esti- \nmates of its experts into the model would show more of the overrun was due \nto contractor mismanagement. The counterintuitive result that the claim value \n‘OGiven the technology of the time (mainframe computers operating with time-sharing, teletype \nprinters, and 100 baud acoustic coupler modems) it was not feasible to run the model live in the \nmeetings. The model developers painfully recall overnight sessions running the model on the \nlargest computer then available. Today it is possible to bring the model to such meetings on a laptop \nand make many changes in assumptions on the spot, slashing the cycle time for experimentation \nand greatly increasing client involvement. ","page_start":88,"page_end":88,"token_count":213,"section_type":"other","chapter_number":3,"chapter_title":"The Modeling Process","chunk_index":111}
{"chunk_id":"9450a99d9abc43f6","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"64 \nPart I Perspective and Process \nincreased demonstrated to all that it is actually quite difficult to engineer a model \nto generate a preselected result. Goldbach commented, “For the first time the Navy \nsaw that Ingalls had a credible case.” Intensive negotiations then began at the high- \nest levels of Litton and the Navy. In June 1978 the parties settled out of court. In- \ngalls received $447 million. \nThus the clients for the modeling work were not only Ingalls’ management and \nattorneys but also the court and the Navy. It may seem counterintuitive to include \nthe opposing side among the client group for a model used in a lawsuit. And indeed \nthe Navy attempted to discredit the model and have it excluded from the proceed- \nings. However, to the extent the model became the focus, even through the critique \nof the Navy experts, the structures in the model and the dynamics they generated \nstarted to become the common framework for discussion of the claim by all par- \nties. The process of changing mental models was well underway. This process has \nsince been observed in many other conflicts (see, e.g., Weil and Etherton 1990, Re- \nichelt and Sterman 1990). Experience shows that the better the oppositions’ under- \nstanding of the model, the more likely it will be influential in the resolution of the \ndispute. \nThough the setting here was a lawsuit, the process applies to any modeling \nproject. Even when the clients for the work are all from the same management \nteam, there will always be different sides and factions, proponents and opponents \nof each policy. Only the intensive involvement of the clients in the modeling \nprocess can create the understanding of the issues needed to change entrenched \nmental models and lead to consensus for action. \n2.3.5 \nContinuing Impact \nThe system dynamics model was the sole technical basis for the delay and disrup- \ntion component of Ingalls’ claim against the Navy. Estimates from the attorneys \nand Ingalls management “place the model’s dollar contribution to the settlement \nbetween $170-350 million” (Cooper 1980, pp. 28). But these sums, large as they \nare, underestimate the benefits of the modeling process. The lawsuit itself can be \nviewed as a large project that generated its own ripple effects. By achieving a set- \ntlement a little over 2 years after beginning the modeling process (a very short in- \nterval in such large disputes), \nThe direct dollar costs of continuing the claim effort were avoided [legal fees and \ncourt costs]. Even more significant, however, was the vast amount of managerial \nand professional time and talent (an entire “claim organization” of over 100 Ingalls \npersonnel) that would have continued to be spent on something other than ship \ndesign and construction . . . Above all, the elimination of the adversary relationship \nbetween Ingalls and its best customer was a milestone achievement (Cooper 1980, \np. 28). \nSince this groundbreaking work Pugh-Roberts and other firms have gone on to ap- ","page_start":89,"page_end":89,"token_count":656,"section_type":"other","chapter_number":3,"chapter_title":"The Modeling Process","chunk_index":112}
{"chunk_id":"12c96691f3a2d406","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"and professional time and talent (an entire “claim organization” of over 100 Ingalls \npersonnel) that would have continued to be spent on something other than ship \ndesign and construction . . . Above all, the elimination of the adversary relationship \nbetween Ingalls and its best customer was a milestone achievement (Cooper 1980, \np. 28). \nSince this groundbreaking work Pugh-Roberts and other firms have gone on to ap- \nply system dynamics to disputes totaling many billions of dollars. These range \nfrom other military and commercial shipbuilding projects to aerospace and \nweapons systems, power plants, civil works such as the cross-channel tunnel, and \nsoftware projects. In most cases contractors use the models in actions against their \ncustomers. In each case the defendants have sought to debunk the models and ","page_start":89,"page_end":89,"token_count":168,"section_type":"other","chapter_number":3,"chapter_title":"The Modeling Process","chunk_index":113}
{"chunk_id":"48f60d3714e16b40","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"Chapter 2 System Dynamics in Action \n65 \nexclude them from the allowable expert testimony but each time the models have \nbeen allowed and have contributed to favorable settlements. \nWhile the dollar value of these actions is impressive and of undoubted benefit \nto the plaintiffs, the damage (the cost overrun) has already been done, and the dis- \npute is only over who pays. The real leverage lies in using these models proac- \ntively so overruns and delays are avoided in the first place. Since the first Ingalls \nmodel, many organizations have gone on to apply similar models to the manage- \nment of large-scale projects in a wide range of industries (for examples see sec- \ntions 6.3.4 and 14.5).” Ingalls itself has used descendants of that first model to \nhelp manage virtually every program since the LHA and DD. The benefits of such \nproactive modeling are harder to quantify but likely outweigh the value of dispute \nsettlements many times. \nAs one illustration, Rich Goldbach left Ingalls in the late 1970s to head up \nMetro Machine, a shipyard in Norfolk, Virginia. Then small and struggling, Metro \ntoday is a highly successful yard specializing in repair and refitting work for the \nNavy with about 700 employees and sales of about $90 milliodyear. Goldbach in- \ntroduced a wide range of innovative management practices including employee in- \nvolvement. The firm is 100% employee owned, with universal participation in the \nemployee stock ownership plan. Metro has won several awards for the high qual- \nity of their work, including National Small Business Prime Contractor of the Year \nand the US Navy AEGIS Excellence Award “for superior performance in quality, \nreliability, delivery and cost”-the first ever given to a repair yard. \nModels continue to play an important role. Goldbach commissioned the de- \nvelopment of a simulation model to project the financial consequences of various \ndecisions for up to 10 years. Metro uses the model to assess acquisitions, capital \ninvestment decisions, new ventures, and all aspects of bidding for jobs. \nWe built the model to a spec[ification] I provided based on what I learned from the \nIngalls model. The model helps the government understand our bids better. It lets \nthe DCAA [Defense Contract Audit Agency, a Department of Defense agency that \naudits defense contractor bids and assesses their ability to do the work] look at al- \nternative scenarios. We use the model interactively with them. There is an on-site \nDCAA auditor who knows the model. She can ask us to run any set of assumptions, \nand we usually get the answer back in an hour (Goldbach, personal communication, \n1999). \nThe financial simulation has been very effective, but far more important, Goldbach \nsays, are the lessons he learned about the challenges of managing complex \nsystems: \nFor the [shipbuilding] industry I thought I was a pretty sophisticated manager, but it \nchanged my whole perspective. I never had the ability I think I got from working ","page_start":90,"page_end":90,"token_count":651,"section_type":"other","chapter_number":3,"chapter_title":"The Modeling Process","chunk_index":114}
{"chunk_id":"f563704459f4013d","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"and we usually get the answer back in an hour (Goldbach, personal communication, \n1999). \nThe financial simulation has been very effective, but far more important, Goldbach \nsays, are the lessons he learned about the challenges of managing complex \nsystems: \nFor the [shipbuilding] industry I thought I was a pretty sophisticated manager, but it \nchanged my whole perspective. I never had the ability I think I got from working \nwith system dynamics to ask ”how will this decision ripple out?” I got to the point \nthat I had the mental self-discipline to fight my impulses and not just do the macho \nthing when there’s a problem. The playing field changes while you’re playing the \n“See also Abdel-Hamid and Madnick (1989a-c, 1990, 1991); Cooper (1993a-c, 1994); Cooper \nand Mullen (1993); Ford and Sterman (1998a-b); Homer et al. (1993); Weil and Etherton (1990); \nand Yourdon (1993). ","page_start":90,"page_end":90,"token_count":227,"section_type":"other","chapter_number":3,"chapter_title":"The Modeling Process","chunk_index":115}
{"chunk_id":"71c6ad2d71e123c2","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"66 \nPart I Perspective and Process \ngame. Now I ask how customers, employees, suppliers and so on will react to what \nwe might do. Sometimes I get it right and sometimes I don't. \nIt permeates every aspect of my thinking. I'm a different person than I was \nbefore. \n2.4 \nPLAYING THE MAINTENANCE GAME'* \nIn 1991, Winston Ledet, then a manager in Gulf Coast Regional Manufacturing \nServices at Du Pont, reflected on the results of an in-house benchmarking study \ndocumenting a large gap between Du Pont's maintenance record and those of the \nbest-practice companies in the global chemicals industry. \nThe benchmarking study revealed an apparent paradox: Du Pont spent more \non maintenance than industry leaders but got less for it. Du Pont had the highest \nnumber of maintenance employees per dollar of plant value yet its mechanics \nworked more overtime. Spare parts inventories were excessive yet the plants re- \nlied heavily on costly expedited procurement of critical components. Most \ndisturbing, Du Pont spent 10-30% more on maintenance per dollar of plant value \nthan the industry leaders, while at the same time overall plant uptime was some \n10-15% lower. \nMany people found the results of the benchmarking study to be counterintu- \nitive. Their mental models suggested that equipment quality should suffer and up- \ntime should be low in a company that spends little on maintenance, while spending \nmore on maintenance should yield high-quality equipment and high uptime. How \ncould Du Pont be spending more and getting less? \nMany people blamed the problem on the difficult competitive environment. \nThe chemicals industry is mature and intensely competitive. Because there is little \nproduct differentiation for bulk (commodity) feedstocks, chemical manufacturers \ncompete on other dimensions, mostly cost and delivery reliability. Since the early \n1970s the industry was hit by one crisis after another: Two severe energy crises \nwreaked havoc with input and operating costs. Always cyclical, the three worst re- \ncessions since the Great Depression caused widespread excess capacity. New com- \npetitors from the Pacific rim and the oil-rich nations of the Middle East entered the \nmarket. Environmental concerns and regulations were growing. \nLedet knew all this; he had lived through it during his 25 years with Du Pont. \nBut blaming outside forces for the problems, while psychologically safe, didn't \nprovide any leverage to improve. Ledet felt that the explanation of the paradox lay \nnot in the outside pressures the company had faced during two turbulent decades \nbut in its response to those pressures. \nLedet and his team needed a way to explore the ways in which different parts \nof the maintenance system interacted, explain why past attempts to improve had \nfailed, and assist in the design of new policies. And they needed to explain these \ncomplex dynamics to the experienced plant operations and maintenance people \nwho had to take action. \n\"Tm indebted to Winston P. Ledet and Winston J. Ledet (principals, The Manufacturing Game), \nPaul Moms (BP Chemicals), and Mark Paich (Colorado College) for permission to present their \nwork and their assistance in the preparation of the material. Thanks also to Tony Cardella, Mark \nDowning, Vince Flynn, and the rest of the Du Pont team. \n","page_start":91,"page_end":91,"token_count":694,"section_type":"other","chapter_number":3,"chapter_title":"The Modeling Process","chunk_index":116}
{"chunk_id":"82d092d67e67a262","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"Chapter 2 System Dynamics in Action \n67 \nLedet and his team began the development of a simulation model to capture \nthe systemwide, dynamic benefits and costs of different maintenance initiatives. \nThey developed the model with the assistance of an experienced modeler, Mark \nPaich. The model was developed interactively, with the participation of Ledet and \nother key team members. The role of the expert modeler was more of a coach and \nfacilitator, and the modeling process involved extensive hands-on workshops in \nwhich the model was discussed, tested, and changed in real time as members of the \nmodeling team identified problems or areas needing improvement. \nDu Pont, like most large firms, already used a number of maintenance plan- \nning tools. These tools tend to focus on the detail complexity of the maintenance \nchallenge, for example, databases to track the maintenance history of each indi- \nvidual piece of equipment, statistical models to optimize maintenance schedules, \nscheduling systems to assign mechanics to planned and reactive work, and so on. \nThese tools are important for the day-to-day management of large plants but they \ndon’t capture the dynamic complexity of the maintenance system. Where the de- \ntailed planning and scheduling models tracked each pump and motor in the plant \nseparately, the dynamic model divided all equipment into just three categories: op- \nerable, broken down, or taken down for planned maintenance. But where the ex- \nisting models assumed failure rates and repair costs and durations were exogenous, \nthe dynamic model treated these factors endogenously. It encompassed technical \nissues such as equipment characteristics; logistical issues such as spare parts avail- \nability, maintenance scheduling, and mechanic assignments; human resources is- \nsues such as mechanic skill, training, and motivation; and financial issues \nincluding maintenance budgets, resource allocation, and overall plant performance. \nThe system dynamics model was a complement to, and not a replacement for, ex- \nisting planning and scheduling tools. \n2.4.1 Dynamic Hypothesis \nUsing the model as a laboratory to design and test different policies, the team grad- \nually developed an appreciation for the dynamic complexity of the maintenance \nsystem. The dynamic hypothesis they developed explained the paradox that Du \nPont spent more on maintenance and got less for it in terms of uptime and equip- \nment reliability. \nThe modeling process led to several important conceptual shifts in the way \nthey viewed maintenance. Prior to the modeling work maintenance was largely \nseen as a process of defect correction (repair of failed equipment) and the mainte- \nnance function was viewed as a cost to be minimized. The first conceptual shift \nwas to change the focus from defect correction to defect prevention and defect \nelimination. The model therefore centered on the physics of breakdowns rather \nthan the cost minimization mentality that prevailed throughout the organization. \nEquipment fails when a sufficient number of latent defects accumulate in it. Latent \ndefects are any problem that might ultimately cause a failure. They include leaky \noil seals in pumps, dirty equipment that causes bearing wear, pump and motor \nshafts that are out of true and cause vibration, poorly calibrated instrumentation, \nand so on. A pump with a leaky oil seal or dirty bearings can still run but will even- \ntually fail unless these latent defects are eliminated. \n","page_start":92,"page_end":92,"token_count":691,"section_type":"other","chapter_number":3,"chapter_title":"The Modeling Process","chunk_index":117}
{"chunk_id":"644a1d386640d3a1","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"68 \nPart I Perspective and Process \nThe total number of latent defects in a plant's equipment is a stock (Figure \n2-8). Defects are created by operations (normal wear and tear) and by collateral \ndamage arising from breakdowns (when the oil leaks out of the pump bearing and \nthe bearing seizes, the shaft may be bent, the motor may overheat, and the vibra- \ntion may break couplings and pipes, introducing new problems). More subtly, \nmaintenance activity can create new defects, through mechanic errors or the use of \npoor quality replacement parts. The lower the intrinsic design quality of the equip- \nment, the more defects these activities create. \nThe stock of defects is drained by two flows: reactive maintenance (repair of \nfailed equipment) and planned maintenance (proactive repair of operable equip- \nment).13 Each of these activities forms a balancing feedback loop. As defects ac- \ncumulate, the chance of a breakdown increases. Breakdowns lead to more reactive \nFIGURE 2-8 \nDefect creation and elimination \nThe diagram is simplified. In the full model equipment was divided into operable, broken \ndown, and taken down for planned maintenance, with an associated stock of latent \ndefects for each category. \nOperations \\ \n+ \nPlanned -b \nDefect \nMaintenance \nElimin-tinn \nEquipment \nQuality \nPart Quality \nQuality and \nProductivity \nEquipment \nDefects \n\\ \nI\n\\\n \nDefect \n4- \nReactive \nElimination -Maintenance \nThrough Repair \nQuality and \nProductivity \nPlanned \nReactive \n.. \nPlanned \nMaintenance \nMaintenance \n4 \nEffort \nTakedown \nRate \n- \n+ \nMaintenance \nRe&.tive \nMaintenance \nBreakdown \nEffort \nRate J \n/ \n+ \n\\ A  \nPlant \nUptime \nI3Planned maintenance includes preventive (time-based) work, e.g., replace worn parts on \npumps every n months, and predictive (condition-based) work, e.g., replace worn parts on a pump \nif vibration exceeds a certain tolerance. \n","page_start":93,"page_end":93,"token_count":448,"section_type":"other","chapter_number":3,"chapter_title":"The Modeling Process","chunk_index":118}
{"chunk_id":"6398aeefa541f562","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"Chapter 2 System Dynamics in Action \n69 \nmaintenance, and, after repair, the equipment is returned to service and the stock \nof defects is reduced (the Reactive Maintenance loop B 1). Similarly, scheduled \nmaintenance or equipment monitoring may reveal the presence of latent defects (a \nvibrating pump, an oil leak). The equipment is then taken out of service and the de- \nfects are corrected before a breakdown occurs (the Planned Maintenance loop B2). \nObviously breakdowns reduce plant uptime. In addition, most planned main- \ntenance activity also reduces uptime since planned maintenance frequently re- \nquires operable equipment be taken out of service so the needed work can be done. \nFigure 2-8 shows only the most basic physics of defect accumulation. The two \nnegative feedbacks regulating the stock of defects appear to be symmetrical: De- \nfects can be eliminated either by planned maintenance or repair of failed equip- \nment. The full system is more complex, however, and includes a number of \npositive, self-reinforcing feedbacks (Figure 2-9). \nFIGURE 2-9 \nPositive feedbacks undercutting planned maintenance \nEquipment \nOperations \nPart Quality \nDefect \nCollateral \nReactive \nMaintenance - \nElimination \nElimination \nMaintenance \nThrough Repair \nMaintenance \nMaintenance \nDamage \nfor PM \n","page_start":94,"page_end":94,"token_count":281,"section_type":"other","chapter_number":3,"chapter_title":"The Modeling Process","chunk_index":119}
{"chunk_id":"56edb2a30b957a6f","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"70 \nPart I Perspective and Process \nConsider the impact of the first oil crisis in late 1973. Input and operating costs \nskyrocketed. But the severe recession that began in 1974 meant chemical produc- \ners could not pass the entire cost increase on to consumers. Under intense financial \npressure, all plants and functions had to cut costs. If maintenance departments are \nasked to cut expenses nearly all of the cut has to come from activities such as plan- \nning and preventive maintenance: When critical equipment breaks down, it must \nbe fixed. At the same time, financial pressure leads to other actions (e.g., postpon- \ning replacement of older, less reliable equipment or running equipment longer and \nmore aggressively than original design specifications indicate), which increase the \nmaintenance workload. With resources for planned maintenance diminishing and \nmaintenance needs increasing, the stock of defects grows. Breakdowns increase. \nBreakdowns cause collateral damage, directly increasing the stock of defects fur- \nther and leading to still more breakdowns in a vicious cycle (the positive loop Rl). \nBecause the total number of mechanics is limited, more breakdowns necessarily \npull mechanics off planned work as management reassigns mechanics to repair \nwork. But many mechanics also prefer repair work. A planned maintenance man- \nager in one plant commented, “We’ve had several people who say they want to get \ninvolved in preventive work but when an outage comes and [they] have a chance \nto work 14-16 hours per week overtime they say ‘to hell with this vibration [mon- \nitoring] stuff, I’m going to the outage area.”’ With less planned work, breakdowns \nincrease still more, forming the reinforcing Go to the Outage loop R2. \nThe rising breakdown rate means more critical equipment will be out of ser- \nvice awaiting repair. Plant uptime falls. Plant operators find it harder to meet de- \nmand. When a mechanic or maintenance supervisor requests that a certain piece of \nequipment be taken off line to correct latent defects, the harried line manager is \nlikely to shout something like “I can barely meet demand as it is and you want me \nto take this line down? No way. If you maintenance people were doing your job, I \nwouldn’t have so many down pumps in the first place. Now get out of here, I’ve \ngot a plant to run.” The balancing Too Busy for PM loop (B3) means operators are \nless willing to take working equipment down for planned maintenance when up- \ntime is low. The side effect of that policy, however, is a further increase in defects \nand breakdowns and still lower uptime. The plant slowly slides down the slippery \nslope (reinforcing loop R3) into a trap of high breakdowns and low uptime, with \nnearly all maintenance resources devoted to crisis management, fire fighting, and \nrepair work. \nThe positive feedbacks Rl to R3 operate fairly quickly but are not the only \nvicious cycles that can drag a plant into the trap of low reliability and high costs. \nThe operational feedbacks in Figure 2-9 are embedded in a larger system shown in ","page_start":95,"page_end":95,"token_count":659,"section_type":"other","chapter_number":3,"chapter_title":"The Modeling Process","chunk_index":120}
{"chunk_id":"67aa898ce62d6ea4","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"slope (reinforcing loop R3) into a trap of high breakdowns and low uptime, with \nnearly all maintenance resources devoted to crisis management, fire fighting, and \nrepair work. \nThe positive feedbacks Rl to R3 operate fairly quickly but are not the only \nvicious cycles that can drag a plant into the trap of low reliability and high costs. \nThe operational feedbacks in Figure 2-9 are embedded in a larger system shown in \nFigure 2- 10. \nA higher breakdown rate increases costs (due to overtime, the nonroutine and \noften hazardous nature of outages, the need to expedite parts procurement, col- \nlateral damage, etc.). The resulting pressure to cut costs leads to a reduction in \nthe quality of parts, increasing the stock of equipment defects and leading to \nstill more breakdowns and still higher costs (the Part Quality loop R4). Cost pres- \nsure also reduces investment in equipment upgrades and other design improve- \nments, so breakdowns increase further (the Design Improvement loop R5). As \ncosts rise training for maintenance workers is cut, particularly training in planned ","page_start":95,"page_end":95,"token_count":237,"section_type":"other","chapter_number":3,"chapter_title":"The Modeling Process","chunk_index":121}
{"chunk_id":"47247b8d2307ba03","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"Chapter 2 System Dynamics in Action \n71 \nFIGURE 2-1 0 \nAdditional positive feedbacks leading to a reactive maintenance culture \nThe contents of the rounded rectangle represent the structure in Figure 2-9. \nI \n/ \nProductivity \n\\ \nPlanning and / 'mpL!!!ement \nScheduling \nEquipmenr \nn,+..,a, \nQuality \nmort \nCapability \nI - 4 \n\\ \nPlanned \nMaintenance \nSkills and Culture \nw \nT r s i n i n m  \n+ \nPressure \nto cut \ncosts \nnepuiari \n\\ \ncosts \nI \n~ \n\\ \nMaintenance \nBudget \n+\\ \nRevenue \nErosion \n. Revenue \nfor Delivery \n@ Reliability \nPrice \nw \n+ \nmaintenance techniques (the Training loop R6). Cost pressure also forces the main- \ntenance department to downsize. The first to go are the planners and sched- \nulers-unlike mechanics, they don't actually fix anything, and with less and less \nplanned maintenance going on there is less for them to do. Without advance plan- \nning, part kits, equipment histories, and engineering drawings for maintenance \nwork are less available, lowering the quality of work still more (the Planning \nCapability loop R7). \nA parallel set of self-reinforcing feedbacks operate to reduce the maintenance \nbudget even as costs rise. Lower uptime directly constrains production and \ntherefore revenue, forcing budget cuts throughout the organization. Worse, high \n","page_start":96,"page_end":96,"token_count":318,"section_type":"other","chapter_number":3,"chapter_title":"The Modeling Process","chunk_index":122}
{"chunk_id":"52a271b57bf8facc","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"72 \nPart I Perspective and Process \nbreakdown rates and low uptime mean the plant is less able to meet its delivery \ncommitments. As it develops a reputation for poor delivery reliability the price it \ncan charge and volume of business it attracts decline, further eroding revenue and \nprofit and forcing still more budget cuts. Cost pressure rises still further, accelerat- \ning the part quality, training, design improvement, and planning capability loops. \nThese loops are summarized as the Revenue Erosion and Reputation Erosion loops \n(R8 and R9). \nAfter years of cost pressure, Du Pont had developed a culture of reactive main- \ntenance. Unreliable equipment and frequent breakdowns had become an accepted \noccurrence. Organizational norms and routines for writing up work orders, sched- \nuling maintenance effort, and ordering parts had come to reflect a world of frequent \nbreakdowns. Mechanics spent most of their time fighting fires. Mechanics who \nwere scheduled for planned maintenance were routinely pulled off to do reactive \nwork. Mechanics knew they could work overtime on a regular basis and consid- \nered overtime pay a part of their regular income. The knowledge that equipment \nwas unreliable had even led to installation of backup pumps in many sites, embed- \nding the low-reliability culture in the physical layout and capital costs of the plants. \nAs the years passed the workforce increasingly consisted of people who had never \nexperienced anything other than the reactive regime. For them, the equipment was \nintrinsically unreliable, low uptime was normal, and reactive maintenance was \nbusiness as usual (the Reactive Culture loop RlO). \nAs the model developed they calibrated it to represent a typical plant. In the \nearly 1990s a typical Du Pont chemical plant was valued at $400 million and spent \nabout 3-3.5% of its value annually on maintenance, or $12 to $14 milliodyear. \nThe spare parts store stocked more than 60,000 parts. It employed about 90 main- \ntenance mechanics who might complete as many as 25,000 work orders per year. \nAverage uptime was 83.5%. Maintenance expenses accounted for 1.5-40% of \ndirect production costs, depending on the process and product. The amount of \nmoney Du Pont spent companywide on maintenance in the late 1980s was about \n$1 billiodyear, a significant fraction of net income. \nOnce the model was adequately calibrated to the historical data, the next step \nwas to design high leverage policies to escape from the reactive regime. The team \nsimulated the impact of different policies, including those that had been tried in the \npast and failed. Table 2-1 shows the results of selected simulations. \nOptimizing the use of scheduling alone, within the traditional cost-minimiza- \ntion mindset, had only a modest impact. Through better scheduling the plant could \nstill meet its traditional uptime of 83.5% with 10% fewer mechanics, generating \nsavings of $350,00O/year. Implementing a full suite of proactive maintenance poli- ","page_start":97,"page_end":97,"token_count":648,"section_type":"other","chapter_number":3,"chapter_title":"The Modeling Process","chunk_index":123}
{"chunk_id":"3c536d70c1a3f53d","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"past and failed. Table 2-1 shows the results of selected simulations. \nOptimizing the use of scheduling alone, within the traditional cost-minimiza- \ntion mindset, had only a modest impact. Through better scheduling the plant could \nstill meet its traditional uptime of 83.5% with 10% fewer mechanics, generating \nsavings of $350,00O/year. Implementing a full suite of proactive maintenance poli- \ncies, including better planning systems, parts, reliability engineering, and so on, al- \nlowed the plant to achieve the traditional uptime with only 61 mechanics, saving \n$1.2 milliodyear. \nHowever, deploying the same suite of proactive policies without downsizing \nallowed uptime to rise above 93% and generated $9 milliodyear in additional \nprofit. Why the difference? The cost-minimization approach means any improve- \nment in productivity generated by the adoption of improved maintenance tech- \nniques is immediately harvested as headcount reduction. Resources for planned \nmaintenance remain constrained. The organization continues to fight fires and ","page_start":97,"page_end":97,"token_count":226,"section_type":"other","chapter_number":3,"chapter_title":"The Modeling Process","chunk_index":124}
{"chunk_id":"d4d995ccc20b39d0","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"Chapter 2 System Dynamics in Action \n73 \nTABLE 2-1 \nResults from \nselected policy \nsimulations \nCases 1 and 2: \nMinimize \nmaintenance \ncosts subject to \nuptime 2 initial \nuptime. \nCase 3: Maximize \nplant profit subject \nto mechanic \nheadcount 5 \ninitial headcount. \nPolicy Mix \n0. Typical plant under existing policies \n1. Use scheduling to minimize \nmaintenance costs \n2. Minimize costs via full suite of \nproactive maintenance policies \n3. Maximize plant profit via full suite of \nproactive maintenance policies \nChange in \nHead \nProfit \nCount Uptime ($ milliodyear) \n91 \n83.5 \n0.00 \n82 \n83.5 \n0.35 \n61 \n83.5 \n1.20 \n91 \n93.3 \n9.00 \nSource: Winston Ledet, Mark Paich, Tony Cardella, and Mark Downing (1991), “The Value of \nIntegrating the CMLT Key Pursuits,” Du Pont internal report. \nfocus on reactive maintenance but does so more efficiently. In contrast, imple- \nmenting the new policies without downsizing frees up resources that can be rein- \nvested in still more planned maintenance. As breakdowns fall, still more mechanics \nare released from fire fighting and outages to do even more planned work. Main- \ntenance expenses drop, releasing resources that can be invested in training, parts \nquality, reliability engineering, planning and scheduling systems, and other activi- \nties that cut defects and breakdowns still more. Higher uptime yields more revenue \nand provides additional resources for still more improvement. For example, up- \ngrading to a more durable type of pump seal improves reliability, allowing main- \ntenance intervals to be lengthened and inventories of replacement seals to be cut. \nAll the positive loops that once acted as vicious cycles to drag reliability down \nbecome virtuous cycles, progressively and cumulatively reducing breakdowns and \nimproving uptime. The result is a tremendous synergy, with the combined effect of \nthe individual policies greatly exceeding the sum of their impacts when imple- \nmented individually. \nThe model also revealed an important insight about the transition path follow- \ning implementation of the new policies. The simulation results in Table 2-1 show \nthat proactive maintenance policies’ with reinvestment of the results ultimately \nlowers maintenance costs and boosts uptime. Immediately after implementation, \nhowever, maintenance costs increase and uptime falls. Why? It takes time for the \nplanned work to cut the breakdown rate; in the short run the plant must bear the \ncost of both the repair work and the additional planned maintenance effort. Uptime \nfalls because additional operable equipment must be taken off-line so planned \nmaintenance can be performed. Only later, as the stock of latent defects starts to \nfall, does the breakdown rate drop. As it does, expenses fall and uptime rises. This \nworse-before-better behavior is quite common in complex systems. However, if \nmanagers do not understand why it occurs or how long it might last, they may in- \nterpret the short-run deterioration in performance as evidence that the policies \ndon’t work and then abandon them. \n","page_start":98,"page_end":98,"token_count":682,"section_type":"other","chapter_number":3,"chapter_title":"The Modeling Process","chunk_index":125}
{"chunk_id":"4bd7b077deef0776","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"74 \nPart I Perspective and Process \n2.4.2 The Implementation Challenge \nLedet and his colleagues felt that the new perspectives they developed on the \nmaintenance problem could improve the contribution of Du Pont’s maintenance \nprogram to corporate profitability. Now their challenge was to implement the \nneeded changes. The team wrote a white paper detailing the results of the model- \ning study and gave presentations throughout the organization. The result? Nothing \nhappened. People would say, “We already know that planned maintenance is a \ngood idea,” “We tried those policies and they didn’t work,” or “Your model doesn’t \naccount for x.” \nLedet realized that the client group for the project-the group of people whose \nbehavior had to change for any results to be realized-was far broader than the \nmanagement team responsible for maintenance. Nothing could happen without the \ncooperation and willing participation of huge numbers of line managers, equip- \nment operators, and maintenance mechanics. The client group numbered in the \nthousands. Reflecting on their own learning process, modeling team members \nrealized that their views had changed radically because they had participated in an \niterative process of modeling. They had seen the model evolve, had challenged and \nquestioned it, had seen their concerns addressed, and had gone through the process \nof working out the feedback structures that explained the dynamics of the system. \nSomehow they had to recreate that learning process throughout the plants, from top \nmanagement to the lowest-grade mechanics. \nIt was obviously impossible for the thousands of people they had to reach to \nparticipate in modeling workshops or even to give them the model so they could \nwork with it themselves. None had training in system dynamics or computer mod- \neling. Line supervisors and maintenance mechanics are action oriented and have \nlittle patience for presentations with lots of charts and graphs. \nLedet was familiar with the Beer Distribution Game, a role-playing manage- \nment flight simulator of a manufacturing supply chain developed by the MIT Sys- \ntem Dynamics Group as an introduction to systems thinking.14 Working with his \nson, Ledet converted the maintenance model into an interactive role-play simula- \ntion that they called the Manufacturing Game (see Ledet 1999). The game was \nembedded in a 2-day workshop or learning laboratory designed to be highly inter- \nactive, to put people at ease, and to create an environment for learning that ad- \ndressed emotional as well as cognitive issues. \nThe game simulates a typical plant. There are three roles: operations manager, \nmaintenance manager, and spare parts stores manager. The operations manager is \ncharged with meeting demand and has equipment, represented by chips, to do so. \nAs production proceeds, red markers representing latent defects are placed on the \nequipment chips. When enough red markers accumulate, the equipment breaks \ndown and capacity falls. The maintenance manager must then allocate mechanics \nto repair the equipment and must go to the spare parts store to see if the needed \nI4The Beer Distribution Game is an enjoyable and effective introduction not only to supply \nchain management but also to the principles of systems thinking in general (see chapter 17; also \nSterman 1989b, 1992 and Senge 1990 for descriptions, but not until after you have played the \ngame). \n","page_start":99,"page_end":99,"token_count":684,"section_type":"other","chapter_number":3,"chapter_title":"The Modeling Process","chunk_index":126}
{"chunk_id":"38be8f19fde58453","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"Chapter 2 System Dynamics in Action \n75 \nparts (determined by a roll of the dice) are available. If the parts are in stock, the \nequipment is repaired. If not, the mechanics must wait until they are available or \npay to have delivery expedited. Alternatively, the maintenance manager can sched- \nule planned work, ordering the needed parts and allocating mechanics in advance. \nPlanned maintenance can only be done, however, if the operations manager agrees \nto take operating equipment out of service. Each round the participants make deci- \nsions such as how much equipment to take down for planned maintenance, how to \nallocate mechanics and maintenance resources, and how many spare parts to order. \nRevenue and cost are recorded, along with production, uptime, inventories, and so \non. While the game is highly simplified compared to real plants, and even com- \npared to the original simulation model, it realistically captures the time delays, \ncosts, and other parameters characterizing a plant. \nDespite its many simplifications the game rapidly becomes in many ways a \nreal plant, with real emotions and conflicts among players. Initialized with high \nbreakdowns and low uptime, the maintenance manager's attempts to increase \nplanned maintenance are often rebuffed by the operations manager, who faces in- \ntense pressure to meet demand, just as in the real world. \nTeams who stick with the prevailing cost-minimization, reactive maintenance \npolicies are able to keep costs low for a while. But as defects build up they find \ntheir uptime slowly sinking and costs gradually rising. Teams who do follow \nthrough with a planned maintenance strategy immediately find costs rising and up- \ntime falling as equipment is taken off line for planned maintenance. Soon, how- \never, costs begin to fall and uptime rises. By compressing time the game allows \npeople to experience the worse-before-better dynamic in a few hours instead of a \nfew months. \nTwo members of the implementation team at Du Pont's Washington Works \ncomplex in Parkersburg, West Virginia, described how they used the game to cat- \nalyze a broad-based improvement program: \nThe team was initiated with a two-day learning lab . . . learning the concepts of de- \nfect elimination and experiencing the Manufacturing Game . . . The basic concepts \nare presented in different manners so that all learning modes are utilized-visual, \nauditory and kinesthetic. The material is presented in the form of lectures, skits and \nparticipative exercises in an off-site environment. Posters and music are used. The \natmosphere is much different than routine plant meetings or training, to open up \ntheir thinking . . . Through interactive exercises, the team develops their personal \naspirations for improving the area where they have chosen to work . . . [Then] \nthey . . . develop an action plan to immediately start ~ 0 r k i n g . l ~  \nThe game and learning laboratory proved popular throughout the company. But \nplaying it once with a small group of managers wasn't enough. The team found \nthat they had to run several workshops for a given plant before a critical mass of ","page_start":100,"page_end":100,"token_count":653,"section_type":"other","chapter_number":3,"chapter_title":"The Modeling Process","chunk_index":127}
{"chunk_id":"f050d93c8803b9b6","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"aspirations for improving the area where they have chosen to work . . . [Then] \nthey . . . develop an action plan to immediately start ~ 0 r k i n g . l ~  \nThe game and learning laboratory proved popular throughout the company. But \nplaying it once with a small group of managers wasn't enough. The team found \nthat they had to run several workshops for a given plant before a critical mass of \npeople emerged to lead action teams that put proactive maintenance policies into \npractice. Often the plant needed to develop its own capability to run the game and \nworkshop so it could be done on demand by local people, with their site-specific \n'STewksbury, R., and R. Steward (1997) Improved Production Capability Program at \nDu Pont's Washington Works, Proceedings of the 1997 Society for Maintenance and Reliability \nannual conference. ","page_start":100,"page_end":100,"token_count":184,"section_type":"other","chapter_number":3,"chapter_title":"The Modeling Process","chunk_index":128}
{"chunk_id":"7e4c423419a7c4b2","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"76 \nFIGURE 2-11 \nWorse-before- \nbetter behavior of \nmaintenance costs \nat a typical plant \nGraph shows \ndirect cost \nsavings after \nimplementation \nof the learning \nlaboratory and \nnew maintenance \npolicies at a \nparticular plant. \nVertical axis \ndisguised. \nPart I Perspective and Process \nexperience and authority. Ledet’s team thus had to develop a group of trained fa- \ncilitators and a training process so that the quality of the workshop could be main- \ntained as it spread into the plants. The demand for the workshop grew slowly at \nfirst, but as favorable word of mouth about the experience and results spread, more \nand more plants asked Ledet’s group to run the program for them. The surge in de- \nmand stressed the number of skilled facilitators, which lagged behind. By the end \nof 1992 some 1200 people had participated in the workshop and more than 50 fa- \ncilitators had been certified. \n2.4.3 Results \nBy 1994 a number of plants throughout the Gulf Coast region had adopted the \nlearning lab and associated policies. Figure 2-1 1 shows the direct maintenance cost \nsavings for a particular plant after implementation of the program. Just as seen in \nthe model and the game, the first effect of the new policies is an increase in costs. \nOnly after several months did the cost savings begin to accumulate. \nAmong plants that implemented the program by the end of 1993, the mean \ntime between failure (MTBF) for pumps (the focus of the program) rose by an av- \nerage of 12% each time cumulative operating experience doubled, while direct \nmaintenance costs had fallen an average of 20%. In 23 comparable plants not im- \nplementing the program the learning rate averaged just 5% per doubling of cumu- \nlative experience and costs were up an average of 7% (Carroll, Sterman, and \nMarcus 1998). The program at Washington Works boosted net production capabil- \nity 20%, improved customer service 9096, and cut delivery lead time by 5070, all \nwith minimal capital investment and a reduction in maintenance costs. It is diffi- \ncult to estimate the total benefit of the program for the company as a whole, but \nconservative estimates exceed $350 milliodyear in avoided maintenance costs. \nThe story does not end here, however. Success creates its own challenges. \nWhat happens to a plant after it succeeds in improving MTBFs and cutting main- \ntenance expenditures? One issue related to the persistence of the cost-saving \n$ \n30 \nE \n.- SS \nfJ4 \n20 \nQ z :  \n- \nz g  \nc .- \nr n =  \n10 \n.? u \n0 \n=I \n0 \n-10 -I \nI \nI \n11/92 \n12/92 \n1 193 \n2/93 \n3/93 \nSource: Allen (1 993). \n","page_start":101,"page_end":101,"token_count":646,"section_type":"other","chapter_number":3,"chapter_title":"The Modeling Process","chunk_index":129}
{"chunk_id":"cdfa9cd6d134b96b","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"Chapter 2 System Dynamics in Action \n77 \nmentality. A member of the modeling team commented, “As soon as you get the \nproblems down, people will be taken away from the effort and the problems will \ngo back up.” In fact, cost-cutting programs mandated by corporate headquarters \ndid cause significant downsizing throughout the entire company and limited their \nability to expand the program. \nAnother problem for Du Pont was rewarding the modeling team. Ledet be- \nlieved the game and learning laboratory had great potential to stimulate improve- \nment in a wide range of companies and industries. He began to receive inquiries \nfrom other firms interested in using the game. Ledet acquired the rights to the game \nfrom Du Pont, took early retirement, and became an entrepreneur, working with \nother companies to implement the approach. These firms include other chemicals \nmanufacturers along with firms in the energy, automotive, and high-tech sectors. \n2.4.4 \nTransferring the Learning: \nThe Lima Experience \nOne of the organizations that adopted the maintenance game and other system dy- \nnamics tools was British Petroleum (BP).16 BP’s Lima, Ohio, refinery was built in \n1886 by John D. Rockefeller to supply fuel and petrochemicals to the Midwest. \nOnce the “Queen of the Fleet,” cost cutting during the 1980s had led to the same \nspiral of increasing breakdowns, declining performance, and still more cost cutting \nthat had plagued Du Pont. By the early 1990s it was a poor performer and lagged \nwell behind other US refineries. A number of improvement programs were tried, \nwith little success, and BP began to think about selling or closing the facility while \ntrying to cut costs. \nIn 1994 the Lima facility introduced the maintenance learning lab and game \nalong with some other tools of system dynamics such as the Beer Distribution \nGame. This was not a top management intervention: The game was initially cham- \npioned by an equipment specialist, a maintenance training supervisor, and an engi- \nneer, Paul Monus, then working in continuous improvement. Successful pilot \nprojects led refinery management to run 80% of all employees through the pro- \ngram. Soon dozens of improvement teams were in place. During the first 6 months \nmaintenance costs ballooned by 30%. Management was prepared for this worse- \nbefore-better dynamic, however, and focused on the improvements generated by \nthe action teams. Momentum began to build. \nIn January 1996 BP announced that it intended to sell the Lima refinery and \nstepped up its cost cutting and downsizing. A few months later BP stunned the em- \nployees by announcing that it could not find a buyer at a satisfactory price and \nwould therefore close the refinery. \nThe announcement was a deep blow to the workers and the city. The Lima \nfacility was one of the most important employers in the community, occupying \n650 acres of prime real estate and generating 400 jobs with payroll, utility, \nand other payments pumping more than $60 milliodyear into Lima’s depressed \neconomy. \n16BP merged with Amoco in 1998, after the work described here was done. \n","page_start":102,"page_end":102,"token_count":669,"section_type":"other","chapter_number":3,"chapter_title":"The Modeling Process","chunk_index":130}
{"chunk_id":"a7a81ad489afe3c2","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"78 \nPart I Perspective and Process \nSome employees became discouraged and questioned the value of continuing \nthe program of defect elimination and proactive maintenance. A few transferred to \nother BP facilities or left altogether. Winston Ledet described what happened next: \nFor those who decided to stay with the ship, a new spirit emerged. They realized \nthat they needed a future in Lima and should take responsibility for creating that \nfuture. The first step was to ensure that the exit of many experienced people did not \nthrow them back in the reactive mode. This heightened the sense of urgency to do \ndefect elimination. It actually created a clearer focus for the people who remained. \nThey were all there because they had chosen to be there.17 \nSoon the cumulative impact of the new maintenance policies and attitudes was \nclearly visible in the performance of the plant. Table 2-2 highlights some of the \nresults. \nThe dramatic improvements in the refinery did not go unnoticed. On July 2, \n1998, the banner headline of the Lima News announced “Oil Refinery Rescued.” \nClark USA, a privately held Fortune 500 company with refining and distribution \ninterests, agreed to buy the Lima refinery from BP for $215 million and keep it op- \nerating as a refinery. Many people and organizations contributed to the rescue of \nthe refinery. Yet without the dramatic improvements in refinery operations stimu- \nlated by the systems thinking intervention it is unlikely Clark, or any buyer, would \nhave offered enough for the facility to keep it running. \n1. Lima Refinery pump MTBF up from 12 to 58 months (pump failures \ndown from more than 640 in 1991 to 131 in 1998). Direct savings: \nTABLE 2-2 \nimprovement at \nthe Lima refinery \n$1.8 million/year. \n2. Total flare-off of hydrocarbon down from 1.5% to 0.35%. Direct savings: \n$0.27/barrel. Improved environmental quality. \n3. On-line analyzer uptime improvement from 75% and not trusted to 97% \nand trusted, permitting real-time optimization of product flow. Savings: \n$0.10-0.12/barrel. \n4. Thirty-four production records set. \n5. Safety incidents and lost hours cut by factor of 4. \n6. Cash margin improved by $0.77 per barrel of oil processed. \n7. Total new value created: $43 million/year. Total cost: $320,00O/year. \n8. BP wide learning initiative under way for all other refineries and plants. \nRatio: 143:l. \nOver 2000 people from sites in the US, UK, Australia, North Sea, Alaska, \nand Europe had participated in the workshop and game by 1998. \nSource: Paul Monus, personal communication; Monus, P. (1997) “Proactive Manufacturing at BP’s \nLima Oil Refinery,” presented at National Petroleum Refiners Association Maintenance Conference, ","page_start":103,"page_end":103,"token_count":632,"section_type":"other","chapter_number":3,"chapter_title":"The Modeling Process","chunk_index":131}
{"chunk_id":"4da6632a5c5284c6","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"Ratio: 143:l. \nOver 2000 people from sites in the US, UK, Australia, North Sea, Alaska, \nand Europe had participated in the workshop and game by 1998. \nSource: Paul Monus, personal communication; Monus, P. (1997) “Proactive Manufacturing at BP’s \nLima Oil Refinery,” presented at National Petroleum Refiners Association Maintenance Conference, \n20-23 May 1997, New Orleans; and Griffith, J., D. Kuenzli, and P. Monus (1998) “Proactive Manufac- \nturing: Accelerating Step Change Breakthroughs in Performance,” NPRA Maintenance Conference, \nMC-98-92. \nI7TMG News, 15 September 1998. ","page_start":103,"page_end":103,"token_count":166,"section_type":"other","chapter_number":3,"chapter_title":"The Modeling Process","chunk_index":132}
{"chunk_id":"e1e3055e105397a9","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"Chapter 2 System Dynamics in Action \n79 \nThe success of the learning laboratory and maintenance game illustrates the \nreal purpose of the modeling process. The model, game, and workshop don’t teach \nanyone how to maintain a pump better or how to do vibration monitoring. Du Pont, \nBP, and other organizations already have plenty of technical tools and knowledge. \nInstead, the game and learning laboratory enable people to experience the long- \nterm organizationwide consequences of their actions, to enact a future in which old \nways of behaving are changed, and to experience emotionally as well as cogni- \ntively what it might be like to make the transition to a high-performing plant. \nThe Lima experience illustrates the power of a shift in mental models. The BP \nteam reduced butane flare-off to zero, generating annual savings of $1.5 million/ \nyear and reducing pollution as well. The effort took 2 weeks and cost $5000, a \nreturn on investment of 30,00O%/year. What had stopped them from implementing \nthis improvement long ago? Members of the team knew about the problem and \nhow to solve it for 8 years. They already had all the engineering know-how they \nneeded to solve the problem and most of the equipment and materials were \nalready on site. The only barriers were the mental models through which employ- \nees came to believe that they were powerless, that the problem was imposed by \nexternal forces beyond their control, and that a few people could never make a \ndifference. \nThese entrenched mental models changed in four essential ways. The belief \nthat the problem was out there had to change from “our equipment is lousy and \nthere’s nothing we can do about it” to “our equipment performs poorly as a result \nof our own past policies-if we change our behavior, the equipment will respond.” \nThe focus on defect correction through repairs had to shift to a focus on defect pre- \nvention and elimination. The focus on minimizing maintenance costs had to shift \nto maximizing overall organizational performance. And they had to realize that es- \ncaping the trap of reactive maintenance necessarily involved a worse-before-better \ntradeoff. \nThe formal model was essential, as it led to the initial insights into the dynam- \nics of process improvement and the synergistic effects of high leverage policies. \nThe model also allowed the modeling team to develop the game and helped make \nit realistic. Ultimately implementation success required the modeling team to em- \nbed their insights into a learning environment that involved the active participation \nof the people on the front lines, that enabled people to discover those insights for \nthemselves, and that spoke not only to their heads but also to their hearts. \nSUMMARY: PRINCIPLES FOR SUCCESSFUL USE OF \nSYSTEM DYNAMICS \nThough the projects described above differed in many ways, they all illustrate a \nnumber of principles for effective development and implementation of system dy- \nnamics models (see chapter 3; see also Forrester 1961; Roberts 1977/1978; and \nMorecroft and Sterman 1994): \n1. Develop a model to solve a particular problem, not to model the system. \nA model must have a clear purpose and that purpose must be to solve the \nproblem of concern to the client. Modelers must exclude all factors not \n","page_start":104,"page_end":104,"token_count":693,"section_type":"other","chapter_number":3,"chapter_title":"The Modeling Process","chunk_index":133}
{"chunk_id":"ae069a33bfeffb47","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"80 \nPart I Perspective and Process \n2. \n3. \n4. \n5. \n6. \n7. \nrelevant to the problem to ensure the project scope is feasible and the results \ntimely. The goal is to improve the performance of the system as defined by \nthe client. Focus on results. \nModeling should be integrated into a project from the beginning. \nThe value of the modeling process begins early on, in the problem \ndefinition phase. The modeling process helps focus diagnosis on the \nstructure of the system rather than blaming problems on the people making \ndecisions in that structure. \nBe skeptical about the value of modeling and force the “why do we \nneed it” discussion at the start of the project. \nThere are many problems for which system dynamics is not useful. \nCarefully consider whether system dynamics is the right technique for the \nproblem. Modelers should welcome difficult questions from the clients \nabout how the process works and how it might help them with their \nproblem. The earlier these issues are discussed, the better. \nSystem dynamics does not stand alone. Use other tools and methods as \nappropriate. \nMost modeling projects are part of a larger effort involving traditional \nstrategic and operational analysis, including benchmarking, statistical work, \nmarket research, etc. Effective modeling rests on a strong base of data and \nunderstanding of the issues. Modeling works best as a complement to other \ntools, not as a substitute. \nFocus on implementation from the start of the project. \nImplementation must start on the first day of the project. Constantly ask, \nHow will the model help the client make decisions? Use the model to set \npriorities and determine the sequence of policy implementation. Use the \nmodel to answer the question, How do we get there from here? Carefully \nconsider the real world issues involved in pulling various policy levers. \nQuantify the full range of costs and benefits of policies, not only those \nalready reported by existing accounting systems. \nModeling works best as an iterative process of joint inquiry between \nclient and consultant. \nModeling is a process of discovery. The goal is to reach new understanding \nof how the problem arises and then use that understanding to design high \nleverage policies for improvement. Modeling should not be used as a tool \nfor advocacy. Don’t build a client’s prior opinion about what should be \ndone into a model. Use workshops where the clients can test the model \nthemselves, in real time. \nAvoid black box modeling. \nModels built out of the sight of the client will never lead to change in \ndeeply held mental models and therefore will not change client behavior. \nInvolve the clients as early and as deeply as possible. Show them the model. \nEncourage them to suggest and run their own tests and to criticize the \nmodel. Work with them to resolve their criticisms to their satisfaction. \n","page_start":105,"page_end":105,"token_count":596,"section_type":"other","chapter_number":3,"chapter_title":"The Modeling Process","chunk_index":134}
{"chunk_id":"42fb663a3bfa2cbc","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"Chapter 2 System Dynamics in Action \n8 \n8. \n9. \n10. \n11. \n12. \nValidation is a continuous process of testing and building confidence in \nthe model. \nModels are not validated after they are completed nor by any one test such \nas their ability to fit historical data. Clients (and modelers) build confidence \nin the utility of a model gradually, by constantly confronting the model with \ndata and expert opinion-their own and others’. Through this process both \nmodel and expert opinions will change and deepen. Seek out opportunities \nto challenge the model’s ability to replicate a diverse range of historical \nexperiences. \nGet a preliminary model working as soon as possible. Add detail only \nas necessary. \nDevelop a working simulation model as soon as possible. Don’t try to \ndevelop a comprehensive conceptual model prior to the development of a \nsimulation model. Conceptual models are only hypotheses and must be \ntested. Formalization and simulation often uncover flaws in conceptual \nmaps and lead to improved understanding. The results of simulation \nexperiments inform conceptual understanding and help build confidence in \nthe results. Early results provide immediate value to clients and justify \ncontinued investment of their time. \nA broad model boundary is more important than a great deal of detail. \nModels must strike a balance between a useful, operational representation \nof the structures and policy levers available to the clients while capturing \nthe feedbacks generally unaccounted for in their mental models. In general, \nthe dynamics of a system emerge from the interactions of the components \nin the system-capturing those feedbacks is more important than a lot of \ndetail in representing the components themselves. \nUse expert modelers, not novices. \nWhile the software available for modeling is easily mastered by a high \nschool student or CEO, modeling is not computer programming. You cannot \ndevelop a qualitative diagram and then hand it off to a programmer for \ncoding into a simulation model. Modeling requires a disciplined approach \nand an understanding of business, skills developed through study and \nexperience. Get the expert assistance you need. Use the project as an \nopportunity to develop the skills of others on the team and in the client \norganization. \nImplementation does not end with a single project. \nIn all three cases the modeling work continued to have impact long after \nthe initial project was over. Models and management flight simulators were \napplied to similar issues in other settings. The modelers developed expertise \nthey applied to related problems and clients moved into new positions and \nnew organizations, taking the insights they gained and, sometimes, a new \nway of thinking, with them. Implementation is a long-term process of \npersonal, organizational, and social change. \n","page_start":106,"page_end":106,"token_count":557,"section_type":"other","chapter_number":3,"chapter_title":"The Modeling Process","chunk_index":135}
{"chunk_id":"7f32818f212ca5db","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"3 \nThe Modeling Process \nPerhaps the fault (for the poor implementation record for models] lies in the \norigins of managerial model-making-the translation of methods and prin- \nciples of the physical sciences into wartime operations research . , . If \nhypothesis, data, and analysis lead to proof and new knowledge in science, \nshouldn’t similar processes lead to change in organizations? The answer is \nobvious-NO! Organizational changes (or decisions or policies) do not \ninstantly Pow from evidence, deductive logic, and mathematical optimization. \n-Edward B. Roberts’ \nIn chapter 1 the concept of a virtual world was introduced as a way to speed the \nlearning process, and chapter 2 showed how models became virtual worlds to help \nsolve problems in three different situations. How can virtual worlds (models) be \nused most effectively? How can useful virtual worlds be created? Modeling takes \nplace in the context of real world problem solving, with all its messiness, ambi- \nguity, time pressure, politics, and interpersonal conflict. The purpose is to solve a \nproblem, not only to gain insight (though insight into the problem is required to \ndesign effective policies). Modeling, as a part of the learning process, is iterative, \na continual process of formulating hypotheses, testing, and revision, of both formal \nand mental models. Experiments conducted in the virtual world inform the design \nand execution of experiments in the real world; experience in the real world then \nleads to changes and improvements in the virtual world and in participants’ mental \n‘Roberts, E. (1977), “Strategies for effective implementation of complex corporate models,” \nInterfaces 7(5); also chapter 4 in Roberts (1978). The paper remains a succinct and still relevant \nstatement of the need for an implementation focus from the very start of any modeling project. \n83 \n","page_start":108,"page_end":108,"token_count":393,"section_type":"other","chapter_number":4,"chapter_title":"Structure and Behavior of Dynamic Systems","chunk_index":136}
{"chunk_id":"f6aeb278e83d9b17","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"84 \nPart I Perspective and Process \n3.1 \n3.2 \nmodels. This chapter discusses the purpose of modeling, describes the process of \nsystem dynamics modeling, the role of the client, and the modeler’s professional \nand ethical responsibilities. \nTHE PURPOSE OF MODELING: \nMANAGERS AS ORGANIZATION DESIGNERS \nJay Forrester often asks, Who are the most important people in the safe operation \nof an aircraft? Most people respond, The pilots. In fact, the most important people \nare the designers. Skilled, well-trained pilots are critical, but far more important is \ndesigning an aircraft that is stable, robust under extreme conditions, and that ordi- \nnary pilots can fly safely even when stressed, tired, or in unfamiliar conditions. In \nthe context of social and business systems, managers play both roles. They are pi- \nlots, malung decisions (who to hire, what prices to set, when to launch the new \nproduct) and they are designers, shaping the organizational structures, strategies, \nand decision rules that influence how decisions are made. The design role is the \nmost important but usually gets the least attention. Too many managers, especially \nsenior managers, spend far too much time acting as pilots-making decisions, tak- \ning control from subordinates-rather than creating an organizational structure \nconsistent with their vision and values and which can be managed well by ordinary \npeople (see Forrester 1965). \nToday designing a new aircraft is impossible without modeling and simulation. \nManagers seeking to enhance their organizational design skills, however, continue \nto design by trial and error, by anecdote, and by imitation of others, though the \ncomplexity of their organizations rivals that of an aircraft. Virtual worlds provide \nan important tool for managers in both the operation and especially the design of \ntheir organizations. \nThere is clearly a role for models that help managers pilot their organizations \nbetter, and system dynamics is often useful for these purposes. But the real value \nof the process comes when models are used to support organizational redesign. In \nIndustrial Dynamics, Forrester calls for courage in the selection of problems, say- \ning, “The solutions to small problems yield small rewards. . . The goal should be \nto find management policies and organizational structures that lead to greater suc- \ncess.” Focus your modeling work on the important issues, on the problems where \nyour work can have lasting benefit, on the problems you care most deeply about. \nTHE CLIENT AND THE MODELER \nModeling does not take place in splendid isolation. It is embedded in an organi- \nzation and social context. Even before the modeling process per se begins, the \nmodeler must gain access to the organization and identify the client. The client is \nnot the person who brings you in to an organization or champions your work, nor \neven the person who pays for the modeling study, though it is helpful to have \ncontacts, champions, and cash. Your clients are the people you must influence for \nyour work to have impact. They are those people whose behavior must change to \nsolve the problem. Your client can be a CEO or a machine operator on the factory \nfloor. Clients can be individuals, groups, or entire communities. The client for a \n","page_start":109,"page_end":109,"token_count":680,"section_type":"other","chapter_number":4,"chapter_title":"Structure and Behavior of Dynamic Systems","chunk_index":137}
{"chunk_id":"d09c8dc809a560e0","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"Chapter 3 The Modeling Process \n85 \nmodeling study can be your academic colleagues, the public at large, or even your- \nself. In the discussion that follows, I will focus on modeling projects conducted for \norganizations. The process, however, is similar for these other contexts as well. \nTo be effective the modeling process must be focused on the clients’ needs. \nThe clients for a modeling project are busy. They are embroiled in organizational \npolitics. They are looking out for their own careers. Their concern is solving a \nproblem and taking action in the real world. They care little for the elegance of \nyour theory or cleverness of your model. Modeling is done to help the client, not \nfor the benefit of the modeler. The client context and real world problem determine \nthe nature of the model, and the modeling process must be consistent with the \nclients’ skills, capabilities, and goals. The purpose is to help the clients solve their \nproblem. If the clients perceive your model does not address their concerns or lose \nconfidence in it, you will have little impact. Focus your modeling work on the \nproblems that keep the clients up at night. \nThe political context of modeling and the need to focus on the clients’ problem \ndoes not mean modelers should be hired guns, willing to do whatever the clients \nwant. Modelers should not automatically accede to clients’ requests to include \nmore detail or to focus on one set of issues while ignoring others, just to keep the \nclients on board. A good modeling process challenges the clients’ conception of the \nproblem. Modelers have a responsibility to require their clients to justify their \nopinions, ground their views in data, and consider new viewpoints. When the \nclients ask you to do something you think is unnecessary or misguided, you must \nwork with them to resolve the issue. \nUnfortunately, far too many clients are not interested in learning but in using \nmodels to support conclusions they’ve already reached or as instruments to gain \npower in their organizations. Sadly, far too many consultants and modelers are \nonly too eager to oblige. As a modeler you have an ethical responsibility to carry \nout your work with rigor and integrity. You must be willing to let the modeling \nprocess change your mind. You must “speak truth to power,” telling the clients that \ntheir most cherished beliefs are wrong, if that is what the modeling process reveals, \neven if it means you will be fired. If your clients push you to generate a result \nthey’ve selected in advance or that is not supported by the analysis, push back. If \nyour clients’ minds are closed, if you can’t convince them to use modeling hon- \nestly, you must quit. Get yourself a better client.2 \n3.3 STEPS OF THE MODELING PROCESS \nIn practice, as a modeler you are first brought into an organization by a contact \nwho thinks you or your modeling tools might be helpful. Your first step is to find \nout what the real problem is and who the real client is. Your initial contact may not ","page_start":110,"page_end":110,"token_count":640,"section_type":"other","chapter_number":4,"chapter_title":"Structure and Behavior of Dynamic Systems","chunk_index":138}
{"chunk_id":"4a7d5911610c24a3","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"your clients’ minds are closed, if you can’t convince them to use modeling hon- \nestly, you must quit. Get yourself a better client.2 \n3.3 STEPS OF THE MODELING PROCESS \nIn practice, as a modeler you are first brought into an organization by a contact \nwho thinks you or your modeling tools might be helpful. Your first step is to find \nout what the real problem is and who the real client is. Your initial contact may not \nbe the client, but only serve as a gatekeeper who can introduce you to the client. \nAs the modeling project proceeds, you may find the client group expands or \nchanges. Assume that you’ve successfully negotiated entry to the organization and \n2Wallace (1994) provides a good collection of articles addressing the ethical issues facing \nmodelers. ","page_start":110,"page_end":110,"token_count":172,"section_type":"other","chapter_number":4,"chapter_title":"Structure and Behavior of Dynamic Systems","chunk_index":139}
{"chunk_id":"fdf6875a4ba2df57","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"86 \nPart I Perspective and Process \nTABLE 3-1 \nSteps of the \nmodeling process \n1. Problem Articulation (Boundary Selection) \nTheme selection: What is the problem? Why is it a problem? \nKey variables: What are the key variables and concepts we must \nconsider? \nTime horizon: How far in the future should we consider? How far back in \nthe past lie the roots of the problem? \nDynamic problem definition (reference modes): What is the historical \nbehavior of the key concepts and variables? What might their behavior \nbe in the future? \n2. Formulation of Dynamic Hypothesis \nInitial hypothesis generation: What are current theories of the problem- \natic behavior? \nEndogenous focus: Formulate a dynamic hypothesis that explains the \ndynamics as endogenous consequences of the feedback structure. \nMapping: Develop maps of causal structure based on initial hypotheses, \nkey variables, reference modes, and other available data, using tools \nsuch as \nModel boundary diagrams, \nSubsystem diagrams, \nCausal loop diagrams, \nStock and flow maps, \nPolicy structure diagrams, \nOther facilitation tools. \n3. Formulation of a Simulation Model \nSpecification of structure, decision rules. \nEstimation of parameters, behavioral relationships, and initial conditions. \nTests for consistency with the purpose and boundary. \nComparison to reference modes: Does the model reproduce the prob- \nRobustness under extreme conditions: Does the model behave realis- \nSensitivity: How does the model behave given uncertainty in parame- \n. . . Many other tests (see chapter 21). \nScenario specification: What environmental conditions might arise? \nPolicy design: What new decision rules, strategies, and structures might \nbe tried in the real world? How can they be represented in the model? \n“What if. . .” analysis: What are the effects of the policies? \nSensitivity analysis: How robust are the policy recommendations under \nInteractions of policies: Do the policies interact? Are there synergies or \n4. Testing \nlem behavior adequately for your purpose? \ntically when stressed by extreme conditions? \nters, initial conditions, model boundary, and aggregation? \n5. Policy Design and Evaluation \ndifferent scenarios and given uncertainties? \ncompensatorv responses? \n","page_start":111,"page_end":111,"token_count":472,"section_type":"other","chapter_number":4,"chapter_title":"Structure and Behavior of Dynamic Systems","chunk_index":140}
{"chunk_id":"c89b19555224b472","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"Chapter 3 The Modeling Process \na7 \n3.4 \nidentified the (initial) clients. How do you proceed to develop a model which can \nbe helpful to them?3 \nThere is no cookbook recipe for successful modeling, no procedure you can \nfollow to guarantee a useful model. Modeling is inherently creative. Individual \nmodelers have different styles and approaches. Yet all successful modelers follow \na disciplined process that involves the following activities: (1) articulating the \nproblem to be addressed, (2) formulating a dynamic hypothesis or theory about the \ncauses of the problem, (3) formulating a simulation model to test the dynamic hy- \npothesis, (4) testing the model until you are satisfied it is suitable for your purpose, \nand (5) designing and evaluating policies for improvement. Table 3-1 lists these \nsteps along with some of the questions each step addresses and the principal tools \nused in each (see also Randers 1980). \nMODELING Is ITERATIVE \nFIGURE 3-1 \nThe modeling \nprocess is \niterative. \nResults of any \nstep can yield \ninsights that lead \nto revisions in \nany earlier step' \n(indicated by the \nlinks in the center \nof the diagram). \nBefore discussing each of these steps in more detail, it is important to place the \nmodeling process in context with the ongoing activities of the people in the system. \nModeling is a feedback process, not a linear sequence of steps. Models go through \nconstant iteration, continual questioning, testing, and refinement. Figure 3- 1 re- \ncasts the modeling process shown in Table 3-1 more accurately as an iterative \ncycle. The initial purpose dictates the boundary and scope of the modeling effort, \nbut what is learned from the process of modeling may feed back to alter our basic \nunderstanding of the problem and the purpose of our effort. Iteration can occur \nfrom any step to any other step (indicated by the interconnections in the center of \nthe diagram). In any modeling project one will iterate through these steps many \ntimes.4 \n(Boundary Selection) \n\\\". \nTesting \n/ \n3. Formulation \n3There is a huge literature on methods for planned organizational change and group interven- \ntions. See particularly Argyris and Schon (1996), Beckhard and Harris (1987), Dyer (1995), \nMichael (1997), and Schein (1987, 1988). \n4Homer (1996) provides an excellent discussion of the value of iteration and rigor in system \ndynamics, not only in academic research but also in consulting work, with a variety of examples. \n","page_start":112,"page_end":112,"token_count":565,"section_type":"other","chapter_number":4,"chapter_title":"Structure and Behavior of Dynamic Systems","chunk_index":141}
{"chunk_id":"6bd7a6d174c3434f","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"88 \nPart I Perspective and Process \nFIGURE 3-2 \nModeling is \nembedded in \nthe dynamics \nof the system. \nEffective modeling \ninvolves constant \niteration between \nexperiments and \nlearning in the \nvirtual world and \nexperiments \nand learning in \nthe real world. \nMost importantly, modeling is embedded in the larger cycle of learning and ac- \ntion constantly taking place in organizations (and described in chapter 1). Pilots \nstep into an aircraft flight simulator and learn more quickly, effectively, and safely \nhow to operate the real aircraft, then put these skills to use in the real thing. They \nfeed back what they learn flying the real thing to the simulator designers so the \nsimulators can be continually improved. What pilots and designers learn in the \nsimulator is used in the real world. And what they learn in the real world is used to \nchange and improve the virtual world of the simulator. So it is with management \nflight simulators and system dynamics models. Figure 3-2 shows the modeling \nprocess embedded in the single- and double-loop learning feedbacks discussed in \nchapter 1. Simulation models are informed by our mental models and by informa- \ntion gleaned from the real world. Strategies, structures, and decision rules used in \nthe real world can be represented and tested in the virtual world of the model. The \nexperiments and tests conducted in the model feed back to alter our mental models \nand lead to the design of new strategies, new structures, and new decision rules. \nThese new policies are then implemented in the real world, and feedback about \ntheir effects leads to new insights and further improvements in both our formal and \nReal \nWorld \nDecisions \n(Organizational \nExperiments) \nInformation \nFeedback \nFormulatibn /=#* \n3. Formulation \nStrategy, \nMental \nStructure, \nDecision \nRules \\ \n/ \nWorld \n","page_start":113,"page_end":113,"token_count":403,"section_type":"other","chapter_number":4,"chapter_title":"Structure and Behavior of Dynamic Systems","chunk_index":142}
{"chunk_id":"f426972e034d6cc8","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"Chapter 3 \nThe Modeling Process \n89 \nmental models. Modeling is not a one-shot activity that yields The Answer, but an \nongoing process of continual cycling between the virtual world of the model and \nthe real world of action. \n3.5 \nOVERVIEW OF THE MODELING PROCESS \n3.5.1 \nProblem Articulation: \nThe Importance of Purpose \nThe most important step in modeling is problem articulation. What is the issue the \nclients are most concerned with? What problem are they trying to address? What is \nthe real problem, not just the symptom of difficulty? What is the purpose of the \nmodel? \nA clear purpose is the single most important ingredient for a successful mod- \neling study. Of course, a model with a clear purpose can still be misleading, un- \nwieldy, and difficult to understand. But a clear purpose allows your clients to ask \nquestions that reveal whether a model is useful in addressing the problem they care \nabout. \nBeware the analyst who proposes to model an entire business or social system \nrather than a problem. Every model is a representation of a system-a group of \nfunctionally interrelated elements forming a complex whole. But for a model to be \nuseful, it must address a specific problem and must simplify rather than attempt to \nmirror an entire system in detail. \nWhat is the difference? A model designed to understand how the business cy- \ncle can be stabilized is a model of a problem. It deals with a specific policy issue. \nA model designed to explore policies to slow fossil fuel use and mitigate global \nwarming is also a model of a problem; it too addresses only a limited set of issues. \nA model that claims to be a representation of the entire economy is a model of a \nwhole system. Why does it matter? The usefulness of models lies in the fact that \nthey simplify reality, creating a representation of it we can comprehend. A truly \ncomprehensive model would be just as complex as the system itself and just as in- \nscrutable. Von Clausewitz famously cautioned that the map is not the territory. It’s \na good thing it isn’t: A map as detailed as the territory would be of no use (as well \nas being hard to fold). \nThe art of model building is knowing what to cut out, and the purpose of the \nmodel acts as the logical knife. It provides the criteria to decide what can be ig- \nnored so that only the essential features necessary to fulfill the purpose are left. In \nthe example above, since the purpose of the comprehensive model would be to rep- \nresent the entire economic system, nothing could be excluded. To answer all con- \nceivable questions about the economy, the model would have to include an \noverwhelming array of variables. Because its scope and boundary are so broad, the \nmodel could never be completed. If it were, the data required to use it could never \nbe compiled. If they were, the model’s underlying assumptions could never be \nexamined or tested. If they were, the model builders could never understand its \nbehavior and the clients’ confidence in it would depend on the authority of the \nmodeler and other nonscientific grounds. Mihailo Mesarovic, a developer of early \n","page_start":114,"page_end":114,"token_count":683,"section_type":"other","chapter_number":4,"chapter_title":"Structure and Behavior of Dynamic Systems","chunk_index":143}
{"chunk_id":"833cabc1a1f2f62b","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"90 \nPart I Perspective and Process \nglobal simulations, captured the impossibility of building models of systems when \nhe said, “No matter how many resources one has, one can envision a complex \nenough model to render resources insufficient to the task.” (Meadows, Richardson, \nand Bruckmann 1982, p. 197). \nA model designed for a particular purpose such as understanding the business \ncycle or global climate change would be much smaller, since it would be limited to \nthose factors believed to be relevant to the question at hand. For example, the busi- \nness cycle model need not include long-term trends in population growth, resource \ndepletion, or climate change. The global warming model could exclude short-term \ndynamics related to interest rates, employment, and inventories. The resulting \nmodels could be simple enough so that their assumptions could be examined. The \nrelation of these assumptions to the most important theories regarding the business \ncycle and climate change could then be assessed to determine how useful the mod- \nels were for their intended purposes. Of course even models with well-defined pur- \nposes can be too large. But without a clear purpose, there is no basis to say “we \ndon’t need to include that” when a member of the client team makes a suggestion. \nIn sum: Always model a problem. Never model a system. \nUsually the modeler develops the initial characterization of the problem \nthrough discussion with the client team, supplemented by archival research, data \ncollection, interviews, and direct observation or participation. There are many \nmethods available to work with a group to elicit the information needed to define \nthe problem dynamically while still keeping the conversation focused firmly on the \nclients and their pr~blem.~ \nTwo of the most useful processes are establishing refer- \nence modes and explicitly setting the time horizon. \nReference Modes \nSystem dynamics modelers seek to characterize the problem dynamically, that is, \nas a pattern of behavior, unfolding over time, which shows how the problem arose \nand how it might evolve in the future. You should develop a reference mode, liter- \nally a set of graphs and other descriptive data showing the development of the \nproblem over time. Reference modes (so-called because you refer back to them \nthroughout the modeling process) help you and your clients break out of the short- \nterm event-oriented worldview so many people have. To do so you and the clients \nmust identify the time horizon and define those variables and concepts you \nconsider to be important for understanding the problem and designing policies to \nsolve it. \nTime Horizon \nThe time horizon should extend far enough back in history to show how the prob- \nlem emerged and describe its symptoms. It should extend far enough into the \nfuture to capture the delayed and indirect effects of potential policies. Most people \ndramatically underestimate the length of time delays and select time horizons that \n5See the references in note 9 for modeling tools that are effective for real time modeling with \norganizations and teams including eliciting and structuring the mental models of a group to define \nthe problem. \n","page_start":115,"page_end":115,"token_count":642,"section_type":"other","chapter_number":4,"chapter_title":"Structure and Behavior of Dynamic Systems","chunk_index":144}
{"chunk_id":"77e65d7f188f4b73","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"Chapter 3 The Modeling Process \n91 \n0 \nare far too short. A principal deficiency in our mental models is our tendency to \nthink of cause and effect as local and immediate. But in dynamically complex sys- \ntems, cause and effect are distant in time and space. Most of the unintended effects \nof decisions leading to policy resistance involve feedbacks with long delays, far re- \nmoved from the point of decision or the problem symptom. Work with your clients \nto think about the possible reactions to policies and how long they might take to \nplay out and then increase the time horizon even further. A long time horizon is a \ncritical antidote to the event-oriented worldview so crippling to our ability to iden- \ntify patterns of behavior and the feedback structures generating them. \nThe choice of time horizon dramatically influences your perception of the \nproblem. Figure 3-3 shows production, consumption, and imports of petroleum in \nthe United States from 1986 to 1996. The historical time horizon is 10 years, al- \nready a long time relative to most discussion of energy policy (the oil shocks of \nthe 1970s are considered ancient history in most policy debate today). The graphs \nshow production slowly trending down, consumption trending slowly up, and \ntherefore imports growing modestly. Prices fluctuate in a narrow band between \n$14 and $23 per barrel, lower than any time since the first oil crisis in 1973 (though \nprices did spike to $40/barrel after the Iraqi invasion of Kuwait, they soon fell \nback). The energy system appears to be relatively stable; there is little evidence of \na long-term problem. \nProduction, \nLower 48 States \nI \nFIGURE 3-3 \nUS oil production, \nconsumption, \n5. \nimports, and price \n. \nzi \nu) - \n2! z \nm \nover a 1 0-year \ntime horizon \n1 8 ;  \nt \nImports \n'p; \n, \n, \n, \n, \n, \n, \n, \n. i \n0 \n1986 \n1988 \n1990 \n1992 \n1994 \n1996 \nSource: EIA (US Energy Information Agency) Annual Energy Review. \n","page_start":116,"page_end":116,"token_count":469,"section_type":"other","chapter_number":4,"chapter_title":"Structure and Behavior of Dynamic Systems","chunk_index":145}
{"chunk_id":"df899d7f06a3f380","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"92 \n- ‘ i  \nConsumption \n+ \nPart I Perspective and Process \nConsumption \n+ \nImports \nFIGURE 3-4 \nUS oil production, \nconsumption, \nimports, and price \nover a 130-year \ntime horizon \nL \nNow consider Figure 3-4, showing the same variables from near the beginning \nof the oil era (the petroleum industry began in earnest in 1859 with Colonel \nDrake’s famous well in Titusville, Pennsylvania). The impression is completely \ndifferent. The history of the oil industry in the United States is divided into two \nregimes. From 1920 through 1973, consumption grew exponentially at an average \nrate of 4.3%/year. Production nearly kept pace, as exploration and better drilling \ntechniques more than offset depletion. Starting in the 1950s, imports grew slightly, \nstimulated by the availability of cheap foreign oil. Prices fluctuated, often dramat- \nically, but along a slowly declining trend as technology improved. All this changed \nin 1970. In 1970, domestic production of oil peaked. It’s been falling ever since, \ndespite the intense exploration stimulated by the much higher prices of the 1970s \nand early 1980s. US production from the lower 48 states and adjacent offshore area \nin 1996 stood at only 54% of its peak level. Even the addition of Prudhoe Bay and \nthe trans-Alaska pipeline did not halt the slide, and Alaskan production peaked in \n1988. Higher prices following the 1970s oil shocks, along with the deepest reces- \nsions since the Great Depression, cut the growth of consumption, but imports nev- \nertheless reached 61% of total oil consumption by 1996. \nChanging the time horizon completely changes the assessment of the problem. \nViewed with a time scale consistent with the life of the resource, it is clear that the \npetroleum problem wasn’t solved in the 1980s but has been steadily getting worse. \n>\n.\n \nr5 2 12- \n2 \nm \n- \nL \nm \nC \n6 -  \n- \n.- \n, \n, \n, \n185 \n#\ni\n \nI \n5 \n4 \n1 \nImports \nLower 40 States \nI \nI \nI \n1870 \n1890 \n1910 \n1930 \n1950 \n1970 \n1990 \n0-I \nt \n1870 \n1890 \n1910 \n1930 \n1950 \n1970 \n1990 \nI \nSource: Production & consumption: 1870-1 949, Davidsen (1 988); 1950-1 966, EIA Annual Energy \nReview, Price: 1880-1 968, Davidsen (1 988); 1968-1 996, EIA Annual Energy Review, Refiners \nAcquisition Cost. \n","page_start":117,"page_end":117,"token_count":622,"section_type":"other","chapter_number":4,"chapter_title":"Structure and Behavior of Dynamic Systems","chunk_index":146}
{"chunk_id":"ee944a0406563ced","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"Chapter 3 The Modeling Process \n.- 8 \n4- 0 \nQ\n-\n \n2 \nn \n% ; \nw\n-\n \nm \nln \nLL \n- \n.- \n93 \n,\n.\n,\n,\n,\nI\n,\n,\n,\n.\n \nI,\\ , \n, \nFIGURE 3-5 \nThe fossil fuel \nera shovvn with a \ntime horizon of \n151,000 years \nPetroleum is a finite nonrenewable resource. In the US, depletion began to domi- \nnate finding rates in the 1960s, leading to an inevitable decline in production, a de- \ncline that began in 1970. The United States is the most heavily explored and \ndensely drilled region of the world. The very success of early wildcatters in find- \ning oil means there is less left to find now. While not all the petroleum in the US \nhas been found or recovered, consumption continues to exceed the rate at which \nwhat remains is found. Consequently, imports continue to grow, leading to still \ngreater dependency on the unstable Persian Gulf region, still more political and \neconomic power for the oil exporting countries and less for the US, and, eventu- \nally, higher oil prices, either at the pump or in the defense budget.6 \nThe oil industry illustrates the dangers of selecting a time horizon too short to \ncapture the important dynamics and feedbacks creating them. Of course, one can \nerr too far in the other direction. Figure 3-5 shows a graph developed by the late \npetroleum geologist M. King Hubbert. Hubbert invented the most successful tech- \nnique for forecasting fossil fuel production ever created. In 1956 he estimated the \nultimate recoverable petroleum resources of the US to be between 150 and 200 bil- \nlion barrels and forecast that “the peak in production should probably occur within \nthe interval 1966-1971” (Hubbert 1975, p. 371). His prediction of decline came at \na time when the US Geological Survey projected ultimate recoverable resources \nnearly three times as large and claimed “the size of the resource base would not \nlimit domestic production capacity ‘in the next 10 to 20 years at least, and proba- \nbly [not] for a much longer time’ ” (Gillette 1974). The actual peak occurred in \n1970 at almost the precise value Hubbert had predicted, one of the most accurate \nlong-term forecasts on record. Hubbert’s success lay in explicitly modeling oil as \na nonrenewable resource. Production could grow exponentially in the early phases \n6There is a large literature of energy modeling in system dynamics, originating with work in \nMeadows et al. (1974). See, e.g., Backus (1996), Bunn and Larsen (1997), Fiddaman (1997), \nFord (1990, 1997, 1999), Ford and Bull (1989), Naill (1977, 1992), and Naill et al. (1992) for \nwork on national and global energy markets, electric utilities, global climate change, and other \nenergy policy issues. \n","page_start":118,"page_end":118,"token_count":674,"section_type":"other","chapter_number":4,"chapter_title":"Structure and Behavior of Dynamic Systems","chunk_index":147}
{"chunk_id":"cf66b038096371f4","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"94 \nPart I Perspective and Process \nof its life cycle but had to fall to zero as it was depleted, forcing a transition to re- \nnewable energy source~.~ \nTo emphasize the transitory nature of fossil fuel civiliza- \ntion, Hubbert showed the production of fossil fuels on a time scale from the \nbeginning of the agricultural revolution 10,000 years ago to 5000 years in the fu- \nture. Against this backdrop, the fossil fuel era is seen as a transitory spike-a \nunique period during which humanity lives extravagantly off a rich inheritance of \nirreplaceable natural capital. The picture is sobering. But Hubbert’s pimple, as it \nwas called by critics, takes a time horizon too long to be useful to policy makers \nwho influence public policy or corporate strategy affecting energy prices, regula- \ntions, capital investment, and R&D. \nThe choice of time horizon can dramatically influence the evaluation of \npolicies. In the early 1970s a US government agency concerned with foreign aid \nsponsored a model focused on the Sahel region of sub-Saharan Africa. The Sahel \nwas then experiencing rapid population growth at the same time the desert was \nexpanding southward, reducing grazing land for the nomadic herders’ cattle. The \npurpose of the model was to identify high leverage policies to spur economic \ndevelopment in the region. The model was used to assess the effects of many of \nthe policies then in use, such as drilling bore holes to increase the water supply for \ncattle by tapping deep aquifers or subsidizing crops such as sorghum and ground \nnuts. Running the model to the year 2000, a round number several decades in the \nfuture at the time, showed that the policies led to improvement. Subsidies in- \ncreased agricultural output. Bore holes permitted cattle stocks to grow, increasing \nthe supply of milk and meat and the wealth of the herders. However, running the \nmodel into the first decades of the 21 st century showed a different outcome: larger \nstocks of cattle began to outstrip the carrying capacity of the region. As the cattle \noverbrowsed and trampled the grasslands, erosion and desertification increased. \nThe cattle population dropped sharply, creating a food deficit in the region. Select- \ning a time horizon too short to capture these feedbacks favored adoption of poli- \ncies counter to the long-term interests of the region’s people and the mission of the \nclient organization.* \nModelers must guard against accepting the client’s initial assessment of the ap- \npropriate time frame. Often these are based on milestones and round numbers hav- \ning little to do with the dynamics of the problem, such as the end of the fiscal year, \nor the next 5-year planning cycle. A good rule of thumb is to set the time horizon \nseveral times as long as the longest time delays in the system, and then some. \n3.5.2 \nFormulating a Dynamic Hypothesis \nOnce the problem has been identified and characterized over an appropriate time ","page_start":119,"page_end":119,"token_count":646,"section_type":"other","chapter_number":4,"chapter_title":"Structure and Behavior of Dynamic Systems","chunk_index":148}
{"chunk_id":"1bbd05b09ab463cc","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"ing little to do with the dynamics of the problem, such as the end of the fiscal year, \nor the next 5-year planning cycle. A good rule of thumb is to set the time horizon \nseveral times as long as the longest time delays in the system, and then some. \n3.5.2 \nFormulating a Dynamic Hypothesis \nOnce the problem has been identified and characterized over an appropriate time \nhorizon, modelers must begin to develop a theory, called a dynamic hypothesis, to \n7Sterman and Richardson (1985), Sterman et al. (1988), and Sterman, Richardson, and Davidsen \n(1990) model the world and US petroleum life cycles and study the evolution of estimates of the \nresource base, showing why Hubbert was so accurate while other estimation methods proved so \nwildly overoptimistic. \n*Picadi and Seifert (1976) describe one of several models of the Sahel region (the model \ndescribed above was not published). ","page_start":119,"page_end":119,"token_count":214,"section_type":"other","chapter_number":4,"chapter_title":"Structure and Behavior of Dynamic Systems","chunk_index":149}
{"chunk_id":"7027079e9afecfca","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"Chapter 3 The Modeling Process \n95 \naccount for the problematic behavior. Your hypothesis is dynamic because it must \nprovide an explanation of the dynamics characterizing the problem in terms of the \nunderlying feedback and stock and flow structure of the system. It is a hypothesis \nbecause it is always provisional, subject to revision or abandonment as you learn \nfrom the modeling process and from the real world. \nA dynamic hypothesis is a working theory of how the problem arose. It guides \nmodeling efforts by focusing you and your clients on certain structures. Much of \nthe remainder of the modeling process helps you to test the dynamic hypothesis, \nboth with the simulation model and by experiments and data collection in the real \nworld. \nIn practice, discussion of the problem and theories about the causes of the \nproblem are jumbled together in conversation with client teams. Each member of \na team likely has a different theory about the source of the problem; you need to \nacknowledge and capture them all. Many times the purpose of the model is to solve \na critically important problem that has persisted for years and generated great \nconflict and not a little animosity among members of the client team. All will \ntenaciously advocate their positions while deriding the views of others in the \ngroup. Early in the modeling process, the modeler needs to act as a facilitator, cap- \nturing these mental models without criticizing or filtering them. Clarifying and \nprobing questions are often useful, but the modeler’s role during this early phase is \nto be a thoughtful listener, not a content expert. A variety of elicitation techniques \nand diagramming tools have been developed to assist you in facilitating a produc- \ntive conversation to elicit people’s theories about the causes of the pr~blem.~ \nYour \ngoal is to help the client develop an endogenous explanation for the problematic \ndynamics. \nEndogenous Explanation \nSystem dynamics seeks endogenous explanations for phenomena. The word “en- \ndogenous” means “arising from within.” An endogenous theory generates the dy- \nnamics of a system through the interaction of the variables and agents represented \nin the model. By specifying how the system is structured and the rules of interac- \ntion (the decision rules in the system), you can explore the patterns of behavior cre- \nated by those rules and that structure and explore how the behavior might change \nif you alter the structure and rules. In contrast, a theory relying on exogenous vari- \nables (those “arising from without,” that is, from outside the boundary of the \nmodel) explains the dynamics of variables you care about in terms of other vari- \nables whose behavior you’ve assumed. Exogenous explanations are really no ex- \nplanation at all; they simply beg the question, What caused the exogenous \nvariables to change as they did? The focus in system dynamics on endogenous ex- \nplanations does not mean you should never include any exogenous variables in \nyour models. But the number of exogenous inputs should be small, and each can- \ndidate for an exogenous input must be carefully scrutinized to consider whether ","page_start":120,"page_end":120,"token_count":653,"section_type":"other","chapter_number":4,"chapter_title":"Structure and Behavior of Dynamic Systems","chunk_index":150}
{"chunk_id":"3eed8a8dc8b7b6da","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"ables whose behavior you’ve assumed. Exogenous explanations are really no ex- \nplanation at all; they simply beg the question, What caused the exogenous \nvariables to change as they did? The focus in system dynamics on endogenous ex- \nplanations does not mean you should never include any exogenous variables in \nyour models. But the number of exogenous inputs should be small, and each can- \ndidate for an exogenous input must be carefully scrutinized to consider whether \n9The literature on group model building is growing rapidly. Reagan-Cirincione et al. (1991), \nMorecroft and Sterman (1994), Vennix (1996), and Vennix et al. (1997) provide good overviews of \ntools and techniques to elicit and capture the mental models of teams and client groups. ","page_start":120,"page_end":120,"token_count":175,"section_type":"other","chapter_number":4,"chapter_title":"Structure and Behavior of Dynamic Systems","chunk_index":151}
{"chunk_id":"43bde97b1a3483a2","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"96 \nPart I Perspective and Process \nthere are in fact any important feedbacks from the endogenous elements to the can- \ndidate. If so, the boundary of the model must be expanded and the variable must be \nmodeled endogenously. \nThe consequences of narrow model boundaries and reliance on exogenous \nvariables are often serious. A typical example is provided by the Project Indepen- \ndence Evaluation System (PIES) model, a hybrid model based on linear program- \nming, econometrics, and input/output analysis used in the 1970s by the US Federal \nEnergy Administration (FEA) and later by the US Department of Energy. As de- \nscribed by the FEA, the purpose of the model was to evaluate different energy poli- \ncies according to the following criteria: their impact on the development of \nalternative energy sources; their impact on economic growth, inflation, and unem- \nployment; their regional and social impacts; their vulnerability to import disrup- \ntions; and their environmental effects. \nSurprisingly, considering the stated purpose, the PIES model treated the econ- \nomy as exogenous. The model economy (including economic growth, interest \nrates, inflation, world oil prices, and the costs of unconventional fuels) was com- \npletely unaffected by the energy situation (including prices, policies, and produc- \ntion). In the model, even a full embargo of imported oil or a doubling of oil prices \nwould have no impact on the economy. \nTreating the economy exogenously made the PIES model inherently contra- \ndictory. Because it assumed high rates of economic growth and low price elastici- \nties, it projected huge increases in energy demand, requiring even greater increases \nin the capital requirements of the energy sector as cheap domestic oil was con- \nsumed. In the model, these huge investments in energy production were satisfied \nwithout reducing investment or consumption in the rest of the economy and with \nno impact on interest rates or inflation. In effect, the model let the economy have \nits pie and eat it too. \nIn part because it ignored the feedbacks between the energy sector and the rest \nof the economy, the PIES model consistently proved to be overoptimistic. In 1974 \nthe model projected that by 1985 the US would be well on the way to energy \nindependence: energy imports would be only 3.3 million barrels per day and \nproduction of shale oil would be 250,000 barrels per day. Furthermore, these \ndevelopments would be accompanied by oil prices of about $22 per barrel (1984 \ndollars) and by vigorous economic growth. It didn’t happen. Imports in the late \n1980s were about 5.5 million barrels per day and grew to more than half of oil con- \nsumption by the mid 1990s. Shale oil and other exotic synfuels never materialized. \nThis situation prevailed despite huge reductions in oil demand caused by oil prices \nin the early 1980s greater than $30/bbl and the most serious recession since the \nGreat Depression. ","page_start":121,"page_end":121,"token_count":652,"section_type":"other","chapter_number":4,"chapter_title":"Structure and Behavior of Dynamic Systems","chunk_index":152}
{"chunk_id":"0ab2fceff3bad850","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"1980s were about 5.5 million barrels per day and grew to more than half of oil con- \nsumption by the mid 1990s. Shale oil and other exotic synfuels never materialized. \nThis situation prevailed despite huge reductions in oil demand caused by oil prices \nin the early 1980s greater than $30/bbl and the most serious recession since the \nGreat Depression. \nA broad model boundary that captures important feedbacks is more impor- \ntant than a lot of detail in the specification of individual components. It is worth \nnoting that the PIES model provided a breakdown of supply, demand, and price for \ndozens of fuels in each region of the country yet its,aggregate projections \nweren’t even close. What purpose was served by the effort devoted to forecasting \nthe demand for jet fuel or naphtha in the Pacific Northwest when the basic as- \nsumptions were so palpably inadequate and the main results were so woefully \nerroneous? ","page_start":121,"page_end":121,"token_count":211,"section_type":"other","chapter_number":4,"chapter_title":"Structure and Behavior of Dynamic Systems","chunk_index":153}
{"chunk_id":"2e6645b148450a1a","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"Chapter 3 The Modeling Process \n97 \nMapping System Structure \nSystem dynamics includes a variety of tools to help you communicate the bound- \nary of your model and represent its causal structure. These include model bound- \nary diagrams, subsystem diagrams, causal loop diagrams, and stock and flow \nmaps. \nModel boundary chart. A model boundary chart summarizes the scope of the \nmodel by listing which key variables are included endogenously, which are exoge- \nnous, and which are excluded from the model. \nTo illustrate, Table 3-2 shows a model boundary diagram for a model designed \nto study the feedbacks between the energy system and the economy (Sterman \n1983). Partly in reaction to the limitations of existing models such as PIES, the De- \npartment of Energy in the late 1970s sought to develop dynamic models with a \nbroader boundary (Nail1 1977, 1992). The purpose of the model was to explore the \nimpact of higher energy prices on economic growth, unemployment, inflation, and \ninterest rates and how these macroeconomic considerations might constrain the de- \nvelopment of new energy sources. The time horizon of the model was quite long \n(1950-2050) to capture the full transition from fossil fuels to renewable or other \nenergy sources and consistent with the long time delays in the development, con- \nstruction, and useful life of energy-producing and energy-consuming capital \nstocks. \nIn contrast to nearly all models used to address these issues at the time, the \nmodel had a broad boundary, with all major macroeconomic variables generated \nendogenously. Unlike the PIES model, the capital, labor, and energy requirements \nTABLE 3-2 \nModel boundary \nEndogenous \nExogenous \nExcluded \nchart for a long- \nGNP \n.. \nConsumption \nInvestment \nterm model of \nenergy-economy \ninteractions \nSavings \nPrices (real and nominal) \nWages (real and nominal) \nInflation rate \nLabor force participation \nEmployment \nUnemployment \nInterest rates \nMoney supply \nDebt \nEnergy production \nEnergy demand \nEnergy imports \nPopulation \nInventories \nTechnological change \nInternational trade \nTax rates \n(except with OPEC) \nEnergy policies \nEnvironmental constraints \nNonenergy resources \nInterfuel substitution \nDistributional equity \nSource: Sterman (1 983). \n","page_start":122,"page_end":122,"token_count":499,"section_type":"other","chapter_number":4,"chapter_title":"Structure and Behavior of Dynamic Systems","chunk_index":154}
{"chunk_id":"f16c73c77b5ef732","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"98 \nPart I Perspective and Process \nof the energy industries were endogenous and the energy industry had to compete \nagainst other sectors for these resources. The model still contained several exoge- \nnous variables. These include population, the rate of overall technological \nprogress, and the price of imported oil. Were these exogenous variables accept- \nable? Population growth and the overall rate of technical progress might be af- \nfected by changes in energy prices and consequent changes in the rate of economic \ngrowth. However, these feedbacks seemed likely to be small. The decision to \nmodel the price of imported oil exogenously is more problematic. Clearly the price \nof oil affects both the demand for and supply of energy in the United States, deter- \nmining the quantity imported. As a major importer, changes in US oil imports can \ndramatically alter the supply/demand balance of the oil exporting nations, feeding \nback to the price of oil in the world market. Treating import prices exogenously \ncuts an important feedback loop. In discussing the boundary of the model I argued \nthat there were in fact important feedbacks between the US energy system and the \nworld oil market. But I also argued that the dynamics of the world price were so \ncomplex that incorporating them endogenously was beyond the scope and purpose \nof the project. I had previously helped build a model of the world oil market for the \nUS Department of Energy and hoped that ultimately the two models could be \njoined. The model boundary chart alerted the clients to a questionable assumption \nso they could evaluate what the effect of the missing feedback might be. \nThe list of excluded concepts also provides important warnings to the model \nuser. The model omitted inventories of goods and materials (and hence short-term \nbusiness cycles)-no problem in such a long-term model. International trade was \nexcluded, except for the flows of oil, goods, capital, and money between the US \nand the oil exporting nations. The petrodollars flowing to OPEC and their recy- \ncling as exports or foreign investment had to be included, but to include nonenergy \ntrade would have expanded the model into a global macroeconomic system, and I \nwould probably still be working on it. Environmental constraints and nonenergy \nresources such as water that might limit new energy sources like synfuels were ex- \ncluded, meaning conclusions about the rate of development of these exotic energy \nsources would be overoptimistic. The model also treated the energy system in a \nfairly aggregate fashion, so interfuel substitution (oil vs. gas, for example), was not \nconsidered, another optimistic assumption. Finally, the model did not consider \nincome distribution, even though some energy policies such as gasoline taxes are \nregressive unless offset by changes in the income tax code. The purpose of listing \nall these omissions from the model was to help model users decide for themselves \nwhether the model was appropriate for their purpose. \nModel boundary diagrams are surprisingly useful and shockingly rare. Often, \nmodels are used not as tools of inquiry but as weapons in a war of advocacy. ","page_start":123,"page_end":123,"token_count":644,"section_type":"other","chapter_number":4,"chapter_title":"Structure and Behavior of Dynamic Systems","chunk_index":155}
{"chunk_id":"5f25613262e0a3b9","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"income distribution, even though some energy policies such as gasoline taxes are \nregressive unless offset by changes in the income tax code. The purpose of listing \nall these omissions from the model was to help model users decide for themselves \nwhether the model was appropriate for their purpose. \nModel boundary diagrams are surprisingly useful and shockingly rare. Often, \nmodels are used not as tools of inquiry but as weapons in a war of advocacy. \nIn such cases modelers seek to hide the assumptions of their models from potential \ncritics. But even when the modelers’ motives are benign, many feel uncomfortable \nlisting what they’ve left out, see the omissions as flaws and prefer to stress the \nstrengths of their model. While this tendency is natural, it undercuts the utility of \nyour model and weakens the ability of people to learn from and improve your \nwork. By explicitly listing the concepts you have chosen not to include, at least \nfor now, you provide a visible reminder of the caveats to the results and limitations \nof the model. Without a clear understanding of the boundary and assumptions, ","page_start":123,"page_end":123,"token_count":227,"section_type":"other","chapter_number":4,"chapter_title":"Structure and Behavior of Dynamic Systems","chunk_index":156}
{"chunk_id":"33dacb8975689a7a","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"Chapter 3 The Modeling Process \n99 \nFIGURE 3-6 \nPatterns of \ncorporate growth \nmodels constructed for one purpose are frequently used for another for which they \nare ill-suited7 sometimes producing absurd results. All too often models with com- \npletely inappropriate and even bizarre assumptions about exogenous and excluded \nvariables are used in policy making because the model users are unable to exam- \nine the boundary of the models themselves and the modelers have not provided \nthat information for them (chapter 21 provides examples; see also Meadows and \nRobinson 1985). \nSubsystem diagram. A subsystem diagram shows the overall architecture of \na model. Each major subsystem is shown along with the flows of material, money, \ngoods, information, and so on coupling the subsystems to one another. Subsystems \ncan be organizations such as the firm and the customer or organizational subunits \nsuch as operations, marketing, and product development. Subsystem diagrams \nconvey information on the boundary and level of aggregation in the model by \nshowing the number and type of different organizations or agents represented. \nThey also communicate some information about the endogenous and exogenous \nvariables. \nIn the 1960s Jay Forrester served on the boards of several successful high-tech \ncompanies and became interested in the dynamics of corporate growth. To help \nhim think about the strategic issues facing these firms, Forrester (1964, p. 32) \ncreated a model designed “to show how the differing kinds of corporate growth \npatterns can be created by different corporate policies and management attitudes \nand by the interactions between a company and its market.” Figure 3-6 shows the \nreference mode. Forrester (pp. 32-33) explained: \nThe very rare company grows smoothly, as in curve A, and eventually reaches \na healthy sustained plateau of mature life. More frequently, the company follows a \npattern, as in curve B, where it appears to succeed at first and then encounters a \nsevere crisis that leads to bankruptcy or merger. Often, the pattern is growth stag- \nnation, as in curve C, marked by neither success nor failure. Of those companies \nwhich do show a long-term growth trend, the most common pattern is that in \ncurve D, where growth is accompanied by repeated crisis. \nTime \nSource: Adapted from Forrester (1 964). \n","page_start":124,"page_end":124,"token_count":496,"section_type":"other","chapter_number":4,"chapter_title":"Structure and Behavior of Dynamic Systems","chunk_index":157}
{"chunk_id":"b01d5616c5d8a471","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"100 \nPart I Perspective and Process \nFIGURE 3-7 \nSubsystem \ndiagram for \nForrester’s \ncorporate growth \nmodel \nForrester argued that “contrary to first impressions, one cannot explain these \ndifferences on the basis of the particular industry or the type and design of prod- \nucts.. . One must therefore look deeper into the structure of information flows and \nthe policies which guide operating decisions” (p. 33). To do so the model consisted \nof two subsystems, the company and the market (Figure 3-7). \nThe two subsystems are coupled by the obvious flows of orders, product, and \nmoney: The firm receives orders from the market, ships product, and receives pay- \nment. But in addition, the firm sends signals to the market including the price of \nthe product, its availability (measured by the delivery delay), its functionality, \nquality, suitability to customer needs, and other intangible attributes of the com- \npany’s reputation. The market responds to these signals through the order rate and \nthrough customer feedback about price, quality, service, product features, and so \non. The diagram elegantly presents the essential feedback processes coupling a \nfirm to its market, stresses that orders depend on much more than price, and begins \nto suggest the structure which must be captured within each subsystem. Forrester \nreflected on the importance of this conceptual framework in his thinking: \nDefining the system boundary and the degree of aggregation are two of the most \ndifficult steps in successful modeling. In this particular study, part-time effort for \nabout two years was devoted to false starts before arriving at the point shown in \n[Figure 3-71. Thereafter, only eight weeks were required to create the entire system \nof some 200 equations. \nChapter 15 presents a simple version of this model, Forrester’s “market growth \nmodel,” and shows how different management policies can create the patterns of \ngrowth described in Figure 3-6. \nA more detailed subsystem diagram is shown in Figure 3-8. The diagram \nshows the architecture for a model of a semiconductor manufacturer (Sterman, \nRepenning, and Kofman 1997). The purpose of the model was to explore the \ndynamics of process improvement programs. The firm had implemented a very \nProduct Suitability \n/Delivery \nof Product \nCompany \nMarket \n\\Payment-/ \nMkt. Response to Price \nMkt. Response to Quality \nSource: Adapted from Forrester (1 964). \n3\n’\n \n","page_start":125,"page_end":125,"token_count":542,"section_type":"other","chapter_number":4,"chapter_title":"Structure and Behavior of Dynamic Systems","chunk_index":158}
{"chunk_id":"e483513826d007fd","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"Chapter 3 The Modeling Process \n101 \nsuccessful quality improvement program. However, despite dramatic improve- \nments in quality, productivity, and customer responsiveness, operating profit \nand the stock price fell, leading to layoffs. Exploring this paradox required a \nmodel with a broad boundary both within the representation of the firm and in \ninteractions of the firm with its environment. Besides the usual subsystems for \nmanufacturing, product development, and accounting, the model includes a \nprocess improvement sector and a sector labeled “Financial Stress.” The Financial \nStress subsystem is not an organizational subunit but represents top manage- \nment decisions regarding layoffs, investment, and the attention given to process \nFIGURE 3-8 Subsystem diagram for model of a semiconductor firm and its quality \nProcess \nimprovement \nimprovement \nimprovement \ncommitment \n‘8 Quality \nI* Process \n‘e Workforce \ni rnp rovemen t Cp rog ram \n‘ \nMarket ’-\nCompeting \nProducts \nMarket \nshare \nPotential \nmarket \nCompetitor \nt \nNew \nProducts \nA \nPrice \nr \n\\ \n+ \n[New-Product Development’ \nDefects \nPricing \nOrders \nBreakthrough products \n0 Line extensions \nDevelolpment projects \n1 \nManagement \nAccounting \nManufacturing \ne Management \nsupport \n4 \nCost of goods sold \nCapital \n- \nc y ~ ~ ~ ; m e  4 \nLabor \nInventory \nt p g z t t d  Budget variances \nHiring/Firing \nInvestment \nOperating income \nLabor variances \nTakeover threat \nForecasted revenue \nI Desired fraction to R&D \nThe \nFirm \nFinancial ’ \nAccounting \nIncome statement \nBalance sheet \nFlow of funds \n7 \n/ \nd \nMarket Value \nFinancial Markets \nSource: Adapted from Sterman, Repenning, and Kofman (1 997). \n","page_start":126,"page_end":126,"token_count":406,"section_type":"other","chapter_number":4,"chapter_title":"Structure and Behavior of Dynamic Systems","chunk_index":159}
{"chunk_id":"453529f9fb9e7204","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"102 \nPart I Perspective and Process \nimprovement. These decisions were affected by the firm’s financial health and the \nthreat of takeover (as influenced by the market value of the firm relative to book \nvalue and cash flow). The diagram also shows that the firm’s sales and market \nshare are endogenous, as is competitor behavior (note that competitors respond not \nonly to the firm’s price but also to its quality improvement efforts). The stock price \nand market valuation of the firm are also endogenous. \nSubsystem diagrams are overviews and should not contain too much detail. \nThe diagram in Figure 3-8 is quite complex; subsystem diagrams should generally \nbe simpler. Multiple subsystem diagrams can be used to convey the hierarchical \nstructure of large models. \nCausal loop diagrams. Model boundary charts and subsystem diagrams \nshow the boundary and architecture of the model but don’t show how the variables \nare related. Causal loop diagrams (CLDs) are flexible and useful tools for dia- \ngramming the feedback structure of systems in any domain. Causal diagrams are \nsimply maps showing the causal links among variables with arrows from a cause \nto an effect. Chapter 2 provides examples; chapter 5 covers the rules for their con- \nstruction and interpretation in depth. \nStock and flow maps. Causal loop diagrams emphasize the feedback struc- \nture of a system. Stock and flow diagrams emphasize their underlying physical \nstructure. Stocks and flows track accumulations of material, money, and informa- \ntion as they move through a system. Stocks include inventories of product, popu- \nlations, and financial accounts such as debt, book value, and cash. Flows are the \nrates of increase or decrease in stocks, such as production and shipments, births \nand deaths, borrowing and repayment, investment and depreciation, and receipts \nand expenditures. Stocks characterize the state of the system and generate the in- \nformation upon which decisions are based. The decisions then alter the rates of \nflow, altering the stocks and closing the feedback loops in the system. Chapter 2 \nshows examples; chapters 6 and 7 discuss the mapping and behavior of stocks and \nflows. \nPolicy structure diagrams. These are causal diagrams showing the informa- \ntion inputs to a particular decision rule. Policy structure diagrams focus attention \non the information cues the modeler assumes decision makers use to govern the \nrates of flow in the system. They show the causal structure and time delays in- \nvolved in particular decisions rather than the feedback structure of the overall sys- \ntem. Chapter 15 provides examples; see Morecroft (1982) for details. \n3.5.3 \nFormulating a Simulation Model \nOnce you’ve developed an initial dynamic hypothesis, model boundary, and con- \nceptual model, you must test them. Sometimes you can test the dynamic hypothe- \nsis directly through data collection or experiments in the real system. Most of the \ntime, however, the conceptual model is so complex that its dynamic implications \nare unclear. As discussed in chapter 1, our ability to infer correctly the dynamics of \na complex model is extremely poor. Further, in many situations, especially human \nsystems, it is difficult, dangerous, unethical, or simply impossible to conduct the \n","page_start":127,"page_end":127,"token_count":676,"section_type":"other","chapter_number":4,"chapter_title":"Structure and Behavior of Dynamic Systems","chunk_index":160}
{"chunk_id":"2d79ba51dc1f5785","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"Chapter 3 The Modeling Process \n1 03 \nreal world experiments that might reveal the flaws in a dynamic hypothesis. In the \nmajority of cases, you must conduct these experiments in a virtual world. To do so, \nyou must move from the conceptual realm of diagrams to a fully specified formal \nmodel, complete with equations, parameters, and initial conditions. \nActually, formalizing a conceptual model often generates important insight \neven before it is ready to be simulated. Formalization helps you to recognize vague \nconcepts and resolve contradictions that went unnoticed or undiscussed during the \nconceptual phase. Formalization is where the real test of your understanding oc- \ncurs: computers accept no hand waving arguments. Indeed, the most experienced \nmodelers routinely write some equations and estimate parameters throughout the \nmodeling process, even in the earliest phases of problem articulation and concep- \ntualization-often with the clients-as a way to resolve ambiguity and test initial \nhypotheses. System dynamics practice includes a large variety of tests one can \napply during the formulation stage to identify flaws in proposed formulations and \nimprove your understanding of the system. \n3.5.4 \nTesting \nTesting begins as soon as you write the first equation. Part of testing, of course, is \ncomparing the simulated behavior of the model to the actual behavior of the sys- \ntem. But testing involves far more than the replication of historical behavior. Every \nvariable must correspond to a meaningful concept in the real world. Every equa- \ntion must be checked for dimensional consistency (so you aren’t adding apples and \noranges). The sensitivity of model behavior and policy recommendations must be \nassessed in light of the uncertainty in assumptions, both parametric and structural. \nModels must be tested under extreme conditions, conditions that may never \nhave been observed in the real world. What happens to the GDP of a simulated \neconomy if you suddenly reduce energy supplies to zero? What happens in a model \nof an automaker if you raise the price of its cars by a factor of one billion? What \nhappens if you suddenly increase dealer inventories by 1000%? Even though these \nconditions have never and could never be observed, there is no doubt about what \nthe behavior of the system must be: Without energy, the GDP of a modern econ- \nomy must fall nearly to zero; with a price one billion times higher, the demand for \nthe firm’s cars must fall to zero; with a huge surplus of cars on dealer lots, produc- \ntion should soon fall to zero but cannot become negative. You might imagine that \nmodels would never fail to pass such obvious tests, that production without energy, \ndemand for goods that cost more than the total wealth of many nations, and nega- \ntive production would never arise. But you’d be wrong. Many widely used models \nin economics, psychology, management, and other disciplines violate basic laws of \nphysics, even though they may replicate historical behavior quite well (see section \n9.3.2 and chapter 21). Extreme conditions tests, along with other tests of model be- ","page_start":128,"page_end":128,"token_count":650,"section_type":"other","chapter_number":4,"chapter_title":"Structure and Behavior of Dynamic Systems","chunk_index":161}
{"chunk_id":"353c7dec675b335c","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"demand for goods that cost more than the total wealth of many nations, and nega- \ntive production would never arise. But you’d be wrong. Many widely used models \nin economics, psychology, management, and other disciplines violate basic laws of \nphysics, even though they may replicate historical behavior quite well (see section \n9.3.2 and chapter 21). Extreme conditions tests, along with other tests of model be- \nhavior, are critical tools to discover the flaws in your model and set the stage for \nimproved understanding. \n3.5.5 \nPolicy Design and Evaluation \nOnce you and the client have developed confidence in the structure and behavior \nof the model, you can use it to design and evaluate policies for improvement. ","page_start":128,"page_end":128,"token_count":156,"section_type":"other","chapter_number":4,"chapter_title":"Structure and Behavior of Dynamic Systems","chunk_index":162}
{"chunk_id":"0e758f6866afb30f","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"104 \nPart I Perspective and Process \nPolicy design is much more than changing the values of parameters such as a tax \nrate or markup ratio. Policy design includes the creation of entirely new strategies, \nstructures, and decision rules. Since the feedback structure of a system determines \nits dynamics, most of the time high leverage policies will involve changing the \ndominant feedback loops by redesigning the stock and flow structure, eliminating \ntime delays, changing the flow and quality of information available at key decision \npoints, or fundamentally reinventing the decision processes of the actors in the sys- \ntem. \nThe robustness of policies and their sensitivity to uncertainties in model para- \nmeters and structure must be assessed, including their performance under a wide \nrange of alternative scenarios. The interactions of different policies must also be \nconsidered: Because real systems are highly nonlinear, the impact of combination \npolicies is usually not the sum of their impacts alone. Often policies interfere \nwith one another; sometimes they reinforce one another and generate substantial \nsynergies. \n3.6 SUMMARY \nThis chapter described the modeling process. While there are certain steps all mod- \nelers go through, modeling is not a cookbook procedure. It is fundamentally cre- \native. At the same time, modeling is a disciplined, scientific, and rigorous process, \nchallenging the modeler and client at every step to surface and test assumptions, \ngather data, and revise their models-both formal and mental. \nModeling is iterative. No one ever built a model by starting with step 1 and \nprogressing in sequence through a list of activities. Modeling is a continual process \nof iteration among problem articulation, hypothesis generation, data collection, \nmodel formulation, testing, and analysis. There are revisions and changes, blind al- \nleys and backtraclung. Effective modeling continually cycles between experiments \nin the virtual world of the model and experiments and data collection in the real \nworld. \nModels must be clearly focused on a purpose. Never build a model of a sys- \ntem. Models are simplifications; without a clear purpose, you have no basis for ex- \ncluding anything from your model and your effort is doomed to failure. Therefore \nthe most important step in the modeling process is working with your client to ar- \nticulate the problem-the real problem, not the symptoms of the problem, the lat- \nest crisis, or the most recent fad. Of course, as the modeling process leads you to \ndeeper insight, your definition and statement of the problem may change. Indeed, \nsuch radical reframings are often the most important outcome of modeling. \nThe purpose of modeling is to help the clients solve their problem. Though the \nmodeling process often challenges the clients’ conception of the problem, ulti- \nmately, if the client perceives that your model does not address their concern, you \ncan have little impact. The modeler must not grow attached to a model, no matter \nhow elegant or how much time has been invested in it. If it doesn’t help the clients \nsolve their problem, it needs to be revised until it does. ","page_start":129,"page_end":129,"token_count":650,"section_type":"other","chapter_number":4,"chapter_title":"Structure and Behavior of Dynamic Systems","chunk_index":163}
{"chunk_id":"63c33f696cb4c122","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"modeling process often challenges the clients’ conception of the problem, ulti- \nmately, if the client perceives that your model does not address their concern, you \ncan have little impact. The modeler must not grow attached to a model, no matter \nhow elegant or how much time has been invested in it. If it doesn’t help the clients \nsolve their problem, it needs to be revised until it does. \nModeling takes place in an organizational and social context. The setting may \nbe a business but can also be a government agency, a scientific community, a pub- \nlic policy debate, or any other organization. Modelers are inevitably caught up in ","page_start":129,"page_end":129,"token_count":140,"section_type":"other","chapter_number":4,"chapter_title":"Structure and Behavior of Dynamic Systems","chunk_index":164}
{"chunk_id":"f4c584ef4570beb0","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"Chapter 3 The Modeling Process \n105 \nthe politics of the community and personalities of its members. Modelers require \nboth first-rate analytical skills and excellent interpersonal and political skills. \nFinally, modelers have an ethical responsibility to pursue the modeling process \nwith rigor and integrity. The fact that modeling is embedded in an organizational \ncontext and subject to political pressures does not relieve you of your responsibil- \nity to carry out your work with the highest standards of scientific inquiry and pro- \nfessional conduct. If your client is not willing to pursue the modeling process \nhonestly, quit and find yourself a better client. \n","page_start":130,"page_end":130,"token_count":127,"section_type":"other","chapter_number":4,"chapter_title":"Structure and Behavior of Dynamic Systems","chunk_index":165}
{"chunk_id":"cb6a1dea17b16634","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"4 \nStructure and Behavior of \nDynamic Systems \nLike all systems, the complex system is an interlocking structure of feedback \nloops . . . This loop structure surrounds all decisions public or private, \nconscious or unconscious. The processes of man and nature, of psychology and \nphysics, of medicine and engineering all fall within this structure. \n-Jay W. Forrester, Urban Dynamics (1969), p. 107. \nThe behavior of a system arises from its structure. That structure consists of the \nfeedback loops, stocks and flows, and nonlinearities created by the interaction of \nthe physical and institutional structure of the system with the decision-making \nprocesses of the agents acting within it. This chapter provides an overview of dy- \nnamics focusing on the relationship between structure and behavior. The basic \nmodes of behavior in dynamic systems are identified along with the feedback \nstructures generating them. These modes include growth, created by positive feed- \nback; goal seeking, created by negative feedback; and oscillations (including \ndamped oscillations, limit cycles, and chaos), created by negative feedback with \ntime delays. More complex modes such as S-shaped growth and overshoot and col- \nlapse arise from the nonlinear interaction of these basic structures. The chapter also \nillustrates the concept of reference modes to capture dynamic behavior and causal \nloop diagrams as a method to represent feedback structure. \n1 07 \n","page_start":132,"page_end":132,"token_count":289,"section_type":"other","chapter_number":4,"chapter_title":"Structure and Behavior of Dynamic Systems","chunk_index":166}
{"chunk_id":"895eeef31aeca91c","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"108 \nPart I Perspective and Process \n4.1 \nFUNDAMENTAL MODES OF DYNAMIC BEHAVIOR \nChange takes many forms, and the variety of dynamics around us is astounding. \nYou might imagine that there must be a correspondingly huge variety of different \nfeedback structures to account for such a rich array of dynamics. In fact, most dy- \nnamics are instances of a fairly small number of distinct patterns of behavior, such \nas exponential growth or oscillation. Figure 4-1 shows the most common modes of \nbehavior. \nThe most fundamental modes of behavior are exponential growth, goal seek- \ning, and oscillation. Each of these is generated by a simple feedback structure: \ngrowth arises from positive feedback, goal seeking arises from negative feedback, \nand oscillation arises from negative feedback with time delays in the loop. Other \ncommon modes of behavior, including S-shaped growth, S-shaped growth with \novershoot and oscillation, and overshoot and collapse, arise from nonlinear inter- \nactions of the fundamental feedback structures. \n4.1 .I \nExponential Growth \nExponential growth arises from positive (self-reinforcing) feedback. The larger the \nquantity, the greater its net increase, further augmenting the quantity and leading to \never-faster growth (Figure 4-2). The paradigm cases are compound interest and the \ngrowth of populations. The more money you have invested, the more interest you \nearn, so the greater your balance and the greater still the next interest payment will \nbe. The larger the population, the bigger the net birth rate, adding to the population \nand eventually leading to still more births, in an ever-accelerating spiral. Pure ex- \nponential growth has the remarkable property that the doubling time is constant: \nthe state of the system doubles in a fixed period of time, no matter how large. \nFIGURE 4-1 \nCommon modes of behavior in dynamic systems \nSoal Seeking \nI S-shaDed Growth \n- \nTime - \nI Oscillation \nGrowth with Overshoot \nOvershoot and Collapse \n","page_start":133,"page_end":133,"token_count":436,"section_type":"other","chapter_number":4,"chapter_title":"Structure and Behavior of Dynamic Systems","chunk_index":167}
{"chunk_id":"f9f63e82f829cd33","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"Chapter 4 Structure and Behavior of Dynamic Systems \n109 \nIt takes the same length of time to grow from one unit to two as it does to grow \nfrom one million to two million. This property is a direct consequence of positive \nfeedback: the net increase rate depends on the size of the state of the system (see \nchapter 8). Positive feedback need not always generate growth. It can also create \nself-reinforcing decline, as when a drop in stock prices erodes investor confidence \nwhich leads to more selling, lower prices, and still lower confidence. \nWhat about linear growth? Linear growth is actually quite rare. Linear growth \nrequires that there be no feedback from the state of the system to the net increase \nrate, because the net increase remains constant even as the state of the system \nchanges. What appears to be linear growth is often actually exponential, but \nviewed over a time horizon too short to observe the acceleration. \nFigure 4-3 shows some examples of exponential growth. Growth is never per- \nfectly smooth (due to variations in the fractional growth rates, cycles, and pertur- \nbations), but in each case exponential growth is the dominant mode of behavior. \nThough the doubling times vary widely (from about 40 years for world population \nto about 2 years for semiconductor performance), these systems all exhibit the \nsame enormous acceleration caused by positive feedback. \nProcess Point: When a Rate Is Not a Rate \nIn dynamic modeling, the term “rate” generally refers to the absolute rate of \nchange in a quantity. The population growth example above states, “the larger the \nFIGURE 4-2 \nExponential growth: structure and behavior \nThe causal loop diagram in the bottom half \nof the figure shows the feedback structure \nthat generates (exponential growth. Arrows \nindicate the direction of causal influences. \nHere, State of the System determines Net \nIncrease Rate (the lower arrow), and Net \nIncrease Rate adds to State of the System \n(the upper arrow). Signs at arrow heads \n(f or -) indicate the polarity of the \nrelationship. A positive polarity, indicated \nby f ,  means an increase in the \nindependent va.riable causes the \ndependent variable to rise above what it \nwould have been (and a decrease causes \na decrease). Negative signs (see Figure \n4-4) mean an increase (decrease) in \nthe independent variable causes the \ndependent variable to decrease (increase) \nbeyond what it would have been. Loop \nidentifiers show the polarity of the loop, \neither positive (self-reinforcing, denoted \nby R) or negative (balancing, denoted \nby B; see Figure 4-4). Chapter 5 \ndiscusses causal loop diagrams in depth. \nf+ \n/ \nNet \nRate \nState of the \nIncrease \nSystem \n","page_start":134,"page_end":134,"token_count":595,"section_type":"other","chapter_number":4,"chapter_title":"Structure and Behavior of Dynamic Systems","chunk_index":168}
{"chunk_id":"a8035e5962bb1879","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"112 \nPart I Perspective and Process \nthe system is compared to the goal. If there is a discrepancy between the desired \nand actual state, corrective action is initiated to bring the state of the system back \nin line with the goal. When you are hungry, you eat, satisfying your hunger; when \ntired, you sleep, restoring your energy and alertness. When a firm’s inventory \ndrops below the stock required to provide good service and selection, production \nincreases until inventory is once again sufficient. \nEvery negative loop includes a process to compare the desired and actual con- \nditions and take corrective action. Sometimes the desired state of the system and \ncorrective action are explicit and under the control of a decision maker (e.g., the \ndesired level of inventory). Sometimes the goal is implicit and not under conscious \ncontrol, or under the control of human agency at all. The amount of sleep you need \nto feel well rested is a physiological factor not under your conscious control. The \nequilibrium surface temperature of the earth depends on the flux of solar energy \nand the concentration of greenhouse gases in the atmosphere, among other physi- \ncal parameters. And a cup of coffee cools via negative feedback until it reaches \nroom temperature. \nIn most cases, the rate at which the state of the system approaches its goal di- \nminishes as the discrepancy falls. We do not often observe a constant rate of ap- \nproach that suddenly stops just as the goal is reached. The gradual approach arises \nbecause large gaps between desired and actual states tend to generate large re- \nsponses, while small gaps tend to elicit small responses. The flow of heat from \nyour coffee cup to the air in the room is larger when the temperature gap between \nthem is large and diminishes as the gap falls. When coffee and room temperatures \nare equal, there is no net heat flow between them. \nWhen the relationship between the size of the gap and the corrective action is \nlinear, the rate of adjustment is exactly proportional to the size of the gap and the \nresulting goal-seeking behavior is exponential decay. As the gap falls, so too does \nthe adjustment rate. And just as exponential growth is characterized by its doubling \ntime, pure exponential decay is characterized by its halflife-the time it takes for \nhalf the remaining gap to be eliminated (see chapter 8). \nFigure 4-5 shows examples of goal-seeking behavior. The top left panel shows \nthe rate of defect generation in the wafer fabrication process of a major semi- \nconductor manufacturer. In 1987, the company began a process improvement \nprogram using principles of Total Quality Management. The goal of the program \nwas zero defects. In 4 years the defect rate declined from 1500 ppm to about 150 \nppm. Note that as the defect rate fell, the rate of improvement declined. The top \nright panel shows the average load factor (up time) for two Finnish nuclear power \nplants started up in 1978. The fraction of the year the plants operated increased \nrapidly at first, then more slowly, until a maximum of about 94% was reached. The ","page_start":137,"page_end":137,"token_count":655,"section_type":"other","chapter_number":5,"chapter_title":"Causal Loop Diagrams","chunk_index":169}
{"chunk_id":"de6206d5f04b0595","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"was zero defects. In 4 years the defect rate declined from 1500 ppm to about 150 \nppm. Note that as the defect rate fell, the rate of improvement declined. The top \nright panel shows the average load factor (up time) for two Finnish nuclear power \nplants started up in 1978. The fraction of the year the plants operated increased \nrapidly at first, then more slowly, until a maximum of about 94% was reached. The \nbottom left panel shows the share of all advertising dollars spent on television in \nthe US. Growth was rapid in the 1950s, but reached a fairly steady level of about \n20-25% by 1980. The bottom right panel shows the roughly exponential decline in \nautomobile-related fatalities in the US per 100 million vehicle miles driven. De- \nspite the substantial decline in death risk per mile, the number of miles driven has \ngrown exponentially, so the total number killed on the roads each year has fluctu- \nated between about 30 and 50 thousand since the 1930s. ","page_start":137,"page_end":137,"token_count":227,"section_type":"other","chapter_number":5,"chapter_title":"Causal Loop Diagrams","chunk_index":170}
{"chunk_id":"06083cc9876485e8","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"FIGURE 4-5 Goal-seeking behavior: examples \nSemi co n ci u cto r Fabrication Defect Rate \nu) 2 5 . ' ' >  \n\"\n.\n\"\n'\n\"\n\"\n'\n\"\n'\n \n~. \nl\n'\n\"\n'\nl\n'\n'\n'\n'\nl\n'\nl\n'\n'\n\"\n'\n'\n'\n.\n \n25 \n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ \nQ - \n.- I \n2 0 -  \n- \n0 20- \n0 \nc \n.- \n1 5 -  \n3 15- \nC \n0 .- - \n8\n:\n \n1 0 -  \ng 10- \n5 -  \n5 5: \n0 , , , , , / / , , , , , , I , I , . , I , I I  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  \nO\n.\n,\n,\n~\n.\n,\n.\n,\n.\n.\n,\n,\n,\n,\n,\n~\n,\n,\n,\n,\n,\n,\n,\n.\n,\n,\n,\n,\n,\n,\n~\n,\n \nI \nI \nI\n,\n,\n I \nI I 1  \n0 \n0 \nc, \nm \nQ) \n]\\ ' \nStart of TQM Program \n- \nv \n~ E l O O O j  \\ \nNuciear Piant Load Factor \n1001 \n'\nI\n '\nI\n '\nI\n '\nI\n '\n1\n '\nI\n '\nI\n \no\n/\n,\n,\n,\n,\n,\n,\n,\n,\n,\n,\n.\n,\n,\n.\n.\n~\n \n1987 \n1988 \n1989 \n1990 \n1991 \no r  \nI\n,\n I\n,\n,\n , \n. \n, \nI\n,\n I \nI\n,\n I \n1978 \n1980 \n1982 \n1984 \n1986 \n1988 \n1990 \n1992 \n","page_start":138,"page_end":138,"token_count":412,"section_type":"other","chapter_number":5,"chapter_title":"Causal Loop Diagrams","chunk_index":171}
{"chunk_id":"58503c91052771a4","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"114 \nFIGURE 4-6 \nOscillation: \nstructure and \nbehavior \nDelays can exist \nin any of the \ncausal links in a \nnegative feedback \nloop. Oscillation \ncan occur if there \nare delays in at \nleast one of \nthe links in a \nnegative loop. \nPart I Perspective and Process \n4.1.3 Oscillation \nOscillation is the third fundamental mode of behavior observed in dynamic sys- \ntems. Like goal-seeking behavior, oscillations are caused by negative feedback \nloops. The state of the system is compared to its goal, and corrective actions are \ntaken to eliminate any discrepancies. In an oscillatory system, the state of the sys- \ntem constantly overshoots its goal or equilibrium state, reverses, then undershoots, \nand so on. The overshooting arises from the presence of significant time delays in \nthe negative loop. The time delays cause corrective actions to continue even after \nthe state of the system reaches its goal, forcing the system to adjust too much, and \ntriggering a new correction in the opposite direction (Figure 4-6). \nOscillations are among the most common modes of behavior in dynamic sys- \ntems. There are many types of oscillation, including damped oscillations, limit cy- \ncles, and chaos (see section 4.3.3). Each variant is caused by a particular feedback \nstructure and set of parameters determining the strengths of the loops and the \nlengths of the delays. But every type of oscillation has, at its core, a negative feed- \nback loop with delays. \nOscillations can arise if there is a significant delay in any part of the negative \nloop. As shown in Figure 4-6, there may be delays in any of the information links \nmaking up the loop. There may be delays in perceiving the state of the system \ncaused by the measurement and reporting system. There may be delays in initiat- \ning corrective actions after the discrepancy is perceived due to the time required \nState of the \nSystem \nTime - \nMeasurement, \nReporting, and \nPerception \nDelays \n+ Stateof the / \nGoal \nAction , /r sg \nDelays \nState of System) \n~ (Desired \nDiscrepancy + \n' \nDelay \nAdministrative and \nDelays \nCorrective \nAction \n+ \nDecision-Ma king \n","page_start":139,"page_end":139,"token_count":508,"section_type":"other","chapter_number":5,"chapter_title":"Causal Loop Diagrams","chunk_index":172}
{"chunk_id":"8610c40e5363e901","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"Chapter 4 Structure and Behavior of Dynamic Systems \n115 \nto reach a decision. And there may be delays between the initiation of a corrective \naction and its effect on the state of the system. It takes time for a company to mea- \nsure and report inventory levels, time for management to meet and decide how \nmuch to produce, and more time while raw materials procurement, the labor force, \nand other needed resources respond to the new production schedule. Sufficiently \nlong delays at any one of these points could cause inventory to oscillate. \nFigure 4-3 showed real GDP in the US. The dominant mode of behavior in the \ndata is exponential growth. But the growth is not smooth. Output fluctuates around \nthe growth trend. In the top panel of Figure 4-7 these oscillations are revealed by \ndetrending the GDP data (removing the best fit exponential function). After the ex- \nponential growth is removed, the business cycle is clearly visible as a fluctuation \naveraging about 5% in amplitude and with an average period of about 4 years. A \nlonger and larger fluctuation in real production is also apparent, with peaks relative \nto trend around 1910 and 1970-the so-called economic long wave.l The bottom \npanels of Figure 4-7 show two critical business cycle indicators--capacity utiliza- \ntion in the US manufacturing sector and the civilian unemployment rate. The am- \nplitude of the business cycle in these important variables is quite large. Utilization \ntypically fluctuates 15 points from peak to trough (nearly 20% of its average \nvalue), while unemployment during the postwar period in the US has ranged from \nunder 3% to nearly 11% of the labor force, with much higher values in Europe. \nNote that the business cycle (and most real world oscillations) is not perfectly \nregular. You should not expect it to be. Many people think a cycle must be as pre- \ndictable as the dawn, as regular as the orbits of the planets, as smooth and sym- \nmetric as the swing of a pendulum clock. But these paradigms of periodicity are \nspecial systems. The planets interact mainly with the sun and only weakly with one \nanother.2 A pendulum clock has been carefully designed to generate a regular mo- \ntion by isolating its components from the environment. Biological, social, and eco- \nnomic systems, in contrast, involve huge numbers of interactions among tightly \ncoupled elements. They are continuously bombarded by perturbations that cause \ntheir motion to be somewhat irregular, a (usually nonlinear) combination of their \nendogenous dynamics and these exogenous shocks (see section 4.3.2). \n‘The long wave, or Kondratiev cycle, has an average period of about 60 years and, as seen in the \ndata, an amplitude much larger than the short-term business cycle. Sterman (1986) and Forrester \n(1977, 1983) present theory and evidence for the existence and feedback structure generating the ","page_start":140,"page_end":140,"token_count":644,"section_type":"other","chapter_number":5,"chapter_title":"Causal Loop Diagrams","chunk_index":173}
{"chunk_id":"7c61ea1c4991ddee","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"endogenous dynamics and these exogenous shocks (see section 4.3.2). \n‘The long wave, or Kondratiev cycle, has an average period of about 60 years and, as seen in the \ndata, an amplitude much larger than the short-term business cycle. Sterman (1986) and Forrester \n(1977, 1983) present theory and evidence for the existence and feedback structure generating the \nlong wave. Sterman (1985b) presents a simple model of the long wave; Sterman 1989a reports an \nexperimental test of the model, and Sterman (1989~) shows that many of the decision rules charac- \nterizing human subjects in the experiment generate chaotic dynamics. \ning as tidal and frictional forces dissipate the earth’s rotational energy. Recent research shows that \nthe orbits of most of the planets are chaotic and that chaotic resonances among the planets can hurl \nmeteorites and asteroids from distant orbits into trajectories that cross the earth’s orbit, perhaps ac- \ncounting for the impacts now believed to have caused the major extinctions. It is only our short (by \nheavenly standards) record of observations that causes us to perceive the solar system to be stable \nand predictable. Peterson (1993) provides an excellent nontechnical treatment of chaotic dynamics \nin the solar system; Diacu and Holmes (1996) cover the origins of chaos in theories of celestial me- \nchanics. Jack Wisdom of MIT pioneered computer simulations that revealed the chaotic character \nof the solar system (see Wisdom 1987 for a review). See section 4.3.3 for more on chaos. \n2Actually, the apparent regularity of the solar system is illusory. The length of the day is increas- ","page_start":140,"page_end":140,"token_count":376,"section_type":"other","chapter_number":5,"chapter_title":"Causal Loop Diagrams","chunk_index":174}
{"chunk_id":"0b0ec690b8981708","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"116 \nFIGURE 4-7 \nOscillation: \nexamples \nThe business \ncycle in the \nUnited States. \nTop: Deviation \nof real GDP \nfrom long-term \nexponential trend. \nMiddle: Capacity \nutilization. \nBottom: Civilian \nunemployment. \nPart I Perspective and Process \nUS Real GDP Deviation from Trend \n.- \nI \n2000 \n-0.41 \nI \n8 \nI \nI \n, \n, \nI \nI \n, \n, \n. \n, \n, \n, \nI \n1850 \n1900 \n1950 \nCapacity Utilization, US Manufacturing \n1945 \n1955 \n1965 \n1975 \n1985 \n1995 \nUS Unemployment Rate \n1 2  '\n'\n'\n'\n\"\n'\n~\n'\n'\nI\n~\n \n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n \n\" I  \nSource: Historical Statistics of the United States, US Bureau of Economic Analysis. \n4.1.4 Process Point \nThe connection between structure and behavior provides a useful heuristic for the \nconceptualization process. Any time you observe exponential growth in a variable, \nyou know there is at least one positive feedback in which the variables of interest \nparticipate (and possibly more). There will, of course, be many negative loops \npresent as well. However, if the system is exhibiting exponential growth, then you \nknow that positive loops are dominant (at least during the regime in which growth \n","page_start":141,"page_end":141,"token_count":333,"section_type":"other","chapter_number":5,"chapter_title":"Causal Loop Diagrams","chunk_index":175}
{"chunk_id":"d56565e1c19beb6c","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"Chapter 4 Structure and Behavior of Dynamic Systems \n117 \noccurs). You can then guide the discussion among the client group toward the iden- \ntification of self-reinforcing processes. Typically, the group will be able to identify \nmany positive loops involving the variables of interest. Of course, it is not possi- \nble to tell which of these candidate loops are active and contributing to the behav- \nior, nor their relative strengths, without recourse to data and/or model simulations. \nBut focusing on the connection between structure and behavior helps generate \nfruitful hypotheses about the key loops. \nSimilarly, any time you observe the other core modes of behavior, you imme- \ndiately know what types of loop must be dominant, guiding your initial search for \nthe structures responsible. Oscillation, for example, must mean there is an impor- \ntant negative feedback with significant time delays. You can then ask about the de- \ncision processes by which the variable is regulated and the time delays in the \nperception of the state of the system, in the decision process, and in the response \nof the system to the corrective actions of the decision makers. \nA caveat: This heuristic helps in the identification of the feedback structures \nresponsible for the observed behavior. In addition, it is essential to consider what \nstructures exist but have not yet played a significant role in the history of the sys- \ntem or left a trace in the available data. As the system evolves these latent feed- \nbacks may become dominant, dramatically changing the dynamics, shifting trends \nand patterns, and altering the system’s response to policies. Identifying potential \nshifts in loop dominance arising from latent structures is a valuable function of \nmodeling. \nTo illustrate, return to the case of exponential growth. No real quantity can \ngrow forever. Eventually, one or more negative loops will become dominant as \nvarious limits to growth are approached. Immediately after identifying some posi- \ntive loops potentially responsible for observed growth, you should ask, What neg- \native loops might stop the growth? Most people can easily generate a wide range \nof potential limits and constraints to the growth of the system. Identifying the po- \ntential constraints to growth is a powerful way to identify possible future bottle- \nnecks and limits, even if there is no evidence of a slowdown in the data. As with \nthe identification of positive loops, empirical investigation and modeling are re- \nquired to determine which negative loops are strongest, what limits to growth they \nreflect, and whether those limits can be relaxed or tightened by other feedbacks or \nthrough policy interventions (see section 4.2.1). \nIdentifying Feedback Structure from System Behavior \n1. Identify the positive loops responsible for the growth in the examples \nshown in Figure 4-3. Sketch a causal loop diagram to capture the loops you \nidentify. Identify as many negative feedbacks that might halt growth in \nthese systems as you can. \n2. Identify the negative loops that might be responsible for the goal-seeking \nbehaviors shown in Figure 4-5. Identify the state of the system, the goal, \nand the corrective action(s) for each case. What counterforces might \nprevent the state of the system from reaching its goal? \n","page_start":142,"page_end":142,"token_count":678,"section_type":"other","chapter_number":5,"chapter_title":"Causal Loop Diagrams","chunk_index":176}
{"chunk_id":"928b8996effd59df","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"118 \nPart I Perspective and Process \n3. Identify the negative loops and time delays that might be responsible for the \noscillations in economic affairs illustrated by Figure 4-7. Identify the state \nof the system, the goal, the corrective action, and delays. Estimate the \nlength of the time delays you identify. \n4.2 INTERACTIONS OF THE FUNDAMENTAL MODES \nFIGURE 4-8 \nS-shaped growth: \nstructure and \nbehavior \nThe three basic modes of behavior-exponential growth, goal seeking, and oscil- \nlation-are caused by three basic feedback structures: positive feedback, negative \nfeedback, and negative feedback with delays. Other, more complex patterns of be- \nhavior arise through the nonlinear interaction of these structures with one another. \n4.2.1 \nS-shaped Growth \nAs discussed above, no real quantity can grow (or decline) forever: eventually one \nor more constraints halt the growth. A commonly observed mode of behavior in \ndynamic systems is S-shaped growth-growth is exponential at first, but then grad- \nually slows until the state of the system reaches an equilibrium level. The shape of \nthe curve resembles a stretched-out “S” (Figure 4-8). To understand the structure \nunderlying S-shaped growth it is helpful to use the ecological concept of carrying \ncapuci~. The carrying capacity of any habitat is the number of organisms of a \nparticular type it can support and is determined by the resources available in the \nCarrying Capacity \nTime- \n/-----%+ \nState of the \nNet \nIn::. \n@ System \nResource \nCarrying \nCapacity \nFractional \nNet Increase \nAdequacy \n","page_start":143,"page_end":143,"token_count":356,"section_type":"other","chapter_number":5,"chapter_title":"Causal Loop Diagrams","chunk_index":177}
{"chunk_id":"d2b688c26984aa7c","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"Chapter 4 Structure and Behavior of Dynamic Systems \n119 \nenvironment and the resource requirements of the population. As a population \napproaches its carrying capacity, resources per capita diminish thereby reducing \nthe fractional net increase rate until there are just enough resources per capita to \nbalance births and deaths, at which point the net increase rate is zero and the pop- \nulation reaches equilibrium. Any real quantity undergoing exponential growth can \nbe interpreted as a population drawing on the resources in its environment. As the \ncapacity of the environment is approached, the adequacy of the required resources \ndiminishes, and the fractional net increase rate must decline. The state of the sys- \ntem continues to grow, but at a slower rate, until resources are just scarce enough \nto halt growth. In general, a population may depend on many resources, each cre- \nating a negative loop which might limit growth. The constraint that is most bind- \ning determines which of the negative loops will be most influential as the state of \nthe system grows. \nThe carrying capacity concept is subtle and complex. While it is appropriate to \nconsider the carrying capacity of an environment to be constant in some situations, \nin general the carrying capacity of an environment is intimately intertwined with \nthe evolution and dynamics of the species it supports. We humans alter the carry- \ning capacity of the planet in ways both intended and unintended, through the de- \nvelopment of technology enabling greater utilization of resources, through changes \nin cultural practices and norms for consumption of resources per capita, and \nthrough consumption, depletion, and erosion of the various resources upon which \nwe depend. Even so-called lower species interact with their environment to alter \nthe carrying capacity. The co-evolution of flowers and pollinating insects permit- \nted greater population densities for both. Similarly, all businesses and organiza- \ntions grow in the context of a market, society, and physical environment that \nimposes limits to their growth. As with natural populations, these limits can in- \ncrease or decrease, both exogenously and, more importantly, endogenously, as the \norganization interacts with its customers, competitors, suppliers, regulators, and \nother entities in the system. In general, one must model the various resources that \ntogether determine the carrying capacity-for a species or an organization-as an \nendogenous element of the system. \nDespite the dynamic character of the carrying capacity, there is, at any mo- \nment, a limit to the size of the population (the current carrying capacity), which, if \nexceeded, causes the population to fall. Further, the carrying capacity itself cannot \ngrow forever. The laws of thermodynamics dictate an absolute limit to the carrying \ncapacity of the earth, though there is no agreement among scholars as to what that \nlevel is, how it is changing, whether population should grow to the carrying ca- \npacity or be voluntarily stabilized below it, or whether a population as large as the \ncarrying capacity would enable a reasonable quality of life or provide only the bare \nminimum for ~ubsistence.~ \nA system generates S-shaped growth only if two critical conditions are met. ","page_start":144,"page_end":144,"token_count":646,"section_type":"other","chapter_number":5,"chapter_title":"Causal Loop Diagrams","chunk_index":178}
{"chunk_id":"eb42974819ef315f","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"capacity of the earth, though there is no agreement among scholars as to what that \nlevel is, how it is changing, whether population should grow to the carrying ca- \npacity or be voluntarily stabilized below it, or whether a population as large as the \ncarrying capacity would enable a reasonable quality of life or provide only the bare \nminimum for ~ubsistence.~ \nA system generates S-shaped growth only if two critical conditions are met. \nFirst, the negative loops must not include any significant time delays (if they did, \nthe system would overshoot and oscillate around the carrying capacity; see section \n3For good discussion of the uncertainty in definitions and estimates of the earth’s carrying \ncapacity, see Cohen (1995). For system dynamics models in which the carrying capacity of the \nearth is treated endogenously and dynamically, see Meadows, Meadows, and Randers (1992). ","page_start":144,"page_end":144,"token_count":185,"section_type":"other","chapter_number":5,"chapter_title":"Causal Loop Diagrams","chunk_index":179}
{"chunk_id":"d3f9a367410f4b42","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"120 \nPart I Perspective and Process \n100 \n1 \n7 5 -  \n5 0 -  \n2 5 -  \n0 \nFIGURE 4-9 \nS-shaped growth: \nexamples \n\" \" \" \" \" \" \" \" \" \" \" \"  \n% of Households with TV \nCable Subscribers \n(Million Households) \n,- \nI \nI \nI \n, \n, . \n, \n, \n, \n, \nI \nI \n, \nI \n, \nI \n* \nI \nGrowth of Sunflowers \n300 1 \nI \n, \nI \n0 \n1 4  \n2 8  \n4 2  \n5 6  \n7 0  \n8 4  \nDays \nAdoption of Cardiac Pacemaker by Physicians \ni \nI \nF \n0 \n1960 \n1962 \n1964 \n1966 \n1968 \n1970 \n1972 \nSource: Sunflowers: Lotka (1 956, p. 74); Cable TV: Kurian (1 994), Statistical Abstract of the US; \nPacemaker adoption: Homer (1 983, 1987). \n2000 \n100 \nc \ns \n2 5  \n4.2.2). Second, the carrying capacity must be fixed. It cannot be consumed by the \ngrowth of the population, lest the population exhaust its resources and force itself \ninto extinction, as a population of yeast consumes the sugar in a cask of wine, ul- \ntimately causing fermentation to stop (see section 4.2.3). \n","page_start":145,"page_end":145,"token_count":332,"section_type":"other","chapter_number":5,"chapter_title":"Causal Loop Diagrams","chunk_index":180}
{"chunk_id":"184847bd5908fd2d","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"Chapter 4 Structure and Behavior of Dynamic Systems \n121 \nFIGURE 4-10 \nS-shaped grow1:h \nwith overshoot \nand oscillation: \nstructure and \nbehavior \nA key aspect of the structure generating S-shaped growth is that the interaction \nof the positive and negative loops must be nonlinear. At first, when the state of the \nsystem is small relative to the resource base, the limits to growth are distant and the \npositive loops dominate. An additional unit added to the state of the system con- \ntributes more to the net increase rate than it decreases the fractional net increase \nrate by reducing resource adequacy. The state of the system grows exponentially. \nHowever, as a direct consequence of that growth, the adequacy of the resource \nbase falls. As the limits to growth are approached, the negative loops grow stronger \nand stronger, until they begin to dominate the dynamics. The inflection point in the \ncurve is the point where the system, though still growing, shifts from acceleration \nto deceleration. The inflection marks the point at which there is a shift in loop \ndominance. It is the point at which an additional unit added to the state of the sys- \ntem reduces the fractional net increase rate more than it adds to the total population \ndriving the growth. \nFigure 4-9 shows some examples of S-shaped growth. Whether the growth of \na plant, the diffusion of a new product or service such as cable television, or the \nadoption of a new idea or technology like the cardiac pacemaker, growth always \nconfronts limits. \n4.2.2 \nS-Shaped Growth with Overshoot \nS-shaped growth requires the negative feedbacks that constrain growth to act \nswiftly as the carrying capacity is approached. Often, however, there are signifi- \ncant time delays in these negative loops. Time delays in the negative loops lead to \nthe possibility that the state of the system will overshoot and oscillate around the \ncarrying capacity (Figure 4-10). Figure 4-11 shows some examples of S-shaped \ngrowth with overshoot and oscillation. \nCarrying Capacity \nState of the \nSystem \nTime - \nNet p+ \nIncrease \nState of the \n ate @ System \n@ \nResource \nCarrying \nFractional \nNet Increase \nRate \nAdequacy \nCapacity \n+y-f \n-F u \n","page_start":146,"page_end":146,"token_count":497,"section_type":"other","chapter_number":5,"chapter_title":"Causal Loop Diagrams","chunk_index":181}
{"chunk_id":"9e5cc1e089e0a5e2","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"122 \n5000 \nz \n5 I \n+ \n0 .- \n2500- \nI \nU \nm \na \nc \n+ \nFIGURE 4-1 1 \nS-shaped growth \nwith overshoot \nand oscillation: \nexamples \n,\n,\n,\nI\n,\n,\n \nI \n1\n.\n1\n,\n \n1\n,\ns\n \ni\n,\n,\n,\n,\n~\n \n,\n/\n,\n 1\n1\n1\n \n, \no-,-, \n, ,-\n,  \n, ,  , , ,  , , ,  , , ,  , \nPart I Perspective and Process \nPopulation of London \n1 0 '  \" \n' \" \n' \n\" \n' \n1 \n' \n1\n'\n I \n\" \" \n1 \n1800 \n1850 \n1900 \n1950 \n2000 \nIdentifying the Limits to Growth \nWhat are the limits to growth for the population of a city and the rise in production \nof commodities such as aluminum? Identify the negative feedbacks that halt the \ngrowth in each case. Identify the time delays responsible for the overshoot and \n41n Urban Dynamics, Forrester (1969) presents a model of urban growth and stagnation, show- \ning how many urban renewal policies actually accelerate the decay of the inner city. Mass (1975) \nand Schroeder, Sweeney, and Alfeld (1975) extend and apply the results of Urban Dynamics, and \nAlfeld and Graham (1976) build up a simplified version of the Urban Dynamics model suitable for \nteaching. \n","page_start":147,"page_end":147,"token_count":332,"section_type":"other","chapter_number":5,"chapter_title":"Causal Loop Diagrams","chunk_index":182}
{"chunk_id":"161cd6c78a5e5f89","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"Chapter 4 Structure and Behavior of Dynamic Systems \n123 \n4.2.3 \nOvershoot and Collapse \nThe second critical assumption underlying S-shaped growth is that the carrying \ncapacity is fixed. Often, however, the ability of the environment to support a \ngrowing population is eroded or consumed by the population itself. For example, \nthe population of deer in a forest can grow so large that they overbrowse the \nvegetation, leading to starvation and a precipitous decline in the population. Figure \n4-12 shows the feedback structure and typical behavior for the overshoot and col- \nlapse behavior mode. \nConsumption or erosion of the carrying capacity by the population creates a \nsecond negative feedback limiting growth. Population growth now cuts resource \nadequacy two ways: by reducing the resources available per capita and by reduc- \ning total resources. As in the S-shaped growth case, when resources are initially \nample the positive growth loop dominates and the state of the system grows expo- \nnentially. As it grows, resource adequacy drops. The negative loops gradually gain \nin strength. At some point, the net increase rate falls to zero, and the population \nreaches its maximum. But unlike the S-shaped growth case, the system does not \nreach equilibrium. When the population reaches its peak, the rate of decline of the \ncarrying capacity is at its maximum. The carrying capacity continues to drop, re- \nsources per capita fall further, and the net increase rate of the population becomes \nnegative. The state of the system declines. Even as it declines, the remaining pop- \nulation continues to consume the carrying capacity, so resources per capita remain \nFIGURE 4-1 2 \nOvershoot and \ncollapse: structure \nand behavior \n/-------+ \n-+ \nConsumption/ \nErosion of \nCarrying Capacity \nState of the \nNet \nIncrease \nr- w\n)\n \n1- \nResource \nCarrying \nAdequacy \nCapacity \nFractional @ \nNet Increase \nRate \n+ u \n+\n-\n \n","page_start":148,"page_end":148,"token_count":431,"section_type":"other","chapter_number":5,"chapter_title":"Causal Loop Diagrams","chunk_index":183}
{"chunk_id":"4b1bded0ec8829c5","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"c \n0 \nN \n0 \nQ, \n-Q, ' \n0 \nQ, \n_ E o  ' \n0 \nIC \n- Q ,  ' \n0 \nW \n-Q, ' \n0 \n0 \n0 \n0 \n0\n'\n \nd \nm \nN \n' \nieaHMw puesnoyl \n0 \n0 \n0 \n0 \n0 7  \nd \ncc) \nN \n' \n'20 AOJI/$ \nI '  \n4 ,\n,\n,\n,\n,\n,\n,\n,\nI\n ,\n,\n,\n,\n,\n,\n 1 \n0 \nco \nco \n0 \n0 \n0' \n0 \nv) \n4- \nw\no\n \nE\nm\n \nU \nS \nm \n124 \n","page_start":149,"page_end":149,"token_count":159,"section_type":"other","chapter_number":5,"chapter_title":"Causal Loop Diagrams","chunk_index":184}
{"chunk_id":"af4de1683385652f","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"Chapter 4 Structure and Behavior of Dynamic Systems \n125 \ninsufficient and the population keeps falling. If there is no regeneration of the car- \nrying capacity (if it is strictly nonrenewable), the equilibrium of the system is ex- \ntinction: any nonzero population continues to consume the resource base, forcing \nit to zero, and with it, the population. If the carrying capacity can be regenerated or \nsupplemented with renewable resources, a nonzero equilibrium can be sustained. \nFigure 4-13 shows some examples of overshoot and collapse. The New Eng- \nland Haddock fishery collapsed due to overfishing of Georges Bank, once one of \nthe world’s richest fishing areas. Overfishing has also shut down the Canadian and \nUS cod fishery, and similar overexploitation is common in fisheries around the \nworld.5 Nuclear power construction ground to a halt in the 1980s as high-level \nwaste-and public concern over safety-accumulated and as the costs of nuclear \npower steadily escalated. The Atari Corporation was the leader of the first wave of \nhome and arcade video games in the late 1970s. Sales doubled roughly every year \nfrom 1976 through 1982. Abrupt saturation of the market-depletion of the stock \nof potential customers-led to a precipitous drop in sales from $2 billion per year \nin 1982 to $100 million per year in 1984. The company lost about $600 million \nduring the collapse. Silver experienced a classic speculative bubble in the late \n1970s, with prices rising tenfold in a year, then collapsing even more precipitously. \nThe interplay between population and carrying capacity leading to overshoot \nand collapse is illustrated in Figure 4-14, which shows the population of Easter \nIsland (Rapa Nui in the local language) and a measure of the carrying capacity de- \nrived from pollen cores indicating the extent of tree cover. \nEaster Island, one of the most remote spots on earth, is a small island of about \n160 km2 located in the eastern Pacific. Easter Island is most famous for the giant \nstone statues, known as moai, that dot the island. Radiocarbon dating puts the ar- \nrival of the first settlers, intrepid sailors of Polynesian origin, at about the year 400 \nand not later than 690. Population is estimated to have grown slowly until about \n1 100, when growth accelerated dramatically, perhaps doubling about every cen- \ntury, until about the year 1400. Pollen counts from soil cores and other records \nshow that prior to the arrival of the first humans, Easter Island was lushly forested \nand supported a diverse set of fauna, particularly birds (Bahn and Flenley 1992; \nSteadman 1995). However, as the human population grew, the forests were pro- \ngressively cut to provide wood and fiber for boats, structures, ropes, and tools, as \nwell as to provide firewood. The Polynesian rat, which arrived with the original ","page_start":150,"page_end":150,"token_count":647,"section_type":"other","chapter_number":5,"chapter_title":"Causal Loop Diagrams","chunk_index":185}
{"chunk_id":"7a90920aab005962","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"and supported a diverse set of fauna, particularly birds (Bahn and Flenley 1992; \nSteadman 1995). However, as the human population grew, the forests were pro- \ngressively cut to provide wood and fiber for boats, structures, ropes, and tools, as \nwell as to provide firewood. The Polynesian rat, which arrived with the original \nsettlers, hastened the decline by killing birds and eating the seeds and nuts of the \nnative palm. \nBy about the year 1400, deforestation was nearly complete. The loss of tree \ncover dramatically reduced the island’s carrying capacity. There is clear strati- \ngraphic evidence that soil erosion increased with deforestation as rain washed \naway the unprotected soil. Without tree cover, wind speeds at ground level in- \ncreased, carrying still more valuable soil into the sea. The erosion was so severe \n5The “Fishbanks” simulation (Meadows, Fiddaman, and Shannon 1993) is a wonderful role-play \nmanagement flight simulator illustrating the dynamics of renewable resources such as fisheries. ","page_start":150,"page_end":150,"token_count":230,"section_type":"other","chapter_number":5,"chapter_title":"Causal Loop Diagrams","chunk_index":186}
{"chunk_id":"15d14c7c04203786","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"126 \nFIGURE 4-1 4 \nEstimated \npopulation and \ntree cover of \nEaster Island \nTop: Population \nestimates for \nEaster Island are \nhighly uncertain. \nThe graph shows \nthe likely range of \npopulation based \non data in Bahn \nand Flenley (1 992, \npp. 80, 178ff). \nBottom: Pollen \nrecords from soil \ncore at Rano Kau, \nEaster Island, \nshowing decline \nin the fraction of \npollen from trees \nand shrubs, \nindicating the \ndeforestation \nof the island \n(remainder of \npollen from \ngrasses, sedges, \nherbs, and ferns). \nDeforestation \nwas essentially \ncomplete by \nabout 1400. \nPart I Perspective and Process \n10000 \nS \n0 .- \n4- 4 5000 \nZT \n0 \nn \n0 \nPopulation of Easter Island \n400 \n0 \n800 \n1200 \nTree Cover \n1600 \n2000 \n100 \nI \nI \nI \nI \n1400 \nYear \n590 \n910 950 \n+50 \nf60 f70 \n+60 \n0 \nDepth \n10 \n(meters) \nNote: Time axes for top and bottom graphs differ. \nSource: Bahn and Flenley (1992, p. 174). \nthat sediment washed from the higher elevations eventually covered many of the \nmoai, so that European visitors thought the giant statues were just heads, when in \nfact they were complete torsos averaging 20 feet in height. Deforestation also in- \ncreased evaporation from the soil and may have reduced rainfall. The few streams \non the island dried up, further reducing food production and the fresh water supply. \nEventually, fishing, the other main source of food, also fell, as boats, lines, and \nhooks, all made from wood, could no longer be replaced. When the first Europeans \narrived, the islanders prized wood above all other items offered in trade. Most of \nthe bird species living on Easter Island became at least locally extinct. Only 1 of \nabout 25 indigenous species still nests on the island today (Steadman 1995). \n","page_start":151,"page_end":151,"token_count":478,"section_type":"other","chapter_number":5,"chapter_title":"Causal Loop Diagrams","chunk_index":187}
{"chunk_id":"a4313f5acf9da05c","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"Chapter 4 Structure and Behavior of Dynamic Systems \n127 \nAs the carrying capacity declined, population growth slowed, reaching a peak \ngenerally estimated to be between 6000 and 10,000 people around the year 1600. \nA precipitous decline in population had set in by about 1680, accompanied by \nmajor changes in social, political, and religious structures. Spear points and other \ntools of war appeared for the first time, and there is evidence of large battles \namong competing groups. Some scholars believe there is evidence of cannibalism \nduring this period. The first Europeans known to visit Easter Island arrived in 1722 \nand found a small and poor population. Scholars generally accept an estimate of \n2000 people in 1786. After Peruvian slave raids and a subsequent smallpox epi- \ndemic the population fell to 111 in 1877. The population recovered to about 2100 \nby the early 1990s, largely the result of immigration and settlement from Chile, \nwhich has governed the island since 1888. \nThe overshoot and collapse of Easter Island is but one of many similar \nepisodes documented in the history of island biogeography (see Kirch 1997). In \neach case, population growth led to deforestation, the extinction of native species, \nand unfavorable changes in local climate, rainfall, and agricultural productivity, \nfollowed by starvation, conflict, and, often, population collapse.6 \n4.3 \nOTHER MODES OF BEHAVIOR \nGrowth, goal seeking, oscillation, and their combinations: are these the only pat- \nterns of behavior systems can exhibit? No, but they cover the vast majority of dy- \nnamics. There are other patterns, for example: (1) stasis, or equilibrium, in which \nthe state of the system remains constant over time; and (2) random variation. \n4.3.1 \nStasis, or Equilibrium \nConstancy arises either because dynamics affecting the state of the system are so \nslow that change is imperceptible or because there are powerful negative feedback \nprocesses keeping the state of the system nearly constant even in the face of envi- \nronmental disturbances. In the former case, change is too slow relative to your time \nhorizon to be meaningful. In the latter case, constancy is an example of highly ef- \nfective goal-seeking behavior. The firmness and reliability with which you remain \nin contact with the ground when standing reflects the equilibrium caused by a \npowerful negative feedback loop: as gravity causes you to sink into the earth, the \nelectrons in the atoms of the ground exert greater and greater upward force on \nthe electrons in the atoms of your feet until the force of their mutual electrostatic \nrepulsion just offsets the force of gravity, at which point you come to rest. \n4.3.2 \nRandomness \nMany variables appear to vary randomly. In most situations, randomness is a mea- \nsure of our ignorance, not intrinsic to the system. (Except in quantum mechanics, ","page_start":152,"page_end":152,"token_count":643,"section_type":"other","chapter_number":5,"chapter_title":"Causal Loop Diagrams","chunk_index":188}
{"chunk_id":"501f67d0d8aae91b","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"electrons in the atoms of the ground exert greater and greater upward force on \nthe electrons in the atoms of your feet until the force of their mutual electrostatic \nrepulsion just offsets the force of gravity, at which point you come to rest. \n4.3.2 \nRandomness \nMany variables appear to vary randomly. In most situations, randomness is a mea- \nsure of our ignorance, not intrinsic to the system. (Except in quantum mechanics, \n6The Easter Island data above are drawn primarily from Bahn and Flenley (1992), Kirch (1984), \nand Van Tilburg (1994). These works, along with Kirch (1997) and Steadman (1995), provide a \ngood survey of recent research on the biological and human history of Rapa Nui and other island \necosystems. ","page_start":152,"page_end":152,"token_count":178,"section_type":"other","chapter_number":5,"chapter_title":"Causal Loop Diagrams","chunk_index":189}
{"chunk_id":"03bfafbb2bae6a04","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"128 \nPart I Perspective and Process \nwhere Einstein’s famous lament “God does not play dice with the universe!” \nappears to be wrong. However, the random behavior of elementary particles near \nthe Planck scale has little if any bearing on the dynamics of macroscopic systems \nsuch as a company). When we say there are “random” variations in, say, the de- \nmand for a firm’s product, what we actually mean is that we don’t know the rea- \nsons for these variations. We are revealing the limitations of our understanding, not \ncharacterizing a feature of reality. The demand for a firm’s product may be grow- \ning and may also experience a seasonal cycle. The firm may understand and can \nperhaps even forecast the trend and seasonal cycle with some accuracy. But after \naccounting for these sources of change, people tend to call the residual variation \nrandom as if the customers were somehow rolling dice to decide whether to buy \nthe product. People generally have reasons for behaving as they do, but the man- \nagers of the firm are not aware of either their decision rules or the information they \nuse to make their decisions. The managers’ model of customer behavior is im- \nperfect. If the firm could, through additional modeling and fieldwork, discover \nthose rules and their inputs, they could explain more of the total variation in de- \nmand, and some of what was formerly deemed random would now be resolved \ninto their theory of the system structure. \nAs a practical matter, no one can never know all the local conditions and idio- \nsyncrasies causing a customer to place an order today or wait until tomorrow or \ncause a machine to break down now instead of 3 hours from now. The aggregate \nimpact of the individual deviations from average behavior means systems are \nbathed in a continuous rain of random shocks. Engineers term these random per- \nturbations “noise,” after the distortion heard on telephone lines caused by thermal \nfluctuations of the atoms in the wires. Of course, the rain of random shocks in- \ncludes the occasional downpour, or even flood (for example, note the impact of \nWWII on economic output in the US, Figure 4-3). \nThe rain of random noise falling on our systems does play an important role in \ndynamics, however. By constantly knocking systems away from their current tra- \njectory, noise can excite modes of behavior that otherwise would lie dormant. A \npendulum swinging in the air will tend towards equilibrium as friction dissipates \nits energy; eventually the bob of the pendulum comes to rest, straight down. How- \never, perturb the bob with small, random jolts, and soon it will begin swinging, \nsomewhat irregularly, with a rhythm close to its natural frequency. The structure of \nthe system has the potential to oscillate, but energy from some external source such \nas high-frequency random noise is required to excite its latent dynamics (chapters \n18-20 provide examples). Random noise can also unfreeze systems that are stuck \non local optima, sending them into a new neighborhood where the dynamics are ","page_start":153,"page_end":153,"token_count":654,"section_type":"other","chapter_number":5,"chapter_title":"Causal Loop Diagrams","chunk_index":190}
{"chunk_id":"3158854141148d8d","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"somewhat irregularly, with a rhythm close to its natural frequency. The structure of \nthe system has the potential to oscillate, but energy from some external source such \nas high-frequency random noise is required to excite its latent dynamics (chapters \n18-20 provide examples). Random noise can also unfreeze systems that are stuck \non local optima, sending them into a new neighborhood where the dynamics are \nquite different, and can determine which of many equally attractive paths a system \ntakes, contributing to path dependence (see chapter 10). These disturbances can be \nmodeled as random variations around the average behavior given by the equations \ncapturing the feedback structure of the system. Other times it is more appropriate \nto model the individual elements and actors in the system, in which case nonaver- \nage behavior arises from the heterogeneity of the population of agents. These roles \nfor random perturbations will be explored in later chapters. ","page_start":153,"page_end":153,"token_count":194,"section_type":"other","chapter_number":5,"chapter_title":"Causal Loop Diagrams","chunk_index":191}
{"chunk_id":"b27468e4a4883a2f","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"Chapter 4 Structure and Behavior of Dynamic Systems \n129 \n4.3.3 Chaos \nIn recent years chaos has become a ubiquitous buzz word in the popular press and \nmanagement literature. Books and articles by a host of new age management gu- \nrus warn companies to “manage at the edge of chaos” or be overtaken by more \nnimble competitors. Extravagant claims have been made that chaos is a new and \nradically different science, one which is fundamentally nonlinear and complex, one \nthat can’t be explained without some mysterious new theory. Actually, the term \n“chaos” has a narrow and precise technical meaning in dynamical theory. Unfortu- \nnately, the hunger for the latest fad in the business world, reinforced by marketing \nhype attending the development of chaos and complexity theory, has led to the \nmisappropriation and dilution of the term. To explain chaos I first describe some \nmore common types of oscillations. \nDamped Oscillations: Local Stability \nOne important characteristic of oscillations is damping: if an oscillatory system is \nperturbed once and then left undisturbed, will the fluctuations die out? If so, the cy- \ncle is damped. Many systems are damped oscillators. The classic example is a pen- \ndulum like a child’s swing: Given a single push, the arc traversed by the swing \nsteadily diminishes as friction dissipates its energy, until it eventually comes to \nrest. If you could reduce the frictional energy losses of the pendulum, damping \nwould be weaker and it would take longer and longer for equilibrium to be reestab- \nlished after a shock. In the (unattainable) limit of zero friction, a single shock \nwould cause a perpetual oscillation at a constant amplitude. \nThe equilibrium of the damped pendulum is said to be locally stable: pertur- \nbations will cause the system to oscillate, but it will eventually return to the same \nequilibrium. The qualifier “locally” is important. Real systems are nonlinear, \nmeaning that the feedback loops and parameters governing the dynamics vary de- \npending on the state of the system (where the system is operating in state space- \nthe space created by the state variables of the ~ystem).~ \nLocal stability means the \nperturbations have to be small relative to nonlinearities that might cause other dy- \nnamics to emerge, as when the pendulum is swung so hard it breaks. \nMany real world oscillators are damped, but the oscillations never die away \nbecause the systems are continually bombarded with noise. Many models suggest \nthat the short-term business cycle (Figure 4-7) is a damped, locally stable oscilla- \ntion (chapter 19). The oscillatory structure is a set of negative feedback loops \nthrough which firms adjust production to control their inventories of products and \nraw materials. These loops are oscillatory because of the lags in the adjustment of \nproduction to changes in demand and inventory, particularly delays in hiring and ","page_start":154,"page_end":154,"token_count":643,"section_type":"other","chapter_number":5,"chapter_title":"Causal Loop Diagrams","chunk_index":192}
{"chunk_id":"00fd62339ea13a85","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"that the short-term business cycle (Figure 4-7) is a damped, locally stable oscilla- \ntion (chapter 19). The oscillatory structure is a set of negative feedback loops \nthrough which firms adjust production to control their inventories of products and \nraw materials. These loops are oscillatory because of the lags in the adjustment of \nproduction to changes in demand and inventory, particularly delays in hiring and \n71n a simple pendulum, there are two state variables: the position of the pendulum and its mo- \nmentum. These two states define a two-dimensional space, and the state of the system is defined at \nany time by the point in that space corresponding to the position and momentum of the pendulum. \nAs the pendulum swings through its arc, its trajectory traces out a curve in state space. More com- \nplex systems have high-dimensional state spaces, but the concept of a trajectory in state space re- \nmains the same. ","page_start":154,"page_end":154,"token_count":203,"section_type":"other","chapter_number":5,"chapter_title":"Causal Loop Diagrams","chunk_index":193}
{"chunk_id":"ef69d2ebe45a87af","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"130 \nFIGURE 4-1 5 \nDamped \noscillation in a \nmodel of the Beer \nDistribution Game \nNote the \nnonlinearity: \nbetween weeks \n30 and 45 there \nis a large surplus \nof inventory but \norders are \nconstrained to be \nnonnegative. \nPart I Perspective and Process \nmaterials acquisition (Forrester 1961; Mass 1975). In these models, both the per- \nsistence and irregularity of the business cycle are caused by the excitation of the \neconomy by random shocks, just as the simple pendulum discussed above fluctu- \nates somewhat irregularly when perturbed by noise. \nFigure 4-15 shows an example of damped oscillation in a simple model of a \nfirm based on the Beer Distribution Game (Sterman 1989b, chap. 17). The game \nrepresents the supply chain in a typical manufacturing industry. The supply chain \nhas four sectors: a retailer, wholesaler, distributor, and factory. Each stage is iden- \ntical and managed by a different person. The managers strive to minimize their \ncosts by controlling inventories as they seek to meet incoming demand. The simu- \nlation shows the response of the factory order rate to a one-time change in cus- \ntomer orders. The decision rule used by each agent in the simulation was estimated \nfrom the behavior of actual players. In response to the shock in demand, factory or- \nders exhibit a damped oscillation which returns the system to equilibrium after \nabout 70 weeks. Here the negative loop is the process by which each stage in the \nsupply chain manages its inventory: ordering more when inventories are inade- \nquate and less when they are high. The delays arise from the time required to \nprocess orders and produce and deliver the beer. \nExpanding Oscillations and Limit Cycles \nWhile many oscillatory systems are damped, the equilibria of other systems are \nlocally unstable, meaning that small disturbances tend to move the system farther \naway from the equilibrium point. Imagine a ball balanced on top of a hill. As long \nas the ball is exactly balanced on the hilltop, it remains in equilibrium. But the \nslightest breeze pushes the ball down the hill ever so slightly, leading to a still \ngreater force downhill, in a positive feedback. The equilibrium is unstable. While \nan equilibrium may be locally unstable, any real system must be globally stable. \nGlobal stability means the trajectories of the system do not diverge to infinity: \nthe trajectories are bounded because the positive feedbacks leading to the accel- \nerating flight from the balance point must ultimately be limited by various nega- \ntive loops. The ball cannot accelerate indefinitely, but will come to rest at the \nbottom of the hill. \n","page_start":155,"page_end":155,"token_count":590,"section_type":"other","chapter_number":5,"chapter_title":"Causal Loop Diagrams","chunk_index":194}
{"chunk_id":"6f1b8469e4b94fa3","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"Chapter 4 Structure and Behavior of Dynamic Systems \n131 \nIf an oscillatory system with a locally unstable equilibrium is given a slight \nnudge off its equilibrium point, its swings grow larger and larger until they are con- \nstrained by various nonlinearities. Such oscillations are known as limit cycles, to \ndenote the nonlinear limits restricting their amplitude. In limit cycles, the states of \nthe system remain within certain ranges (they are limited to a certain region of state \nspace). In the steady state, after the effects of any initial perturbations have died \nout, a limit cycle follows a particular orbit (closed curve) in state space. The steady \nstate orbit is known as an attractor, since trajectories near enough to it will move \ntoward it, just as the bob of the damped pendulum is attracted to its stable equilib- \nrium point. \nFigure 4-16 shows an example of a limit cycle from the Beer Distribution \nGame. The situation in the figure is the same as described above for the damped \noscillation except that the parameters of the ordering decision rule are slightly dif- \nferent. As in the case of the damped oscillation, the parameters characterize the be- \nhavior of an actual player. Again, there is a one-time change in customer demand. \nInstead of dying out, the cycle persists indefinitely, even though the environment \nis completely unchanging. The figure shows the cycle both as a time series and as \na so-called phase plot with orders on the vertical axis and inventory on the hori- \nzontal axis, showing the closed orbit perpetually traced by the system. \nOf course, limit cycles are not perpetual motion machines. The energy re- \nquired to maintain the cycle must be provided from a source outside the oscillator. \nLimit cycles are quite common. Your life depends on them-your heartbeat and \nrespiration are limit cycles. The circadian rhythms (daily fluctuations in alertness, \nhormone production, and a host of other physiological parameters) observed in al- \nmost all organisms, from bacteria to people, are limit cycles. Many cycles in the bi- \nological world also appear to be limit cycles, including cycles in predator-prey \npopulations, cycles in the mass fruiting of certain plant species such as Piiion pines \nand some bamboos, and the periodic population explosions of certain insects such \nas the 17-year cicada (see Murray 1993). Many models suggest that very long-term \nFIGURE 4-1 6 \nLe,ft Time series of factory orders. The cycle repeats indefinitely without any external variation. \nRight: The orbit of the system is a closed curve, shown here with factory orders plotted against net \nfactory inventory (inventory less backlog). \nA limit cycle generated in the Beer Distribution Game \n600 \n700 \n800 \n900 \n1000 \nWeeks \n0 \n-30 -20 \n-10 \n0 \n1 0  \n2 0  \nFactory Net Inventory \n","page_start":156,"page_end":156,"token_count":625,"section_type":"other","chapter_number":5,"chapter_title":"Causal Loop Diagrams","chunk_index":195}
{"chunk_id":"2091930d50eb9287","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"132 \nPart I Perspective and Process \nfluctuations in the world economy known as “long waves” are self-perpetuating \nlimit cycles (Sterman 1985; Forrester 1983). Sterman (1989a) reports an experi- \nment in which people managed a simple economic model; the vast majority gener- \nated long waves much like the behavior of the model. Sterman (1989~) shows that \nmany of the decision rules’characterizing the human subjects generate chaos and \nvarious forms of limit cycle. \nChaotic Oscillations \nChaos, like damped fluctuations and limit cycles, is a form of oscillation. How- \never, unlike limit cycles, a chaotic system fluctuates irregularly, never exactly re- \npeating, even though its motion is completely deterministic. The irregularity arises \nendogenously and is not created by external, random shocks. Like a limit cycle, the \npath of a chaotic system is bounded to a certain region of state space. Because \nchaotic systems are bounded, chaos, like limit cycles, can only arise in nonlinear \nsystems. However, unlike linear systems or limit cycles, chaotic dynamics do not \nhave a well-defined period, as does the simple pendulum discussed above. The mo- \ntion of a chaotic system never repeats; instead, the orbits of the system approach \nwhat is known as a strange attractor-a set of closely related but slightly different \norbits rather than a single closed curve. Furthermore, chaotic systems have the \nproperty known as sensitive dependence on initial conditions. Two nearby tra- \njectories, no matter how close, will diverge exponentially until the state of one \nprovides no more information about the state of the other than any randomly cho- \nsen trajectory. Sensitive dependence means that the prediction horizon for chaotic \nsystems-the length of time over which forecasts of future behavior are accurate- \nis likely to be short even if our model of the system structure and parameter esti- \nmates are perfect. Further, the cost of increasing the prediction horizon a fixed \namount by improving our knowledge of the current state of the system increases \nexponentially. \nFigure 4-17 shows chaotic behavior in a simulation of the Beer Distribution \nGame. Only the parameters of the decision rule for orders have been altered; again, \nFIGURE 4-17 Chaos in the Beer Distribution Game \nLeft: Time series showing factory orders. Right: Phase plot showing orders vs. net factory inventory \n(inventory less backlog). \n8 o  t \n8\n6 0  \nE 6 0  \n2 2  \nQ \nh \n2 2  \nLL \nE \n0 \n2. 40 \n0 \n0 \nm \nz% 40 \n+ \n8 c \n- c  \n0 \n2 0  \n2 0  \n0 \n0 \n600 \n7 0 0  \n800 \n900 \n1000 \n-100 \n-50 \n0 \n5 0  \n100 \nFactory Net Inventory \nWeeks \n","page_start":157,"page_end":157,"token_count":629,"section_type":"other","chapter_number":5,"chapter_title":"Causal Loop Diagrams","chunk_index":196}
{"chunk_id":"d31c156e96632dc3","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"Chapter 4 Structure and Behavior of Dynamic Systems \n133 \nthese parameters were estimated from the behavior of an actual player. Like the \nlimit cycle, orders fluctuate indefinitely, in this case with an amplitude ranging \nfrom 0 to about 50 units per week and an average period of about 20 weeks. Un- \nlike the limit cycle, the oscillation does not have a regular amplitude, periodicity, \nor shape, even though the environment is completely constant and the system is \ncompletely free of random shocks. The trajectory of the system in state space fol- \nlows a well-defined path, but one which never closes on itself.8 \nIn all three of these cases, damped oscillation, limit cycle, and chaos, the feed- \nback structure and decision rules are the same. The only differences are in the pa- \nrameters of the ordering rule such as the size of desired inventory and the \naggressiveness with which managers react to the discrepancy between desired and \nactual inventory. \n4.4 SUMMARY \nThe feedback structure of a system generates its behavior. Most dynamics ob- \nserved in the real world are examples of a small set of basic patterns or modes of \nbehavior. Three of these modes are fundamental: exponential growth, goal seeking, \nand oscillation. Each of these modes is generated by a particular underlying feed- \nback structure. Exponential growth is generated by positive feedback processes, \ngoal seeking is generated by negative feedback, and oscillation is generated \nby negative feedback with delays. More complex patterns of behavior such as \nS-shaped growth, growth with overshoot, and overshoot and collapse result from \nthe nonlinear interaction of these basic feedback structures. \nThe principle that the structure of a system generates its behavior leads to a \nuseful heuristic to help modelers discover the feedback loop structure of a system. \nWhenever a particular pattern of behavior is observed, you know which of the \nbasic feedback structures must have been dominant during the period covered by \nthe data. Observing that a variable of interest has been fluctuating, for example, \nimplies the existence of (at least) one negative feedback loop with significant time \ndelays, which helps to guide the search for the particular structures, decision \nprocesses, and time delays that comprise the negative loop. While this heuristic is \nuseful as an aid to the initial conceptualization process, modelers must also take \ncare to search for and include in their models the feedback loops and structures that \nhave not been important in generating the dynamics to date but that may become \nactive as the system evolves. \nsMosekilde (1996) provides an excellent treatment of chaotic and other nonlinear dynamics in \nthe Beer Distribution Game and a wide variety of other physical, technical, and biological systems. \nStrogatz (1994) provides an excellent mathematical introduction to nonlinear dynamics and chaos. \n","page_start":158,"page_end":158,"token_count":594,"section_type":"other","chapter_number":5,"chapter_title":"Causal Loop Diagrams","chunk_index":197}
{"chunk_id":"f031b411af97dccb","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"Causal Loop Diagrams \nWe shape our buildings; thereaffer; our buildings shape us. -Winston Churchill \nFeedback is one of the core concepts of system dynamics. Yet our mental models \noften fail to include the critical feedbacks determining the dynamics of our \nsystems. In system dynamics we use several diagramming tools to capture the \nstructure of systems, including causal loop diagrams and stock and flow maps. \nThis chapter focuses on causal loop diagrams, including guidelines, pitfalls, and \nexamples. \n5.1 \nCAUSAL DIAGRAM NOTATION \nCausal loop diagrams (CLDs) are an important tool for representing the feedback \nstructure of systems. Long used in academic work, and increasingly common in \nbusiness, CLDs are excellent for \nQuickly capturing your hypotheses about the causes of dynamics; \nEliciting and capturing the mental models of individuals or teams; \nCommunicating the important feedbacks you believe are responsible for a \nproblem. \nThe conventions for drawing causal diagrams are simple but should be followed \nfaithfully. Think of causal diagrams as musical scores. Neatness counts, and idio- \nsyncratic symbols and styles make it hard for fellow musicians to read your score. \nAt first, you may find it difficult to construct and interpret these diagrams. With \npractice, however, you will soon be sight-reading. \n137 \n","page_start":162,"page_end":162,"token_count":280,"section_type":"other","chapter_number":5,"chapter_title":"Causal Loop Diagrams","chunk_index":198}
{"chunk_id":"df2bc20d7ba7e5b8","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"138 \nPart I1 Tools for Systems Thinking \nFIGURE 5-1 \nCausal loop \ndiagram notation \nA causal diagram consists of variables connected by arrows denoting the \ncausal influences among the variables. The important feedback loops are also iden- \ntified in the diagram. Figure 5-1 shows an example and key to the notation. \nVariables are related by causal links, shown by arrows. In the example, the \nbirth rate is determined by both the population and the fractional birth rate. Each \ncausal link is assigned a polarity, either positive (+) or negative (-) to indicate \nhow the dependent variable changes when the independent variable changes. The \nimportant loops are highlighted by a loop identifier which shows whether the \nloop is a positive (reinforcing) or negative (balancing) feedback. Note that the loop \nidentifier circulates in the same direction as the loop to which it corresponds. In the \nexample, the positive feedback relating births and population is clockwise and so \nis its loop identifier; the negative death rate loop is counterclockwise along with its \nidentifier. \nTable 5-1 summarizes the definitions of link polarity. \nExample \nn+ \n-\n-\n \nDeath Rate \n(3 \nPopulation \ntil \nBirth Rate \nFractional \nBirth Rate \nAverage \nLifetime \nCausal Link \n-\n+\n \nLink Polarity \nBirth Rate \nVariable \nPopulation \nVariable \nLoop Identifier: Positive (Reinforcing) Loop \n0 \nor +iJ \nLoop Identifier: Negative (Balancing) Loop \n","page_start":163,"page_end":163,"token_count":322,"section_type":"other","chapter_number":5,"chapter_title":"Causal Loop Diagrams","chunk_index":199}
{"chunk_id":"f0f9895ed9711eb5","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"Chapter 5 Causal Loop Diagrams \n139 \nA positive link means that if the cause increases, the effect increases above \nwhat it would otherwise have been, and if the cause decreases, the effect de- \ncreases below what it would otherwise have been. In the example in Figure 5-1 an \nincrease in the fractional birth rate means the birth rate (in people per year) will \nincrease above what it would have been, and a decrease in the fractional birth rate \nmeans the birth rate will fall below what it would have been. That is, if average \nfertility rises, the birth rate, given the population, will rise; if fertility falls, the \nnumber of births will fall. When the cause is a rate of flow that accumulates into a \nstock then it is also true that the cause adds to the stock. In the example, births add \nto the population (see chapter 6 for more on stocks and flows). \nA negative link means that if the cause increases, the effect decreases below \nwhat it would otherwise have been, and if the cause decreases, the effect increases \nabove what it would otherwise have been. In the example, an increase in the aver- \nage lifetime of the population means the death rate (in people per year) will fall \nbelow what it would have been, and a decrease in the average lifetime means the \ndeath rate will rise above what it would have been. That is, if life expectancy \nincreases, the number of deaths will fall; and if life expectancy falls, the death rate \nwill rise. \nLink polarities describe the structure of the system. They do not describe the \nbehavior of the variables. That is, they describe what would happen IF there were \na change. They do not describe what actually happens. The fractional birth rate \nmight increase; it might decrease-the causal diagram doesn’t tell you what will \nhappen. Rather, it tells you what would happen if the variable were to change. \nNote the phrase above (or below) what it otherwise would have been in the \ndefinition of link polarity. An increase in a cause variable does not necessarily \nmean the effect will actually increase. There are two reasons. First, a variable of- \nten has more than one input. To determine what actually happens you need to know \nhow all the inputs are changing. In the population example, the birth rate depends \nTABLE 5-1 \nLink polarity: definitions and examples \nSymbol \nInterpretation \nMathematics \nExamples \n+ \nProduct - \nQuality \nEffort -Results \nSales \ndY/dX > 0 \n+ \n(decreases) above (below) \nIn the case of \naccumulations, \nAll else equal, if X increases \n(decreases), then Y increases \nwhat it would have been. \n+ \nx - 2 - y  \nIn the case of accumulations, \ny = \n+ . . .)ds + ytO \nX adds to Y. \nBirths \n+ \nt \nPopulation \nSales \nProduct- ","page_start":164,"page_end":164,"token_count":633,"section_type":"other","chapter_number":5,"chapter_title":"Causal Loop Diagrams","chunk_index":200}
{"chunk_id":"762b6c9b4583fae5","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"+ \n(decreases) above (below) \nIn the case of \naccumulations, \nAll else equal, if X increases \n(decreases), then Y increases \nwhat it would have been. \n+ \nx - 2 - y  \nIn the case of accumulations, \ny = \n+ . . .)ds + ytO \nX adds to Y. \nBirths \n+ \nt \nPopulation \nSales \nProduct- \ndY/dX < 0 \nIn the case of \naccumulations, \nAll else equal, if X increases \n(increases) below (above) \nwhat it would have been. \nX subtracts from Y. \n(decreases), then Y decreases \nPrice - \nFrustration \nResults - \nx -y \nIn the case of accumulations, \nY = (-x + . . .)ds + Yt0 \nDeaths \nPopulation ","page_start":164,"page_end":164,"token_count":190,"section_type":"other","chapter_number":5,"chapter_title":"Causal Loop Diagrams","chunk_index":201}
{"chunk_id":"a618fb8d7918face","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"140 \nPart I1 Tools for Systems Thinking \non both the fractional birth rate and the size of the population (that is, Birth Rate = \nFractional Birth Rate * Population). You cannot say whether an increase in the \nfractional birth rate will actually cause the birth rate to rise; you also need to know \nwhether the population is rising or falling. A large enough drop in the population \nmay cause the birth rate to fall even if the fractional birth rate rises. When assess- \ning the polarity of individual links, assume all other variables are constant (the fa- \nmous assumption of ceteris pavibus). When assessing the actual behavior of a \nsystem, all variables interact simultaneously (all else is not equal) and computer \nsimulation is usually needed to trace out the behavior of the system and determine \nwhich loops are dominant. \nSecond, and more importantly, causal loop diagrams do not distinguish be- \ntween stocks and flows-the accumulations of resources in a system and the rates \nof change that alter those resources (see chapter 6). In the population example, the \npopulation is a stock-it accumulates the birth rate less the death rate. An increase \nin the birth rate will increase the population, but a decrease in the birth rate does \nnot decrease the population. Births can only increase the population, they can \nnever reduce it. The positive link between births and population means that the \nbirth rate adds to the population. Thus an increase in the birth rate increases the \npopulation above what it otherwise would have been and a decrease in the birth \nrate decreases population below what it otherwise would have been. \nSimilarly, the negative polarity of the link from the death rate to population in- \ndicates that the death rate subtracts from the population. A drop in the death rate \ndoes not add to the population. A drop in deaths means fewer people die and more \nremain alive: the population is higher than it would otherwise have been. Note that \nyou cannot tell whether the population will actually be increasing or decreasing: \nPopulation will be falling even if the birth rate is rising if the death rate exceeds \nbirths. To know whether a stock is increasing or decreasing you must know its net \nrate of change (in this case, births less deaths). It is always true, however, that if the \nbirth rate rises, population will rise above what it would have been in the absence \nof the change in births, even if the population continues to fall. Population will be \nfalling at a slower rate than it otherwise would. Chapters 6 and 7 discuss the struc- \nture and behavior of stocks and flows. \nProcess Point: A Note on Notation \nIn some of the system dynamics literature, especially the systems thinking tradition \n(see, e.g., Senge et al. 1994 and Kim 1992), an alternate convention for causal dia- \ngrams has developed. Instead of + or - the polarity of a causal link is denoted \nby s or 0, respectively (denoting the same or opposite relationship between inde- \npendent and dependent variables): \nX\nA\nY\n \nX\nA\nY\n \ninsteadof X d\nY\n \ninsteadof X \nY \n","page_start":165,"page_end":165,"token_count":666,"section_type":"other","chapter_number":5,"chapter_title":"Causal Loop Diagrams","chunk_index":202}
{"chunk_id":"c6f68b4bee3a2b13","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"Chapter 5 \nCausal Loop Diagrams \n141 \nThe link denoted with an s is read as “X and Y move in the same direction” \nwhile the link denoted with an o is read as “X and Y move in the opposite direc- \ntion.” Thus Product Quality and Sales tend to move in the same direction while \nProduct Price and Sales tend to move in the opposite direction. \nThe s and o notation was motivated by a desire to make causal diagrams even \neasier to understand for people with little mathematical background. Which nota- \ntion is better is hotly debated. Richardson (1997) provides strong arguments \nagainst the use of s and 0. He notes that the statement “X and Y move in the same \ndirection” is not in general correct, for the reasons stated above. The correct state- \nment is, “If X increases, Y increases above what it would have been.” That is, a \ncausal link is a contingent statement of the individual effect of a hypothesized \nchange. The variables X and Y may be positively linked and yet Y may fall even as \nX increases, as other variables also affect Y. The s and o definitions also don’t \nwork for stock and flow relationships. Births and population do not move in the \nsame direction: a decrease in births does not cause population to decrease because \nthe birth rate is an inflow to the stock of population. The correct definition is given \nin Table 5-1: for positive link polarity, if X increases, Y will always be higher than \nit would have been; for negative polarity, if X increases, Y will always be lower \nthan it would have been. In this book I will use the + and - signs to denote link \npolarity. As a modeler you should know how to interpret the s and o notation when \nyou see it, but you should use the + and - notation to denote link polarity. \n5.2 \nGUIDELINES FOR CAUSAL LOOP DIAGRAMS \n5.2.1 \nCausation versus Correlation \nEvery link in your diagram must represent (what you believe to be) causal rela- \ntionships between the variables. You must not include correlations between vari- \nables. The Latin root of the word simulate, sirnulare, means “to imitate.” A system \ndynamics model must mimic the structure of the real system well enough that the \nmodel behaves the same way the real system would. Behavior includes not only \nreplicating historical experience but also responding to circumstances and policies \nthat are entirely novel. Correlations among variables reflect the past behavior of a \nsystem. Correlations do not represent the structure of the system. If circumstances \nchange, if previously dormant feedback loops become dominant, if new policies \nare tried, previously reliable correlations among variables may break down. Your \nmodels and causal diagrams must include only those relationships you believe cap- \nture the underlying causal structure of the system. Correlations among variables \nwill emerge from the behavior of the model when you simulate it. \nThough sales of ice cream are positively correlated with the murder rate, you ","page_start":166,"page_end":166,"token_count":653,"section_type":"other","chapter_number":5,"chapter_title":"Causal Loop Diagrams","chunk_index":203}
{"chunk_id":"8f56a1dbc1ba6de1","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"change, if previously dormant feedback loops become dominant, if new policies \nare tried, previously reliable correlations among variables may break down. Your \nmodels and causal diagrams must include only those relationships you believe cap- \nture the underlying causal structure of the system. Correlations among variables \nwill emerge from the behavior of the model when you simulate it. \nThough sales of ice cream are positively correlated with the murder rate, you \nmay not include a link from ice cream sales to murder in your models. Instead, as \nshown in Figure 5-2, both ice cream sales and murder rise in summer and fall in \nwinter as the average temperature fluctuates. Confusing correlation with causality \ncan lead to terrible misjudgments and policy errors. The model on the left side of \nFigure 5-2 suggests that cutting ice cream consumption would slash the murder \nrate, save lives, and allow society to cut the budget for police and prisons. ","page_start":166,"page_end":166,"token_count":193,"section_type":"other","chapter_number":5,"chapter_title":"Causal Loop Diagrams","chunk_index":204}
{"chunk_id":"a5ef14873a58bd20","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"142 \nPart I1 Tools for Systems Thinking \nFIGURE 5-2 \nCausal diagrams \nmust include \nonly (what you \nbelieve to be) \ngenuine causal \nrelationships. \nIncorrect - \nIce Cream \nMurder \nSales \nRate \nCorrect \nIce Cream \nSales \nMurder \nRate \n/c’ \nAverage / \nTemperature \nWhile few people are likely to attribute murders to the occasional double-dip \ncone, many correlations are more subtle, and it is often difficult to determine the \nunderlying causal structure. A great deal of scientific research seeks the genuine \ncausal needles in a huge haystack of correlations: Does vitamin C cure the com- \nmon cold? Can eating oat bran reduce cholesterol, and if it does, will your risk of \na heart attack drop? Does economic growth lead to lower birth rates, or is the lower \nrate attributable to literacy, education for women, and increasing costs of child \nrearing? Do companies with serious quality improvement programs earn superior \nreturns for stockholders? Scientists have learned from bitter experience that reli- \nable answers to such questions are hard to come by and require dedication to the \nscientific method-controlled experiments, randomized, double-blind trials, large \nsamples, long-term follow-up studies, replication, statistical inference, and so on. \nIn the social and human systems we often model, such experiments are difficult, \nrare, and often impossible. Modelers must take extra care to consider whether the \nrelationships in their models are causal, no matter how strong the correlation, how \nhigh the R2, or how great the statistical significance of the coefficients in a re- \ngression may be. As the English economist Phelps-Brown (1972, p. 6) noted, \n“Where, as so often, the fluctuations of different series respond in common to the \npulse of the economy, it is fatally easy to get a good fit, and get it for quite a num- \nber of different equations . . . Running regressions between time series is only \nlikely to deceive.” \n5.2.2 \nLabeling Link Polarity \nBe sure to label the polarity of every link in your diagrams. Label the polarity of \nthe important feedback loops in your diagrams, using the definitions in Table 5-1 \nto help you determine whether the links are positive or negative. Positive feed- \nback loops are also called reinforcing loops and are denoted by a + or R, while \nnegative loops are sometimes called balancing loops and are denoted by a - or B \n(Figure 5-3). \n","page_start":167,"page_end":167,"token_count":532,"section_type":"other","chapter_number":5,"chapter_title":"Causal Loop Diagrams","chunk_index":205}
{"chunk_id":"d5d56a1f3f74c284","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"Chapter 5 Causal Loop Diagrams \n143 \nFIGURE 5-3 \nLabel link and loop \npolarities. \nNote that all linlks \nare labeled and \nloop polarity \nidentifiers show \nwhich loops are \npositive and which \nare negative. \nLoop identifiers \nare clockwise \nfor the clockwise \nloops (and vice \nversa). \nIncorrect \nnn \nCustomer \nCustomer \nSales from \nWord of \nBase \nLoss Rate \nMou\nu \nCorrect \nCustomer \nLoss Rate \nAssigning Link Polarities \nConsider the attractiveness of a product to customers as it depends on various at- \ntributes of the product (Figure 5-4). Assign link polarities. What feedback loops \nmight be created as product attractiveness changes the demand for the firm’s prod- \nuct? Add these to the diagram, labeling the link and loop polarities. \nQuality \nPrice \nProduct \nAttractiveness \nDelay \nDelivery ’/ \nFunctionality \n5.2.3 \nDetermining Loop Polarity \nThere are two methods for determining whether a loop is positive or negative: the \nfast way and the right way. \n","page_start":168,"page_end":168,"token_count":238,"section_type":"other","chapter_number":5,"chapter_title":"Causal Loop Diagrams","chunk_index":206}
{"chunk_id":"dff91220e0b58eb1","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"144 \nPart I1 Tools for Systems Thinking \nThe Fast Way: Count the Number of Negative Links \nThe fast way to tell if a loop is positive or negative is to count the number of \nnegative links in the loop. If the number of negative links is even, the loop is posi- \ntive; if the number is odd, the loop is negative. The rule works because positive \nloops reinforce change while negative loops are self-correcting; they oppose dis- \nturbances. Imagine a small disturbance in one of the variables. If the disturbance \npropagates around the loop to reinforce the original change, then the loop is posi- \ntive. If the disturbance propagates around the loop to oppose the original change, \nthen the loop is negative. To oppose the disturbance, the signal must experience a \nnet sign reversal as it travels around the loop. Net reversal can only occur if the \nnumber of negative links is odd. A single negative link causes the signal to reverse: \nan increase becomes a decrease. But another negative link reverses the signal \nagain, so the decrease becomes an increase, reinforcing the original disturbance. \nSee “Mathematics of Loop Polarity” below for a formal derivation of this rule. \nThe fast method always works . . . except when it doesn’t. Why might it fail? \nIn a complex diagram it is all too easy to miscount the number of negative links in \na loop. And it is easy to mislabel the polarity of links when you first draw the dia- \ngram. Counting the number of negative signs is unlikely to reveal these errors. The \nright method, carefully tracing the effect of a disturbance around the loop, will of- \nten reveal a wrongly labeled polarity and will help you and your audience to grasp \nthe meaning and mechanism of the loop. Assigning loop polarity the right way \nrather than the fast way saves time in the long run. \nThe Right Way: Trace the Effect of a Change around the Loop \nThe right way to determine the polarity of a loop is to trace the effect of a small \nchange in one of the variables as it propagates around the loop. If the feedback ef- \nfect reinforces the original change, it is a positive loop; if it opposes the original \nchange, it is a negative loop. You can start with any variable in the loop; the result \nmust be the same. In the market loops shown in Figure 5-3, assume sales from \nword of mouth increase. Because the link from sales from word of mouth to the \ncustomer base is positive, the customer base increases. Because the link from the \ncustomer base back to sales from word of mouth is positive, the signal propagates \naround the loop to increase sales from word of mouth still further. The feedback ef- \nfect reinforces the original change, so the loop is positive. Turning to the other \nloop, assume a small increase in the customer loss rate. If customer losses increase, \nthe customer base falls. With a lower customer base, there are fewer customers \nwho can drop out. The feedback effect opposes the original change, so the loop is \nnegative. ","page_start":169,"page_end":169,"token_count":650,"section_type":"other","chapter_number":5,"chapter_title":"Causal Loop Diagrams","chunk_index":207}
{"chunk_id":"54fe7d7e6ad32bc2","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"around the loop to increase sales from word of mouth still further. The feedback ef- \nfect reinforces the original change, so the loop is positive. Turning to the other \nloop, assume a small increase in the customer loss rate. If customer losses increase, \nthe customer base falls. With a lower customer base, there are fewer customers \nwho can drop out. The feedback effect opposes the original change, so the loop is \nnegative. \nThis method works no matter how many variables are in a loop and no matter \nwhich variable you start with. (Identify the loop polarities for the example starting \nwith customer base instead of sales from word of mouth: you should get the same \nresult). You may also assume an initial decrease in a variable rather than an initial \nincrease. ","page_start":169,"page_end":169,"token_count":161,"section_type":"other","chapter_number":5,"chapter_title":"Causal Loop Diagrams","chunk_index":208}
{"chunk_id":"03b94ad903eb46ab","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"Chapter 5 Causal Loop Diagrams \n145 \nIdentifying Link and Loop Polarity \nIdentify and label the polarity of the links and loops in the examples shown in \nFigure 5-5. \nAttractiveness \nf Of Market \nProfits \n4 \nNumber of \nCompetitors \n1 \nP r i c e d  \n?Pressure to Clean \nUp Environment \nEnvironmental \nCleanuD \nCumulative \nr \nProduction A \nP r i c e J  \nMarket \nUnit \nShare \ncosts \nI \nPerceived \nSolvency of \nNet \nQuality \nWithdrawals L \nBank \nMathematics of Loop Polarity \nWhen you determine loop polarity, you are calculating what is known in control \ntheory as the sign of the open loop gain of the loop. The term “gain” refers to the \nstrength of the signal returned by the loop: a gain of two means a change in a vari- \nable is doubled each cycle around the loop; a gain of negative 0.5 means the dis- \nturbance propagates around the loop to oppose itself with a strength half as large. \nThe term “open loop” means the gain is calculated for just one feedback cycle by \nbreaking-opening-the loop at some point. Consider an arbitrary feedback loop \nconsisting of n variables, xl, . . . , x,. You can calculate the open loop gain at any \npoint; let x1 denote the variable you choose. When you break the loop, x1 splits into \nan input, xll, and output, xl0 (Figure 5-6). The open loop gain is defined as the \n(partial) derivative of xl0 with respect to xll, that is, the feedback effect of a small \nchange in the variable as it returns to itself. The polarity of the loop is the sign of \nthe open loop gain: \nPolarity of loop = SGN(dx,O/dxll) \n(5- 1) \nwhere SGN() is the signum or sign function, returning + 1 if its argument is posi- \ntive and -1 if the argument is negative (if the open loop gain is zero, the SGN \nfunction = 0: there is no loop). The open loop gain is calculated by the chain rule \nfrom the gains of the individual links, dxi/dxi-,: \n","page_start":170,"page_end":170,"token_count":490,"section_type":"other","chapter_number":5,"chapter_title":"Causal Loop Diagrams","chunk_index":209}
{"chunk_id":"6d04a235419e5efd","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"146 \nFIGURE 5-6 \nCalculating the \nopen-loop gain \nof a loop \nPart I1 Tools for Systems Thinking \n'1 \\ \nBreak \natany \nthe \npoint \nloop /*I \n'1' 1 \nx2 \nand trace the effect \nof a change around \nthe loop. \nPolarity = SGN(~X~O/~X,I) \nSince the sign of a product is the product of the signs, loop polarity is also \ngiven by: \nSGN(dx1O/dx,') = SGN(dx,'/dx,) * SGN(dxn/dx,_1) * SGN(~X,-,/~X,_~) \n* . . - * SGN(dx2/dxI1) \n(5-3) \nUsing the right method to determine loop polarity by tracing the effect of a \nsmall change around a loop is equivalent to calculating equation (5-3). Equation \n(5-3) also explains why the fast method works: Since the product of two negative \nsigns is a positive sign, negative open loop polarity requires an odd number of neg- \native links in the loop. \nAll Links Should Have Unambiguous Polarities \nSometimes people say a link can be either positive or negative, depending on other \nparameters or on where the system is operating. For example, people often draw \nthe diagram on the left side of Figure 5-7 relating a firm's revenue to the price of \nits product and then argue that the link between price and company revenue can be \neither positive or negative, depending on the elasticity of demand. If demand is \nhighly elastic, a higher price means less revenue because a 1% increase in price \ncauses demand to fall more than 1 %. The link would have negative polarity. If de- \nmand is inelastic, then a l % increase in price causes demand to drop less than l %, \nso revenues rise. The link would be positive. It appears no single polarity can be \nassigned. \nWhen you have trouble assigning a clear and unambiguous polarity to a link it \nusually means there is more than one causal pathway connecting the two variables. \nYou should make these different pathways explicit in your diagram. In the exam- \nple, price has at least two effects on revenue: (1) it determines how much revenue \nis generated per unit sold and (2) it affects the number of units sold. That is, Reve- \nnue = Price * Sales, and (Unit) Sales depend on Price (presumably the demand \ncurve is downward sloping: Higher prices reduce sales). The proper diagram is \n","page_start":171,"page_end":171,"token_count":549,"section_type":"other","chapter_number":5,"chapter_title":"Causal Loop Diagrams","chunk_index":210}
{"chunk_id":"55d911f6b5e4b11c","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"Chapter 5 Causal Loop Diagrams \n147 \nFIGURE 5-7 \nCausal links \nmust have \nunambiguous \npolarity. \nApparently \nambiguous \npolarities usually \nindicate the \npresence of \nmultiple causal \npathways that \nshould be \nrepresented \nseparately. \nIncorrect \nCorrect \nPrice \nRevenue \nPrice \nRevenue \nSales 2 \n+ \nshown on the right side of Figure 5-7. There is now no ambiguity about the polar- \nity of any of the links. \nThe price elasticity of demand determines which causal pathway dominates. If \ndemand is quite insensitive to price (the elasticity of demand is less than one), then \nthe lower path in Figure 5-7 is weak, price raises unit revenue more than it de- \ncreases sales, and the net effect of an increase in price is an increase in revenue. \nConversely, if customers are quite price sensitive (the elasticity of demand is \ngreater than one), the lower path dominates. The increase in revenue per unit is \nmore than offset by the decline in the number of units sold, so the net effect of a \nprice rise is a drop in revenue. Separating the pathways also allows you to specify \ndifferent delays, if any, in each. In the example above, there is likely to be a long \ndelay between a change in price and a change in sales, while there is little or no de- \nlay in the effect of price on revenue. \nSeparating links with apparently ambiguous polarity into the underlying mul- \ntiple pathways is a fruitful method to deepen your understanding of the causal \nstructure, delays, and behavior of the system. \nEmployee Motivation \nYour client team is worried about employee motivation and is debating the best \nways to generate maximum effort from their people. They have drawn a diagram \n(Figure 5-8) and are arguing about the polarity of the links. One group argues that \nthe greater the performance shortfall (the greater the gap between Required Per- \nformance and Actual Performance), the greater the motivation of employees will \nbe. They argue that the secret of motivation is to set aggressive, even impossible \ngoals (so-called stretch objectives) to elicit maximum motivation and effort. The \nother group argues that too big a performance shortfall simply causes frustration as \npeople conclude there is no chance to accomplish the goal, so the link to employee \nmotivation should be negative. Expand the diagram to resolve the apparent conflict \nby incorporating both theories. Discuss which links dominate under different cir- \ncumstances. Can you give some examples from your own experience where these \ndifferent pathways were dominant? How can a manager tell which pathway is \nlikely to dominate in any situation? What are the implications for goal setting in or- \nganizations? Actual and required performance are not exogenous but part of the \nfeedback structure. How does motivation feed back to performance, and how \nmight actual performance affect the goal? Indicate these loops in your diagram and \nexplain their importance. \n","page_start":172,"page_end":172,"token_count":625,"section_type":"other","chapter_number":5,"chapter_title":"Causal Loop Diagrams","chunk_index":211}
{"chunk_id":"59c26d13eeb9244b","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"148 \nPart I1 Tools for Systems Thinking \nActual \nRequired \nPerformance \n+/ \nPerformance \nPerformance \nShortfall \nEm p I oyee \nMotivation \n5.2.4 Name Your Loops \nWhether you use causal diagrams to elicit the mental models of a client group or to \ncommunicate the feedback structure of a model, you will often find yourself trying \nto keep track of more loops than you can handle. Your diagrams can easily over- \nwhelm the people you are trying to reach. To help your audience navigate the net- \nwork of loops, it’s helpful to give each important feedback a number and a name. \nNumbering the loops R1, R2, B1, B2, and so on helps your audience find each loop \nas you discuss it. Naming the loops helps your audience understand the function of \neach loop and provides useful shorthand for discussion. The labels then stand in for \na complex set of causal links. When working with a client group, it’s often possi- \nble to get them to name the loop. Many times, they will suggest a whimsical phrase \nor some organization-specific jargon for each loop. \nFigure 5-9 shows a causal diagram developed by engineers and managers in a \nworkshop designed to explore the causes of late delivery for their organization’s \ndesign work. The diagram represents the behavior of the engineers trying to \ncomplete a project against a deadline. The engineers compare the work remaining \nto be done against the time remaining before the deadline. The larger the gap, the \nmore Schedule Pressure they feel. When schedule pressure builds up, engineers \nhave several choices. First, they can work overtime. Instead of the normal 50 hours \nper week, they can come to work early, skip lunch, stay late, and work through the \nweekend. By burning the Midnight Oil, they increase the rate at which they com- \nplete their tasks, cut the backlog of work, and relieve the schedule pressure (bal- \nancing loop B l). However, if the workweek stays too high too long, fatigue sets in \nand productivity suffers. As productivity falls, the task completion rate drops, \nwhich increases schedule pressure and leads to still longer hours: the reinforcing \nBurnout loop R1 limits the effectiveness of overtime. Another way to complete the \nwork faster is to reduce the time spent on each task. Spending less time on each \ntask boosts the number of tasks done per hour (productivity) and relieves schedule \npressure, thus closing the balancing loop B2. Discussion of the name for this loop \nwas heated. The managers claimed the engineers always gold-plated their work; \nthey felt schedule pressure was needed to squeeze out waste and get the engineers \nto focus on the job. The engineers argued that schedule pressure often rose so high \nthat they had no choice but to cut back quality assurance and skip documentation \n","page_start":173,"page_end":173,"token_count":598,"section_type":"other","chapter_number":5,"chapter_title":"Causal Loop Diagrams","chunk_index":212}
{"chunk_id":"1bd03c19e75570e3","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"Chapter 5 Causal Loop Diagrams \n149 \nFIGURE 5-9 \nName and number \nyour loops to \nincrease diagraim \nclarity and provide \nmemorable lablels \nfor important \nfeedbacks. \nTime \nRemaining \n/ \nWork \nError Rate \nof their work. They called it the Corner Cutting loop (B2). The engineers then ar- \ngued that corner cutting is self-defeating because it increases the error rate, which \nleads to rework and lower productivity in the long run: “Haste makes waste,” they \nsaid, and schedule pressure rises further, leading to still more pressure to cut cor- \nners (loop R2). \nThe full model included many more loops (section 5.1 provides a closely re- \nlated example; see also section 2.3). The names given to the loops by one group \n(engineers) communicated their attitudes and the rationale for their behavior to the \nmanagers in a clear and compelling way. The conversation did not degenerate into \nad hominem arguments between managers shouting that engineers just need to \nhave their butts kicked and engineers griping that getting promoted to management \nturns your brain to [fertilizer]-the mode of discourse most common in the orga- \nnization prior to the intervention. Participants soon began to talk about the Burnout \nLoop kicking in and the nonlinear relationships between schedule pressure, over- \ntime, fatigue, and errors. The names for the loops made it easy to refer to complex \nchunks of feedback structure. The concepts captured by the names gradually began \nto enter the mental models and decision making of the managers and engineers in \nthe organization and led to change in deeply ingrained behaviors. \n","page_start":174,"page_end":174,"token_count":359,"section_type":"other","chapter_number":5,"chapter_title":"Causal Loop Diagrams","chunk_index":213}
{"chunk_id":"c28beef2708158b9","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"150 \nPart I1 Tools for Systems Thinking \nFIGURE 5-10 \nRepresenting \ndelays in causal \ndiagrams \n5.2.5 \nIndicate Important Delays in Causal Links \nDelays are critical in creating dynamics. Delays give systems inertia, can create os- \ncillations, and are often responsible for trade-offs between the short- and long-run \neffects of policies. Your causal diagrams should include delays that are important \nto the dynamic hypothesis or significant relative to your time horizon. As shown in \nchapter 11, delays always involve stock and flow structures. Sometimes it is im- \nportant to show these structures explicitly in your diagrams. Often, however, it is \nsufficient to indicate the presence of a time delay in a causal link without explic- \nitly showing the stock and flow structure. Figure 5-10 shows how time delays are \nrepresented in causal diagrams. \nWhen the price of a good rises, supply will tend to increase, but often only af- \nter significant delays while new capacity is ordered and built and while new firms \nenter the market. See also the time delays in the Burnout and Haste Makes Waste \nloops in Figure 5-9. \nExample: Energy Demand \nThe response of gasoline sales to price involves long delays. In the short run, gaso- \nline demand is quite inelastic: if prices rise, people can cut down on discretionary \ntrips somewhat, but most people still have to drive to work, school, and the super- \nmarket. As people realize that prices are likely to stay high they may organize car- \npools or switch to public transportation, if it is already available. Over time high \nprices induce other responses. First, consumers (and the auto companies) wait to \nsee if gas prices are going to stay high enough and long enough to justify buying \nor designing more efficient cars (a perceptual and decision-making delay of per- \nhaps a year or more). Once people have decided that the price won’t drop back \ndown any time soon, the auto companies must then design and build more efficient \ncars (a delay of several years). Even after more efficient cars become available, the \nvast majority of cars on the road will be inefficient, older models which are only \nreplaced as they wear out and are discarded, a delay of about 10 years. If prices \nstay high, eventually the density of settlement patterns will increase as people \nabandon the suburbs and move closer to their jobs. Altogether, the total delay in the \nlink between price and demand for gasoline is significantly more than a decade. As \nthe stock of cars on the road is gradually replaced with more efficient cars, and as \n(perhaps) new mass transit routes are designed and built, the demand for gasoline \nwould fall substantially-long-run demand is quite elastic. Figure 5-1 1 makes \nthese different pathways for the adjustment of gasoline demand explicit. \nExplicitly portraying the many delays between a change in price and the \nresulting change in demand makes it easier to see the worse-before-better behavior \nof expenditures on gasoline caused by a price increase. The bottom of Figure \n5-1 1 shows the response of gasoline demand and expenditures to a hypothetical \n","page_start":175,"page_end":175,"token_count":676,"section_type":"other","chapter_number":5,"chapter_title":"Causal Loop Diagrams","chunk_index":214}
{"chunk_id":"67ffb6a07c0b7e6e","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"Chapter 5 Causal Loop Diagrams \n151 \nunanticipated step increase in the price of gasoline. In the short run gasoline \ndemand is rather inflexible, so the first response to an increase in the price of gas \nis an increase in gasoline expenditures. As the high price persists, efficiency \nFIGURE 5-11 \nTop: The short run response to higher prices is weak, while the long run response is substantial as the \nstock of cars is gradually replaced with more efficient models, and as lifestyles change. \nBottom: Resporise to a hypothetical permanent unanticipated increase in gasoline price. Consumption \nslowly declines 'due to the long delays in adjusting the efficiency of automobiles and in changing \nsettlement patterns and mass transit routes. Expenditures therefore immediately rise and only later fall \nbelow the initial level: a worse-before-better trade-off for consumers. Of course, as demand falls, there \nwould be downvvard pressure on price, possibly lowering expenditures still more, but also discouraging \nfurther efficiency improvements. The feedback to price is deliberately ignored in the diagram. \nDifferent time delays in the response of gasoline demand and expenditures to price \nGasoline \nExpenditures \nPrice \nDiscretionary \nTrips \nDemand for \nShort-Term \nPrice \n-\n>\nI\n€\n€\n-\n \n+ \nper Year \nGasoline \nUse of Existing \n+ \nMass Transit \nDensity of \nSettlement Patterns, \n+ \nDevelopment of New \nMass Transit Routes \n+ \nPrice \n+ \\4 Efficiency \nEfficiency of \nCars on Road \nof Carson 2_1 Delay \nMarket \nGasoline Price \nL \nTime \n","page_start":176,"page_end":176,"token_count":343,"section_type":"other","chapter_number":5,"chapter_title":"Causal Loop Diagrams","chunk_index":215}
{"chunk_id":"fcd0691fc5284ce9","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"152 \nFIGURE 5-1 2 \nVariable names \nshould be nouns \nor noun phrases. \nFIGURE 5-1 3 \nVariable names \nshould have a \nclear sense of \ndirection. \nPart I1 Tools for Systems Thinking \nimprovements gradually cut consumption of gasoline per vehicle mile, and even- \ntually, settlement patterns and mass transit availability will adjust to reduce the \nnumber of vehicle miles driven per year. In the long run, demand adjustments more \nthan offset the price increase and expenditures fall. From the point of view of the \nconsumer, this is a worse-before-better situation. The time delays and the trade-off \nthey create help explain why it has proven so difficult, in the United States at least, \nto increase gasoline taxes. Although the long-run benefits outweigh the short-run \ncosts, even in net present value terms, they only begin to accrue after many years. \nGovernment officials focused on the next reelection campaign judge the short-run \ncosts to be politically unacceptable. In turn, they make this judgment because the \npublic is unwilling to sacrifice a little today for larger benefits tomorrow. \n5.2.6 \nVariable Names \nVariable Names Should Be Nouns or Noun Phrases \nThe variable names in causal diagrams and models should be nouns or noun \nphrases. The actions (verbs) are captured by the causal links connecting the vari- \nables. A causal diagram captures the structure of the system, not its behavior-not \nwhat has actually happened but what would happen if other variables changed in \nvarious ways. Figure 5- 12 shows examples of good and bad practice. \nThe correct diagram states: If costs rise, then price rises (above what it would \nhave been), but if costs fall, then price will fall (below what it would have been). \nAdding the verb “rises” to the diagram presumes costs will only rise, biasing the \ndiscussion towards one pattern of behavior (inflation). It is confusing to talk of a \ndecrease in costs rising or a fall in price increases-are prices rising, rising at a \nfalling rate, or falling? \nVariable Names Must Have a Clear Sense of Direction \nChoose names for which the meaning of an increase or decrease is clear, variables \nthat can be larger or smaller. Without a clear sense of direction for the variables \nyou will not be able to assign meaningful link polarities. \nOn the left side of Figure 5-13 neither variable has a clear direction: If feed- \nback from the boss increases, does that mean you get more comments? Are these \nIncorrect \nn+ \nCosts Rise \nPrice Rises \nIncorrect \nCorrect \nn+\ncosts \nPrice \nCorrect \n-+ \nn+\nMorale \nMental \nPraise from \nAttitude \nthe Boss \nFeedback \nfrom the \nBoss \n","page_start":177,"page_end":177,"token_count":595,"section_type":"other","chapter_number":5,"chapter_title":"Causal Loop Diagrams","chunk_index":216}
{"chunk_id":"94e4dbb7bd8b7791","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"Chapter 5 Causal Loop Diagrams \n153 \nFIGURE 5-1 4 \nChoose variables \nwhose normal \nsense of direction \nis positive. \nIncorrect \ncosts \nLosses \nCorrect \ncosts \nProfit \nm- \nHappiness \nn+ \nCriticism \nUnhappiness \nCriticism \ncomments from the boss good or bad? And what does it mean for mental attitude \nto increase? The meaning of the right side is clear: More praise from the boss \nboosts morale; less praise erodes it (though you should probably not let your self- \nesteem depend so much on your boss’ opinion). \nChoose Variables Whose Normal Sense of Direction Is Positive \nVariable names should be chosen so their normal sense of direction is positive. \nAvoid the use of variable names containing prefixes indicating negation (non, un, \netc.; Figure 5-14). \nStandard accounting practice is Profit = Revenue - Costs, so the better vari- \nable name is Profit, which falls when costs rise and rises when costs fall. Likewise, \ncriticism may make you unhappy, but it is confusing to speak of rising un- \nhappiness; a better choice is the positive happiness, which may fall when you are \ncriticized and rise when criticism drops. Though there are occasional excep- \ntions, decreasing noncompliance with this principle will diminish your audience’s \nincomprehension. \n5.2.7 \nTips for Causal Loop Diagram Layout \nTo maximize the clarity and impact of your causal diagrams, you should follow \nsome basic principles of graphic design. \n1. Use curved lines for information feedbacks. Curved lines help the reader \nvisualize the feedback loops. \n2. Make important loops follow circular or oval paths. \n3. Organize your diagrams to minimize crossed lines. \n4. Don’t put circles, hexagons, or other symbols around the variables in causal \ndiagrams. Symbols without meaning are “chart junk” and serve only to \nclutter and distract. An exception: You will often need to make the stock \nand flow structure of a system explicit in your diagrams. In these cases the \nrectangles and valves around the variables tell the reader which are stocks \nand which are flows-they convey important information (see chapter 6). \n5. Iterate. Since you often won’t know what all the variables and loops will be \nwhen you start, you will have to redraw your diagrams, often many times, \nto find the best layout. \n","page_start":178,"page_end":178,"token_count":523,"section_type":"other","chapter_number":5,"chapter_title":"Causal Loop Diagrams","chunk_index":217}
{"chunk_id":"5c348126955377e7","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"154 \nFIGURE 5-1 5 \nMake intermediate \nlinks explicit to \nclarify a causal \nrelationship. \nPart I1 Tools for Systems Thinking \nIf your audience was confused by \n-- \nMarket \nUnit \nShare \ncosts \nyou might make the intermediate concepts explicit as follows: \n+ Cumulative \n/ \nPytruccm d \nProduction \nExperience \nMarket \nShare \nUnit \ncosts \n5.2.8 \nChoose the Right Level of Aggregation \nCausal loop diagrams are designed to communicate the central feedback structure \nof your dynamic hypothesis. They are not intended to be descriptions of a model at \nthe detailed level of the equations. Having too much detail makes it hard to see the \noverall feedback loop structure and how the different loops interact. Having too lit- \ntle detail makes it hard for your audience to grasp the logic and evaluate the plau- \nsibility and realism of your model. \nIf your audience doesn’t grasp the logic of a causal link, you should make \nsome of the intermediate variables more explicit. Figure 5-15 shows an example. \nYou might believe that in your industry, market share gains lead to lower unit costs \nbecause higher volumes move your company down the learning curve faster. The \ntop panel compresses this logic into a single causal link. If your audience found \nthat link confusing, you should disaggregate the diagram to show the steps of your \nreasoning in more detail, as shown in the bottom panel. \nOnce you’ve clarified this logic to the satisfaction of all, you often can \n“chunk” the more detailed representation into a simple, more aggregate form. The \nsimpler diagram then serves as a marker for the richer, underlying causal structure. \n5.2.9 \nDon’t Put All the Loops into \nOne Large Diagram \nShort-term memory can hold 7 t 2 chunks of information at once. This puts a \nrather sharp limit on the effective size and complexity of a causal map. Presenting \na complex causal map all at once makes it hard to see the loops, understand which \nare important, or understand how they generate the dynamics. Resist the tempta- \ntion to put all the loops you and your clients have identified into a single compre- \nhensive diagram. Such diagrams look impressive-My, what a lot of work must \nhave gone into it! How big and comprehensive your model must be!-but are not \neffective in communicating with your audience. A large, wall-filling diagram may \nbe perfectly comprehensible to the person who drew it, but to the people with \n","page_start":179,"page_end":179,"token_count":539,"section_type":"other","chapter_number":5,"chapter_title":"Causal Loop Diagrams","chunk_index":218}
{"chunk_id":"f47927c37dd57ffe","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"Chapter 5 Causal Loop Diagrams \n155 \nwhom the author seeks to communicate, it is indistinguishable from a Jackson \nPollock and considerably less valuable. \nHow then do you communicate the rich feedback structure of a system without \noversimplifying? Build up your model in stages, with a series of smaller causal \nloop diagrams. Each diagram should correspond to one part of the dynamic story \nbeing told. Few people can understand a complex causal diagram unless they have \na chance to digest the pieces one at a time. Develop a separate diagram for \neach important loop. These diagrams can have enough detail in them to show how \nthe process actually operates. Then chunk the diagrams into a simpler, high- \nlevel overview to show how they interact with one another. In presentations, build \nup your diagram piece by piece from the chunks (see sections 5.4 and 5.6 for \nexamples). \n5.2.10 \nMake the Goals of Negative Loops Explicit \nAll negative feedback loops have goals. Goals are the desired state of the system, \nand all negative loops function by comparing the actual state to the goal, then ini- \ntiating a corrective action in response to the discrepancy. Make the goals of your \nnegative loops explicit. Figure 5-16 shows two examples. The top panel shows a \nnegative loop affecting the quality of a company’s product: the lower the quality, \nthe more quality improvement programs will be started, and (presumably) the de- \nficiencies in quality will be corrected. Making goals explicit encourages people to \nask how the goals are formed. The goals in most systems are not given exoge- \nnously but are themselves part of the feedback structure. Goals can vary over time \nand respond to pressures in the environment. In the example, what determines the \nFIGURE 5-16 \nMake the goals of \nnegative loops \nexplicit. \nHuiman agency or \nnatural processes \ncan determine \ngoals. \nTop: The goal alf \nthe loop is \ndetermined by \nmanagement \ndecision. \nThe \nBottom: \nlaws of \nthermodynamics \ndetermine the goal \nof the loop. \n( i e G t u r e 1  \nCoffee \nCooling Rate + \nIncorrect \n+ Product \nImprovement \nPrograms \nCorrect \nDesired \n+ \nProduct \nQuality \nQuality \nImprovement \nPrograms \n+ \nCoffee \nRoom \nTemperature \nTemperature \n4 B) \nTemperature \nDifference \nCooling \nRate \n+ \n","page_start":180,"page_end":180,"token_count":523,"section_type":"other","chapter_number":5,"chapter_title":"Causal Loop Diagrams","chunk_index":219}
{"chunk_id":"7c012d9a5c227a16","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"156 \nPart I1 Tools for Systems Thinking \ndesired level of product quality? The CEO’s edict? Benchmarking studies of com- \npetitor quality? Customer input? The company’s own past quality levels? When the \ngoal is explicit these questions are more likely to be asked and hypotheses about \nthe answers can be quickly incorporated in the model. \nMaking the goals of negative loops explicit is especially important when the \nloops capture human behavior. But often it is important to represent goals explic- \nitly even when the loop does not involve people at all. The second example por- \ntrays the negative feedback by which a cup of coffee cools to room temperature. \nThe rate of cooling (the rate at which heat diffuses from the hot coffee to the sur- \nrounding air) is roughly proportional to the difference between the coffee temper- \nature and room temperature. The cooling process stops when the two temperatures \nare equal. This basic law of thermodynamics is made clear when the goal is shown \nexplicitly. \nThere are exceptions to the principle of showing the goals of negative loops. \nConsider the death rate loop in Figure 5- 1. The goal of the death rate loop is im- \nplicit (and equal to zero: in the long run, we are all dead). Your models should not \nexplicitly portray the goal of the death loop or the goals of similar decay processes \nsuch as the depreciation of capital equipment. \n5.2.11 \nDistinguish between Actual and \nPerceived Conditions \nOften there are significant differences between the true state of affairs and the \nperception of that state by the actors in the system. There may be delays caused by \nreporting and measurement processes. There may be noise, measurement error, \nbias, and distortions. In the quality management example shown in Figure 5-16, \nthere may be significant delays in assessing quality and in changing management’s \nopinion about product quality. Separating perceived and actual conditions helps \nprompt questions such as How long does it take to measure quality? To change \nmanagement’s opinion about quality even after the data are available? To im- \nplement a quality improvement program? To realize results? Besides the long time \ndelays, there may be bias in the reporting system causing reported quality to differ \nsystematically from quality as experienced by the customer. Customers don’t file \nwarranty claims for all problems or report all defects to their sales representative. \nSales and repair personnel may not report all customer complaints to the home \noffice. There may be bias in senior management’s quality assessment because sub- \nordinates filter the information that reaches them. Some auto executives are pro- \nvided with the latest models for their personal use; these cars are carefully selected \nand frequently serviced by company mechanics. Their impression of the quality of \ntheir firm’s cars will be higher than that of the average customer who buys off the \nlot and keeps the car for 10 years. The diagram might be revised as shown in \nFigure 5-17. The diagram now shows how management, despite good inten- \ntions, can come to hold a grossly exaggerated view of product quality, and you are \nwell positioned for a discussion of ways to shorten the delays and eliminate the \ndistortions. \n","page_start":181,"page_end":181,"token_count":678,"section_type":"other","chapter_number":5,"chapter_title":"Causal Loop Diagrams","chunk_index":220}
{"chunk_id":"dd47beaff7d4d62c","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"Chapter 5 Causal Loop Diagrams \n157 \nFIGURE 5-17 \nDistinguish \nbetween actual \nand perceived \nconditions. \nBias in \nReporting \nSystem \nManagement \nBias Toward \nProduct \nQuality \n+ 6High \nQuality \nQuality \nProduct \nManagement \nPerception of \nDelay \nProduct Quality \nDesired \nProduct \nQuality \nQuality \nPrograms \nImprovement \nShortfall \n+ \n5.3 \nPROCESS POINT: \nDEVELOPING CAUSAL DIAGRAMS FROM INTERVIEW DATA \nMuch of the data a modeler uses to develop a dynamic hypothesis comes from in- \nterviews and conversations with people in organizations. There are many tech- \nniques available to gather data from members of organizations, including surveys, \ninterviews, participant observation, archival data, and so on. Surveys generally do \nnot yield data rich enough to be useful in developing system dynamics models. In- \nterviews are an effective method to gather data useful in formulating a model, ei- \nther conceptual or formal. Semistructured interviews (where the modeler has a set \nof predefined questions to ask but is free to depart from the script to pursue av- \nenues of particular interest) have proven to be particularly effective. \nInterviews are almost never sufficient alone and must be supplemented by \nother sources of data, both qualitative and quantitative. People have only a local, \npartial understanding of the system, so you must interview all relevant actors, at \nmultiple levels, including those outside the organization (customers, suppliers, \netc.). Interview data is rich, including descriptions of decision processes, internal \npolitics, attributions about the motives and characters of others, and theories to ex- \nplain events, but these different types of information are mixed together. People \nboth know more than they will tell you and can invent rationales and even inci- \ndents to justify their beliefs, providing you with “data” they can’t possibly know \n(Nisbett and Wilson 1977). The modeler must triangulate by using as many sources \nof data as possible to gain insight into the structure of the problem situation and the \ndecision processes of the actors in it. An extensive literature provides guidance in \ntechniques for qualitative data collection and analysis; see, for example, Argyris et \nal. (1985), Emmerson et al. (1995), Glaser and Strauss (1967), Kleiner and Roth \n(1997), March et al. (1991), Morecroft and Sterman (1994), Van Maanen (1988), \nand Yin (1994). \n","page_start":182,"page_end":182,"token_count":549,"section_type":"other","chapter_number":5,"chapter_title":"Causal Loop Diagrams","chunk_index":221}
{"chunk_id":"c3e304486d0149b7","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"158 \nPart I1 Tools for Systems Thinking \nOnce you’ve done your interviews, you must be able to extract the causal \nstructure of the system from the statements of the interview subjects. Formulate \nvariable names so that they correspond closely to the actual words used by the per- \nson you interviewed, while still adhering to the principles for proper variable name \nselection described above (noun phrases, a clear and positive sense of direction). \nCausal links should be directly supported by a passage in the transcript. Typically, \npeople will not describe all the links you may see and will not explicitly close \nmany feedback loops. Should you add these additional links? It depends on the \npurpose of your diagram. \nIf you are trying to represent a person’s mental model, you must not include \nany links that cannot be grounded in the person’s own statements. However, you \nmay choose to show the initial diagram to the person and invite him or her to elab- \norate or add any missing links. People will often mention the motivation for a de- \ncision they made, with the feedback effect on the state of the system implicitly \nunderstood. For example, “Our market share was slipping, so we fired the market- \ning VP and got ourselves a new ad agency.” Implicit in this description is the be- \nlief that a new VP and agency would lead to better ads and an increase in market \nshare, closing the negative loop. \nIf the purpose of your interviews is to develop a good model of the problem \nsituation, you should supplement the links suggested by the interviews with other \ndata sources such as your own experience and observations, archival data, and so \non. In many cases, you will need to add additional causal links not mentioned in \nthe interviews or other data sources. While some of these will represent basic phys- \nical relationships and be obvious to all, others require justification or explanation. \nYou should draw on all the knowledge you have from your experience with the \nsystem to complete the diagram1 \nProcess Improvement \nThe following two quotes are actual interview transcripts developed in fieldwork \ncarried out in an automobile company in the United States. The managers, from \ntwo different component plants in the same division of the company, describe why \nthe yield of their lines was persistently low and why it had been so difficult to get \nprocess improvement programs off the ground (Repenning and Sterman 1999): \nIn the minds of the [operations team leaders] they had to hit their pack counts [daily \nquotas]. This meant if you were having a bad day and your yield had fallen . . . you \nhad to run like crazy to hit your target. You could say, “You are making 20% \ngarbage, stop the line and fix the problem,” and they would say, ‘‘I can’t hit my \npack count without running like crazy.” They could never get ahead of the game. \nSupervisors never had time to make improvements or do preventive maintenance \non their lines . . . they had to spend all their time just trying to keep the line going, \n-Manager at Plant A \n‘Burchill and Fine (1997) illustrate how causal diagrams can be developed from interview data \nin a product development context. \n","page_start":183,"page_end":183,"token_count":678,"section_type":"other","chapter_number":5,"chapter_title":"Causal Loop Diagrams","chunk_index":222}
{"chunk_id":"9dede705dac9b42a","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"Chapter 5 Causal Loop Diagrams \n159 \nbut this meant it was always in a state of flux . . . because everything was so unpre- \ndictable. It was a kind of snowball effect that just kept getting worse. \n-Supervisor ut Plant B \nDevelop a single causal diagram capturing the dynamics described by the inter- \nviews. Name your loops using terms from the quotes where possible. Explain in a \nparagraph or two how the loops capture the dynamics described. Build your dia- \ngram around the basic physical structure shown in Figure 5-18. The Net Through- \nput of a process (the number of usable parts produced per time period, for example, \nthe number of usable parts produced per day) equals Gross Throughput (the total \nnumber produced per time period) multiplied by the process Yield (the fraction of \ngross throughput that passes inspection and is usable). The remainder, Gross \nThroughput * (1 - Yield), are defective. \n5.4 CONCEPTUALIZATION CASE STUDY: \nMANlAGlNG YOUR WORKLOAD \nThis section illustrates the use of causal diagrams to model an issue. The example \nshows how causal diagramming can be an aid to the development of a dynamic hy- \npothesis, along with identifying variables and developing a reference mode show- \ning the dynamics of the variables over the relevant time horizon. \n5.4.1 \nProblem Definition \nConsider the process of managing your workload. You might be an engineer in a \nproduct development organization, a consultant, or a CEO. To keep it concrete, fo- \ncus on a student managing his or her workload. A student (imagine yourself) must \nbalance classes and assignments with outside activities, a personal life, and sleep. \nDuring the semester you attend classes, do the readings, and hand in assignments \nas they are due, at least occasionally. You probably try to work harder if you think \nyour grades are lower than you desire and take more time off when you are sleep- \ndeprived and your energy level falls. There are two basic policies you can follow: \n(1) The ant strategy-never put off until tomorrow what you can do today; or \n(2) the grasshopper strategy-never do today what can be put off until tomorrow. \nThe ant works steadily throughout the semester as work is assigned and never \nbuilds up a large backlog of assignments. As a result, the ant avoids the end of se- \nmester crunch, keeps the workweek under control, and is able to stay well rested. \nBecause the ant gets enough sleep, productivity is high, and the ant has plenty of \n","page_start":184,"page_end":184,"token_count":551,"section_type":"other","chapter_number":5,"chapter_title":"Causal Loop Diagrams","chunk_index":223}
{"chunk_id":"0a420f826d82f7e7","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"160 \nPart I1 Tools for Systems Thinking \ntime to participate in outside activities. The ant’s grades improve steadily through- \nout the term. \nThe grasshopper, in contrast, defers the work until the last minute. The \ngrasshopper’s workweek is low at the beginning of the term, providing lots of time \nfor parties and outside activities. The grasshopper can stay reasonably well rested \ndespite a heavy social schedule because the workweek is low. But because the \ngrasshopper doesn’t do the work as fast as it is assigned, the assignment backlog \nsteadily builds up. Eventually, it’s crunch time, and the grasshopper starts putting \nin long hours, perhaps pulling a few all-nighters. Unfortunately, as sleep suffers, \nenergy and productivity fall. The rate and quality of work suffers. Grades plummet, \nand the term ends before the grasshopper can finish all the work, perhaps leading \nthe grasshopper to plead for extensions from the faculty. \n5.4.2 \nIdentifying Key Variables \nThe description above suggests several variables important in a model of student \nworkload management (units of measure are given in parentheses): \nAssignment rate: the rate at which professors assign work throughout the \nterm (taskdweek). \nWork completion rate: the rate at which tasks are completed (taskdweek). \nAssignment backlog: the number of tasks that have been assigned but not \nyet completed (tasks). \nGrades: the grade received for work handed in (0-100 scale). \nWorkweek: the number of hours spent on academic work, including \nclasses, reading, homework, projects, etc. (hourdweek). \nEnergy level: measures how well rested the student is. Arbitrary scale from \n0-100% where 100% = fully rested and 0 = comatose). \nOther variables could be added, but this set provides a reasonable starting point for \nconceptualization of the feedback structure governing the dynamics. As you pro- \nceed, you may find you need to revise the list. \n5.4.3 Developing the Reference Mode \nFigure 5- 19 translates the written descriptions of the ant’s behavior into graphical \nform (Figure 5-20 shows the grasshopper strategy). These graphs constitute the ref- \nerence mode characterizing the problem. Some items to note: \n1. The time horizon is explicitly stated. Here, the semester is 13 weeks long. \n2. Several different graphs are used to avoid clutter. The time axes of each \ngraph are aligned so that the timing of events can be directly compared. \n3. Variables with the same units are plotted on the same axis. For example, the \nassignment and completion rates are both measured in taskdweek and are \nplotted together. \n4. You don’t need quantitative data to capture the dynamics in the reference \nmodes. When numerical data are unavailable you should estimate the \n","page_start":185,"page_end":185,"token_count":611,"section_type":"other","chapter_number":5,"chapter_title":"Causal Loop Diagrams","chunk_index":224}
{"chunk_id":"67519e43afe59601","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"Chapter 5 \nCausal Loop Diagrams \n161 \nFIGURE 5-1 9 \nReference mode \nfor the ant strat’egy \nAssignment Rate \nWork Completion Rate \n0 \nTime (weeks of the semester) \n13 \nAssignment Bac..log \n0 \nTime (weeks of the semester) \n13 \n100 \nh \n___--- \ng \n/------ \nO\nh\n \nGrades \ng g  \n/------ \nU \n- &  \nQ ) u  \n__ _-_____ - \n\\I \n0 \nTime (weeks of the semester) \n13- \nbehavior of the variables from the written description and other qualitative \ninformation. Scales and rough magnitudes are provided where possible, as \nthey are for the workweek, grades, and energy level. Of course, when \nquantitative data are available, they should be used. But don’t omit \nimportant variables simply because they haven’t been measured yet or \nbecause the data aren’t readily available. An important goal of the modeling \n","page_start":186,"page_end":186,"token_count":212,"section_type":"other","chapter_number":5,"chapter_title":"Causal Loop Diagrams","chunk_index":225}
{"chunk_id":"ae2fa609ecfaf5dd","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"162 \nPart I1 Tools for Systems Thinking \nFIGURE 5-20 \nReference \nmode for the \ngrasshopper \nstrategy \n0 \nTime (weeks of the semester) \n13 \n0 \nTime (weeks of the semester) \n13 \n100 \nn \nY \n8 \n8 3 \nE \nG \nGrades \n3 \nE \n0\n’\n \n\\ \n3 ----------_I----- \n----- I_ \n_____\nY \nQ, \nQ, \nP \n13 \n0 \nTime (weeks of the semester) \nprocess is the identification of variables that should be measured so the \nnecessary empirical work can be done. \n5. There should be a basis in the data (numerical or written) for each feature of \nthe reference mode. For example, the graph of the ant’s grades rises because \nthe description of the ant strategy states that the ant’s grades improve \nsteadily throughout the term. Likewise, for the grasshopper the “term ends \n","page_start":187,"page_end":187,"token_count":208,"section_type":"other","chapter_number":5,"chapter_title":"Causal Loop Diagrams","chunk_index":226}
{"chunk_id":"752ba84ecfb908c9","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"Chapter 5 Causal Loop Diagrams \n163 \nbefore the grasshopper can finish all the work\" so the assignment backlog, \nthough falling, remains positive even as the term ends. \n6. The magnitudes and timing of variables should be consistent with your \nknowledge of the system even if the description available does not specify \nthese features. Details matter. For example, consider the grasshopper \nstrategy. The work completion rate must depend on the student's work \neffort (workweek), so these move together. However, because energy and \nproductivity are falling at the end, the completion rate does not rise as much \nas the workweek during the end of semester crunch. To make this even \nmore obvious, you might define the variable Productivity explicitly (try \nsketching its dynamics from the description above). \n7. Make sure your graphs are consistent with any stock and flow relationships \namong the variables. Since the assignment backlog accumulates the rate of \nassignments less the rate of work completion, it must be rising whenever \nthe assignment rate exceeds the completion rate, and vice versa. The \nrelationship between the backlog and its flows is most clearly seen in \nthe grasshopper strategy. Until week 10, the assignment rate exceeds the \ncompletion rate, so the backlog builds up. At week 10, the grasshopper \nis handing in work just as fast as new work is assigned, and the backlog \nreaches its peak. After week 10, the completion rate exceeds the assignment \nrate and the backlog falls. \n5.4.4 \nDeveloping the Causal Diagrams \nNext you must use the description of the system and reference modes to develop a \ncausal map of the feedback processes you believe are responsible for the dynamics. \nConsider Figure 5-21. The Assignment Rate is assumed to be exogenous: Once \na student has signed up for a set of courses, the assignment rate is determined. \nClasses can sometimes be dropped, but this possibility is ignored for now. The As- \nsignment Backlog is increased by the Assignment Rate and decreased by the Com- \npletion Rate. Completion Rate (taskdweek) is Workweek (hours per week) times \nProductivity (tasks completed per hour of effort) times the Effort Devoted to As- \nsignments. Effort Devoted to Assignments is the effort put in by the student com- \npared to the effort required to complete the assignment with high quality. If work \npressure is high, the student may choose to cut corners, skim some reading, skip \nclasses, or give less complete answers to the questions in assignments. For exam- \nple, if a student works 50 hours per week and can do one task per hour with high \nquality but only does half the work each assignment requires for a good job, then \nthe completion rate would be (50)( 1)(.5) = 25 task equivalents per week. \nWork Pressure determines the workweek and effort devoted to assignments. \nWork pressure depends on the assignment backlog and the Time Remaining to \ncomplete the work: The bigger the backlog or the less time remaining, the higher ","page_start":188,"page_end":188,"token_count":653,"section_type":"other","chapter_number":5,"chapter_title":"Causal Loop Diagrams","chunk_index":227}
{"chunk_id":"85fff4c01aeb01dc","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"quality but only does half the work each assignment requires for a good job, then \nthe completion rate would be (50)( 1)(.5) = 25 task equivalents per week. \nWork Pressure determines the workweek and effort devoted to assignments. \nWork pressure depends on the assignment backlog and the Time Remaining to \ncomplete the work: The bigger the backlog or the less time remaining, the higher \nthe workweek needs to be to complete the work on time. Time remaining is of \ncourse simply the difference between the Due Date and the current Calendar Time. \nThe two most basic options available to a student faced with high work pressure \nare to (1) work longer hours, thus increasing the completion rate and reducing the ","page_start":188,"page_end":188,"token_count":149,"section_type":"other","chapter_number":5,"chapter_title":"Causal Loop Diagrams","chunk_index":228}
{"chunk_id":"8d54d7cf3796ee06","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"164 \nPart I1 Tools for Systems Thinking \nFIGURE 5-21 \nBasic control loops for the assignment backlog \nWork \nCompletion + \n* \nAssign men t \nRate \nAssignment \nBacklog \nC a I e n d a r \nTime \\ \nCutting \nEffort Devoted \nProductivity \nc \nTime \\ \nWork \nPressure \n\\to \nAssignments \nDue \nDate \nMidnight \nOil \nbacklog (the Midnight Oil loop B l), or (2) work faster by spending less time on \neach task, speeding the completion rate and reducing the backlog (the Corner Cut- \nting loop B2). Both are negative feedbacks whose goal is to reduce work pressure \nto a tolerable level. \nHowever, each of these negative feedbacks has side effects. Consider Figure \n5-22. Sustained high workweeks cut into sleep and the satisfaction of other needs \n(eating, exercise, human companionship, etc.), causing the student’s Energy Level \nto fall. As energy level falls, so too do concentration and focus. Errors rise. Pro- \nductivity drops, reducing the completion rate-a tired student must spend longer \nthan a well-rested one to complete a task with a given level of quality. As the com- \npletion rate falls, the backlog remains higher than it would otherwise be and work \npressure intensifies, leading to still higher workweeks and still lower energy and \nproductivity. If the self-reinforcing Burnout loop, R1, dominates the balancing \nMidnight Oil loop, an increase in workweek would actually lower the completion \nrate as the extra hours are more than offset by the increase in errors and reduction \nin productivity. \nReducing the effort devoted to each assignment also has side effects. Putting \nless effort into each task does allow assignments to be completed in less time \nbut reduces the Quality of Work, lowering the student’s Grades. When grades fall \n","page_start":189,"page_end":189,"token_count":401,"section_type":"other","chapter_number":5,"chapter_title":"Causal Loop Diagrams","chunk_index":229}
{"chunk_id":"f6ea180814aeb935","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"Chapter 5 \nCausal Loop Diagrams \n165 \nFIGURE 5-22 The burnout loop \nWork \nCompletion + \n3 \nAssignment \nRate \nAssign men t \nCalendar \nTime -x \nEffort Devoted \nProductivity \n+ \nTime \nP m a i n i n g  \\ \nWork \n/ \nPressure \nDue \nDate \nBurnout \nrelative to the student’s aspirations, there is pressure to boost the effort put into \neach task. The negative Quality Control loop B3 prevents effort and quality from \nfalling too far even when work pressure is high (Figure 5-23). However, the effort \nto maintain quality also creates an insidious positive feedback. As work pressure \nforces the workweek up, energy level eventually falls (note the delay), reducing \ngrades. The student responds by increasing the effort put into each task in an at- \ntempt to boost grades back up through the quality control loop. But increasing the \ntime spent on each task lowers the completion rate. The backlog of work rises, in- \ntensifying work pressure and leading to still more overtime, still lower energy, and \nstill lower grades. When the exhausted student is Too Tired to Think, the positive \nloop R2 operates as a vicious cycle-efforts to boost grades only succeed in creat- \ning more work pressure, longer hours, even lower energy, and still lower quality \nwork. \nYou may wonder why anyone would keep working when their efforts not only \nyielded diminishing returns but negative returns. Wouldn’t the grasshoppers real- \nize their efforts were actually counterproductive? It is precisely when people \nare exhausted that their judgment is most impaired. How many times have you \ncontinued to work on a project when, at least in retrospect, you should have called \nit a day? \n","page_start":190,"page_end":190,"token_count":378,"section_type":"other","chapter_number":5,"chapter_title":"Causal Loop Diagrams","chunk_index":230}
{"chunk_id":"23b5634741458457","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"166 \nPart I1 Tools for Systems Thinking \nFIGURE 5-23 The “too tired to think’ loop \nWork \nCompletion + \n- \nAssignment \nRate \nAssignment \nCalendar \nTime \\ \nF \nWork \nTime \nRemaining \nDue \nDate \nIf all else fails, the exhausted student can appeal to the faculty for relief, gen- \nerating Requests for Extensions (Figure 5-24). Usually, such requests are accom- \npanied by stories of bad luck and hardship beyond the student’s control: “My dog \nate my homework,” “My hard disk crashed,” “My roommate had a nervous break- \ndown.” If the faculty are moved by these tales of tragedy and woe (a big if), the \ndue date is slipped, making more time available and reducing work pressure. Be- \ncause faculty rarely give extensions unless there are genuine extenuating circum- \nstances, the negative My Dog Ate My Homework loop B4 is quite weak. Note that \nslipping the deadline, because it lowers work pressure, may actually cause the \nworkweek to fall and the effort devoted to each assignment to rise, both reducing \nthe completion rate and causing work pressure to build up again. These feedbacks \nare responsible for Parkinson’s (1957) famous law: “Work expands to fill the time \navailable for its completion.” \nWhile there are many other loops you could add to the framework, these six \nfeedbacks jointly explain most of the dynamics created by the ant and grasshopper \nstrategies. \n5.4.5 Limitations of the Causal Diagram \nCausal diagrams can never be comprehensive (and you shouldn’t try: modeling is \nthe art of simplification). They are also never final, but always provisional. The \n","page_start":191,"page_end":191,"token_count":365,"section_type":"other","chapter_number":6,"chapter_title":"Stocks and Flows","chunk_index":231}
{"chunk_id":"e02a14c5f317b891","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"Chapter 5 Causal Loop Diagrams \n167 \nFIGURE 5-24 My dog ate my homework-Parkinson's Law 7 \nWork \nCompletion + \n3 \nAssignment \nRate \nAssignment \nCalendar \nMy Dog Ate \nMy Homework \nDate \nmaps evolve as your understanding improves and as the purpose of the modeling \neffort evolves. The account of workload management above is far from perfect. \nHere are some issues to consider: \nFirst, the diagram does not distinguish between stocks and flows. In particular, \nit would be helpful to show the stock and flow structure of the assignment backlog. \nWhat other variables in this model are stocks? \nSecond, some loops could be specified in more detail. For example, the qual- \nity control loop assumes that effort increases when grades fall relative to the stu- \ndent's aspirations. It would be clearer to specify those aspirations explicitly, for \nexample, by creating a variable Desired Grade Point Average (GPA). Effort would \nthen be affected by the student's Satisfaction with Grades, which measures the gap \nbetween desired and actual grades. An explicit goal for grades makes it easier to \nexplore the dynamics for students with different aspirations and attitudes about the \nimportance of grades. Making the goal explicit also motivates questions such as \nWhat determines aspirations for academic achievement?-that is, what feedback \nprocesses might cause the desired GPA to vary over time? \nA variety of pressures for achievement, external to the workload management \nmodel, put upward pressure on grade aspirations. Such pressures arise from obser- \nvations of the grades your peers receive (or claim to have received), from parents, \n","page_start":192,"page_end":192,"token_count":341,"section_type":"other","chapter_number":6,"chapter_title":"Stocks and Flows","chunk_index":232}
{"chunk_id":"df2808cdd44dd74f","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"168 \nPart I1 Tools for Systems Thinking \nFIGURE 5-25 \nMaking the goal of \na loop explicit \nAdding the desired \nGPA and its \ndeterminants. \nCHALLENGE \nWork Pressure \nI- \nEffort Devoted \nto Assignments \\ \nQuality Control \nSatisfaction \n@ \nwith Grades \nGoal Erosion \nGrades \nQuality of \nWork \n+ \nDesired \nGPA \nPressure for \nAchievement \nEnergy Level \n+ \nor from the (perceived) requirements of future employers or graduate school ad- \nmissions officers. Figure 5-25 shows another important determinant of student \ngoals: Aspirations adjust to past actual achievement, forming the negative Goal \nErosion loop. Many people judge what is possible, at least in part, from what has \nbeen achieved. Eroding your goals in the face of a persistent discrepancy between \naspiration and achievement is a common way to reduce what Festinger (1957) \ncalled “cognitive dissonance” and has been amply documented in many situations. \nThe goal erosion loop can be an important learning process or may create a harm- \nful self-fulfilling prophecy. For example, most students admitted to elite universi- \nties were at the top of their high school class. Once enrolled in the Ivy League or \nMIT, however, half of them will be in the bottom half of their class. The adjust- \nment of grade aspirations to a new situation prevents perpetual disappointment, \nstress, and self-doubt. On the other hand, overly flexible goals can lead to under- \nachievement. Some grasshoppers, reflecting on how much midnight oil they \nburned at the end of the term and the disappointing grades those hours led to, may \nconclude they aren’t A or even B students and lower their aspirations to relieve the \ndissonance between expectations and achievement. Sadly, this lesson may be en- \ntirely erroneous: Fewer hours of effort, if they were well rested, may easily have \nled to higher grades. \nPolicy Analysis with Causal Diagrams \nThe boundary of the student workload model could be extended to include many \nother feedback processes. Modify the student workload diagram to include the \nfollowing issues: \n1. Dropping classes in response to high work pressure, low grades, or low energy. \n2. Drinking coffee or taking stimulants to stay awake when energy level is low. \n","page_start":193,"page_end":193,"token_count":512,"section_type":"other","chapter_number":6,"chapter_title":"Stocks and Flows","chunk_index":233}
{"chunk_id":"2a911ddcc00ccc48","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"Chapter 5 \nCausal Loop Diagrams \n169 \n3. Cheating on assignments to boost the completion rate and raise grades. \n4. Other loops you believe to be important. \nAs you expand the boundary of the model, ask yourself Does the ability of the \nmodel to explain the dynamics change? Does the response of the model to policies \nchange? Are the conclusions of the earlier analysis robust to changes in the bound- \nary of the model? \n5.5 \nADAM SMITH’S INVISIBLE HAND AND THE \nFEEDBACK STRUCTURE OF MARKETS \nAdam Smith’s invisible hand is one of the most famous metaphors in the English \nlanguage. Smith realized that a free market creates powerful negative feedback \nloops that cause prices and profits to be self-regulating. While Smith lacked mod- \nem tools such as causal diagrams and simulation models, the feedback loops in his \ndescription of the functioning of markets are clear. In The Wealth ofNations Smith \nargued that for any commodity there was a “natural” price which is just “sufficient \nto pay the rent of the land, the wages of the labour, and the profits of the [capital] \nstock employed in raising, preparing, and bringing [the commodity] to market . . .” \nAt the natural price, a “commodity is then sold precisely for what it is worth, or for \nwhat it really costs the person who brings it to market . . .” In contrast, the actual \nmarket price “may either be above, or below, or exactly the same with its natural \nprice”-that is, markets may at any time be out of equilibrium. \nSmith then noted how prices respond to the balance between demand and \nsupply: \nThe market price of every particular commodity is regulated by the proportion \nbetween the quantity which is actually brought to market, and the demand of those \nwho are willing to pay the natural price of the commodity . . . When the quantity of \nany commodity which is brought to market falls short of the effectual demand, all \nthose who are willing to pay the whole value . . . cannot be supplied with the quan- \ntity which they want. Rather than want it altogether, some of them will be willing \nto give more. A competition will immediately begin among them, and the market \nprice will rise more or less above the natural price. \nSimilarly, when supply exceeds demand, “[tlhe market price will sink more or less \nbelow the natural price.” \nBut supply in turn responds to the market price: \nIf. . . the quantity brought to market should at any time fall short of the effectual \ndemand, some of the component parts of its price must rise above their natural rate. \nIf it is rent, the interest of all other landlords will naturally prompt them to prepare \nmore land for the raising of this commodity; if it is wages or profit, the interest of \nall other labourers and dealers will soon prompt them to employ more labour and \nstock in preparing and bringing it to market. The quantity brought thither will soon \nbe sufficient to supply the effectual demand. All the different parts of its price will \nsoon sink to their natural rate, and the whole price to its natural price. \n","page_start":194,"page_end":194,"token_count":670,"section_type":"other","chapter_number":6,"chapter_title":"Stocks and Flows","chunk_index":234}
{"chunk_id":"eeb2a05cf88f354d","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"170 \nFIGURE 5-26 \nThe invisible hand: \nthe feedback \nstructure of \nmarkets \nDemand responds \nto the relative \nvalue of the com- \nmodity compared \nto substitutes; \nhigher relative \nvalue increases \ndemand, bidding \nprices up and \nlowering relative \nvalue. Supply \nexpands when \nprofits rise; profit \ndepends on price \nrelative to pro- \nduction costs \nincludina the re- \n“ \nquired return on \ncapital. Greater \nsupply bids prices \ndown, lowering \nprofits. The price \nof substitutes and \nthe cost of produc- \ntion determine \nwhat Adam Smith \ncalled the “natural \nprice” of the com- \nmodity-the equi- \nlibrium price at \nwhich supply and \ndemand are equal. \nPart I1 Tools for Systems Thinking \n+ \nDemand \nPrice of \nSubstitutes \\i / \nRelative \n+ f  \nProfits \ncost of \nProduction \nA simple representation of the feedback structure Smith describes is shown in Fig- \nure 5-26. When the price of a commodity rises above the natural price, fewer buy- \ners “will be willing to give more” and more will be forced to “want it altogether.” \nThat is, as price rises relative to the price of substitutes, including all substitute \nuses for the funds available to the buyer, consumers will seek substitutes or find \nthemselves simply priced out of the market. As demand falls prices will be bid \ndown, forming a negative loop. At the same time, higher prices increase the profit \nsuppliers can realize, which attracts new entrants to the market and encourages \nexisting producers to increase output. As the supply increases, prices are bid down- \nwards. These two negative feedback loops cause price to adjust until, in the ab- \nsence of further external shocks, the market reaches equilibrium, with production \nequal to consumption and price equal to its natural level. Smith concludes: \nThe natural price, therefore, is, as it were, the central price, to which the prices of \nall commodities are continually gravitating. Different accidents may sometimes \nkeep them suspended a good deal above it, and sometimes force them down even \nsomewhat below it. But whatever may be the obstacles which hinder them from \nsettling in this centre of repose and continuance, they are constantly tending \ntowards it. \nSmith’s great insight was to realize that when prices rise above the natural level, \nproducers who seek to maximize their own gain will continue to enter the market \nuntil the price is bid down to the point where the return on their capital is no higher \n(today we would add “on a risk adjusted basis”) than that available elsewhere, re- \nsulting in competitive prices and an efficient allocation of resources throughout so- \nciety. He famously concludes: \nEvery individual endeavors to employ his capital so that its produce may be of \ngreatest value. He generally neither intends to promote the public interest, nor \nknows how much he is promoting it. He intends only his own security, only his \nown gain. And he is in this led by an invisible hand to promote an end which was \nno part of his intention. By pursuing his own interest he frequently promotes that of \nsociety more effectually than when he really intends to promote it. \n","page_start":195,"page_end":195,"token_count":694,"section_type":"other","chapter_number":6,"chapter_title":"Stocks and Flows","chunk_index":235}
{"chunk_id":"118897cd714722ac","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"Chapter 5 Causal Loop Diagrams \n171 \nSmith was thus one of the first systems thinkers to show how the local, intendedly \nrational self-interested behavior of individual people could, through the feedback \nprocesses created by their interactions, lead to unanticipated side effects for all. \nOf course, Smith’s concept of the invisible hand is far more famous as the \ncredo of modern free market capitalism. It is the core of the faith that markets \nknow best. Smith himself, however, was careful to note the limits of the market \nfeedbacks in equilibrating demand and supply at the natural price. “This at least \nwould be the case” Smith notes, “where there was perfect liberty”-that is, under \nconditions of perfect competition (free entry and exit, free mobility of the factors \nof production, and free exchange of information on demand, supply, costs, and \nprofits). Where there are monopolies, trade secrets, government regulations, barri- \ners to trade, restrictions on immigration and capital mobility, or other feedbacks \noutside the simple negative loops coupling supply and demand, Smith notes that \nprices and profits may rise above the natural level for many years, even decades. \nThe feedback structure for competitive markets shown in Figure 5-26 is quite \nuseful. Beginning with the general framework, one can disaggregate to show the \nspecific adjustment processes at work in any particular market for both demand \nand supply. Additional feedbacks besides the demand and supply loops can be \nadded, both positive and negative, and their implications assessed. The time de- \nlays, if any, in the reaction of demand and supply to higher prices can be estimated, \nand the implications for the stability of the market explored. If either the demand \nor supply loop operates strongly and swiftly (high short-run elasticities), then the \nmarket will rapidly return to equilibrium if perturbed. However, if there are long \ndelays or weak responses in the loops (low short-run elasticity and high long-run \nelasticity), then the market will be prone to persistent disequilibrium and instabil- \nity; random shocks in demand or production will excite the latent oscillatory be- \nhavior of the market (see chapters 4 and 20). \nNot all markets clear through price alone. Few products are pure commodities \nfor which price is the only consideration: Products and services are increasingly \ndifferentiated and companies compete to offer the best availability, delivery relia- \nbility, service, functionality, terms of payment, aftermarket support, and so on. In \nmany markets prices do not change fast enough to equilibrate supply and demand \nand other competitive variables such as availability become important in clearing \nthe market. Prices may be sluggish due to government regulation, the costs and ad- \nministrative burden of frequent price changes, or considerations of fairness. For \nexample, most people consider it unfair for hardware stores to raise the price of \nsnow shovels after a storm, even though demand may have increased (see Kahne- \nman, Knetsch, and Thaler 1986; Thaler 1991). ","page_start":196,"page_end":196,"token_count":653,"section_type":"other","chapter_number":6,"chapter_title":"Stocks and Flows","chunk_index":236}
{"chunk_id":"7c281248fb19c705","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"the market. Prices may be sluggish due to government regulation, the costs and ad- \nministrative burden of frequent price changes, or considerations of fairness. For \nexample, most people consider it unfair for hardware stores to raise the price of \nsnow shovels after a storm, even though demand may have increased (see Kahne- \nman, Knetsch, and Thaler 1986; Thaler 1991). \nIn many institutional settings price does not mediate markets at all. Most \norganizations, for example, have no price-mediated markets for offices, parking \nspaces, senior management attention, and many other scarce resources. In these \ncases, supply and demand are still coupled via negative feedbacks, but resources \nare allocated on the basis of availability, politics, perceived fairness, lottery, \nor other administrative procedures. Figure 5-27 shows examples of non-price- \nmediated markets. In each case the feedback structure is a set of coupled negative \nloops which regulate the demand for and supply of a resource. As in the case of \nprice-mediated markets, there may be substantial delays in the adjustments, lead- \ning to persistent disequilibria. ","page_start":196,"page_end":196,"token_count":244,"section_type":"other","chapter_number":6,"chapter_title":"Stocks and Flows","chunk_index":237}
{"chunk_id":"ecbd5c93891420eb","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"172 \nPart I1 Tools for Systems Thinking \nFIGURE 5-27 \nLeft: Availability is an important competitive variable in many product markets, and firms regulate \nproduction in response to inventory adequacy and delivery delay. \nRight: In service settings, higher service quality stimulates demand, but greater demand erodes service \nquality as waiting time increases, and accuracy, friendliness, and other experiential aspects of the \nservice encounter deteriorate. \nFeedback structure of non-price-mediated resource allocation systems \nProduct \nBacklog of \nAttractiveness @ Unfilled Orders \nProduct \nAvailability \n+ \nI \nDesired \nb \nI \n@ \nProduction \nInventory \n+ \n+ \nProduction \n+ Customer \n+ \nService \nRequests \nCustomer \nSatisfaction \n+ \nService \nService \n@ \nAdequacy \nResources \nof Service \nThe Oil Crises of the 1970s \nIn 1973 the first OPEC oil shock stunned the industrial world. Oil prices more than \ntripled in a matter of months as many Arab oil producers embargoed shipments to \nwestern nations to retaliate for their support of Israel in the Yom Kippur war. Many \nanalysts believed market forces would bring the price of oil back to pre-embargo \nlevels in a matter of months, or at most a year or two, as demand and supply re- \nacted. Instead, prices remained high, then rose even higher as Iranian production \nfell in the wake of the 1979 revolution. By the early 1980s, many analysts pre- \ndicted that oil prices were headed even higher and would never return to the low \nlevels of the early 1970s. But after reaching nearly $50 per barrel (in 1990 dollars), \nthe price of oil collapsed in the mid 1980s. Many oil exploration and alternative \nenergy projects were canceled; bankruptcy was common. In the US, gasoline \nprices in real terms fell below their pre-embargo level-gasoline in the late 1990s \nwas often one-fourth the price of designer water. \nStarting with the basic market feedback structure (Figure 5-26), develop a \ncausal diagram to explain (1) the failure of market forces to bring prices back to \nequilibrium soon after the first oil shock (that is, How could prices remain so high \nso long?) and (2) why prices collapsed in the mid 1980s and remained below the \nequilibrium level for so long (that is, Why didn’t prices stay high?). To help, Figure \n5-11 shows some of the causal links on the demand side of the market. Figure 3-4 \nshows US petroleum production, consumption, and real prices over the relevant \n","page_start":197,"page_end":197,"token_count":571,"section_type":"other","chapter_number":6,"chapter_title":"Stocks and Flows","chunk_index":238}
{"chunk_id":"9f326fa64f3720a3","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"Chapter 5 Causal Loop Diagrams \n173 \ntime horizon. Keep your diagram simple and follow the guidelines for causal loop \ndiagrams. \nUse your diagram to sketch the pattern of behavior you would expect for the \nrate of oil production and the rate of drilling of new wells from 1970 to 1990. Also \nplot capacity utilization for both activities (that is, what fraction of existing wells \nare pumping, and what fraction of existing drill rigs are operating, at any given \ntime). What does your diagram suggest about the likely dynamics of the world oil \nprice over the next few decades? \nSpeculative Bubbles \nNot all markets consist of negative feedbacks alone. In many markets the locally \nrational behavior of individual entrepreneurs creates positive feedbacks as they in- \nteract with one another and with the physical structure of the system. One common \nexample is the speculative bubble. There have been many dozens of major specu- \nlative bubbles in the past few centuries, from the infamous tulip mania of 1636 and \nSouth Sea bubble of 1720 to the manias and crashes of the past few decades, in- \ncluding gold, silver, real estate, impressionist paintings, and internet stocks.2 \nJohn Stuart Mill distilled the essence of the dynamics of speculation in the fol- \nlowing passage from his famous text Principles of Political Economy, originally \npublished in 1848: \nWhen there is a general impression that the price of some commodity is likely to \nrise, from an extra demand, a short crop, obstructions to importation, or any other \ncause, there is a disposition among dealers to increase their stocks, in order to profit \nby the expected rise. This disposition tends in itself to produce the effect which it \nlooks forward to, a rise of price: and if the rise is considerable and progressive, \nother speculators are attracted, who, so long as the price has not begun to fall, are \nwilling to believe that it will continue rising. These, by further purchases, produce a \nfurther advance: and thus a rise of price for which there were originally some ratio- \nnal grounds, is often heightened by merely speculative purchases, until it greatly \nexceeds what the original grounds will justify. After a time this begins to be per- \nceived; the price ceases to rise, and the holders, thinking it time to realize their \ngains, are anxious to sell. Then the price begins to decline: the holders rush into \nmarket to avoid a still greater loss, and, few being willing to buy in a falling mar- \nket, the price falls much more suddenly than it rose. \nDevelop a reference mode for Mill’s description of a speculative bubble. Begin- \nning with the basic two-loop structure for a market (Figure 5-26), develop a causal \ndiagram grounded in Mill’s text which explains the dynamics he describes. Explain \nbriefly how the feedback structure corresponds to Mill’s description and how it ex- \nplains the behavior. Give examples of the phenomenon. \n2Perhaps the best treatment of speculative bubbles is Charles Kindleberger’s (1978) Manias, \nPanics, and Crushes. See also Galbraith’s (1988) The Great Crush on the 1929 stock market crash. \n","page_start":198,"page_end":198,"token_count":686,"section_type":"other","chapter_number":6,"chapter_title":"Stocks and Flows","chunk_index":239}
{"chunk_id":"873b3b7ec7443c7f","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"174 \nPart I1 Tools for Systems Thinking \nThe Thoroughbred Horse Market \nFigure 5-28 shows the price of top yearling thoroughbreds in the US from 1965 \nthrough 1990. From 1974 to 1984 nominal prices for these elite horses increased \nby almost a factor of 10, to about $450,000. Even after removing the effects of in- \nflation, the real price of a top thoroughbred increased by more than a factor of 4. \nPrices then collapsed, falling by nearly 50% in just 4 years (in real terms). Adapt \nyour diagram of speculative bubbles to the thoroughbred horse market. Add suffi- \ncient detail to specify the particular biological and institutional features of the mar- \nket. For example, what are the motivations for owning a top race horse? (You can \nconsider a race horse to be an investment like a common stock, with an uncertain \nfuture payoff depending on the horse's performance on the track, but this is only \none of the reasons people own race horses, and expected cash flow rarely justifies \nsuch a risky investment). How is the supply of horses increased? What time delays \nare involved? \nUse your causal diagram to explain the dynamics of the thoroughbred price \nduring the 1970s and 80s. Why did the market rise so dramatically? Why did it \ncrash even faster? In 1965 about 18,000 thoroughbreds were born in North Amer- \nica. Using your model, sketch the likely behavior of the birth rate of North Amer- \nican thoroughbreds through 1990. \n400- \n69 = 300- \nm \n3 \n+ \nc\" 200: \ni n n  \n1965 \n1970 \n1975 \n1980 \n1985 \n1 \n~ 990 \nSource: Hermann and Link (1990). \n5.5.1 \nMarket Fai I ure, Adverse Selection, \nand the Death Spiral \nMany real world markets are imperfect due to limitations of information, costs of \nentry and exit, and inflexibility of resources. These imperfections create feedbacks \nthat sometimes overwhelm the negative loops normally balancing supply and de- \nmand, leading to inefficiency or even the complete failure of the market. One \nsource of market failure is adverse selection. \nAdverse selection can arise when sellers and buyers in a market have different \ninformation. A classic example, first developed by Akerlof (1970), considers the \n","page_start":199,"page_end":199,"token_count":528,"section_type":"other","chapter_number":6,"chapter_title":"Stocks and Flows","chunk_index":240}
{"chunk_id":"d8a75ab3495008ee","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"Chapter 5 Causal Loop Diagrams \n175 \nused car market. To illustrate how adverse selection works, Akerlof assumed that \nthe owners of used cars know the true quality of their cars while potential buyers \ndo not. At any given market price, owners, knowing the true quality of their cars, \nwill offer for sale only those cars actually worth less than the market price (the \n“lemons”) while keeping any car actually worth more (the “peaches”). Therefore, \nthe only cars offered for sale will be lemons. Potential buyers, realizing this, refuse \nto buy. Akerlof showed that in equilibrium no one will be willing to buy a used \ncar-the market will not exist, even though there are buyers and sellers who would \nbe willing to trade if both knew which were lemons and which were pea~hes.~ \nEach person, behaving rationally given the information available to them, causes \nan outcome undesirable for all. Akerlof’s result was a breakthrough in economics. \nNot only did his model form the foundation for the important field of information \neconomics, a field of immense importance in economics today, but he also demon- \nstrated that the workings of free markets were not always benign, even without \nmonopoly power or collusive agreements among producers. Adam Smith cele- \nbrated market forces for creating an invisible hand leading individuals to “promote \nan end which was no part of [their] intention,” an end which “frequently promotes \n[the interests] of society.” Akerlof showed that rational self-interest could lead \nindividuals to promote, though unintentionally, an end harmful to the interests of \nsociety-and themselves. \nHowever, Akerlof’s theory, like most economic models, is an equilibrium \nmodel and does not address the dynamics of the process. To examine the dynam- \nics of adverse selection in an important public policy context, consider the market \nfor health insurance. \nSince the 1950s, health care costs in the US have grown much faster than GDP \nand have long been the highest in the world, both in absolute expenditures per \ncapita and as a percent of national income. As costs rose, so too did health insur- \nance premiums. Federal programs such as Medicare (for the elderly) and Medicaid \n(for the poor) were created to provide a safety net for these groups. But rising \nhealth care costs soon outstripped federal benefits, and forced the elderly to seek \nprivate insurance to supplement Medicare. As the costs of private insurance rose, \nhowever, many were frozen out of the market. To prevent health care from bank- \nrupting them, many states required health insurers to offer so-called medigap in- \nsurance to senior citizens in return for the privilege of underwriting other business \nin their state. In Massachusetts, insurers were required to offer at least one medi- \ngap plan providing unlimited coverage for prescription drugs, one of the highest \ncosts for the elderly. At first, the program was very successful. In the 1980s, a wide \nrange of insurers offered medigap coverage in Massachusetts, capturing a large ","page_start":200,"page_end":200,"token_count":659,"section_type":"other","chapter_number":6,"chapter_title":"Stocks and Flows","chunk_index":241}
{"chunk_id":"1dfca64e8a3bc9e2","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"surance to senior citizens in return for the privilege of underwriting other business \nin their state. In Massachusetts, insurers were required to offer at least one medi- \ngap plan providing unlimited coverage for prescription drugs, one of the highest \ncosts for the elderly. At first, the program was very successful. In the 1980s, a wide \nrange of insurers offered medigap coverage in Massachusetts, capturing a large \nshare of the total senior citizen market. The largest program, Medex, offered by \n30f course, there is a used car market. Akerlof’s assumption that buyers have no knowledge of \nquality was a simplifying assumption to make the example clear. The real used car market has \nevolved various means to prevent market failure. Buyers can gain some information on quality \nthrough test drives and by having their own mechanic look at the car, and regulations such as lemon \nlaws and implied warranty doctrine reduce the buyer’s risk. Information on the past quality of cars \noffered by used car dealers deters some from selling lemons to unwitting buyers. The cost (in time \nand money) of these activities is a measure of the impact of the adverse selection problem in the \nused car market. ","page_start":200,"page_end":200,"token_count":253,"section_type":"other","chapter_number":6,"chapter_title":"Stocks and Flows","chunk_index":242}
{"chunk_id":"f4f3e8f29242735b","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"176 \nPart I1 Tools for Systems Thinking \nBlue Cross/Blue Shield of Massachusetts, covered about one-third of all senior cit- \nizens in the state in 1987. Premiums were low, about $50/month. In the late 1980s, \nhealth care cost inflation accelerated, and underwriters had to raise premiums, in- \ncluding the premiums for medigap and Medex. In response, some of the elderly \nwere forced to drop their medigap coverage. Others found they could get lower \nrates with other carriers or by signing up for plans offering fewer benefits or which \ncapped benefits for items such as prescriptions. However, only the healthiest se- \nniors were eligible for these other, cheaper plans. The sickest of the elderly, those \nsuffering from chronic illnesses, those with a history putting them at high risk- \nthose with so-called pre-existing conditions-were not eligible for less expensive \ncoverage or health maintenance organizations (HMOs) and had no choice but to \nstay with medigap. In many cases, the cost of prescriptions alone for those elderly \ncovered by Medex exceeded their premiums by hundreds of dollars each year. As \nmedigap losses mounted, premiums grew. But higher premiums forced still more \nof the comparatively healthy elderly to opt out of medigap as they found coverage \nelsewhere or simply did without, bearing the risk of illness themselves. Those re- \nmaining with the plan were, on average, sicker and costlier, forcing premiums up \nfurther. Figure 5-29 shows the evolution of the Medex subscriber base and premi- \nums. Total subscribers fell from nearly 300,000 in 1988 to about 158,000 in 1997, \nwhile subscribers of the premium Medex Gold option, which provided unlimited \ncoverage for prescriptions, fell even faster, from about 250,000 in 1988 to about \n65,000 in 1997. Over the same 10 years premiums rose from about $50/month to \n$228/month, with further increases projected. As the customer base shrank and \nlosses grew, underwriters began to withdraw from the market. In the early 1990s \nhalf a dozen insurers wrote medigap coverage in Massachusetts; by 1997 only \nMedex remained. A consumer activist lamented, “As healthier people continue to \ndrop out and sicker people stay in, premiums continue to go up, and you create a \ndeath spiral.” (Boston Globe, 20 January 1998, A12). \n1. Develop a causal loop diagram capturing the death spiral as depicted in \nsection 5.5.1. Your diagram should explain not only the dynamics of the \nsubscriber base and premiums, but also the profitability of the medigap \nmarket, the number of carriers offering coverage, and the health status of \nthose in the program. Note any important delays in your diagram. Use your \ndiagram to analyze the impact of the following policies: \na. Requiring all carriers doing business in the state to insure all qualified \napplicants, regardless of age or health. \nb. ","page_start":201,"page_end":201,"token_count":658,"section_type":"other","chapter_number":6,"chapter_title":"Stocks and Flows","chunk_index":243}
{"chunk_id":"ad3a83cf36b07814","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"subscriber base and premiums, but also the profitability of the medigap \nmarket, the number of carriers offering coverage, and the health status of \nthose in the program. Note any important delays in your diagram. Use your \ndiagram to analyze the impact of the following policies: \na. Requiring all carriers doing business in the state to insure all qualified \napplicants, regardless of age or health. \nb. \nRequiring all medigap plans (all the versions of Medex) to provide \nunlimited coverage for prescription drugs. The goal is to pool healthier \nseniors who generally use fewer drugs and choose the less expensive \nMedex plans with the sicker seniors who use more drugs and opt for \nMedex Gold. \nProvide a subsidy to lower medigap premiums, funded by the state. \nc. ","page_start":201,"page_end":201,"token_count":172,"section_type":"other","chapter_number":6,"chapter_title":"Stocks and Flows","chunk_index":244}
{"chunk_id":"414da21b8bb8c67b","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"Chapter 5 \nCausal Loop Diagrams \n177 \nd. Allowing BC/BS to drop Medex, effectively eliminating all medigap \ncoverage in the state of Massachusetts. \nIn assessing the impact of the policies, consider their effects on the insurers, on \nthe elderly (insured and uninsured), and on society at large. \n2. What assumptions about information availability and consumer behavior \nunderlie the theory captured in your causal loop diagram of the health \ninsurance market? How might the validity of these assumptions be altered, \nfor example, by advances in information technology which might make a \nperson's entire health history available to insurers, or advances in genetic \nscreening which might reveal which people were at increased risk for the \ndevelopment of particular illnesses? \n3. What other examples of adverse selection can you identify? Map their \nfeedback structure. \ndeath spiral: subscribers and premiums for medigap insurance \nnsurance for the elderly offered by Blue Cross/Blue Shield of Massachusetts. \nunlimited prescription drugs with a small copayment. Other Medex plans limit total \ne for December 1 of each year. * indicates proposed rate for 1998 of $278/month. \nuuscriuers \n* \n,:\" - 250 \n200 \n-150 \n5 \n3 \n-100 3 \n- 50 \n-\nn\n \n\" \n1988 1989 1990 1991 1992 1993 1994 1995 1996 1997 \nSource: Boston Globe, 20 January 1998, A1 \n5.6 \nEX P [.AI N I NG Po L I CY R ES I STAN c E : TR A FFI c CON G ESTI o N \nBy showing the network of feedback loops in which policies are embedded, causal \ndiagrams are often an effective way to show how event-oriented, open-loop men- \ntal models lead to policy resistance. Consider the problem of traffic congestion. \nAmerica's roads are choked with traffic. In 1995 there were nearly 200 million ve- \nhicles registered in the US. The 1990 census reported that about 100 million peo- \nple, 87% of all workers, traveled to work by motor vehicle, 85% of them alone. \nOnly 5% used public transportation. In 1960 64% commuted by motor vehicle. \nSince 1970 the number of registered vehicles grew by 70% and annual vehicle \nmiles grew by 90%, both much faster than the growth in population or households, \n","page_start":202,"page_end":202,"token_count":534,"section_type":"other","chapter_number":6,"chapter_title":"Stocks and Flows","chunk_index":245}
{"chunk_id":"c26570e874250d20","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"178 \n3 \n2 -  \n1 -  \n0 -  \nPart I1 Tools for Systems Thinking \n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n \n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n \n, \nI\nS\n I \nFIGURE 5-30 \nMore roads, \nmore traffic \nwhile public transportation stagnated (Figure 5-30). More and more of the average \nperson's day is spent inside a car: The government estimates Americans spend \n8 billion hours per year stuck in traffic. The cost of driving includes about $6000 \nper car per year in direct costs and up to another $9400 in indirect, externalized \ncosts. Estimates of lost productivity due to traffic congestion range from $43 to \n$168 billion per year. The economy and culture of the US (and of other auto-rich \nnations) have adapted themselves to the dominance of the auto, from the $40 bil- \nlion spent annually in the US to market automobiles to the rise of drive-through \nfast foods, especially foods you can eat with one hand (while the other steers). \nRoad rage is increasingly recognized as a common mental disorder, and frustrated \ndrivers have taken to shooting those who cut them off on the so-called freeway. \nWhat went wrong?4 \n5.6.1 \nMental Models of the Traffic Problem \nThe traditional solution to traffic jams and congestion has been road building. Fig- \nure 5-3 1 shows the open-loop perspective on the problem: The problem is highway \ncongestion; the solution is to build more roads. \nTotal Passengers on US Public Transit Systems \nO\nS\nO i  ,\n.\n,\n.\n,\n.\n,\n,\n.\n,\n.\n.\n,\n.\n.\n.\n,\n.\n.\n,\n.\n.\n.\n.\n,\n.\n,\n.\n.\n,\n.\n.\n,\n,\n.\n,\n.\n.\n.\n~\n \n1920 \n1940 \n1960 \n1980 \n2000 \nSources: Historical Statistics of the US; Kurian (1994). \n4Some of these data appear in Kay (1997), whose book Asphalt Nation discusses a broad range \nof social, cultural, economic, and environmental effects of automobile addiction. See also Downs \n(1992), Hansen (1995), and Gibbs (1997). \n","page_start":203,"page_end":203,"token_count":523,"section_type":"other","chapter_number":6,"chapter_title":"Stocks and Flows","chunk_index":246}
{"chunk_id":"d4a76ce939a752ee","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"Chapter 5 Causal Loop Diagrams \n179 \nFIGURE 5-31 \nOpen-loop view of \ntraffic congestion \nFIGURE 5-32 \nDeterminants of \ntravel time \nCongestion \nBuild New \nand Delays - \nRoads \nBut what happens when new roads are built? And where should you begin the \ndevelopment of a causal diagram to show the feedback effects of road construc- \ntion? It’s usually best to begin by capturing the physical structure of the system. \nSystems consist of both a physical structure and the decision rules used by the peo- \nple in the system (the behavioral structure). The physical structure is often easier \nto visualize and represent than the decision-making structure. Additionally, con- \nceptualization is often part of a group process in which people must share their \nown mental models and reach agreement over a single representation. It is usually \neasier to gain agreement about the physical structure. The behavioral structure is \noften more controversial; if you start there your group process may grind to a halt \nbefore you’ve really begun. \nA good place to start for the traffic congestion case is congestion itself. A good \nmodel requires a variable that has operational meaning and can be measured. One \ngood summary measure of congestion is average travel time (for the typical trip in \na particular region). What determines travel time? Travel time depends on the bal- \nance between the capacity of the highways to handle traffic and the number of ve- \nhicles using the roads, denoted Traffic Volume in Figure 5-32. \nAs the number of vehicles on the roads increases, given the highway capacity, \nthe average trip will take longer. As highway capacity rises, given the vehicle vol- \nume, the average travel time will fall. Highway capacity is altered by construction \nof new roads. Road construction here includes not only new roads but also im- \nprovements to existing roads such as adding lanes or increasing capacity by chang- \ning the flow of traffic, for example by converting a four-way intersection into a \ncloverleaf. Any project that augments the capacity of the roads to carry traffic \nwould be included in the notion of road construction, at least in this first version of \n+I \nHighway \nCapacity \nTraffic \nVolume \n","page_start":204,"page_end":204,"token_count":472,"section_type":"other","chapter_number":6,"chapter_title":"Stocks and Flows","chunk_index":247}
{"chunk_id":"d1e5f748e3f17424","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"180 \nPart I1 Tools for Systems Thinking \nFIGURE 5-33 \nCongestion \nleads to political \npressure to build \nmore roads, \nreducing con- \ngestion via the \nnegative Capacity \nExpansion \nfeedback. \nthe model (later you could disaggregate the construction of new roads from widen- \ning of existing roads, if that was deemed to be necessary for the purpose). Since \nhighway projects take time, the delay between the initiation of a construction proj- \nect and the increase in highway capacity is explicitly noted. \nWhen developing a causal map it is helpful to consider the units of measure for \nthe constructs in your diagram. Having consistent units is often a great aid to clear \nthinking about the definitions of and relationships among the variables. Specifying \nunits and checking for dimensional consistency is useful even when your model is \npurely conceptual and you do not intend to develop a formal simulation. Travel \ntime would be measured in minutes per trip (for the average trip in the region). \nHighway Capacity and Traffic Volume are measured in vehicle-miles per day (a \nvehicle mile is one mile traveled by one vehicle). \nHaving specified the physical structure of road building and highway con- \nstruction, next ask what drives highway construction programs. The primary moti- \nvation is congestion: as travel time rises, as traffic jams become the norm, as the \nrush hour expands from dawn through dusk, political pressure to build will build. \nFigure 5-33 adds the link from travel time to road construction. \nCongestion creates pressure for new roads; after the new capacity is added, \ntravel time falls, relieving the pressure. The Capacity Expansion loop (B 1) acts to \nreduce travel time to acceptable levels. Note that the goal of the loop, the desired \ntravel time, has been made explicit. Desired travel time is the travel time driv- \ners consider acceptable (on average), perhaps 20 minutes for the commute from \nhome to work. The 1990 census found average one-way commuting times for all \nmodes and all workers of about 22 minutes, though more than 17 million people \nspent more than 40 minutes getting to work and nearly 2 million spent more than \n90 minutes. \nConstruction \nPressure to \nReduce \nCongestion \n+I \nHighway \nCapacity \nCapacity \nExpansion \nTraffic \nVolume \n","page_start":205,"page_end":205,"token_count":491,"section_type":"other","chapter_number":6,"chapter_title":"Stocks and Flows","chunk_index":248}
{"chunk_id":"ee9ad74b38116ee2","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"Chapter 5 Causal Loop Diagrams \n181 \n5.6.2 \nCompensating Feedback: \nThe Response to Decreased Congestion \nSo far traffic volume is considered to be exogenous. This assumption is an accu- \nrate reflection of the mental models of many politicians, city planners, and trans- \nportation officials, for whom traffic volume grows as the population of the region \ngrows and as the local economy develops. They see their job as building enough \nroads to keep travel time at the acceptable level, so political pressure stays low, so \nthey can be reelected, and so they can serve special interests such as construction \nfirms, real estate developers, and the business community who benefit from road \nbuilding and who often provide lucrative jobs for them when they leave office. \nIf the capacity expansion loop were the only feedback operating in the system, \nthen the policy of road building to relieve congestion would work well: whenever \ntraffic volume rose, leading to congestion and pressure from the community, a road \nbuilding program would be started and highway capacity would expand until the \npressure was relieved. \nHowever, traffic volume is not exogenous. To formulate the causal structure \ndetermining traffic flow it is again helpful to consider the physics of the system \nand the units of measure for the variables. What determines the volume of traffic? \nTo have traffic, there must be. . . cars. No cars, no traffic. So the number of cars in \nthe region must be a determinant of traffic volume. Traffic volume is measured in \nvehicle-miles per day. Total traffic volume must therefore equal the number of \nvehicles in the region multiplied by the number of miles each vehicle travels per \nday. In turn, the number of miles each vehicle travels per day is the product of \nthe number of trips each vehicle makes per day and the length of each trip. Thus, \naveraging over the vehicle population, \nTraffic Volume = Vehicles * Average Trips per Day * Average Trip Length \nVehicle Milesmay = Vehicles * \nTripsDay \n* \nMilesnrip \nThe number of trips per day and the average trip length are not constant but de- \npend on the level of congestion. If traffic is light, people are more likely to take ad- \nditional and longer trips. When congestion is heavy, people will forego or defer \ntrips and make shorter trips, skipping that quick run to the video shop and buying \nwhat they need at the closest store rather going on to the mall. Likewise, the num- \nber of cars in the region is not constant. The number of vehicles in the region can \nbe thought of as the product of the population of the region and the number of cars \nper person: The more people in the region (and the more businesses), the more ve- \nhicles there will be. The number of vehicles per person or business in turn is not \nconstant but depends on the attractiveness of driving. The attractiveness of driving \ndepends on the level of congestion (Figure 5-34). \nAdding these relationships to the model closes three negative feedback loops, ","page_start":206,"page_end":206,"token_count":644,"section_type":"other","chapter_number":6,"chapter_title":"Stocks and Flows","chunk_index":249}
{"chunk_id":"7a1cf6499e525075","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"be thought of as the product of the population of the region and the number of cars \nper person: The more people in the region (and the more businesses), the more ve- \nhicles there will be. The number of vehicles per person or business in turn is not \nconstant but depends on the attractiveness of driving. The attractiveness of driving \ndepends on the level of congestion (Figure 5-34). \nAdding these relationships to the model closes three negative feedback loops, \nall of which act to increase congestion whenever new roads are built. Suppose new \nroads are built to relieve congestion. In the short run, travel time falls-the num- \nber of cars in the region hasn’t changed and people’s habits haven’t adjusted to the \nnew, shorter travel times. As people notice that they can now get around much \nfaster than before, they will take more Discretionary Trips (loop B2). They will ","page_start":206,"page_end":206,"token_count":191,"section_type":"other","chapter_number":6,"chapter_title":"Stocks and Flows","chunk_index":250}
{"chunk_id":"b1fe2c5216e2d999","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"182 \nPart I1 Tools for Systems Thinking \nFIGURE 5-34 Traffic volume depends on congestion, closing several negative loops that cause traffic \nto increase whenever new roads are built. \nCapacity \nExpansion \nConstruction \n+ \nPressure to \nReduce \nCongestion \nHighway \nCapacity \nDesired \n& \nAdequacy of \nTraffic \nAttractiveness \nPublic Transit \nDiscretionary \nTrips \nof Driving \n+ \nPublic \nTransit \nPopulation \nExtra Miles \nActivity of \nRegion \nand Economic \nAverage \nFare \nTake the \nBus? \nTrip Length + \n\\ \nTransit \nCars per /Ridership \n\\ \nCars in \nRegion \nPerson \n- \n+ \n+ \nalso travel Extra Miles (loop B3). Over time, seeing that driving is now much more \nattractive than other modes of transport such as the public transit system, some \npeople will give up the bus or subway and buy a car. The number of cars per per- \nson (and business) rises as people ask why they should Take the Bus? (loop B4). \nAll three of these loops compensate for any new road construction by increas- \ning traffic flow. But road construction stimulates other long-term feedbacks. The \npopulation of the region is not exogenous but is affected by the accessibility of the \noutlying districts. As the road network expands, as new freeways and ring roads \nlink the countryside with the center city, the size of the region within a reasonable \ntravel time grows. Of course, average travel time has a negative effect on the size \nof the accessible region: The greater the congestion, the smaller the radius accessi- \nble within, say, a 30-minute drive of the city (Figure 5-35). \nThe links to the population of the region close two more feedbacks. People be- \ngin to Move to the Suburbs (B5). As the population of the suburbs grows, the auto \npopulation rises as well. The roads begin to fill. Traffic volume grows further and \n","page_start":207,"page_end":207,"token_count":430,"section_type":"other","chapter_number":6,"chapter_title":"Stocks and Flows","chunk_index":251}
{"chunk_id":"df7fd8eed9bb4d1b","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"Chapter 5 Causal Loop Diagrams \n183 \nFIGURE 5-35 Reduced travel time and an expanded highway network increase the size of the region \naccessible from the center, which expands the population and leads to still more traffic. \nPressure to \nReduce \nCongestion \n+t‘ \nHighway \nCapacity \nCapacity \nExpansion \nDesired \nDiscretionary \n& \nAdequacy of \nSize of Regiion \nTraffic \nTrips \nPublic Transit \nwithin Desired \nof Driving \nTravel Time @ + \nPublic \nF’opulation \nExtra Miles \nTransit \nActivity of \nRegion \nand Economic \nFare \nTake the \nAverage \nBus? \nTrip Length + \nTransit \nCars per /Ridership \nCars in \nRegion \nPerson \n- \n+ \n+ \ntravel time rises until the resulting congestion makes the suburbs sufficiently unat- \ntractive to stop further inmigration and development. \nThe combined effect of the four negative feedbacks B2 through B5 is to com- \npensate strongly for any decrease in travel time caused by new roads. If new high- \nways were built and then all construction stopped, there would be an immediate \ndrop in travel time. But as people respond to their newfound ease of travel, more, \nlonger trips would be taken. More people would abandon the bus and buy cars to \ncommute to work. The population of the suburbs would grow. These adjustments \ncontinue until travel time rises enough to stop the expansion of the suburbs be- \ncause the commute required is too long. The delays in these negative loops could \ncause congestion to overshoot the desirable level. \nBut road construction doesn’t stop. As new highways Open the Hinterlands \n(loop Rl), it becomes possible to live in the countryside and commute to work in \nthe town or city. What was once remote farm country or woods now becomes a \n20 minute drive from the city, with its jobs, culture, and nightlife. Whole new \n","page_start":208,"page_end":208,"token_count":412,"section_type":"other","chapter_number":6,"chapter_title":"Stocks and Flows","chunk_index":252}
{"chunk_id":"8002ced8b5442d64","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"184 \nPart I1 Tools for Systems Thinking \ncommunities spring up, communities where the people have to drive not only to \nwork but also to the market, to school, to the homes of their friends and their chil- \ndren’s friends. The burgeoning population brings new development. Shops, strip \nmalls, and other businesses spring up, turning countryside to condo development, \npasture to parking lot. All the while, the number of cars on the road grows. After \nsome years, traffic congestion in these formerly quiet towns becomes a terrible \nproblem. Political pressure grows and still more roads are built. \nRoute 128, a ring road around Boston built in the 1950s to relieve congestion \nby diverting long-haul traffic around the center city, rapidly attracted local drivers \nand soon proved inadequate. To relieve the congestion it was widened, from four \nto eight, and in places, even more lanes. In stretches the breakdown lane was \nopened to traffic during rush hour (not a few hapless motorists have been killed \nwhen they had the temerity to use the breakdown lane for a breakdown). Traffic \nsoon filled these new lanes, and today during rush hour the cars crawl along \nbumper to bumper through long stretches of route 128. A second ring road, Inter- \nstate 495, was then built another 15 to 20 miles farther out. The expanded network \nmade even more countryside accessible, and another round of population growth \nand economic development began. This self-reinforcing process leads to more and \nmore new roads, pushing ever farther into the countryside, in a vain attempt to ease \ncongestion. The story is similar for other cities in the US, including the paradigm \ncase of congestion-Los Angeles-as well as London, Paris, Istanbul, Cairo, \nTokyo, Bangkok, and countless other cities around the world. \nThe model clearly shows the futility of attempts to reduce traffic congestion \nthrough road building. It may take some years, but, in an automotive version of \nParkinson’s Law, traffic always expands to fill the highways available for its travel. \nTraffic volume grows until congestion is just bad enough to deter people from tak- \ning that additional trip, from driving to work instead of riding public transit, or \nfrom moving just a little farther out into the ~uburbs.~ \nTraffic engineers call this re- \naction “road generated traffic.” Hansen’s (1995) econometric study of US metro- \npolitan areas showed that the elasticity of traffic volume with respect to highway \ncapacity was 0.9 after just 5 years, that is, a 10% increase in capacity led to a 9% \nincrease in traffic within 5 years. Many of the feedbacks identified in the model \noperate over even longer periods, fully negating the effect of road construction on \ncongestion. Some analysts even argue that by “adding capacity to a crowded [high- \nway] network you could actually slow things down” (Kay 1997, p. 15), a phenom- \nenon known as Braess’ Law after the operations research analyst who first coined ","page_start":209,"page_end":209,"token_count":656,"section_type":"other","chapter_number":6,"chapter_title":"Stocks and Flows","chunk_index":253}
{"chunk_id":"8cf38839226c81f0","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"increase in traffic within 5 years. Many of the feedbacks identified in the model \noperate over even longer periods, fully negating the effect of road construction on \ncongestion. Some analysts even argue that by “adding capacity to a crowded [high- \nway] network you could actually slow things down” (Kay 1997, p. 15), a phenom- \nenon known as Braess’ Law after the operations research analyst who first coined \nit. For example, the M25, London’s ring road, was designed to carry long distance \ntraffic around London. Instead, it is actually used primarily for short trips by local \nresidents and commuters. It soon became the busiest highway in Europe and has \nlong been known as ‘the longest parking lot in the world’, though commuters on \nthe Long Island Expressway, Paris’ Peripherique, and the San Diego Freeway \nmight disagree. In response, the M25 has been steadily widened, all to no avail. \nStudies typically find, as the London Times reported (10 November 1997), that \n5The analogy with Parhnson’s Law (“work expands to fill the time available for its comple- \ntion”) is more than casual: Parhnson’s Law arises through a negative feedback loop structure quite \nsimilar to that governing traffic congestion. See section 5.4. ","page_start":209,"page_end":209,"token_count":283,"section_type":"other","chapter_number":6,"chapter_title":"Stocks and Flows","chunk_index":254}
{"chunk_id":"73b549f060ec80bf","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"Chapter 5 Causal Loop Diagrams \n185 \nTraffic congestion on a widened section of the M25 is now greater than before the \nimprovement took place, a motoring survey suggests. The widening of a stretch of \nthe motorway at junction 15, west of London, was intended to curb congestion, but \nthe survey showed that jams on the stretch were now commonplace, although last \nyear traffic was generally free-flowing. \n5.6.3 The Mass Transit Death Spiral \nStandard economic analysis suggests that a decline in the attractiveness of a good \nor service should lead people to switch to substitutes. Why, then, as congestion \nbuilds up, don’t people turn to mass transit? Part of the answer is shown in Fig- \nure 5-36. \nAs lower travel time caused by new roads increases the attractiveness of driv- \ning, ridership and revenue of the public transit system fall. Costs don’t fall very \nmuch, since most of the costs are the fixed costs of providing service: the buses \nmust run whether they are full or empty. If the transit authority tries to close its \ndeficit by Cost Cutting (loop B6), service and quality erode. Routes are closed and \nthe frequency of service is cut. The relative attractiveness of driving rises and mass \ntransit ridership falls still more. The deficit widens, leading to still more cuts in the \npublic transit network as the self-reinforcing Route Expansion loop R2 operates as \na vicious cycle of decreasing ridership, greater cuts, and still fewer riders. \nRaising fares to balance the transit authority budget is little better: Higher fares \nincrease the relative attractiveness of driving, and more people abandon mass tran- \nsit for cars. Ridership falls, and fares must be raised again, Choking off Ridership \n(loop R3). Because mass transit systems have a high proportion of fixed costs, they \nare highly vulnerable to these self-reinforcing feedbacks. As road construction and \nauto use accelerated in America, particularly after the late 1940s, people aban- \ndoned trolleys, trains, and buses. These positive loops became a death spiral of \nhigher fares, reduced service, and declining quality until in many cities only the \npoorest people, those who cannot afford to move to the suburbs or own a car, are \nleft to ride the public transit system. Attempts to build up the mass transit network \nto offset the positive loops that erode ridership through Mass Transit Capacity Ex- \npansion (loop B7) often fight a losing battle due to their long delays and high costs. \nOne final positive feedback is worth adding: The adequacy of a public transit \nsystem depends not only on the scope of the network and the frequency of service \nbut also on the size and population density of the region. As the countryside is de- \nveloped, the locus of activity shifts away from the area served by existing mass \ntransit. As population density falls, fewer and fewer people live near a bus or sub- \nway route. Public transit becomes less and less useful because You Can’t Get There ","page_start":210,"page_end":210,"token_count":648,"section_type":"other","chapter_number":6,"chapter_title":"Stocks and Flows","chunk_index":255}
{"chunk_id":"4f211f4e2c5d7c52","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"system depends not only on the scope of the network and the frequency of service \nbut also on the size and population density of the region. As the countryside is de- \nveloped, the locus of activity shifts away from the area served by existing mass \ntransit. As population density falls, fewer and fewer people live near a bus or sub- \nway route. Public transit becomes less and less useful because You Can’t Get There \non the Bus, leading to still more driving and still lower mass transit ridership, in \nanother vicious cycle, loop R4 (Figure 5-37). The suburbs grow and the adequacy \nof public transit falls much faster than mass transit capacity can be added. \nThe model above is still incomplete (as all models always are). One could add \nmany more feedbacks. For example, the spread of population into the less densely \npopulated suburbs increases the average length of trips, forming additional chan- \nnels by which congestion rises to offset any gains caused by new highways. The \nmodel does not explore other side effects of the automobile’s rise to dominance, ","page_start":210,"page_end":210,"token_count":226,"section_type":"other","chapter_number":6,"chapter_title":"Stocks and Flows","chunk_index":256}
{"chunk_id":"0fea92b06c188c5c","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"FIGURE 5-36 The high fixed costs of mass transit lead to a death spiral. \nAs mass transit ridership falls, service must be cut and fares raised, further driving people to drive. \nConstruction \n\\ \nPressure to \nReduce \nCongestion \nH ig h way \nCapacity \nCapacity \nExpansion \nTravel Time \n2- \nAdequacy of \nTraffic \nAttractiveness \nVolume \nPublic \nPopulation \nExtra Miles \nChoke Off \nTransit \ncost \nCutting \nRidership \n+ \nand Economic \nActivity of \nRegion \nAverage \nBus? \nTrip Length + \nFare \nIncrease \nTransit \nTransit \n+ \nDeficit \n+ \nRegion \nCars per /Ridership \nPublic \nCars in \n+ \n+ \nPerson \n- \nRevenue \n","page_start":211,"page_end":211,"token_count":169,"section_type":"other","chapter_number":6,"chapter_title":"Stocks and Flows","chunk_index":257}
{"chunk_id":"7b54453fd8e5c0fb","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"FGURE 5-37 You can't get there on the bus. \nAs the size of the populated region expands, the adequacy of public transit declines. The result is more driving, more congestion, and \nstill more road construction rather than an expansion of the public transit network. \nRoad \nConstruction \n\\ \nPressure to \nReduce \n\\ \nCongestion \n+r' \nHigh way \nCapacity \nCapacity \n/ \nExpansion \nHinterlands \nOpenthe \n~ \nE <- \nTravel Time (7) \nMT Capacity \nExpansion \nAdequacy of \nwithin \nSize \n+ / G ? s c r e t i o n a r y  \nof Desired \nRegion \nTraffic \nTrips \nAttractiveness \nPublic Transit 7 \nPublic \nand Economic \nIncrease \nTransit \nCan't Get There \n","page_start":212,"page_end":212,"token_count":173,"section_type":"other","chapter_number":6,"chapter_title":"Stocks and Flows","chunk_index":258}
{"chunk_id":"7aaf1aecab85c8e8","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"188 \nPart I1 Tools for Systems Thinking \nincluding the deaths, injuries and costs of accidents, the health effects of smog and \nozone production, greenhouse gas generation, the solid waste problem posed by \nthe discard of millions of vehicles each year (see chapter 6), and the dependence of \nthe highly automotive nations on insecure supplies of imported oil. What other \nfeedbacks and side effects do you see? \n5.6.4 Policy Analysis: The Impact of Technology \nDespite its limitations and omissions, the model provides a rich explanation for the \npersistent failure of road-building programs to alleviate traffic congestion. You can \nnow use the model to assess the likely effect of other policies. \nIn the 1970s and 1980s, a popular solution was HOV lanes (high-occupancy \nvehicle, or carpool lanes). These lanes are restricted to cars with at least two occu- \npants (sometimes only during rush hour). The result? To the extent drivers joined \ncarpools, the number of trips per day fell, reducing traffic volume slightly. The re- \nsulting reduction in congestion, however, simply encouraged others to take to the \nroads instead of mass transit, to take additional trips they might otherwise have \nforegone, and to leave for work a little later. The total volume of traffic during rush \nhours didn’t change and more people were now on the highways than before, fur- \nther eroding mass transit ridership. And some enterprising but immoral motorists \ntook to riding with inflatable dummies in the passenger seat to fool the police and \nillegally take advantage of the HOV lane. \nDespite the persistent failure of road building and innovations such as HOV \nlanes, many transportation planners continue to pin their hopes on technological \nsolutions to the congestion problem. The latest of these is so-called intelligent \nvehicle-highway systems. Many clever technologies are under development, from \nsensors to detect the distance to the car ahead and automatically adjust your car’s \nspeed, to transponders or magnets embedded in the road surface to automatically \nsteer your car. Already sensors embedded in some highways transmit real time traf- \nfic data to cars equipped with special receivers. Technologists look forward to the \nday when the internet, GPS, and real time vehicle controls will allow your car to \npick the optimal route to your destination and drive you there while you relax or \nread a book. Some of these technologies are designed to increase highway safety. \nMany are motivated by the need to increase highway capacity in cities where \nbuilding new roads and adding new lanes is no longer possible: under computer \ncontrol, the technologists promise, cars could zip safely along at 70 miles per hour \nonly inches apart, greatly expanding the capacity of existing highways. \nThe model shows the futility of these hopes. There is no technological solution \nto the congestion problem. The more effectively these technologies increase high- \nway capacity, the more trips will be taken, the more people will buy cars, the less \nattractive public transit will be, and the more countryside will be developed into ","page_start":213,"page_end":213,"token_count":643,"section_type":"other","chapter_number":6,"chapter_title":"Stocks and Flows","chunk_index":259}
{"chunk_id":"35384e74e1bc1b23","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"control, the technologists promise, cars could zip safely along at 70 miles per hour \nonly inches apart, greatly expanding the capacity of existing highways. \nThe model shows the futility of these hopes. There is no technological solution \nto the congestion problem. The more effectively these technologies increase high- \nway capacity, the more trips will be taken, the more people will buy cars, the less \nattractive public transit will be, and the more countryside will be developed into \nbedroom communities for commuters. The volume of traffic will swiftly rise to ab- \nsorb all the new capacity technology can yield. We might zip along the freeway at \nseventy, but we’ll be stuck in much longer lines at the entrance ramp and on sec- \nondary routes. On the roadways of the future we may ride more safely and more \ncomfortably, but we won’t ride more swiftly. ","page_start":213,"page_end":213,"token_count":186,"section_type":"other","chapter_number":6,"chapter_title":"Stocks and Flows","chunk_index":260}
{"chunk_id":"0c8e7697240dac64","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"Chapter 5 \nCausal Loop Diagrams \n189 \nEconomists generally suggest the solution is to charge tolls that increase as \ncongestion rises (Downs 1992). While some regions are experimenting with time- \nof-day tolls and congestion-based pricing using real time sensing equipment, there \nis considerable political resistance to the notion of paying for the freeway, and \nsome concern over the regressive impact of tolls. Worse, drivers tend to switch to \nsecondary roads and city streets where tolls are infeasible. \nSome nations have come to understand these dynamics and are moving to \nreduce traffic and the attendant pollution, accidents, and destruction of open land \nit causes by increasing travel times. In September 1997 Sweden’s parliament \nadopted “Vision Zero”, a policy aimed at eliminating all traffic fatalities by per- \nmitting towns to reduce speed limits to 30 kilometers per hour and install speed \nbumps and other flow restricting devices. The model suggests these policies will, \nin addition to saving lives, encourage people to use other modes such as bus, train, \nand bicycle, thus reducing the pressure for road building and the growth in traffic. \n5.6.5 \nCompensating Feedback: \nThe Source of Policy Resistance \nThe feedbacks affecting traffic clearly show that attempts to control congestion \nthrough road building are vain. Any reduction in congestion leads to more trips and \nmore cars, swiftly building congestion back up. What road construction actually \ncontrols is the size of the metropolitan area and the number of cars on the road. \nRoad construction causes the dramatic expansion of the urbanized and suburban- \nized area, the growth of strip malls and parking lots, and the decline of farm, for- \nest, and field. \nThe causal structure of the traffic problem illustrates how policy resistance \narises in a wide range of complex systems. Road-building programs are typical of \npolicies directed at the symptom of difficulty. Policies directed at alleviating the \nsymptoms of a problem usually fail because they trigger compensating feedbacks, \nfeedbacks that undercut the intended effects of the policy. The compensating loops \narise because other actors, with their own goals, respond to changes in the state of \nthe system in such a way as to offset the intended effects of the policy. While each \nindividual loop may be weak, the combined effect can often compensate com- \npletely for any policy directed at a symptom of a problem. Directing policies at \nthe symptoms of a problem is like trying to squeeze a balloon to make it smaller. \nWhenever you squeeze, the air pressure increases, expanding some other part of \nthe balloon so its volume remains about the same. \nWhy then do so many policies focus on alleviating the symptoms of difficulty? \nWe focus on symptoms because so much of our experience is with simple systems \nin which cause and effect are closely related in time and space, in which symptom \nand cause are obvious. Most of our experience is with systems in which there is a \nsingle, dominant negative feedback, as when you reach out to grasp an object by \nassessing the gap between the position of the object and your hand. We then ex- \ntrapolate these everyday experiences with simple systems into the management of \ncomplex systems. But, as Jay Forrester (1969, pp. 9-10) notes \n","page_start":214,"page_end":214,"token_count":694,"section_type":"other","chapter_number":6,"chapter_title":"Stocks and Flows","chunk_index":261}
{"chunk_id":"59c927147fff0202","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"190 \nPart I1 Tools for Systems Thinking \nIn the crrmplex system the cause of a difficulty may lie far back in time from \nthe symptoms, or in a completely different and remote part of the system. In fact, \ncauses are usually found, not in prior events, but in the structure and policies of the \nsystem . . . Conditioned by our training in simple systems, we apply the same intu- \nition to complex systems and are led into error. As a result we treat symptoms, not \ncauses. The outcome lies between ineffective and detrimental . . . If the attempted \nsolution intensifies the problem, wrongly attributed to another source, the organiza- \ntion likely will redouble its “corrective” action, producing more difficulty and pres- \nsure for still more remedial action. A destructive spiral becomes established. \nIdentifying the Feedback Structure of \nPolicy Resistance \n1. Consider the failed Romanian population policy described in chapter 1. \nDevelop a causal loop diagram explaining the failure of the government’s \nefforts to increase the birth rate. \n2. Table 1-1 lists a number of common examples of policy resistance in social, \nbusiness, and economic systems. Develop simple causal diagrams for each. \nUse your diagrams to explain why each policy failed. \n5.7 \nSUMMARY \nCausal diagrams are a powerful tool to map the feedback structure of complex sys- \ntems. Causal diagrams can be helpful to you in the early phases of a project, when \nyou need to work with the client team to elicit and capture their mental models. \nThey are helpful in presenting the results of your modeling work in a nontechnical \nfashion. To be effective, you should follow the rules for causal diagrams, including \nselection of variable names, layout, and assignment of link and loop polarities. It \nis best to build up diagrams in steps: resist the urge to create a single, comprehen- \nsive diagram. As in learning to read music, practice is everything. Develop your \nskills in mapping the feedback structure of systems by sketching causal diagrams \nto capture the feedbacks you recognize as you read the newspaper or the great \nworks of literature. \n","page_start":215,"page_end":215,"token_count":459,"section_type":"other","chapter_number":6,"chapter_title":"Stocks and Flows","chunk_index":262}
{"chunk_id":"f53a9bc2e097827f","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"6 \nStocks and Flows \nI’m very good at integral and differential calculus, \nI know the scientific names of beings animalculous; \nIn short, in matters vegetable, animal, and mineral, \nI am the very model of a modem Major-General. \n-W. \nS. Gilbert, The Pirates of Penzance, Act 1. \nThis chapter introduces the concept of stocks and flows, a central idea in dynam- \nics. It presents the conceptual and mathematical definitions of stocks and flows, the \ndiagramming tools for mapping networks of stocks and flows, and case studies of \nthe use of stocks and flows in modeling projects including automobile recycling \nand the construction of pulp and paper mills. Developing facility in identifying, \nmapping, and interpreting the stock and flow networks of systems is a critical skill \nfor any modern systems modeler. \n6.1 STOCKS, FLOWS, AND ACCUMULATION \nCausal loop diagrams are wonderfully useful in many situations. They are well \nsuited to represent interdependencies and feedback processes. They are used ef- \nfectively at the start of a modeling project to capture mental models-both those \nof a client group and your own. They are also used to communicate the results of a \ncompleted modeling effort. \nHowever, causal loop diagrams suffer from a number of limitations and can \neasily be abused. Some of these are discussed in chapter 5. One of the most im- \nportant limitations of causal diagrams is their inability to capture the stock and \nflow structure of systems. Stocks and flows, along with feedback, are the two cen- \ntral concepts of dynamic systems theory. \n191 \n","page_start":216,"page_end":216,"token_count":345,"section_type":"other","chapter_number":6,"chapter_title":"Stocks and Flows","chunk_index":263}
{"chunk_id":"4f2558905c53d895","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"192 \nPart I1 Tools for Systems Thinking \nStocks are accumulations. They characterize the state of the system and gener- \nate the information upon which decisions and actions are based. Stocks give sys- \ntems inertia and provide them with memory. Stocks create delays by accumulating \nthe difference between the inflow to a process and its outflow. By decoupling rates \nof flow, stocks are the source of disequilibrium dynamics in systems. \nStocks and flows are familiar to all of us. The inventory of a manufacturing \nfirm is the stock of product in its warehouses. The number of people employed by \na business is a stock. The balance in your checking account is a stock. Stocks are \naltered by inflows and outflows. A firm’s inventory is increased by the flow of pro- \nduction and decreased by the flow of shipments (and possibly other outflows due \nto spoilage or shrinkage). The workforce increases via the hiring rate and decreases \nvia the rate of quits, layoffs, and retirements. Your bank balance increases with de- \nposits and decreases as you spend. Yet despite everyday experience of stocks and \nflows, all too often people fail to distinguish clearly between them. Is the US fed- \neral deficit a stock or a flow? Many people, including politicians responsible for \nfiscal policy, are unclear. Failure to understand the difference between stocks and \nflows often leads to underestimation of time delays, a short-term focus, and policy \nresistance. \n6.1.1 \nDiagramming Notation for Stocks and Flows \nSystem dynamics uses a particular diagramming notation for stocks and flows \n(Figure 6- 1 1. \n0 \nStocks are represented by rectangles (suggesting a container holding the \ncontents of the stock). \nInflows are represented by a pipe (arrow) pointing into (adding to) the \nstock. \nOutflows are represented by pipes pointing out of (subtracting from) \nthe stock. \nValves control the flows. \nClouds represent the sources and sinks for the flows. A source represents \nthe stock from which a flow originating outside the boundary of the model \narises; sinks represent the stocks into which flows leaving the model \nboundary drain. Sources and sinks are assumed to have infinite capacity and \ncan never constrain the flows they support. \nThe structure of all stock and flow structures is composed of these elements. \nAs the example in the figure shows, a firm’s inventory is a stock that accumulates \nthe inflow of production and is reduced by the outflow of shipments. These are the \nonly flows considered in the model: unless explicitly shown, other possible flows \ninto or out of the stock, such as inventory shnnkage or spoilage, are assumed to be \nzero. The clouds indicate that the stock of raw materials never starves the produc- \ntion rate and the stock of product shipped to customers never grows so high that it \nblocks the shipment rate. \n","page_start":217,"page_end":217,"token_count":619,"section_type":"other","chapter_number":6,"chapter_title":"Stocks and Flows","chunk_index":264}
{"chunk_id":"5d4be7125b741c0d","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"Chapter 6 Stocks and Flows \nL1 \nFlow of material \ninto stock \n193 \n~ \nL1 \nc3 \nStock \noutofstock \nFIGURE 6-1 \nStock and flow \ndiagramming \nnotation \nv \nL1 \nc3 \n+. \nGeneral Structure: \n~ \nInventory \nL1 \nmc3 \nv \n\\;7 \nc3 \nY 4 Stock \nOutflow \n- \nInflow \nKey: \nI \nStock \nFlow \nX \nc3 \nValve (Flow Regulator) \nSource or Sink \n(Stocks outside model boundary) \nt \\ \nf \n/ \n/ \n\\- Nameof , \n\\ \nflow \nExample: \n6.1.2 \nMathematical Representation of \nStocks and Flows \nThe stock and flow diagramming conventions (originated by Forrester 1961) were \nbased on a hydraulic metaphor-the flow of water into and out of reservoirs. \nIndeed, it is helpful to think of stocks as bathtubs of water. The quantity of water \n","page_start":218,"page_end":218,"token_count":228,"section_type":"other","chapter_number":6,"chapter_title":"Stocks and Flows","chunk_index":265}
{"chunk_id":"43af50329ec4279a","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"194 \nFIGURE 6-2 \nFour equivalent \nrepresentations \nof stock and \nflow structure \nEach \nrepresentation \ncontains \nprecisely the \nsame \ninformation. \nPart I1 Tools for Systems Thinking \nin your bathtub at any time is the accumulation of the water flowing in through the \ntap less the water flowing out through the drain (assume no splashing or evapora- \ntion). In exactly the same way, the quantity of material in any stock is the accumu- \nlation of the flows of material in less the flows of material out. Despite the prosaic \nmetaphor the stock and flow diagram has a precise and unambiguous mathemati- \ncal meaning. Stocks accumulate or integrate their flows; the net flow into the stock \nis the rate of change of the stock. Hence the structure represented in Figure 6-1 \nabove corresponds exactly to the following integral equation: \nStock(t) = \n[Inflow(s) - Outflow(s)]ds + Stock(t,) \n(6-1) \nJI,' \nwhere Inflow(s) represents the value of the inflow at any time s between the initial \ntime to and the current time t. Equivalently, the net rate of change of any stock, its \nderivative, is the inflow less the outflow, defining the differential equation \nd(Stock)/dt = Inflow(t) - Outflow(t). \nIn general, the flows will be functions of the stock and other state variables and pa- \nrameters. Figure 6-2 shows four equivalent representations of the general stock and \nflow structure. The bathtub and stock and flow diagrams may appear to be less rig- \norous than the integral or differential equation representations, but they are pre- \ncisely equivalent and contain exactly the same information. From any system of \nintegral or differential equations we can construct the corresponding stock and \nflow map; from any stock and flow map we can generate the corresponding inte- \ngral or differential equation system. \nHydraulic Metaphor: \nf \nStock and Flow Diagram: \nIntegral Equation: \nt \nStock(t) = 1 [Inflow(s) - Outflow(s)]ds + Stock (to) \nto \nDifferential Equation: \nd(Stock)/dt = Net Change in Stock = Inflow(t) - Outflow(t) \n","page_start":219,"page_end":219,"token_count":489,"section_type":"other","chapter_number":6,"chapter_title":"Stocks and Flows","chunk_index":266}
{"chunk_id":"faf1c6491a8b2118","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"Chapter 6 Stocks and Flows \n195 \nProcess Point: Notation for Accumulation \nThe traditional notation used in calculus and shown in Figure 6-2 is often con- \nfusing to many people. In this book, I will generally represent the process of accu- \nmulation with the INTEGRAL() function: \nStock = INTEGRAL(1nflow - Outflow, Stockh) \n(6-3) \nThe INTEGRAL() function is exactly equivalent to equation (6-1) and represents \nthe concept that the stock accumulates its inflows less its outflows, beginning with \nan initial value of Stockh. \n6.1.3 \nThe Contribution of Stocks to Dynamics \nStocks are critical in generating the dynamics of systems for the following reasons \n(Mass 1980): \n1. Stocks characterize the state of the system and provide the basis for \nactions. \nThe stocks in a system tell decision makers where they are, providing them \nwith the information needed to act. A pilot must know the state of the aircraft \nincluding position, heading, altitude, and fuel level. Without knowledge of \nthese states, the pilot is flying blind and won’t survive long. Likewise, a \nfirm can’t set its production schedule appropriately without knowledge of \nthe order backlog, the stock of inventory, the parts stocks, the labor force, \nand other stocks. A balance sheet characterizes the financial health of a \ncorporation by reporting the values of stocks such as cash, inventory, \npayables, and debt. Information about these stocks affects decisions such as \nissuing new debt, paying dividends, and controlling expenses via layoffs. \n2. Stocks provide systems with inertia and memory. \nStocks accumulate past events. The content of a stock can only change \nthrough an inflow or outflow. Without changes in these flows, the past \naccumulation into the stock persists. The stock of lead in the paint of \nAmerica’s inner city housing remains high today even though lead paint was \nbanned in 1978. Once the stock of lead paint accumulated, the only way to \neliminate it is through expensive deleading or the eventual demolition of the \nhousing itself. Even then the lead remains, either safely sequestered or more \nlikely dispersed into the environment as dust, chips, or lead leaching from \nlandfills into water supplies. Likewise, the stock of ozone-destroying \nchlorine generated by CFCs will remain in the atmosphere for decades even \nafter the production rate of CFCs falls to zero because the rate at which \nchlorine is scrubbed from the stratosphere is very low. Stocks don’t have to \nbe tangible. Memories and beliefs are stocks that characterize your mental \nstates. Your beliefs persist over time, generating inertia and continuity in \nyour attitudes and behavior. If you have a bad experience on an airline and \nnever fly on that carrier again, your belief about the low quality of their \nservice remains even if they’ve improved. \n","page_start":220,"page_end":220,"token_count":625,"section_type":"other","chapter_number":6,"chapter_title":"Stocks and Flows","chunk_index":267}
{"chunk_id":"a2f99d1d2df8b183","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"196 \nPart I1 Tools for Systems Thinking \n3. Stocks are the source of delays. \nAll delays involve stocks. A delay is a process whose output lags behind its \ninput. The difference between the input and output accumulates in a stock of \nmaterial in process. There is a lag between the time you mail a letter and the \ntime it is received. During this interval, the letter resides in a stock of letters \nin transit. Even email accumulates in stocks of undelivered packets and \nmessages residing in the memory of various computers between the sender \nand receiver. There is a lag of several years between the decision to build \nnew office buildings and the time they are ready for occupancy. During this \ninterval there is a supply line of buildings under development, including a \nstock of proposed projects and a stock of buildings under construction. \nBy definition, when the input to a delay changes, the output lags behind \nand continues at the old rate for some time. During such adjustments, the \nstock accumulating the difference between input and output changes. If you \nmail wedding invitations to 1000 of your closest friends all at once, while the \nrate at which other mail is deposited remains constant, the stock of letters in \ntransit jumps by 1000 and remains at the new level as the letters make their \nway to their destinations. Only as the invitations begin to arrive does the \nstock of letters in transit start to fall. The delivery rate exceeds the mailing \nrate, shrinking the stock of mail in transit, until all the invitations have been \ndelivered, at which point the delivery rate once again equals the rate at which \nmail is deposited and the stock of letters in transit returns to its original level. \nPerception delays also involve stocks though these stocks do not involve \nany material flows. For example, the belief of managers in a company’s \nTaiwan headquarters about the shipment rate from their Silicon Valley plant \nlags behind the true shipment rate due to measurement and reporting delays. \nMeasurement of a rate such as shipments always involves a stock. Due to \nunpredictable variations in customer orders, product availability, and \ntransportation, shipments can vary significantly from hour to hour, day to \nday, or over even longer periods. Shipments must be accumulated for some \nperiod of time such as a day, week, or month to provide a meaningful \nmeasurement of the rate. If shipments are highly volatile, the firm will have \nto accumulate them over longer intervals to filter out the short-term noise and \nprovide a meaningful average managers can use to make decisions. In \naddition there are reporting delays involving a stock of shipment information \nwaiting to be uploaded to and downloaded from the firm’s computer system. \nThere may be further delays in the adjustment of the executives’ beliefs even \nafter they see the latest data. Chapter 11 describes the structure and dynamics \nof delays in detail. \n4. Stocks decouple rates of flow and create disequilibrium dynamics. \nStocks absorb the differences between inflows and outflows, thus permitting \nthe inflows and outflows to a process to differ. In equilibrium, the total \ninflow to a stock equals its total outflow so the level of the stock is \nunchanging. However, inflows and outflows usually differ because they are \noften governed by different decision processes. Disequilibrium is the rule \nrather than the exception. \n","page_start":221,"page_end":221,"token_count":700,"section_type":"other","chapter_number":6,"chapter_title":"Stocks and Flows","chunk_index":268}
{"chunk_id":"a53500569fdb3c36","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"Chapter 6 Stocks and Flows \n197 \nThe production of grain depends on the yearly cycle of planting and \nharvest, along with unpredictable natural variations in weather, pest \npopulations, and so on. Consumption of grain depends on how many mouths \nthere are to feed. The difference between grain production and consumption \nrates accumulates in grain stocks, stored throughout the distribution system \nfrom field to grain elevator to processor inventories to market to kitchen \ncupboard. Without a stock of grain to buffer the differences between \nproduction and consumption, consumption would necessarily equal \nproduction at all times and people would starve between harvests. Thus \nJoseph advised Pharaoh to stockpile grain during the 7 good years in \nanticipation of the 7 lean years during which consumption would exceed \nharvests. While on average the production of grain balances consumption \n(and losses) as farmers respond to market prices and inventory conditions \nin determining how much to plant, and as consumers adjust consumption \nin response to prices and availability, production and consumption are \nrarely equal. \nmakers, involve different resources, and are subject to different random \nshocks, a buffer or stock between them must exist, accumulating the \ndifference. As these stocks vary, information about the size of the buffer \nwill feed back in various ways to influence the inflows and outflows. Often, \nbut not always, these feedbacks will operate to bring the stock into balance. \nWhether and how equilibrium is achieved cannot be assumed but is an \nemergent property of the whole system as its many feedback loops interact \nsimultaneously. Understanding the nature and stability of these dynamics \nis often the purpose of a system dynamics model. \nWhenever two coupled activities are controlled by different decision \n6.2 \nIdentifying Stocks and Flows \nThe distinction between stocks and flows is recognized in many disciplines. \nTable 6-1 shows some common terms used to distinguish between stocks and \nflows in various fields. In mathematics, system dynamics, control theory, and re- \nlated engineering disciplines, stocks are also known as integrals or state variables. \nFlows are also known as rates or derivatives. Chemists speak of reactants and \nreaction products (the stocks) and reaction rates (the flows). In manufacturing \nsettings, stocks and flows are also called bufSers and throughput. In economics, \nstocks are also known as levels and flows as rates. For example, the capital stock \nof an economy is its level of wealth (measured in, say, dollars) while the GDP is \nthe aggregate rate of national output (measured in $/year). In accounting, balance \nsheet items are stocks, such as cash, the book value of inventory, long-term debt, \nand shareholder equity (all measured in, e.g., dollars). Items appearing on the in- \ncome statement or flow of funds report are flows which alter the corresponding \nstocks on the balance sheet, such as net receipts, the cost of goods sold, long-term \nborrowing, and the change in retained earnings. These flows are measured in \n$/year. Physiological models often lump different stocks into a small number of \ncompartments or boxes connected by diffusion rates (the flows). For example, the \nstock of glucose in a human can be represented by a three compartment model: \n","page_start":222,"page_end":222,"token_count":683,"section_type":"other","chapter_number":6,"chapter_title":"Stocks and Flows","chunk_index":269}
{"chunk_id":"14bdfb7677443fda","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"198 \nPart I1 Tools for Systems Thinking \nField \nStocks \nFlows \nTABLE 6-1 \nTerminology used \nto distinguish \nMathematics, physics \nbetween stocks \nand engineering \nand flows in \ndifferent \ndisciplines \nChemistry \nManufacturing \nEconomics \nAccounting \nBiology, physiology \nMedicine, \nepidemiology \nIntegrals, states, state \nvariables, stocks \nReactants and reaction \nproducts \nBuffers, inventories \nLevels \nStocks, balance sheet \nitems \nCompartments \nPrevalence, reservoirs \nDerivatives, rates of \nchange, flows \nReaction rates \nThroughput \nRates \nFlows, cash flow or \nincome statement \nitems \nDiffusion rates, flows \nIncidence, infection, \nmorbidity and \nmortality rates \nglucose in the digestive system, glucose in the bloodstream, and glucose in the in- \ntracellular matrix. In epidemiology, prevalence measures the number or stock of \npeople who have a particular condition at any given time, while incidence is the \nrate at which people come down with the disease or condition. In December 1998 \nthe prevalence of HIV/AIDS worldwide was estimated by the United Nations \nAIDS program to be 33.4 million and the incidence of HIV infection was estimated \nto be 5.8 million/year. That is, a total of 33.4 million people were estimated to be \nHIV-positive or to have AIDS; the rate of addition to this stock was 5.8 million \npeople per year (16,000 new infections per day). The net change in the population \nof HIV-positive individuals was estimated to be 3.3 million people per year due to \nthe death rate from AIDS, estimated to be 2.5 million people per year in 1998. \nHow can you tell which concepts are stocks and which are flows? Stocks are \nquantities of material or other accumulations. They are the states of the system. \nThe flows are the rates at which these system states change. Imagine a river flow- \ning into a reservoir. The quantity of water in the reservoir is a stock (measured in, \nsay, cubic meters). If you drew an imaginary line across the point where the river \nenters the reservoir, the flow is the rate at which water passes the line-the rate of \nflow in cubic meters per second. \n6.2.1 \nUnits of Measure in Stock and Flow Networks \nThe units of measure can help you distinguish stocks from flows. Stocks are \nusually a quantity such as widgets of inventory, people employed, or Yen in an \naccount. The associated flows must be measured in the same units per time period, \nfor example, the rate at which widgets are added per week to inventory, the hiring \nrate in people per month, or the rate of expenditure from an account in %/hour. Note \nthat the choice of time period is arbitrary. You are free to select any measurement \nsystem you like as long as you remain consistent. You can measure the flow of pro- \nduction into inventory as widgets per week, widgets per day, or widgets per hour. \nThe statement “The current rate of production is 1200 widgets per day” is exactly \n","page_start":223,"page_end":223,"token_count":682,"section_type":"other","chapter_number":6,"chapter_title":"Stocks and Flows","chunk_index":270}
{"chunk_id":"c20e5c9de78b5733","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"Chapter 6 Stocks and Flows \n199 \nequivalent to the statement that production is proceeding at a rate of 8400 widgets \nper week, 50 widgets per hour, 5/6 widgets per minute, or even 43,800,000 widgets \nper century. All are statements about how many widgets are being produced right \nnow-at this instant. Whether the cumulative number of widgets produced in any \ngiven interval such as a day, week, or century is equal to 1200,8400, or 43,800,000 \ndepends on whether the current rate stays constant over that interval (or averages \nout to the current rate). Most likely it won’t. \n6.2.2 \nThe Snapshot Test \nStocks characterize the state of the system. To identify key stocks in a system, \nimagine freezing the scene with a snapshot. Stocks would be those things you \ncould count or measure in the picture, including psychological states and other in- \ntangible variables. You can estimate the stock of water in a reservoir from a set \nof satellite images and topographic data, but you cannot determine whether the \nwater level is rising or falling. Your bank statement tells you how much money is \nin your account but not the rate at which you are spending it now. If time stopped, \nit would be possible to determine how much inventory a company has or the price \nof materials but not the net rate of change in inventory or the rate of inflation in \nmaterials prices. The snapshot test applies also to less tangible stocks. The plant \nmanager’s expectation of the customer order rate at any instant or perception of the \nsize of inventory are stocks, even though they are mental and not physical stocks. \nA snapshot of people’s mental states, however, does not indicate how fast they are \nrevising their beliefs. \nFigure 6-3 lists some common concepts and identifies them as stocks or flows, \nshowing their stock and flow structure and units of measure. Population, Employ- \nees, and Debt are straightforward. Why is the price of a product a stock? Prices \ncharacterize the state of the system, in this case how much you must pay per unit. \nA price posted on an item remains in effect until it is changed, just as the number \nof widgets in an inventory remains constant until it is changed by a flow of pro- \nduction or shipments. Even the bids and offers called out in a trading pit at a fi- \nnancial market are stocks, albeit short-lived ones: a bid or offer remains in effect \nuntil the trader withdraws or alters it by crying out another. \nWhy is the expected customer order rate for a product a stock? Clearly, the ac- \ntual customer order rate is a flow. The flow of customer orders accumulates in a \nbacklog or stock of unfilled orders until the product can be delivered. However, a \nmanager’s belief about the rate at which customer orders are booked is a stock-it \nis a state of the system, in this case a mental state. No one knows the true current \nor future order rate. The manager’s belief about orders can, and usually does, dif- ","page_start":224,"page_end":224,"token_count":659,"section_type":"other","chapter_number":6,"chapter_title":"Stocks and Flows","chunk_index":271}
{"chunk_id":"053d6622ba3a3001","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"tual customer order rate is a flow. The flow of customer orders accumulates in a \nbacklog or stock of unfilled orders until the product can be delivered. However, a \nmanager’s belief about the rate at which customer orders are booked is a stock-it \nis a state of the system, in this case a mental state. No one knows the true current \nor future order rate. The manager’s belief about orders can, and usually does, dif- \nfer from the true order rate (the belief can be wrong). Managers’ beliefs about the \ncustomer order rate will tend to remain the same until they become aware of new \ninformation and update their beliefs. The Change in Expected Order Rate is the \nrate at which the belief is updated. Note the units of measure for the expected or- \nder rate. Like the actual order rate, the expected order rate is measured in widgets \nper time period (say weeks). The units of measure for the rate at which the belief \nabout customer orders is updated are (widgets1week)lweek. ","page_start":224,"page_end":224,"token_count":217,"section_type":"other","chapter_number":6,"chapter_title":"Stocks and Flows","chunk_index":272}
{"chunk_id":"206e8c00ab711132","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"200 \nv \nY \nGs \nPart I1 Tools for Systems Thinking \nEmployees \nv \na \n(people) \nFIGURE 6-3 \nExamples of \nstocks and flows \nwith their units of \nmeasure \nThe choice of time \nunit for the flows \n(e.g., days, weeks, \nyears) is arbitrary \nbut must be \nconsistent within a \nsingle model. \nDebt \n($1 \nv \nPopulation \nv \nL1 \nfoeoole) \nL1 \nv \nL3 \nI, \n8 \nI \nBirth Rate \n' \nDeath Rate \nv \nL1 \nb \n(people/yea r) \n(people/yea r) \nExpected \nCustomer \nOrders \nRetirement Rate \n(people/year) \n(people/yea r) \nLayoff Rate \n(people/yea r) \n(people/year) - \nPrice \nI \nu \n($/unit) \nRate of Price \nChange \n($/uniWyea r) \nOrder Rate \n(widge WweeWweek) \nNote that the rate of price change and the change in the expected order rate can \nbe positive or negative (prices and demand forecasts can rise or fall). Any flow into \nor out of a stock can be either positive or negative. The direction of the arrow \n(pointing into or out of a stock) defines the sign convention for the flow. An inflow \nadds to the stock when the flow is positive; if the flow is negative it subtracts from \nthe stock. When the outflow is positive, the flow subtracts from the stock. \n","page_start":225,"page_end":225,"token_count":341,"section_type":"other","chapter_number":6,"chapter_title":"Stocks and Flows","chunk_index":273}
{"chunk_id":"caf6aa7f5584269a","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"Chapter 6 Stocks and Flows \n201 \n6.2.3 \nConservation of Material in \nStock and Flow Networks \nA major strength of the stock and flow representation is the clear distinction be- \ntween the physical flows through the stock and flow network and the information \nfeedbacks that couple the stocks to the flows and close the loops in the system. The \ncontents of the stock and flow networks are consewed in the sense that items en- \ntering a stock remain there until they flow out. When an item flows from one stock \nto another the first stock loses precisely as much as the second gains. Consider the \nstock and flow structure representing the accounts receivable of a firm (Figure \n6-4). The stock of receivables is increased by billings and decreased by payments \nreceived and by defaults. The flow of billings is conserved in the sense that once a \ncustomer is billed, the invoice remains in the stock of receivables until it explicitly \nflows out when the receivables department records the customer’s payment or ac- \nknowledges that the customer has defaulted and writes off the account. In contrast, \ninformation about the stock of receivables is not conserved. The corporate ac- \ncounting system makes the value of the receivables stock available to many \nthroughout the organization. Accessing and using this information does not use it \nup or make it unavailable to others. \nNote also that while the units of accounts payable are dollars and the billing, \npayment, and default flows are measured in dollars per time period, the contents of \nthe stock are not actually dollars. Rather, the content of the receivables stock is in- \nformation, specifically, a ledger or database consisting of records of invoices out- \nstanding. To see why, imagine trying to exchange your firm’s stock of receivables \nfor cash-you can sell them to a collection agency, but only for much less than 100 \ncents on the dollar. Though the contents of the stock of receivables is information \nand not a material quantity, it is nevertheless conserved-you cannot sell a given \nstock of receivables more than once (not legally, anyway). Stocks can represent in- \nformation as well as more tangible quantities such as people, money, and materi- \nals. Stocks can also represent intangible variables including psychological states, \nperceptions, and expectations such as employee morale, the expected rate of infla- \ntion, or perceived inventory. \n","page_start":226,"page_end":226,"token_count":518,"section_type":"other","chapter_number":6,"chapter_title":"Stocks and Flows","chunk_index":274}
{"chunk_id":"b2d50ac4fd3f5e62","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"202 \nPart I1 Tools for Systems Thinking \nFIGURE 6-4 \nStock and flow \nstructure of \naccounts \nreceivable \nThe material flow- \ning through the \nnetwork is actually \ninformation about \ncustomers and the \namounts they owe. \nThis information is \nconserved-the \nonly way a receiv- \nable, once billed, \nis removed from \nthe stock is if the \ncustomer pays or \ndefaults. Informa- \ntion about the size \nand composition of \naccounts payable, \nhowever, can be \nmade available \nthroughout the \nsystem and is \nnot depleted by \nusage. \nInformation about \nAccounts Receivable \nAvailable to Decision \nMakers \nAccounts \nReceivable \nBillings \nPayments \nDefaults \nc3 \n6.2.4 \nState-Determined Systems \nThe theory of dynamic systems takes a state-determined system or state variable \napproach. The only way a stock can change is via its inflows and outflows. In turn, \nthe stocks determine the flows (Figure 6-5). \nSystems therefore consist of networks of stocks and flows linked by informa- \ntion feedbacks from the stocks to the rates (Figure 6-6). As shown in the figure, the \ndeterminants of rates include any constants and exogenous variables. These too are \nstocks. Constants are state variables that change so slowly they are considered to \nbe constant over the time horizon of interest in the model. Exogenous variables are \nstocks you have chosen not to model explicitly and are therefore outside the model \nboundary. For example, in a model of the demand for a new video game, the size \nof the potential market might depend on the population between, say, ages 4 and \n20. The product life cycle will last a few years at most. Over this time horizon the \npopulation between 4 and 20 years of age is not likely to change significantly and \ncan reasonably be assumed constant. Alternatively, you could model the stock of \nchildren in the target age group as an exogenous variable, using census data and \nprojections to estimate its values. Making population constant or exogenous is ac- \nceptable in ths case since there are no significant feedbacks between sales of video \ngames and birth, death, or migration rates. \n6.2.5 \nAuxiliary Variables \nAs illustrated in Figure 6-6, mathematical description of a system requires only the \nstocks and their rates of change. For ease of communication and clarity, however, \nit is often helpful to define intermediate or auxiliary variables. Auxiliaries consist \nof functions of stocks (and constants or exogenous inputs). For example, a popula- \ntion model might represent the net birth rate as depending on population and the \nfractional birth rate; fractional birth rate in turn can be modeled as a function of \nfood per capita. The left side of Figure 6-7 shows the structure and equations for \n","page_start":227,"page_end":227,"token_count":615,"section_type":"other","chapter_number":6,"chapter_title":"Stocks and Flows","chunk_index":275}
{"chunk_id":"08d1a6d508245bf5","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"Chapter 6 Stocks and Flows \n203 \nFIGURE 6-5 \nState-determined \nsystems \nSystems evolve \nby feedback of \ninformation frorn \nthe state of the \nsystem to the \nflows that alter \nthe states. \nLeft Causal loop \nrepresentation in \nwhich the stock. \nand flow \nstructure is not \nexplicit. \nRight: Explicit \nstock and flow \nstructure for the \nsame feedback \nThe equations \ncorrespond to the \nstock and flow \nmap. The net \nrate of change \nof ithe stock is a \nfunction of the \nstock itself, \nclosing the \nfeedback loop. \nloop. \nNet Rate of \nState of thc \nChange \nSystem \nState of the \nSystem \n(Stock) \nNet Rate of \nChange \nState of the System = INTEGRAL(Net Rate of Change, State of the Systemt,) \nNet Rate of Change = f (State of the System) \nthe model. The Net Birth Rate accumulates in the Population stock. The auxiliary \nvariables Fractional Birth Rate and Food per Capita are neither stocks nor flows. \nThey are functions of the stocks (and exogenous inputs, in this case Food). Popu- \nlation participates in two feedback loops: a positive loop (more people, more \nbirths, more people) and a negative loop (more people, less food per person, lower \nfractional net birth rate, fewer births). The inclusion of the auxiliary variables dis- \ntinguishes the two loops and allows unambiguous assignment of link and loop po- \nlarities. \nThe auxiliaries can always be eliminated and the model reduced to a set of \nequations consisting only of stocks and their flows. By substituting the equation \nfor Food per Capita into the equation for Fractional Birth Rate and then substitut- \ning the result into the equation for Net Birth Rate, you can eliminate the auxiliaries, \nreducing the model to one with only Net Birth Rate and Population. The right side \nof Figure 6-7 shows this model and its equations. Though the model is mathemat- \nically equivalent to the model with auxiliaries, it is harder to explain, understand, \nand modify. Note that in the reduced form model population enters the equation for \nthe rate of change of population in both the numerator and denominator. The \npolarity of the causal link between Population and Net Births is now ambiguous, \nand it is not possible to distinguish the two feedback loops involving population \nand births. \nThe process of creating the reduced form model by substitution of intermedi- \nate variables into their rates is a general one and can be carried out on any model. \nHowever, the use of auxiliary variables is critical to effective modeling. Ideally, \neach equation in your models should represent one main idea. Don’t try to econo- \nmize on the number of equations by writing long ones that embed multiple con- \ncepts. These long equations will be hard for others to read and understand. They \nwill be hard for you to understand. Finally, equations with multiple components \nand ideas are hard to change if your client disagrees with one of the ideas. \n","page_start":228,"page_end":228,"token_count":661,"section_type":"other","chapter_number":6,"chapter_title":"Stocks and Flows","chunk_index":276}
{"chunk_id":"0bcb225702a8ae81","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"204 \nPart I1 Tools for Systems Thinking \nFIGURE 6-6 Networks of stocks and flows are coupled by information feedback. \nStocks accumulate their rates of flow; information about the stocks feeds back to alter the rates, \nclosing the loops in the system. Constants are stocks changing too slowly to be modeled explicitly; \nexogenous variables are stocks outside the model boundary (shown by the rectangle with rounded \ncorners). \nEquation representation: The derivatives of the stocks in dynamic systems are, in general, nonlinear \nfunctions of the stocks, the exogenous variables, and any constants. In matrix notation, the rates of \nchange dS/dt are a function f ( )  of the state vector S, the exogenous variables U and the constants C: \ndS/dt = f(S, U, C) \nFor the diagram below, the equation for the rate of change of S4 is \ndS&t = fq(S3, Sq, U3, C3) \nExogenous \nInput, \nExogenous \nInputs \nExogenous \nInput3 \n6.2.6 \nStocks Change Only Through Their Rates \nStocks change only through their rates of flow. There can be no causal link directly \ninto a stock. Consider a model for customer service. Customers arrive at some rate \nand accumulate in a queue of Customers Awaiting Service. The queue could be a \nline at a fast food restaurant, cars awaiting repair at a body shop, or people on hold \ncalling for airline reservations. When the service is completed customers depart \nfrom the queue, decreasing the stock of customers waiting for service. The rate at \nwhich customers can be processed depends on the number of service personnel, \ntheir productivity (in customers processed per hour per person), and the number of \nhours they work (the workweek). If the number of people waiting for service \nincreases, employees increase their workweek as they stay an extra shift, skip \nlunch, or cut down on breaks. \n","page_start":229,"page_end":229,"token_count":412,"section_type":"other","chapter_number":6,"chapter_title":"Stocks and Flows","chunk_index":277}
{"chunk_id":"5f82f036b1d48934","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"Chapter 6 Stocks and Flows \n*z \nb \n205 \nPopulation \nFIGURE 6-7 \nAuxiliary variables \nLeft:A simple population model with auxiliary variables. Fractional Birth Rate and Food per Capita are \nneither stocks nor flows, but intermediate concepts added to the model to aid clarity. \nRight: The same model with the auxiliary variables eliminated by substitution into the rate equation. \nThe link from Population to Net Birth Rate now has an ambiguous sign, a poor practice. \nCorrect \nIncorrect \nFood \nPopulation = INTEGRAL(Net Birth Rate, Populationto) \nNet Birth Rate = f’opulation * Fractional Birth Rate \nFractional Birth Rate = f(Food per Capita) \nFood per Capita = Food/Population \nPopulation = INTEGRAL(Net Birth Rate, PopulationJ \nNet Birth Rate = Population * f(Food/Population) \nI have often seen people in workshops draw the diagram shown in the top of \nFigure 6-8. They correctly recognize that the rate at which customers are processed \nis the product of Service Staff, Productivity, and Workweek and that higher queues \nof waiting customers lead to longer hours and hiring of additional staff, forming \ntwo balancing feedbacks. But often people draw information feedbacks directly \nfrom the workweek and service staff to the stock of Customers Awaiting Service, \nassigning them a negative polarity. They reason that an increase in the workweek \nor staff level decreases the number of customers remaining in the queue, thus clos- \ning the negative feedback loops. \nThe correct diagram is shown in the lower panel of Figure 6-8. The only way \ncustomers can exit the stock is via the departure rate. The departure rate is the \nproduct of the number of staff, their workweek, and their productivity. An increase \nin any of these inputs boosts the rate at which customers are processed and leave \nthe queue. The balancing feedbacks are still present: A longer queue of waiting \ncustomers leads to longer hours and more staff and an increase in the processing \nrate. The valve controlling the outflow from the stock of waiting customers opens \nwider, and customers depart the queue at a higher rate. The polarities of the infor- \nmation links in the feedback loop are all positive, but an increase in the customer \ndeparture rate causes a reduction in the stock of waiting customers because the de- \nparture rate is an outflow from the stock. \n","page_start":230,"page_end":230,"token_count":510,"section_type":"other","chapter_number":6,"chapter_title":"Stocks and Flows","chunk_index":278}
{"chunk_id":"0471bf7d370cd8a4","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"206 \nv \nY \nPart I1 Tools for Systems Thinking \nCustomers \nw \n- \nWaiting for \nY \nFIGURE 6-8 \nStocks change \nonly through \ntheir rates. \nTop: Incorrect \nstock and flow \nmap of a service \noperation. Work- \nweek, Service \nStaff ,and other \nvariables cannot \ndirectly alter the \ntomers Awaiting \nService. \nBofforn: Corrected \ndiagram. The \nWorkweek, \nnumber of Service \nStaff, and Produc- \ntivity drive the \nCustomer Depar- \nture Rate, which \ndecreases the \ntomers Awaiting \nService. \nstock of CUS- \nstock of CUS- \nIncorrect - \nCustomers \nY \nCustomer \n- \nCustomer \nStaff \n+ \nCorrect \nArrival \n/ /  \nDeparture \nRate \nWorkweek \n6.2.7 \nContinuous Time and Instantaneous Flows \nThe stock and flow perspective (and its equivalent integral or differential equation \nstructure) represents time as unfolding continuously. That is, as our experience \nsuggests, time progresses smoothly and continuously. In system dynamics we \nalmost always represent time as continuous. Events can happen at any time; \nchange can occur continuously; and time can be divided into intervals as fine as \none desires.] \n'In numerical simulation time is divided into discrete intervals. However, these intervals must \nbe small enough that the numerical solution is a good approximation of the underlying continuous \ndynamics, and model dynamics cannot depend on the length of the solution interval (cutting it in \nhalf, e.g., should not affect any of your conclusions). In discrete time or difference equation sys- \ntems the time interval is an irreducible minimum time delay in every feedback loop and often has \na large impact on the dynamics. Appendix A discusses numerical integration and the selection of an \nappropriate time step for your simulations. \n","page_start":231,"page_end":231,"token_count":399,"section_type":"other","chapter_number":7,"chapter_title":"Dynamics of Stocks and Flows","chunk_index":279}
{"chunk_id":"e62db672b5869fdf","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"Chapter 6 Stocks and Flows \n207 \nA flow at any time is defined to be its instantaneous value-the rate at which \nwater is flowing into your bathtub right now. Mathematically, the net flow to a \nstock (inflows less outflows) is the instantaneous rate of change of the stock-its \nderivative (this is the meaning of equation 6-2). No one can measure the instanta- \nneous value of any flow. The government does not and cannot report the GDP at a \nparticular moment but instead reports the average rate of production over some \nprior, finite interval of time (typically a quarter of a year). Likewise, quarterly re- \nports of a firm’s sales are the cumulative sales during the quarter, not the instanta- \nneous sales rate at the end of the quarter. During the quarter sales likely varied \nsubstantially. Sales reports at more frequent intervals such as monthly or even \ndaily are better approximations of the instantaneous sales rate but still represent av- \nerages taken over some prior, finite interval. Similarly, the speedometer of a car \ndoes not measure its instantaneous velocity. Because the components of the veloc- \nity sensor and instrumentation have inertia, the speedometer indicates an average \nof the velocity over a (short) prior interval. \nAs the length of the measurement interval shrinks, the reported average rate \nbecomes a better approximation of the instantaneous rate. Most speedometers re- \nspond quickly relative to the rate of change of the car’s true velocity, so for practi- \ncal purposes the average velocity reported on the instrument panel is the same as \nthe actual, current velocity. On the other hand, the delays in reporting the state of \nthe economy or the profits of a company are often long relative to their rates of \nchange and dramatically influence the stability of the system. Though we might \ndevelop instruments for our physical and social systems that shrink the delays in \nmeasuring and reporting rates of flow, we can never measure the instantaneous \nvalue of the flows affecting any stock. \n6.2.8 \nContinuously Divisible versus \nQuantized Flows \nJust as time can be represented as unfolding continuously or in discrete intervals, \nso too the units flowing into and out of stocks can be thought of either as continu- \nously divisible or as a discrete numbers of items. Most flows are actually quan- \ntized, meaning they consist of collections of individual items which cannot be \ndivided into arbitrarily small units. Oil tankers are commissioned one at a time- \nit is not meaningful to speak of launching half a tanker. Company hiring consists \nof a whole number of people. Even the flow in a river consists of an (astronomi- \ncally large) integer number of water molecules. The stock and flow concept and \nthe four equivalent notations shown in Figure 6-2 apply whether the flow is con- \nceived to be infinitely divisible or quantized. The metaphor of the flow of water \ninto a bathtub emphasizes our everyday experience of water as a continuously di- \nvisible substance-we aren’t concerned with the identity of the individual water ","page_start":232,"page_end":232,"token_count":651,"section_type":"other","chapter_number":7,"chapter_title":"Dynamics of Stocks and Flows","chunk_index":280}
{"chunk_id":"973d648a63338878","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"cally large) integer number of water molecules. The stock and flow concept and \nthe four equivalent notations shown in Figure 6-2 apply whether the flow is con- \nceived to be infinitely divisible or quantized. The metaphor of the flow of water \ninto a bathtub emphasizes our everyday experience of water as a continuously di- \nvisible substance-we aren’t concerned with the identity of the individual water \nmolecules. However, if it were important to our purpose, we could just as easily \nimagine that the tub is filled by a lumpy flow of individual ice cubes. Whether con- \ntinuous or quantized, the quantity in the stock is always the accumulation of the in- \nflows to the stock less its outflows. \nIn many models it is appropriate and useful to approximate the flow of individ- \nual items as a continuous stream. In modeling the cash flow of a large organization ","page_start":232,"page_end":232,"token_count":186,"section_type":"other","chapter_number":7,"chapter_title":"Dynamics of Stocks and Flows","chunk_index":281}
{"chunk_id":"8023762b9980197a","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"208 \nPart I1 Tools for Systems Thinking \nyou usually do not need to track individual payments; it is a perfectly acceptable \napproximation to consider the flow of revenue and expenditures as continuous in \ntime and continuously divisible (though of course the accounting department must \ntrack individual payments). Similarly, though organizations hire discrete, whole in- \ndividuals, it is usually acceptable to assume the flows of people are continuously \ndivisible. Some clients are troubled by the fractional people your model will gen- \nerate, but almost always the error is insignificant compared to the measurement er- \nror in parameters including the number of employees the firm actually has. Since \npeople can be hired part time, work in job-sharing situations, or be assigned to \nmultiple projects, it is quite meaningful to speak of fractional employees, measured \nin FTE (Full-Time Equivalent) people. \nWhen the purpose of the model requires tracking the individual people, for ex- \nample modeling the behavior of people entering the line at the supermarket to de- \ntermine the optimal number of checkout counters, then people can be modeled as \ndiscrete individuals arriving at discrete points; this is a classic modeling paradigm \nin queuing theory (Prabhu 1997; Gross and Harris 1998; Papadopoulos 1993). Yet \neven in many queuing applications, the continuous time, continuous flow approx- \nimation works extremely well and the errors it introduces are often small compared \nto measurement error and parameter uncertainty in the real system. The decision to \nrepresent stocks and flows as continuous or discrete always depends on the pur- \npose of the model. For example, if your purpose is to understand the dynamics of \nprice and the origin of cycles in the oil tanker market (see chapter 20), it is fine to \nassume that the rates of tanker ordering, construction, and scrappage are continu- \nous in time and continuously divisible. In contrast, if your purpose were to model \nthe arrival and offloading of tankers to optimize port facilities you would have to \nmodel the ships as discrete entities. \n6.2.9 \nWhich Modeling Approach Should You Use? \nThe choice of modeling technique and software will depend on which assumptions \nabout the stocks and flows in your system are appropriate to your purpose. In all \ncases make sure your modeling software and method can include the feedback \nprocesses you consider important. In modeling the behavior of people in line at the \nsupermarket, for example, you might choose to use a discrete time, quantized flow \nrepresentation and select a stochastic modeling package, or even use a spreadsheet. \nBe sure, however, that your tools allow you to capture behavioral feedbacks such \nas the feedback from the length of the line to the rate at which people join the line. \nSome models and a great many of the theorems in queuing theory assume that the \nrate of arrivals to a queue such as the checkout line is exogenous. People actually \nchoose to enter a line based on its length (more precisely, their estimate of ex- \npected waiting time). A long line will cause people to switch to another, defer their ","page_start":233,"page_end":233,"token_count":647,"section_type":"other","chapter_number":7,"chapter_title":"Dynamics of Stocks and Flows","chunk_index":282}
{"chunk_id":"8d127fc1dc5ee61b","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"as the feedback from the length of the line to the rate at which people join the line. \nSome models and a great many of the theorems in queuing theory assume that the \nrate of arrivals to a queue such as the checkout line is exogenous. People actually \nchoose to enter a line based on its length (more precisely, their estimate of ex- \npected waiting time). A long line will cause people to switch to another, defer their \nshopping to a less crowded time of day, or even go to a different store. Such balk- \ning creates a powerful negative feedback loop: The longer the line, the smaller the \narrival rate. Omitting such feedback processes from your model in the interests of \nanalytical tractability or programming convenience will often lead to a fatal flaw \nin your analysis and policy conclusions. ","page_start":233,"page_end":233,"token_count":172,"section_type":"other","chapter_number":7,"chapter_title":"Dynamics of Stocks and Flows","chunk_index":283}
{"chunk_id":"6314f5df7fcad60e","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"Chapter 6 Stocks and Flows \n209 \n6.2.1 0 \nProcess Point: \nPortraying Stocks and Flows in Practice \nEach of the stock and flow representations in Figure 6-2 (the bathtub, stock and \nflow diagram, integral equation, and differential equation) contains precisely the \nsame information. They are exactly equivalent. Which should you use to develop \nand present your models, especially when you are working in a team? \nThe answer depends on the context of the modeling project you are doing and \nthe background of your client team. While many mathematically sophisticated \nmodelers scoff at the idea of explaining a complex model using bathtubs and pipes, \nI have many times seen otherwise brilliant modeling efforts founder because the \nanalyst tried to explain a model using differential equations and mathematical no- \ntation-or the simulation code-to a client team with little technical background. \nOne of the worst things a consultant can do is humiliate the client. Showing off \nyour mathematical knowledge by using differential equations, lots of Greek letters, \nand other notation the client never studied or forgot a long time ago is a sure-fire \nway to convince your clients you care more for the elegance of your equations than \nfor helping them solve their problem. \nStock and flow diagrams contain the same information as the more mathemat- \nically formal notation but are easier to understand and to modify on the fly. Still, \nsome team members consider even the stock and flow diagram format to be too ab- \nstract. I have often seen clever graphics of tanks, pipes, and valves used to excel- \nlent effect with client teams. For example, a consulting project with a multinational \nchemicals firm represented the flows of production, inventories, shipments, and \ncustomer stocks-along with capacity, cash, and even equipment defects-as a se- \nries of pipes, valves, and tanks. The team members were able to grasp the stock \nand flow structure readily since they were all familiar with the tanks and pipes car- \nrying materials in their plants. In fact, most of the client team were engineers by \ntraining and had plenty of background in mathematics. Yet several commented that \nthey never really understood how the business worked until they saw the chart \nshowing its stock and flow structure as tanks and pipes. \nWhat if your clients have even less technical training than these chemical com- \npany executives? The bathtub metaphor is often used to good effect, as illustrated \nby the case of automobile leasing (see Figure 2.4). What if the stocks and flows in \nyour model aren’t as tangible as barrels of oil or automobiles? Get creative. In a \nmanagement flight simulator of insurance claims processing (Kim 1989; Diehl \n1994), a flow of letters arriving to an inbox represented the addition of new claims \nto the stock of unresolved claims. Letters containing checks flowed out to the cus- \ntomers as claims were settled. Icons of people represented the stock and flow struc- \nture of claims adjusters (Figure 6-9). Participants in workshops using the model \nwere able to understand the system structure much better than if the more abstract ","page_start":234,"page_end":234,"token_count":654,"section_type":"other","chapter_number":7,"chapter_title":"Dynamics of Stocks and Flows","chunk_index":284}
{"chunk_id":"4d73f46f593c4b50","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"1994), a flow of letters arriving to an inbox represented the addition of new claims \nto the stock of unresolved claims. Letters containing checks flowed out to the cus- \ntomers as claims were settled. Icons of people represented the stock and flow struc- \nture of claims adjusters (Figure 6-9). Participants in workshops using the model \nwere able to understand the system structure much better than if the more abstract \nsymbols had been used. \nI am not recommending that you keep the equations or stock and flow dia- \ngrams hidden from your client. Never hide your model from a curious client. You \nshould always look for and create opportunities for client team members to learn \nmore about the modeling process; you should always be prepared to explain the \nworkings of your model. ","page_start":234,"page_end":234,"token_count":163,"section_type":"other","chapter_number":7,"chapter_title":"Dynamics of Stocks and Flows","chunk_index":285}
{"chunk_id":"bfb35139b88a9c7d","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"21 0 \nPart I1 Tools for Systems Thinking \nFIGURE 6-9 \nStocks and flows \nof claims and \nclaims adjusters \nin an insurance \ncompany \nHiring \nm#& \nAdjusters \nTurnover \nClaims \nReceived \nClaims \nOutstanding \nClaims \nSettled \nSource: Kim 1989. \nAnd while I caution the mathematically sophisticated modeler against overly \ntechnical presentation, the opposite problem can also arise: some clients are of- \nfended by what they consider to be simplistic cartoon diagrams and prefer what \nthey view as the more professional presentation of stock and flow diagrams or \neven equations. As always, you must get to know your client deeply and early in \nthe modeling process. \nFinally, a caution for those with less technical training and mathematical back- \nground: Clients may not need to understand the deep relationship between their \nbathtub and the mathematics underlying stocks and flows, but you do. While you \ndon’t need to be able to solve differential equations to be a successful modeler, you \ndo need to understand the structure and dynamics of stocks and flows thoroughly \nand rigorously. \n6.3 \nMAPPING STOCKS AND FLOWS \n6.3.1 \nWhen Should Causal Loop Diagrams Show \nStock and Flow Structure? \nCausal diagrams can be drawn without showing the stock and flow structure of a \nsystem. Or, as shown in Figure 6-8, they can include the stock and flow structure \nexplicitly. When should you include the stock and flow structure, and when can \nyou omit it? Generally, you should include stock and flow structures representing \nphysical processes, delays, or stocks whose behavior is important in the dynamics \nyou seek to explain. For example, consider the flow of a product through a supply \nchain from producer to consumer. The product travels through a network of stocks \n(inventories) and flows (shipment and delivery rates). The stock and flow repre- \nsentation for this process is shown in the top panel of Figure 6-10. \nProduction starts add to the stock of work in process (WIP) Inventory. The \nProduction Completion Rate reduces the stock of WIP and increases the stock of \n","page_start":235,"page_end":235,"token_count":464,"section_type":"other","chapter_number":7,"chapter_title":"Dynamics of Stocks and Flows","chunk_index":286}
{"chunk_id":"7945fba76cf8cc8e","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"Chapter 6 Stocks and Flows \nWork in \nProcess \n*z-b \nInventory \n21 1 \nv \nFinished \nL-l \nInventory \nL1 \nn \nA \nFIGURE 6-1 0 Stock and flow vs. causal diagram representations \nStock and Flow Representation of a Manufacturing Process \nStart Rate \nCompletion \nRate \nRate \nCausal Loop Diagram Representation of the Manufacturing Process \nA- \nk-----l \nProduction \nWork in \nProduction \nFinished \nShipment \nStart Rate \nProcess \nCompletion \nInventory \nRate \nInventory \nRate \nFinished Inventory. Shipments to customers deplete Finished Inventory. Equiva- \nlently, the stock of WIP accumulates production starts less completions, and the \nstock of finished inventory accumulates production completions less shipments. \nThe causal diagram representation is shown in the bottom panel of Figure \n6- 10. While technically correct, the causal diagram makes it hard to see the physi- \ncal flow of product through the system and the conservation of material in the \nstock and flow chain. It is often confusing to interpret the polarities of the causal \nlinks when they involve stocks and flows. An increase in the Production Comple- \ntion Rate causes Finished Inventory to rise above what it would have been other- \nwise (it rises at a faster rate), hence the polarity of the link is positive. A decrease \nin production completions, however, does not cause finished inventory to fall. \nRather, a decrease in the production completion rate causes finished inventory to \nbe less than it would have been. You cannot say whether finished inventory will be \nrising or falling based on the behavior of the production rate alone. Inventory will \nrise only when production completions exceed the shipment rate; that is, inventory \nrises only when we add to it faster than we remove units from it. You need to know \nthe values of all the flows affecting a stock to determine its behavior. Richardson \n(1986a, 1997) carefully documents the pitfalls of causal diagrams, most of which \ninvolve the failure of causal diagrams to show the stocWflow distinction. \nCIiALLEMGE \nAdding Stock and Flow Structure to Causal Diagrams \nConsider the causal loop diagrams in chapter 5. For each, redraw the diagram \nshowing the important stock and flow structure along with the feedback structure \nshown in the diagram. In particular, identify the main stocks and flows in the fol- \nlowing conceptualization case studies presented in chapter 5: \n","page_start":236,"page_end":236,"token_count":520,"section_type":"other","chapter_number":7,"chapter_title":"Dynamics of Stocks and Flows","chunk_index":287}
{"chunk_id":"cd882e9b49831568","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"21 2 \nPart I1 Tools for Systems Thinking \n1. The workload management example. \n2. The oil industry and horse racing examples. \n3. The traffic congestion example. \nIn each case, consider whether the explicit representation of the main stocks and \nflows enhances your ability to understand the dynamics of the system or merely \nclutters the diagram. \nLinking Stock and Flow Structure with Feedback \nOften understanding the dynamics of a system requires linking the feedback loop \nstructure with the stock and flow structure. As an example, consider the gasoline \nshortages of the 1970s. In 1979 the United States (and some other industrialized \nnations) experienced a severe gasoline shortage. Iran’s exports of oil dropped in \nthe wake of the revolution there, and petroleum prices on the world market in- \ncreased sharply. Within weeks, a shortage of gasoline began. Some service stations \nfound their tanks emptied before the next delivery. Drivers, remembering the first \noil embargo in 1973 and worried that they wouldn’t be able to get gas, began to top \noff their tanks, instead of filling up only when the gas gauge fell toward empty. \nSoon, long lines of cars were seen idling in front of gas stations, and “Sorry-No \nGas” signs sprouted along the highways of America as station after station found \nits underground tanks pumped dry. The shortage was the top story on the evening \nnews-aerial footage of cars lined up around the block, close-ups of “No Gas” \nsigns, and interviews with anxious drivers dominated the news. In some states, \nmandatory rationing was imposed, including limiting purchases to, for example, no \nmore than $10 worth of gas. California imposed oddeven purchase rules: Drivers \nwere allowed to buy gas only every other day, based on whether their license plate \nnumber was odd or even. It seemed that the supply of gasoline had been slashed. \nCuriously, the impact of the Iranian revolution on the flow of oil to the US was \nsmall. True, US oil imports from the Persian Gulf (including Iran) fell by 500,000 \nbarrels per day between 1978 and 1979, about 3% of US consumption, but imports \nfrom other nations increased by 640,000 barrels per day, so imports in 1979 actu- \nally increased by 140,000 barrels per day. Domestic production fell by 150,000 \nbarrels per day, so total supply was essentially constant, while consumption fell by \nabout 330,000 barrels per day, a drop of 2% from 1978. Plainly, for the year as a \nwhole, there was no shortage. But if the flow of oil into the US was essentially \nconstant, what caused the shortage? Where did the gas go? \nFirst, develop a stock and flow map for the gasoline distribution system. You \nneed not consider the entire supply chain for gasoline but can focus on retail dis- \ntribution. Your diagram should begin with the flow of gasoline to service stations, \nthen represent the stock and flow structure for its subsequent storage, sale, and \neventual combustion. ","page_start":237,"page_end":237,"token_count":656,"section_type":"other","chapter_number":7,"chapter_title":"Dynamics of Stocks and Flows","chunk_index":288}
{"chunk_id":"2ef179465434f122","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"constant, what caused the shortage? Where did the gas go? \nFirst, develop a stock and flow map for the gasoline distribution system. You \nneed not consider the entire supply chain for gasoline but can focus on retail dis- \ntribution. Your diagram should begin with the flow of gasoline to service stations, \nthen represent the stock and flow structure for its subsequent storage, sale, and \neventual combustion. \nOnce you’ve mapped the stock and flow structure, identify the information in- \nputs to the rates of flow in your diagram. Assume that the rate at which gasoline is \ndelivered to service stations is exogenous. By identifying the information inputs to ","page_start":237,"page_end":237,"token_count":135,"section_type":"other","chapter_number":7,"chapter_title":"Dynamics of Stocks and Flows","chunk_index":289}
{"chunk_id":"f813b12407a826a6","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"Chapter 6 Stocks and Flows \n21 3 \nthe flows in your stock and flow map, you will be closing some feedback loops, \nloops which should help explain why the shortage occurred and answer the ques- \ntion, Where did the gas go? Be sure to ask how individual drivers would learn \nabout the shortage and what their behavior would then be. \nFinally, using your diagram, assess the likely effectiveness of the maximum \npurchase and odd/even policies. Do policies of this type help ease the shortage or \nmake it worse? Why? What policy would you recommend to ease the shortage? \n6.3.2 \nAggregation in Stock and Flow Mapping \nThe ability to map the stocks and flows in a system is critical to effective model- \ning. Usually it is wise to identify the main stocks in a system and then the flows \nthat alter those stocks. You must select an appropriate level of aggregation and \nboundary for these stock and flow maps. The level of aggregation refers to the \nnumber of internal categories or stocks represented. The boundary refers to how \nfar upstream and downstream one chooses to represent the flows of materials and \nother quantities in the model. \nTo illustrate, consider the manufacturing process discussed above in which \nmaterial flows from production starts through WIP inventory to finished inventory \nand finally shipment to the customer. All the various parts, components, and sub- \nassemblies are aggregated together into a single stock of WIP. And though the firm \nmay carry tens of thousands of SKUs (stock keeping units), these individual items \nare all aggregated into a single stock of finished inventory. For many purposes the \naggregate picture is sufficient. However, the model purpose might require more de- \ntail. If the purpose involved a closer look at the manufacturing process, you could \ndisaggregate the stock of work in process serially to represent the different stages, \nsuch as part fabrication, assembly, and testing (Figure 6- 11). \nThe sum of the three intermediate stocks is the total work in process inventory, \nbut now the model tracks throughput at a finer level of resolution and can represent \nmore potential bottlenecks in the production process. Note that in both the original, \naggregate diagram and in this more detailed diagram there is no provision for re- \nwork or scrap. All units started are eventually completed-the flow of widgets \nthrough the system is conserved. Note also that as material flows through the sys- \ntem it is transformed from parts to finished product. To maintain consistent units \nof measure we might measure parts in widget equivalents-that is, a widget’s \nworth of parts. If necessary for the purpose, you can further disaggregate the stock \nand flow structure. \n","page_start":238,"page_end":238,"token_count":556,"section_type":"other","chapter_number":7,"chapter_title":"Dynamics of Stocks and Flows","chunk_index":290}
{"chunk_id":"024e090939cdbc43","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"21 4 \nPart I1 Tools for Systems Thinking \nFIGURE 6-11 \nDisaggregated \nstock and flow \nmap for a \nmanufacturing \nprocess \nProduction \nP Start Rate \nWork in \nProcess \nInventory \nParts in \nProcess \nAssembly \nStart Rate \nAssemblies in \nProcess \nTest \nStart Rate \nf \nProduct in \nTesting \nLn4 \nProduction \nCompletion \nRate \nFinished \nInventory \nShipment \nRate \nEach of the three stages of WIP identified in Figure 6-11 consists of other steps, \neach with its own stock and flow structure. Suppose you learn that part fabrication \n","page_start":239,"page_end":239,"token_count":132,"section_type":"other","chapter_number":7,"chapter_title":"Dynamics of Stocks and Flows","chunk_index":291}
{"chunk_id":"faaaea86035d7b7e","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"Chapter 6 Stocks and Flows \n21 5 \nat the plant you are modeling actually requires several operations: welding, grind- \ning, and painting. Observation of the grinding operation reveals that workers draw \nparts ready for grinding from a buffer generated by the welding operation. When \ngrinding is completed, the parts are placed in a bin which then goes on to the next \noperation (painting). The welding and paint shops are similar. Draw the disaggre- \ngated stock and flow map for the part fabrication step to show the welding, grind- \nUp to now the discussion has focused on serial disaggregation: how finely to \nbreak down the stages of processing. Throughout, the many different parts and \nproducts produced by a typical firm are aggregated into a single chain of stocks \nand flows. In many situations the process occurs not only in series but also in- \nvolves parallel activities. You could of course replicate the main stock and flow \nchain for each product (many simulation software packages support array struc- \ntures for this purpose). When there are multiple, parallel activities you must make \na decision not only about the number of stages of the process to represent but also \nhow much to aggregate the different parallel processes together. For example, the \nassembly process for automobiles involves integrating the chassis and engine. \nEach subassembly is built on a separate line, often in plants far from the final as- \nsembly point. Suppose the client argues that you can’t aggregate all subcompo- \nnents into a single flow of parts, but must separate chassis and engine fabrication \n(omit the body for simplicity). The stock and flow map for the assembly process \nmight be shown as in Figure 6-12. \nThere are now three distinct stock and flow chains, one each for engines, chas- \nsis, and assembled cars. Because the three chains are separate, each can be mea- \nsured in different units: engines, chassis, and cars. The three chains are linked \nbecause each car beginning the final assembly process requires one engine from \nthe stock of completed engines and one chassis from the stock of completed chas- \nsis. The information arrows from the assembly rate to the engine and chassis use \nrates show these links. The number of engines and chassis available also determine \nthe maximum assembly start rate, which in turn constrains actual assembly starts: \nIf either component buffer falls to zero, assembly must cease.2 These links (not \nshown) define two balancing feedbacks that regulate the outflows from the stocks \nof components and couple the stock and flow networks. The diagram does not rep- \nresent many other information flows that must exist in the system (such as the de- \nterminants of the chassis start and completion rates); try adding these to the map. \nYou could of course continue to disaggregate. The process can be broken down \ninto more steps: The paint process, for example, actually consists of multiple \nactivities separated by buffers such as part preparation (solvent bath), drying, \nspraying the first coat, drying in the oven, spraying the second coat, drying, and ","page_start":240,"page_end":240,"token_count":645,"section_type":"other","chapter_number":7,"chapter_title":"Dynamics of Stocks and Flows","chunk_index":292}
{"chunk_id":"e5d03a457b6c119f","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"terminants of the chassis start and completion rates); try adding these to the map. \nYou could of course continue to disaggregate. The process can be broken down \ninto more steps: The paint process, for example, actually consists of multiple \nactivities separated by buffers such as part preparation (solvent bath), drying, \nspraying the first coat, drying in the oven, spraying the second coat, drying, and \nso on, with various inspections along the way. You could also continue the parallel \ndisaggregation by splitting the engine or chassis assembly processes into their \n2Firms can sometimes build incomplete units and add the missing components later. When a \n1997 strike shut down a critical supplier, Ford continued to assemble its popular Explorer, storing \nthe nearly completed cars until the missing parts became available and could be retrofitted (try \nmodifying the diagram in Figure 6-12 to accommodate such retrofitting). ","page_start":240,"page_end":240,"token_count":190,"section_type":"other","chapter_number":7,"chapter_title":"Dynamics of Stocks and Flows","chunk_index":293}
{"chunk_id":"caa0978b4d2a849b","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"21 6 \nPart I1 Tools for Systems Thinking \nFIGURE 6-1 2 \nDisaggregating parallel activities \nEngines in 1 \n4Completed I \nEngines \nI \nEngine \nI \nEngine ' \nI Engine \nStart \nRate \nCompletion \nRate \nUse \nRate \n'4AssembliesI \nin Process \nAssembly \nAssembly \nStart \nCompletion \nRate \nRate \nChassis in 1 \n4Completed I \nChassis - \nChassis \nChassis \nChassis \nStart \nRate \nCompletion \nRate \nUse \nRate \nsubassemblies. In the limit each and every part and operation would be represented \nseparately. Obviously such a model would be just as complex as the real system, at \nleast as hard to understand, and quite useless. \nWhere should you stop? How much detail is necessary? This is always a mat- \nter of judgment to be made by considering the model purpose and the needs of the \nclient. If the purpose is representing the lag in the response of the manufacturing \nsystem to changes in demand as part of a larger model of firm strategy, the simpler \nrepresentation is probably fine. If you seek to reengineer the flow of material \nthrough the production line, a more detailed representation is required. It is better \nto start with a high-level, aggregate representation and add detail if needed to ad- \ndress the purpose. Beginning with detailed process maps often leads to paralysis \ndue to their complexity, data requirements, and rapid obsolescence rates. The ag- \ngregate map showing only production starts, WIP, production, and finished inven- \ntory is quite stable and remains appropriate even as the details of the production \nprocess change, while a detailed map may become obsolete as new products, tool- \ning, or process technologies are introduced. \n6.3.3 \nGuidelines for Aggregation \nWhen is it appropriate to aggregate different activities together? To determine \nwhether activities taking place serially can be aggregated, consider the average \nresidence time of items in each stock (the average time between entering and exit- \ning the stock). Stocks with short residence times relative to the time scale for the \n","page_start":241,"page_end":241,"token_count":456,"section_type":"other","chapter_number":7,"chapter_title":"Dynamics of Stocks and Flows","chunk_index":294}
{"chunk_id":"50fa5ccf95ad00d5","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"Chapter 6 Stocks and Flows \n21 7 \ndynamics of interest generally do not need to be represented explicitly and can ei- \nther be omitted or lumped into adjacent stocks. For example, in the long-term plan- \nning models of the US energy system developed by the US Department of Energy \n(Nail1 1992), various stocks of undiscovered petroleum and known reserves are \nexplicitly represented because their lifetimes range from years to decades (at cur- \nrent production rates). However, stocks of crude oil and refined products in the pe- \ntroleum supply chain represent only a few months of consumption. In a long-term \nmodel these stocks are too short-lived to require explicit treatment. They fluctuate \naround their equilibrium values as producers, refiners, and distributors react to \nchanges in inventory. In a model of short-term movements in spot petroleum \nprices, however, these stocks are critically important. A good model would repre- \nsent the key stocks in the petroleum supply chain explicitly, perhaps even includ- \ning a separate stock for the inventory of gasoline at retail service stations and the \ninventory of gasoline in the tanks of cars on the road. On the other hand, a short- \nterm spot price model need not include petroleum reserves or undiscovered re- \nsources, as these stocks change too slowly to influence the spot market over a time \nhorizon of a year. \nParallel activities can legitimately be aggregated together if the individual \nflows are governed by similar decision rules and if the time the different items \nspend in the individual stocks is similar. For example, it is often appropriate to ag- \ngregate the many parts required to manufacture a product into a small number of \ncategories since they are usually ordered using the same procedures and their de- \nlivery lead times and residence times in parts inventories generally don’t differ too \nmuch. In contrast, plant and equipment sometimes must be disaggregated. Their \nlifetimes are very different, and the decision rules for new green-field facilities dif- \nfer substantially from those used to order equipment for existing facilities due to \ndifferences in lead times, costs, financing, permitting, and regulatory issues. \nAs a rule of thumb, clients generally want to see more detail in a model than \nthe modeler thinks is needed, and modelers, in turn, generally overestimate the de- \ntail necessary to capture the dynamics of interest. Of course, the amount of detail \nneeded to capture the dynamics relevant to the client’s purpose and the amount of \ndetail needed to give the client confidence in the results are two different things. \nRoberts (1977/1978) estimated that clients often require twice as much detail as the \nmodeler feels is needed to feel comfortable with and accept a model as a basis for \naction, and in my experience this is often an underestimate. Success requires you \nto include the detail necessary to satisfy the client. But this does not mean you \nshould acquiesce to all client demands for more detail-you will end up with an \nexpensive and useless black box. You must work with the client to understand why ","page_start":242,"page_end":242,"token_count":644,"section_type":"other","chapter_number":7,"chapter_title":"Dynamics of Stocks and Flows","chunk_index":295}
{"chunk_id":"088e4a2b35c6e300","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"modeler feels is needed to feel comfortable with and accept a model as a basis for \naction, and in my experience this is often an underestimate. Success requires you \nto include the detail necessary to satisfy the client. But this does not mean you \nshould acquiesce to all client demands for more detail-you will end up with an \nexpensive and useless black box. You must work with the client to understand why \nexcessive detail is often unnecessary. Often, models end up with too much detail, \nbut as the client gains confidence and understanding of the important feedbacks \ndriving the dynamics, the excess structure can be eliminated, resulting in a simpler, \nmore easily maintained, and more useful model (Randers 1980). Still, Roberts is \ncorrect: “You must provide the level of detail that causes [the client] to be per- \nsuaded that you have properly taken into account his issues, his questions, his level \nof concerns. Otherwise he will not believe the model you have built, he will not ac- \ncept it, and he will not use it” (p. SO). ","page_start":242,"page_end":242,"token_count":231,"section_type":"other","chapter_number":7,"chapter_title":"Dynamics of Stocks and Flows","chunk_index":296}
{"chunk_id":"2cb2cbeef03f786e","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"21 8 \nPart I1 Tools for Systems Thinking \n6.3.4 \nSystem Dynamics in Action: \nModeling Large-Scale Construction Projects \nAggregation of multiple serial and parallel activities is well illustrated in a model \nof large construction projects developed by Jack Homer (Homer et al. 1993). The \nclient was a multinational forest products company, specifically the division of the \ncompany that designs and builds pulp and paper mills. Competition for the small \nnumber of mills built each year was intensifying as the industry globalized, and the \nfirm, already a leader, saw that to remain strong they had to dramatically reduce \nthe time required to design and build mills. Their goal was to reduce significantly \nthe total cycle time, from the handshake with a customer to the handoff of a work- \ning mill, without increasing costs. They knew traditional project management tech- \nniques were not adequate: the design and construction process is exceedingly \ncomplex, with tight couplings among the phases, and they had already done all the \neasy things. They decided to develop a system dynamics model of the entire engi- \nneering, procurement, and construction (EPC) process. \nEarly meetings of the project team focused on the model boundary and aggre- \ngation, in particular, descriptions of the stock and flow structure of a typical pro- \nject. Many issues were raised: Is there a typical project? How much detail is \nneeded? What activities could be aggregated together? One member of the client \nteam argued that the model couldn’t be useful if it didn’t represent every engineer- \ning drawing, every purchase order, and every component installed at the site. Ob- \nviously, such a model could never be built or made useful. Other members of the \nclient team argued for a simpler approach. They already had highly disaggregate \nscheduling and planning models based on traditional project management tools to \nmanage the detail complexity of the projects. They lacked a tool to manage the dy- \nnamic complexity and interdependencies among the phases and activities of the \nprojects. \nAfter extensive discussion, an initial model boundary and level of aggregation \nwere set (Figure 6-13). The figure is a high-level subsystem diagram showing how \nprojects were aggregated into a reasonable number of phases. The overall project \nwas divided into two main stock and flow chains representing P&E (process and \nequipment) and construction. Each activity goes through design preparation, re- \nview, and design revisions. Next suppliers are selected and purchase orders are is- \nsued. The suppliers then fabricate the materials needed for each activity. On the \nconstruction side, the client felt it was acceptable to aggregate all construction ma- \nterials (e.g., structural steel, concrete forms, rebar) into a single category. The \nprocess and equipment side, however, was divided into three categories: reactor \nvessels, major equipment (e.g., large tanks, pipelines, and conveyors), and minor \nequipment (e.g., pumps, motors, valves, and instrumentation). The design, pro- \ncurement, and construction of these types of equipment are sufficiently different in ","page_start":243,"page_end":243,"token_count":654,"section_type":"other","chapter_number":7,"chapter_title":"Dynamics of Stocks and Flows","chunk_index":297}
{"chunk_id":"5a72d6cdf71ea2c0","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"terials (e.g., structural steel, concrete forms, rebar) into a single category. The \nprocess and equipment side, however, was divided into three categories: reactor \nvessels, major equipment (e.g., large tanks, pipelines, and conveyors), and minor \nequipment (e.g., pumps, motors, valves, and instrumentation). The design, pro- \ncurement, and construction of these types of equipment are sufficiently different in \nscope, duration, and cost that they could not reasonably be lumped together. The \nreactor vessels, in particular, had to be modeled in more detail as they are the \nlargest subassembly, almost always fall on the critical path, and are frequently a \nbottleneck constraining construction progress. During construction, reactor ves- \nsels, other equipment, and site preparation such as foundations and grading all ","page_start":243,"page_end":243,"token_count":180,"section_type":"other","chapter_number":7,"chapter_title":"Dynamics of Stocks and Flows","chunk_index":298}
{"chunk_id":"6a5191883f0a6875","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"Chapter 6 Stocks and Flows \n21 9 \nFIGURE 6-13 \nSubsystem diagram showing flows of engineering, procurement, and construction work in a model of \na pulp mill construction project. The diagram illustrates the sector boundaries and level of aggregation \nwithout showing all details. Each block represents a project phase, modeled with a generic module with \nroughly the same structure. An internal gate captures the constraints on work available within a phase \nas a function of ,the work completed. For example, foundations cannot be completed until surveying \nand site prepara.tion are done; see section 14.5. \nBuilding a pulp and paper mill \nDesign \nInternal \nPreparation, \nGate \nReview, & \nInternal \nPreparation, \nGate \nReview, & \n\\ Revision \nf \nP&E \\ \nPurchasing \nPO'S & \n\\ \nRevisions J \nPurchasing \nPO'S & \nRevisions \nVessel \nErection \nI \nBasework& 4 \nb \n'Check \nOut' \nBasework & \nb \nInternal \nGate \nStart-up 0 \nSource: Homer et al. (1993). \nmust come together, followed by a functionality check out, start-up and, finally, \nhandoff to the customer. \nEach block in Figure 6-13 represents a project phase. The model consisted of \na generic project phase module, replicated for each block and linked as shown. \nEach module contained a stock and flow structure including the flows of tasks \nwithin the phase along with scheduled deadlines, the labor force dedicated to the \n","page_start":244,"page_end":244,"token_count":331,"section_type":"other","chapter_number":7,"chapter_title":"Dynamics of Stocks and Flows","chunk_index":299}
{"chunk_id":"1ec115c6dcfa15a4","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"220 \nFIGURE 6-1 4 \nStock and flow \nstructure of tasks \nin a project phase \nSimplified repre- \nsentation of the \nstock and flow \nstructure of a \nphase in the pulp \nmill project model. \nDeterminants of \nthe flows and cou- \nplings among the \ndifferent phases \nare not shown. \nPart I1 Tools for Systems Thinking \nphase, worker productivity, fatigue levels, error rates, and costs. The stock and \nflow structure for tasks within a phase models the progression of tasks from base- \nwork through completion (Figure 6-14). In general the tasks to be completed in a \nphase can only be done as upstream tasks upon which they depend are completed \n(the rate at which basework tasks become available). For example, the reactor ves- \nsels cannot be erected on site until their foundations are completed. Likewise, not \nall tasks within a given phase can be done concurrently. For example, the detailed \ndesign of conveyors and pipelines between the chippers, reactor vessels, and paper \nmachines cannot be done until the high-level physical design of the plant is com- \npleted. These within- and between-phase dependencies were modeled explicitly. \nThe flow of work from the stock of tasks awaiting completion to the stock of tasks \nrequiring rework represents those tasks completed incorrectly or rendered obsolete \nby changes in other subsystems. Generally, errors are not detected immediately and \nthe delay in the discovery of rework can be substantial, as when a design error is \nnot detected until construction in the field is underway. The discovery of rework \nmoves tasks thought to be complete back into the stock of tasks awaiting comple- \ntion (see Ford and Sterman 1998b for a detailed and fully documented model of a \nmultiphase project similar to the one used here; see also the shipbuilding project \nmodel described in section 2.3). \nThe model was substantially simpler than the client firm’s detailed project \nplanning model, which included literally thousands of individual activities (high \ndetail complexity) but no feedback loops (no dynamic complexity). It was disag- \ngregated enough to capture important interdependencies among design, procure- \nment, and construction activities and between construction and the various types of \nBasework \nTasks Awaiting \nGo-Ahead \nBasework \nTasks Given \nGo-Ahead \nDetection of \nRequired Rework \nUndiscovered \nRework \nTasks \nAwaiting \nComoletion \nI\\ \nTasks Apparently \nCompletion \nRequiring Rework \n& \nTask \nCompleted \n7\n,\n \nI \nTasks \nCompleted \n","page_start":245,"page_end":245,"token_count":542,"section_type":"other","chapter_number":7,"chapter_title":"Dynamics of Stocks and Flows","chunk_index":300}
{"chunk_id":"8ef02935ea4366c2","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"Chapter 6 Stocks and Flows \n221 \nequipment. The model could capture shifts in the critical path that might result \nfrom policies accelerating the fabrication of the reactor vessels, a policy favored by \nsome client team members. \nIt is important to note that the process of developing the final level of aggre- \ngation involved a number of iterations and revisions. And though the model repre- \nsents the project at a high level of aggregation, the modeling team developed many \nmore detailed diagrams. These more detailed maps helped the modeler and client \nteam discover flaws in their thinlung, estimate parameters better, and deepen their \nunderstanding of the process. And they developed confidence that the more aggre- \ngate representation in the simulation model was acceptable for their purpose so \nthese more detailed stock and flow structures did not have to be incorporated into \nthe model. \nThe level of detail selected also permitted the model to be calibrated against a \nwide range of data collected on one of the company’s current EPC projects. The \nmodel successfully (that is, to the satisfaction of the client) reproduced all relevant \nproject activities, including the various workforces and labor hours, overtime and \nrework rates, purchase order volumes and revision rates, vendor shipments, and the \nprogress of vessel erection and construction (Figure 6-15 shows an example). \nWhile the clients prefer not to disclose the details of policy recommendations, \nthey viewed the model as credible and useful and developed confidence, shared \namong the team, that the model did a good job of representing their EPC projects. \nThey used the model to analyze many policies and identified several which, while \npreviously appearing to be desirable, in fact generated harmful side effects. The \nmodel also helped identify policies that reduced project delivery times by at least \n30% within a few years. Several of the policies were not apparent to the client team \nor were hotly debated prior to the modeling effort. The modeling process helped \nbuild understanding of and consensus around these controversial initiatives, help- \ning the firm successfully implement many of the recommendations. \nFIGURE 6-1 5 !Sample comparison of historical and simulated behavior of the pulp mill model \nP&E = process and equipment. \n1 Cum. P&E Design Labor Hours \n1 Cum. Construction Labor Hours \n---- Actual \n- \nSimulated \n---- Actual \n- \nSimulated \n- \nSimulated \n- \nSimulated \n0 \n20 \n40 \n60 \n80 \n100 \n0 \n20 \n40 \n60 \n80 \n100 \nTime units \nTime units \nNote: Time is expressed as time units to protect client confidential information. \nSource: Homer et al. (1 993). \n","page_start":246,"page_end":246,"token_count":558,"section_type":"other","chapter_number":7,"chapter_title":"Dynamics of Stocks and Flows","chunk_index":301}
{"chunk_id":"1b75aabf9062d31c","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"222 \nPart I1 Tools for Systems Thinking \n6.3.5 \nSetting the Model Boundary: \n“Challenging the Clouds” \nMapping the stock and flow structure of a system involves important decisions \nabout the boundary of the model. In reality, flows of material, people, and money \ninto a stock have to come from somewhere; the flows out have to go somewhere. \nTo keep your models manageable, you must truncate these chains using sources \nand sinks, represented in the stock and flow maps by ‘‘clouds’’; see Figure 6-1. \nSources and sinks represent the stocks supplying material to or absorbing material \nfrom the modeled system. Sources and sinks are assumed to have infinite capacity \nand can never constrain the flows they support. In the real world, the stocks sup- \nplying or absorbing flows have finite capacity and do influence the flows. When \nyou truncate a stock and flow chain with a cloud you are setting the boundary of \nthe model-stocks and flows beyond this point are ignored; you exclude all possi- \nble feedbacks from or interactions with the stocks outside the boundary. \nAs a modeler you must critically examine these boundary assumptions; you \nmust, in the words of Barry Richmond (1993, p. 132), “challenge the clouds.” Is it \nappropriate for your purpose to exclude the stocks outside the boundary of the \nmodel? What feedbacks ignored by your model might exist in the real world, and \nmight they affect your policy recommendations? Can the sources for the flows be \ndepleted and constrain the inflow? Can the sinks be filled and block the outflows, \nbacking up the system like a clogged drain? \nConsider the automobile industry. A stock and flow map for automobile pro- \nduction might begin with production starts, WIP inventory, production, finished in- \nventory, and shipments (Figure 6-16). Drawing the map with a source for the \nproduction start flow presumes that the supply of parts is unlimited and can never \nconstrain the production start rate. Likewise, because shipments flow to a sink, the \nmodeler has assumed stocks of product in the hands of dealers and customers have \nno effect on shipments. In challenging the clouds you ask whether these assump- \ntions are reasonable. For the auto industry they are not. Production starts require \nthe automaker to have an adequate stock of parts. Yet parts stocks may easily be \ndepleted. Suppliers cannot respond instantly to changes in parts orders. Large or- \nders may outstrip supplier capacity, leading to shortages. A strike at a supplier may \ninterrupt the flow of parts to the firm. At the other end, shipments of new cars to \ndealers depend on the size of dealer stocks. Dealers generally try to maintain about \n40 to 60 days of inventory on their lots; this is enough to provide good selection for \nconsumers without carrying excessive and costly inventory. If stocks are low rela- \ntive to their targets, dealers order more from the manufacturers; if stocks are high, \nthey cut back. Figure 6-17 expands the model boundary to capture these effects. ","page_start":247,"page_end":247,"token_count":653,"section_type":"other","chapter_number":7,"chapter_title":"Dynamics of Stocks and Flows","chunk_index":302}
{"chunk_id":"5da68729624cbe1d","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"dealers depend on the size of dealer stocks. Dealers generally try to maintain about \n40 to 60 days of inventory on their lots; this is enough to provide good selection for \nconsumers without carrying excessive and costly inventory. If stocks are low rela- \ntive to their targets, dealers order more from the manufacturers; if stocks are high, \nthey cut back. Figure 6-17 expands the model boundary to capture these effects. \nThe model now represents three distinct organizational entities-suppliers, manu- \nfacturers, and dealers. The inventory of parts held by the manufacturer is now ex- \nplicit. The supplier has the same basic structure as the automaker: a stock of \nfinished inventory and a stock of work in process. At the shipment end, manufac- \nturer shipments no longer disappear into a sink but flow into dealer stocks, allow- \ning you to model the purchase rate as a function of the dealer inventory and sales \nto customers. ","page_start":247,"page_end":247,"token_count":204,"section_type":"other","chapter_number":7,"chapter_title":"Dynamics of Stocks and Flows","chunk_index":303}
{"chunk_id":"7bd4fb935aa24c3c","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"Chapter 6 Stocks and Flows \n223 \nFIGURE 6-1 6 \ninitial stock and \nflow map for \nthe automobile \nindustry, showing \nthe model \nboundary \nThe sources arid \nsinks for the \nflows through \nthe system are \nassumed to be \ninfinite and can \nhave no impact on \nthe dynamics. \nSource: \nUnlimited \nMaterial 0 \nSupply of 1 \nModel \nBoundary \nSink: 1 \nUnlimited \nAbsorption \nCapacity \nYou could and should continue to challenge the boundary of the model. The \nmodel now allows you to represent supplier order processing, inventory manage- \nment, and delivery, including the possibility that suppliers can become a bottleneck \nand starve automobile production. But now the suppliers are assumed to have un- \nlimited parts and raw materials availability. Is this appropriate? It depends on the \nmodel purpose. You could continue to expand the model boundary by adding the \nsuppliers to the suppliers, and their suppliers, and so on, until you reached the point \nwhere it is acceptable to assume that the supply of materials to the farthest up- \nstream supplier is unlimited. Alternatively, you could represent the entire upstream \nsupply chain by a single aggregate supplier stage. \nThe map shown in Figure 6-17 also assumes that dealer sales flow into a sink \nso there is no feedback from the stock of cars on the road to purchases of new cars. \nThis is obviously a bad assumption: Sales of new cars depend on the number and \nage of the cars people already have relative to their needs. People who have just ac- \nquired a new car are unlikely to buy another for several years, until their loan is \npaid off, their lease expires, or their car is involved in an accident and must be re- \nplaced (see section 2.2). Figure 6-18 expands the downstream end of the stock and \nflow map to include the stock of cars on the road. \nYou can continue to challenge the model boundary. What happens to the \ncars when they are scrapped? In the current map, they simply disappear. In reality, \nthey don’t. In North America some 10 to 12 million vehicles are scrapped per \nyear. Roughly 94% are shredded and the steel and some nonferrous metals are \n","page_start":248,"page_end":248,"token_count":483,"section_type":"other","chapter_number":7,"chapter_title":"Dynamics of Stocks and Flows","chunk_index":304}
{"chunk_id":"360a648e2eb52b05","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"224 \nFIGURE 6-17 \nChallenging the \nclouds \nAdding a supplier \nand dealer sector \nto the stock and \nflow chain for \nautomobile pro- \nduction. Rectan- \ngles with rounded \ncorners denote \nthe boundaries \nbetween different \norganizational en- \ntities and decision- \nmaking units. \nPart I1 Tools for Systems Thinking \nSupplier \nStarts \nC.3 \nProduction \nSupplier \nWIP \nSupplier \nProduction \nSupplier \nInventory \nSupplier \nSupplier \n~ \nSector \nm \nInventory \nProduction \nStarts \n$ Production \nStocks \nNew Car \nSales \nManufacturer \nSector \nDealer \nSector \nrecovered, one of the highest recycling fractions of any industry. However, some \ncars end up abandoned as dangerous eyesores on the side of the road. And much of \nthe plastic, glass, and other nonmetal materials end up in landfills, constituting a \nsignificant source of pollution (more than two billion discarded tires, most sitting \nin huge piles across the country, have already accumulated in the US). \n","page_start":249,"page_end":249,"token_count":228,"section_type":"other","chapter_number":7,"chapter_title":"Dynamics of Stocks and Flows","chunk_index":305}
{"chunk_id":"0808257936073548","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"FIGURE 6-18 \nExpanded \nautomobile model \nThe boundary now \ninclludes the stock \nof cars on the \nroad, which feeds \nback to influence \nsales of new cairs. \nChapter 6 Stocks and Flows \nShipments \n225 \nCars on \nthe Road \nScrap \nDealer \nSector \nHousehold \nSector \n6.3.6 \nSystem Dynamics in Action: \nAutomobile Recycling \nBy the mid 1990s, as landfills filled and environmental awareness grew, pressure \nbuilt to recycle more of the material in cars. Germany debated a law that would re- \nquire auto manufacturers to take back their old cars when people deregistered \nthem. Pushed by these forces, the auto industry, first in Europe and then in the US, \nbegan to study ways to increase the recovery of parts and the recycling of materi- \nals from cars. \nPave1 Zamudio-Ramirez (1996) modeled part recovery and the materials recy- \ncling in the US auto industry to help the industry think about a future of enhanced \nauto recycling. Figure 6-19 shows a simplified stock and flow structure adapted \nfrom the model. Old or wrecked cars can either be scrapped legally (sold to a junk- \nyard or dismantler) or illegally abandoned. The stock of abandoned, often burned- \nout, cars is a blight on the landscape and significant source of pollution. There are \ntwo outflows from the stock of illegally abandoned cars: Dismantlers will process \nthem if the value of the recoverable parts and materials is high enough. Alterna- \ntively, illegally dumped cars can be collected (say by local governments) and taken \nto shredders for proper disposal. Both these flows are relatively small, so the stock \nof abandoned cars can build up to high levels even if the abandonment rate is low. \nCars held in the dismantlers’ inventories are stripped of those parts whose \nvalue exceeds the cost of recovery. These parts enter a used parts stock and are \nthen sold to repair shops and used to replace worn or damaged parts on operating \ncars. In this map, the part usage rate flows into a sink. In actuality, these parts are \ninstalled in cars still on the road and eventually flow again through the scrap or \nabandonment rate. Since the number of recovered parts is very small relative to the \ntotal flow of materials through the system, this omission is probably reasonable. \n","page_start":250,"page_end":250,"token_count":516,"section_type":"other","chapter_number":7,"chapter_title":"Dynamics of Stocks and Flows","chunk_index":306}
{"chunk_id":"75d9ba7fd531f474","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"226 \nAuto \nMaterials in 4 \nPart I1 Tools for Systems Thinking \nShredder \nInventory 4 \nT 7  \nL1 \nFIGURE 6-1 9 Stock and flow map for a model of automobile recycling \nThe stock and flow structure for the development of new vehicle platforms, defining the mass and \nmaterials composition of cars and level of design for disassembly, is not shown. The model includes a \nparallel stock and flow structure (co-flow) tracking each of these properties as vehicles age and are \neventually retired, dismantled, and shredded. See chapter 12. \nNew Car \nSales Rate \nRate \nSales to \nMaterials \nProcessors \nMaterials \nInventor \nMaterials \nUsage \nRate \n","page_start":251,"page_end":251,"token_count":154,"section_type":"other","chapter_number":7,"chapter_title":"Dynamics of Stocks and Flows","chunk_index":307}
{"chunk_id":"515ecf70a6f6572a","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"Chapter 6 Stocks and Flows \n227 \nAfter all parts worth recovering are removed, the gutted car, now called a hulk, \nis sold to a shredder. In the mid 1990s there were about 200 shredders in the US \nwho processed roughly 94% of all deregistered cars. After shredding, the valuable \nmaterials (principally steel and some nonferrous metals) are separated out for re- \ncycling. If the prices of the recovered materials don’t justify the cost, shredders can \ntake hulks directly to a landfill and cut their purchases from dismantlers. What re- \nmains after shredding and separation is a mixture of plastics, glass, elastomers, and \nsome unrecovered metal called automotive shredder residue (ASR) or “fluff,” \nwhich is then landfilled. ASR is one of the major environmental concerns gener- \nated by the disposal of old cars. \nThe recyclable materials accumulate in an inventory and are eventually sold to \nmaterials processors such as steel mills. The inventory of raw materials is then \nused to manufacture new products, including automobiles, thus helping to create a \nclosed material flow and cutting the use of nonrenewable resources. As in the case \nof parts, the materials usage rate flows into a sink since the flow of recovered ma- \nterials relative to the total flow of virgin materials is small. \nZamudio-Ramirez’s model included a rich feedback structure representing the \nbehavior of the various actors in the system, including the automakers, car owners, \ndismantlers, and shredders. Markets for recovered materials were explicit. The \nstock and flow structure for autos began at the design stage for new models and \nplatforms and tracked key properties of the cars including their mass, materials \ncomposition (ferrous, nonferrous, plastics), and the level of design for disassembly \nbuilt into the design. These attributes were tracked as the cars embodying them \nmoved from the design stage to market, age, and are then retired, dismantled, and \nshredded. \nTo gather the required data, Zamudio-Ramirez conducted interviews with var- \nious actors, including carmakers, dismantlers, shredders, and industry analysts and \nmade extensive use of various auto and recycling industry databases. Some of the \ndata required, such as age-dependent scrap rates for cars, were relatively easy to \ngather. Other key parameters were not. Two critical relationships in the model are \nthe supply curves for recovered parts and recovered materials. That is, how will the \nnumber of parts recovered by dismantlers vary as the price they can get and the \ncosts of recovery vary? \nEstimating the parts supply curve is a daunting problem. The principal cost of \nrecovery is the labor time required to remove a part. But the time required to re- \nmove a given part depends on how many other parts must be removed first. These \nprecedence relationships depend on the design of the car and the value of the in- \ntervening parts (can the seat be ripped out quickly to get at a valuable part under it ","page_start":252,"page_end":252,"token_count":657,"section_type":"other","chapter_number":7,"chapter_title":"Dynamics of Stocks and Flows","chunk_index":308}
{"chunk_id":"a88410274d5a7efb","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"costs of recovery vary? \nEstimating the parts supply curve is a daunting problem. The principal cost of \nrecovery is the labor time required to remove a part. But the time required to re- \nmove a given part depends on how many other parts must be removed first. These \nprecedence relationships depend on the design of the car and the value of the in- \ntervening parts (can the seat be ripped out quickly to get at a valuable part under it \nor must it be removed carefully? Should workers get at a part from in front or be- \nhind?). To estimate these relationships Zamudio-Ramirez worked at the Vehicle \nRecycling Partnership, a consortium of the Big Three US automakers, dismantlers, \nand the recycling industry. The Vehicle Recycling Partnership assembled a com- \nprehensive database of part removal times by completely disassembling a variety \nof late model cars. Zamudio-Ramirez and his colleague Andrew Spicer then de- \nveloped an optimization model to estimate the supply curve for parts recovery as \nfunctions of part and materials prices, labor costs, and the design of the vehicles. \nThe optimization model determined the number of parts worth recovering and the ","page_start":252,"page_end":252,"token_count":246,"section_type":"other","chapter_number":7,"chapter_title":"Dynamics of Stocks and Flows","chunk_index":309}
{"chunk_id":"2a1af953dcdf3336","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"228 \nPart I1 Tools for Systems Thinking \noptimal dismantling order for any set of prices, labor costs, and design parame- \nters-the supply curve for recovered parts. The results of the optimization model \nwere then embedded in the simulation model. As the design parameters for cars \nchange and the removal time for key parts falls, the estimated supply curve re- \nsponds by realistically increasing the number and types of parts recovered. \nThough the stock and flow structure in Figure 6-19 is simplified and does not \nshow any of the feedback structure determining the various flows from the full \nmodel, it illustrates the response of the automobile and materials markets to poli- \ncies designed to increase recycling of cars. \nFirst consider the effect of a design for disassembly (DFD) program designed \nto increase the part recovery rate and reduce the amount of fluff ending up in land- \nfills. DFD can reduce the labor cost of part recovery through better design, differ- \nent choice of part fasteners, improved selection and labeling of materials, and other \ntechniques. The first effect is ... nothing. There is a lag of at least several years be- \ntween the time an automaker starts a DFD program and the time the first cars de- \nsigned to those specs roll off the assembly line. The average car in the United \nStates stays on the road for about a decade, and new cars have very low scrap rates \n(most of these are wrecks declared total losses by insurance companies). Only af- \nter a delay of many years will the stock of recycling-ready cars be large enough \nand old enough for them to constitute a significant fraction of the scrapped cars \npurchased by dismantlers. \nWhat then happens? Manufacturers expected DFD would eventually cause \npart and material recovery to rise, permanently reducing the flow of materials to \nlandfills. Instead, the model suggests the next effect will be a glut of used parts, as \nthe part recovery rate rises above the used parts usage rate. As parts inventories \nbuild, the price dismantlers can get for used parts falls. The number of parts that \ncan be economically recovered drops, and the dismantling rate drops back. Prices \ncontinue to fall until the number of parts recovered falls enough to balance the \nused parts usage rate. The part usage rate may rise, stimulated by lower prices, but \nunless the demand for used parts is highly price elastic, the part recovery rate will \ndrop back close to its original rate prior to DFD. The demand for used parts is \nlikely to be rather insensitive to price. Automakers and third-party producers of re- \nplacement parts will be reluctant to lose the lucrative parts market and may be able \nto prohibit the use of recovered parts by authorized service centers or for warranty \nrepairs or compete on price. If the demand for used parts is inelastic, the principal \neffect of DFD might simply be to depress the price of used parts, offsetting most \nof the benefit of improved design. \nNow consider the effect of a trend toward smaller, lighter cars with signifi- \ncantly higher plastic content and less steel and metal. Such changes are promoted ","page_start":253,"page_end":253,"token_count":657,"section_type":"other","chapter_number":7,"chapter_title":"Dynamics of Stocks and Flows","chunk_index":310}
{"chunk_id":"a88f19e2f973d477","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"to prohibit the use of recovered parts by authorized service centers or for warranty \nrepairs or compete on price. If the demand for used parts is inelastic, the principal \neffect of DFD might simply be to depress the price of used parts, offsetting most \nof the benefit of improved design. \nNow consider the effect of a trend toward smaller, lighter cars with signifi- \ncantly higher plastic content and less steel and metal. Such changes are promoted \nto improve fuel economy, increase part recoverability, and decrease the quantity of \nfluff ending up in landfills. However, the stock and flow structure may cause the \nimpact of such policies to be counter to their intent. The auto industry is a signifi- \ncant consumer of steel. When new cars begin to use less, the recovery of steel from \nshredding of old hulks continues at the prior rate. The price of scrap metal will fall, \nreducing shredder profitability. The number of hulks shredded and the quantity of ","page_start":253,"page_end":253,"token_count":211,"section_type":"other","chapter_number":7,"chapter_title":"Dynamics of Stocks and Flows","chunk_index":311}
{"chunk_id":"9af71dad8a7dc624","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"Chapter 6 Stocks and Flows \n229 \nmetals recovered may fall, and the volume of fluff disposed in landfills may actu- \nally rise. Further, once the scrap rate of cars with reduced steel content increases, \nshredder profit can fall further. With less steel and nonferrous content, shredder \nrevenue per hulk falls, while the fixed costs of shredding remain the same. Zamu- \ndio-Ramirez found that a sustained increase in the plastic content of cars, as ex- \npected, would increase the fraction of materials recovered by dismantlers. But cars \nwith less recyclable metal could also depress hulk prices enough to cut shredder \nprofit, decrease the shredding rate, and actually increase the number of abandoned \ncars and the amount of fluff buried in landfills. \nThe stock and flow map helps illustrate the long delays between a change in \nthe design of cars and the flows of old cars to landfills. By making the stocks of re- \ncovered parts and materials explicit, it is easier to see that there is imperfect coor- \ndination between inflows and outflows, leading to potential imbalances and \nchanges in prices that invalidate the assumptions behind recycling programs. In- \nstitutional structures such as requirements that service centers use new replacement \nparts can overwhelm the logic of the market. Market mechanisms, even when pre- \nsent, are not likely to work smoothly, possibly leading to instability and ineffi- \nciency. Similar dynamics have already been observed in the market for recycled \npaper (Taylor 1999). Supply side steps to increase recyclability alone are not likely \nto be effective unless matched by policies to increase the usage of recovered parts \nand materials. The collection of recyclable materials and the actual recycling of \nthose materials aren’t the same thing. \n6.4 SUMMARY \nThis chapter introduced the stock and flow concept. Stocks accumulate their in- \nflows less their outflows. Stocks are the states of the system upon which decisions \nand actions are based, are the source of inertia and memory in systems, create de- \nlays, and generate disequilibrium dynamics by decoupling rates of flow. The dia- \ngramming notation for stocks and flows can be used with a wide range of \naudiences and makes it easier to relate a causal diagram to the dynamics of the sys- \ntem. Stocks accumulate (integrate) their inflows less their outflows. Equivalently, \nthe rate of change of a stock is the total inflow less the total outflow. Thus a stock \nand flow map corresponds exactly to a system of integral or differential equations. \nHowever, stock and flow maps are much easier to work with and explain. \nThere are several ways to identify the stocks in systems. In the snapshot test \nyou imagine freezing the system at a moment of time-the measurable quantities \n(physical, informational, and psychological) are the stocks, while flows are not in- \nstantaneously observable or measurable. Units of measure can also help identify \nstocks and flows. If a stock is measured in units, its flows must be measured in \nunits per time period. ","page_start":254,"page_end":254,"token_count":652,"section_type":"other","chapter_number":7,"chapter_title":"Dynamics of Stocks and Flows","chunk_index":312}
{"chunk_id":"f12372a39dadbf37","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"There are several ways to identify the stocks in systems. In the snapshot test \nyou imagine freezing the system at a moment of time-the measurable quantities \n(physical, informational, and psychological) are the stocks, while flows are not in- \nstantaneously observable or measurable. Units of measure can also help identify \nstocks and flows. If a stock is measured in units, its flows must be measured in \nunits per time period. \nStocks existing in series in a network can be aggregated together if they are \nshort-lived relative to the time horizon and dynamics of interest. Multiple parallel \nactivities can be aggregated into a single stock and flow network if the activities \nare governed by similar decision processes and utilize similar resources and if the ","page_start":254,"page_end":254,"token_count":148,"section_type":"other","chapter_number":7,"chapter_title":"Dynamics of Stocks and Flows","chunk_index":313}
{"chunk_id":"5a5ec0e6aeb0d268","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"230 \nPart I1 Tools for Systems Thinhng \nresidence times of the items in the stocks is similar enough for the purpose of your \nmodel. \nSources and sinks for the flows in a system have infinite capacity, unlike \nstocks in the real world, and thus represent the boundary of the model. Modelers \nshould always challenge these boundary assumptions, asking if the assumption of \ninfinite supply for sources and infinite absorption capacity for sinks is appropriate \nrelative to the model purpose. \n","page_start":255,"page_end":255,"token_count":100,"section_type":"other","chapter_number":7,"chapter_title":"Dynamics of Stocks and Flows","chunk_index":314}
{"chunk_id":"5e65000b5d369c4c","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"7 \nDynamics of Stocks and Flows \nNature laughs at the dificulties of integration. \n-Pierre-Simon de Laplace (1749-1827) \nThe successes of the differential equation paradigm were impressive and \nextensive. Many problems, including basic and important ones, led to \nequations that could be solved. A process of self-selection set in, wheveby \nequations that could not be solved were automatically of less interest than \nthose that could. \n-Ian \nStewart (1989, p. 39). \nChapter 6 introduced the stock and flow concept and techniques for mapping the \nstock and flow networks of systems. This chapter explores the behavior of stocks \nand flows. Given the dynamics of the flows, what is the behavior of the stock? \nFrom the dynamics of the stock, can you infer the behavior of the flows? These \ntasks are equivalent to integrating the flows to yield the stock and differentiating \nthe stock to yield its net rate of change. For people who have never studied calcu- \nlus, these concepts can seem daunting. In fact, relating the dynamics of stocks and \nflows is actually quite intuitive; it is the use of unfamiliar notation and a focus on \nanalytic solutions that deters many people from study of calculus. \nWhat if you have a strong background in calculus and differential equations? \nIt is generally not possible to solve even small models analytically due to their high \norder and nonlinearities, so the mathematical tools many people have studied are \nof little direct use. If you have more mathematical background you will find this \nchapter straightforward but should still do the graphical integration examples and \nchallenges to be sure your intuitive understanding is as solid as your technical \n231 \n","page_start":256,"page_end":256,"token_count":359,"section_type":"other","chapter_number":7,"chapter_title":"Dynamics of Stocks and Flows","chunk_index":315}
{"chunk_id":"c02e8edb8dd934e1","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"232 \nPart I1 Tools for Systems Thinking \nknowledge. Modelers, no matter how great or small their training in mathematics, \nneed to be able to relate the behavior of stocks and flows intuitively, using graphi- \ncal and other nonmathematical techniques. The chapter also illustrates how stock \nand flow dynamics give insight into two important policy issues: global warming \nand the war on drugs. \n7.1 \nRELATIONSHIP BETWEEN STOCKS AND FLOWS \nRecall the basic definitions of stocks and flows: the net rate of change of a stock is \nthe sum of all its inflows less the sum of all its outflows. Stocks accumulate the net \nrate of change. Mathematically, stocks integrate their net flows; the net flow is the \nderivative of the stock. \n7.1 .I \nStatic and Dynamic Equilibrium \nA stock is in equilibrium when it is unchanging (a system is in equilibrium when \nall its stocks are unchanging). For a stock to be in equilibrium the net rate of \nchange must be zero, implying the total inflow is just balanced by the total outflow. \nIf water drains out of your tub at exactly the rate it flows in, the quantity of water \nin the tub will remain constant and the tub is in equilibrium. Such a state is termed \na dynamic equilibrium since the water in the tub is always changing. Static equi- \nlibrium arises when all flows into and out of a stock are zero. Here not only is the \ntotal volume of water in the tub constant, but the tub contains the same water, hour \nafter hour. The number of members of the US senate has been in dynamic equilib- \nrium since 1959 when Hawaii joined the union: the total number of senators re- \nmains constant at 100 even as the membership turns over (albeit slowly). The stock \nof known Bach cantatas is in static equilibrium since we are unlikely to lose the \nones we know of, the odds of discovering previously unknown cantatas are remote, \nand Bach can’t write any new ones. \n7.1.2 Calculus without Mathematics \nTo understand dynamics, you must be able to relate the behavior of the stocks and \nflows in a system. Given the flows into a stock, what must the behavior of the \nstock be? Given the behavior of the stock, what must the net rate of change have \nbeen? These questions are the domain of the calculus. Calculus provides rules to \nanswer these questions mathematically provided you can characterize the behavior \nof the stocks or flows as mathematical functions. Calculus is one of the most beau- \ntiful and useful branches of mathematics but one far too few have studied. Happily, \nthe intuition behind the relationship between stocks and flows is straightforward \nand does not require any mathematics. If you are shown a graph of the behavior of \nthe flows over time, you can always infer the behavior of the stock. This process is \nknown as graphical integration. Likewise, from the trajectory of the stock you can \nalways infer its net rate of change, a process known as graphical diflerentiation. ","page_start":257,"page_end":257,"token_count":652,"section_type":"other","chapter_number":7,"chapter_title":"Dynamics of Stocks and Flows","chunk_index":316}
{"chunk_id":"af47450f4767d73d","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"the intuition behind the relationship between stocks and flows is straightforward \nand does not require any mathematics. If you are shown a graph of the behavior of \nthe flows over time, you can always infer the behavior of the stock. This process is \nknown as graphical integration. Likewise, from the trajectory of the stock you can \nalways infer its net rate of change, a process known as graphical diflerentiation. \nIntegration and differentiation are the two fundamental operations in the calculus. \nTable 7-1 provides the definitions graphically and in plain language. \nThe amount added to a stock during any time interval is the area bounded by \nthe curve defining its net rate of change. Why? Consider the bathtub metaphor ","page_start":257,"page_end":257,"token_count":145,"section_type":"other","chapter_number":7,"chapter_title":"Dynamics of Stocks and Flows","chunk_index":317}
{"chunk_id":"937cc036b452721b","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"Chapter 7 Dynamics of Stocks and Flows \n233 \nTABLE 7-1 \nIntegration and differentiation: definitions and examples \nIntegration \nDifferentiation \nStocks accurriulate or integrate their net flow. \nThe quantity added to a stock over any interval \nis the area bounded by the graph of the net rate \nbetween the start and end of the interval. The \nfinal value of Ihe stock is the initial value plus the \narea under the net rate curve between the initial \nand final times. \nIn the example below, the value of the stock at \ntime tl = Si. E\\dding the area under the net rate \ncurve between times tl and t2 increases the \nStock to S2. \nThe slope of a line tangent to any point of the \ntrajectory of the stock equals the net rate of \nchange for the stock at that point. The slope of \nthe stock trajectory is the derivative of the stock. \nIn the example below, the slope of the stock \ntrajectory at time t, is R1, so the net rate at ti = \nR1. At time t2, the slope of the stock is larger, so \nthe net rate at t, = R2 is greater than R1. The \nstock rises at an increasing rate, so the net rate \nis positive and increasing. \nn \nu) \nc \nS \nY \n0 \nv) \ne s, \nB s, \nv \nChange in Stock \nh \nQ) \nR, \nC T -  \nQ) \nR, \nt;;g \n= S  \nv \n0 \nn \nu) \nC \nS \nc \n.- \nU \n./. \n/ \n~ in Stock \nI ..... . . -7 \nY 8 \n3i \ntl \nt2 \nagain. How much water is added to the tub in any time interval, such as between \ntime tl and t, in Table 7-l? Divide the entire interval into a number of smaller seg- \nments, each small enough that the net flow of water is not changing significantly \nduring the segment (Figure 7-1). The length of each segment is called “dt” for \n“delta time.” How much water flows in during each small interval of duration dt? \nThe quantity added is the net flow during the interval, say R, multiplied by \nthe length of the interval, that is, the area of the rectangle dt periods wide and \nR unitslperiod high: \nQuantity added during interval of length dt = \nR \n* \ndt \n(Units) \n= (UnitsRime) (Time) \n(7-1) \nNote the units of measure: The flow in units per time, accumulated for a period of \ntime yields the quantity added to the stock. \nTo use a concrete example, suppose tl = 1 minute and t2 = 2 minutes. The \nquestion is how much water flows into the tub during that minute. Divide the \n","page_start":258,"page_end":258,"token_count":619,"section_type":"other","chapter_number":7,"chapter_title":"Dynamics of Stocks and Flows","chunk_index":318}
{"chunk_id":"dbd2881d82d9bfe2","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"234 \nPart I1 Tools for Systems Thinking \nFIGURE 7-1 \nI \nGraphical \nintegration \nDivide time into \nsmall intervals of \nlength dt. Each \nrectangle repre- \nsents the amount \nadded during the \ninterval dt, assum- \ning the net rate Ri \nat that time re- \nmains constant \nduring the interval. \nThe area of each \nrectangle is Ridt. \nThe total added to \nthe stock between \nt, and t2 is then the \nsum of the areas \nof the rectangles. \nDividing time into \nsmaller increments \nincreases the \naccuracy of the \napproxi mation. \nminute up into six 10-second intervals and assume the flow is constant throughout \neach of these intervals. If at the start of the first interval the flow was 6 liters per \nminute (that is, 0.1 liters/second), then the amount added would be (0.1 literdsec- \nond)(lO seconds) = 1 liter. At the start of the second 10-second interval, the flow \nhas increased, perhaps to 7 literdminute, or about 0.117 literdsecond. The area of \nthe second rectangle is then 1.17 liters. Calculating the area of all six rectangles \nand adding them together gives an approximation of the total volume of water \nadded during the minute. The approximation isn't perfect because the net flow is \nactually changing during each 6-second interval. In Figure 7-1, the flow is actually \nrising, so the calculated value of the stock will be too small. To increase the accu- \nracy of the approximation, simply divide time into even finer intervals, increasing \nthe number of rectangles. Computer simulations integrate the stocks in the model \nin precisely this fashion; the modeler must choose the time step dt so that the ap- \nproximation is acceptable for the purp0se.l In the limit, as the time interval be- \ncomes infinitesimal, the sum of the areas of all the rectangles becomes equal to the \ntotal area under the net rate curve. Calculus provides formulas that give the exact \narea under the net rate-provided the net rate can be expressed as a certain type of \nmathematical function. But whether the net rate can be integrated analytically or \nnot, the amount added to a stock is always the area under the net rate. Graphical in- \ntegration is the process of estimating that area from a graph of the net rate. \n7.1.3 \nGraphical Integration \nTo illustrate graphical integration, consider the most basic stock and flow system: \na single stock with one inflow and one outflow. Assume the flows are exogenous- \nthere are no feedbacks from the stock to either flow. Suppose the outflow from the \n'The procedure described above is known as Euler integration and is the most commonly used \nmethod for numerical simulation. Other methods such as Runge-Kutta integration use more sophis- \nticated methods to estimate the area and select the timt step. See Appendix A. \n","page_start":259,"page_end":259,"token_count":653,"section_type":"other","chapter_number":7,"chapter_title":"Dynamics of Stocks and Flows","chunk_index":319}
{"chunk_id":"8fdff96de91b13c7","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"Chapter 7 Dynamics of Stocks and Flows \n235 \nFIGURE 7-2 \nGraphical \nintegration: \nexample \nWhile the rate \nsteps up and steps \ndown, the stock \nrises and remains \nat a higher level. \nNote the different \nunits of rneasure \nfor the rate and \nstock. \n400 7 \n0 '  \nI \nI \nI \n0 \n10 \n20 \n30 \nTime (seconds) \nstock is zero. Suppose also that the inflow to the stock follows the pattern shown \nin Figure 7-2. The inflow begins at zero. At time 10 the inflow suddenly increases \nto 20 unitdsecond, remains at that level for 10 seconds, then steps back down to \nzero. If the initial level of the stock is 100 units, how much is in the stock at time \n30, and what is the behavior of the stock over time? \nTable 7-2 shows the steps involved in graphical integration. Applying these \nsteps to Figure 7-2, first make a set of axes for the stock, lined up under the graph \nfor the flows. Next calculate the net rate. Since there is only one inflow and one \noutflow, and since the outflow is zero at all times, the net rate of change of the \nstock (Total Inflow - Total Outflow) simply equals the inflow. Initially, the stock \nhas a value of 100 units. Between time 0 and time 10, the net flow is zero units/ \nsecond, so the stock remains constant at its initial value. At time 10, the net rate \njumps to 20 unitshecond and remains there for 10 seconds. The amount added is \nthe area under the net rate curve (between the net rate curve and the zero line). \nSince the rate is constant, the area is a rectangle 20 unitshecond high and 10 sec- \nonds long, so the stock rises by 200 units, giving a total level of 300 units by time \n20. Because the net rate is positive and constant during this interval, the stock rises \nlinearly at a rate 20 unitshecond (the slope of the stock is 20 units/second). \nAt time 20, the inflow suddenly ceases. The net rate of change is now zero and \nremains constant, and the stock is again unchanging, though now at the level of \n300 units. \nNote how the process of accumulation creates inertia: though the rate rises and \nfalls back to its original level, the stock does not return to its original level. Instead, \nit remains at its maximum when the net rate falls back to zero. In this fashion, \nstocks provide a memory of all the past events in a system. The only way for the \nstock to fall is for the net rate to become negative (for the outflow to exceed the in- \nflow). Note also how the process of accumulation changed the shape of the input. \nThe input is a rectangular pulse with two discontinuous jumps; the output is a \nsmooth, continuous curve. \n","page_start":260,"page_end":260,"token_count":654,"section_type":"other","chapter_number":7,"chapter_title":"Dynamics of Stocks and Flows","chunk_index":320}
{"chunk_id":"884b04b7a5e84ff0","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"236 \nPart I1 Tools for Systems Thinking \nTABLE 7-2 \nSteps in graphical \nintegration \n1. Calculate and graph the total rate of inflow to the stock (the sum of all \ninflows). Calculate and graph the total rate of outflow from the stock (the \nsum of all outflows). \n2. Calculate and graph the net rate of change of the stock (the total inflow less \nthe total outflow). \n3. Make a set of axes to graph the stock. Stocks and their flows have different \nunits of measure (if a stock is measured in units its flows are measured in \nunits per time period). Therefore stocks and their flows must be graphed on \nseparate scales. Make a separate graph for the stock under the graph for \nthe flows, with the time axes lined up. \n4. Plot the initial value of the stock on the stock graph. The initial value must \nbe specified; it cannot be inferred from the net rate. \n5. Break the net flow into intervals with the same behavior and calculate the \namount added to the stock during the interval. Segments might be intervals \nin which the net rate is constant, changing linearly, or following some other \npattern. The amount added to or subtracted from the stock during a \nsegment is the area under the net rate curve during that segment. For \nexample, does the net flow remain constant from time t, to time t,? \nIf so, \nthe rate of change of the stock during that segment is constant, and the \nquantity added to the stock is the area of the rectangle defined by the net \nrate between t, and tp. If the net rate rises linearly in a segment, then the \namount added is the area of the triangle. Estimate the area under the net \nrate curve for the segment and add it to the value of the stock at the start of \nthe segment. The total is the value of the stock at the end of the segment. \nPlot this point on the graph of the stock. \n6. Sketch the trajectory of the stock between the start and end of each \nsegment. Find the value of the net rate at the beginning of the segment. \nIs it positive or negative? If the net flow is positive, the stock will be \nincreasing at that time. If the net flow is negative, the stock will be \ndecreasing. Then ask whether it is rising or falling at an increasing or \ndecreasing rate, and sketch the pattern you infer on the graph. \nIf the net rate is positive and increasing, the stock increases at an \nincreasing rate (the stock accelerates upward). \nIf the net rate is positive and decreasing, the stock increases at a \ndecreasing rate (the stock is decelerating but still moving upward). \nIf the net rate is negative and its magnitude is increasing (the net rate is \nbecoming more negative), the stock decreases at an increasing rate. \nIf the net rate is negative and its magnitude is decreasing (becoming less \nnegative), the stock decreases at a decreasing rate. ","page_start":261,"page_end":261,"token_count":637,"section_type":"other","chapter_number":7,"chapter_title":"Dynamics of Stocks and Flows","chunk_index":321}
{"chunk_id":"80f5abfd741976a3","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"increasing rate (the stock accelerates upward). \nIf the net rate is positive and decreasing, the stock increases at a \ndecreasing rate (the stock is decelerating but still moving upward). \nIf the net rate is negative and its magnitude is increasing (the net rate is \nbecoming more negative), the stock decreases at an increasing rate. \nIf the net rate is negative and its magnitude is decreasing (becoming less \nnegative), the stock decreases at a decreasing rate. \n7. Whenever the net rate is zero, the stock is unchanging. Make sure that \nyour graph of the stock shows no change in the stock everywhere the net \nrate is zero. If the net rate remains zero for some interval, the stock \nremains constant at whatever value it had when the net rate became zero. \nAt points where the net rate changes from positive to negative, the stock \nreaches a maximum as it ceases to rise and starts to fall. At points where \nthe net rate changes from negative to positive, the stock reaches a \nminimum as it ceases to fall and starts to rise. \n8. Repeat steps 5 through 7 until done. ","page_start":261,"page_end":261,"token_count":241,"section_type":"other","chapter_number":7,"chapter_title":"Dynamics of Stocks and Flows","chunk_index":322}
{"chunk_id":"f7647952e41180e1","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"Chapter 7 Dynamics of Stocks and Flows \n237 \nFIGURE 7-3 \nNote the me-quarter cycle lag between the peaks of the net flow and the peaks of the stock. \nThe accumulation process creates delays. \n200 \n150 \nc, \nS . \nE \n100 \n- \nz \nu) \nC \n3 \nu) \n5., .- \n50 \nv \nL\no\n \n-50 \n600 \n400 \n0 3 6 9 1 2  \n24 \n36 \n48 \nTime (months) \nNow consider the flows specified in the top panel of Figure 7-3. The outflow \nis constant at 100 unitdmonth, but the inflow fluctuates around an average of 100 \nwith a period of 12 months and an amplitude of +50 unitdmonth. At the start, the \ninflow is at its maximum. Assume the initial value of the stock is 500 units. \nSince the outflow is constant, the net inflow is a fluctuation with amplitude \nF50 unitdmonth and a mean of zero. The stock begins at its initial value of 500 \nunits, but since the inflow is at its maximum, the stock initially rises with a slope \nof 50 unitdmonth. However, the net flow falls over the first 3 months, so the stock \nincreases at a decreasing rate. At month 3 the net flow reaches zero, then goes neg- \native. The stock must therefore reach a maximum at month 3. The amount added \nto the stock in the first 3 months is the area under the net rate curve. It is not easy \n","page_start":262,"page_end":262,"token_count":350,"section_type":"other","chapter_number":7,"chapter_title":"Dynamics of Stocks and Flows","chunk_index":323}
{"chunk_id":"0a245f1130686691","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"238 \nPart I1 Tools for Systems Thinking \nto estimate the area from the graph because the net rate curve is constantly chang- \ning. You could estimate it by approximating the area as a set of rectangles, as de- \nscribed above, though this would take time. Using simulation to carry out the \naccumulation shows that a little less than 100 units are added to the stock by the \ntime the net rate falls to zero at month 3. \nFrom month 3 to month 6, the net rate is negative. The stock is therefore \nfalling. Just after month 3, the net rate is just barely negative, so the rate of decline \nof the stock is slight. But the magnitude of the net rate increases, so the stock falls \nat an increasing rate. At 6 months, the net rate has reached its minimum (most neg- \native) value of -50 unitslmonth. The stock is declining at its maximum rate; there \nis an inflection point in the trajectory of the stock at month 6. \nHow much did the stock lose between month 3 and month 6? Assuming the \nfluctuation in the net rate is symmetrical, the loss just balanced what was gained in \nthe first 3 months, reducing the stock back to its initial level of 500 units. \nFrom month 6 to month 9, the net flow remains negative, so the stock contin- \nues to fall, but now at a decreasing rate. By month 9 the net flow again reaches \nzero, so the stock ceases to fall and reaches its minimum. Again using the assump- \ntion of symmetry, the quantity lost from months 6 to 9 is equal to the quantity lost \nfrom months 3 to 6, so the stock falls to a level just above 400 units. \nFrom months 9 to 12 the net flow is positive, so the stock is rising. During this \ntime the net rate rises, so the stock increases at an increasing rate, ending with a \nslope of 50 unitdmonth as the net rate reaches its maximum. Again, the stock gains \nthe same amount, recovering its initial level of 500 units exactly at month 12. Be- \nyond month 12 the cycle repeats. \nThe example illustrates the way in which the process of accumulation creates \ndelays. The input to the system is a fluctuation with a 12-month period reaching its \npeak at time = 0, 12, 24, . . . months. The stock, or output of the system, also fluc- \ntuates with a 12-month period but lags behind the net inflow rate, reaching its \npeaks at t = 3, 15, 27, . . . months. The lag is precisely one-quarter cycle. The lag \narises because the stock can only decrease when the net flow is negative. If the net \nflow is positive and falls to zero, the stock increases and reaches its maximum. \nAnalytical Integration of a Fluctuation \nThe example in Figure 7-3 can be made precise using a little basic calculus. The ","page_start":263,"page_end":263,"token_count":658,"section_type":"other","chapter_number":8,"chapter_title":"Closing the Loop:","chunk_index":324}
{"chunk_id":"8bf5b85c310840bc","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"peaks at t = 3, 15, 27, . . . months. The lag is precisely one-quarter cycle. The lag \narises because the stock can only decrease when the net flow is negative. If the net \nflow is positive and falls to zero, the stock increases and reaches its maximum. \nAnalytical Integration of a Fluctuation \nThe example in Figure 7-3 can be made precise using a little basic calculus. The \nstock S is the integral of the net rate R. Assuming the net flow is a cosine with pe- \nriod 12 months and amplitude 50 units/month, R = 50cos(2d12), then \nS = Rdt = 50cos(2~t/12)dt = 50(12/21~)sin(2.rrt/12) + S, \n(7-2) \nJ\nJ\nThe stock follows a sine wave with the same period and amplitude (12/2~r) times \nthat of the net flow. The delay caused by the accumulation process is easily seen \nsince sin(0) = cos(@ - d2): \nS = 5 0 ( 1 2 / 2 ~ ) ~ 0 ~ ( 2 d 1 2  \n- ~ 1 2 )  \n+ S, \n(7-3) \nThe stock follows the same trajectory as the net flow but with a phase lag of d 2  \n(one-quarter cycle). Equation (7-2) also shows that the amplitude of the stock is \n(50 unitdmonth) * (12 months/2~) = 96 units, so the stock fluctuates between \nabout 404 and 596, as seen in the figure. ","page_start":263,"page_end":263,"token_count":367,"section_type":"other","chapter_number":8,"chapter_title":"Closing the Loop:","chunk_index":325}
{"chunk_id":"3298832142d0d85b","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"Chapter 7 Dynamics of Stocks and Flows \n239 \n7.1.4 \nGraphical Differentiation \nThe inverse of integration is differentiation, the calculation of the net rate of \nchange of a stock from its trajectory. Given a graph of a stock, it is always possi- \nble to infer the net rate of change and plot it. As in the case of integration, there are \nanalytic methods to calculate the net rate of a stock if the function describing the \nstock’s path is known. However, in most dynamic models no analytic function for \nthe stocks is known, so you must develop the skill of graphical differentiation. \nGraphical differentiation is straightforward. Simply estimate the slope of the \nstock at each point in time and plot it on a graph of the net rate. Figure 7-5 provides \nan example. \n","page_start":264,"page_end":264,"token_count":173,"section_type":"other","chapter_number":8,"chapter_title":"Closing the Loop:","chunk_index":326}
{"chunk_id":"40a0f3bcf4fdf260","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"240 \nPart I1 Tools for Systems Thinking \nFIGURE 7-5 \nGraphical \ndifferentiation \n2000 \n1750 \n1500 \n1250 \n1000 \n5 weeks \n5 weeks \nTime (weeks) \nThe initial stock is 2000 units. For the first 10 weeks the stock declines lin- \nearly, so the net rate during this interval is negative and constant. The stock falls \nfrom 2000 to 1000 units in 10 weeks, so the net rate (the slope of the stock) is \n- 100 unitdweek. At week 10 the stock suddenly starts increasing. Drawing a line \ntangent to the stock curve at time 10 gives an estimate of the slope of 200 units/ \nweek. The net rate therefore steps up from - 100 unitdweek the instant before the \nstart of week 10 to +200 unitdweek just after it starts. From weeks 10 to 20 the \nstock increases at a decreasing rate, so the net rate is positive but falling. At time \n20 the stock reaches a maximum so the net rate is zero. There are no kinks or \nbumps in the stock trajectory, implying a steady, linear decline in the net rate from \n200 units/week in week 10 to zero in week 20. From week 20 to week 30 the stock \nis falling. By week 30 it is falling rapidly; the slope of a line tangent to the stock \ntrajectory at week 30 has a slope of -200 unitdweek. Again, there are no kinks in \nthe trajectory, so the net rate declines linearly from zero in week 20 to -200 units/ \nweek in week 30. At week 30 the stock suddenly stops changing and remains con- \nstant afterwards. The net rate suddenly steps up from -200 to zero unitdweek and \nremains at zero thereafter. \nGraphical differentiation of a stock reveals only its net rate of change. If the \nstock has multiple inflows and outflows it is not possible to determine their \n","page_start":265,"page_end":265,"token_count":434,"section_type":"other","chapter_number":8,"chapter_title":"Closing the Loop:","chunk_index":327}
{"chunk_id":"37631a35f335fd13","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"Chapter 7 Dynamics of Stocks and Flows \n241 \nindividual values from the net rate alone: a firm’s stock of cash remains constant \nwhether revenues and expenditures both equal $1 million per year or $1 billion \nper year. \n7.2 \nSYSTEM DYNAMICS IN ACTION: GLOBAL WARMING \nMuch of the power of the system dynamics perspective comes from understand- \ning how the process of accumulation creates dynamics, even before considering \nthe feedbacks coupling the stocks and their flows. To illustrate, consider global \nwarming. \nIs the earth warming? Is the warming caused by emissions of greenhouse gases \n(GHGs) caused by human activity? How much warming is likely over the next \ncentury? What changes in climate patterns, rainfall, growing season, storm inci- \ndence and severity, and sea level might ensue, and how much damage would these \nchanges cause to humanity and to other species? These questions are difficult to \nanswer, and legitimate scientific debates about the impact of anthropogenic GHG \nemissions continue. \nDespite the scientific uncertainty, several facts are not in dispute. The temper- \nature at the earth’s surface-the land, lower atmosphere, and surface layer of the \nocean (the so-called mixed layer, the top 50 to 100 meters, where most sea life ex- \nists)-is primarily determined by the balance of the incoming solar radiation and \nthe outgoing reradiated energy. The earth is a warm mass surrounded by the cold \nof space and like all such masses emits so-called black body radiation whose fre- \nquency distribution and intensity depends on its surface temperature. The warmer \nthe mass, the more energy it radiates. Incoming solar energy warms the earth. As it \nwarms, more energy is radiated back into space. The temperature rises until the \nearth is just warm enough for the energy radiated back to space to balance the in- \ncoming solar energy. \n","page_start":266,"page_end":266,"token_count":404,"section_type":"other","chapter_number":8,"chapter_title":"Closing the Loop:","chunk_index":328}
{"chunk_id":"506bcf85b259f943","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"242 \nPart I1 Tools for Systems Thinking \nThe amount of energy radiated back into space depends on the composition of \nthe atmosphere. GHGs such as carbon dioxide and methane trap some of the en- \nergy radiated by the earth, instead of allowing it to escape into space. Thus an in- \ncrease in GHGs causes the earth to warm. The earth heats up until the energy \nescaping through the atmosphere to space rises enough to again balance the in- \ncoming solar energy. Greenhouse gases reduce the emissivity of the atmosphere \nenough to warm the surface of the earth (including the oceans) to a life-sustaining \naverage of about 15°C (59°F). Without GHGs in the atmosphere, the mean global \ntemperature would be about - 17°C (1°F) and a blanket of ice would perpetually \ncover the earth. \nNatural processes have caused the concentration of carbon dioxide (CO,) in \nthe atmosphere to fluctuate significantly over geological time, and surface temper- \natures have fluctuated with it. Human activity has now reached a scale where it can \naffect these processes. As shown in Figure 7-7, the rate of anthropogenic GHG \nemissions has been growing exponentially since the beginning of the industrial \nage. Atmospheric concentrations of C02 and other GHGs including nitrous oxide \n(N,O), methane (CH,), chlorofluorocarbons (CFCs), hydrofluorocarbons (HFCs), \nperfluorinated carbons (PFCs), and others have been growing exponentially, with \nconcentrations of CO,, N,O, and CH, up by 30, 15, and 145%, respectively, since \n1800. Mean global surface temperature has been rising, though not in a steady pat- \ntern. Compared to the late 1800s, average global temperatures are about 0.5 to 1°C \nwarmer today. By comparison, the mean global temperature during the last ice age, \nwhen sheets of ice 1000 feet thick covered much of the northern hemisphere, was \nabout 5°C colder than today. \nDebate continues about the dynamics of the global climate system, its response \nto forcing by human activity, and the consequences of a rise in global mean tem- \nperature. The public discussion has been polarized by well-financed campaigns \nto discount the science. Nevertheless, consensus is emerging. In 1995, the UN \nsponsored Intergovernmental Panel on Climate Change (IPCC) concluded that \nglobal warming was indeed occurring, and that human activity was responsible, \nstating “The balance of evidence suggests a discernible human influence on cli- \nmate” (IPCC 1996). Through the UN Framework Convention on Climate Change \n(UNFCCC) various nations are negotiating limits to GHG emissions, though com- \npliance remains elusive. \nSimulation models of various types are the primary research tool to explore \nthese issues. The enormously detailed general circulation models (GCMs) calcu- \nlate climate at finely spaced intervals covering the entire surface of the earth, but ","page_start":267,"page_end":267,"token_count":651,"section_type":"other","chapter_number":8,"chapter_title":"Closing the Loop:","chunk_index":329}
{"chunk_id":"780deaa325edc4df","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"mate” (IPCC 1996). Through the UN Framework Convention on Climate Change \n(UNFCCC) various nations are negotiating limits to GHG emissions, though com- \npliance remains elusive. \nSimulation models of various types are the primary research tool to explore \nthese issues. The enormously detailed general circulation models (GCMs) calcu- \nlate climate at finely spaced intervals covering the entire surface of the earth, but \ntake GHG emissions as exogenous inputs. At the other extreme, so-called inte- \ngrated climate-economy models close some of the feedbacks among the human \neconomy, carbon emissions, and global climate but treat the carbon cycle and cli- \nmate as global aggregates with a small number of stocks. Tom Fiddaman (1997) \nanalyzed many of the most widely used climate-economy models, identifying a \nnumber of problems and inconsistencies in them. For example, the widely cited \nDICE model (Nordhaus 1992a, 1992b) violates the law of conservation of mass by \nassuming that a significant fraction of carbon emissions simply disappear (Nord- \nhaus assumed they flow into a sink outside the model boundary). Fiddaman (1997) ","page_start":267,"page_end":267,"token_count":254,"section_type":"other","chapter_number":8,"chapter_title":"Closing the Loop:","chunk_index":330}
{"chunk_id":"986b464994a66f7c","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"Chapter 7 Dynamics of Stocks and Flows \nI\n,\n.\n,\n,\n.\n \n- 750- \nMama Loa \nE \nGas Recorder Data \nO B  \n.- \nu .I! \nZ E  \n5 $ \n700- \na\ns\n \n2 s  650- \ng g  \nSiple Station \nIce Core Data \n600-, \n- \nI\n,\n,\n,\n,\n , \n,\n'\n'\n'\n/\n'\n'\nI\n'\n \n243 \nFlGiURE 7-7 \nGHG emissions, \nconcentration, \nand global mean \ntemperatwre \n1 . 0 '  \" \" \nI\n'\n \" \" \n' \n~ \n' \n1\n'\n \" \n' \nAngell \n1800 \n1850 \n1900 \n1950 \n2( 00 \nSources: Data from the Carbon Dioxide Information Analysis Center (CDIAC), Oak Ridge National \nLaboratory (http://cdiac.esd.ornl.gov/trends/trends.htm). Emissions: Keeling (1 997). Emissions in- \nclude carbon from burning fossil fuels only and excludes other GHGs and changes in carbon flux \nfrom, e.g., deforestation. COP in atmosphere: Siple Station ice core data (Neftel et al. 1994). Mauna \nLoa gas recorder data (Keeling et al. 1997); concentration in ppmv converted to billion tons in total \natmosphere. Global mean surface temperature anomaly: Jones, Wigley, and Wright (1 997) and Angell \n(1997); rescaled so 1960-70 = 0.2'C. \ndeveloped a model that corrects these and other defects in common climate- \neconomy models and linked it to a model of the economy and energy system. The \nmodel sectors were based on the relevant scientific knowledge of the global carbon \ncycle and climate system and carefully calibrated to the available data. \n","page_start":268,"page_end":268,"token_count":413,"section_type":"other","chapter_number":8,"chapter_title":"Closing the Loop:","chunk_index":331}
{"chunk_id":"043ae33b8c3f0b97","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"244 \nPart I1 Tools for Systems Thinking \nDespite the differences among the models, all show the climate system to pos- \nsess enormous inertia. Changes in GHG emissions only slowly show up in changes \nin global temperature and climate, and the changes persist for many decades. To \nillustrate, Figure 7-8 shows an extreme conditions test using Fiddaman’s model. In \nthe simulation, anthropogenic CO, emissions follow their historical path through \nthe mid 1990s, remain constant until 2000, and then fall to zero after 2000. Sur- \nprisingly, though the rate of CO, emissions falls to zero in the year 2000, mean \nglobal temperature continues to rise for about three more decades. It then falls \nvery slowly. \nThe stock and flow structure responsible for the counterintuitive result that \ntemperature rises even though emissions fall to zero is shown in Figure 7-9. The \nleft side of the figure portrays the global carbon cycle; the right side portrays the \nglobal heat balance. Burning fossil fuels adds CO, to the atmosphere. There are \nseveral outflows from the stock of atmospheric CO,. Higher atmospheric CO, con- \ncentration increases the rate at which CO, is consumed by aquatic life or dissolves \ninto the mixed layer of the ocean. Eventually, CO, taken up by the surface layer \ndiffuses to deeper waters, both through ocean currents and as detritus from aquatic \nlife sinks. The transfer of carbon to the depths is slow, and mixing between the sur- \nface and abyssal waters is weak, so many carbon cycle models disaggregate the \nwater column into a number of distinct states and model the transfer of carbon \nbetween adjacent layers explicitly. Fiddaman’s model utilizes 10 layers, enough to \ncapture the slow adjustment of abyssal C02 concentrations to changes in CO, in \nthe mixed layer. \nIncreased atmospheric CO, concentration also stimulates uptake of carbon by \nterrestrial plants (the flux of CO, to biomass). Carbon in biomass can be released \nback into the atmosphere through respiration and metabolic activity of animal and \nbacterial life and by fire (natural and human-caused). As biomass decays, the stock \nof carbon stored in soil increases (the flux of carbon from biomass to soil humus). \nThe carbon in humus can be taken up directly into biomass as plants grow or can \nbe released into the atmosphere through decay. \nNote that the model represents the inflow of CO, to the atmosphere from the \nburning of fossil fuels as flowing from an unlimited source when in fact the flow \ndraws down the carbon sequestered in global stocks of fossil fuels. Similarly, the \nmodel does not capture the conversion of carbon in humus or the abyssal layer of \nthe ocean into new stocks of fossil fuels. Although the dynamics of global warm- \ning will play out over the next several centuries, this time horizon is so short rela- \ntive to the millions of years required to form oil, gas, and coal that these carbon \nflows can be safely ignored. \nThe right side of Figure 7-9 shows the stock and flow structure for the heat ","page_start":269,"page_end":269,"token_count":658,"section_type":"other","chapter_number":8,"chapter_title":"Closing the Loop:","chunk_index":332}
{"chunk_id":"950ec85e5f364001","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"the ocean into new stocks of fossil fuels. Although the dynamics of global warm- \ning will play out over the next several centuries, this time horizon is so short rela- \ntive to the millions of years required to form oil, gas, and coal that these carbon \nflows can be safely ignored. \nThe right side of Figure 7-9 shows the stock and flow structure for the heat \nbalance of the earth’s surface, atmosphere, and oceans. The surface and atmos- \nphere, including the surface layer of the ocean, absorb incoming solar energy and \nradiate heat back into space. Heat is also transferred between the surface layer and \nthe deep ocean, though at slow rates. The rate of heat transfer between surface and \ndeep ocean depends on the temperature differential between the different layers, \ncreating two negative feedbacks which seek to equilibrate the temperatures of the \ndifferent layers. Similarly, net radiative forcing is the difference between the in- \ncoming solar energy and the energy radiated from the warm earth back into space. ","page_start":269,"page_end":269,"token_count":215,"section_type":"other","chapter_number":8,"chapter_title":"Closing the Loop:","chunk_index":333}
{"chunk_id":"5ec2fa4e026dffda","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"FIGURE \n7-8 \nGlobal tempera \nture rises well after \nGHlG emissions \nfall to zero. \nSi ni u I ated emis- \nsions fall to zero \nin 2000. Mean \nsurface tempera- \nture contiinues tlo \nrise for roughly \n20 years \nChapter 7 Dynamics of Stocks and Flows \n245 \n0.8 1 \nAngel1 \nData t \nDO \n2025 \n205 \nSource: Fiddaman (1997). \nThe warmer the surface, the more energy is radiated back into space, cooling the \nearth and forming another negative loop. The concentration of C02 and other \nGHGs increases net radiative forcing by reducing the rate at which energy is radi- \nated back into space for any given surface temperature. \nThe diagram (though not the full model) deliberately omits many additional \nfeedbacks affecting the rates of carbon flow and heat exchange as well as cou- \nplings to other biogeochemical cycles. Knowledge of the nature and strength of \nthe many feedbacks coupling climate, carbon cycle, and human activity is still \nevolving. Some of these feedbacks are negative and may offset GHG emissions or \n","page_start":270,"page_end":270,"token_count":255,"section_type":"other","chapter_number":8,"chapter_title":"Closing the Loop:","chunk_index":334}
{"chunk_id":"362358da99e0a26f","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"246 \nPart I1 Tools for Systems Thinking \nFIGURE 7-9 Stock and flow diagram of global carbon cycle and heat balance \nBurning fossil fuels adds C02 to the atmosphere, increasing net radiative forcing until the temperature \nof the land, ocean surface, and atmosphere rises enough to balance reradiation of energy into space \nwith incoming insolation. The diagram deliberately omits many of the feedbacks, both positive and \nnegative, among the carbon stocks and global mean temperature. Flows with arrowheads at both ends \ncan be positive or negative (e.g., Net Radiative Forcing can be an inflow of heat to the atmosphere or \nan outflow). The solid arrowhead indicates the positive direction of two-way flows. \nFlux Biomass \nFlux Humus to \nInsolation \nFlux Atmosphere \nFlux Ocean \nb.3 ' ' \nto Atmosphere \nto Ocean \nI \nI \nCO, in \nMixed Layer \nn \nNet C o p  Fiux \nto Deep Ocean \nCO, in \nDeep Ocean \nAtmosphere \n& Upper Ocean \nTem perat u re \nAtmosphere \n& Upper Ocean \n\\ f. \n, \nExchange \n, \n;Tempera7 \n+ \nDifference \nbetween \nSurface and \nDeep Ocean \nHeat Stored in \n/ \nDeep Ocean \nTemperature \nDeep Ocean \n+ \nSource: Adapted from Fiddaman (1 997). \n","page_start":271,"page_end":271,"token_count":301,"section_type":"other","chapter_number":8,"chapter_title":"Closing the Loop:","chunk_index":335}
{"chunk_id":"5197abc51ec82469","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"Chapter 7 Dynamics of Stocks and Flows \n247 \nwarming. These include increased carbon uptake by biomass, stimulated by higher \nC02 concentrations, and increased cloud cover from enhanced evaporation, re- \nflecting more incoming sunlight to space. Particulate aerosols from fossil fuel con- \nsumption (air pollution and smog) also increase reflection of incoming solar \nradiation and may account for the slower than expected rate of temperature rise ob- \nserved in the Northern Hemisphere. \nAmong the positive feedbacks driving climate change are changes in surface \nalbedo: Warming reduces the winter snow cover and shrinks the highly reflective \npolar ice caps, thus increasing heat absorption and leading to further melting, less \nsnow cover, and still greater absorption. Scientists expect this positive loop will \ncause much greater warming at the poles than in the tropics and more warming in \nwinter than summer. Thawing of permafrost may release large quantities of \nmethane from decay of organic matter, increasing the concentration of GHGs and \nleading to further warming in another positive loop. Increased evaporation from \nwarmer land and surface waters may be self-reinforcing since water vapor is a \npowerful GHG. At present it is not known whether the negative or positive feed- \nbacks dominate the dynamics nor how the dominance of the loops might change as \nvarious nonlinearities come into play. However, Goulden et al. (1998) studied the \nnorthern boreal forest of Canada and found that warming has resulted in net carbon \nflux to the atmosphere as C02 released from decay of thawed biomass outweighed \nincreased carbon uptake by plants. For that biome, at least, the positive feedbacks \nappear to dominate the negative loop of increased biotic activity. \nThe impact of warming on sea level may also be driven by positive feedback. \nThe huge West Antarctic Ice Sheet (WAIS) consists of a floating tongue attached \nto a larger ice mass so heavy it rests on bedrock below sea level. The WAIS holds \na lot of water: “If it melted away in a greenhouse-warmed world, it would raise all \nthe world’s oceans by 5 meters” (Kerr 1998, p. 17). If warmer seas cause the WAIS \nto thin, it will rise farther off the sea bed, exposing more of the ice to melting and \naccelerating thinning in a positive loop. As the edge thins, the higher ice on the \nAntarctic land mass flows faster into the sea, where it is exposed to the warmer wa- \nters, further speeding melting in another positive feedback. Rignot (1998) notes \nthat a glacier with “[tlhis configuration is theoretically unstable because a retreat \nof its grounding line (where the glacier starts to float) would be self-perpetuating \nand irreversible” and shows that the grounding line of the Pine Island glacier feed- \ning the WAIS is retreating at 1.2 ? 0.3 kilometers per year. Ice cores show that \nwithin the past 1.3 million years, “at a time perhaps not much warmer than today, ","page_start":272,"page_end":272,"token_count":657,"section_type":"other","chapter_number":8,"chapter_title":"Closing the Loop:","chunk_index":336}
{"chunk_id":"e99721fa2015304e","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"that a glacier with “[tlhis configuration is theoretically unstable because a retreat \nof its grounding line (where the glacier starts to float) would be self-perpetuating \nand irreversible” and shows that the grounding line of the Pine Island glacier feed- \ning the WAIS is retreating at 1.2 ? 0.3 kilometers per year. Ice cores show that \nwithin the past 1.3 million years, “at a time perhaps not much warmer than today, \nthe WAIS wasted away to a scrap and flooded the world’s coasts” (Kerr 1998, \np. 17). Ice core data from Greenland also suggest the paleoclimate repeatedly \nwarmed and cooled, with corresponding changes in snowfall, over time scales of \nonly decades. These rapid changes suggest positive feedbacks may have domi- \nnated climate dynamics in geologically recent times. \nIt will take years of research to discover all the feedbacks that drive the climate \nand determine the likely effects of greenhouse warming. Nevertheless, the stock \nand flow structure of the global carbon cycle and heat budget explains some basic \nfeatures of the dynamics. The stock and flow structure shows how it is possible for ","page_start":272,"page_end":272,"token_count":248,"section_type":"other","chapter_number":8,"chapter_title":"Closing the Loop:","chunk_index":337}
{"chunk_id":"688eb1d3d976e9fd","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"248 \nPart I1 Tools for Systems Thinking \nthe global temperature to rise even after human GHG emissions fall to zero. When \nemissions fall to zero the inflows to the stock of atmospheric carbon fall below the \noutflows. Therefore the stock of CO, in the atmosphere peaks and begins to fall. \nThe concentration of CO, in the atmosphere falls only slowly, however. First, the \nuptake of carbon by biomass falls as the concentration of CO, in the atmosphere \ndeclines, while CO, continues to flow into the air from burning and decay of bio- \nmass and humus stocks. Second, as atmospheric C02 falls, the flux of carbon from \nthe air to the mixed layer of the ocean falls, while the flux of carbon from the ocean \nto the air increases. These compensatory responses slow the decline of atmospheric \nCO, so that 50 years after human emissions stop completely, the concentration of \nCO, in the model atmosphere has fallen back only to its 1990 level. \nThe heat content of the surface layer rises as long as incoming radiation ex- \nceeds the heat radiated back to space or transferred to the deep ocean. Though \nfalling after the year 2000, global atmospheric C02 concentrations remain high \nenough to reduce the energy radiated back to space below incoming insolation. \nDeclining atmospheric C02 after 2000 means global mean temperature grows at a \ndiminishing rate. By about 2030 the surface has warmed enough and the concen- \ntration of CO, in the atmosphere has fallen enough for insolation to be balanced \nagain by the earth’s black-body radiation and the rate of heat transfer to the deep \nocean. Note that global mean temperature falls only slowly after 2030. First, the \nslow decline of GHG concentrations after 2000 slows the increase in radiative \nemissivity. Second, during the warmest decades when the surface temperature ex- \nceeded the temperature of the deep ocean, heat flowed from the surface layer to the \ndeep. As the surface layer cools, heat stored in the deep ocean now flows back to \nthe surface, slowing atmospheric cooling. \nThe stock and flow structure of the carbon cycle and heat balance explains the \nseemingly paradoxical result that temperatures can rise even when emissions fall. \nThere are several lessons. First, global warming cannot be proven or disproven by \ncorrelating emissions and temperature: the dynamics are too complex for such \nnaive commonsense approaches. Second, the full impact of past emissions has not \nyet been observed. The oceans and terrestrial carbon stocks have been absorbing \ncarbon out of the atmosphere at higher rates, suppressing the rise in atmospheric \nCO, concentrations. And as these stocks increase, their absorption capacity dimin- \nishes. The impact of future emissions on atmospheric CO, may well be larger than \nthat observed in the past. Third, the inertia of the system means further warming \nand climate change are already underway. Action to halt warming must be taken \ndecades before we can know what the consequences of warming will be and before \nscientific certainty about the dynamics of the global climate can be gained. ","page_start":273,"page_end":273,"token_count":655,"section_type":"other","chapter_number":8,"chapter_title":"Closing the Loop:","chunk_index":338}
{"chunk_id":"47a81ce8a632fa5d","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"CO, concentrations. And as these stocks increase, their absorption capacity dimin- \nishes. The impact of future emissions on atmospheric CO, may well be larger than \nthat observed in the past. Third, the inertia of the system means further warming \nand climate change are already underway. Action to halt warming must be taken \ndecades before we can know what the consequences of warming will be and before \nscientific certainty about the dynamics of the global climate can be gained. \nMost important, the stock and flow structure of the global climate means sta- \nbilizing emissions near current rates will not stabilize the climate. Figure 7- 10 \nshows a simulation in which emissions are stabilized in 1995. The concentration of \natmospheric CO, continues to rise, more than doubling by 2300. Global mean sur- \nface temperature rises by about 3°C. Many industrialized nations agreed at the Rio \nconference on the environment to stabilize their GHG emissions at 1990 levels, \nand 38 industrialized nations agreed at the 1997 Kyoto conference of the UNFCCC \nto reduce emissions by 2012 to about 95% of 1990 rates. But the US Senate de- \nclared the treaty dead on arrival. Implementation remains elusive; signing a treaty ","page_start":273,"page_end":273,"token_count":264,"section_type":"other","chapter_number":8,"chapter_title":"Closing the Loop:","chunk_index":339}
{"chunk_id":"808586cf41a42538","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"Chapter 7 Dynamics of Stocks and Flows \n249 \nFIGURE 7-1 0 \nStabilizing GHG \nemissions does \nnot stabilize the \nclimate. \nStabilizing GHG \nemiissions at 19!35 \nlevels causes at- \nmospheric COP \nconcentrations to \ndouble by 2300, \nwhile mean global \nsurface tc, lm p era- \nture increases \nabout 3°C;. Even \nunder the pro- \nposed Kyoto \nagreement, global \nemissions are \nlikely to increase \nsubstantially over \nthe next several \ndecades. \n1 L \n2 \nHistory :v \n0 \n1950 \n2000 \nI\n.\n,\n.\n \n2050 ~ . . ~ ' ~ ' ' ' ' l . ' . ' ~ ' \" ' ~ '\n2100 \n2150 \n2200 \n2250 \n2300 \nSimulati \nHistory Simulation \n8ool \" ' ' I '  \" \" \nI\n'\n ' \" \nI\n'\n \" \" \" \" \nI\n'\n \" \n'\nI\n A \n1950 \n2000 \n2050 \n2100 \n2150 \n220C \nSource: Fiddaman (1 997) \nis one thing, actually reducing emissions another. Most troubling, the emissions of \nrapidly developing nations such as China continue to grow at high exponential \nrates. The US Energy Information Administration forecast in 1997 that GHG emis- \nsions from developing nations would nearly double by 2015, accounting for the \nlarge majority of the world total (Malakoff 1997). \nWhile different climate models differ in their details and in their estimates of \nfuture warming, all agree that stabilizing emissions near current levels will not sta- \nbilize the climate. Mitigating the risk of climate change from global warming re- \nquires a substantial decline in the rate of GHG emissions. The world has yet to face \nup to the inexorable logic of the stocks and flows of the global climate system. \n","page_start":274,"page_end":274,"token_count":430,"section_type":"other","chapter_number":8,"chapter_title":"Closing the Loop:","chunk_index":340}
{"chunk_id":"297d5c36a6d2ae43","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"250 \nPart II Tools for Systems Thinking \n7.3 SYSTEM DYNAMICS IN ACTION: THE WAR ON DRUGS \nIn the 1980s the use of cocaine increased dramatically. As cocaine spread, crime, \nviolence, and health problems grew exponentially. The United States declared a \nwar on drugs. A new federal agency, the White House Office of National Drug \nControl Policy (ONDCP), headed by the “drug czar,” was appointed to oversee the \ncampaign. Penalties for possession, sale and use of drugs were stiffened. Billions \nwere spent to increase enforcement, especially to reduce the flow of cocaine into \nthe US, estimated by the ONDCP to be 550 to 660 metric tons in 1989. The focus \nof the war on drugs was primarily the supply side: slashing the production of co- \ncaine, choking off smuggling into the US, and stiffening penalties for possession \nand sale. On the demand side, kids were told to “Just say NO.” \nDid it work? In the late 1980s the data told a conflicting story. Some drug data \nshowed improvement. Through the “National Household Survey” (NHS) and \n“High School Senior Survey” (HSSS), the government regularly asks people about \ntheir use of alcohol and drugs. To assess trends in incidence and prevalence, the \nsurveys ask whether people have ever used cocaine, whether they’ve used it in the \nlast year, and whether they’ve used it in the last month. Figure 7-11 shows NHS \ndata for the fraction of people responding that they have used cocaine in the past \nmonth. According to the surveys, cocaine use was falling sharply, with less than \n1% of the population reporting past month cocaine use in 1990, down from 3% in \n1985. The drop in reported use coincided with a sharp increase in the seizure rate, \nto more than 75 metric tons per year (Figure 7-11). The war on drugs seemed to be \nworking; citing these data, the administration called for even more money to finish \nthe job. \nHowever, other indicators showed the problem was getting worse. Arrests for \npossession and sale of cocaine, the number of emergency room visits associated \nwith cocaine, and the number of cocaine-related deaths all showed exponential in- \ncreases, while the purity of cocaine on the street was growing and the street price \nwas falling (Figure 7-11). By these measures, cocaine use was up sharply and \navailability was growing. Critics, citing the failure of prohibition in the 1920s and \n1930s, argued that interdiction could never work and called for stronger demand- \nside measures (MacCoun and Reuter 1997 review the debate). Others argued that \ndecriminalization would eliminate the crime problem caused by use of illegal \ndrugs and allow the government to regulate purity to prevent accidental overdoses. \nMuch of the debate focused on which data series were right and which were \nwrong. The stakes were high: Besides the issues of public health and safety, the ","page_start":275,"page_end":275,"token_count":650,"section_type":"other","chapter_number":8,"chapter_title":"Closing the Loop:","chunk_index":341}
{"chunk_id":"1305abc269be3920","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"side measures (MacCoun and Reuter 1997 review the debate). Others argued that \ndecriminalization would eliminate the crime problem caused by use of illegal \ndrugs and allow the government to regulate purity to prevent accidental overdoses. \nMuch of the debate focused on which data series were right and which were \nwrong. The stakes were high: Besides the issues of public health and safety, the \ndrug war was prosecuted and data series were collected by an alphabet soup of \nfederal and state agencies, including the FBI, DEA, SAMHSA, NIJ, NIDA, DEPB, \nONDCP, and CIA.2 Each argued for the primacy and correctness of its data and \n2Federal Bureau of Investigation, Drug Enforcement Agency, Substance Abuse and Mental \nHealth Services Administration of the Department of Health and Human Services, National \nInstitute of Justice, National Institute on Drug Abuse, Drug Enforcement Policy Board, Office of \nNational Drug Control Policy, and Central Intelligence Agency. ","page_start":275,"page_end":275,"token_count":204,"section_type":"other","chapter_number":8,"chapter_title":"Closing the Loop:","chunk_index":342}
{"chunk_id":"0df652549519e3d6","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"t '  \n, \" L \" \" \" \" ' '  \nW \nb \n,\n\"\n'\n,\n,\n'\n'\n#\n.\n-\nm\n \n0 \n0 \n0 - 0  \nI \n,\n\"\n'\n1\n\"\n'\n1\n\"\n'\n1\n\"\n'\n \n0 \n0 \n0 \n0 \na \nnn \n0 \nIn \n0 \nilc \nIn \nN \n-I------, \n' \n' \n' \nI \n' \n' \n' \nI \n' \n' \n' \nr. \n0 \nm \nm \nc \nm \nm \nm \nc \nW \nCO \nm \nc \nd \nm \nm \nc \nN \nm \nm \nc \n0 \nm \nm \nr \n0) \nb \nm \nc \nW \nb \nm \nr- \n0 \nm \nm \nc \nm \nm \nm \n7 \nW \nm \nm \nc \nP \nm \nm \nc \nN \ne0 \nm \nr \n0 \nm \nm \nr \nco \nb \nm \nr \nW \nb \nm \nc \n0 \n0 \n0 \n0 \n-=J \nN \n< \nieaK/aldoad puesnoyl \nm \nm \nm\n-\n \n7 \n(D \nm \nm\n-\n \nc \nP \nm \nm\n-\n \nc \nN \nm \nm\n-\n \nc \n0 \nm \nm\n-\n \nc \nm \nm\n-\n \nb \nc \n0 \nm \nm \nc \ne0 \nm \nm \nr \nW \nm \nm \nc \n.;r \nm \nm \nc \nN \nm \nm \n7 \n0 \nm \nm \n7 \nm \nb \nm \n7 \nW \nb \nm \nc \n0 \n0 \n0 \n0 \n0 \n0 \n0 \n0) \nW \nd \n01 \nm \ne\no\n \n251 \n","page_start":276,"page_end":276,"token_count":423,"section_type":"other","chapter_number":8,"chapter_title":"Closing the Loop:","chunk_index":343}
{"chunk_id":"5b0568f69f0cf274","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"252 \nPart I1 Tools for Systems Thinking \ndrug-enforcement programs as they struggled to gain a larger share of more than \n$10 billion per year devoted to the war on drugs. \nSupporters of the interdiction strategy argued that the survey data directly \nmeasured what counts-the use of drugs-while other indicators were indirect. \nThey argued that rising arrest rates and seizures reflected greater enforcement, not \ngreater drug use, and were therefore a sign of success; falling prices, rising purity, \nand the surge in medical emergencies and deaths simply reflected the substitution \nof more potent crack for the less pure powder form. Critics of interdiction and the \nsurvey data argued that drug users are less likely than law-abiding citizens to be se- \nlected for or participate in the surveys. Many cocaine users are likely to deny they \nuse drugs when the government asks. Defenders of the surveys pointed to the so- \nphisticated sampling methods they used to account for possible underrepresenta- \ntion of certain subpopulations. They guaranteed anonymity to survey respondents \nand claimed that while “[tlhe value of self-reports obviously depends on the hon- \nesty and memory of sampled respondents[, rlesearch has supported the validity of \nself-report data in similar contexts” (SAMHSA 1994). \nIn the late 1980s the National Institute of Justice commissioned a study to re- \nsolve the apparent paradox of declining measures of cocaine use and rising con- \nsumption, crime, arrests, and deaths. As part of the study, a system dynamics \nmodel was developed to integrate the demand and supply sides of the market \n(Homer 1993, 1997). The full model consisted of several hundred equations and \nincluded a detailed representation of the stock and flow structure of users, along \nwith the feedbacks among different market actors, the market, and the criminal jus- \ntice system. \nFigure 7-12 shows a simplified representation of the stock and flow structure \nfor the different categories of drug users represented in the model. The NHS con- \nsiders all persons age 12 and over to be potential drug users. As people in this age \ngroup first experiment with cocaine they move from the “never used” population \nto the stock of active casual users (those who have used cocaine in the past month \nbut are not addicted). Some casual users find they cannot control their cocaine con- \nsumption and become compulsive users. Active users, both casual and compulsive, \ncan stop, becoming “transitional users” (those who have used cocaine in the past \nyear, but not in the past month). Transitional users can relapse, becoming active \nusers again. After a year without any cocaine use, transitional users are reclassified \nas ex-users. Some ex-users relapse, becoming active users again. Others quit per- \nmanently. There are, of course, death rates out of each stock, both from drug- \nrelated causes and all other sources. \nThe full model has a more complex stock and flow structure than shown \nin Figure 7- 12, explicitly distinguishing between casual and compulsive transi- ","page_start":277,"page_end":277,"token_count":654,"section_type":"other","chapter_number":8,"chapter_title":"Closing the Loop:","chunk_index":344}
{"chunk_id":"cf011002492be8f3","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"users again. After a year without any cocaine use, transitional users are reclassified \nas ex-users. Some ex-users relapse, becoming active users again. Others quit per- \nmanently. There are, of course, death rates out of each stock, both from drug- \nrelated causes and all other sources. \nThe full model has a more complex stock and flow structure than shown \nin Figure 7- 12, explicitly distinguishing between casual and compulsive transi- \ntional and ex-users and between users of powder and crack cocaine. The model \naccounted for escalation from casual to compulsive use and for switching between \npowder and crack. This disaggregation was necessary because the probabilities \nof moving from one state to another depend on the form and intensity of use. \nCompulsive users are less likely to quit and more likely to relapse, and crack users \nare more likely to escalate from casual to compulsive use and suffer higher re- \nlapse rates. ","page_start":277,"page_end":277,"token_count":203,"section_type":"other","chapter_number":8,"chapter_title":"Closing the Loop:","chunk_index":345}
{"chunk_id":"4380f58a6a483e0b","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"Chapter 7 Dynamics of Stocks and Flows \n253 \nFIG~JRE \n7-1 2 \nCocaine use: \nstocks and flows \nr \nActive \nActive \nCasual \n- \nUsers \nEscalsion to \nUsers \nCompulsive \nUse \nT 7  \nbCompulsive \nTotal Active Users \nTransitional \nUser Relapse \nRelapse \nRate \nRate \nTransitionall z 4 Ex-Users I \nI \nUsers \nQuit - \nRate \nEver-Used Population \nSource:Adapted from Homer (1993). \n+ew3 \nDeath Rate \n(All Causes) \nNote that the categories of use in the model can be directly compared to those \nused in the surveys. The total number of active users, both casual and compulsive, \nfor both powder and crack, is the number of people who have actually used cocaine \nin the past month. The sum of the active users and the transitional users is the total \nnumber who actually used cocaine in the past year. Finally, the sum of active, tran- \nsitional, and ex-users is the total number who have ever used cocaine. \nWhat are the determinants of the initiation rate-what causes people to use co- \ncaine for the first time? Studies show most people begin using drugs through peer \ninfluence-by observing others using drugs and through their membership in so- \ncial networks in which others use drugs (that is, by hanging with the wrong \ncrowd). As more people start using cocaine, the social networks of users expand, \nbringing still more nonusers into contact with the drug, in a positive feedback \nprocess analogous to the spread of an infectious disease (chapter 9). The strength \nof the social exposure feedback depends on the social aura of the drug: how chic \ncocaine is perceived to be (is this the drug the opinion leaders, the beautiful peo- \nple, are using this year?). The positive feedback also depends on whether current \n","page_start":278,"page_end":278,"token_count":412,"section_type":"other","chapter_number":8,"chapter_title":"Closing the Loop:","chunk_index":346}
{"chunk_id":"ddd591c9b6c1d047","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"254 \nPart I1 Tools for Systems Thinking \nand potential users view the drug as benign-is it perceived to offer a good high \nwithout negative effects such as addiction, bad trips or the risk of sudden death? \nPrice has a comparatively modest effect, at least in higher socioeconomic groups, \nbecause high price and scarcity confer social status on those who can provide the \ndrug for friends at parties or in the workplace. In the mid 1970s, as the cocaine \nepidemic began, cocaine was viewed as a benign, nonaddictive drug posing little \nhealth risk. It became the in-group drug of choice among certain professional \nelites. The entertainment industry reinforced the chic image of the drug. All these \nself-reinforcing processes are captured by the Word of Mouth loop R1 in Fig- \nure 7-13. \nThe dynamics of the market reinforced the growth of the epidemic. As con- \nsumption increased, the supply side of the market became much more efficient. \nPrice declined and purity increased. The growing scale of the industry created huge \nincentives for technological and organizational innovation by producers and smug- \nglers. The introduction of crack cocaine in 1981 was the most important, but far \nfrom the only, technical innovation in the market. As in many legitimate industries, \ngrowth led to production and especially distribution scale economies. Horizontal \nand vertical market integration through the cocaine cartels cut costs and led to \nmore consistent product quality. Growing experience led to a substantial learning \ncurve as harvesting, production, smuggling, distribution, and money laundering \noperations were improved. These scale and learning effects created additional pos- \nitive feedbacks leading to wider availability, greater purity, and lower prices, mak- \ning cocaine affordable and accessible to all (loop R2). \nAs long as people perceived the health and legal risks of cocaine to be small, \nthese positive feedbacks dominated the system. Cocaine use mushroomed, spread- \ning gradually from middle and upper income, trend-conscious populations on the \neast and west coasts to every social and income level in every state of the country. \nWhy then did the data show such a large drop in the incidence of current co- \ncaine use after 1985? Supporters of the interdiction strategy credited the adminis- \ntration’s supply-side policy. They argued that enhanced enforcement increased the \nfraction of cocaine seized, cutting the availability of the drug (the balancing Sup- \nply Disruption loop B 1) and that aggressively arresting and incarcerating pushers \nand users helps clean up the Streets (the balancing loop B2). Both these negative \nloops, it was argued, cut drug use, as indicated by the survey data. \nHowever, stock and flow structure for drug users showed that the survey data \ncould not be correct and were substantially understating the prevalence of drug \nuse. In addition to asking about past month use, the NHS asks respondents if they \nhave used cocaine in the past year and if they have ever used cocaine. Homer care- \nfully disaggregated the user population into stocks corresponding to these cate- \ngories so the model could be directly compared to the data. ","page_start":279,"page_end":279,"token_count":658,"section_type":"other","chapter_number":8,"chapter_title":"Closing the Loop:","chunk_index":347}
{"chunk_id":"0e65019479e9ead5","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"However, stock and flow structure for drug users showed that the survey data \ncould not be correct and were substantially understating the prevalence of drug \nuse. In addition to asking about past month use, the NHS asks respondents if they \nhave used cocaine in the past year and if they have ever used cocaine. Homer care- \nfully disaggregated the user population into stocks corresponding to these cate- \ngories so the model could be directly compared to the data. \nFigure 7-14 shows the NHS data for the fraction of the population who re- \nsponded affirmatively when asked if they had ever used cocaine. Note that the \nreported ever-used-cocaine population peaks in 1982 at about 12% and falls to \nabout 10% by 1988. \nThe lifetime cocaine prevalence data in Figure 7-14 is the ratio of the ever- \nused population to the total population (those who never used plus those who ever \nused). The inflow to the total stock of people who have actually used cocaine is the ","page_start":279,"page_end":279,"token_count":216,"section_type":"other","chapter_number":8,"chapter_title":"Closing the Loop:","chunk_index":348}
{"chunk_id":"b74006ae58b4b2bc","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"FIGURE 7-1 3 \nFeedback structure of the cocaine epidemic \n/ - \nRepcrtd \nUnderreporting of \nPrevalence of \nCocaine Use \nCocaine Use \n(Fraction of Users Lying) \nSocial \nExposure to \nWord of Mouth \n/Cocaine User Populatioa \nCocaine Market \nRetail price \nDisaggregated by \nPreferred form \nScale and \nRetail sales \nIntensity of use \nLearning \nImports \n@ \nPurity \n- \nRecency of use \nEffects \nSocial \nAcceptability \nof Drugs \n+ \nCocaine- \nHealth \nRisks \nCrime \nEnforcement Intensity; \nPerceived \nLegal Risks \nIncarceration + \nSource:Adapted from Homer (1993). \nh) \ntn \ncn \n","page_start":280,"page_end":280,"token_count":175,"section_type":"other","chapter_number":8,"chapter_title":"Closing the Loop:","chunk_index":349}
{"chunk_id":"293bdc8a18cb91b3","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"256 \n0 .- \nc - \nQ \nf \nFIGURE 7-14 \nSurvey estimates \nof lifetime cocaine \nprevalence \nNHS Lifetime User Prevalence Fraction \nPart I1 Tools for Systems Thinking \nm \n0 - \n? \np ' o . 0 0  \n, \n, \n, \n, \n, \n, \n, \n, \n, \n, \n, \n, \nI\n,\n,\n , \n, \n, \n, \ninitiation rate. The only outflow is death. The only way the stock of people who \nhave ever used cocaine can decline is for the death rate of current and past users to \nexceed the initiation rate of new users.3 Yet the survey data reported a 3.2% drop \nin the number of people who have ever used cocaine from 1982 to 1988. Even if \nthe rate at which people tried cocaine for the first time fell to zero in 1985-even \nif every man, woman, and child in the US who had never used cocaine just said \nNO !, something not even the administration believed-mortality rates of the ever- \nused population are too small to cause the reported decline in the number of peo- \nple who have ever tried cocaine. Even with the most optimistic estimates for the \ndecline in the initiation rate, it is physically impossible for the stock of people who \nhave ever used cocaine to fall as quickly as the surveys ~uggested.~ \nWhy then did the reported incidence of use fall so dramatically after 1985? \nThere are two main reasons. First, the surveys presume that their samples are prop- \nerly stratified, that is, that the representation and response rates of subpopulations \n(such as different geographic, ethnic, racial, and socioeconomic groups) are ad- \njusted to match the proportion of these groups in the overall population and that \nany underrepresentation is constant through time. Heavy drug users, however, are \nmuch less likely to be interviewed for the survey. Though the NHS methodology \nattempted to adjust for this underrepresentation, they cautioned that \nPrevalence estimates for specific subgroups are sometimes based on modest to \nsmall sample sizes, which may lead to substantial sampling error. . . [Tlhis report \ndoes not present estimates for some segments of the US population that may con- \ntain a substantial proportion of drug users, such as transients not residing in shelters \n31n principle, the lifetime prevalence fraction could fall if those in the ever-used population emi- \ngrated from the US to other countries at a rate much higher than that of those who have never used \ncocaine. These rates, however, are negligible. For the survey to be correct the required outmigration \nof drug users would greatly exceed all outmigration from the US. \nlation that has ever used cocaine. The decline in relative lifetime prevalence would require the \ndeath rate of former cocaine users to greatly exceed the death rate of those who have never used ","page_start":281,"page_end":281,"token_count":622,"section_type":"other","chapter_number":8,"chapter_title":"Closing the Loop:","chunk_index":350}
{"chunk_id":"e64982f3b32cf036","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"grated from the US to other countries at a rate much higher than that of those who have never used \ncocaine. These rates, however, are negligible. For the survey to be correct the required outmigration \nof drug users would greatly exceed all outmigration from the US. \nlation that has ever used cocaine. The decline in relative lifetime prevalence would require the \ndeath rate of former cocaine users to greatly exceed the death rate of those who have never used \ncocaine. The difference in death rates, however, is very small, partly due to the low excess mortal- \nity of active users and largely because most members of the ever-used population no longer use \ncocaine and experience mortality rates about the same as the never-used population. \n4The problem in the survey data is worse. The NHS reported a drop in thefraction of the popu- ","page_start":281,"page_end":281,"token_count":176,"section_type":"other","chapter_number":8,"chapter_title":"Closing the Loop:","chunk_index":351}
{"chunk_id":"65b631f9cc9d90bb","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"Chapter 7 Dynamics of Stocks and Flows \n257 \n(e.g., users of soup kitchens or residents of street encampments) and those incarcer- \nated in county jails or State and Federal prisons (SAMHSA 1994). \nThat is, few federal workers are willing to knock on the doors of a crack house to \nask the occupants whether they use illegal drugs. Consequently, active and espe- \ncially compulsive users are underrepresented in the surveys. Because these popu- \nlations grew rapidly in the 1980s, the surveys systematically underestimated the \ngrowth in cocaine use. \nSecond, and more importantly, increasing legal risks caused a larger fraction \nof current and especially former users to deny they ever used cocaine. In plain lan- \nguage, more people lied about their past cocaine use. The changing distribution of \ncocaine users and declining social acceptance of cocaine led to systematic under- \nestimation of cocaine prevalence in the survey data. \nBy integrating all the available data into a consistent and unified framework, \nthe model provided more accurate estimates of drug use than were available previ- \nously. Model estimates of the ever-used population (along with the other categories \nof drug use) were derived to be consistent with other demographic, crime, health, \nprice, and purity data, constrained by the stock and flow structure of the population \nand epidemiological and medical data on health risks. Understanding the dynam- \nics of the stocks and flows of users helps reconcile the apparently contradictory \ndata. Figure 7-15 compares the model’s behavior for reported lifetime use against \nthe survey data, along with the model’s estimate of the actual ever-used population. \nThe actual population of past users must have continued to grow because the num- \nber of people trying cocaine for the first time exceeded the death rate of those who \nhad ever tried it. The availability, purity, and use of cocaine were in fact increasing \nthroughout the late 1980s despite the billions spent on enforcement and supply \nreduction. \nIn hindsight it seems quite obvious that the stock of people who have ever used \ncocaine cannot decline as rapidly as the data suggested, so the survey data should \nimmediately have been challenged. But hindsight is always crystal clear. The fact \nremains that the data were not challenged. Instead, the government used the survey \ndata to take credit for winning the drug war, to justify intervention in the affairs of \nother nations, and to lobby for tougher penalties, greater powers for law enforce- \nment agencies, more prisons, and more resources to defend the borders of the US \nagainst the threat of foreign drugs. \nPerhaps the administration knew the data overstated the reduction in drug use \nand used it cynically to manipulate public opinion and the congress. Even if true, \nit immediately begs the question of why others in government, along with the me- \ndia, policy analysts, and the public at large did not recognize the flaw in the data. \nThe administration, congress, and the media all focused on the data showing \nrecent use-the NHS past month or past week data, along with the HSSS-rather ","page_start":282,"page_end":282,"token_count":650,"section_type":"other","chapter_number":8,"chapter_title":"Closing the Loop:","chunk_index":352}
{"chunk_id":"4891461e174b7f7b","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"and used it cynically to manipulate public opinion and the congress. Even if true, \nit immediately begs the question of why others in government, along with the me- \ndia, policy analysts, and the public at large did not recognize the flaw in the data. \nThe administration, congress, and the media all focused on the data showing \nrecent use-the NHS past month or past week data, along with the HSSS-rather \nthan lifetime use. Recent use provides a better snapshot of current drug trends, and \nshowed the largest decline, making the case most favorable to the administration. \nHowever, the data showing decline in recent use confounded the actual decline \nin use with the increase in underreporting. The two sources of decline cannot be \ndisentangled from the recent-use data because the recent user stock can drop as \npeople quit; likewise, past users age out of the high school senior population. It is ","page_start":282,"page_end":282,"token_count":192,"section_type":"other","chapter_number":8,"chapter_title":"Closing the Loop:","chunk_index":353}
{"chunk_id":"3ab39eb204c2c4cd","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"258 \nPart I1 Tools for Systems Thinking \nFIGURE 7-1 5 \nSimulated vs. \nactual population \nof lifetime cocaine \nusers \nNote that while the \nsurvey data show \na drop in the ever- \nused population \nafter 1982, the \nmodel estimates \nfor the actual \npopulation of \nthose who have \never used cocaine \ncontinue to rise, \nthough at a \ndiminishing rate. \nIncreasing legal \nrisks led to a large \nincrease in the \nfraction of former \nusers who denied \ntheir cocaine use. \nS \n0 .- \nc \nE = \n0.2- \nFraction \n1976 \n1980 \n1984 \n1988 \n1992 \n1996 \no\n,\n,\n,\n.\n,\n,\n,\n,\n,\n,\n,\n,\n,\n,\n,\n,\nI\n,\nSource: Homer (1993, 1997). \nonly by explicitly accounting for the stock and flow structure of drug use-for the \ninexorable accumulation of users into the ever-used population-that the two com- \npeting sources of decline in current use data can be separated. Unfortunately, the \nability to understand basic stock and flow relationships is far too rare in our soci- \nety today, even among many professional policy analysts. \n7.3.1 \nThe Cocaine Epidemic after 1990 \nThe model showed persuasively that the survey data significantly underestimated \ncocaine use and highlighted the failure of the supply-side strategy. As MacCoun \nand Reuter (1997, p. 47) put it, “The probability of a cocaine or heroin seller being \nincarcerated has risen sharply since about 1985 but that has led neither to increased \nprice nor reduced availability.” However, a close look at the simulation in Figure \n7-15 shows that by the late 1980s the number of people who had ever used \ncocaine, though still rising, was growing at a diminishing rate. Therefore the ini- \ntiation rate must have been falling. By the mid 1990s, the epidemic began to abate: \nthe growth of cocaine-related medical emergencies and deaths slowed; arrests fell \nslightly. The ONDCP estimated net imports in 1995 at between 421 and 5 13 metric \ntons, with 98 metric tons seized, leaving net cocaine available on the streets of \nAmerica at about three-quarters the 1989 level. The model, originally developed \nin the late 1980s, forecast these dramatic shifts in cocaine use quite well (Fig- \nure 7-16). \nNote that the point-by-point fit of the model in the 1990s isn’t perfect, and you \nshould not expect it to be. Simulated arrests are too high, and the model does not \ntrack the temporary dip in cocaine related medical emergencies in 1990-9 1. Never- ","page_start":283,"page_end":283,"token_count":604,"section_type":"other","chapter_number":8,"chapter_title":"Closing the Loop:","chunk_index":354}
{"chunk_id":"c4491dd7cfdcc063","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"in the late 1980s, forecast these dramatic shifts in cocaine use quite well (Fig- \nure 7-16). \nNote that the point-by-point fit of the model in the 1990s isn’t perfect, and you \nshould not expect it to be. Simulated arrests are too high, and the model does not \ntrack the temporary dip in cocaine related medical emergencies in 1990-9 1. Never- \ntheless, the model’s ability to capture the turning point in the epidemic, from \nexponential growth to gradual decline, is quite remarkable, considering that the \nsimulations shown in Figure 7-16 were based on data available only through 1989. \nThe only exogenous inputs affecting model behavior after 1990 are the target \npopulation (those age 12 and over) and the prevalence of marijuana use (a proxy \nfor social tolerance of drugs). Changes in data-reporting systems and definitions \nwere not included. ","page_start":283,"page_end":283,"token_count":200,"section_type":"other","chapter_number":8,"chapter_title":"Closing the Loop:","chunk_index":355}
{"chunk_id":"50ed29e13effa273","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"Chapter I \nDynamics of Stocks and Flows \nHistory \n259 \nForecast \nFIGIJRE \n7-1 6 \nSimulated vs. \nactual cocaine \nepidemic \nDashed lines, \ndata; solicl lines, \nmodel. \nHistory Forecast \n1 \nL \n600- \nP \n% 4001 \na, \nP - \n-0 \nm \nu) \nc \nI- s 200: \n1976 \n1980 \n1984 \n1988 \n1992 \n0 \n1 \n1996 \n- 0 . 0 5  \n~\n\"\n\"\n'\n~\n\"\n\"\n\"\n'\n'\n*\n \n5 \n. \nSimulated \nHistory Forecast \n1976 \n1980 \n1984 \n1988 \n1992 \n1996 \nSource: Homer (1 993, 1997). \nAdding additional exogenous inputs could improve the fit to the data. But \nmodels should not be tuned to fit data by introducing exogenous variables whose \nsole function is to improve the correspondence of model output to data. Exogenous \nvariables must be justified by significant real world evidence independent of their \npotential contribution to historical fit. Further, variables involved in any feedback \nloops judged to be potentially significant relative to the model purpose must be \ncaptured as part of the model's endogenous structure and cannot be used as exoge- \nnous inputs to improve historical fit. \n","page_start":284,"page_end":284,"token_count":294,"section_type":"other","chapter_number":8,"chapter_title":"Closing the Loop:","chunk_index":356}
{"chunk_id":"303d57e041d3d517","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"260 \nPart I1 Tools for Systems Thinking \nWhile the model shows that the survey data overestimated the decline in co- \ncaine use, model-generated estimates of the actual number of active users, while \nremaining significantly higher than the estimates reported in the surveys, do show \na decline. The field research and model results showed the drop in cocaine use was \nnot caused primarily by the Supply Disruption Loop B 1 in Figure 7-13 or by the \nClean up the Streets loop B2, as supporters of the interdiction policy claimed. \nRather, the exponential growth of cocaine use was eventually halted by two nega- \ntive feedbacks involving public perceptions of cocaine’s health and legal risks. \nFirst, cocaine is not the benign substance it was thought to be in the 1970s. As peo- \nple began to experience or hear about the Negative Health and Social Effects of the \ndrug, they became less likely to start and more likely to stop (balancing loop B3 in \nFigure 7-13). Second, growing legal risks of drug use due to higher arrest rates and \nlonger sentences decreased the willingness of people to start and increased the quit \nrate-the Fear of Arrest reduced usage (balancing loop B4). As the population of \nactive users began to fall, the social exposure of nonusers also fell, weakening the \nreinforcing Word of Mouth loop (R1). \nUnfortunately, both of these negative loops involve long delays. First, there is \na lag between growth in cocaine use and the incidence of harmful health and legal \neffects. As the initiation rate grew exponentially, so did the stock of active casual \nusers. The stock of compulsive users also rose exponentially, though with a sub- \nstantial lag. The lag in the growth of the compulsive user population is important \nbecause compulsive users are more likely to experience severe health effects (es- \npecially as they turn to crack) and more likely to commit drug-related crimes in- \ncluding pushing the drug to finance their own habits. Thus the exponential growth \nin cocaine-related crime, arrests, medical emergencies, and deaths lags behind the \ngrowth of the casual user population, which in turn lags behind the initiation rate. \nThere is a further lag in the perception by the public of the true health effects \nof cocaine. Most people don’t read the New England Journal of Medicine or the \nAnnals of Addiction to learn about the health risks of illegal drugs. Instead, public \nperceptions of risk are strongly conditioned by personal experience, personal \nacquaintance with someone harmed by cocaine, and media reports of high-profile \nindividuals who were arrested for, injured by, or died from cocaine use, such as the \ncomedian Richard Pryor, who was severely burned while freebasing, or the Uni- \nversity of Maryland basketball star Len Bias, who died of acute heart failure while \ndoing cocaine to celebrate his selection as a top draft pick by the Boston Celtics of \nthe National Basketball Association. \nThe strength of all these channels of public awareness therefore lags behind \nthe population of active users driving the growth of the epidemic. Exponential ","page_start":285,"page_end":285,"token_count":654,"section_type":"other","chapter_number":8,"chapter_title":"Closing the Loop:","chunk_index":357}
{"chunk_id":"8e4b0b23287239dc","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"comedian Richard Pryor, who was severely burned while freebasing, or the Uni- \nversity of Maryland basketball star Len Bias, who died of acute heart failure while \ndoing cocaine to celebrate his selection as a top draft pick by the Boston Celtics of \nthe National Basketball Association. \nThe strength of all these channels of public awareness therefore lags behind \nthe population of active users driving the growth of the epidemic. Exponential \ngrowth in cocaine use did eventually reduce the social acceptability of the drug and \nthus the initiation rate. However, the stock of active users lags well behind the ini- \ntiation rate. The stock of active users will rise as long as initiation exceeds the rate \nat which people stop using, and the stock of compulsive users increases as long as \nthe escalation rate exceeds the rate at which compulsive users stop. The dynamics \nof the stock and flow structure inevitably mean that the population of drug users, \nespecially the compulsive users responsible for most of the crime and health ef- \nfects, continues to grow even after the initiation rate peaks and falls. The delay en- \nsures that the reinforcing social exposure and word of mouth feedbacks dominate ","page_start":285,"page_end":285,"token_count":245,"section_type":"other","chapter_number":8,"chapter_title":"Closing the Loop:","chunk_index":358}
{"chunk_id":"955c89aa7df3b7e9","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"Chapter 7 Dynamics of Stocks and Flows \n261 \nthe negative risk perception loops in the early years of the epidemic, leading to a \nlater and higher peak for incidence and prevalence. \nStill, by the late 1980s, nearly every community had experienced the arrest, in- \njury, or death of at least one of its promising young people, slowly strengthening \nthe negative feedbacks that slow the initiation rate. Ironically, the cocaine epidemic \ndid not abate because interdiction made the drug less available; on the contrary, the \ndata showed growing accessibility, purity, and affordability throughout the 1980s. \nInstead, the very abundance of cocaine, by leading to a large increase in personal \nknowledge of its harmful effects, led people to turn away from the drug. No longer \nchic, stripped of its social aura and benign image, those who craved escape from \nthe world turned from cocaine to other drugs. Thus, the cocaine epidemic was ul- \ntimately self-limiting. \nThe feedback structure outlined in Figure 7-13 is quite general and applies to \nany harmful drug, legal or illegal. The positive feedbacks generating growth in us- \nage act swiftly, while the negative feedbacks that deter usage, particularly public \nrecognition of a drug’s harmful effects, are only perceived slowly. The result is the \ncharacteristic boom and bust pattern for drug use. Each new or newly popular drug \ngenerates a wave of naive enthusiasm in which users extol its benefits, only to dis- \ncover as the population of users grows and more people escalate to compulsive use \nthat the drug isn’t as benign as people were led to believe. \nIn fact, the cocaine epidemic of the 1980s was not the first. A similar boom and \nbust in cocaine use occurred in the late 1800s. It began with medicinal use, as co- \ncaine was praised by the medical community, including Freud in his famous 1884 \npaper “On Coca,” as a cure for opium addiction, alcoholism, fatigue, depression, \nnervousness, timidity, impotence, and seasickness, among other complaints. Fol- \nlowing the classic pattern, cocaine moved into more general and recreational use, \nbecoming an ingredient in Coca-Cola and some cigarettes. As use spread, avail- \nability and purity increased; instead of injecting or drinking the preparation, pow- \nder for snorting became popular. Soon the harmful effects began to be experienced, \nobserved, and reported in the medical and popular press. By the early 1900s, co- \ncaine use had spread from social elites to lower social classes. Communities across \nthe country struggled to deal with compulsive users (known as “coke fiends”), and \n“by 1914 the Atlanta police chief was blaming 70 percent of the crimes [in the city] \non cocaine” (Grinspoon and Bakalar 1985, p. 38). In response, legal restrictions \nand prohibitions grew increasingly severe; in 1922 congress defined cocaine as a ","page_start":286,"page_end":286,"token_count":645,"section_type":"other","chapter_number":8,"chapter_title":"Closing the Loop:","chunk_index":359}
{"chunk_id":"2d8f5d348844a4ca","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"the country struggled to deal with compulsive users (known as “coke fiends”), and \n“by 1914 the Atlanta police chief was blaming 70 percent of the crimes [in the city] \non cocaine” (Grinspoon and Bakalar 1985, p. 38). In response, legal restrictions \nand prohibitions grew increasingly severe; in 1922 congress defined cocaine as a \nnarcotic and banned importation of coca; by 193 1 every state had restricted its sale \nand most made possession a crime. Cocaine use fell from its peak and remained \nlow as people turned to other drugs, until the current epidemic began. Similar \nwaves of drug use have been repeatedly observed for the opiates, for psychedelics, \nand for various stimulants and barbiturates. \nWhile epidemics of any particular illegal drug are ultimately self-limiting (if \nthe drug is harmful enough) people have always sought out mind-altering sub- \nstances. Even as one drug falls out of favor, new epidemics begin, centered on new \ndrugs for which there is as yet no experience of harmful effects or on old drugs for \nwhich the hard-won knowledge of harm gained by prior generations has faded \nfrom collective memory. The modest decline in cocaine use in the 1990s led to an \nincrease in the use of other drugs, including marijuana, methamphetamine, and ","page_start":286,"page_end":286,"token_count":296,"section_type":"other","chapter_number":8,"chapter_title":"Closing the Loop:","chunk_index":360}
{"chunk_id":"44810ef12a054a4f","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"262 \n7.4 \nPart I1 Tools for Systems Thinking \nmost troubling, a resurgence of heroin use, more than 20 years after the last wave \nof heroin crested. This latest heroin epidemic was stimulated by the usual self- \nreinforcing word of mouth and media feedbacks, including the glorification of \n“heroin chic” in popular culture and Calvin Klein underwear ads.5 \nSUMMARY \nThis chapter showed how stocks and flows generate dynamics. The process of ac- \ncumulation is equivalent to integration in calculus. The amount added to a stock in \nany period is equal to the area swept out by the net rate of change in the stock over \nthat period. Conversely, the slope of the trajectory of a stock at any time is its de- \nrivative, the net rate of change. Graphical methods for integration and differentia- \ntion were introduced. Given the behavior over time for the rates affecting any \nstock, you can deduce the behavior of the stock; given the trajectory of the stock \nyou can deduce its net rate of change, all without use of calculus. The ability to re- \nlate stocks and flows intuitively is essential for all modelers, even those with ex- \ntensive mathematics training, because most realistic models have no analytical \nsolutions. Examples show that understanding the dynamics of stocks and flows, \neven without feedback, can yield insight into important problems. \n5Further reading: Shreckengost developed a model for the US CIA to estimate heroin imports \nby integrating prevalence, crime, price, purity, and other data (Gardiner and Shreckengost 1987). \nShreckengost (1991) applies the framework to cocaine. Levin, Hirsch, and Roberts (1975), in The \nPersistent Poppy, develop a system dynamics model of heroin use and abuse in a community based \non a case study of the south Bronx. They use the model to explore a variety of policy options in- \ncluding demand-side policies, increased enforcement, and methadone maintenance. See also Levin, \nHirsch, and Roberts (1978). Richardson (1983) develops a simple model to explain why aggressive \npolice effort to seize street supplies of heroin actually increases drug-related crime. Goluke, \nLandeen, and Meadows (1981a, 1981b) developed a model of addictive behavior, focusing on \nalcoholism. Holder and Blose (1987) develop a model of community level policy responses to \nalcoholism. Homer et al. (1982) present a system dynamics model of (tobacco) smoking and \nanalyze a variety of policies. \n","page_start":287,"page_end":287,"token_count":552,"section_type":"other","chapter_number":8,"chapter_title":"Closing the Loop:","chunk_index":361}
{"chunk_id":"830ca81d6d5a393c","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"8 \nClosing the Loop: Dynamics of \nSimple Structures \nA mathematical theory is not to be considered complete until you have made it \nso clear that you can explain it to the first man whom you meet on the street. \n-David Hilbert \nI hope to show. ..that mathematical notation can be kept close to the vocabulary \nof business; that each variable and constant in an equation has individual \nmeaning to the practicing manager; that the required mathematics is within the \nreach of almost anyone who can successfully manage a modern corporation. \n-Jay W. Forrester (Industrial Dynamics, 1961, p. 9) \nThis chapter formalizes the connection between structure and behavior by linking \nfeedback with stock and flow structures. The focus is the simplest feedback sys- \ntems, those with one stock (known as first-order systems). Linear first-order sys- \ntems (defined in this chapter) can generate exponential growth and goal-seeking \nbehavior. Nonlinearity in first-order systems causes shifts in the dominant loops, \nleading for example to S-shaped growth. The chapter also introduces the concept \nof a phase plot-a graph showing how the net rate of change of a stock is related \nto the stock itself-and shows how dynamics can be derived from the phase plot \nwithout calculus or differential equations. \n8.l \nFIRSFORDER \nSYSTEMS \nChapter 4 discussed the basic modes of behavior generated by complex systems \nand the feedback structures responsible for them. The most fundamental modes are \n263 \n","page_start":288,"page_end":288,"token_count":308,"section_type":"other","chapter_number":8,"chapter_title":"Closing the Loop:","chunk_index":362}
{"chunk_id":"01a3d79be8699d81","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"264 \nPart I1 Tools for Systems Thinking \nFIGURE 8-1 Growth and goal seeking: structure and behavior \nState of the / \nNet / \ni+ \nIncrease \ns;:.~he \nRate \nGoal \n- \nTime - \n+ State of the \nGoal \nSystem \\ \n(Desired \n\\ S t a T f  System) \n( \nDiscrepancy + \nCorrective \nAction \n+ \nexponential growth and goal seeking. Positive feedback causes exponential \ngrowth, and negative feedback causes goal-seeking behavior (Figure 8- 1). \nThe simplest system that can generate these behaviors is the first-order, linear \nfeedback system. The order of a dynamic system or loop is the number of state \nvariables, or stocks, it contains. A first-order system contains only one stock. Lin- \near systems are systems in which the rate equations are linear combinations of the \nstate variables and any exogenous inputs. \nThe term “linear” has a precise meaning in dynamics: in a linear system the \nrate equations (the net inflows to the stocks) are always a weighted sum of the state \nvariables (and any exogenous variables, denoted Uj ): \ndS/dt = Net Inflow = alSl + a,S2 + . . . + a$” f blUl + b2U2 + . . . + bmUm (8-1) \nwhere the coefficients ai and bj are constants. Any other form for the net inflows is \nnonlinear.’ \n8.2 \nPOSITIVE FEEDBACK AND EXPONENTIAL GROWTH \nThe simplest feedback system is a first-order positive feedback loop. In a first- \norder system, there is only one state variable (stock), denoted here by s. The state \nof the system accumulates its net inflow rate; in turn, the net inflow depends on the \n‘For example, formulations for the net inflow such as a, * S1 * Sz, a, * Sl/S2. or MAX(0, al * S,) \nare all nonlinear. The term “nonlinear” is often used in other senses, for example to describe the \nnonchronological narrative structure of novels such as Cortizar ’s Hopscotch. The term “nonlinear” \nin these contexts actually means “nonsequential” and has nothing to do with the technical meaning \nof linearity. \n","page_start":289,"page_end":289,"token_count":502,"section_type":"other","chapter_number":8,"chapter_title":"Closing the Loop:","chunk_index":363}
{"chunk_id":"4c4d4b4f9333e994","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"Chapter 8 Closing the Loop: Dynamics of Simple Structures \n265 \nstate of the system (for now, assume no exogenous inputs). In general, the net in- \nflow is a possibly nonlinear function of the state of the system: \nS = INTEGRAL(Net Inflow, S(0)) \n(8-2) \nNet Inflow = f<S). \n(8-3) \nIf the system is linear, the net inflow must be directly proportional to the state of \nthe system: \nNet Inflow = gS \n(8-4) \nwhere the constant g has units of (Mime) and represents the fractional growth rate \nof the stock.2 \nFigure 8-2 shows the structure of this system as a causal diagram and also as a \nset of equations. As examples, consider the accumulation of interest income into a \nbank account or the growth of a population. The principal and prevailing interest \nrate determine the interest payment; population and the fractional net birth rate \ndetermine the net birth rate.3 \nWhat will the behavior of the system be? Section 8.2.1 uses basic calculus to \nsolve the differential equation; the solution is the exponential function \ns(t> = S(O)exp(gt) \n(8-5) \nwhere S(0) is the value of S at the initial time t = 0. The state of the system grows \nexponentially from its initial value at a constant fractional rate of g per time unit. \n8.2.1 \nAnalytic Solution for the \nLinear First-Order System \nTo solve the differential equation for the first-order linear system, dS/dt = gS, first \nseparate variables, to obtain \ndS - \n= gdt \nS \nNow, integrate both sides \n1 f = lgdt \nto get \nln(S) = gt + c \nwhere c is a constant. Taking exponentials of both sides gives \n21n the general case of a multistate system, the rates of change, dS/dt, are a functionfo of the \nstate vector S and any exogenous variables U: dS/dt = f ( S ,  U). In a linear system, the rates are \nlinear combinations of the states and exogenous variables: dS/dt = AS + BU where A and B are \nmatrices of coefficients. For good treatments of linear system theory, see, e.g., Ogata (1997) and \nKamopp, Margolis, and Rosenberg (1990). \nbirth and the ability to reproduce, a poor assumption for mammals, but reasonable for many \nunicellular and other small organisms. \n3Representing population growth as a first-order process assumes there is no delay between \n","page_start":290,"page_end":290,"token_count":575,"section_type":"other","chapter_number":8,"chapter_title":"Closing the Loop:","chunk_index":364}
{"chunk_id":"31006b20108dbeba","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"266 \nPart I1 Tools for Systems Thinking \ndS/dt \nT7 \nL1 \nNet Inflow \nS \nState of \nthe System \ndS/dt = Net Inflow Rate = gS \nExamples \n.i7 \nL1 \nPrincipal \nNet Interest \nNet Interest Income \n= Interest Rate * Principal \nInterest Rate d \nPopulation \nNet Birth \nNet Birth Rate \n= Fractional Net Birth Rate * Population \nFractional Net \nBirth Rate \nS = c*exp(gt) \n(8-9) \nwhere c* is exp(c). The value of S at the initial time, when exp(gt) = 1, is by defi- \nnition S(O), so c* must equal S(0). Substitution yields equation (8-5). \n8.2.2 \nGraphical Solution of the \nLinear First-Order Positive Feedback System \nYou do not need calculus to solve the equation for the first-order linear system. \nYou can also deduce its behavior graphically. Figure 8-3 shows a third representa- \ntion of the structure of the system: a phase plot-a graph showing the net rate as a \nfunction of the state of the system. The graph shows that the net inflow rate is a \nstraight line starting at the origin with positive slope g. \n","page_start":291,"page_end":291,"token_count":276,"section_type":"other","chapter_number":8,"chapter_title":"Closing the Loop:","chunk_index":365}
{"chunk_id":"71386dd78d841b57","file_id":"17d50151-db40-466e-8791-9f869023eec4","filename":"John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf","text":"Chapter 8 Closing the Loop: Dynamics of Simple Structures \n267 \nFIGURE \n8-3 \nPha.se plot for \nthe first-order, \nlinear positive \nfeedback system \ndS/dt = Net inflow Rate = gS \n0 \no\n\\\n \nState of the System (units) \nUnstable \nEquilibrium \nNote that if the state of the system is zero, the net inflow is also zero. Zero is \nan equilibrium of the system: no savings, no interest income; no people, no births. \nHowever, the equilibrium is unstable: add any quantity to the stock and there will \nnow be a small, positive net inflow, increasing the state of the system a bit. The \ngreater state of the system leads now to a slightly greater net inflow and a still \nlarger addition to the stock. The slightest departure from the equilibrium leads to \nfurther movement away from the equilibrium, just as a ball balanced exactly at the \ntop of a hill, if disturbed even slightly, will roll ever faster away from the balance \npoint. The greater the state of the system, the greater the net inflow: this is pre- \ncisely the meaning of the positive feedback loop coupling the stock and its net in- \nflow. In the general case where the phase plot of a state variable can be nonlinear, \nthe state of the system will grow whenever the net rate is an increasing function of \nthe stock. An equilibrium is unstable whenever the slope of the net rate at the equi- \nlibrium point is positive. \nBecause the rate equation in the example is linear, the net increase rate grows \nexactly in proportion to the state of the system. Every time the state of the system \ndoubles, so too will its absolute rate of increase. Therefore, the trajectory of \nthe system in time shows an ever-increasing acceleration. Figure 8-4 shows the tra- \njectory of the first-order linear positive feedback system on the phase plot and as a \ntime series. In the figure, the growth rate g is 0.7%/time period and the initial state \nof the system is 1 unit. The arrows along the phase plot show that the flow of the \nsystem is away from the unstable equilibrium point. From any nonnegative start- \ning point, the state of the system grows at an ever-accelerating rate as it moves \nalong the line Net Inflow = gS.4 The accelerating growth is easily seen in the time \nVhe system is symmetric for negative values of the state variable. If S(0) < 0, S will become \never more negative at exponential rates. In most systems, however, the state variables are restricted \nto nonnegative values (there can be no negative populations). \n","page_start":292,"page_end":292,"token_count":576,"section_type":"other","chapter_number":8,"chapter_title":"Closing the Loop:","chunk_index":366}
{"chunk_id":"d1803dcfcfd687e8","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"Conceptual Understanding \nStudents need to be equipped with both the methods and conceptual  \nunderstanding of statistics. MyStatLab offers a full question library of over \n1,000 conceptual-based questions to help tighten the comprehension of  \nstatistical concepts.\nReal-World Statistics\nMyStatLab video resources help foster conceptual understanding. StatTalk  \nVideos, hosted by fun-loving statistician, Andrew Vickers, demonstrate  \nimportant statistical concepts through interesting stories and real-life events. \nThis series of 24 videos includes assignable questions built in MyStatLab and  \nan instructor’s guide.\nVisit www.mystatlab.com and click Get Trained to make sure  \nyou’re getting the most out of MyStatLab.\n","page_start":2,"page_end":2,"token_count":142,"section_type":"other","chapter_number":1,"chapter_title":"INTRODUCTION TO STATISTICS","chunk_index":0}
{"chunk_id":"f0724cf8ecd041da","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"BIOSTATISTICS\nFOR THE BIOLOGICAL  \nAND HEALTH SCIENCES\nMARC M. TRIOLA, MD, FACP\nNew York University School of Medicine\nMARIO F. TRIOLA\nDutchess Community College \nJASON ROY, PHD\nUniversity of Pennsylvania \nPerelman School of Medicine\nSECOND EDITION\n","page_start":3,"page_end":3,"token_count":70,"section_type":"other","chapter_number":1,"chapter_title":"INTRODUCTION TO STATISTICS","chunk_index":1}
{"chunk_id":"523f4d4b9ced0e5a","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"To Ginny\nDushana and Marisa\nTrevor and Mitchell\nDirector, Portfolio Management Deirdre Lynch\nSenior Portfolio Manager Suzy Bainbridge\nPortfolio Management Assistant Justin Billing\nContent Producer Peggy McMahon\nManaging Producer Karen Wernholm\nCourseware QA Manager Mary Durnwald\nSenior Producer Vicki Dreyfus\nProduct Marketing Manager Yvonne Vannatta\nField Marketing Manager Evan St. Cyr\nProduct Marketing Assistant Jennifer Myers\nField Marketing Assistant Erin Rush\nSenior Author Support/Technology Specialist Joe Vetere \nManager, Rights and Permissions Gina M. Cheselka\nText and Cover Design, Illustrations, Production  Coordination, \nComposition Cenveo Publisher Services\nCover Image Robert Essel NYC/Getty Images\nCopyright © 2018, 2006 by Pearson Education, Inc. All Rights Reserved. Printed in the United States of America. This publica-\ntion is protected by copyright, and permission should be obtained from the publisher prior to any prohibited reproduction, storage \nin a retrieval system, or transmission in any form or by any means, electronic, mechanical, photocopying, recording, or otherwise. \nFor information regarding permissions, request forms and the appropriate contacts within the Pearson Education Global Rights & \nPermissions department, please visit www.pearsoned.com/permissions/.\nAttributions of third party content appear on page 683–684, which constitutes an extension of this copyright page.\nPEARSON, ALWAYS LEARNING, and MYSTATLAB are exclusive trademarks owned by Pearson Education, Inc. or its affiliates \nin the U.S. and/or other countries.\nUnless otherwise indicated herein, any third-party trademarks that may appear in this work are the property of their respective own-\ners and any references to third-party trademarks, logos or other trade dress are for demonstrative or descriptive purposes only. Such \nreferences are not intended to imply any sponsorship, endorsement, authorization, or promotion of Pearson’s products by the owners \nof such marks, or any relationship between the owner and Pearson Education, Inc. or its affiliates, authors, licensees or distributors.\nMICROSOFT AND>OR ITS RESPECTIVE SUPPLIERS MAKE NO REPRESENTATIONS ABOUT THE SUITABILITY OF THE INFORMATION CONTAINED IN THE \nDOCUMENTS AND RELATED GRAPHICS PUBLISHED AS PART OF THE SERVICES FOR ANY PURPOSE. ALL SUCH DOCUMENTS AND RELATED GRAPHICS \nARE PROVIDED “AS IS” WITHOUT WARRANTY OF ANY KIND. MICROSOFT AND>OR ITS RESPECTIVE SUPPLIERS HEREBY DISCLAIM ALL WARRANTIES \nAND CONDITIONS WITH REGARD TO THIS INFORMATION, INCLUDING ALL WARRANTIES AND CONDITIONS OF MERCHANTABILITY, WHETHER EXPRESS, \nIMPLIED OR STATUTORY, FITNESS FOR A PARTICULAR PURPOSE, TITLE AND NON-INFRINGEMENT. IN NO EVENT SHALL MICROSOFTAND>OR ITS RESPEC-\nTIVE SUPPLIERS BE LIABLE FOR ANY SPECIAL, INDIRECT OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES WHATSOEVER RESULTING FROM LOSS OF \nUSE, DATA OR PROFITS, WHETHER IN AN ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT OF OR IN CONNECTION WITH \nTHE USE OR PERFORMANCE OF INFORMATION AVAILABLE FROM THE SERVICES.\nTHE DOCUMENTS AND RELATED GRAPHICS CONTAINED HEREIN COULD INCLUDE TECHNICAL INACCURACIES OR TYPOGRAPHICAL ERRORS. CHANGES ","page_start":4,"page_end":4,"token_count":664,"section_type":"other","chapter_number":1,"chapter_title":"INTRODUCTION TO STATISTICS","chunk_index":2}
{"chunk_id":"d32174e398691aa5","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"TIVE SUPPLIERS BE LIABLE FOR ANY SPECIAL, INDIRECT OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES WHATSOEVER RESULTING FROM LOSS OF \nUSE, DATA OR PROFITS, WHETHER IN AN ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT OF OR IN CONNECTION WITH \nTHE USE OR PERFORMANCE OF INFORMATION AVAILABLE FROM THE SERVICES.\nTHE DOCUMENTS AND RELATED GRAPHICS CONTAINED HEREIN COULD INCLUDE TECHNICAL INACCURACIES OR TYPOGRAPHICAL ERRORS. CHANGES \nARE PERIODICALLY ADDED TO THE INFORMATION HEREIN. MICROSOFT AND>OR ITS RESPECTIVE SUPPLIERS MAY MAKE IMPROVEMENTS AND>OR \nCHANGES IN THE PRODUCT(S) AND>OR THE PROGRAM(S) DESCRIBED HEREIN AT ANY TIME. PARTIAL SCREEN SHOTS MAY BE VIEWED IN FULL WITHIN \nTHE SOFTWARE VERSION SPECIFIED.\nLibrary of Congress Cataloging-in-Publication Data\nNames: Triola, Marc M. | Triola, Mario F. | Roy, Jason (Jason Allen)\nTitle: Biostatistics for the biological and health sciences.\nDescription: Second edition / Marc M. Triola, New York University, \nMario F. Triola, Dutchess Community College, Jason Roy, University of \nPennsylvania. | Boston : Pearson, [2018] | Includes bibliographical \nreferences and index.\nIdentifiers: LCCN 2016016759| ISBN 9780134039015 (hardcover) | ISBN\n0134039017 (hardcover)\nSubjects: LCSH: Biometry. | Medical statistics.\nClassification: LCC QH323.5 .T75 2018 | DDC 570.1/5195–dc23\nLC record available at https://lccn.loc.gov/2016016759\n1 16\nISBN 13: 978-0-13-403901-5\nISBN 10: 0-13-403901-7","page_start":4,"page_end":4,"token_count":406,"section_type":"other","chapter_number":1,"chapter_title":"INTRODUCTION TO STATISTICS","chunk_index":3}
{"chunk_id":"fad0628ad7f50faf","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"iii\nMarc Triola, MD, FACP is the \nAssociate Dean for Educational \nInformatics at NYU School of \nMedicine, the founding director \nof the NYU Langone  Medical \nCenter Institute for Innovations \nin Medical Education (IIME), \nand an  Associate Professor of \nMedicine. Dr. Triola’s research \nexperience and expertise focus \non the disruptive effects of the \npresent revolution in educa-\ntion, driven by technological \nadvances, big data, and learn-\ning analytics. Dr. Triola has \nworked to create a “learning \necosystem” that includes interconnected computer-based e-learning tools and new \nways to effectively integrate growing amounts of electronic data in educational re-\nsearch. Dr. Triola and IIME have been funded by the National Institutes of Health, \nthe Integrated Advanced Information Management Systems program, the National \nScience Foundation Advanced Learning Technologies program, the Josiah Macy, \nJr. Foundation, the U.S. Department of Education, and the American Medical As-\nsociation Accelerating Change in Medical Education program. He chairs numer-\nous committees at the state and national levels focused on the future of health \nprofessions educational technology development and research.\nMario F. Triola is a Professor \nEmeritus of Mathematics at \nDutchess Community College, \nwhere he has taught statistics \nfor over 30 years. Marty is the \nauthor of Elementary Statistics, \n13th edition, Essentials of Sta-\ntistics, 5th edition, Elementary \nStatistics Using Excel, 6th edi-\ntion, and Elementary Statis-\ntics Using the TI-83>84 Plus \nCalculator, 4th edition, and \nhe is a co-author of Statistical \nReasoning for Everyday Life, \n5th edition. Elementary Statis-\ntics is currently available as an \nInternational Edition, and it has been translated into several foreign languages. \nMarty designed the original Statdisk statistical software, and he has  written \n several  manuals and workbooks for technology supporting statistics education. \nABOUT THE AUTHORS\n","page_start":5,"page_end":5,"token_count":425,"section_type":"other","chapter_number":1,"chapter_title":"INTRODUCTION TO STATISTICS","chunk_index":4}
{"chunk_id":"d3e4bbafcf3f70a2","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"iv \nAbout the Authors\nHe has been a speaker at many conferences and colleges. Marty’s consulting work \nincludes the design of casino slot machines and the design of fishing rods. He has \nworked with attorneys in determining probabilities in paternity lawsuits, analyz-\ning data in medical malpractice lawsuits, identifying salary inequities based on \ngender, and analyzing disputed election results. He has also used statistical meth-\nods in analyzing medical school surveys and in analyzing survey results for the \nNew York City Transit Authority. Marty has testified as an expert witness in the \nNew York State Supreme Court.\nJason Roy, PhD, is Associate \nProfessor of Biostatistics in \nthe Department of Biostatistics \nand Epidemiology, Perelman \nSchool of Medicine, Univer-\nsity of Pennsylvania. He re-\nceived his PhD in Biostatistics \nin 2000 from the University \nof Michigan. He was recipi-\nent of the 2002 David P. Byar \nYoung Investigator Award from \nthe American Statistical Asso-\nciation Biometrics Section. His \nstatistical research interests are \nin the areas of causal inference, \nmissing data, and prediction \nmodeling. He is especially interested in the statistical challenges with analyzing \ndata from large health care databases. He collaborates in many different disease \nareas, including chronic kidney disease, cardiovascular disease, and liver diseases. \nDr Roy is Associate Editor of Biometrics, Journal of the American Statistical \nAssociation, and Pharmacoepidemiology & Drug Safety, and has over 90 peer- \nreviewed publications.\n","page_start":6,"page_end":6,"token_count":327,"section_type":"other","chapter_number":1,"chapter_title":"INTRODUCTION TO STATISTICS","chunk_index":5}
{"chunk_id":"4f2830149674a022","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"v\nCONTENTS\n1 \nINTRODUCTION TO STATISTICS \n1\n1-1  \nStatistical and Critical Thinking  4\n1-2  \nTypes of Data  13\n1-3  \nCollecting Sample Data  24\n2 \nEXPLORING DATA WITH TABLES AND GRAPHS \n40\n2-1  \nFrequency Distributions for Organizing and Summarizing Data  42\n2-2  Histograms  51\n2-3  Graphs That Enlighten and Graphs That Deceive  56\n2-4  Scatterplots, Correlation, and Regression  65\n3 \nDESCRIBING, EXPLORING, AND COMPARING DATA \n75\n3-1  \nMeasures of Center  77\n3-2  Measures of Variation  89\n3-3  Measures of Relative Standing and Boxplots  102\n4 \nPROBABILITY \n118\n4-1  \nBasic Concepts of Probability  120\n4-2  Addition Rule and Multiplication Rule  131\n4-3  Complements, Conditional Probability, and Bayes’ Theorem  144\n4-4  Risks and Odds  153\n4-5  Rates of Mortality, Fertility, and Morbidity  162\n4-6  Counting  167\n5 \nDISCRETE PROBABILITY DISTRIBUTIONS \n180\n5-1  \nProbability Distributions  182\n5-2  Binomial Probability Distributions  193\n5-3  Poisson Probability Distributions  206\n6 \nNORMAL PROBABILITY DISTRIBUTIONS \n216\n6-1  \nThe Standard Normal Distribution  218\n6-2  Real Applications of Normal Distributions  231\n6-3  Sampling Distributions and Estimators  241\n6-4  The Central Limit Theorem  252\n6-5  Assessing Normality  261\n6-6  Normal as Approximation to Binomial  269\n7 \nESTIMATING PARAMETERS AND DETERMINING SAMPLE SIZES \n282\n7-1 \nEstimating a Population Proportion  284\n7-2  Estimating a Population Mean  299\n7-3  Estimating a Population Standard Deviation or Variance  315\n7-4  Bootstrapping: Using Technology for Estimates  324\n8 \nHYPOTHESIS TESTING  \n336\n8-1  \nBasics of Hypothesis Testing  338\n8-2  Testing a Claim About a Proportion  354\n8-3  Testing a Claim About a Mean  366\n8-4  Testing a Claim About a Standard Deviation or Variance  377\n9 \nINFERENCES FROM TWO SAMPLES  \n392\n9-1  \nTwo Proportions  394\n9-2  Two Means: Independent Samples  406\n9-3  Two Dependent Samples (Matched Pairs)  418\n9-4  Two Variances or Standard Deviations  428\n","page_start":7,"page_end":7,"token_count":648,"section_type":"other","chapter_number":1,"chapter_title":"INTRODUCTION TO STATISTICS","chunk_index":6}
{"chunk_id":"8cde3d2c1ea70565","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"vi \nContents\n10 \nCORRELATION AND REGRESSION  \n442\n10-1  Correlation  444\n10-2  Regression  462\n10-3  Prediction Intervals and Variation  474\n10-4  Multiple Regression  481\n10-5  Dummy Variables and Logistic Regression  489\n11 \nGOODNESS-OF-FIT AND CONTINGENCY TABLES  \n502\n11-1  Goodness-of-Fit  503\n11-2  Contingency Tables  514\n12 \nANALYSIS OF VARIANCE  \n531\n12-1  One-Way ANOVA  533\n12-2  Two-Way ANOVA  547\n13 \nNONPARAMETRIC TESTS  \n560\n13-1  Basics of Nonparametric Tests  562\n13-2  Sign Test  564\n13-3  Wilcoxon Signed-Ranks Test for Matched Pairs  575\n13-4  Wilcoxon Rank-Sum Test for Two Independent Samples  581\n13-5  Kruskal-Wallis Test for Three or More Samples  586\n13-6  Rank Correlation  592\n14 \nSURVIVAL ANALYSIS  \n603\n14-1  Life Tables  604\n14-2  Kaplan-Meier Survival Analysis  614\nAPPENDIX A TABLES  \n625\nAPPENDIX B DATA SETS  \n638\nAPPENDIX C WEBSITES AND BIBLIOGRAPHY OF BOOKS   \n645\nAPPENDIX D ANSWERS TO ODD-NUMBERED SECTION EXERCISES  \n646\n(and all Quick Quizzes, all Review Exercises, and all Cumulative Review Exercises)\nCredits  683\nIndex  685\n","page_start":8,"page_end":8,"token_count":377,"section_type":"other","chapter_number":1,"chapter_title":"INTRODUCTION TO STATISTICS","chunk_index":7}
{"chunk_id":"ba8e2147c9d3b339","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"PREFACE\nStatistics permeates nearly every aspect of our lives, and its role has become partic-\nularly important in the biological, life, medical, and health sciences. From opinion \npolls to clinical trials in medicine and analysis of big data from health applications, \nstatistics influences and shapes the world around us. Biostatistics for the Health and \nBiological Sciences forges the relationship between statistics and our world through \nextensive use of a wide variety of real applications that bring life to theory and \nmethods.\nGoals of This Second Edition\n \n■Incorporate the latest and best methods used by professional statisticians.\n \n■Include features that address all of the recommendations included in the Guide-\nlines for Assessment and Instruction in Statistics Education (GAISE) as recom-\nmended by the American Statistical Association.\n \n■Provide an abundance of new and interesting data sets, examples, and exercises.\n \n■Foster personal growth of students through critical thinking, use of technology, \ncollaborative work, and development of communication skills.\n \n■Enhance teaching and learning with the most extensive and best set of supple-\nments and digital resources.\nAudience, Prerequisites\nBiostatistics for the Health and Biological Sciences is written for students major-\ning in the biological and health sciences, and it is designed for a wide variety of \nstudents taking their first statistics course. Algebra is used minimally, and calculus \nis not required. It is recommended that students have completed at least an elemen-\ntary algebra course or that students should learn the relevant algebra components \nthrough an integrated or co-requisite course. In many cases, underlying theory is \nincluded, but this book does not require the mathematical rigor more appropriate for \nmathematics majors.\nHallmark Features\nGreat care has been taken to ensure that each chapter of Biostatistics for the Health \nand Biological Sciences will help students understand the concepts presented. The \nfollowing features are designed to help meet that objective.\nReal Data\nHundreds of hours have been devoted to finding data that are real, meaningful, and \ninteresting to students. Fully 87% of the examples are based on real data, and 89% of \nthe exercises are based on real data. Some exercises refer to the 18 data sets listed in \nAppendix B, and 12 of those data sets are new to this edition. Exercises requiring use \nof the Appendix B data sets are located toward the end of each exercise set and are \nmarked with a special data set icon \n.\nReal data sets are included throughout the book to provide relevant and interesting \nreal-world statistical applications, including biometric security, body measurements, \nbrain sizes and IQ scores, and data from births. Appendix B includes descriptions of \nvii\n","page_start":9,"page_end":9,"token_count":562,"section_type":"other","chapter_number":1,"chapter_title":"INTRODUCTION TO STATISTICS","chunk_index":8}
{"chunk_id":"f60aaa9a972b8352","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"viii \nPreface\nthe 18 data sets that can be downloaded from the companion website www.pearson-\nhighered.com/triola, the author maintained www.TriolaStats.com and MyStatLab.\nTriolaStats.com includes downloadable data sets in formats for technologies \nincluding Excel, Minitab, JMP, SPSS, and TI@83>84 Plus calculators. The data \nsets are also included in the free Statdisk software, which is also available on the \nwebsite.\nReadability\nGreat care, enthusiasm, and passion have been devoted to creating a book that is readable, \nunderstandable, interesting, and relevant. Students pursuing any major in the biological, \nlife, medical, or health fields are sure to find applications related to their future work.\nWebsite\nThis textbook is supported by www.TriolaStats.com, and www.pearsonhighered.com/\ntriola which are continually updated to provide the latest digital resources, including:\n \n■Statdisk: A free, robust statistical software package designed for this book.\n \n■Downloadable Appendix B data sets in a variety of technology formats.\n \n■Downloadable textbook supplements including Glossary of Statistical Terms and \nFormulas and Tables.\n \n■Online instructional videos created specifically for this book that provide step-\nby-step technology instructions.\n \n■Triola Blog, which highlights current applications of statistics, statistics in the \nnews, and online resources.\nChapter Features\nChapter Opening Features\n \n■Chapters begin with a Chapter Problem that uses real data and motivates the \nchapter material.\n \n■Chapter Objectives provide a summary of key learning goals for each section in \nthe chapter.\nExercises\nMany exercises require the interpretation of results. Great care has been taken to \nensure their usefulness, relevance, and accuracy. Exercises are arranged in order of \nincreasing difficulty, and they begin with Basic Skills and Concepts. Most sections \ninclude additional Beyond the Basics exercises that address more difficult concepts or \nrequire a stronger mathematical background. In a few cases, these exercises introduce \na new concept.\nEnd-of-Chapter Features\n \n■Chapter Quick Quiz provides review questions that require brief answers.\n \n■Review Exercises offer practice on the chapter concepts and procedures.\n \n■Cumulative Review Exercises reinforce earlier material.\n \n■Technology Project provides an activity that can be used with a variety of \n technologies.\n \n■From Data to Decision is a capstone problem that requires critical thinking and \nwriting.\n \n■Cooperative Group Activities encourage active learning in groups.\n","page_start":10,"page_end":10,"token_count":510,"section_type":"other","chapter_number":1,"chapter_title":"INTRODUCTION TO STATISTICS","chunk_index":9}
{"chunk_id":"5bb4caa583866f8d","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"Preface \nix\nOther Features\nMargin Essays There are 57 margin essays designed to highlight real-world topics \nand foster student interest.\nFlowcharts The text includes flowcharts that simplify and clarify more complex con-\ncepts and procedures. Animated versions of the text’s flowcharts are available within \nMyStatLab and MathXL.\nQuick-Reference Endpapers Tables A-2 and A-3 (the normal and t distributions) are \nreproduced on the rear inside cover pages.\nDetachable Formula and Table Card This insert, organized by chapter, gives students \na quick reference for studying, or for use when taking tests (if allowed by the instruc-\ntor). It also includes the most commonly used tables. This is also available for download \nat www.TriolaStats.com, www.pearsonhighered.com/triola and in MyStatLab.\nTechnology Integration\nAs in the preceding edition, there are many displays of screens from technology through-\nout the book, and some exercises are based on displayed results from technology. Where \nappropriate, sections include a reference to an online Tech Center subsection that in-\ncludes detailed instructions for Statdisk, Minitab®, Excel®, StatCrunch, or a TI@83>84\nPlus® calculator. (Throughout this text, “TI-83>84 Plus” is used to identify a TI-83 Plus \nor TI-84 Plus calculator). The end-of-chapter features include a Technology Project.\nThe Statdisk statistical software package is designed specifically for this textbook \nand contains all Appendix B data sets. Statdisk is free to users of this book, and it can \nbe downloaded at www.statdisk.org.\nChanges in This Edition\nNew Features\nChapter Objectives provide a summary of key learning goals for each section in the \nchapter.\nLarger Data Sets: Some of the data sets in Appendix B are much larger than in the \nprevious edition. It is no longer practical to print all of the Appendix B data sets in this \nbook, so the data sets are described in Appendix B, and they can be downloaded at \nwww.TriolaStats.com, www.pearsonhighered.com/triola, and MyStatLab.\nNew Content: New examples, new exercises, and Chapter Problems provide relevant \nand interesting real-world statistical applications, including biometric security, drug \ntesting, gender selection, and analyzing ultrasound images.\nNumber\nNew to This Edition\nUse Real Data\nExercises\n1600\n85%\n89%\nExamples\n 200\n84%\n87%\nMajor Organization Changes\nAll Chapters\n \n■New Chapter Objectives: All chapters now begin with a list of key learning goals \nfor that chapter. Chapter Objectives replaces the former Overview numbered sec-\ntions. The first numbered section of each chapter now covers a major topic.\nChapter 1\n \n■New Section 1-1: Statistical and Critical Thinking\n \n■New Subsection 1-3, Part 2: Big Data and Missing Data: Too Much and Not Enough\n","page_start":11,"page_end":11,"token_count":612,"section_type":"other","chapter_number":1,"chapter_title":"INTRODUCTION TO STATISTICS","chunk_index":10}
{"chunk_id":"e288a6a80d348ed6","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"x \nPreface\nChapters 2 and 3\n \n■Chapter Partitioned: Chapter 2 (Describing, Exploring, and Comparing Data) \nfrom the first edition has been partitioned into Chapter 2 (Summarizing and Graph-\ning) and Chapter 3 (Statistics for Describing, Exploring, and Comparing Data).\n \n■New Section 2-4: Scatterplots, Correlation, and Regression This new section \nincludes scatterplots in Part 1, the linear correlation coefficient r in Part 2, and \nlinear regression in Part 3. These additions are intended to greatly facilitate cover-\nage for those professors who prefer some early coverage of correlation and regres-\nsion concepts. Chapter 10 includes these topics discussed with much greater detail.\nChapter 4\n \n■Combined Sections: Section 3-3 (Addition Rule) and Section 3-4 (Multiplication \nRule) from the first edition are now combined into one section: 4-2 (Addition \nRule and Multiplication Rule).\n \n■New Subsection 4-3, Part 3: Bayes’ Theorem\nChapter 5\n \n■Combined Sections: Section 4-3 (Binomial Probability Distributions) and \nSection 4-4 (Mean, Variance, and Standard Deviation for the Binomial Distribu-\ntion) from the first edition are now combined into one section: 5-2 (Binomial \nProbability Distributions).\nChapter 6\n \n■Switched Sections: Section 6-5 (Assessing Normality) now precedes Section 6-6 \n(Normal as Approximation to Binomial).\nChapter 7\n \n■Combined Sections: Sections 6-4 (Estimating a Population Mean: s Known) \nand 6-5 (Estimating a Population Mean: s Not Known) from the first edition \nhave been combined into one section: 7-2 (Estimating a Population Mean). The \ncoverage of the s known case has been substantially reduced and it is now lim-\nited to Part 2 of Section 7-2.\n \n■New Section 7-4: Bootstrapping: Using Technology for Estimates\nChapter 8\n \n■Combined Sections: Sections 7-4 (Testing a Claim About a Population Mean: s \nKnown) and 7-5 (Testing a Claim About a Population Mean: s Not Known) from \nthe first edition have been combined into one section: 8-3 (Testing a Claim About \na Mean). Coverage of the s known case has been substantially reduced and it is \nnow limited to Part 2 of Section 8-3.\nChapter 10\n \n■New Section: 10-5 Dummy Variables and Logistic Regression\nChapter 11\n \n■New Subsection: Section 11-2, Part 2 Test of Homogeneity, Fisher’s Exact Test, \nand McNemar’s Test for Matched Pairs\nChapter 14\n \n■Combined Sections: Section 13-2 (Elements of a Life Table) and Section 13-3 \n(Applications of Life Tables) from the first edition have been combined into \nSection 14-1 (Life Tables).\n \n■New Section: 14-2 Kaplan-Meier Survival Analysis\n","page_start":12,"page_end":12,"token_count":677,"section_type":"other","chapter_number":1,"chapter_title":"INTRODUCTION TO STATISTICS","chunk_index":11}
{"chunk_id":"4986db9908ce7ccc","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"Preface \nxi\nFlexible Syllabus\nThis book’s organization reflects the preferences of most statistics instructors, but \nthere are two common variations:\n \n■Early Coverage of Correlation and Regression: Some instructors prefer to \ncover the basics of correlation and regression early in the course. Section 2-4 \nnow includes basic concepts of scatterplots, correlation, and regression without \nthe use of formulas and greater depth found in Sections 10-1 (Correlation) and \n10-2 (Regression).\n \n■Minimum Probability: Some instructors prefer extensive coverage of probability, \nwhile others prefer to include only basic concepts. Instructors preferring mini-\nmum coverage can include Section 4-1 while skipping the remaining sections of \nChapter 4, as they are not essential for the chapters that follow. Many instructors \nprefer to cover the fundamentals of probability along with the basics of the addi-\ntion rule and multiplication rule (Section 4-2).\nGAISE\nThis book reflects recommendations from the American Statistical Association and \nits Guidelines for Assessment and Instruction in Statistics Education (GAISE). Those \nguidelines suggest the following objectives and strategies.\n1. Emphasize statistical literacy and develop statistical thinking: Each section \nexercise set begins with Statistical Literacy and Critical Thinking exercises. \nMany of the book’s exercises are designed to encourage statistical thinking \nrather than the blind use of mechanical procedures.\n2. Use real data: 87% of the examples and 89% of the exercises use real data.\n3. Stress conceptual understanding rather than mere knowledge of procedures: \nInstead of seeking simple numerical answers, most exercises and examples \ninvolve conceptual understanding through questions that encourage practical \ninterpretations of results. Also, each chapter includes a From Data to Decision \nproject.\n4. Foster active learning in the classroom: Each chapter ends with several \nCooperative Group Activities.\n5. Use technology for developing conceptual understanding and analyzing data: \nComputer software displays are included throughout the book. Special Tech \nCenter subsections are available online, and they include instruction for using \nthe software. Each chapter includes a Technology Project. When there are dis-\ncrepancies between answers based on tables and answers based on technology, \nAppendix D provides both answers. The websites www.TriolaStats.com and \nwww.pearsonhighered.com/triola as well as MyStatLab include free text-specific \nsoftware (Statdisk), data sets formatted for several different technologies, and \ninstructional videos for technologies.\n6. Use assessments to improve and evaluate student learning: Assessment tools \ninclude an abundance of section exercises, Chapter Quick Quizzes, Review \nExercises, Cumulative Review Exercises, Technology Projects, From Data to \nDecision projects, and Cooperative Group Activities.\n","page_start":13,"page_end":13,"token_count":556,"section_type":"other","chapter_number":1,"chapter_title":"INTRODUCTION TO STATISTICS","chunk_index":12}
{"chunk_id":"bf0b145f8f402a11","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"xii \nPreface\nAcknowledgments\nWe would like to thank the many statistics professors and students who have contrib-\nuted to the success of this book. We thank the reviewers for their suggestions for this \nsecond edition:\nJames Baldone, Virginia College\nNaomi Brownstein, Florida State University\nChristina Caruso, University of Guelph\nErica A. Corbett, Southeastern Oklahoma State University\nXiangming Fang, East Carolina University\nPhil Gona, UMASS Boston\nSharon Homan, University of North Texas\nJackie Milton, Boston University\nJoe Pick, Palm Beach State College\nSteve Rigdon, St. Louis University\nBrian Smith, Black Hills State University\nMahbobeh Vezvaei, Kent State University\nDavid Zeitler, Grand Valley State University\nWe also thank Paul Lorczak, Joseph Pick and Erica Corbett for their help in \nchecking the accuracy of the text and answers.\nMarc Triola\nMario Triola\nJason Roy\nSeptember 2016\n","page_start":14,"page_end":14,"token_count":210,"section_type":"other","chapter_number":1,"chapter_title":"INTRODUCTION TO STATISTICS","chunk_index":13}
{"chunk_id":"81c6603c3733a8fb","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"MyStatLab\n® Online Course for Biostatistics: For  \nthe Biological and Health Sciences, 2e by Marc M. Triola, \nMario F. Triola and Jason Roy (access code required)\nMyStatLab is available to accompany Pearson’s market leading text offerings. To give \nstudents a consistent tone, voice, and teaching method each text’s flavor and ap-\nproach is tightly integrated throughout the accompanying MyStatLab course, making \nlearning the material as seamless as possible.\nReal-World Data Examples - Help \nunderstand how statistics applies to \neveryday life through the extensive \ncurrent, real-world data examples and \nexercises provided throughout the text.\nMathXL coverage - MathXL is a market-leading \ntext-speciﬁc autograded homework system built \nto improve student learning outcomes.\nEnhanced video program to meet Introductory \nStatistics needs:\n•  New! Tech-Specific Video Tutorials - These \nshort, topical videos address how to use varying \ntechnologies to complete exercises.\n•  Updated! Section Lecture Videos - Watch author, \nMarty Triola, work through examples and elaborate \non key objectives of the chapter.\nResources for Success\nwww.mystatlab.com\nxiii\n","page_start":15,"page_end":15,"token_count":254,"section_type":"other","chapter_number":1,"chapter_title":"INTRODUCTION TO STATISTICS","chunk_index":14}
{"chunk_id":"c8c1b84b31902f95","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"xiv \nPreface\nSupplements\nFor the Student\nStudent’s Solutions Manual, by James Lapp (Colorado \nMesa University) provides detailed, worked-out solutions \nto all odd-numbered text exercises.\n(ISBN-13: 978-0-13-403909-1; ISBN-10: 0-13-403909-2)\nStudent Workbook for the Triola Statistics Series, by \nLaura lossi (Broward College) offers additional exam-\nples, concept exercises, and vocabulary exercises for each \nchapter.\n(ISBN-13: 978-0-13-446423-7; ISBN 10: 0-13-446423-0)\nThe following technology manuals, available in  MyStatLab, \ninclude instructions, examples from the main text, and \ninterpretations to complement those given in the text.\nExcel Student Laboratory Manual and Workbook \n(Download Only), by Laurel Chiappetta (University of \nPittsburgh).\n(ISBN-13: 978-0-13-446427-5; ISBN-10: 0-13-446427-3)\nMINITAB Student Laboratory Manual and Work-\nbook (Download Only), by Mario F. Triola.\n(ISBN-13: 978-0-13-446418-3; ISBN-10: 0-13-446418-4)\nGraphing Calculator Manual for the TI-83 Plus, \nTI-84 Plus, TI-84 Plus C and TI-84 Plus CE (Down-\nload Only), by Kathleen McLaughlin (University of \nConnecticut) & Dorothy Wakefield (University of Con-\nnecticut Health Center).\n(ISBN-13: 978-0-13-446414-5; ISBN 10: 0-13-446414-1)\nStatdisk Student Laboratory Manual and Workbook \n(Download Only), by Mario F. Triola. These files are \navailable to instructors and students through the Triola Sta-\ntistics Series website, www.pearsonhighered.com/triola, \nand MyStatLab.\nSPSS Student Laboratory Manual and Workbook \n(Download Only), by James J. Ball (Indiana State Uni-\nversity). These files are available to instructors and stu-\ndents through the Triola Statistics Series website, www.\npearsonhighered.com/triola, and MyStatLab.\nFor the Instructor\nInstructor’s Solutions Manual (Download Only), by \nJames Lapp (Colorado Mesa University) contains so-\nlutions to all the exercises. These files are available to \nqualified instructors through Pearson Education’s on-\nline catalog at www.pearsonhighered.com/irc or within \nMyStatLab.\nInsider’s Guide to Teaching with the Triola Statistics \nSeries, by Mario F. Triola, contains sample syllabi and \ntips for incorporating projects, as well as lesson overviews, \nextra examples, minimum outcome objectives, and recom-\nmended assignments for each chapter.\n(ISBN-13: 978-0-13-446425-1; ISBN-10: 0-13-446425-7)","page_start":16,"page_end":16,"token_count":643,"section_type":"other","chapter_number":1,"chapter_title":"INTRODUCTION TO STATISTICS","chunk_index":15}
{"chunk_id":"c17f4416d7805361","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"MyStatLab.\nInsider’s Guide to Teaching with the Triola Statistics \nSeries, by Mario F. Triola, contains sample syllabi and \ntips for incorporating projects, as well as lesson overviews, \nextra examples, minimum outcome objectives, and recom-\nmended assignments for each chapter.\n(ISBN-13: 978-0-13-446425-1; ISBN-10: 0-13-446425-7)\nTestGen® Computerized Test Bank (www.pearsoned.\ncom/testgen) enables instructors to build, edit, print, and \nadminister tests using a computerized bank of questions \ndeveloped to cover all the objectives of the text. TestGen is \nalgorithmically based, allowing instructors to create mul-\ntiple but equivalent versions of the same question or test \nwith the click of a button. Instructors can also modify test \nbank questions or add new questions. The software and tes-\ntbank are available for download from Pearson Education’s \nonline catalog at www.pearsonhighered.com. A test bank \n(Download Only) is also available from the  online catalog.\nLearning Catalytics: Learning Catalytics is a web-based \nengagement and assessment tool. As a “bring-your-own-\ndevice” direct response system, Learning Catalytics offers \na diverse library of dynamic question types that allow stu-\ndents to interact with and think critically about statistical \nconcepts. As a real-time resource, instructors can take ad-\nvantage of critical teaching moments both in the classroom \nor through assignable and gradeable homework.\nTechnology Resources\nThe following resources can be found on the Triola Statistics \nSeries website (http://www.pearsonhighered.com/triola), the \nauthor maintained www.triolastats.com, and MyStatLab\n■Appendix B data sets formatted for Minitab, SPSS, \nSAS, Excel, JMP, and as text files. Additionally, these \ndata sets are available as an APP for the TI-83>84 \nPlus calculators, and supplemental programs for the \nTI-83>84 Plus calculator are also available.\n■Statdisk statistical software instructions for down-\nload. New features include the ability to directly use \nlists of data instead of requiring the use of their sum-\nmary statistics.\n■Extra data sets, an index of applications, and a sym-\nbols table.\nVideo resources have been expanded, updated and now \nsupplement most sections of the book, with many topics \npresented by the author.  The videos aim to support both \ninstructors and students through lecture, reinforcing sta-\ntistical basics through technology, and applying concepts:\n■Section Lecture Videos","page_start":16,"page_end":16,"token_count":556,"section_type":"other","chapter_number":1,"chapter_title":"INTRODUCTION TO STATISTICS","chunk_index":16}
{"chunk_id":"b4e3cb3f612b28bf","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"Preface \nxv\n■New! Technology Video Tutorials - These short, \ntopical videos address how to use Excel, Statdisk, \nand the TI graphing calculator to complete exercises.\n■StatTalk Videos: 24 Conceptual Videos to Help \nYou Actually Understand Statistics. Fun-loving \nstatistician Andrew Vickers takes to the streets of \nBrooklyn, NY, to demonstrate important statistical \nconcepts through interesting stories and real-life \nevents. These fun and engaging videos will help \nstudents actually understand statistical concepts. \nAvailable with an instructors user guide and assess-\nment questions.\nMyStatLab™ Online Course (access code required)\nMyStatLab is a course management system that delivers \nproven results in helping individual students succeed.\n■MyStatLab can be successfully implemented in \nany environment—lab-based, hybrid, fully online, \ntraditional—and demonstrates the quantifiable differ-\nence that integrated usage has on student retention, \nsubsequent success, and overall achievement.\n■MyStatLab’s comprehensive online gradebook au-\ntomatically tracks students’ results on tests, quizzes, \nhomework, and in the study plan. Instructors can use \nthe gradebook to provide positive feedback or inter-\nvene if students have trouble. Gradebook data can be \neasily exported to a variety of spreadsheet programs, \nsuch as Microsoft Excel. You can determine which \npoints of data you want to export, and then analyze \nthe results to determine success.\nMyStatLab provides engaging experiences that personal-\nize, stimulate, and measure learning for each student. In \naddition to the resources below, each course includes a full \ninteractive online version of the accompanying textbook.\n■Tutorial Exercises with Multimedia Learning Aids: \nThe homework and practice exercises in MyStatLab \nalign with the exercises in the textbook, and they \nregenerate algorithmically to give students unlim-\nited opportunity for practice and mastery. Exercises \noffer immediate helpful feedback, guided solutions, \nsample problems, animations, videos, and eText clips \nfor extra help at point-of-use.\n■Getting Ready for Statistics: A library of questions \nnow appears within each MyStatLab course to offer \nthe developmental math topics students need for the \ncourse. These can be assigned as a prerequisite to \nother assignments, if desired.\n■Conceptual Question Library: In addition to algo-\nrithmically regenerated questions that are aligned with \nyour textbook, there is a library of 1000 Conceptual \nQuestions available in the assessment manager that re-\nquire students to apply their statistical understanding.\n■StatCrunch™: MyStatLab integrates the web-based \nstatistical software, StatCrunch, within the online as-\nsessment platform so that students can easily analyze \ndata sets from exercises and the text. In addition, \nMyStatLab includes access to www.StatCrunch.com, \na website where users can access more than 15,000 \nshared data sets, conduct online surveys, perform \ncomplex analyses using the powerful statistical \nsoftware, and generate compelling reports.\n■Statistical Software Support: Knowing that  students ","page_start":17,"page_end":17,"token_count":633,"section_type":"other","chapter_number":1,"chapter_title":"INTRODUCTION TO STATISTICS","chunk_index":17}
{"chunk_id":"c8ef729f75805f09","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"statistical software, StatCrunch, within the online as-\nsessment platform so that students can easily analyze \ndata sets from exercises and the text. In addition, \nMyStatLab includes access to www.StatCrunch.com, \na website where users can access more than 15,000 \nshared data sets, conduct online surveys, perform \ncomplex analyses using the powerful statistical \nsoftware, and generate compelling reports.\n■Statistical Software Support: Knowing that  students \noften use external statistical software, we make it \neasy to copy our data sets, both from the ebook and \nthe MyStatLab questions, into software such as \nStatCrunch, Minitab, Excel, and more. Students have \naccess to a variety of support tools—Technology  \nTutorial Videos, Technology Study Cards, and Tech-\nnology Manuals for select titles—to learn how to \neffectively use statistical software.\nMathXL® for Statistics Online Course (access code \nrequired)\nMathXL® is the homework and assessment engine that \nruns MyStatLab. (MyStatLab is MathXL plus a learning \nmanagement system.)\nWith MathXL for Statistics, instructors can:\n■Create, edit, and assign online homework and tests \nusing algorithmically generated exercises correlated \nat the objective level to the textbook.\n■Create and assign their own online exercises and \nimport TestGen tests for added flexibility.\n■Maintain records of all student work, tracked in \nMathXL’s online gradebook.\nWith MathXL for Statistics, students can:\n■Take chapter tests in MathXL and receive personal-\nized study plans and>or personalized homework \nassignments based on their test results.\n■Use the study plan and>or the homework to link \ndirectly to tutorial exercises for the objectives they \nneed to study.\n■Students can also access supplemental animations \nand video clips directly from selected exercises.\n■Knowing that students often use external statistical \nsoftware, we make it easy to copy our data sets, both \nfrom the ebook and the MyStatLab questions, into \nsoftware like StatCrunch™, Minitab, Excel, and more.","page_start":17,"page_end":17,"token_count":429,"section_type":"other","chapter_number":1,"chapter_title":"INTRODUCTION TO STATISTICS","chunk_index":18}
{"chunk_id":"fda75358f1ac572d","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"xvi\t\nPreface\nMathXL for Statistics is available to qualified adopters. \nFor more information, visit our website at www.mathxl \n.com, or contact your Pearson representative.\nStatCrunch™\nStatCrunch is powerful, web-based statistical software \nthat allows users to perform complex analyses, share data \nsets, and generate compelling reports. A vibrant online \ncommunity offers more than 15,000 data sets for students \nto analyze.\n■\n■Collect. Users can upload their own data to ­StatCrunch \nor search a large library of publicly shared data sets, \nspanning almost any topic of interest. Also, an online \nsurvey tool allows users to quickly collect data via \nweb-based surveys.\n■\n■Crunch. A full range of numerical and graphical \nmethods allow users to analyze and gain insights \nfrom any data set. Interactive graphics help users \nunderstand statistical concepts and are available for \nexport to enrich reports with visual representations \nof data.\n■\n■Communicate. Reporting options help users create a \nwide variety of visually appealing representations of \ntheir data.\nFull access to StatCrunch is available with ­MyStatLab \nand StatCrunch is available by itself to qualified adopt-\ners. StatCrunch Mobile is now available to access from \nyour mobile device. For more information, visit our web-\nsite at www.StatCrunch.com, or contact your Pearson \n­representative.\nMinitab® 17 and Minitab Express™ make learning sta-\ntistics easy and provide students with a skill-set that’s \nin demand in today’s data driven workforce. Bundling \nMinitab® software with educational materials ensures stu-\ndents have access to the software they need in the class-\nroom, around campus, and at home. And having 12 month \nversions of Minitab 17 and Minitab Express available \nensures students can use the software for the duration of \ntheir course.\nISBN 13: 978-0-13-445640-9\nISBN 10: 0-13-445640-8 (Access Card only; not sold as \nstand alone.)\nJMP Student Edition, Version 12 is an easy-to-use, stream-\nlined version of JMP desktop statistical discovery software \nfrom SAS Institute, Inc., and is available for bundling with \nthe text.\n(ISBN-13: 978-0-13-467979-2 ISBN-10: 0-13-467979-2)\n","page_start":18,"page_end":18,"token_count":515,"section_type":"other","chapter_number":1,"chapter_title":"INTRODUCTION TO STATISTICS","chunk_index":19}
{"chunk_id":"80d0f3d5df5c8623","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"Statistical and Critical \nThinking\nTypes of Data\nCollecting Sample Data\n1-1\n1-2\n1-3\nSurvey Question: Do You Need Caffeine to Start Up Your Brain for the Day?\nCHAPTER \nPROBLEM\nIntroduction  \nto Statistics\n1\nSurveys provide data that enable us to improve products or \nservices. Surveys guide political candidates, shape business \npractices, identify effective medical treatments, and affect \nmany aspects of our lives. Surveys give us insight into the \nopinions and behaviors of others. As an example, the National \nHealth and Nutrition Examination Survey (NHANES) is part \n1\nof a research program that studies the health and nutrition of \nthousands of adults and children in the United States.\nLet’s consider one USA Today survey in which respondents \nwere asked if they need caffeine to start up their brain for the \nday. Among 2,006 respondents, 74% said that they did need the \ncaffeine. Figure 1-1 includes graphs that depict these results.\n","page_start":19,"page_end":19,"token_count":217,"section_type":"other","chapter_number":1,"chapter_title":"INTRODUCTION TO STATISTICS","chunk_index":20}
{"chunk_id":"32d500badb94670b","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"The survey results suggest that people overwhelmingly need caffeine to start up their brains \nfor the day. The graphs in Figure 1-1 visually depict the survey results. One of the most impor-\ntant objectives of this book is to encourage the use of critical thinking so that such results are \nnot blindly accepted. We might question whether the survey results are valid. Who conducted \nthe survey? How were respondents selected? Do the graphs in Figure 1-1 depict the results \nwell, or are those graphs somehow misleading?\nThe survey results presented here have major flaws that are among the most common, so \nthey are especially important to recognize. Here are brief descriptions of each of the major flaws:\nFlaw 1: Misleading Graphs The bar chart in Figure 1-1(a) is very deceptive. By using a \nvertical scale that does not start at zero, the difference between the two percentages is grossly \nexaggerated. Figure 1-1(a) makes it appear that approximately eight times as many people \nneed the caffeine. However, with 74% needing caffeine and 26% not needing caffeine, the \nratio is actually about 3:1, rather than the 8:1 ratio that is suggested by the graph.\nThe illustration in Figure 1-1(b) is also deceptive. Again, the difference between the actual \nresponse rates of 74% (needing caffeine) and 26% (not needing caffeine) is a difference that \nis grossly distorted. The picture graph (or “pictograph”) in Figure 1-1(b) makes it appear that \n2 \nCHAPTER 1 Introduction to Statistics\nFIGURE 1-1(a) Survey Results\nFIGURE 1-1(b) Survey Results\nPeople Needing Caﬀeine to Start\nUp Brain for the Day\nPeople Not Needing Caﬀeine to Start\nUp Brain for the Day\n","page_start":20,"page_end":20,"token_count":399,"section_type":"other","chapter_number":1,"chapter_title":"INTRODUCTION TO STATISTICS","chunk_index":21}
{"chunk_id":"297b9b1d1ddb8066","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"the ratio of people needing caffeine to people not needing caffeine is roughly 9:1 instead of \nthe correct ratio of about 3:1. (Objects with area or volume can distort perceptions because \nthey can be drawn to be disproportionately larger or smaller than the data indicate.) Decep-\ntive graphs are discussed in more detail in Section 2-3, but we see here that the illustrations in \nFigure 1-1 grossly exaggerate the number of people needing caffeine.\nFlaw 2: Bad Sampling Method The aforementioned survey responses are from a USA \nToday survey of Internet users. The survey question was posted on a website and Internet \nusers decided whether to respond. This is an example of a voluntary response sample—a \nsample in which respondents themselves decide whether to participate. With a voluntary \nresponse sample, it often happens that those with a strong interest in the topic are more likely \nto participate, so the results are very questionable. For example, people who strongly feel that \nthey cannot function without their morning cup(s) of coffee might be more likely to respond to \nthe caffeine survey than people who are more ambivalent about caffeine or coffee. When using \nsample data to learn something about a population, it is extremely important to obtain sample \ndata that are representative of the population from which the data are drawn. As we proceed \nthrough this chapter and discuss types of data and sampling methods, we should focus on \nthese key concepts:\n• Sample data must be collected in an appropriate way, such as through a process of \nrandom selection.\n• If sample data are not collected in an appropriate way, the data may be so completely \nuseless that no amount of statistical torturing can salvage them.\nIt would be easy to accept the preceding survey results and blindly proceed with calcula-\ntions and statistical analyses, but we would miss the critical two flaws described above. We \ncould then develop conclusions that are fundamentally wrong and misleading. Instead, we \nshould develop skills in statistical thinking and critical thinking so that we are better prepared \nto analyze such data.\nChapter Objectives \n3\nThe single most important concept presented in this chapter is this: When using meth-\nods of statistics with sample data to form conclusions about a population, it is absolutely \nessential to collect sample data in a way that is appropriate. Here are the main chapter \nobjectives:\nStatistical and Critical Thinking\n• Analyze sample data relative to context, source, and sampling method.\n• Understand the difference between statistical significance and practical significance.\n• Define and identify a voluntary response sample and know that statistical conclu-\nsions based on data from such a sample are generally not valid.\n1-1\nCHAPTER OBJECTIVES\n>>>\n","page_start":21,"page_end":21,"token_count":551,"section_type":"other","chapter_number":1,"chapter_title":"INTRODUCTION TO STATISTICS","chunk_index":22}
{"chunk_id":"039714a6f87fd35a","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"4 \nCHAPTER 1 Introduction to Statistics\nBecause populations are often very large, a common objective of the use of statis-\ntics is to obtain data from a sample and then use those data to form a conclusion about \nthe population.\nTypes of Data\n• Distinguish between a parameter and a statistic.\n• Distinguish between quantitative data and categorical (or qualitative or attribute) data.\n• Distinguish between discrete data and continuous data.\n• Determine whether basic statistical calculations are appropriate for a particular data set.\nCollecting Sample Data\n• Define and identify a simple random sample.\n• Understand the importance of sound sampling methods and the importance of \ngood design of experiments.\n1-2\n1-3\nTypes of Data\n• Distinguish between a parameter and a\nr r\nstatistic.\n• Distinguish between quantitative data and categorical (or \nl l\nqualitative or attribute) data.\n• Distinguish between discrete data and continuous data.\n• Determine whether basic statistical calculations are appropriate for a particular data set.\nCollecting Sample Data\n• Define and identify a simple random sample.\n• Understand the importance of sound sampling methods and the importance of \ngood design of experiments.\nKey Concept In this section we begin with a few very basic definitions, and then we \nconsider an overview of the process involved in conducting a statistical study. This \nprocess consists of “prepare, analyze, and conclude.” “Preparation” involves consid-\neration of the context, the source of data, and sampling method. In future chapters we \nconstruct suitable graphs, explore the data, and execute computations required for the \nstatistical method being used. In future chapters we also form conclusions by deter-\nmining whether results have statistical significance and practical significance.\nStatistical thinking involves critical thinking and the ability to make sense of results. \nStatistical thinking demands so much more than the ability to execute complicated cal-\nculations. Through numerous examples, exercises, and discussions, this text will help \nyou develop the statistical thinking skills that are so important in today’s world.\nWe begin with some very basic definitions.\n1-1 \nStatistical and Critical Thinking\nDEFINITIONS\nData are collections of observations, such as measurements, or survey responses. \n(A single data value is called a datum, a term rarely used. The term “data” is plural, \nso it is correct to say “data are…” not “data is…”)\nStatistics is the science of planning studies and experiments; obtaining data; and \norganizing, summarizing, presenting, analyzing, and interpreting those data and \nthen drawing conclusions based on them.\nA population is the complete collection of all measurements or data that are be-\ning considered. Typically, the population is the complete collection of data that we \nwould like to make inferences about.\nA census is the collection of data from every member of the population.\nA sample is a subcollection of members selected from a population.\n","page_start":22,"page_end":22,"token_count":593,"section_type":"other","chapter_number":1,"chapter_title":"INTRODUCTION TO STATISTICS","chunk_index":23}
{"chunk_id":"31c2ddc3ed6ad99e","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"1-1 Statistical and Critical Thinking \n5\nWe now proceed to consider the process involved in a statistical study. See Figure 1-2 \nfor a summary of this process and note that the focus is on critical thinking, not mathe-\nmatical calculations. Thanks to wonderful developments in technology, we have power-\nful tools that effectively do the number crunching so that we can focus on understanding \nand interpreting results.\nEXAMPLE 1  Residential Carbon Monoxide Detectors\nIn the journal article “Residential Carbon Monoxide Detector Failure Rates in the \nUnited States” (by Ryan and Arnold, American Journal of Public Health, Vol. 101, \nNo. 10), it was stated that there are 38 million carbon monoxide detectors installed \nin the United States. When 30 of them were randomly selected and tested, it was \nfound that 12 of them failed to provide an alarm in hazardous carbon monoxide \nconditions. In this case, the population and sample are as follows:\nPopulation: All 38 million carbon monoxide detectors in the United States \nSample: The 30 carbon monoxide detectors that were selected and tested \nThe objective is to use the sample data as a basis for drawing a conclusion about the \npopulation of all carbon monoxide detectors, and methods of statistics are helpful in \ndrawing such conclusions.\nConclude\n1. Signiﬁcance\n• Do the results have statistical signiﬁcance?\n• Do the results have practical signiﬁcance?\nAnalyze\n1. Graph the Data\n2. Explore the Data\n• Are there any outliers (numbers very far away from almost all of the other data)?\n• What important statistics summarize the data (such as the mean and standard deviation\n described in Chapter 3)?\n• How are the data distributed?\n• Are there missing data?\n• Did many selected subjects refuse to respond?\n3. Apply Statistical Methods\n• Use technology to obtain results.\nPrepare\n1. Context\n• What do the data represent?\n• What is the goal of study? \n2. Source of the Data\n• Are the data from a source with a special interest so that there is pressure to obtain \n results that are favorable to the source?\n3. Sampling Method\n• Were the data collected in a way that is unbiased, or were the data collected in a \n way that is biased (such as a procedure in which respondents volunteer to participate)?\nFIGURE 1-2 Statistical Thinking\nSurvivorship Bias\nIn World War \nII, statisti-\ncian Abraham \nWald saved \nmany lives \nwith his work \non the Applied \nMathematics Panel. Military \nleaders asked the panel how they \ncould improve the chances of \naircraft bombers returning after \nmissions. They wanted to add \nsome armor for protection, and \nthey recorded locations on the \nbombers where damaging holes \nwere found. They reasoned that \narmor should be placed in loca-\ntions with the most holes, but \nWald said that strategy would be \na big mistake. He said that armor \nshould be placed where returning \nbombers were not damaged. His ","page_start":23,"page_end":23,"token_count":647,"section_type":"other","chapter_number":1,"chapter_title":"INTRODUCTION TO STATISTICS","chunk_index":24}
{"chunk_id":"d5de5bb110151ea6","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"could improve the chances of \naircraft bombers returning after \nmissions. They wanted to add \nsome armor for protection, and \nthey recorded locations on the \nbombers where damaging holes \nwere found. They reasoned that \narmor should be placed in loca-\ntions with the most holes, but \nWald said that strategy would be \na big mistake. He said that armor \nshould be placed where returning \nbombers were not damaged. His \nreasoning was this: The bombers \nthat made it back with damage \nwere survivors, so the damage \nthey suffered could be survived. \nLocations on the aircraft that \nwere not damaged were the most \nvulnerable, and aircraft suffer-\ning damage in those vulnerable \nareas were the ones that did \nnot make it back. The military \nleaders would have made a big \nmistake with survivorship bias by \nstudying the planes that survived \ninstead of thinking about the \nplanes that did not survive.","page_start":23,"page_end":23,"token_count":199,"section_type":"other","chapter_number":1,"chapter_title":"INTRODUCTION TO STATISTICS","chunk_index":25}
{"chunk_id":"84498c72e208924f","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"6 \nCHAPTER 1 Introduction to Statistics\nPrepare\nContext Figure 1-2 suggests that we begin our preparation by considering the context \nof the data, so let’s start with context by considering the data in Table 1-1. (The data \nare from Data Set 9 “IQ and Brain Size” in Appendix B.) The data in Table 1-1 consist \nof measured IQ scores and measured brain volumes from 10 different subjects. The \ndata are matched in the sense that each individual “IQ>brain volume” pair of values \nis from the same person. The first subject had a measured IQ score of 96 and a brain \nvolume of 1005 cm3. The format of Table 1-1 suggests the following goal: Determine \nwhether there is a relationship between IQ score and brain volume. This goal suggests \na possible hypothesis: People with larger brains tend to have higher IQ scores.\nSource of the Data The data in Table 1-1 were provided by M. J. Tramo, W. C. \nLoftus, T. A. Stukel, J. B. Weaver, and M. S. Gazziniga, who discuss the data in the \narticle “Brain Size, Head Size, and IQ in Monozygotic Twins,” Neurology, Vol. 50. \nThe researchers are from reputable medical schools and hospitals, and they would not \ngain by presenting the results in way that is misleading. In contrast, Kiwi Brands, a \nmaker of shoe polish, commissioned a study that resulted in this statement, which was \nprinted in some newspapers: “According to a nationwide survey of 250 hiring profes-\nsionals, scuffed shoes was the most common reason for a male job seeker’s failure to \nmake a good first impression.”\nWhen physicians who conduct clinical experiments on the efficacy of drugs re-\nceive funding from drug companies, they have an incentive to obtain favorable results. \nSome professional journals, such as the Journal of the American Medical Association, \nnow require that physicians report sources of funding in journal articles. We should be \nskeptical of studies from sources that may be biased.\nSampling Method Figure 1-2 suggests that we conclude our preparation by consid-\nering the sampling method. The data in Table 1-1 were obtained from subjects whose \nmedical histories were reviewed in an effort to ensure that no subjects had neurologic \nor psychiatric disease. In this case, the sampling method appears to be sound, but we \ncannot be sure of that without knowing how the subjects were recruited and whether \nany payments may have affected participation in the study.\nSampling methods and the use of randomization will be discussed in Section 1-3, \nbut for now, we stress that a sound sampling method is absolutely essential for good \nresults in a statistical study. It is generally a bad practice to use voluntary response (or \nself-selected) samples, even though their use is common.\nTABLE 1-1 IQ Scores and Brain Volumes (cm3)\nIQ\n96\n87\n101\n103\n127\n96\n88\n85\n97\n124\nBrain Volume (cm3)\n1005\n1035\n1281\n1051","page_start":24,"page_end":24,"token_count":661,"section_type":"other","chapter_number":1,"chapter_title":"INTRODUCTION TO STATISTICS","chunk_index":26}
{"chunk_id":"b12ce1672d04db64","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"but for now, we stress that a sound sampling method is absolutely essential for good \nresults in a statistical study. It is generally a bad practice to use voluntary response (or \nself-selected) samples, even though their use is common.\nTABLE 1-1 IQ Scores and Brain Volumes (cm3)\nIQ\n96\n87\n101\n103\n127\n96\n88\n85\n97\n124\nBrain Volume (cm3)\n1005\n1035\n1281\n1051\n1034\n1079\n1104\n1439\n1029\n1160\nDEFINITION\nA voluntary response sample (or self-selected sample) is one in which the \nrespondents themselves decide whether to be included.\nThe following types of polls are common examples of voluntary response samples. \nBy their very nature, all are seriously flawed because we should not make conclusions \nabout a population on the basis of samples with a strong possibility of bias:\n■Internet polls, in which people online can decide whether to respond\n■Mail-in polls, in which people decide whether to reply\nOrigin of “Statistics”\nThe word \nstatistics is \nderived from \nthe Latin word \nstatus (mean-\ning “state”). \nEarly uses of \nstatistics involved compilations \nof data and graphs describing \nvarious aspects of a state or \ncountry. In 1662, John Graunt \npublished statistical information \nabout births and deaths. Graunt’s \nwork was followed by studies \nof mortality and disease rates, \npopulation sizes, incomes, and \nunemployment rates. House-\nholds, governments, and busi-\nnesses rely heavily on statistical \ndata for guidance. For example, \nunemployment rates, inflation \nrates, consumer indexes, and \nbirth and death rates are carefully \ncompiled on a regular basis, \nand the resulting data are used \nby business leaders to make \ndecisions affecting future hiring, \nproduction levels, and expansion \ninto new markets.","page_start":24,"page_end":24,"token_count":402,"section_type":"other","chapter_number":1,"chapter_title":"INTRODUCTION TO STATISTICS","chunk_index":27}
{"chunk_id":"7e533002b8dba3e8","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"1-1 Statistical and Critical Thinking \n7\n \n■Telephone call-in polls, in which newspaper, radio, or television announcements \nask that you voluntarily call a special number to register your opinion\nThe Chapter Problem involves a USA Today survey with a voluntary response sample. \nSee also the following Example 2.\nEXAMPLE 2  Voluntary Response Sample\nUSA Today posted this question on the electronic edition of their newspaper: “Have \nyou ever been bitten by an animal?” Internet users who saw that question then de-\ncided themselves whether to respond. Among the 2361 responses, 65% said “yes” \nand 35% said “no.” Because the 2361 subjects themselves chose to respond, they \nare a voluntary response sample and the results of the survey are highly question-\nable. It would be much better to get results through a poll in which the pollster ran-\ndomly selects the subjects, instead of allowing the subjects to volunteer themselves.\nAnalyze\nFigure 1-2 indicates that after completing our preparation by considering the context, \nsource, and sampling method, we begin to analyze the data.\nGraph and Explore An analysis should begin with appropriate graphs and explora-\ntions of the data. Graphs are discussed in Chapter 2, and important statistics are dis-\ncussed in Chapter 3.\nApply Statistical Methods Later chapters describe important statistical methods, \nbut application of these methods is often made easy with technology (calculators \nand>or statistical software packages). A good statistical analysis does not require \nstrong computational skills. A good statistical analysis does require using common \nsense and paying careful attention to sound statistical methods.\nConclude\nFigure 1-2 shows that the final step in our statistical process involves conclusions, and \nwe should develop an ability to distinguish between statistical significance and practi-\ncal significance.\nStatistical Significance Statistical significance is achieved in a study when we get \na result that is very unlikely to occur by chance. A common criterion is that we have \nstatistical significance if the likelihood of an event occurring by chance is 5% or less.\n \n■Getting 98 girls in 100 random births is statistically significant because such an \nextreme outcome is not likely to result from random chance.\n \n■Getting 52 girls in 100 births is not statistically significant because that event \ncould easily occur with random chance.\nPractical Significance It is possible that some treatment or finding is effective, but \ncommon sense might suggest that the treatment or finding does not make enough of a \ndifference to justify its use or to be practical, as illustrated in Example 3 which follows.\n","page_start":25,"page_end":25,"token_count":535,"section_type":"other","chapter_number":1,"chapter_title":"INTRODUCTION TO STATISTICS","chunk_index":28}
{"chunk_id":"3edb3ad36ad0434e","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"8 \nCHAPTER 1 Introduction to Statistics\nAnalyzing Data: Potential Pitfalls\nHere are a few more items that could cause problems when analyzing data.\nMisleading Conclusions When forming a conclusion based on a statistical analy-\nsis, we should make statements that are clear even to those who have no understand-\ning of statistics and its terminology. We should carefully avoid making statements \nnot justified by the statistical analysis. For example, later in this book we introduce \nthe concept of a correlation, or association between two variables, such as smoking \nand pulse rate. A statistical analysis might justify the statement that there is a cor-\nrelation between the number of cigarettes smoked and pulse rate, but it would not \njustify a statement that the number of cigarettes smoked causes a person’s pulse rate \nto change. Such a statement about causality can be justified by physical evidence, not \nby statistical analysis.\nCorrelation does not imply causation.\nSample Data Reported Instead of Measured When collecting data from people, \nit is better to take measurements yourself instead of asking subjects to report results. \nAsk people what they weigh and you are likely to get their desired weights, not their \nactual weights. People tend to round, usually down, sometimes way down. When \nasked, someone with a weight of 187 lb might respond that he or she weighs 160 lb. \nAccurate weights are collected by using a scale to measure weights, not by asking \npeople what they weigh.\nLoaded Questions If survey questions are not worded carefully, the results of a \nstudy can be misleading. Survey questions can be “loaded” or intentionally worded to \nelicit a desired response. Here are the actual rates of “yes” responses for the two dif-\nferent wordings of a question:\n97% yes: “Should the President have the line item veto to eliminate waste?”\n57% yes: “Should the President have the line item veto, or not?”\nOrder of Questions Sometimes survey questions are unintentionally loaded \nby such factors as the order of the items being considered. See the following two \nEXAMPLE 3   Statistical Significance Versus  \nPractical Significance\nProCare Industries once supplied a product named Gender Choice that supposedly \nincreased the chance of a couple having a baby with the gender that they desired. \nIn the absence of any evidence of its effectiveness, the product was banned by the \nFood and Drug Administration (FDA) as a “gross deception of the consumer.” But \nsuppose that the product was tested with 10,000 couples who wanted to have baby \ngirls, and the results consist of 5200 baby girls born in the 10,000 births. This re-\nsult is statistically significant because the likelihood of it happening due to chance \nis only 0.003%, so chance doesn’t seem like a feasible explanation. That 52% rate \nof girls is statistically significant, but it lacks practical significance because 52% is \nonly slightly above 50%. Couples would not want to spend the time and money to \nincrease the likelihood of a girl from 50% to 52%. (Note: In reality, the likelihood \nof a baby being a girl is about 48.8%, not 50%.)\n","page_start":26,"page_end":26,"token_count":664,"section_type":"other","chapter_number":1,"chapter_title":"INTRODUCTION TO STATISTICS","chunk_index":29}
{"chunk_id":"7d69a029ebbd6384","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"1-1 Statistical and Critical Thinking \n9\nquestions from a poll conducted in Germany, along with the very different response \nrates:\n“Would you say that traﬃc contributes more or less to air pollution than indus-\ntry?” (45% blamed traﬃc; 27% blamed industry.)\n“Would you say that industry contributes more or less to air pollution than traf-\nﬁc?” (24% blamed traﬃc; 57% blamed industry.)\nIn addition to the order of items within a question, as illustrated above, the order of \nseparate questions could also affect responses.\nNonresponse A nonresponse occurs when someone either refuses to respond to \na survey question or is unavailable. When people are asked survey questions, some \nfirmly refuse to answer. The refusal rate has been growing in recent years, partly be-\ncause many persistent telemarketers try to sell goods or services by beginning with a \nsales pitch that initially sounds as though it is part of an opinion poll. (This “selling \nunder the guise” of a poll is called sugging.) In Lies, Damn Lies, and Statistics, author \nMichael Wheeler makes this very important observation:\nPeople who refuse to talk to pollsters are likely to be different from those \nwho do not. Some may be fearful of strangers and others jealous of their \nprivacy, but their refusal to talk demonstrates that their view of the \nworld around them is markedly different from that of those people who \nwill let poll-takers into their homes.\nPercentages Some studies cite misleading or unclear percentages. Note that 100% \nof some quantity is all of it, but if there are references made to percentages that exceed \n100%, such references are often not justified. If a medical researcher claims that she \nhas developed a treatment for migraine headaches and the treatment results in a 150% \nreduction in those headaches, that researcher cannot be correct, because totally elimi-\nnating all migraine headaches would be a 100% reduction. It is impossible to reduce \nthe number of migraine headaches by more than 100%.\nWhen working with percentages, we should know that % or “percent” really \nmeans “divided by 100.” Here is a principle used often in this book.\nPercentage of: To ﬁnd a percentage of an amount, replace the % symbol with \ndivision by 100, and then interpret “of” to be multiplication. The following \n calculation shows that 6% of 1200 is 72:\n6% of 1200 responses =\n6\n100 * 1200 = 72\nStatistical Literacy and Critical Thinking\n1. Online Medical Info USA Today posted this question on its website: “How often do you seek \nmedical information online?” Of 1072 Internet users who chose to respond, 38% of them responded \nwith “frequently.” What term is used to describe this type of survey in which the people surveyed \nconsist of those who decided to respond? What is wrong with this type of sampling method?\n2. Reported Versus Measured In a survey of 1046 adults conducted by Bradley Corpora-","page_start":27,"page_end":27,"token_count":648,"section_type":"other","chapter_number":1,"chapter_title":"INTRODUCTION TO STATISTICS","chunk_index":30}
{"chunk_id":"1bc31b016d3649ec","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"medical information online?” Of 1072 Internet users who chose to respond, 38% of them responded \nwith “frequently.” What term is used to describe this type of survey in which the people surveyed \nconsist of those who decided to respond? What is wrong with this type of sampling method?\n2. Reported Versus Measured In a survey of 1046 adults conducted by Bradley Corpora-\ntion, subjects were asked how often they wash their hands when using a public restroom, and \n70% of the respondents said “always.”\na. Identify the sample and the population.\nb. Why would better results be obtained by observing the hand washing instead of asking about it?\n1-1 Basic Skills and Concepts\ne \nPublication Bias\nThere is a “pub-\nlication bias” \nin professional \njournals. It is \nthe tendency to \npublish positive \nresults (such \nas showing that some treatment \nis effective) much more often \nthan negative results (such as \nshowing that some treatment has \nno effect). In the article “Regis-\ntering Clinical Trials” (Journal of \nthe American Medical Asso-\nciation, Vol. 290, No. 4), authors \nKay Dickersin and Drummond \n Rennie state that “the result of \nnot knowing who has performed \nwhat (clinical trial) is loss and \ndistortion of the evidence, waste \nand duplication of trials, inability \nof funding agencies to plan, and \na chaotic system from which \nonly certain sponsors might \nbenefit, and is invariably against \nthe interest of those who offered \nto participate in trials and of \npatients in general.” They sup-\nport a process in which all clinical \ntrials are registered in one central \nsystem, so that future research-\ners have access to all previous \nstudies, not just the studies that \nwere published.","page_start":27,"page_end":27,"token_count":385,"section_type":"other","chapter_number":1,"chapter_title":"INTRODUCTION TO STATISTICS","chunk_index":31}
{"chunk_id":"eff34371af68a215","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"10 \nCHAPTER 1 Introduction to Statistics\n3. Statistical Significance Versus Practical Significance When testing a new treatment, \nwhat is the difference between statistical significance and practical significance? Can a treat-\nment have statistical significance, but not practical significance?\n4. Correlation One study showed that for a recent period of 11 years, there was a strong cor-\nrelation (or association) between the numbers of people who drowned in swimming pools and \nthe amounts of power generated by nuclear power plants (based on data from the Centers for \nDisease Control and Prevention and the Department of Energy). Does this imply that increas-\ning power from nuclear power plants is the cause of more deaths in swimming pools? Why or \nwhy not?\nConsider the Source. In Exercises 5–8, determine whether the given source has the \n potential to create a bias in a statistical study.\n5. Physicians Committee for Responsible Medicine The Physicians Committee for Re-\nsponsible Medicine tends to oppose the use of meat and dairy products in our diets, and that \norganization has received hundreds of thousands of dollars in funding from the Foundation to \nSupport Animal Protection.\n6. Arsenic in Rice Amounts of arsenic in samples of rice grown in Texas were measured by \nthe Food and Drug Administration (FDA).\n7. Brain Size A data set in Appendix B includes brain volumes from 10 pairs of monozygotic \n(identical) twins. The data were collected by researchers at Harvard University, Massachusetts \nGeneral Hospital, Dartmouth College, and the University of California at Davis.\n8. Chocolate An article in Journal of Nutrition (Vol. 130, No. 8) noted that chocolate is rich \nin flavonoids. The article notes “regular consumption of foods rich in flavonoids may reduce \nthe risk of coronary heart disease.” The study received funding from Mars, Inc., the candy com-\npany, and the Chocolate Manufacturers Association.\nSampling Method. In Exercises 9–12, determine whether the sampling method appears \nto be sound or is flawed.\n9. Nuclear Power Plants In a survey of 1368 subjects, the following question was posted \non the USA Today website: “In your view, are nuclear plants safe?” The survey subjects \nwere Internet users who chose to respond to the question posted on the electronic edition of \nUSA Today.\n10. Clinical Trials Researchers at Yale University conduct a wide variety of clinical trials by \nusing subjects who volunteer after reading advertisements soliciting paid volunteers.\n11. NHANES Examinations In a recent year, the National Health and Nutrition Examina-\ntion Survey (NHANES), sponsored by the National Center for Health Statistics, selected \nmore than 9000 subjects who were given physical exams. Subjects were selected through \na somewhat complicated procedure designed to obtain results that are representative of the \npopulation.\n12. Health In a survey of 3014 randomly selected U.S. adults, 45% reported that they have \nat least one chronic health condition, such as diabetes or high blood pressure. The survey was \nconducted by Princeton Survey Research Associates International.\nStatistical Significance and Practical Significance. In Exercises 13–16, determine ","page_start":28,"page_end":28,"token_count":647,"section_type":"other","chapter_number":1,"chapter_title":"INTRODUCTION TO STATISTICS","chunk_index":32}
{"chunk_id":"ec4c921f92b6f59d","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"a somewhat complicated procedure designed to obtain results that are representative of the \npopulation.\n12. Health In a survey of 3014 randomly selected U.S. adults, 45% reported that they have \nat least one chronic health condition, such as diabetes or high blood pressure. The survey was \nconducted by Princeton Survey Research Associates International.\nStatistical Significance and Practical Significance. In Exercises 13–16, determine \nwhether the results appear to have statistical significance, and also determine whether the \nresults appear to have practical significance.\n13. Diet and Exercise Program In a study of the Kingman diet and exercise program, \n40  subjects lost an average of 22 pounds. There is about a 1% chance of getting such results \nwith a program that has no effect.","page_start":28,"page_end":28,"token_count":161,"section_type":"other","chapter_number":1,"chapter_title":"INTRODUCTION TO STATISTICS","chunk_index":33}
{"chunk_id":"94447e613d3448c6","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"1-1 Statistical and Critical Thinking \n11\n14. MCAT The Medical College Admissions Test (MCAT) is commonly used as part of the \n decision-making process for determining which students to accept into medical schools. To test \nthe effectiveness of the Siena MCAT preparation course, 16 students take the MCAT test, then \nthey complete the preparatory course, and then they retake the MCAT test, with the result that the \naverage (mean) score for this group rises from 25 to 30. There is a 0.3% chance of getting those \nresults by chance. Does the course appear to be effective?\n15. Gender Selection In a study of the Gender Aide method of gender selection used to \n increase the likelihood of a baby being born a girl, 2000 users of the method gave birth to \n980 boys and 1020 girls. There is about a 19% chance of getting that many girls if the method \nhad no effect.\n16. Systolic Blood Pressure High systolic blood pressure is 140 mm Hg or higher.  (Normal \nvalues are less than 120 mm Hg, and prehypertension levels are between 120 mm Hg and \n139 mm Hg.) Subjects with high blood pressure are encouraged to take action to lower it. A \npharmaceutical company develops a new medication designed to lower blood pressure, and \ntests on 25 subjects result in an average (mean) decrease of 2 mm Hg. Analysis of the results \nshows that there is a 15% chance of getting such results if the medication has no effect.\nIn Exercises 17–20, refer to the sample of body temperatures (degrees Fahrenheit) in the \ntable below. (The body temperatures are recorded on the same day from a sample of five \nrandomly selected males listed in a data set in Appendix B.)\nSubject\n1\n2\n3\n4\n5\n8 AM\n97.0\n98.5\n97.6\n97.7\n98.7\n12 AM\n97.6\n97.8\n98.0\n98.4\n98.4\n17. Context of the Data Refer to the table of body temperatures. Is there some meaning-\nful way in which each body temperature recorded at 8 AM is matched with the 12 AM \n temperature?\n18. Source The listed body temperatures were obtained from Dr. Steven Wasserman, Dr. \nPhilip Mackowiak, and Dr. Myron Levine, who were researchers at the University of Maryland. \nIs the source of the data likely to be biased?\n19. Conclusion Given the body temperatures in the table, what issue can be addressed by con-\nducting a statistical analysis of the data?\n20. Conclusion If we analyze the listed body temperatures with suitable methods of statistics, \nwe conclude that when the differences are found between the 8 AM body temperatures and \nthe 12 AM body temperatures, there is a 64% chance that the differences can be explained by \nrandom results obtained from populations that have the same 8 AM and 12 AM body tempera-\ntures. What should we conclude about the statistical significance of those differences?","page_start":29,"page_end":29,"token_count":660,"section_type":"other","chapter_number":1,"chapter_title":"INTRODUCTION TO STATISTICS","chunk_index":34}
{"chunk_id":"d82af0d16a352bca","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"ducting a statistical analysis of the data?\n20. Conclusion If we analyze the listed body temperatures with suitable methods of statistics, \nwe conclude that when the differences are found between the 8 AM body temperatures and \nthe 12 AM body temperatures, there is a 64% chance that the differences can be explained by \nrandom results obtained from populations that have the same 8 AM and 12 AM body tempera-\ntures. What should we conclude about the statistical significance of those differences?\nIn Exercises 21–24, refer to the data in the table below. The entries are white blood cell \ncounts (1000 cells,ML) and red blood cell counts (million cells,ML) from male subjects \n examined as part of a large health study conducted by the National Center for Health Statis-\ntics. The data are matched, so that the first subject has a white blood cell count of 8.7 and a \nred blood cell count of 4.91, and so on.\nSubject\n1\n2\n3\n4\n5\nWhite\n8.7\n5.9\n7.3\n6.2\n5.9\nRed\n4.91\n5.59\n4.44\n4.80\n5.17\ncontinued","page_start":29,"page_end":29,"token_count":260,"section_type":"other","chapter_number":1,"chapter_title":"INTRODUCTION TO STATISTICS","chunk_index":35}
{"chunk_id":"c106bfbf2911f359","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"12 \nCHAPTER 1 Introduction to Statistics\n21. Context Given that the data (on the bottom of the preceding page) are matched and consid-\nering the units of the data, does it make sense to use the difference between each white blood \ncell count and the corresponding red blood cell count? Why or why not?\n22. Analysis Given the context of the data in the table (on the bottom of the preceding page), \nwhat issue can be addressed by conducting a statistical analysis of the measurements?\n23. Source of the Data Considering the source of the data (on the bottom of the preceding \npage), does that source appear to be biased in some way?\n24. Conclusion If we analyze the sample data (on the bottom of the preceding page) and \nconclude that there is a correlation between white and red blood cell counts, does it follow that \nhigher white are the cause of higher red blood cell counts?\nWhat’s Wrong? In Exercises 25–28, identify what is wrong.\n25. Potatoes In a poll sponsored by the Idaho Potato Commission, 1000 adults were asked to \nselect their favorite vegetables, and the favorite choice was potatoes, which were selected by \n26% of the respondents.\n26. Healthy Water In a USA Today online poll, 951 Internet users chose to respond, and 57% \nof them said that they prefer drinking bottled water instead of tap water.\n27. Cheese and Bedsheet Deaths In recent years, there has been a strong correlation be-\ntween per capita consumption of cheese in the United States and the numbers of people who \ndied from being tangled in their bedsheets. Really. Therefore, consumption of cheese causes \nbedsheet entanglement fatalities.\n28. Smokers The electronic cigarette maker V2 Cigs sponsored a poll showing that 55% of \nsmokers surveyed say that they feel ostracized “sometimes,” “often,” or “always.”\nPercentages. In Exercises 29 and 30, answer the given questions, which are related to \npercentages.\n29. Health It was noted in Exercise 12 “Health” that in a survey of 3014 randomly selected \nU.S. adults, 45% reported that they have at least one chronic health condition, such as diabetes \nor high blood pressure.\na. What is 45% of 3014 adults?\nb. Could the result from part (a) be the actual number of survey subjects who have at least one \nchronic condition?\nc. What is the actual number of survey subjects who have at least one chronic condition?\nd. Among those surveyed, 1808 were called by landline and 1206 were called by cell phone. \nWhat percentage of the survey subjects were called by cell phone?\n30. Chillax USA Today reported results from a Research Now for Keurig survey in which \n1458 men and 1543 women were asked this: “In a typical week, how often can you kick back \nand relax?”\na. Among the women, 19% responded with “rarely, if ever.” What is the exact value that is 19% \nof the number of women surveyed?","page_start":30,"page_end":30,"token_count":647,"section_type":"other","chapter_number":1,"chapter_title":"INTRODUCTION TO STATISTICS","chunk_index":36}
{"chunk_id":"87d76ad327c3ea9d","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"What percentage of the survey subjects were called by cell phone?\n30. Chillax USA Today reported results from a Research Now for Keurig survey in which \n1458 men and 1543 women were asked this: “In a typical week, how often can you kick back \nand relax?”\na. Among the women, 19% responded with “rarely, if ever.” What is the exact value that is 19% \nof the number of women surveyed?\nb. Could the result from part (a) be the actual number of women who responded with “rarely, if \never”? Why or why not?\nc. What is the actual number of women who responded with “rarely, if ever”?\nd. Among the men who responded, 219 responded with “rarely, if ever.” What is the percentage \nof men who responded with “rarely, if ever”?\ne. Consider the question that the subjects were asked. Is that question clear and unambiguous so \nthat all respondents will interpret the question the same way? How might the survey be improved?","page_start":30,"page_end":30,"token_count":229,"section_type":"other","chapter_number":1,"chapter_title":"INTRODUCTION TO STATISTICS","chunk_index":37}
{"chunk_id":"5eab198823143022","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"1-2 Types of Data \n13\nIf we have more than one statistic, we have “statistics.” Another meaning of “statis-\ntics” was given in Section 1-1, where we defined statistics to be the science of plan-\nning studies and experiments; obtaining data; organizing, summarizing, presenting, \nanalyzing, and interpreting those data; and then drawing conclusions based on them. \nWe now have two different definitions of statistics, but we can determine which of \nthese two definitions applies by considering the context in which the term statistics is \nused, as in the following example.\n31. What’s Wrong with This Picture? The Newport Chronicle ran a survey by asking read-\ners to call in their response to this question: “Do you support a ban on electronic cigarettes, \nwhich foster smoking among our children?” It was reported that 20 readers responded and that \n87% said “no,” while 13% said “yes.” Identify four major flaws in this survey.\n32. Falsifying Data A researcher at the Sloan-Kettering Cancer Research Center was once \ncriticized for falsifying data. Among his data were figures obtained from 6 groups of mice, \nwith 20 individual mice in each group. The following values were given for the percentage of \nsuccesses in each group: 53%, 58%, 63%, 46%, 48%, 67%. What’s wrong with those values?\n1-1 Beyond the Basics\nDEFINITIONS\nA parameter is a numerical measurement describing some characteristic of a \npopulation.\nA statistic is a numerical measurement describing some characteristic of a sample.\nHINT The alliteration in “population parameter” and “sample statistic” helps us \nremember the meanings of these terms.\nEXAMPLE 1  Parameter, Statistic\nThere are 17,246,372 high school students in the United States. In a study of 8505 \nU.S. high school students 16 years of age or older, 44.5% of them said that they \ntexted while driving at least once during the previous 30 days (based on data in \nKey Concept A major use of statistics is to collect and use sample data to make con-\nclusions about populations. We should know and understand the meanings of the terms \nstatistic and parameter, as defined below. In this section we describe a few different \ntypes of data. The type of data is one of the key factors that determine the statistical \nmethods we use in our analysis.\nIn Part 1 of this section we describe the basics of different types of data, and then \nin Part 2 we consider “big data” and missing data.\nPART 1\n Basic Types of Data\nParameter, Statistic\n \n1-2 \nTypes of Data\ncontinued\n","page_start":31,"page_end":31,"token_count":570,"section_type":"other","chapter_number":1,"chapter_title":"INTRODUCTION TO STATISTICS","chunk_index":38}
{"chunk_id":"b8e376a0902cfc3b","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"14 \nCHAPTER 1 Introduction to Statistics\nQuantitative, Categorical\nSome data are numbers representing counts or measurements (such as a systolic blood \npressure of 118 mm Hg), whereas others are attributes (such as eye color of green or \nbrown) that are not counts or measurements. The terms quantitative data and cat-\negorical data distinguish between these types.\n“Texting While Driving and Other Risky Motor Vehicle Behaviors Among U.S. \nHigh School Students,” by Olsen, Shults, Eaton, Pediatrics, Vol. 131, No. 6).\n \n1. Parameter: The population size of all 17,246,372 high school students is a \nparameter, because it is the size of the entire population of all high school \nstudents in the United States. If we somehow knew the percentage of all \n17,246,372 high school students who reported they had texted while driving, \nthat percentage would also be a parameter.\n \n2. Statistic: The value of 44.5% is a statistic, because it is based on the sample, \nnot on the entire population.\nDEFINITIONS\nQuantitative (or numerical) data consist of numbers representing counts or mea-\nsurements.\nCategorical (or qualitative or attribute) data consist of names or labels (not num-\nbers that represent counts or measurements).\nCAUTION Categorical data are sometimes coded with numbers, with those num-\nbers replacing names. Although such numbers might appear to be quantitative, \nthey are actually categorical data. See the third part of Example 2.\nInclude Units of Measurement With quantitative data, it is important to use the \nappropriate units of measurement, such as dollars, hours, feet, or meters. We should \ncarefully observe information given about the units of measurement, such as “all \namounts are in thousands of dollars,” or “all units are in kilograms.” Ignoring such \nunits of measurement can be very costly. The National Aeronautics and Space Admin-\nistration (NASA) lost its $125 million Mars Climate Orbiter when the orbiter crashed \nbecause the controlling software had acceleration data in English units, but they were \nincorrectly assumed to be in metric units.\nEXAMPLE 2  Quantitative, Categorical\n \n1. Quantitative Data: The ages (in years) of subjects enrolled in a clinical trial\n \n2. Categorical Data as Labels: The genders (male>female) of subjects enrolled \nin a clinical trial\n \n3. Categorical Data as Numbers: The identiﬁcation numbers 1, 2, 3, . . . , 25 \nare assigned randomly to the 25 subjects in a clinical trial. Those numbers \nare substitutes for names. They don’t measure or count anything, so they are \ncategorical data, not quantitative data.\n","page_start":32,"page_end":32,"token_count":580,"section_type":"other","chapter_number":1,"chapter_title":"INTRODUCTION TO STATISTICS","chunk_index":39}
{"chunk_id":"7979dbff848fa6e0","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"1-2 Types of Data \n15\nDiscrete, Continuous\nQuantitative data can be further described by distinguishing between discrete and con-\ntinuous types.\nDEFINITIONS\nDiscrete data result when the data values are quantitative and the number of \nvalues is finite or “countable.” (If there are infinitely many values, the collection of \nvalues is countable if it is possible to count them individually, such as the number \nof tosses of a coin before getting tails or the number of births in Houston before \ngetting a male.)\nContinuous (numerical) data result from infinitely many possible quantitative \nvalues, where the collection of values is not countable. (That is, it is impossible \nto count the individual items because at least some of them are on a continuous \nscale, such as the lengths of distances from 0 cm to 12 cm.)\nCAUTION The concept of countable data plays a key role in the preceding defini-\ntions, but it is not a particularly easy concept to understand. Continuous data can \nbe measured, but not counted. If you select a particular data value from continuous \ndata, there is no “next” data value. See Example 3.\n \n Continuous Data\n \n Discrete Data\nEXAMPLE 3  Discrete, Continuous\n \n1. Discrete Data of the Finite Type: Each of several physicians plans to count \nthe number of physical examinations given during the next full week. The \ndata are discrete data because they are ﬁnite numbers, such as 27 and 46 that \nresult from a counting process.\n \n2. Discrete Data of the Inﬁnite Type: Researchers plan to test the accuracy of a \nblood typing test by repeating the process of submitting a sample of the same \nblood (Type O+) until the test yields an error. It is possible that each research-\ner could repeat this test forever without ever getting an error, but they can \nstill count the number of tests as they proceed. The collection of the numbers \nof tests is countable, because you can count them, even though the counting \ncould go on forever.\n \n3. Continuous Data: When the typical patient has blood drawn as part of a \nroutine examination, the volume of blood drawn is between 0 mL and 50 mL. \nThere are inﬁnitely many values between 0 mL and 50 mL. Because it is im-\npossible to count the number of diﬀerent possible values on such a continuous \nscale, these amounts are continuous data.\n","page_start":33,"page_end":33,"token_count":520,"section_type":"other","chapter_number":1,"chapter_title":"INTRODUCTION TO STATISTICS","chunk_index":40}
{"chunk_id":"fd9aa70a0f8a7d68","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"16 \nCHAPTER 1 Introduction to Statistics\nLevels of Measurement\nAnother common way of classifying data is to use four levels of measurement: nomi-\nnal, ordinal, interval, and ratio, all defined below. (Also see Table 1-2 for brief de-\nscriptions of the four levels of measurements.) When we are applying statistics to \nreal problems, the level of measurement of the data helps us decide which procedure \nto use. There will be references to these levels of measurement in this book, but the \nimportant point here is based on common sense: Don’t do computations and don’t use \nstatistical methods that are not appropriate for the data. For example, it would not \nmake sense to compute an average (mean) of Social Security numbers, because those \nnumbers are data used for identification, and they don’t represent measurements or \ncounts of anything.\nGRAMMAR: FEWER VERSUS LESS When describing smaller amounts, it is \ncorrect grammar to use “fewer” for discrete amounts and “less” for continuous \namounts. It is correct to say that we drank fewer cans of cola and that, in the pro-\ncess, we drank less cola. The numbers of cans of cola are discrete data, whereas \nthe volume amounts of cola are continuous data.\nDEFINITION\nThe nominal level of measurement is characterized by data that consist of \nnames, labels, or categories only. It is not possible to arrange the data in some \norder (such as low to high).\nEXAMPLE 4  Nominal Level\nHere are examples of sample data at the nominal level of measurement.\n1. Yes, No, Undecided: Survey responses of yes, no, and undecided\n \n2. Coded Survey Responses: For an item on a survey, respondents are given a \nchoice of possible answers, and they are coded as follows: “I agree” is coded \nas 1; “I disagree” is coded as 2; “I don’t care” is coded as 3; “I refuse to \nanswer” is coded as 4; “Go away and stop bothering me” is coded as 5. The \nnumbers 1, 2, 3, 4, 5 don’t measure or count anything.\nBecause nominal data lack any ordering or numerical significance, they should \nnot be used for calculations. Numbers such as 1, 2, 3, and 4 are sometimes assigned \nto the different categories (especially when data are coded for computers), but these \nnumbers have no real computational significance and any average (mean) calculated \nfrom them is meaningless and possibly misleading.\nDEFINITION\nData are at the ordinal level of measurement if they can be arranged in some \norder, but differences (obtained by subtraction) between data values either cannot \nbe determined or are meaningless.\n","page_start":34,"page_end":34,"token_count":581,"section_type":"other","chapter_number":1,"chapter_title":"INTRODUCTION TO STATISTICS","chunk_index":41}
{"chunk_id":"10dc1b9ac26a5554","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"1-2 Types of Data \n17\nOrdinal data provide information about relative comparisons, but not the magni-\ntudes of the differences. Usually, ordinal data should not be used for calculations such \nas an average (mean), but this guideline is sometimes disregarded (such as when we \nuse letter grades to calculate a grade-point average).\nEXAMPLE 5  Ordinal Level\nHere is an example of sample data at the ordinal level of measurement.\nCourse Grades: A biostatistics professor assigns grades of A, B, C, D, or F. These \ngrades can be arranged in order, but we can’t determine differences between the \ngrades. For example, we know that A is higher than B (so there is an ordering), but \nwe cannot subtract B from A (so the difference cannot be found).\nDEFINITION\nData are at the interval level of measurement if they can be arranged in order, and \ndifferences between data values can be found and are meaningful; but data at this \nlevel do not have a natural zero starting point at which none of the quantity is present.\nEXAMPLE 6  Interval Level\nThese examples illustrate the interval level of measurement.\n \n1. Temperatures: Body temperatures of 98.2°F and 98.8°F are examples of data \nat this interval level of measurement. Those values are ordered, and we can \ndetermine their diﬀerence of 0.6°F. However, there is no natural starting point. \nThe value of 0°F might seem like a starting point, but it is arbitrary and does \nnot represent the total absence of heat.\n \n2. Years: The years 1492 and 1776 can be arranged in order, and the diﬀerence \nof 284 years can be found and is meaningful. However, time did not begin in \nthe year 0, so the year 0 is arbitrary instead of being a natural zero starting \npoint representing “no time.”\nDEFINITION\nData are at the ratio level of measurement if they can be arranged in order, differ-\nences can be found and are meaningful, and there is a natural zero starting point \n(where zero indicates that none of the quantity is present). For data at this level, dif-\nferences and ratios are both meaningful.\nEXAMPLE 7  Ratio Level\nThe following are examples of data at the ratio level of measurement. Note the pres-\nence of the natural zero value, and also note the use of meaningful ratios of “twice” \nand “three times.”\n \n1. Heights of Students: Heights of 180 cm and 90 cm for a high school student and a \npreschool student (0 cm represents no height, and 180 cm is twice as tall as 90 cm.)\n \n2. Class Times: The times of 50 min and 100 min for a statistics class (0 min \nrepresents no class time, and 100 min is twice as long as 50 min.)\n","page_start":35,"page_end":35,"token_count":616,"section_type":"other","chapter_number":1,"chapter_title":"INTRODUCTION TO STATISTICS","chunk_index":42}
{"chunk_id":"be240e4b1fdab581","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"18 \nCHAPTER 1 Introduction to Statistics\nSee Table 1-2 for brief descriptions of the four levels of measurements.\nTABLE 1-2 Levels of Measurement\nLevel of \nMeasurement\nBrief Description\nExample\nRatio\nThere is a natural zero starting point and \nratios make sense.\nHeights, lengths, distances, \nvolumes\nInterval\nDifferences are meaningful, but there is \nno natural zero starting point and ratios \nare meaningless.\nBody temperatures in degrees \nFahrenheit or Celsius\nOrdinal\nData can be arranged in order, but dif-\nferences either can’t be found or are \nmeaningless.\nRanks of colleges in U.S. News & \nWorld Report\nNominal\nCategories only. Data cannot be arranged \nin order.\nEye colors\nHINT The distinction between the interval and ratio levels of measurement can \nbe a bit tricky. Here are two tools for help with that distinction:\n1.  Ratio Test Focus on the term “ratio” and know that the term “twice” describes the \nratio of one value to be double the other value. To distinguish between the interval \nand ratio levels of measurement, use a “ratio test” by asking this question: Does \nuse of the term “twice” make sense? “Twice” makes sense for data at the ratio level \nof measurement, but it does not make sense for data at the interval level of mea-\nsurement.\n2.  True Zero For ratios to make sense, there must be a value of “true zero,” where \nthe value of zero indicates that none of the quantity is present, and zero is not \nsimply an arbitrary value on a scale. The temperature of 0°F is arbitrary and \ndoes not indicate that there is no heat, so temperatures on the Fahrenheit scale \nare at the interval level of measurement, not the ratio level.\nEXAMPLE 8   Distinguishing Between the Ratio Level and  \nInterval Level\nFor each of the following, determine whether the data are at the ratio level of mea-\nsurement or the interval level of measurement:\na. Times (minutes) it takes to complete a statistics test.\nb. Body temperatures (Celsius) of statistics students.\nSOLUTION\na. Apply the “ratio test” described in the preceding hint. If one student completes \nthe test in 40 minutes and another student completes the test in 20 min, does it \nmake sense to say that the ﬁrst student used twice as much time? Yes! So the \ntimes are at the ratio level of measurement. Also, a time of 0 minutes does repre-\nsent “no time,” so the value of 0 is a true zero indicating that no time was used.\nb. Apply the “ratio test” described in the preceding hint. If one student has a \nbody temperature of 40°C and another student has a body temperature of \n20°C, does it make sense to say that the ﬁrst student is twice as hot as the \nT\nSurvey Pitfalls\nSurveys con-\nstitute a huge \nand growing \nbusiness in the \nUnited States, \nbut survey \nresults can be ","page_start":36,"page_end":36,"token_count":647,"section_type":"other","chapter_number":1,"chapter_title":"INTRODUCTION TO STATISTICS","chunk_index":43}
{"chunk_id":"3ff4168ae77e2dad","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"b. Apply the “ratio test” described in the preceding hint. If one student has a \nbody temperature of 40°C and another student has a body temperature of \n20°C, does it make sense to say that the ﬁrst student is twice as hot as the \nT\nSurvey Pitfalls\nSurveys con-\nstitute a huge \nand growing \nbusiness in the \nUnited States, \nbut survey \nresults can be \ncompromised by many factors. \nA growing number of people \nrefuse to respond; the average \nresponse rate is now about 22%, \ncompared to 36% around the \nyear 2000. A growing number of \npeople are more difficult to reach \nbecause they use cell phones \n(no directories); about 15% of \nadults now have cell phones and \nno landlines, and they tend to \nbe younger than average. There \nare obvious problems associated \nwith surveys that ask respon-\ndents about drug use, theft, or \nsexual behavior, and a social \ndesirability bias occurs when sur-\nvey respondents are not honest \nbecause they don’t want to be \nviewed negatively by the person \nconducting the interview.","page_start":36,"page_end":36,"token_count":248,"section_type":"other","chapter_number":1,"chapter_title":"INTRODUCTION TO STATISTICS","chunk_index":44}
{"chunk_id":"b0e0617c244a8ecc","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"1-2 Types of Data \n19\nPART 2\n  Big Data and Missing Data:  \nToo Much and Not Enough\nWhen working with data, we might encounter some data sets that are excessively \nlarge, and we might also encounter some data sets with individual elements missing. \nHere in Part 2 we briefly discuss both cases.\nBig Data\nEdward Snowden used his employment at the NSA (National Security Agency) to re-\nveal substantial top secret documents that led to the realization that the NSA was con-\nducting telephone and Internet surveillance of U.S. citizens as well as world leaders. \nThe NSA was collecting massive amounts of data that were analyzed in an attempt to \nprevent terrorism. Monitoring telephone calls and Internet communications is made \npossible with modern technology. The NSA can compile big data, and such ginormous \ndata sets have led to the birth of data science. There is not universal agreement on the \nfollowing definitions, and various other definitions can be easily found elsewhere.\n second student? (Ignore subjective amounts of attractiveness and consider \nonly science.) No! So the body temperatures are not at the ratio level of \nmeasurement. Because the diﬀerence between 40°C and 20°C is the same as \nthe diﬀerence between 90°C and 70°C, the diﬀerences are meaningful, but be-\ncause ratios do not make sense, the body temperatures are at the interval level \nof measurement. Also, the temperature of 0°C does not represent “no heat” so \nthe value of 0 is not a true zero indicating that no heat is present.\nDEFINITIONS\nBig data refers to data sets so large and so complex that their analysis is beyond \nthe capabilities of traditional software tools. Analysis of big data may require soft-\nware simultaneously running in parallel on many different computers.\nData science involves applications of statistics, computer science, and software en-\ngineering, along with some other relevant fields (such as biology and epidemiology).\nExamples of Data Set Magnitudes We can see from the above definition of big \ndata that there isn’t a fixed number that serves as an exact boundary for determining \nwhether a data set qualifies as being big data, but big data typically involves amounts \nof data such as the following.\n■Terabytes (1012 or 1,000,000,000,000 bytes) of data\n■Petabytes (1015 bytes) of data\n■Exabytes (1018 bytes) of data\n■Zettabytes (1021 bytes) of data\n■Yottabytes (1024 bytes) of data\nExamples of Applications of Big Data The following are a few examples involv-\ning big data:\n■Attempt to forecast flu epidemics by analyzing Internet searches of flu symptoms.\n■The Spatio Temporal Epidemiological Modeler developed by IBM is providing a \nmeans for using a variety of data that are correlated with disease data.\ne-\nl \no\nBig Data Instead  \nof a Clinical Trial\nNicholas \nTatonetti of \nColumbia \nUniversity \nsearched Food \nand Drug \nAdministration \ndatabases for \nadverse reactions in patients that ","page_start":37,"page_end":37,"token_count":650,"section_type":"other","chapter_number":1,"chapter_title":"INTRODUCTION TO STATISTICS","chunk_index":45}
{"chunk_id":"8523153b949144b5","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"ing big data:\n■Attempt to forecast flu epidemics by analyzing Internet searches of flu symptoms.\n■The Spatio Temporal Epidemiological Modeler developed by IBM is providing a \nmeans for using a variety of data that are correlated with disease data.\ne-\nl \no\nBig Data Instead  \nof a Clinical Trial\nNicholas \nTatonetti of \nColumbia \nUniversity \nsearched Food \nand Drug \nAdministration \ndatabases for \nadverse reactions in patients that \nresulted from different pairings \nof drugs. He discovered that \nthe paroxetine drug for depres-\nsion and the pravastatin drug \nfor high cholesterol interacted \nto create increases in glucose \n(blood sugar) levels. When taken \nseparately by patients, neither \ndrug raised glucose levels, but \nthe increase in glucose levels \noccurred when the two drugs \nwere taken together. This finding \nresulted from a general database \nsearch of interactions from many \npairings of drugs, not from a \nclinical trial involving patients \nusing Paxil and pravastatin.\ncontinued","page_start":37,"page_end":37,"token_count":223,"section_type":"other","chapter_number":1,"chapter_title":"INTRODUCTION TO STATISTICS","chunk_index":46}
{"chunk_id":"c91ef7caf6572d1b","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"20 \nCHAPTER 1 Introduction to Statistics\n \n■A National Electronic Disease Surveillance System is used to monitor disease \ntrends and identify outbreaks of infectious disease.\n \n■Google provides live traffic maps by recording and analyzing GPS (global posi-\ntioning system) data collected from the smartphones of people traveling in their \nvehicles.\n \n■Amazon monitors and tracks 1.4 billion items in its store that are distributed \nacross hundreds of fulfillment centers around the world.\nExamples of Jobs According to Analytic Talent, there are 6000 companies hiring \ndata scientists, and here are some job posting examples:\n \n■Facebook: Data Scientist\n \n■IBM: Data Scientist\n \n■PayPal: Data Scientist\n \n■The College Board: SAS Programmer>Data Scientist\n \n■Netflix: Senior Data Engineer>Scientist\nStatistics in Data Science The modern data scientist has a solid background in \nstatistics and computer systems as well as expertise in fields that extend beyond sta-\ntistics. The modern data scientist might be skilled with Hadoop software, which uses \nparallel processing on many computers for the analysis of big data. The modern data \nscientist might also have a strong background in some other field, such as psychology, \nbiology, medicine, chemistry, or economics. Because of the wide range of disciplines \nrequired, a data science project might typically involve a team of collaborating indi-\nviduals with expertise in different fields. An introductory statistics course is a great \nfirst step in becoming a data scientist.\nMissing Data\nWhen collecting sample data, it is quite common to find that some values are miss-\ning. Ignoring missing data can sometimes create misleading results. If you make the \nmistake of skipping over a few different sample values when you are manually typ-\ning them into a statistics software program, the missing values are not likely to have \na serious effect on the results. However, if a survey includes many missing salary en-\ntries because those with very low incomes are reluctant to reveal their salaries, those \nmissing low values will have the serious effect of making salaries appear higher than \nthey really are.\nFor an example of missing data, see the following table. The body temperature for \nSubject 2 at 12 AM on day 2 is missing. (The table below includes the first three rows \nof data from Data Set 2 “Body Temperatures” in Appendix B.)\n Body Temperatures (in degrees Fahrenheit) of Healthy Adults\nTemperature  \nDay 1\nTemperature  \nDay 2\nSubject\nAge\nSex\nSmoke\n8 AM\n12 AM\n8 AM\n12 AM\n1\n22\nM\nY\n98.0\n98.0\n98.0\n98.6\n2\n23\nM\nY\n97.0\n97.6\n97.4\n----\n3\n22\nM\nY\n98.6\n98.8\n97.8\n98.6\n","page_start":38,"page_end":38,"token_count":593,"section_type":"other","chapter_number":1,"chapter_title":"INTRODUCTION TO STATISTICS","chunk_index":47}
{"chunk_id":"4b0a2332db2225dd","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"1-2 Types of Data \n21\nThere are different categories of missing data. See the following definitions.\nDEFINITION\nA data value is missing completely at random if the likelihood of its being miss-\ning is independent of its value or any of the other values in the data set. That is, any \ndata value is just as likely to be missing as any other data value.\n(Note: More complete discussions of missing data will distinguish between missing \ncompletely at random and missing at random, which means that the likelihood of a \nvalue being missing is independent of its value after controlling for another variable. \nThere is no need to know this distinction in this book.)\nExample of Missing Data—Random When using a keyboard to manually enter \nages of survey respondents, the operator is distracted by a colleague singing “Day-\ndream Believer” and makes the mistake of failing to enter the age of 37 years. This \ndata value is missing completely at random.\nDEFINITION\nA data value is missing not at random if the missing value is related to the reason \nthat it is missing.\nExample of Missing Data—Not at Random A survey question asks each respon-\ndent to enter his or her annual income, but respondents with very low incomes skip \nthis question because they find it embarrassing.\nBiased Results? Based on the above two definitions and examples, it makes sense \nto conclude that if we ignore data missing completely at random, the remaining values \nare not likely to be biased and good results should be obtained. However, if we ignore \ndata that are missing not at random, it is very possible that the remaining values are \nbiased and results will be misleading.\nCorrecting for Missing Data There are different methods for dealing with missing \ndata.\n1. Delete Cases: One very common method for dealing with missing data is to \ndelete all subjects having any missing values.\n■If the data are missing completely at random, the remaining values are not \nlikely to be biased and good results can be obtained, but with a smaller sam-\nple size.\n■If the data are missing not at random, deleting subjects having any missing \nvalues can easily result in a bias among the remaining values, so results can \nbe misleading.\n2. Impute Missing Values: We impute missing data values when we substitute \nvalues for them. There are different methods of determining the replacement \nvalues, such as using the mean of the other values, or using a randomly selected \nvalue from other similar cases, or using a method based on regression analysis \n(which will make more sense after studying Chapter 10).\nMeasuring  \nDisobedience\nHow are data \ncollected about \nsomething that \ndoesn’t seem \nto be measur-\nable, such as \npeople’s level of \ndisobedience? \nPsychologist Stanley Milgram \ndevised the following experi-\nment: A researcher instructed a \nvolunteer subject to operate a \ncontrol board that gave increas-\ningly painful “electrical shocks” \nto a third person. Actually, no real \nshocks were given, and the third \nperson was an actor. The volun-","page_start":39,"page_end":39,"token_count":639,"section_type":"other","chapter_number":1,"chapter_title":"INTRODUCTION TO STATISTICS","chunk_index":48}
{"chunk_id":"1087b251467c2069","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"something that \ndoesn’t seem \nto be measur-\nable, such as \npeople’s level of \ndisobedience? \nPsychologist Stanley Milgram \ndevised the following experi-\nment: A researcher instructed a \nvolunteer subject to operate a \ncontrol board that gave increas-\ningly painful “electrical shocks” \nto a third person. Actually, no real \nshocks were given, and the third \nperson was an actor. The volun-\nteer began with 15 volts and was \ninstructed to increase the shocks \nby increments of 15 volts. The \ndisobedience level was the point \nat which the subject refused to \nincrease the voltage. Surpris-\ningly, two-thirds of the subjects \nobeyed orders even when the \nactor screamed and faked a \nheart attack.","page_start":39,"page_end":39,"token_count":175,"section_type":"other","chapter_number":1,"chapter_title":"INTRODUCTION TO STATISTICS","chunk_index":49}
{"chunk_id":"32bfa82507315e7d","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"22 \nCHAPTER 1 Introduction to Statistics\nIn this book we do not work much with missing data, but it is important to under-\nstand this:\nWhen analyzing sample data with missing values, try to determine why \nthey are missing, and then decide whether it makes sense to treat the \nremaining values as being representative of the population. If it appears \nthat there are missing values that are missing not at random (that is, \ntheir values are related to the reasons why they are missing), know that \nthe remaining data may well be biased and any conclusions based on \nthose remaining values may well be misleading.\nStatistical Literacy and Critical Thinking\n1. Health Survey In a survey of 1020 adults in the United States, 44% said that they wash \ntheir hands after riding public transportation (based on data from KRC Research).\na. Identify the sample and the population.\nb. Is the value of 44% a statistic or a parameter?\n2. Health Survey For the same survey from Exercise 1, answer the following.\na. What is the level of measurement of the value of 44%? (nominal, ordinal, interval, ratio)\nb. Are the numbers of subjects in such surveys discrete or continuous?\nc. The responses are “yes,” “no,” “not sure,” or “refused to answer.” Are these responses quan-\ntitative data or categorical data?\n3. Quantitative, Categorical Data Identify each of the following as quantitative data or cat-\negorical data.\na. The platelet counts of exam subjects in Data Set 1 “Body Data” in Appendix B\nb. The names of the pharmaceutical companies that manufacture aspirin tablets\nc. The colors of pills\nd. The weights of aspirin tablets\n4. Discrete, Continuous Data Which of the following describe discrete data?\na. The numbers of people surveyed in each of the next several National Health and Nutrition \n Examination Surveys\nb. The exact foot lengths (cm) of a random sample of statistics students\nc. The exact times that randomly selected drivers spend texting while driving during the past 7 days\nIn Exercises 5–12, identify whether the given value is a statistic or a parameter.\n5. Brain Volume The average (mean) volume of the brains included in Data Set 9 “IQ and \nBrain Size” in Appendix B is 1126.0 cm3.\n6. CHIS A recent California Health Interview Survey (CHIS) included 2799 adolescent resi-\ndents of California.\n7. Cigarettes A data set in Appendix B includes measurements from 25 king-size cigarettes, \nand the average (mean) amount of nicotine in those 25 cigarettes is 1.26 mg.\n8. Triangle Fire Fatalities A deadly disaster in the United States was the Triangle Shirtwaist \nFactory Fire in New York City. A population of 146 garment workers died in that fire.\n1-2 Basic Skills and Concepts\n","page_start":40,"page_end":40,"token_count":610,"section_type":"other","chapter_number":2,"chapter_title":"EXPLORING DATA WITH TABLES AND GRAPHS","chunk_index":50}
{"chunk_id":"6180bd0ca2a6942a","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"1-2 Types of Data \n23\n9. Birth Weight In a study of 400 babies born at four different hospitals in New York State, it \nwas found that the average (mean) weight at birth was 3152.0 grams.\n10. Birth Genders In the same study cited in the preceding exercise, 51% of the babies were girls.\n11. Titanic A study was conducted of all 2223 passengers aboard the Titanic when it sank.\n12. Periodic Table The average (mean) atomic weight of all elements in the periodic table is \n134.355 unified atomic mass units.\nIn Exercises 13–20, determine whether the data are from a discrete or continuous  \ndata set.\n13. Freshman 15 In a study of weight gains by college students in their freshman year, re-\nsearchers record the amounts of weight gained by randomly selected students (as in Data Set \n10 “Freshman 15” in Appendix B).\n14. Births Data Set 3 “Births” in Appendix B includes the length of stay (in days) for each \nbaby in a sample of babies born in New York State. The first few values are 2, 2, 36, 5, and 2.\n15. CHIS Among the subjects surveyed as part of the California Health Interview Survey \n(CHIS), several subjects are randomly selected and their heights are recorded.\n16. Arm Circumference From Data Set 1 “Body Data” in Appendix B we see that a female \nhad an arm circumference of 32.49 cm.\n17. Families A sample of married couples is randomly selected and the number of children in \neach family is recorded.\n18. Criminal Forensics When studying the relationship between lengths of feet and heights \nso that footprint evidence at a crime scene can be used to estimate the height of the suspect, a \nresearcher records the exact lengths of feet from a large sample of random subjects.\n19. Stitch In Time The Emergency Room of the Albany Medical Center records the numbers \nof stitches used for patients in a week.\n20. Texting Fatalities The Insurance Institute for Highway Safety collects data consisting of \nthe numbers of motor vehicle fatalities caused by driving while texting.\nIn Exercises 21–28, determine which of the four levels of measurement (nominal, ordinal, \ninterval, ratio) is most appropriate.\n21. Brain Volumes Volumes (cm3) of brains listed in Data Set 9 “IQ and Brain Size” in \n Appendix B\n22. Blood Lead Level Blood lead levels of low, medium, and high used to describe the sub-\njects in Data Set 8 “IQ and Lead” in Appendix B\n23. Body Temperatures Body temperatures (in degrees Fahrenheit) listed in Data Set 2 \n“Body Temperatures” in Appendix B.\n24. Privacy Codes Instead of using actual names, subjects included in the National Health \nand Nutrition Examination Survey are coded with consecutive numbers.\n25. Hospitals A research project on the effectiveness of heart transplants begins with a compi-\nlation of the U.S. hospitals that provide heart transplants.\n26. Hospital Charges A research project on the effectiveness of heart transplants begins ","page_start":41,"page_end":41,"token_count":654,"section_type":"other","chapter_number":2,"chapter_title":"EXPLORING DATA WITH TABLES AND GRAPHS","chunk_index":51}
{"chunk_id":"9a89241381491bc5","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"“Body Temperatures” in Appendix B.\n24. Privacy Codes Instead of using actual names, subjects included in the National Health \nand Nutrition Examination Survey are coded with consecutive numbers.\n25. Hospitals A research project on the effectiveness of heart transplants begins with a compi-\nlation of the U.S. hospitals that provide heart transplants.\n26. Hospital Charges A research project on the effectiveness of heart transplants begins \nwith a compilation of the charges (dollars) for heart transplant procedures that were conducted \nwithin the past year.\n27. Physician Ranks A research project on the effectiveness of heart transplants includes \nrankings (scale of 1, 2, 3, 4, 5) of physicians who perform those procedures.\n28. Pharmaceuticals Pfizer records the years in which new products were launched, \n beginning with 1849.","page_start":41,"page_end":41,"token_count":172,"section_type":"other","chapter_number":2,"chapter_title":"EXPLORING DATA WITH TABLES AND GRAPHS","chunk_index":52}
{"chunk_id":"067577a1f96d931c","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"24 \nCHAPTER 1 Introduction to Statistics\nIn Exercises 29–32, identify the level of measurement of the data as nominal, ordinal, inter-\nval, or ratio. Also, explain what is wrong with the given calculation.\n29. Hospital ID The four hospitals included in Data Set 3 “Births” in Appendix B are coded as \nfollows: Albany Medical Center (1); Bellevue Hospital Center (1438); Olean General Hospital \n(66); Strong Memorial Hospital (413). The average (mean) of those numbers is 479.5.\n30. Social Security Numbers As part of a clinical study, the Social Security number of each \nsubject is recorded and the average (mean) of the individual digits is computed to be 4.7.\n31. Temperatures A person has a body temperature of 98.0°F during the time when the out-\nside air temperature is 49.0°F, so the person is twice as warm as the outside air.\n32. Medical School Ranks As of this writing, U.S. News & World Report ranked medical \nschools, including these results: Harvard (1), Stanford (2), Johns Hopkins (3), University of \nCalifornia at San Francisco (4), and University of Pennsylvania (5). The difference between \nHarvard and Stanford is the same as the difference between Johns Hopkins and University of \nCalifornia at San Francisco.\n33. Countable For each of the following, categorize the nature of the data using one of these \nthree descriptions: (1) discrete because the number of possible values is finite; (2) discrete \nbecause the number of possible values is infinite but countable; (3) continuous because the \nnumber of possible values is infinite and not countable.\na. Exact lengths of the feet of members of the band the Monkees\nb. Shoe sizes of members of the band the Monkees (such as 9, 9½, and so on)\nc. The number of albums sold by the Monkees band\nd. The numbers of monkeys sitting at keyboards before one of them randomly types the lyrics \nfor the song “Daydream Believer”\n1-2 Beyond the Basics\nKey Concept When using statistics in a study, planning is very important, and it is \nessential to use an appropriate method for collecting the sample data. This section \nincludes comments about various methods and sampling procedures. Of particular im-\nportance is the method of using a simple random sample. We will make frequent use \nof this sampling method throughout the remainder of this book.\nAs you read this section, remember this:\nIf sample data are not collected in an appropriate way, the data may be \nso utterly useless that no amount of statistical torturing can salvage them.\nPART 1\n  Basics of Design of Experiments and \nCollecting Sample Data\nThe Gold Standard Randomization with placebo>treatment groups is sometimes \ncalled the “gold standard” because it is so effective. (A placebo such as a sugar pill \nhas no medicinal effect.) The following example describes how the gold standard was \nused in the largest health experiment ever conducted.\n \n1-3 \nCollecting Sample Data\n","page_start":42,"page_end":42,"token_count":647,"section_type":"other","chapter_number":2,"chapter_title":"EXPLORING DATA WITH TABLES AND GRAPHS","chunk_index":53}
{"chunk_id":"77ed33f83663cedf","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"1-3 Collecting Sample Data \n25\nExample 1 describes an experiment because subjects were given a treatment, but ethi-\ncal, cost, time, and other considerations sometimes prohibit the use of an experiment. \nWe would never want to conduct a driving/texting experiment in which we ask sub-\njects to text while driving—some of them could die. It would be far better to observe \npast crash results to understand the effects of driving while texting. See the following \ndefinitions.\nEXAMPLE 1  The Salk Vaccine Experiment\nIn 1954, an experiment was designed to test the effectiveness of the Salk vaccine in \npreventing polio, which had killed or paralyzed thousands of children. By random \nselection, 401,974 children were randomly assigned to two groups: (1) 200,745 \nchildren were given a treatment consisting of Salk vaccine injections; (2) 201,229 \nchildren were injected with a placebo that contained no drug. Children were as-\nsigned to the treatment or placebo group through a process of random selection, \nequivalent to flipping a coin. Among the children given the Salk vaccine, 33 later \ndeveloped paralytic polio, and among the children given a placebo, 115 later devel-\noped paralytic polio.\nDEFINITIONS\nIn an experiment, we apply some treatment and then proceed to observe its \n effects on the individuals. (The individuals in experiments are called experimental \nunits, and they are often called subjects when they are people.)\nIn an observational study, we observe and measure specific characteristics, but \nwe don’t attempt to modify the individuals being studied.\nExperiments are often better than observational studies because well-planned experi-\nments typically reduce the chance of having the results affected by some variable that \nis not part of a study. A lurking variable is one that affects the variables included in \nthe study, but it is not included in the study.\nEXAMPLE 2  Ice Cream and Drownings\nObservational Study: Observe past data to conclude that ice cream causes drown-\nings (based on data showing that increases in ice cream sales are associated with \nincreases in drownings). The mistake is to miss the lurking variable of temperature \nand the failure to see that as the temperature increases, ice cream sales increase and \ndrownings increase because more people swim.\nExperiment: Conduct an experiment with one group treated with ice cream while \nanother group gets no ice cream. We would see that the rate of drowning victims \nis about the same in both groups, so ice cream consumption has no effect on \ndrownings.\nHere, the experiment is clearly better than the observational study.\nDesign of Experiments\nGood design of experiments includes replication, blinding, and randomization.\n■Replication is the repetition of an experiment on more than one individual. Good \nuse of replication requires sample sizes that are large enough so that we can see \nn \nClinical Trials vs. \nObservational Studies\nIn a New York \nTimes article \nabout hormone \ntherapy for \nwomen, reporter \nDenise Grady \nwrote about \nrandomized \nclinical trials that involve subjects ","page_start":43,"page_end":43,"token_count":648,"section_type":"other","chapter_number":2,"chapter_title":"EXPLORING DATA WITH TABLES AND GRAPHS","chunk_index":54}
{"chunk_id":"47a393de66da8d7a","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"Design of Experiments\nGood design of experiments includes replication, blinding, and randomization.\n■Replication is the repetition of an experiment on more than one individual. Good \nuse of replication requires sample sizes that are large enough so that we can see \nn \nClinical Trials vs. \nObservational Studies\nIn a New York \nTimes article \nabout hormone \ntherapy for \nwomen, reporter \nDenise Grady \nwrote about \nrandomized \nclinical trials that involve subjects \nwho were randomly assigned to \na treatment group and another \ngroup not given the treatment. \nSuch randomized clinical trials \nare often referred to as the “gold \nstandard” for medical research. \nIn contrast, observational studies \ncan involve patients who decide \nthemselves to undergo some \ntreatment. Subjects who decide \nthemselves to undergo treat-\nments are often healthier than \nother subjects, so the treatment \ngroup might appear to be more \nsuccessful simply because it \ninvolves healthier subjects, not \nnecessarily because the treat-\nment is effective. Researchers \ncriticized observational studies of \nhormone therapy for women by \nsaying that results might appear \nto make the treatment more ef-\nfective than it really is.","page_start":43,"page_end":43,"token_count":253,"section_type":"other","chapter_number":2,"chapter_title":"EXPLORING DATA WITH TABLES AND GRAPHS","chunk_index":55}
{"chunk_id":"0e3dac7a19d180a9","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"26 \nCHAPTER 1 Introduction to Statistics\neffects of treatments. In the Salk experiment in Example 1, the experiment used \nsufficiently large sample sizes, so the researchers could see that the Salk vaccine \nwas effective.\n■Blinding is used when the subject doesn’t know whether he or she is receiving a \ntreatment or a placebo. Blinding is a way to get around the placebo effect, which \noccurs when an untreated subject reports an improvement in symptoms. (The \nreported improvement in the placebo group may be real or imagined.) The Salk \nexperiment in Example 1 was double-blind, which means that blinding occurred \nat two levels: (1) The children being injected didn’t know whether they were \ngetting the Salk vaccine or a placebo, and (2) the doctors who gave the injec-\ntions and evaluated the results did not know either. Codes were used so that the \nresearchers could objectively evaluate the effectiveness of the Salk vaccine.\n■Randomization is used when individuals are assigned to different groups \nthrough a process of random selection, as in the Salk vaccine experiment in \nExample 1. The logic behind randomization is to use chance as a way to create \ntwo groups that are similar. The following definition refers to one common and \neffective way to collect sample data in a way that uses randomization.\nDEFINITION\nA simple random sample of n subjects is selected in such a way that every pos-\nsible sample of  the same size n has the same chance of being chosen. (A simple \nrandom sample is often called a random sample, but strictly speaking, a random \nsample has the weaker requirement that all members of the population have the \nsame chance of being selected. That distinction is not so important in this text. \n(See Exercise 38 “Simple Random Sample vs. Random Sample.”)\nThroughout, we will use various statistical procedures, and we often have \na requirement that we have collected a simple random sample, as defined \nabove.\nUnlike careless or haphazard sampling, random sampling usually requires very \ncareful planning and execution.\nOther Sampling Methods In addition to simple random sampling, here are some \nother sampling methods commonly used for surveys. Figure 1-3 illustrates these dif-\nferent sampling methods.\nDEFINITIONS\nIn systematic sampling, we select some starting point and then select every kth \n(such as every 50th) element in the population.\nWith convenience sampling, we simply use data that are very easy to get.\nIn stratified sampling, we subdivide the population into at least two different \nsubgroups (or strata) so that subjects within the same subgroup share the same \ncharacteristics (such as gender). Then we draw a sample from each subgroup (or \nstratum).\nIn cluster sampling, we first divide the population area into sections (or clusters). \nThen we randomly select some of those clusters and choose all the members from \nthose selected clusters.\nHawthorne and \nExperimenter Effects\nThe well-\nknown \nplacebo effect \noccurs when \nan untreated \nsubject incor-\nrectly believes ","page_start":44,"page_end":44,"token_count":645,"section_type":"other","chapter_number":2,"chapter_title":"EXPLORING DATA WITH TABLES AND GRAPHS","chunk_index":56}
{"chunk_id":"82f5473efefe8488","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"characteristics (such as gender). Then we draw a sample from each subgroup (or \nstratum).\nIn cluster sampling, we first divide the population area into sections (or clusters). \nThen we randomly select some of those clusters and choose all the members from \nthose selected clusters.\nHawthorne and \nExperimenter Effects\nThe well-\nknown \nplacebo effect \noccurs when \nan untreated \nsubject incor-\nrectly believes \nthat he or she is receiving a \nreal treatment and reports an \nimprovement in symptoms. The \nHawthorne effect occurs when \ntreated subjects somehow re-\nspond differently, simply because \nthey are part of an experiment. \n(This phenomenon was called \nthe “Hawthorne effect” because \nit was first observed in a study \nof factory workers at Western \nElectric’s Hawthorne plant.) An \nexperimenter effect (sometimes \ncalled a Rosenthal effect) occurs \nwhen the researcher or experi-\nmenter unintentionally influences \nsubjects through such factors as \nfacial expression, tone of voice, \nor attitude.","page_start":44,"page_end":44,"token_count":226,"section_type":"other","chapter_number":2,"chapter_title":"EXPLORING DATA WITH TABLES AND GRAPHS","chunk_index":57}
{"chunk_id":"2889cdbda5407dba","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"1-3 Collecting Sample Data \n27\nMultistage Sampling Professional pollsters and government researchers often  collect \ndata by using some combination of the preceding sampling methods. In a  multistage \nsample design, pollsters select a sample in different stages, and each stage might use \ndifferent methods of sampling, as in the following example.\nMAIN\nCENTER\nHeritage\nSchool\nPark St.\nNorth St.\n1st St.\n2nd St.\n3rd St.\n82nd St.\n52nd St.\n36th St.\n43rd St.\nA St.\nB St.\nC St.\nD St.\nE St.\nF St.\nWay St.\n4th St.\n5th St.\nMLK PKWY\n555-867-5309\n555-606-0842\n555-777-9311\nSimple Random Sample\nA sample of n subjects is selected \nso that every sample of the same \nsize n has the same chance of \nbeing selected.\nStratiﬁed Sample\nSubdivide population into strata \n(groups) with the same \ncharacteristics, then randomly \nsample within those strata.\nCluster Sample\nPartition the population in clusters \n(groups), then randomly select \nsome clusters, then select all \nmembers of the selected clusters.\nSystematic Sample\nSelect every kth subject.\nConvenience Sample\nUse data that are very easy to get.\nMen\nWomen\n3rd\n6th\nFIGURE 1-3 Common Sampling Methods\nEXAMPLE 3  Multistage Sample Design\nThe U.S. government’s unemployment statistics are based on surveys of house-\nholds. It is impractical to personally survey each household in a simple random \nsample, because they would be scattered all over the country. Instead, the U.S. \n Census Bureau and the Bureau of Labor Statistics collaborate to conduct a survey \ncalled the Current Population Survey. A recent survey incorporates a multistage \nsample design, roughly following these steps:\n1. The entire United States is partitioned into 2,007 diﬀerent regions called \nprimary sampling units (PSUs). The primary sampling units are metropolitan \nareas, large counties, or combinations of smaller counties. The 2,007 primary \nsampling units are then grouped into 824 diﬀerent strata.\nValue of a  \nStatistical Life\nThe value of a \nstatistical life \n(VSL) is a mea-\nsure routinely \ncalculated and \nused for making \ndecisions in \nfields such as \nmedicine, insurance, environ-\nmental health, and transportation \nsafety. As of this writing, the \nvalue of a statistical life is  \n$6.9 million.\nMany people oppose the con-\ncept of putting a value on a hu-\nman life, but the word statistical \nin the “value of a statistical life” \nis used to ensure that we don’t \nequate it with the true worth \nof a human life. Some people \nlegitimately argue that every life \nis priceless, but others argue that ","page_start":45,"page_end":45,"token_count":626,"section_type":"other","chapter_number":2,"chapter_title":"EXPLORING DATA WITH TABLES AND GRAPHS","chunk_index":58}
{"chunk_id":"0b2524ccb7a06a68","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"safety. As of this writing, the \nvalue of a statistical life is  \n$6.9 million.\nMany people oppose the con-\ncept of putting a value on a hu-\nman life, but the word statistical \nin the “value of a statistical life” \nis used to ensure that we don’t \nequate it with the true worth \nof a human life. Some people \nlegitimately argue that every life \nis priceless, but others argue that \nthere are conditions in which it \nis impossible or impractical to \nsave every life, so a value must \nbe somehow assigned to a hu-\nman life in order that sound and \nrational decisions can be made. \nNot far from the author’s home, a \nparkway was modified at a cost \nof about $3 million to improve \nsafety at a location where car \noccupants had previously died \nin traffic crashes. In the cost-\nbenefit analysis that led to this \nimprovement in safety, the value \nof a statistical life was surely \nconsidered.\ncontinued","page_start":45,"page_end":45,"token_count":219,"section_type":"other","chapter_number":2,"chapter_title":"EXPLORING DATA WITH TABLES AND GRAPHS","chunk_index":59}
{"chunk_id":"a70226f67d1a856c","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"28 \nCHAPTER 1 Introduction to Statistics\nPART 2\n  Beyond the Basics of Design of \nExperiments and Collecting Sample Data\nObservational Studies In Part 2 of this section, we discuss different types of ob-\nservational studies and different ways of designing experiments. The following defi-\nnitions identify the standard terminology used in professional journals for different \ntypes of observational studies. These definitions are illustrated in Figure 1-4.\n \n2. In each of the 824 diﬀerent strata, one of the primary sampling units is \nselected so that the probability of selection is proportional to the size of the \npopulation in each primary sampling unit.\n \n3. In each of the 824 selected primary sampling units, census data are used to \nidentify a census enumeration district, with each containing about 300 house-\nholds. Enumeration districts are then randomly selected.\n \n4. In each of the selected enumeration districts, clusters of about four addresses \n(contiguous whenever possible) are randomly selected.\n \n5. A responsible person in each of the 60,000 selected households is interviewed \nabout the employment status of each household member of age 16 or older.\nThis multistage sample design includes a combination of random, stratified, and \ncluster sampling at different stages. The end result is a very complicated sampling \ndesign, but it is much more practical, less expensive, and faster than using a simpler \ndesign, such as a simple random sample.\nWhen\nare the\nobservations\nmade?\nObservational Study:\nObserve and measure,\nbut do not modify.\nOne point in time\nRetrospective\n(or case-control) study:\nGo back in time to \ncollect data over some \npast period.\nCross-sectional \nstudy:\nData are\nmeasured at one \npoint in time.\nProspective\n(or longitudinal or cohort) study:\nGo forward in time and observe\ngroups sharing common factors,\nsuch as smokers and nonsmokers.\nForward in time\nPast period of time\nFIGURE 1-4 Types of Observational Studies\nDEFINITIONS\nIn a cross-sectional study, data are observed, measured, and collected at one \npoint in time, not over a period of time.\nIn a retrospective (or case-control) study, data are collected from a past time pe-\nriod by going back in time (through examination of records, interviews, and so on).\nIn a prospective (or longitudinal or cohort) study, data are collected in the future \nfrom groups that share common factors (such groups are called cohorts).\n","page_start":46,"page_end":46,"token_count":523,"section_type":"other","chapter_number":2,"chapter_title":"EXPLORING DATA WITH TABLES AND GRAPHS","chunk_index":60}
{"chunk_id":"8ccd1c6d9ba6ae4e","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"1-3 Collecting Sample Data \n29\nExperiments In a study, confounding occurs when we can see some effect, but \nwe can’t identify the specific factor that caused it, as in the ice cream and drowning \nobservational study in Example 2. See also the bad experimental design illustrated \nin  Figure 1-5(a), where confounding can occur when the treatment group of women \nshows strong positive results. Because the treatment group consists of women and the \nplacebo group consists of men, confounding has occurred because we cannot deter-\nmine whether the treatment or the gender of the subjects caused the positive results. \nThe Salk vaccine experiment in Example 1 illustrates one method for controlling the \neffect of the treatment variable: Use a completely randomized experimental design, \nwhereby randomness is used to assign subjects to the treatment group and the placebo \ngroup. A completely randomized experimental design is one of the following methods \nthat are used to control effects of variables.\nCompletely Randomized Experimental Design: Assign subjects to different treat-\nment groups through a process of random selection, as illustrated in Figure 1-5(b).\nTreatment Group: Women\nBad experimental design:\nTreat all women subjects\nand give the men a placebo.\n(Problem: We don’t know if\neﬀects are due to sex or\nto treatment.)\nCompletely randomized\nexperimental design:\nUse randomness to\ndetermine who gets the\ntreatment and who gets\nthe placebo.\n  \nTreat all women subjects.\nPlacebo Group: Men\n  \nGive all men a placebo\nTreat these  randomly\nselected subjects and give\nthe others a placebo.\n(a)\n(b)\nBefore\nAfter\nAlex\nBob\nChris\nBlock of Women\nRandomized block design:\n1. Form a block of women\n \nand a block of men.\n2. Within each block,\n \nrandomly select subjects\n \nto be treated.\nMatched pairs design:\nGet measurements from the\nsame subjects before and after\nsome treatment.\n  \nTreat randomly selected\nwomen.\nBlock of Men\n  \nTreat randomly selected men.\n(c)\n(d)\nFIGURE 1-5 Designs of Experiments\n","page_start":47,"page_end":47,"token_count":444,"section_type":"other","chapter_number":2,"chapter_title":"EXPLORING DATA WITH TABLES AND GRAPHS","chunk_index":61}
{"chunk_id":"686d01a644e63fcd","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"30 \nCHAPTER 1 Introduction to Statistics\nExperimental design requires much more thought and care than we can describe \nin this relatively brief section. Taking a complete course in the design of experiments \nis a good start in learning so much more about this important topic.\nRandomized Block Design: See Figure 1-5c. A block is a group of subjects that are \nsimilar, but blocks differ in ways that might affect the outcome of the experiment. Use \nthe following procedure, as illustrated in Figure 1-5(c):\n1. Form blocks (or groups) of subjects with similar characteristics.\n2. Randomly assign treatments to the subjects within each block.\nFor example, in designing an experiment to test the effectiveness of aspirin treatments \non heart disease, we might form a block of men and a block of women, because it is \nknown that the hearts of men and women can behave differently. By controlling for \ngender, this randomized block design eliminates gender as a possible source of con-\nfounding.\nA randomized block design uses the same basic idea as stratified sampling, but \nrandomized block designs are used when designing experiments, whereas stratified \nsampling is used for surveys.\nMatched Pairs Design: Compare two treatment groups (such as treatment and pla-\ncebo) by using subjects matched in pairs that are somehow related or have similar \ncharacteristics, as in the following cases.\n \n■Before/After: Matched pairs might consist of measurements from subjects before \nand after some treatment, as illustrated in Figure 1-5(d) on the preceding page. \nEach subject yields a “before” measurement and an “after” measurement, and \neach before/after pair of measurements is a matched pair.\n \n■Twins: A test of Crest toothpaste used matched pairs of twins, where one twin \nused Crest and the other used another toothpaste.\nRigorously Controlled Design: Carefully assign subjects to different treatment \ngroups, so that those given each treatment are similar in the ways that are important to \nthe experiment. This can be extremely difficult to implement, and often we can never \nbe sure that we have accounted for all of the relevant factors.\nSampling Errors\nIn statistics, you could use a good sampling method and do everything correctly, and \nyet it is possible to get wrong results. No matter how well you plan and execute the \nsample collection process, there is likely to be some error in the results. The different \ntypes of sampling errors are described here.\nDEFINITIONS\nA sampling error (or random sampling error) occurs when the sample has been \nselected with a random method, but there is a discrepancy between a sample \nresult and the true population result; such an error results from chance sample \nfluctuations.\nA nonsampling error is the result of human error, including such factors as wrong \ndata entries, computing errors, questions with biased wording, false data provided \nby respondents, forming biased conclusions, or applying statistical methods that \nare not appropriate for the circumstances.\nA nonrandom sampling error is the result of using a sampling method that is not \nrandom, such as using a convenience sample or a voluntary response sample.\n","page_start":48,"page_end":48,"token_count":646,"section_type":"other","chapter_number":2,"chapter_title":"EXPLORING DATA WITH TABLES AND GRAPHS","chunk_index":62}
{"chunk_id":"20da42875f2879ea","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"1-3 Collecting Sample Data \n31\nStatistical Literacy and Critical Thinking\n1. Back Pain Treatment In a study designed to test the effectiveness of paracetamol (also \nknown as acetaminophen) as a treatment for lower back pain, 1643 patients were randomly \nassigned to one of three groups: (1) the 547 subjects in the placebo group were given pills \ncontaining no medication; (2) 550 subjects were in a group given pills with paracetamol taken \nat regular intervals; (3) 546 subjects were in a group given pills with paracetamol to be taken \nwhen needed for pain relief. (See “Efficacy of Paracetamol for Acute Low-Back Pain,” by \n Williams et al., Lancet.) Is this study an experiment or an observational study? Explain.\n2. Blinding What does it mean when we say that the study cited in Exercise 1 was “double-blind”?\n3. Replication In what specific way was replication applied in the study cited in Exercise 1?\n4. Sampling Method The patients included in the study cited in Exercise 1 were those “who \nsought care for low-back pain directly or in response to a community advertisement.” What \ntype of sampling best describes the way in which the 1634 subjects were chosen: simple ran-\ndom sample, systematic sample, convenience sample, stratified sample, cluster sample? Does \nthe method of sampling appear to adversely affect the quality of the results?\nExercises 5–8 refer to the study of an association between which ear is used for cell phone \ncalls and whether the subject is left-handed or right-handed. The study is reported in “Hemi-\nspheric Dominance and Cell Phone Use,” by Seidman et al., JAMA Otolaryngology—Head \n& Neck Surgery, Vol. 139, No. 5. The study began with a survey e-mailed to 5000 people \nbelonging to an otology online group, and 717 surveys were returned. (Otology relates to the \near and hearing.)\n5. Sampling Method What type of sampling best describes the way in which the 717 subjects \nwere chosen: simple random sample, systematic sample, convenience sample, stratified sample, \ncluster sample? Does the method of sampling appear to adversely affect the quality of the results?\n6. Experiment or Observational Study Is the study an experiment or an observational \nstudy? Explain.\n7. Response Rate What percent of the 5000 surveys were returned? Does that response rate \nappear to be low? In general, what is a problem with a very low response rate?\n8. Sampling Method Assume that the population consists of all students currently in your \nstatistics class. Describe how to obtain a sample of six students so that the result is a sample of \nthe given type.\na. Simple random sample\nb. Systematic sample\nc. Stratified sample\nd. Cluster sample\nIn Exercises 9–20, identify which of these types of sampling is used: random, systematic, \nconvenience, stratified, or cluster.","page_start":49,"page_end":49,"token_count":648,"section_type":"other","chapter_number":2,"chapter_title":"EXPLORING DATA WITH TABLES AND GRAPHS","chunk_index":63}
{"chunk_id":"46f4351553cdb050","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"8. Sampling Method Assume that the population consists of all students currently in your \nstatistics class. Describe how to obtain a sample of six students so that the result is a sample of \nthe given type.\na. Simple random sample\nb. Systematic sample\nc. Stratified sample\nd. Cluster sample\nIn Exercises 9–20, identify which of these types of sampling is used: random, systematic, \nconvenience, stratified, or cluster.\n9. Cormorant Density Cormorant bird population densities were studied by using the “line \ntransect method” with aircraft observers flying along the shoreline of Lake Huron and collecting \nsample data at intervals of every 20 km (based on data from Journal of Great Lakes Research).\n1-3 Basic Skills and Concepts","page_start":49,"page_end":49,"token_count":160,"section_type":"other","chapter_number":2,"chapter_title":"EXPLORING DATA WITH TABLES AND GRAPHS","chunk_index":64}
{"chunk_id":"a089828e88fc400c","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"32 \nCHAPTER 1 Introduction to Statistics\n10. Sexuality of Women The sexuality of women was discussed in Shere Hite’s book Women \nand Love: A Cultural Revolution. Her conclusions were based on sample data that consisted of \n4500 mailed responses from 100,000 questionnaires that were sent to women.\n11. Acupuncture Study In a study of treatments for back pain, 641 subjects were randomly \nassigned to the four different treatment groups of individualized acupuncture, standardized \nacupuncture, simulated acupuncture, and usual care (based on data from “A Randomized Trial \nComparing Acupuncture, Simulated Acupuncture, and Usual Care for Chronic Low Back \nPain,” by Cherkin et al., Archives of Internal Medicine, Vol. 169, No. 9).\n12. Class Survey A professor surveys her statistics class by identifying groups of males and \nfemales, then randomly selecting five students from each of those two groups.\n13. Class Survey A professor conducts a survey by randomly selecting three different classes \nand surveying all of the students as they left those classes.\n14. Exercise Program In a study designed to test the effectiveness of exercise in lowering \nblood pressure, 532 subjects were randomly assigned to these two different groups: (1) group \ngiven regular exercise programs; (2) group given no exercise programs.\n15. Hospital Survey A researcher collects sample data by randomly selecting 20 hospital \n employees from each of the categories of physician, nurse, and administrator.\n16. Deforestation Rates Satellites are used to collect sample data for estimating deforesta-\ntion rates. The Forest Resources Assessment of the United Nations (UN) Food and Agriculture \nOrganization uses a method of selecting a sample of a 10-km-wide square at every 1° intersec-\ntion of latitude and longitude.\n17. Testing Lipitor In a clinical trial of the cholesterol drug Lipitor (atorvastatin), subjects \nwere partitioned into groups given a placebo or Lipitor doses of 10 mg, 20 mg, 40 mg, or \n80 mg. The subjects were randomly assigned to the different treatment groups (based on data \nfrom Pfizer, Inc.).\n18. Blood Drives A researcher for the American Red Cross randomly selected five different \nblood donor sites and then interviewed all blood donors as they left the sites.\n19. Smoking Prevalence A medical student collects sample data on the prevalence of smok-\ning among adults by surveying all of the patients she encounters in the clinic where she is doing \nher residency.\n20. Health Survey The Texas Health and Human Services Commission obtains an alphabeti-\ncal listing of all 20,126,759 adults and constructs a sample by selecting every 10,000th name \non that list.\nCritical Thinking: What’s Wrong? In Exercises 21–28, determine whether the study is \nan experiment or an observational study, and then identify a major problem with the study.\n21. Online Medical Information In a survey conducted by USA Today, 1072 Internet users \nchose to respond to this question posted on the USA Today electronic edition: “How often do \nyou seek medical information online?” 38% of the respondents said “frequently.”","page_start":50,"page_end":50,"token_count":658,"section_type":"other","chapter_number":2,"chapter_title":"EXPLORING DATA WITH TABLES AND GRAPHS","chunk_index":65}
{"chunk_id":"7d558a1c3cc50482","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"on that list.\nCritical Thinking: What’s Wrong? In Exercises 21–28, determine whether the study is \nan experiment or an observational study, and then identify a major problem with the study.\n21. Online Medical Information In a survey conducted by USA Today, 1072 Internet users \nchose to respond to this question posted on the USA Today electronic edition: “How often do \nyou seek medical information online?” 38% of the respondents said “frequently.”\n22. Physicians’ Health Study The Physicians’ Health Study involved 22,071 male physi-\ncians. Based on random selections, 11,037 of them were treated with aspirin and the other \n11,034 were given placebos. The study was stopped early because it became clear that aspirin \nreduced the risk of myocardial infarctions by a substantial amount.\n23. Drinking and Driving A researcher for a consortium of insurance companies plans to \ntest for the effects of drinking on driving ability by randomly selecting 1000 drivers and then \nrandomly assigning them to two groups: One group of 500 will drive in New York City after no \nalcohol consumption, and the second group will drive in New York City after consuming three \nshots of Jim Beam bourbon whiskey.","page_start":50,"page_end":50,"token_count":258,"section_type":"other","chapter_number":2,"chapter_title":"EXPLORING DATA WITH TABLES AND GRAPHS","chunk_index":66}
{"chunk_id":"03981e86ffd09ab1","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"1-3 Collecting Sample Data \n33\n24. Blood Pressure A medical researcher tested for a difference in systolic blood pressure \nlevels between male and female students who are 20 years of age. She randomly selected four \nmales and four females for her study.\n25. Salt Deprivation In a program designed to investigate the effects of salt deprivation in \ndiets, the original plan was to use a sample of 500 adults randomly selected throughout the \ncountry. The program managers know that they would get a biased sample if they limit their \nstudy to adults in New York City, so they planned to compensate for that bias by using a larger \nsample of 2000 adults in New York City.\n26. Atkins Weight Loss Program An independent researcher tested the effectiveness of the \nAtkins weight loss program by randomly selecting 1000 subjects using that program. Each of \nthe subjects was called to report his or her weight before the diet and after the diet.\n27. Crime Research A researcher has created a brief survey to be given to 2000 adults ran-\ndomly selected from the U.S. population. Here are her first two questions: (1) Have you ever \nbeen the victim of a felony crime? (2) Have you ever been convicted of a felony?\n28. Medications The Pharmaceutical Research and Manufacturers of America wants infor-\nmation about the consumption of various medications. An independent researcher conducts a \nsurvey by mailing 10,000 questionnaires to randomly selected adults in the United States, and \nshe receives 152 responses.\nIn Exercises 29–32, indicate whether the observational study used is cross-sectional, \n retrospective, or prospective.\n29. Nurses’ Health Study II Phase II of the Nurses’ Health Study was started in 1989 with \n116,000 female registered nurses. The study is ongoing.\n30. Heart Health Study Samples of subjects with and without heart disease were selected, \nthen researchers looked back in time to determine whether they took aspirin on a regular basis.\n31. Marijuana Study Researchers from the National Institutes of Health want to determine the \ncurrent rates of marijuana consumption among adults living in states that have legalized the use \nof marijuana. They conduct a survey of 500 adults in those states.\n32. Framingham Heart Study The Framingham Heart Study was started in 1948 and is ongo-\ning. Its focus is on heart disease.\nIn Exercises 33–36, identify which of these designs is most appropriate for the given \nexperiment: completely randomized design, randomized block design, or matched pairs \ndesign.\n33. Lunesta Lunesta (eszopiclone) is a drug designed to treat insomnia. In a clinical trial of \nLunesta, amounts of sleep each night are measured before and after subjects have been treated \nwith the drug.\n34. Lipitor A clinical trial of Lipitor treatments is being planned to determine whether its \neffects on diastolic blood pressure are different for men and women.\n35. West Nile Vaccine Currently, there is no approved vaccine for the prevention of West Nile \nvirus infection. A clinical trial of a possible vaccine is being planned to include subjects treated \nwith the vaccine while other subjects are given a placebo.","page_start":51,"page_end":51,"token_count":653,"section_type":"other","chapter_number":2,"chapter_title":"EXPLORING DATA WITH TABLES AND GRAPHS","chunk_index":67}
{"chunk_id":"eb7d1a0223f4f38f","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"with the drug.\n34. Lipitor A clinical trial of Lipitor treatments is being planned to determine whether its \neffects on diastolic blood pressure are different for men and women.\n35. West Nile Vaccine Currently, there is no approved vaccine for the prevention of West Nile \nvirus infection. A clinical trial of a possible vaccine is being planned to include subjects treated \nwith the vaccine while other subjects are given a placebo.\n36. HIV Vaccine The HIV Trials Network is conducting a study to test the effectiveness of two \ndifferent experimental HIV vaccines. Subjects will consist of 80 pairs of twins. For each pair \nof twins, one of the subjects will be treated with the DNA vaccine and the other twin will be \ntreated with the adenoviral vector vaccine.\n1-3 Beyond the Basics","page_start":51,"page_end":51,"token_count":161,"section_type":"other","chapter_number":2,"chapter_title":"EXPLORING DATA WITH TABLES AND GRAPHS","chunk_index":68}
{"chunk_id":"4122b861d9438e6e","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"34 \nCHAPTER 1 Introduction to Statistics\n37. Sample Design Literacy In “Cardiovascular Effects of Intravenous Triiodothyronine in \nPatients Undergoing Coronary Artery Bypass Graft Surgery” (Journal of the American Medi-\ncal Association, Vol. 275, No. 9), the authors explain that patients were assigned to one of \nthree groups: (1) a group treated with triiodothyronine, (2) a group treated with normal saline \nbolus and dopamine, and (3) a placebo group given normal saline. The authors summarize the \nsample design as a “prospective, randomized, double-blind, placebo-controlled trial.” Describe \nthe meaning of each of those terms in the context of this study.\n38. Simple Random Sample vs. Random Sample Refer to the definition of simple random \nsample in this section and the accompanying definition of random sample enclosed within pa-\nrentheses. Determine whether each of the following is a simple random sample and a random \nsample.\na. A statistics class with 36 students is arranged so that there are 6 rows with 6 students in each \nrow, and the rows are numbered from 1 through 6. A die is rolled and a sample consists of all \nstudents in the row corresponding to the outcome of the die.\nb. For the same class described in part (a), the 36 student names are written on 36 individual \nindex cards. The cards are shuffled and six names are drawn from the top.\nc. For the same class described in part (a), the six youngest students are selected.\n1. Clinical Study When conducting a clinical study, it is common to maintain the privacy of \nsubjects by assigning them number codes that will be used instead of their actual names. Sev-\neral subjects are assigned these codes: 1, 2, 3, 5, 6, 9, 11, 13, 16, 20, 22, 26, 32, and 40. Does it \nmake sense to calculate the average (mean) of these numbers?\n2. Clinical Study Which of the following best describes the level of measurement of the data \nlisted in Exercise 1: nominal, ordinal, interval, ratio?\n3. Waist Data Set 1 “Body Data” includes measurements of waist circumferences. Are waist \ncircumferences values that are discrete or continuous?\n4. Waist Are the waist circumferences described in Exercise 3 quantitative data or categorical \ndata?\n5. Waist Which of the following best describes the level of measurement of the waist \n circumferences described in Exercise 3: nominal, ordinal, interval, ratio?\n6. Waist If you construct a sample by selecting every sixth waist circumference from those \nlisted in Data Set 1 “Body Data,” is the result a simple random sample of the listed waist \n circumferences?\n7. Gallup Poll In a recent Gallup poll, pollsters randomly selected adults and asked them \nwhether they smoke. Because the subjects agreed to respond, is the sample a voluntary re-\nsponse sample?\n8. Parameter and Statistic In a recent Gallup poll, pollsters randomly selected adults and ","page_start":52,"page_end":52,"token_count":651,"section_type":"other","chapter_number":2,"chapter_title":"EXPLORING DATA WITH TABLES AND GRAPHS","chunk_index":69}
{"chunk_id":"8bdd34f9169509cd","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"listed in Data Set 1 “Body Data,” is the result a simple random sample of the listed waist \n circumferences?\n7. Gallup Poll In a recent Gallup poll, pollsters randomly selected adults and asked them \nwhether they smoke. Because the subjects agreed to respond, is the sample a voluntary re-\nsponse sample?\n8. Parameter and Statistic In a recent Gallup poll, pollsters randomly selected adults and \nasked them whether they smoke. Among the adults who responded to the survey question, 21% \nsaid that they did smoke. Is that value of 21% an example of a statistic or a parameter?\n9. Observational Study or Experiment Are the data described in Exercise 8 the result of an \nobservational study or an experiment?\n10. Statistical Significance and Practical Significance True or false: If data lead to a con-\nclusion with statistical significance, then the results also have practical significance.\nChapter Quick Quiz","page_start":52,"page_end":52,"token_count":191,"section_type":"other","chapter_number":2,"chapter_title":"EXPLORING DATA WITH TABLES AND GRAPHS","chunk_index":70}
{"chunk_id":"bef5108b0b69ff8b","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"1. Hospitals Currently, there are 5723 registered hospitals in the United States.\na. Are the numbers of hospitals in different states discrete or continuous?\nb. What is the level of measurement for the numbers of hospitals in different years? (nominal, \nordinal, interval, ratio)\nc. If a survey is conducted by randomly selecting 10 patients in every hospital, what type of \nsampling is used? (random, systematic, convenience, stratified, cluster)\nd. If a survey is conducted by randomly selecting 20 hospitals and interviewing all of the mem-\nbers of each board of directors, what type of sampling is used? (random, systematic, conve-\nnience, stratified, cluster)\ne. What is wrong with surveying patient satisfaction by mailing questionnaires to 10,000 ran-\ndomly selected patients?\n2. What’s Wrong? A survey sponsored by the American Laser Centers included responses \nfrom 575 adults, and 24% of the respondents said that the face is their favorite body part (based \non data from USA Today). What is wrong with this survey?\n3. What’s Wrong? A survey included 2028 responses from Internet users who decided to \nrespond to a question posted by AOL. Here is the question: “How often do you drink soda?” \nAmong the respondents, 33% said that they drink soda almost every day. What is wrong with \nthis survey?\n4. Sampling Seventy-two percent of Americans squeeze their toothpaste tube from the top. \nThis and other not-so-serious findings are included in The First Really Important Survey of \nAmerican Habits. Those results are based on 7000 responses from the 25,000 questionnaires \nthat were mailed.\na. What is wrong with this survey?\nb. As stated, the value of 72% refers to all Americans, so is that 72% a statistic or a parameter? \nExplain.\nc. Does the survey constitute an observational study or an experiment?\n5. Percentages\na. The labels on U-Turn protein energy bars include the statement that these bars contain \n“125% less fat than the leading chocolate candy brands” (based on data from Consumer \nReports magazine). What is wrong with that claim?\nb. In a Pew Research Center poll on driving, 58% of the 1182 respondents said that they like to \ndrive. What is the actual number of respondents who said that they like to drive?\nc. In a Pew Research Center poll on driving, 331 of the 1182 respondents said that driving is a \nchore. What percentage of respondents said that driving is a chore?\n6. Simple Random Sample Which of the following is>are simple random samples?\na. As Lipitor pills are being manufactured, a quality control plan is to select every 500th pill \nand test it to confirm that it contains 80 mg of atorvastatin.\nb. To test for a gender difference in the way that men and women make online purchases, \n Gallup surveys 500 randomly selected men and 500 randomly selected women.\nc. A list of all 10,877 adults in Trinity County, California, is obtained; the list is numbered from ","page_start":53,"page_end":53,"token_count":661,"section_type":"other","chapter_number":2,"chapter_title":"EXPLORING DATA WITH TABLES AND GRAPHS","chunk_index":71}
{"chunk_id":"6a485e72a7e11104","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"and test it to confirm that it contains 80 mg of atorvastatin.\nb. To test for a gender difference in the way that men and women make online purchases, \n Gallup surveys 500 randomly selected men and 500 randomly selected women.\nc. A list of all 10,877 adults in Trinity County, California, is obtained; the list is numbered from \n1 to 10,877; and then a computer is used to randomly generate 250 different numbers between \n1 and 10,877. The sample consists of the adults corresponding to the selected numbers.\nReview Exercises\nCHAPTER 1 Review Exercises \n35","page_start":53,"page_end":53,"token_count":129,"section_type":"other","chapter_number":2,"chapter_title":"EXPLORING DATA WITH TABLES AND GRAPHS","chunk_index":72}
{"chunk_id":"a01a696f2151ca37","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"36 \nCHAPTER 1 Introduction to Statistics\n7. Statistical Significance and Practical Significance The Gengene Research Group has \ndeveloped a procedure designed to increase the likelihood that a baby will be born a girl. In a \nclinical trial of their procedure, 112 girls were born to 200 different couples. If the method has \nno effect, there is about a 4% chance that such extreme results would occur. Does the procedure \nappear to have statistical significance? Does the procedure appear to have practical signifi-\ncance?\n8. Marijuana Survey In a recent Pew poll of 1500 adults, 52% of the respondents said that the \nuse of marijuana should not be made legal. In the same poll, 23% of the respondents said that \nthe use of marijuana for medical purposes should not be legal.\na. The sample of 1500 adults was selected from the population of all adults in the United \nStates. The method used to select the sample was equivalent to placing the names of all adults \nin a giant bowl, mixing the names, and then drawing 1500 names. What type of sampling is \nthis? (random, systematic, convenience, stratified, cluster)\nb. If the sampling method consisted of a random selection of 30 adults from each of the 50 states, \nwhat type of sampling would this be? (random, systematic, convenience, stratified, cluster)\nc. What is the level of measurement of the responses of yes, no, don’t know, and refused to \nrespond?\nd. Is the given value of 52% a statistic or a parameter? Why?\ne. What would be wrong with conducting the survey by mailing a questionnaire that respon-\ndents could complete and mail back?\n9. Marijuana Survey Identify the type of sampling (random, systematic, convenience, strati-\nfied, cluster) used when a sample of the 1500 survey responses is obtained as described. Then \ndetermine whether the sampling scheme is likely to result in a sample that is representative of \nthe population of all adults.\na. A complete list of all 241,472,385 adults in the United States is compiled, and every \n150,000th name is selected until the sample size of 1500 is reached.\nb. A complete list of all 241,472,385 adults in the United States is compiled, and 1500 adults \nare randomly selected from that list.\nc. The United States is partitioned into regions with 100 adults in each region. Then 15 of those \nregions are randomly selected, and all 100 people in each of those regions are surveyed.\nd. The United States is partitioned into 150 regions with approximately the same number of \nadults in each region; then 10 people are randomly selected from each of the 150 regions.\ne. A survey is mailed to 10,000 randomly selected adults, and the 1500 responses are used.\n10. Marijuana Survey Exercise 8 referred to a Pew poll of 1500 adults, and 52% of the \n respondents said that the use of marijuana should not be made legal.","page_start":54,"page_end":54,"token_count":647,"section_type":"other","chapter_number":2,"chapter_title":"EXPLORING DATA WITH TABLES AND GRAPHS","chunk_index":73}
{"chunk_id":"45d62e9abd9daa0d","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"adults in each region; then 10 people are randomly selected from each of the 150 regions.\ne. A survey is mailed to 10,000 randomly selected adults, and the 1500 responses are used.\n10. Marijuana Survey Exercise 8 referred to a Pew poll of 1500 adults, and 52% of the \n respondents said that the use of marijuana should not be made legal.\na. Among the 1500 adults who responded, what is the number of respondents who said that the \nuse of marijuana should not be made legal?\nb. In the same poll of 1500 adults, 345 of the respondents said that the use of marijuana for \nmedical purposes should not be legal. What is the percentage of respondents who said that the \nuse of marijuana for medical purposes should not be legal?\nc. In this survey of 1500 adults, 727 are men and 773 are women. Find the percentage of \n respondents who are men, and then find the percentage of respondents who are women.\nd. Does the difference between the two percentages from part (c) appear to have statistical \nsignificance?\ne. Does the difference between the two percentages from part (c) appear to have practical \n significance?","page_start":54,"page_end":54,"token_count":253,"section_type":"other","chapter_number":2,"chapter_title":"EXPLORING DATA WITH TABLES AND GRAPHS","chunk_index":74}
{"chunk_id":"a6db5b02e2e032a8","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"For Chapter 2 through Chapter 14, the Cumulative Review Exercises include topics from \npreceding chapters. For this chapter, we present a few calculator warm-up exercises, with \nexpressions similar to those found throughout this book. Use your calculator to find the \nindicated values.\n1. Birth Weights Listed below are the weights (grams) of newborn babies from Albany Medi-\ncal Center Hospital. What value is obtained when those weights are added and the total is di-\nvided by the number of weights? (This result, called the mean, is discussed in Chapter 3.) What \nis notable about these values, and what does it tell us about how the weights were measured?\n3600 1700 4000 3900 3100 3800\n2200 3000\n2. Six Children Jule Cole is a founder of Mabel’s Labels, and she is the mother of six chil-\ndren. The probability that six randomly selected children are all girls is found by evaluating \n0.56. Find that value.\n3. Tallest Person Robert Wadlow (1918–1940) is the tallest known person to have lived. The \nexpression below converts his height of 272 cm to a standardized score. Find this value and \nround the result to two decimal places. Such standardized scores are considered to be signifi-\ncantly high if they are greater than 2 or 3. Is the result significantly high?\n272 - 176\n6\n4. Body Temperature The given expression is used for determining the likelihood that the av-\nerage (mean) human body temperature is different from the value of 98.6°F that is commonly \nused. Find the given value and round the result to two decimal places.\n98.2 - 98.6\n0.62\n2106\n5. Determining Sample Size The given expression is used to determine the size of the sam-\nple necessary to estimate the proportion of college students who have the profound wisdom to \ntake a statistics course. Find the value and round the result to the nearest whole number.\n1.962 # 0.25\n0.032\n6. Standard Deviation One way to get a very rough approximation of the value of a standard \ndeviation of sample data is to find the range, then divide it by 4. The range is the difference be-\ntween the highest sample value and the lowest sample value. In using this approach, what value \nis obtained from the sample data listed in Exercise 1 “Birth Weights”?\n7. Standard Deviation The standard deviation is an extremely important concept introduced \nin Chapter 3. Using the sample data from Exercise 1 “Birth Weights,” part of the calculation of \nthe standard deviation is shown in the expression below. Evaluate this expression. (Fortunately, \ncalculators and software are designed to automatically execute such expressions, so our future \nwork with standard deviations will not be burdened with cumbersome calculations.)\n13600 - 3162.52 2\n7\n8. Standard Deviation The given expression is used to compute the standard deviation of \nthree randomly selected body temperatures. Perform the calculation and round the result to two \ndecimal places.\nB","page_start":55,"page_end":55,"token_count":662,"section_type":"other","chapter_number":2,"chapter_title":"EXPLORING DATA WITH TABLES AND GRAPHS","chunk_index":75}
{"chunk_id":"7514dd2f6c727dfb","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"the standard deviation is shown in the expression below. Evaluate this expression. (Fortunately, \ncalculators and software are designed to automatically execute such expressions, so our future \nwork with standard deviations will not be burdened with cumbersome calculations.)\n13600 - 3162.52 2\n7\n8. Standard Deviation The given expression is used to compute the standard deviation of \nthree randomly selected body temperatures. Perform the calculation and round the result to two \ndecimal places.\nB\n198.4 - 98.62 2 + 198.6 - 98.62 2 + 198.8 - 98.62 2\n3 - 1\nCumulative Review Exercises\nCHAPTER 1 Cumulative Review Exercises \n37","page_start":55,"page_end":55,"token_count":152,"section_type":"other","chapter_number":2,"chapter_title":"EXPLORING DATA WITH TABLES AND GRAPHS","chunk_index":76}
{"chunk_id":"e519f33b4a3127a6","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"38 \nCHAPTER 1 Introduction to Statistics\nScientific Notation. In Exercises 9–12, the given expressions are designed to yield re-\nsults expressed in a form of scientific notation. For example, the calculator-displayed re-\nsult of 1.23E5 can be expressed as 123,000, and the result of 1.23E-4 can be expressed as \n0.000123. Perform the indicated operation and express the result as an ordinary number \nthat is not in scientific notation.\n9. 0.48  10. 911  11. 614  12. 0.312\nTechnology Project\nMissing Data The focus of this project is to download a data set and manipulate it to work \naround missing data.\na. First, download Data Set 2 “Body Temperatures” in Appendix B from www.TriolaStats.com. \nChoose the download format that matches your technology. (If you have no preferred technol-\nogy, you can download a free copy of Statdisk (from www.statdisk.org), which is designed for \nthis book and contains all Appendix B data sets.)\nb. Some statistical procedures, such as those involved with correlation and regression (dis-\ncussed in later chapters) require data that consist of matched pairs of values, and those proce-\ndures ignore pairs in which at least one of the data values in a matched pair is missing. Assume \nthat we want to conduct analyses for correlation and regression on the last two columns of \ndata in Data Set 2: body temperatures measured at 8 AM on day 2 and again at 12 AM on day \n2. For those last two columns, identify the rows with at least one missing value. Note that in \nsome technologies, such as TI-83>84 Plus calculators, missing data must be represented by a \nconstant such as -9 or 999.\nc. Here are two different strategies for reconfiguring the data set to work around the missing \ndata in the last two columns (assuming that we need matched pairs of data with no missing \nvalues):\ni. Manual Deletion Highlight rows with at least one missing value in the last two columns, \nthen delete those rows. This can be tedious if there are many rows with missing data and those \nrows are interspersed throughout instead of being adjacent rows.\nii. Sort Most technologies have a Sort feature that allows you to rearrange all rows using one \nparticular column as the basis for sorting (TI-83>84 Plus calculators do not have this type of sort \nfeature). The result is that all rows remain the same but they are in a different order. First use \nthe technology’s Sort feature to rearrange all rows using the “8 AM day 2” column as the basis \nfor sorting (so that all missing values in the “8 AM day 2” column are at the beginning); then \nhighlight and delete all of those rows with missing values in the “8 AM day 2” column. Next, \nuse the technology’s Sort feature to rearrange all rows using the “12 AM day 2” column as the ","page_start":56,"page_end":56,"token_count":653,"section_type":"other","chapter_number":2,"chapter_title":"EXPLORING DATA WITH TABLES AND GRAPHS","chunk_index":77}
{"chunk_id":"f1af95acb679bdb0","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"the technology’s Sort feature to rearrange all rows using the “8 AM day 2” column as the basis \nfor sorting (so that all missing values in the “8 AM day 2” column are at the beginning); then \nhighlight and delete all of those rows with missing values in the “8 AM day 2” column. Next, \nuse the technology’s Sort feature to rearrange all rows using the “12 AM day 2” column as the \nbasis for sorting (so that all missing values in the “12 AM day 2” column are at the beginning); \nthen highlight and delete all of those rows with missing values in the “12 AM day 2” column. \nThe remaining rows will include matched pairs of body temperatures, and those rows will be \nsuitable for analyses such as correlation and regression. Print the resulting reconfigured data set.","page_start":56,"page_end":56,"token_count":180,"section_type":"other","chapter_number":2,"chapter_title":"EXPLORING DATA WITH TABLES AND GRAPHS","chunk_index":78}
{"chunk_id":"8c7d4f5634a23aa7","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"Cooperative Group Activities\n1. In-class activity Working in groups of three or four, design an experiment to determine \nwhether pulse rates of college students are the same while the students are standing and sitting. \nConduct the experiment and collect the data. Save the data so that they can be analyzed with \nmethods presented in the following chapters.\n2. In-class activity Working in groups of three or four, construct a brief survey that includes \nonly a few questions that can be quickly asked. Include some objective questions along with \nsome that are biased, such as the first question below.\n•  Should your college force all students to pay a $100 activity fee?\n•  Should your college fund activities by collecting a $100 fee?\n Conduct the survey and try to detect the effect that the biased wording has on the  responses.\n3. In-class activity Identify problems with a mailing from Consumer Reports magazine that \nincluded an annual questionnaire about cars and other consumer products. Also included were \na request for a voluntary contribution of money and a voting ballot for the board of directors. \nResponses were to be mailed back in envelopes that required postage stamps.\n4. Out-of-class activity Find a report of a survey that used a voluntary response sample. De-\nscribe how it is quite possible that the results do not accurately reflect the population.\n5. Out-of-class activity Find a professional journal with an article that includes a statistical \nanalysis of an experiment. Describe and comment on the design of the experiment. Identify \none particular issue addressed by the study, and determine whether the results were found to \nbe statistically significant. Determine whether those same results have practical significance.\nFROM DATA TO DECISION\nCritical Thinking:  \nDo Male Symphony Conductors Really Live Longer?\nSeveral media reports made the interesting observation that \nmale symphony conductors live longer than other males. \nJohn Amaral wrote in Awaken that orchestra conductors \n“live longer than almost any other group of people by three \nto seven years.” Robert Levine wrote in Polyphonic.org that \nthey live longer “because they stand up while working.” \nSome provided other explanations for this phenomenon, \noften referring to cardiovascular activity. But do male sym-\nphony conductors really live longer than other groups of \nmales? The Internet can be researched for possible answers. \nLet’s also consider the following.\nAnalysis\n1. Consider the statement that “male symphony conductors \nlive longer.” Identify the specific group that they supposedly \nlive longer than. Does that other group consist of males ran-\ndomly selected from the general population?\n2. It is reasonable to assume that males do not become sym-\nphony conductors until they have reached at least the age \nof 40 years. When comparing life spans of male conduc-\ntors, should we compare them to other males in the general \n population, or should we compare them to other males who \nlived until at least 40 years of age? Explain.\n3. Without any disabilities, males qualify for Medicare if ","page_start":57,"page_end":57,"token_count":653,"section_type":"other","chapter_number":2,"chapter_title":"EXPLORING DATA WITH TABLES AND GRAPHS","chunk_index":79}
{"chunk_id":"0cceff16bf119143","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"domly selected from the general population?\n2. It is reasonable to assume that males do not become sym-\nphony conductors until they have reached at least the age \nof 40 years. When comparing life spans of male conduc-\ntors, should we compare them to other males in the general \n population, or should we compare them to other males who \nlived until at least 40 years of age? Explain.\n3. Without any disabilities, males qualify for Medicare if \nthey are 65 or older and meet a few other requirements. If \nwe compare life spans of males on Medicare to life spans \nof males randomly selected from the general population, \nwhy would we find that males on Medicare have longer life \nspans?\n4. Explain in detail how to design a study for collecting data \nto determine whether it is misleading to state that male sym-\nphony conductors live longer. Should the study be an experi-\nment or an observational study?\nCHAPTER 1 Cooperative Group Activities \n39","page_start":57,"page_end":57,"token_count":202,"section_type":"other","chapter_number":2,"chapter_title":"EXPLORING DATA WITH TABLES AND GRAPHS","chunk_index":80}
{"chunk_id":"6f62fc361efc32b7","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"40\nFrequency Distributions \nfor Organizing and \nSummarizing Data\nHistograms\nGraphs That Enlighten \nand Graphs That \nDeceive\nScatterplots, \nCorrelation, and \nRegression\n2-1\n2-2\n2-3\n2-4\nDoes Exposure to Lead Affect IQ Scores?\nCHAPTER \nPROBLEM\nExploring Data with \nTables and Graphs\nData Set 8 “IQ and Lead” in Appendix B includes full IQ scores \nfrom three groups of children who lived near a lead smelter. \nThe children in Group 1 had low levels of measured lead in \ntheir blood (with blood levels less than 40 micrograms>100 mL \nin each of two years). Group 2 had medium levels of measured \nlead in their blood (with blood levels of at least  \n40 micrograms/100 mL in exactly one of two years). Group 3 \nhad high levels of measured lead in their blood (with blood lev-\nels of at least 40 micrograms>100 mL in each of two years).\nLet’s consider the measured full IQ scores from Group 1  \n(low lead level) and Group 3 (high lead level), as listed in \nTable 2-1. It is an exceptionally rare person who can look \nat both lists of IQ scores and form meaningful conclusions. \nAlmost all of us must work at describing, exploring, and \n2\n","page_start":58,"page_end":58,"token_count":294,"section_type":"other","chapter_number":2,"chapter_title":"EXPLORING DATA WITH TABLES AND GRAPHS","chunk_index":81}
{"chunk_id":"b9bc69224af0446d","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"comparing the two sets of data. In this chapter we pres-\nent methods that focus on summarizing the data and using \ngraphs that enable us to understand important characteris-\ntics of the data, especially the distribution of the data. These \nmethods will help us compare the two sets of data so that we \ncan determine whether the IQ scores of the low lead group \nare somehow different from the IQ scores of the high lead \ngroup. Such comparisons will be helpful as we try to address \nthis important and key issue: Does exposure to lead have an \neffect on IQ score?\nThis chapter and the following chapter focus on important characteristics of data, \nincluding the following:\nCharacteristics of Data\n1. Center: A representative value that shows us where the middle of the data set is \nlocated.\n2. Variation: A measure of the amount that the data values vary.\n3. Distribution: The nature or shape of the spread of the data over the range of values \n(such as bell-shaped).\n4. Outliers: Sample values that lie very far away from the vast majority of the other \nsample values. (Later, a more objective definition of “outlier” will be given.)\n5. Time: Any change in the characteristics of the data over time.\nThis chapter provides tools that enable us to gain insight into data by organizing, sum-\nmarizing, and representing them in ways that enable us to see important characteristics \nof the data. Here are the chapter objectives:\nFrequency Distributions for Organizing and Summarizing Data\n• Develop an ability to summarize data in the format of a frequency distribution and a \nrelative frequency distribution.\n• For a frequency distribution, identify values of class width, class midpoint, class lim-\nits, and class boundaries.\n2-1\nChapter Objectives \n41\nCHAPTER OBJECTIVES\n>>>\nTABLE 2-1 Full IQ Scores of the Low Lead Group and the High Lead Group\nLow Lead Level (Group 1)\n70\n85\n86\n76\n84\n96\n94\n56\n115\n97\n77\n128\n99\n80\n118\n86\n141\n88\n96\n96\n107\n86\n80\n107\n101\n91\n125\n96\n99\n99\n115\n106\n105\n96\n50\n99\n85\n88\n120\n93\n87\n98\n78\n100\n105\n87\n94\n89\n80\n111\n104\n85\n94\n75\n73\n76\n107\n88\n89\n96\n72\n97\n76\n107\n104\n85\n76\n95\n86\n89\n76\n96\n101\n108\n102\n77\n74\n92\nHigh Lead Level (Group 3)\n82\n93\n85\n75\n85\n80\n101\n89\n80\n94\n88\n104\n88\n88\n83\n104\n96\n76\n80\n79\n75\n","page_start":59,"page_end":59,"token_count":607,"section_type":"other","chapter_number":2,"chapter_title":"EXPLORING DATA WITH TABLES AND GRAPHS","chunk_index":82}
{"chunk_id":"d7fb69b9699c6bb1","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"42 \nCHAPTER 2 Exploring Data with Tables and Graphs\nHistograms\n• Develop the ability to picture the distribution of data in the format of a histogram or \nrelative frequency histogram.\n• Examine a histogram and identify common distributions, including a uniform distribu-\ntion and a normal distribution.\nGraphs That Enlighten and Graphs That Deceive\n• Develop an ability to graph data using a dotplot, stemplot, time-series graph, Pareto \nchart, pie chart, and frequency polygon.\n• Determine when a graph is deceptive through the use of a nonzero axis or a \n pictograph that uses an object of area or volume for one-dimensional data.\nScatterplots, Correlation, and Regression\n• Develop an ability to construct a scatterplot of paired data.\n• Analyze a scatterplot to determine whether there appears to be a correlation \n between two variables.\n2-2\n2-3\n2-4\nHistograms\n• Develop the ability to picture the distribution of data in the format of a histogram or \nrelative frequency histogram.\n• Examine a histogram and identify common distributions, including a uniform distribu-\ntion and a normal distribution.\nGraphs That Enlighten and Graphs That Deceive\n• Develop an ability to graph data using a dotplot, stemplot, time-series graph, Pareto\nchart, pie chart, and frequency polygon.\n• Determine when a graph is deceptive through the use of a nonzero axis or a\npictograph that uses an object of area or volume for one-dimensional data.\nScatterplots, Correlation, and Regression\n• Develop an ability to construct a scatterplot of paired data.\n• Analyze a scatterplot to determine whether there appears to be a correlation \nbetween two variables.\nKey Concept When working with large data sets, a frequency distribution (or frequency \ntable) is often helpful in organizing and summarizing data. A frequency distribution \nhelps us to understand the nature of the distribution of a data set.\n2-1\n Frequency Distributions for Organizing  \nand Summarizing Data\nDEFINITION\nA frequency distribution (or frequency table) shows how data are partitioned \namong several categories (or classes) by listing the categories along with the num-\nber (frequency) of data values in each of them.\nConsider the IQ scores of the low lead group listed in Table 2-1. Table 2-2 is a fre-\nquency distribution summarizing those IQ scores. The frequency for a particular class \nis the number of original values that fall into that class. For example, the first class in \nTable 2-2 has a frequency of 2, so 2 of the IQ scores are between 50 and 69 inclusive.\nThe following standard terms are often used in constructing frequency distributions \nand graphs.\nTABLE 2-2 IQ Scores of the \nLow Lead Group\nIQ Score\nFrequency\n50–69\n 2\n70–89\n33\n 90–109\n35\n110–129\n 7\n130–149\n 1\nDEFINITIONS\nLower class limits are the smallest numbers that can belong to each of the differ-","page_start":60,"page_end":60,"token_count":646,"section_type":"other","chapter_number":2,"chapter_title":"EXPLORING DATA WITH TABLES AND GRAPHS","chunk_index":83}
{"chunk_id":"f4e89e8ebe1b258c","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"The following standard terms are often used in constructing frequency distributions \nand graphs.\nTABLE 2-2 IQ Scores of the \nLow Lead Group\nIQ Score\nFrequency\n50–69\n 2\n70–89\n33\n 90–109\n35\n110–129\n 7\n130–149\n 1\nDEFINITIONS\nLower class limits are the smallest numbers that can belong to each of the differ-\nent classes. (Table 2-2 has lower class limits of 50, 70, 90, 110, and 130.)\nUpper class limits are the largest numbers that can belong to each of the different \nclasses. (Table 2-2 has upper class limits of 69, 89, 109, 129, and 149.)\nClass boundaries are the numbers used to separate the classes, but without the \ngaps created by class limits. In Figure 2-1 we see that the values of 69.5, 89.5, \n109.5, and 129.5 are in the centers of those gaps, and following the pattern of \nthose class boundaries, we see that the lowest class boundary is 49.5 and the ","page_start":60,"page_end":60,"token_count":250,"section_type":"other","chapter_number":2,"chapter_title":"EXPLORING DATA WITH TABLES AND GRAPHS","chunk_index":84}
{"chunk_id":"5ccd051777b6c558","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"2-1 Frequency Distributions for Organizing and Summarizing Data  \n43\nProcedure for Constructing a Frequency Distribution\nWe construct frequency distributions to (1) summarize large data sets, (2) see the dis-\ntribution and identify outliers, and (3) have a basis for constructing graphs (such as \nhistograms, introduced in Section 2-2). Technology can generate frequency distribu-\ntions, but here are the steps for manually constructing them:\n1. Select the number of classes, usually between 5 and 20. The number of classes \nmight be affected by the convenience of using round numbers.\n2. Calculate the class width.\nClass width ≈1maximum data value2 - 1minimum data value2\nnumber of classes\nRound this result to get a convenient number. (It’s usually best to round up.) \nUsing a specific number of classes is not too important, and it’s usually wise to \nchange the number of classes so that they use convenient values for the class \nlimits.\n3. Choose the value for the first lower class limit by using either the minimum \nvalue or a convenient value below the minimum.\nhighest class boundary is 149.5. Thus the complete list of class boundaries is 49.5, \n69.5, 89.5, 109.5, 129.5, and 149.5.\nClass midpoints are the values in the middle of the classes. Table 2-2 has class \nmidpoints of 59.5, 79.5, 99.5, 119.5, and 139.5. Each class midpoint is computed \nby adding the lower class limit to the upper class limit and dividing the sum by 2.\nClass width is the difference between two consecutive lower class limits (or two \nconsecutive lower class boundaries) in a frequency distribution. Table 2-2 uses a \nclass width of 20. (The first two lower class boundaries are 50 and 70, and their dif-\nference is 20.)\nCAUTION Finding the correct class width can be tricky. For class width, don’t \nmake the most common mistake of using the difference between a lower class limit \nand an upper class limit. See Table 2-2 and note that the class width is 20, not 19.\n69.5\n49.5\n50\n69\n149.5\nSTEP 1:\nList the class limits\nfrom Table 2-2.\nSTEP 2:\nSplit the diﬀerence\nas shown.\nSTEP 3:\nFind the ﬁrst and\nlast values of 49.5\nand 149.5 by\nprojecting the\nsame pattern.\n70\n89\n89.5\n90\n109\n109.5\n110\n129\n129.5\n130\n149\nFIGURE 2-1 Finding Class Boundaries from Class Limits in Table 2-2\nGrowth Charts Updated\nPediatricians \ntypically use \nstandardized \ngrowth charts to \ncompare their \npatient’s weight \nand height \nto a sample of other children. \nChildren are considered to be in ","page_start":61,"page_end":61,"token_count":653,"section_type":"other","chapter_number":2,"chapter_title":"EXPLORING DATA WITH TABLES AND GRAPHS","chunk_index":85}
{"chunk_id":"78ebaf5d40f24d9e","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"last values of 49.5\nand 149.5 by\nprojecting the\nsame pattern.\n70\n89\n89.5\n90\n109\n109.5\n110\n129\n129.5\n130\n149\nFIGURE 2-1 Finding Class Boundaries from Class Limits in Table 2-2\nGrowth Charts Updated\nPediatricians \ntypically use \nstandardized \ngrowth charts to \ncompare their \npatient’s weight \nand height \nto a sample of other children. \nChildren are considered to be in \nthe normal range if their weight \nand height fall between the 5th \nand 95th percentiles. If they fall \noutside that range, they are often \ngiven tests to ensure that there \nare no serious medical problems. \nPediatricians became increas-\ningly aware of a major problem \nwith the charts: Because they \nwere based on children living be-\ntween 1929 and 1975, the growth \ncharts had become inaccurate. \nTo rectify this problem, the charts \nwere updated in 2000 to reflect \nthe current measurements of \nmillions of children. The weights \nand heights of children are good \nexamples of populations that \nchange over time. This is the \nreason for including changing \ncharacteristics of data over time \nas an important consideration for \na population.\nh\nhild\nCAUTION For class boundaries, remember that they split the difference between \nthe end of one class and the beginning of the next class, as shown in Figure 2-1.\ncontinued","page_start":61,"page_end":61,"token_count":324,"section_type":"other","chapter_number":2,"chapter_title":"EXPLORING DATA WITH TABLES AND GRAPHS","chunk_index":86}
{"chunk_id":"5035067145999107","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"44 \nCHAPTER 2 Exploring Data with Tables and Graphs\n4. Using the first lower class limit and the class width, list the other lower class \nlimits. (Do this by adding the class width to the first lower class limit to get the \nsecond lower class limit. Add the class width to the second lower class limit to \nget the third lower class limit, and so on.)\n5. List the lower class limits in a vertical column and then determine and enter the \nupper class limits.\n6. Take each individual data value and put a tally mark in the appropriate \nclass. Add the tally marks to find the total frequency for each class.\nWhen constructing a frequency distribution, be sure the classes do not overlap. \nEach of the original values must belong to exactly one class. Include all classes, even \nthose with a frequency of zero. Try to use the same width for all classes, although it is \nsometimes impossible to avoid open-ended intervals, such as “65 years or older.”\nEXAMPLE 1  IQ Scores of Low Lead Group\nUsing the IQ scores of the low lead group in Table 2-1, follow the above procedure \nto construct the frequency distribution shown in Table 2-2. Use five classes.\nSOLUTION\nStep 1: Select 5 as the number of desired classes.\nStep 2: Calculate the class width as shown below. Note that we round 18.2 up to 20, \nwhich is a much more convenient number.\n Class width ≈1maximum data value2 - 1minimum data value2\nnumber of classes\n = 141 - 50\n5\n= 18.2 ≈20 1rounded up to a convenient number2\nStep 3: The minimum data value is 50 and it is a convenient starting point, so use \n50 as the first lower class limit. (If the minimum value had been 52 or 53, we would \nhave rounded down to the more convenient starting point of 50.)\nStep 4: Add the class width of 20 to 50 to get the second lower class limit of 70. \nContinue to add the class width of 20 until we have five lower class limits. The \nlower class limits are therefore 50, 70, 90, 110, and 130.\nStep 5: List the lower class limits vertically, as shown in the margin. From this list, \nwe identify the corresponding upper class limits as 69, 89, 109, 129, and 149.\nStep 6: Enter a tally mark for each data value in the appropriate class. Then add the \ntally marks to find the frequencies shown in Table 2-2.\n 50–\n 70–\n 90–\n110–\n130–\nCategorical Data So far we have discussed frequency distributions using only quan-\ntitative data sets, but frequency distributions can also be used to summarize categori-\ncal (or qualitative or attribute) data, as illustrated in Example 2.\nEXAMPLE 2   Emergency Room Visits for Injuries from Sports \nand Recreation \nTable 2-3 lists data for the highest seven sources of injuries resulting in a visit to \na hospital emergency room (ER) in a recent year (based on data from the Centers \nfor Disease Control and Prevention). The activity names are categorical data at \n","page_start":62,"page_end":62,"token_count":695,"section_type":"other","chapter_number":2,"chapter_title":"EXPLORING DATA WITH TABLES AND GRAPHS","chunk_index":87}
{"chunk_id":"8f22d115843bb93c","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"2-1 Frequency Distributions for Organizing and Summarizing Data  \n45\nRelative Frequency Distribution\nA variation of the basic frequency distribution is a relative frequency distribution or \npercentage frequency distribution, in which each class frequency is replaced by a \nrelative frequency (or proportion) or a percentage. In this text we use the term “rela-\ntive frequency distribution” whether we use relative frequencies or percentages. Rela-\ntive frequencies and percentages are calculated as follows.\n Relative frequency for a class = frequency for a class\nsum of all frequencies\n Percentage for a class = frequency for a class\nsum of all frequencies * 100%\nTable 2-4 is an example of a relative frequency distribution. It is a variation of \nTable 2-2 in which each class frequency is replaced by the corresponding percent-\nage value. Because there are 78 data values, divide each class frequency by 78, and \nthen multiply by 100%. The first class of Table 2-2 has a frequency of 2, so divide \n2 by 78 to get 0.0256, and then multiply by 100% to get 2.56%, which we rounded \nto 2.6%. The sum of the percentages should be 100%, with a small discrepancy al-\nlowed for rounding errors, so a sum such as 99% or 101% is acceptable. The sum \nof the percentages in Table 2-4 is 100.1%.\nThe sum of the percentages in a relative frequency distribution must be \nvery close to 100%.\nCumulative Frequency Distribution\nAnother variation of a frequency distribution is a cumulative frequency distribu-\ntion in which the frequency for each class is the sum of the frequencies for that class \nand all previous classes. Table 2-5 is a cumulative frequency distribution based on \nTable 2-2. Using the original frequencies of 2, 33, 35, 7, and 1, we add 2 + 33 to get \nthe second cumulative frequency of 35; then we add 2 + 33 + 35 to get the third; \nand so on. See Table 2-5, and note that in addition to the use of cumulative frequen-\ncies, the class limits are replaced by “less than” expressions that describe the new \nranges of values.\nTABLE 2-3 Annual ER Visits for Injuries from Sports and Recreation\nActivity\nFrequency\nBicycling\n26,212\nFootball\n25,376\nPlayground\n16,706\nBasketball\n13,987\nSoccer\n10,436\nBaseball\n 9,634\nAll-terrain vehicle\n 6,337\nthe nominal level of measurement, but we can create the frequency distribution as \nshown. It might be surprising to see that bicycling is at the top of this list, but this \ndoesn’t mean that bicycling is the most dangerous of these activities; many more \npeople bicycle than play football or ride an all-terrain vehicle or do any of the other \nlisted activities.\nTABLE 2-4 Relative  \nFrequency Distribution of IQ \nScores of Low Lead Group\nIQ Score\nFrequency\n50–69\n2.6%","page_start":63,"page_end":63,"token_count":668,"section_type":"other","chapter_number":2,"chapter_title":"EXPLORING DATA WITH TABLES AND GRAPHS","chunk_index":88}
{"chunk_id":"465872070e0ca6e2","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"shown. It might be surprising to see that bicycling is at the top of this list, but this \ndoesn’t mean that bicycling is the most dangerous of these activities; many more \npeople bicycle than play football or ride an all-terrain vehicle or do any of the other \nlisted activities.\nTABLE 2-4 Relative  \nFrequency Distribution of IQ \nScores of Low Lead Group\nIQ Score\nFrequency\n50–69\n2.6%\n70–89\n42.3%\n 90–109\n44.9%\n110–129\n 9.0%\n130–149\n 1.3%\nTABLE 2-5 Cumulative  \nFrequency Distribution of IQ \nScores of Low Lead Group\nIQ Score\nCumulative \nFrequency\nLess than 70\n 2\nLess than 90\n35\nLess than 110\n70\nLess than 130\n77\nLess than 150\n78","page_start":63,"page_end":63,"token_count":189,"section_type":"other","chapter_number":2,"chapter_title":"EXPLORING DATA WITH TABLES AND GRAPHS","chunk_index":89}
{"chunk_id":"aa86456ec8444eb8","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"46 \nCHAPTER 2 Exploring Data with Tables and Graphs\nCritical Thinking: Using Frequency Distributions  \nto Understand Data\nAt the beginning of this section we noted that a frequency distribution can help us un-\nderstand the distribution of a data set, which is the nature or shape of the spread of the \ndata over the range of values (such as bell-shaped). In statistics we are often interested \nin determining whether the data have a normal distribution. (Normal distributions are \ndiscussed extensively in Chapter 6.) Data that have an approximately normal distribu-\ntion are characterized by a frequency distribution with the following features:\nNormal Distribution\n1. The frequencies start low, then increase to one or two high frequencies, and \nthen decrease to a low frequency.\n2. The distribution is approximately symmetric: Frequencies preceding the \nmaximum frequency should be roughly a mirror image of those that follow \nthe maximum frequency.\nTable 2-6 satisfies these two conditions. The frequencies start low, increase to the max-\nimum of 56, and then decrease to a low frequency. Also, the frequencies of 1 and 10 \nthat precede the maximum are a mirror image of the frequencies 10 and 1 that follow \nthe maximum. Real data sets are usually not so perfect as Table 2-6, and judgment \nmust be used to determine whether the distribution comes “close enough” to satisfying \nthe above two conditions. (There are more objective procedures included later.)\nTABLE 2-6 Frequency Distribution Showing a Normal Distribution\nScore\nFrequency\nNormal Distribution\n50–69\n 1\nd Frequencies start low, . . .\n70–89\n10\n 90–109\n56\nd  Increase to a maximum, . . .\n110–129\n10\n130–149\n 1\nd  Decrease to become low again.\nAnalysis of Last Digits Example 3 illustrates this principle:\nFrequencies of last digits sometimes reveal how the data were collected \nor measured.\nEXAMPLE 3   Exploring Data: How Were the Weights Obtained in \nCalifornia? \nWhen collecting weights of people, it’s better to actually weigh people than to \nask them what they weigh. People often tend to round way down, so that a weight \nof 196 lb might be reported as 170 lb. Table 2-7 summarizes the last digits of the \nweights of 100 people used in the California Health Interview Survey. If people are \nactually weighed on a scale, the last digits of weights tend to have frequencies that \nare approximately the same, but Table 2-6 shows that the vast majority of weights \nhave last digits of 0 or 5, and this is strong evidence that people reported their \nweights and were not physically weighed. (Also, the word “interview” in the title \nof the California Health Interview Survey reveals that people were interviewed and \nwere not physically measured.)\n","page_start":64,"page_end":64,"token_count":598,"section_type":"other","chapter_number":2,"chapter_title":"EXPLORING DATA WITH TABLES AND GRAPHS","chunk_index":90}
{"chunk_id":"614ace2e687d7535","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"2-1 Frequency Distributions for Organizing and Summarizing Data  \n47\nGaps Example 4 illustrates this principle:\nThe presence of gaps can suggest that the data are from two or more \ndiﬀerent populations.\nThe converse of this principle is not true, because data from different populations do \nnot necessarily result in gaps.\nTABLE 2-7  Last Digits of Weights from the \nCalifornia Health Interview Survey\nLast Digit of Weight\nFrequency\n0\n46\n1\n 1\n2\n 2\n3\n 3\n4\n 3\n5\n30\n6\n 4\n7\n 0\n8\n 8\n9\n 3\nEXAMPLE 4  Exploring Data: What Does a Gap Tell Us?\nTable 2-8 is a frequency distribution of the heights (in.) of males. Examination of \nthe frequencies reveals a large gap between the shortest males and the tallest males. \nThis can be explained by the fact that half of the males are 7 years old and the other \nhalf are adults, so we really have samples from two different populations.\nTABLE 2-8 Heights of Males\nHeight (in.)\nFrequency\n40–44\n 3\n45–49\n17\n50–54\n29\n55–59\n 1\n60–64\n 0\n65–69\n24\n70–74\n23\n75–79\n 3\n","page_start":65,"page_end":65,"token_count":301,"section_type":"other","chapter_number":2,"chapter_title":"EXPLORING DATA WITH TABLES AND GRAPHS","chunk_index":91}
{"chunk_id":"14a9393a3253470f","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"48 \nCHAPTER 2 Exploring Data with Tables and Graphs\nTABLE 2-9 IQ Scores from the Low Lead Group and the High Lead Group\nIQ Score\nLow Lead Group\nHigh Lead Group\n50–69\n 2.6%\n70–89\n42.3%\n71.4%\n 90–109\n44.9%\n28.6%\n110–129\n 9.0%\n130–149\n 1.3%\nEXAMPLE 5   Comparing IQ Scores of the Low Lead Group and \nthe High Lead Group \nTable 2-1, which is given with the Chapter Problem at the beginning of this chapter, \nlists IQ scores from the low lead group and the high lead group. Because the sample \nsizes of 78 and 21 are so different, a comparison of frequency distributions is not \neasy, but Table 2-9 shows the relative frequency distributions for those two groups. \nBy comparing those relative frequencies, we see that the majority of children in the \nlow lead group had IQ scores of 90 or higher, but the majority of children in the \nhigh lead group had IQ scores below 90. This suggests that perhaps high lead expo-\nsure has a detrimental effect on IQ scores.\nFrequency Distributions\nAccess tech instructions, videos, and data sets at www.TriolaStats.com\nTECH CENTER \nStatistical Literacy and Critical Thinking\n1. Cotinine in Smokers Refer to the accompanying table summarizing measured amounts \nof serum cotinine (ng/mL) from a sample of smokers (from Data Set 14 “Passive and Active \nSmoke” in Appendix B). When nicotine is absorbed by the body, cotinine is produced. How \nmany subjects are included in the summary? Is it possible to identify the exact values of all of \nthe original cotinine measurements?\n2-1 Basic Skills and Concepts \nCotinine (ng, mL)\nFrequency\n 0–99\n11\n100–199\n12\n200–299\n14\n300–399\n 1\n400-499\n 2\n2. Cotinine in Smokers Refer to the accompanying frequency distribution. What problem is \ncreated by using classes of 0–100, 100–200, . . . ?\n3. Relative Frequency Distribution Use percentages to construct the relative frequency dis-\ntribution corresponding to the accompanying frequency distribution for cotinine amounts.\n4. What’s Wrong? Heights of adult males are known to have a normal distribution, as de-\nscribed in this section. A researcher claims to have randomly selected adult males and mea-\nsured their heights with the resulting relative frequency distribution as shown here. Identify two \nmajor flaws with theses results.\nHeight \n(cm)\nRelative  \nFrequency\n130–144\n23%\n145–159\n25%\n160–174\n22%\n175–189\n27%\n190–204\n28%\nComparisons Example 5 illustrates this principle:\nCombining two or more relative frequency distributions in one table \nmakes comparisons of data much easier.\n","page_start":66,"page_end":66,"token_count":620,"section_type":"other","chapter_number":2,"chapter_title":"EXPLORING DATA WITH TABLES AND GRAPHS","chunk_index":92}
{"chunk_id":"1ae3c7f04b1076b2","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"2-1 Frequency Distributions for Organizing and Summarizing Data  \n49\nIn Exercises 5–8, identify the class width, class midpoints, and class boundaries for the \ngiven frequency distribution. The frequency distributions are based on real data from \nAppendix B.\n5. \nCotinine (NonSmokers  \nExposed to Smoke  \nin ng, mL)\nFrequency\n0–99\n34\n100–199\n 2\n200–299\n 1\n300–399\n 1\n400–499\n 0\n500–599\n 2\n6. \nBrain Volume (cm3)\nFrequency\n960–1049\n6\n1050–1139\n7\n1140–1229\n3\n1230–1319\n2\n1320–1409\n1\n1410–1499\n1\n7. \nBlood Platelet \nCount of Males\nFrequency\n 0–99\n 1\n100–199\n51\n200–299\n90\n300–399\n10\n400–499\n 0\n500–599\n 0\n600–699\n 1\n8. \nBlood Platelet \nCount of Females\nFrequency\n100–199\n25\n200–299\n92\n300–399\n28\n400–499\n 0\n500–599\n 2\nNormal Distributions. In Exercises 9–12, answer the given questions, which are related \nto normal distributions.\n9. Cotinine Determine whether the frequency distribution given in Exercise 5 is approximately \na normal distribution. Explain.\n10. Brain Volume Refer to the frequency distribution given in Exercise 6 and ignore the given fre-\nquencies. Assume that the first three frequencies are 1, 3, and 6, respectively. Assuming that the dis-\ntribution of the 20 sample values is a normal distribution, identify the remaining three frequencies.\n11. Normal Distribution Refer to the frequency distribution given in Exercise 7 and ignore \nthe given frequencies. Assume that the first three frequencies are 2, 12, and 18, respectively. \nAssuming that the distribution of the 153 sample values is a normal distribution, identify the \nremaining four frequencies.\n12. Normal Distribution Refer to the frequency distribution given in Exercise 8 and deter-\nmine whether it appears to be a normal distribution. Explain.\nConstructing Frequency Distributions. In Exercises 13–22, use the indicated data and \nconstruct the frequency distribution. (The data for Exercises 13–22 can be downloaded at \nTriolaStats.com.)\n13. Pulse Rates of Males Refer to Data Set 1 “Body Data” in Appendix B and use the pulse \nrates (beats per minute) of males. Begin with a lower class limit of 40 and use a class width of \n10. Do the pulse rates of males appear to have a normal distribution?\n14. Pulse Rates of Females Refer to Data Set 1 “Body Data” in Appendix B and use the \npulse rates (beats per minute) of females. Begin with a lower class limit of 30 and use a class ","page_start":67,"page_end":67,"token_count":653,"section_type":"other","chapter_number":2,"chapter_title":"EXPLORING DATA WITH TABLES AND GRAPHS","chunk_index":93}
{"chunk_id":"c969d193ac22a458","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"rates (beats per minute) of males. Begin with a lower class limit of 40 and use a class width of \n10. Do the pulse rates of males appear to have a normal distribution?\n14. Pulse Rates of Females Refer to Data Set 1 “Body Data” in Appendix B and use the \npulse rates (beats per minute) of females. Begin with a lower class limit of 30 and use a class \nwidth of 10. Do the pulse rates of females appear to have a normal distribution?\n15. Lead and IQ Refer to Data Set 8 “IQ and Lead” in Appendix B and use the verbal IQ \nscores of the low lead group. Begin with a lower class limit of 50 and use a class width of 10. \nDo these IQ scores appear to be normally distributed?","page_start":67,"page_end":67,"token_count":172,"section_type":"other","chapter_number":2,"chapter_title":"EXPLORING DATA WITH TABLES AND GRAPHS","chunk_index":94}
{"chunk_id":"9441cae907840115","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"50 \nCHAPTER 2 Exploring Data with Tables and Graphs\n16. Lead and IQ Refer to Data Set 8 “IQ and Lead” in Appendix B and use the verbal IQ \nscores of the high lead group. Begin with a lower class limit of 60 and use a class width of 10. \nDo these IQ scores appear to be normally distributed?\n17. Male Red Blood Cell Counts Refer to Data Set 1 “Body Data” in Appendix B and use \nthe red blood cell counts (million cells>mL) for males. Begin with a lower class limit of 3.00 \nand use a class width of 0.50. Using a very loose interpretation of the requirements for a nor-\nmal distribution, do the red blood cell counts appear to be normally distributed?\n18. Female Red Blood Cell Counts Repeat the preceding exercise using the red blood cell \ncounts for females.\n19. Freshman 15 Refer to Data Set 10 “Freshman 15” in Appendix B and use the weights (kg) \nof males in September of their freshman year. Begin with a lower class limit of 50 kg and use a \nclass width of 10 kg.\n20.  Freshman 15 Repeat the preceding exercise using the weights (kg) of males in April. \nCompare the result to the frequency distribution from the preceding exercise. Does it appear \nthat males gain 15 lb (or 6.8 kg) during their freshman year?\n21. Analysis of Last Digits Heights of statistics students were obtained by one of the authors \nas part of an experiment conducted for class. The last digits of those heights are listed below. \nConstruct a frequency distribution with 10 classes. Based on the distribution, do the heights ap-\npear to be reported or actually measured? What do you know about the accuracy of the results?\n0 0 0 0 0 0 0 0 0 1 1 2 3 3 3 4 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 6 6 8 8 8 9\n22. Analysis of Last Digits Listed below are the last digits of weights of subjects. After con-\nstructing the frequency distribution, does it appear that the weights were reported or physically \nmeasured? Explain.\n2 7 7 3 2 8 5 9 7 2 8 6 9 2 7 5 6 4 0 7 6 8 4 0 4\n7 5 5 4 8 6 3 8 9 3 9 2 6 0 1 1 1 7 2 0 3 5 6 6 8\nRelative Frequencies for Comparisons. In Exercises 23 and 24, find the relative fre-\nquencies and answer the given questions.\n23. Cotinine Construct one table (similar to Table 2-9 on page 48) that includes relative fre-","page_start":68,"page_end":68,"token_count":653,"section_type":"other","chapter_number":2,"chapter_title":"EXPLORING DATA WITH TABLES AND GRAPHS","chunk_index":95}
{"chunk_id":"152cf1df2f464763","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"Relative Frequencies for Comparisons. In Exercises 23 and 24, find the relative fre-\nquencies and answer the given questions.\n23. Cotinine Construct one table (similar to Table 2-9 on page 48) that includes relative fre-\nquencies based on the frequency distributions from Exercise 1 (smokers) and Exercise 5 (non-\nsmokers exposed to smoke), and then compare them. Are there notable differences?\n24. Blood Platelet Counts Construct one table (similar to Table 2-9 on page 48) that includes \nrelative frequencies based on the frequency distributions from Exercises 7 and 8, and then com-\npare them. Are there notable differences?\nCumulative Frequency Distributions. In Exercises 25 and 26, construct the cumulative \nfrequency distribution that corresponds to the frequency distribution in the exercise indicated.\n25. Exercise 5\n26. Exercise 6\n27. Interpreting Effects of Outliers Exercise 5 in this section involved cotinine levels of \nnonsmokers who were exposed to tobacco smoke. (See the middle column in Data Set 14 \n “Passive and Active Smoke” in Appendix B.)\na. Identify any outliers.\nb. After adding another value of 999 to the cotinine levels of nonsmokers exposed to smoke, construct \nthe frequency distribution as in Exercise 5. How is the frequency distribution affected by the addition \nof the outlier 999? State a generalization about the effect of an outlier on a frequency distribution.\n2-1 Beyond the Basics ","page_start":68,"page_end":68,"token_count":319,"section_type":"other","chapter_number":2,"chapter_title":"EXPLORING DATA WITH TABLES AND GRAPHS","chunk_index":96}
{"chunk_id":"aa089d87fe781c77","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"2-2 Histograms \n51\nImportant Uses of a Histogram\n \n■Visually displays the shape of the distribution of the data\n \n■Shows the location of the center of the data\n \n■Shows the spread of the data\n \n■Identifies outliers\nA histogram is basically a graph of a frequency distribution. For example, \n Figure 2-2 shows the histogram corresponding to the frequency distribution given in \nTable 2-2 on page 42.\nClass frequencies should be used for the vertical scale and that scale should be la-\nbeled as in Figure 2-2. There is no universal agreement on the procedure for selecting \nwhich values are used for the bar locations along the horizontal scale, but it is com-\nmon to use class boundaries (as shown in Figure 2-2) or class midpoints or class limits \nor something else. It is often easier for us mere mortals to use class midpoints for the \nhorizontal scale. Histograms can usually be generated using technology.\nRelative Frequency Histogram\nA relative frequency histogram has the same shape and horizontal scale as a histo-\ngram, but the vertical scale uses relative frequencies (as percentages or proportions) \ninstead of actual frequencies. Figure 2-3 is the relative frequency histogram corre-\nsponding to Figure 2-2.\nPART 1\nBasic Concepts of Histograms\nKey Concept While a frequency distribution is a useful tool for summarizing data \nand investigating the distribution of data, an even better tool is a histogram, which is a \ngraph that is easier to interpret than a table of numbers.\n2-2 \nHistograms\nDEFINITION\nA histogram is a graph consisting of bars of equal width drawn adjacent to each \nother (unless there are gaps in the data). The horizontal scale represents classes of \nquantitative data values, and the vertical scale represents frequencies. The heights \nof the bars correspond to frequency values.\nFIGURE 2-2 Histogram\nFIGURE 2-3 Relative Frequency Histogram\n","page_start":69,"page_end":69,"token_count":406,"section_type":"other","chapter_number":2,"chapter_title":"EXPLORING DATA WITH TABLES AND GRAPHS","chunk_index":97}
{"chunk_id":"252bdf6e2a99333a","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"52 \nCHAPTER 2 Exploring Data with Tables and Graphs\nCritical Thinking: Interpreting Histograms\nThe ultimate objective of a histogram is to understand characteristics of the data. Ex-\nplore the data by analyzing the histogram to see what can be learned about “CVDOT”: \nthe center of the data, the variation (which will be discussed at length in Section 3-2), \nthe shape of the distribution, whether there are any outliers (values far away from the \nother values), and time (whether there is any change in the characteristics of the data \nover time). Examining Figure 2-2, we see that the histogram is centered close to 90, \nthe values vary from around 50 to 150, and the distribution is roughly bell-shaped. \nThere aren’t any outliers and any changes in time are irrelevant for these data.\nCommon Distribution Shapes\nThe histograms shown in Figure 2-4 depict four common distribution shapes.\nNormal Distribution\nWhen graphed as a histogram, data with a normal distribution have a “bell” shape \nsimilar to the one superimposed in Figure 2-5. Many collections of data have a dis-\ntribution that is approximately normal. Many statistical methods require that sample \ndata come from a population having a distribution that is approximately a normal dis-\ntribution, and we can often use a histogram to judge whether this requirement is satis-\nfied. There are more advanced and less subjective methods for determining whether \nthe distribution is a normal distribution. Normal quantile plots are very helpful for \nassessing normality: see Part 2 of this section.\n   \n   \nFIGURE 2-4 Common Distributions\n(a)\n(b)\n(c)\n(d)\n","page_start":70,"page_end":70,"token_count":353,"section_type":"other","chapter_number":2,"chapter_title":"EXPLORING DATA WITH TABLES AND GRAPHS","chunk_index":98}
{"chunk_id":"39fe7e9735cca80c","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"2-2 Histograms \n53\nUniform Distribution\nThe different possible values occur with approximately the same frequency, so the \nheights of the bars in the histogram are approximately uniform, as in Figure 2-4(b). \nFigure 2-4(b) depicts outcomes of last digits of weights from a large sample of ran-\ndomly selected subjects, and such a graph is helpful in determining whether the sub-\njects were actually weighed or whether they reported their weights.\nPopulation sizes of an organism are often uniformly distributed when they are \nfound in equally sized areas of a region where they must compete for a limited re-\nsource. For example, redwood trees must compete for light, and numbers of redwood \ntrees in equally sized areas of a region tend to be uniformly distributed.\nSkewness\nA distribution of data is skewed if it is not symmetric and extends more to one side \nthan to the other. Data skewed to the right (also called positively skewed) have a \nlonger right tail, as in Figure 2-4(c). Annual incomes of adult Americans are skewed \nto the right; death rates of nations are skewed to the right. Data skewed to the left \n(also called negatively skewed) have a longer left tail, as in Figure 2-4(d). Life span \ndata in humans are skewed to the left. (Here’s a mnemonic for remembering skew-\nness: A distribution skewed to the right resembles the toes on your right foot, and \none skewed to the left resembles the toes on your left foot.) Distributions skewed to \nthe right are more common than those skewed to the left because it’s often easier to \nget exceptionally large values than values that are exceptionally small. With annual \nincomes, for example, it’s impossible to get values below zero, but there are a few \npeople who earn millions or billions of dollars in a year. Annual incomes therefore \ntend to be skewed to the right.\nPART 2\n  Assessing Normality with  \nNormal Quantile Plots\nSome methods presented in later chapters have a requirement that sample data must \nbe from a population having a normal distribution. Histograms can be helpful in de-\ntermining whether the normality requirement is satisfied, but they are not very help-\nful with small data sets. Section 6-5 discusses methods for assessing normality—that \nis, determining whether the sample data are from a normally distributed population. \nSection 6-5 includes a procedure for constructing normal quantile plots, which are \nFIGURE 2-5  Bell-Shaped Distribution\nBecause this histogram is roughly bell-shaped, we say that the \ndata have a normal distribution. (A more rigorous deﬁnition will be \ngiven in Chapter 6.)\nRemembering Skewness:\nSkewed Left:   Resembles \ntoes on left \nfoot\nSkewed Right:  Resembles \ntoes on right \nfoot\n","page_start":71,"page_end":71,"token_count":603,"section_type":"other","chapter_number":2,"chapter_title":"EXPLORING DATA WITH TABLES AND GRAPHS","chunk_index":99}
{"chunk_id":"583bfa01567b23ef","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"54 \nCHAPTER 2 Exploring Data with Tables and Graphs\neasy to generate using technology such as Statdisk, SPSS, JMP, Minitab, XLSTAT, \nStatCrunch, or a TI-83>84 Plus calculator. Interpretation of a normal quantile plot is \nbased on the following criteria:\nCriteria for Assessing Normality with a Normal Quantile Plot\nNormal Distribution: The population distribution is normal if the pattern of the \npoints in the normal quantile plot is reasonably close to a straight line, and the \npoints do not show some systematic pattern that is not a straight-line pattern.\nNot a Normal Distribution: The population distribution is not normal if the \nnormal quantile plot has either or both of these two conditions:\n•  The points do not lie reasonably close to a straight-line pattern.\n•  The points show some systematic pattern that is not a straight-line pattern.\nThe following are examples of normal quantile plots. Procedures for creating such \nplots are described in Section 6-5.\nNormal Distribution: The points are  \nreasonably close to a straight-line pattern, \nand there is no other systematic pattern \nthat is not a straight-line pattern.\nNot a Normal Distribution: The \npoints do not lie reasonably close to a \nstraight line.\nNot a Normal Distribution: The \npoints show a systematic pattern that \nis not a straight-line pattern.\nHistograms\nAccess tech instructions, videos, and data sets at www.TriolaStats.com\nTECH CENTER \nStatistical Literacy and Critical Thinking\n1. Histogram Table 2-2 is a frequency distribution summarizing the IQ scores of the low lead \ngroup listed in Table 2-1 on page 41, and Figure 2-2 on page 51 is a histogram depicting that \nsame data set. When trying to better understand the IQ data, what is the advantage of examin-\ning the histogram instead of the frequency distribution?\n2. Voluntary Response Sample The histogram in Figure 2-2 on page 51 is constructed from \na simple random sample of children. If you construct a histogram with data collected from a \nvoluntary response sample, will the distribution depicted in the histogram reflect the true dis-\ntribution of the population? Why or why not?\n3. Blood Platelet Counts Listed below are blood platelet counts (1000 cells>mL) randomly \nselected from adults in the United States. Why does it not make sense to construct a histogram \nfor this data set?\n191 286 263 193 193 215 162 646 250 386\n2-2 Basic Skills and Concepts\n","page_start":72,"page_end":72,"token_count":569,"section_type":"other","chapter_number":2,"chapter_title":"EXPLORING DATA WITH TABLES AND GRAPHS","chunk_index":100}
{"chunk_id":"f41d3828a4db9d81","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"2-2 Histograms \n55\n4. Normal Distribution When it refers to a normal distribution, does the term “normal” have \nthe same meaning as in ordinary language? What criterion can be used to determine whether \nthe data depicted in a histogram have a distribution that is approximately a normal distribution? \nIs this criterion totally objective, or does it involve subjective judgment?\nInterpreting a Histogram. In Exercises 5–8, answer the questions by referring to the fol-\nlowing histogram, which represents the sepal widths (mm) of a sample of irises. (See Data \nSet 16 “Iris Measurements” in Appendix B.)\n5. Sample Size Based on the histogram, what is the approximate number of irises in \nthe sample?\n6. Class Width and Class Limits What is the class width? What are the approximate lower \nand upper class limits of the first class?\n7. Outlier? What is the largest possible value? Would that value be an outlier?\n8. Normal Distribution Does it appear that the sample is from a population having a normal \ndistribution?\nConstructing Histograms. In Exercises 9–18, construct the histograms and answer the \ngiven questions. Use class midpoint values for the horizontal scale.\n9. Pulse Rates of Males Use the frequency distribution from Exercise 13 in Section 2-1 on \npage 49 to construct a histogram. Do the pulse rates of males appear to have a normal distribution?\n10. Pulse Rates of Females Use the frequency distribution from Exercise 14 in Section 2-1  \non page 49 to construct a histogram. Do the pulse rates of females appear to have a normal \ndistribution?\n11. Lead and IQ Use the frequency distribution from Exercise 15 in Section 2-1 on page 49 to \nconstruct a histogram. Do the IQ scores appear to have a normal distribution?\n12. Lead and IQ Use the frequency distribution from Exercise 16 in Section 2-1 on page 50 to \nconstruct a histogram. Do the IQ scores appear to have a normal distribution?\n13.  Male Red Blood Cell Counts Use the frequency distribution from Exercise 17 in \nSection 2-1 on page 50 to construct a histogram. Do the red blood cell counts appear to have a \nnormal distribution?\n14. Female Red Blood Cell Counts Use the frequency distribution from Exercise 18 in \nSection 2-1 on page 50 to construct a histogram. Do the red blood cell counts appear to have \na normal distribution?\n15. Freshman 15 Use the frequency distribution from Exercise 19 in Section 2-1 on page 50 \nto construct a histogram.\n16. Freshman 15 Use the frequency distribution from Exercise 20 in Section 2-1 on page 50 \nto construct a histogram.\n","page_start":73,"page_end":73,"token_count":584,"section_type":"other","chapter_number":2,"chapter_title":"EXPLORING DATA WITH TABLES AND GRAPHS","chunk_index":101}
{"chunk_id":"09f418bbcd3cbcb0","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"56 \nCHAPTER 2 Exploring Data with Tables and Graphs\n17. Last Digit Analysis Use the frequency distribution from Exercise 21 in Section 2-1 on \npage 50 to construct a histogram. What does the histogram suggest about the method used to \ncollect the heights?\n18. Last Digit Analysis Use the frequency distribution from Exercise 22 in Section 2-1 on \npage 50 to construct a histogram. What does the histogram suggest about the method used to \ncollect the weights?\n2-2 Beyond the Basics\nKey Concept Section 2-2 introduced the histogram, and this section introduces other \ncommon graphs that foster understanding of data. We also discuss some graphs that \nare deceptive because they create impressions about data that are somehow mislead-\ning or wrong.\nThe era of charming and primitive hand-drawn graphs has passed, and technol-\nogy now provides us with powerful tools for generating a wide variety of graphs. \nHere we go.\nGraphs That Enlighten\nDotplots\nA dotplot consists of a graph of quantitative data in which each data value is plotted \nas a point (or dot) above a horizontal scale of values. Dots representing equal values \nare stacked.\nFeatures of a Dotplot\n \n■Displays the shape of the distribution of data.\n \n■It is usually possible to recreate the original list of data values.\n2-3 \nGraphs That Enlighten and Graphs That Deceive\n19. Interpreting Normal Quantile Plots Which of the following normal quantile plots  appear \nto represent data from a population having a normal distribution? Explain.\n(a)\n(b)\n(c)\n(d)\n","page_start":74,"page_end":74,"token_count":335,"section_type":"other","chapter_number":2,"chapter_title":"EXPLORING DATA WITH TABLES AND GRAPHS","chunk_index":102}
{"chunk_id":"10662412bf7b93b5","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"2-3 Graphs That Enlighten and Graphs That Deceive \n57\nStemplots\nA stemplot (or stem-and-leaf plot) represents quantitative data by separating each \nvalue into two parts: the stem (such as the leftmost digit) and the leaf (such as the \nrightmost digit). Better stemplots are often obtained by first rounding the original data \nvalues. Also, stemplots can be expanded to include more rows and can be condensed \nto include fewer rows.\nFeatures of a Stemplot\n \n■Shows the shape of the distribution of the data.\n \n■Retains the original data values.\n \n■The sample data are sorted (arranged in order).\nFIGURE 2-6 Dotplot of Pulse Rates of Males\nEXAMPLE 1  Dotplot of Pulse Rates of Males\nFigure 2-6 shows a dotplot of the pulse rates (beats per minute) of males from Data \nSet 1 “Body Data” in Appendix B. The two stacked dots above the position at 50 in-\ndicate that two of the pulse rates are 50. (In this dotplot, the horizontal scale allows \neven numbers only, but the original pulse rates are all even numbers.)\nEXAMPLE 2  Stemplot of Male Pulse Rates\nThe following stemplot displays the pulse rates of the males in Data Set 1 “Body \nData” in Appendix B. The lowest pulse rate of 40 is separated into the stem of 4 and \nthe leaf of 0. The stems and leaves are arranged in increasing order, not the order in \nwhich they occur in the original list. If you turn the stemplot on its side, you can see \nthe distribution of the IQ scores in the same way you would see it in a histogram or \ndotplot.\nPulse rates are 40 and 42\nPulse rates are 90, 92, 94, 96, 96\nTime-Series Graph\nA time-series graph is a graph of time-series data, which are quantitative data that \nhave been collected at different points in time, such as monthly or yearly. An advan-\ntage of a time-series graph is that it reveals information about trends over time.\nFeatures of a Time-series Graph\n \n■Reveals information about trends over time\n","page_start":75,"page_end":75,"token_count":475,"section_type":"other","chapter_number":3,"chapter_title":"DESCRIBING, EXPLORING, AND COMPARING DATA","chunk_index":103}
{"chunk_id":"b4bb137c4bee6dc1","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"58 \nCHAPTER 2 Exploring Data with Tables and Graphs\nBar Graphs\nA bar graph uses bars of equal width to show frequencies of categories of categori-\ncal (or qualitative) data. The bars may or may not be separated by small gaps.\nFeature of a Bar Graph\n \n■Shows the relative distribution of categorical data so that it is easier to compare \nthe different categories\nPareto Charts\nA Pareto chart is a bar graph for categorical data, with the added stipulation that the \nbars are arranged in descending order according to frequencies, so the bars decrease \nin height from left to right.\nFeatures of a Pareto Chart\n \n■Shows the relative distribution of categorical data so that it is easier to compare \nthe different categories\n \n■Draws attention to the more important categories\nFIGURE 2-7  Time-Series Graph of Law  \nEnforcement Fatalities\nEXAMPLE 3   Time-Series Graph of Fatalities of Law  \nEnforcement Officers\nThe time-series graph shown in Figure 2-7 depicts the yearly number of fatalities \nof law enforcement officers in the United States. See that a spike occurred in 2001, \nthe year of the September 11, 2001 terrorist attacks. Except for the data from 2001, \nthere appears to be a slight downward trend.\nEXAMPLE 4  Pareto Chart of Causes of Accidental Deaths\nFor the accidental deaths in a recent year, Figure 2-8 shows the most common \ncauses. We can see that deaths from poison represent the most serious problem. \n(Deaths from poison include deaths from drug overdoses.)\nThe Power of a Graph\nWith annual \nsales around \n$13 billion and \nwith roughly \n50 million \npeople using \nit, Pfizer’s \nprescription drug Lipitor (ator-\nvastatin) has become the most \nprofitable and most widely used \nprescription drug ever marketed. \nIn the early stages of its develop-\nment, Lipitor was compared to \nother drugs (Zocor [simvastatin], \nMevacor [lovastatin], Lescol \n[fluvastatin], and Pravachol \npravastatin) in a process that \ninvolved controlled trials. The \nsummary report included a graph \nshowing a Lipitor curve that had \na steeper rise than the curves for \nthe other drugs, visually showing \nthat Lipitor was more effective \nin reducing cholesterol than the \nother drugs. Pat Kelly, who was \nthen a senior marketing execu-\ntive for Pfizer, said, “I will never \nforget seeing that chart…. It was \nlike ‘Aha!’ Now I know what this \nis about. We can communicate \nthis!” The Food and Drug Admin-\nistration approved Lipitor and al-\nlowed Pfizer to include the graph \nwith each prescription. Pfizer \nsales personnel also distributed \nthe graph to physicians.\n","page_start":76,"page_end":76,"token_count":600,"section_type":"other","chapter_number":3,"chapter_title":"DESCRIBING, EXPLORING, AND COMPARING DATA","chunk_index":104}
{"chunk_id":"faec7054bc554fea","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"2-3 Graphs That Enlighten and Graphs That Deceive \n59\nPie Charts\nA pie chart is a very common graph that depicts categorical data as slices of a circle, \nin which the size of each slice is proportional to the frequency count for the category. \nAlthough pie charts are very common, they are not as effective as Pareto charts.\nFeature of a Pie Chart\n \n■Shows the distribution of categorical data in a commonly used format\nFIGURE 2-8  Pareto Chart of Causes of \n Accidental Deaths\nEXAMPLE 5  Pie Chart of Causes of Accidental Deaths\nFigure 2-9 is a pie chart of the same cause of death data from Example 4. Construc-\ntion of a pie chart involves slicing up the circle into the proper proportions that rep-\nresent relative frequencies. For example, the category poison accounts for 34% of \nthe total, so the slice representing poison should be 34% of the total (with a central \nangle of 0.34 * 360° = 122°).\nFIGURE 2-9  Pie Chart of Causes of \nAccidental Deaths\nThe Pareto chart in Figure 2-8 and the pie chart in Figure 2-9 depict the same data in \ndifferent ways, but the Pareto chart does a better job of showing the relative sizes of the \ndifferent components. Graphics expert Edwin Tufte makes the following suggestion:\nNever use pie charts because they waste ink on components that are not \ndata, and they lack an appropriate scale.\n","page_start":77,"page_end":77,"token_count":318,"section_type":"other","chapter_number":3,"chapter_title":"DESCRIBING, EXPLORING, AND COMPARING DATA","chunk_index":105}
{"chunk_id":"cdaea11f3f5956ae","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"60 \nCHAPTER 2 Exploring Data with Tables and Graphs\nFrequency Polygon\nA frequency polygon uses line segments connected to points located directly above \nclass midpoint values. A frequency polygon is very similar to a histogram, but a fre-\nquency polygon uses line segments instead of bars.\nA variation of the basic frequency polygon is the relative frequency polygon, \nwhich uses relative frequencies (proportions or percentages) for the vertical scale. An \nadvantage of relative frequency polygons is that two or more of them can be combined \non a single graph for easy comparison, as in Figure 2-11.\nFIGURE 2-10  Frequency Polygon of Full IQ \nScores of Low Lead Group\nEXAMPLE 6   Frequency Polygon of Full IQ Scores of  \nLow Lead Group\nSee Figure 2-10 for the frequency polygon corresponding to the full IQ scores of the \nlow lead group summarized in the frequency distribution of Table 2-2 on page 42 \n(from Data Set 8 in Appendix B). The heights of the points correspond to the class \nfrequencies, and the line segments are extended to the right and left so that the graph \nbegins and ends on the horizontal axis. The points are plotted directly above class \nmidpoint values.\nEXAMPLE 7   Relative Frequency Polygon: IQ Scores  \nof Lead Groups\nFigure 2-11 shows the relative frequency polygons for the full IQ scores of two \ngroups: (1) group with low blood lead levels; (2) group with high blood lead levels. \nHere, relative frequency polygons are much better than frequency polygons because \nthe different sample sizes of 21 and 78 would have made a comparison difficult, but \nthat difficulty is removed by using relative percentages.\nFigure 2-11 shows that the group with high blood lead levels has full IQ scores \nthat are somewhat lower than those in the low blood level group. This suggests that \nexposure to lead has an effect on IQ scores. Later chapters will provide us with \nmore tools that allow us to examine this issue beyond the subjective interpretation \nof a graph.\nF\nA\nc\nq\nFlorence Nightingale\nFlorence \nNightingale \n(1820–1910) \nis known to \nmany as the \nfounder of \nthe nursing \nprofession, but she also saved \nthousands of lives by using \nstatistics. When she encountered \nan unsanitary and undersup-\nplied hospital, she improved \nthose conditions and then used \nstatistics to convince others of \nthe need for more widespread \nmedical reform. She developed \noriginal graphs to illustrate that \nduring the Crimean War, more \nsoldiers died as a result of \nunsanitary conditions than were \nkilled in combat. Florence Night-\ningale pioneered the use of social \nstatistics as well as graphics \ntechniques.\n","page_start":78,"page_end":78,"token_count":580,"section_type":"other","chapter_number":3,"chapter_title":"DESCRIBING, EXPLORING, AND COMPARING DATA","chunk_index":106}
{"chunk_id":"f973edabce1e8513","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"2-3 Graphs That Enlighten and Graphs That Deceive \n61\nGraphs That Deceive\nDeceptive graphs are commonly used to mislead people, and we really don’t want \nstatistics students to be among those susceptible to such deceptions. Graphs should be \nconstructed in a way that is fair and objective. The readers should be allowed to make \ntheir own judgments, instead of being manipulated by misleading graphs. We present \ntwo of the ways in which graphs are commonly used to misrepresent data.\nNonzero Vertical Axis\nA common deceptive graph involves using a vertical scale that starts at some value \ngreater than zero to exaggerate differences between groups.\nFIGURE 2-11  Relative Frequency Polygons for Full IQ \nScores of High and Low Lead Groups\nNONZERO AXIS: Always examine a graph carefully to see whether a vertical axis \nbegins at some point other than zero so that differences are exaggerated.\nEXAMPLE 8  Nonzero Axis\nFigure 2-12(a) and Figure 2-12(b) are based on the same data from a clinical trial of \nOxyContin (oxycodone), a drug used to treat moderate to severe pain. The results of \nthat clinical trial included the percentage of subjects who experienced nausea in an \nOxyContin treatment group and the percentage in a group given a placebo.\n \nFIGURE 2-12 Nausea in a Clinical Trial\n(a)\n(b)\ncontinued\n","page_start":79,"page_end":79,"token_count":297,"section_type":"other","chapter_number":3,"chapter_title":"DESCRIBING, EXPLORING, AND COMPARING DATA","chunk_index":107}
{"chunk_id":"3f49a16fd25292a0","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"62 \nCHAPTER 2 Exploring Data with Tables and Graphs\nPictographs\nDrawings of objects, called pictographs, are often misleading. Data that are one-\ndimensional in nature (such as budget amounts) are often depicted with two-dimensional \nobjects (such as dollar bills) or three-dimensional objects (such as stacks of coins, \nhomes, or barrels). With pictographs, artists can create false impressions that grossly \ndistort differences by using these simple principles of basic geometry: (1) When you \ndouble each side of a square, its area doesn’t merely double; it increases by a factor \nof four. (2) When you double each side of a cube, its volume doesn’t merely double; \nit increases by a factor of eight.\nBy using a vertical scale that starts at 10% instead of 0%, Figure 2-12(a) \ngrossly exaggerates the difference between the two groups. Figure 2-12(a) makes it \nappear that those using OxyContin experience nausea at a rate that is about 12 times \nhigher than the rate for those using a placebo, but Figure 2-12(b) shows that the true \nratio is about 2:1, not 12:1. Perhaps someone wants to discourage recreational use \nof OxyContin by misleading people into thinking that the problem with nausea is \nmuch greater than it really is. The objective might be sincere, but the use of a mis-\nleading graph is not the way to achieve that objective.\nPICTOGRAPHS: When examining data depicted with a pictograph, determine \nwhether the graph is misleading because objects of area or volume are used to \ndepict amounts that are actually one-dimensional. (Histograms and bar charts \nrepresent one-dimensional data with two-dimensional bars, but they use bars with \nthe same width so that the graph is not misleading.)\nEXAMPLE 9  Pictograph of Cigarette Smokers\nRefer to Figure 2-13 and see that the larger cigarette is about twice as long, twice as \ntall, and twice as deep as the smaller cigarette, so the volume of the larger cigarette \nis about eight times the volume of the smaller cigarette. (The data are from the Cen-\nters for Disease Control and Prevention.) The larger cigarette appears to be eight \ntimes as large as the smaller cigarette, but the actual percentages show that the 37% \nsmoking rate in 1970 is about twice that of the 18% rate in 2013.\n \nFIGURE 2-13 Smoking by U.S. Adults\n1970: 37% of U.S. adults smoked.       2013: 18% of U.S. adults smoked.\n","page_start":80,"page_end":80,"token_count":564,"section_type":"other","chapter_number":3,"chapter_title":"DESCRIBING, EXPLORING, AND COMPARING DATA","chunk_index":108}
{"chunk_id":"fda19f258d69d9ec","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"2-3 Graphs That Enlighten and Graphs That Deceive \n63\nConcluding Thoughts\nIn addition to the graphs we have discussed in this section, there are many other useful \ngraphs—some of which have not yet been created. The world desperately needs more \npeople who can create original graphs that enlighten us about the nature of data. In \nThe Visual Display of Quantitative Information, Edward Tufte offers these principles:\n■For small data sets of 20 values or fewer, use a table instead of a graph.\n■A graph of data should make us focus on the true nature of the data, not on other \nelements, such as eye-catching but distracting design features.\n■Do not distort data; construct a graph to reveal the true nature of the data.\n■Almost all of the ink in a graph should be used for the data, not for other design \nelements.\nGraphing Capabilities\nAccess tech instructions, videos, and data sets at www.TriolaStats.com\nTECH CENTER \nStatistical Literacy and Critical Thinking\n1. Body Temperatures Listed below are body temperatures (°F) of healthy adults. Why is it \nthat a graph of these data would not be very effective in helping us understand the data?\n98.6 98.6 98.0 98.0 99.0 98.4 98.4 98.4 98.4 98.6\n2. Voluntary Response Data If we have a large voluntary response sample consisting of \nweights of subjects who chose to respond to a survey posted on the Internet, can a graph help to \novercome the deficiency of having a voluntary response sample?\n3. Ethics There are data showing that smoking is detrimental to good health. Given that people \ncould be helped and lives could be saved by reducing smoking, is it ethical to graph the data in \na way that is misleading by exaggerating the health risks of smoking?\n4. CVDOT Section 2-1 introduced important characteristics of data summarized by the acro-\nnym CVDOT. What characteristics do those letters represent, and which graph does the best \njob of giving us insight into the last of those characteristics?\nDotplots. In Exercises 5 and 6, construct the dotplot.\n5. Pulse Rates Listed below are pulse rates (beats per minute) of females selected from Data \nSet 1 “Body Data” in Appendix B. All of those pulse rates are even numbers. Is there a pulse \nrate that appears to be an outlier? What is its value?\n80  94  58  66  56  82  78  86  88  56  36  66  84  76  78  64  66  78  60  64\n6. Diastolic Blood Pressure Listed below are diastolic blood pressure measurements \n(mm Hg) of females selected from Data Set 1 “Body Data” in Appendix B. All of the values are \neven numbers. Are there any outliers? If so, identify their values.","page_start":81,"page_end":81,"token_count":644,"section_type":"other","chapter_number":3,"chapter_title":"DESCRIBING, EXPLORING, AND COMPARING DATA","chunk_index":109}
{"chunk_id":"fe7698ea2b93bacb","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"6. Diastolic Blood Pressure Listed below are diastolic blood pressure measurements \n(mm Hg) of females selected from Data Set 1 “Body Data” in Appendix B. All of the values are \neven numbers. Are there any outliers? If so, identify their values.\n62 70 72 88 70 66 68 70 82 74 90 62 70 76 90 86 60 78 82 78 84 76 60 64\nStemplots. In Exercises 7 and 8, construct the stemplot.\n7. Pulse Rates Refer to the data listed in Exercise 5. How are the data sorted in the stemplot?\n8. Diastolic Blood Pressure Refer to the data listed in Exercise 6. Identify the two values \nthat are closest to the middle when the data are sorted in order from lowest to highest. (These \nvalues are often used to find the median, which is defined in Section 3-1.)\n2-3 Basic Skills and Concepts","page_start":81,"page_end":81,"token_count":216,"section_type":"other","chapter_number":3,"chapter_title":"DESCRIBING, EXPLORING, AND COMPARING DATA","chunk_index":110}
{"chunk_id":"875d01f70de7b96f","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"64 \nCHAPTER 2 Exploring Data with Tables and Graphs\nTime-Series Graphs. In Exercises 9 and 10, construct the time-series graph.\n9. Triplets Listed below are the numbers of triplets born in the United States each year beginning \nwith 1995. Is there a trend?\n4551 5298 6148 6919 6742 6742 6885 6898 7110\n6750 6208 6118 5967 5877 5905 5153 5137 4598\n10. Drunk Driving Fatalities Listed below are annual fatality rates (per 100,000 population) \nfrom drunk driving. The first entry represents the year 1991. Is there a trend? Any explanation?\n6.3 5.5 5.3 5.1 5.1 5.1 4.8 4.6 4.6 4.7 4.7\n4.7 4.5 4.5 4.6 4.5 4.3 3.9 3.5 3.3 3.2 3.3\nPareto Charts. In Exercises 11 and 12 construct the Pareto chart.\n11. Journal Retractions In a study of retractions in biomedical journals, 436 were due to \nerror, 201 were due to plagiarism, 888 were due to fraud, 291 were duplications of publica-\ntions, and 287 had other causes (based on data from “Misconduct Accounts for the Majority \nof Retracted Scientific Publications,” by Fang, Steen, Casadevall, Proceedings of the National \nAcademy of Sciences of the United States of America, Vol. 110, No. 3). Among such retrac-\ntions, does misconduct (fraud, duplication, plagiarism) appear to be a major factor?\n12. Getting a Job In a survey, subjects seeking a job were asked to whom they send a thank-\nyou note after having a job interview. Results were as follows: 40 said only the person they \nspent the most time with, 40 said only the most senior-level person, 396 said everyone that they \nmet, 15 said the person that they had the best conversation with, and 10 said that they don’t \nsend thank-you notes (based on data from TheLadders.com). Comment on the results.\nPie Charts. In Exercises 13 and 14, construct the pie chart.\n13. Journal Retractions Use the data from Exercise 11 “Journal Retractions.”\n14. Getting a Job Use the data from Exercise 12 “Getting a Job.”\nFrequency Polygon. In Exercises 15 and 16, construct the frequency polygons.\n15. Pulse Rates of Males Use the frequency distribution for the pulse rates of males from \nExercise 13 in Section 2-1 on page 49 to construct a frequency polygon. Comment on the \nshape of the distribution.\n16. Pulse Rates of Females Use the frequency distribution for the pulse rates of females ","page_start":82,"page_end":82,"token_count":650,"section_type":"other","chapter_number":3,"chapter_title":"DESCRIBING, EXPLORING, AND COMPARING DATA","chunk_index":111}
{"chunk_id":"8bbee45324871a11","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"14. Getting a Job Use the data from Exercise 12 “Getting a Job.”\nFrequency Polygon. In Exercises 15 and 16, construct the frequency polygons.\n15. Pulse Rates of Males Use the frequency distribution for the pulse rates of males from \nExercise 13 in Section 2-1 on page 49 to construct a frequency polygon. Comment on the \nshape of the distribution.\n16. Pulse Rates of Females Use the frequency distribution for the pulse rates of females \nfrom Exercise 14 in Section 2-1 on page 49 to construct a frequency polygon. Comment on the \nshape of the distribution.\nDeceptive Graphs. In Exercises 17–18, identify how the graph is deceptive.\n17. Self-Driving Vehicles In a survey of adults, subjects were asked if they felt comfortable \nbeing in a self-driving vehicle. The accompanying graph depicts the results (based on data from \nTE Connectivity).","page_start":82,"page_end":82,"token_count":189,"section_type":"other","chapter_number":3,"chapter_title":"DESCRIBING, EXPLORING, AND COMPARING DATA","chunk_index":112}
{"chunk_id":"95fe522a369d4fb9","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"2-4 Scatterplots, Correlation, and Regression \n65\n18. Cost of Giving Birth According to the Agency for Healthcare Research and Quality \nHealthcare Cost and Utilization Project, the typical cost of a C-section baby delivery is $4500, \nand the typical cost of a vaginal delivery is $2600. See the accompanying illustration.\nCost of C-Section Delivery: $4500\nCost of Vaginal Delivery: $2600\nKey Concept This section introduces the analysis of paired (or “bivariate”) sample \ndata, which are data from two different variables that are paired in some way, such \nas the variables of heights and weights from subjects. In Part 1 of this section we dis-\ncuss correlation and the role of a graph called a scatterplot. In Part 2 we provide an \nintroduction to the use of the linear correlation coefficient. In Part 3 we provide a very \nbrief discussion of linear regression, which involves the equation and graph of the \nstraight line that best fits the sample paired data.\nAll of the principles discussed in this section are discussed more fully in Chapter 10, \nbut this section serves as a quick introduction to some important concepts of correlation \nand regression. This section does not include details for executing manual calculations, \nand those calculations are rarely done. Instructions for using technology to obtain results \ncan be found at www.TriolaStats.com; refer to the instructions for Chapter 10.\nPART 1\n Scatterplot and Correlation \nOur objective in this section is to explore whether there is a correlation, or associa-\ntion, between two variables. We begin with basic definitions.\n2-4 \nScatterplots, Correlation, and Regression\nDEFINITIONS\nA correlation exists between two variables when the values of one variable are \nsomehow associated with the values of the other variable.\nA linear correlation exists between two variables when there is a correlation and \nthe plotted points of paired data result in a pattern that can be approximated by a \nstraight line.\nA scatterplot or scatter diagram is a plot of paired (x, y) quantitative data with a \nhorizontal x-axis and a vertical y-axis. The horizontal axis is used for the first vari-\nable (x), and the vertical axis is used for the second variable (y).\n","page_start":83,"page_end":83,"token_count":473,"section_type":"other","chapter_number":3,"chapter_title":"DESCRIBING, EXPLORING, AND COMPARING DATA","chunk_index":113}
{"chunk_id":"355a5005327942fc","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"66 \nCHAPTER 2 Exploring Data with Tables and Graphs\nA scatterplot can be used as a visual aid in determining whether there is a correlation \n(or relationship) between the two variables. (This issue is discussed at length when the \ntopic of correlation is considered in Section 10-1.)\nCAUTION: The presence of a correlation between two variables is not evidence \nthat one of the variables causes the other. We might find a correlation between beer \nconsumption and weight, but we cannot conclude from the statistical evidence that \ndrinking beer has a direct effect on weight.\nCorrelation does not imply causality!\nEXAMPLE 1  Correlation: Waist and Arm Circumference\nData Set 1 “Body Data” in Appendix B includes waist circumferences (cm) and arm \ncircumferences (cm) of randomly selected adult subjects. Figure 2-14 is a scatter-\nplot of the paired waist>arm measurements. The points show a pattern of increasing \nvalues from left to right. This pattern suggests that there is a correlation or relation-\nship between waist circumferences and arm circumferences.\nEXAMPLE 2  No Correlation: Weight and Pulse Rate\nData Set 1 “Body Data” in Appendix B includes weights (kg) and pulse rates (beats \nper minute) of randomly selected adult subjects. Figure 2-15 is a scatterplot of the \npaired weight>pulse rate measurements. The points in Figure 2-15 do not show any \nobvious pattern, and this lack of a pattern suggests that there is no correlation or re-\nlationship between weights and pulse rates.\nFIGURE 2-14  Waist and Arm Circumferences\nCorrelation: The distinct straight-line pattern of the plotted \npoints suggests that there is a correlation between waist \ncircumferences and arm circumference.\nFIGURE 2-15 Weights and Pulse Rates\nNo Correlation: The plotted points do not show a distinct \npattern, so it appears that there is no correlation between \nweights and pulse rates.\nThe preceding two examples involve making decisions about a correlation \nbased on subjective judgments of scatterplots, but Part 2 introduces the linear corre-\nlation coefficient as a numerical measure that can help us make such decisions more \nobjectively. Using paired data, we can calculate the value of the linear correlation \ncoefficient r.\n","page_start":84,"page_end":84,"token_count":480,"section_type":"other","chapter_number":3,"chapter_title":"DESCRIBING, EXPLORING, AND COMPARING DATA","chunk_index":114}
{"chunk_id":"266f22d2054a9e8d","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"2-4 Scatterplots, Correlation, and Regression \n67\nPART 2\nLinear Correlation Coefficient r\nUsing paired data, we can calculate the value of the linear correlation coefficient r.\nDEFINITION\nThe linear correlation coefficient is denoted by r, and it measures the strength of \nthe linear association between two variables.\nThe value of a linear correlation coefficient r can be manually computed by applying \nFormula 10-1 or Formula 10-2 found in Section 10-1 on page 447, but in practice, r is \nalmost always found by using technology.\nUsing r for Determining Correlation\nThe computed value of the linear correlation coefficient is always between -1 and \n1. A value of exactly -1 or 1 implies that all of the data fall exactly on a line, which \nreflects a perfect correlation. If r is close to -1 or close to 1, there appears to be a \nstrong correlation, but if r is close to 0, there appears to be a weak or no linear cor-\nrelation. For the data depicted in the scatterplot of Figure 2-14, r = 0.802 (somewhat \nclose to 1), and the data in the scatterplot of Figure 2-15 result in r = 0.082 (pretty \nclose to 0). These descriptions of “close to” -1 or 1 or 0 are vague, but there are other \nobjective criteria discussed in Chapter 10. See the following example illustrating the \ninterpretation of the linear correlation coefficient r.\nTABLE 2-10 Shoe Print Lengths and Heights of Males\nShoe Print Length (cm)\n29.7\n29.7\n31.4\n31.8\n27.6\nHeight (cm)\n175.3\n177.8\n185.4\n175.3\n172.7\nEXAMPLE 3   Correlation Between Shoe Print  \nLengths and Heights?\nConsider the data in Table 2-10 (using data from Data Set 7 “Foot and Height” in \nAppendix B). From the accompanying scatterplot of the paired data in Table 2-10, it \nisn’t very clear whether there is a linear correlation. The Statdisk display of the results \nshows that the linear correlation coefficient has the value of r = 0.591 (rounded).\nPolice Deaths in Car \nChases\nUSA Today \ninvestigated \nthe annual \nreporting of \nthe numbers of \npolice who were \nkilled during \ncar chases. It was found that the \nFederal Bureau of Investigation \n(FBI) counted 24 deaths in the \npast 35 years, but other records \nshow that there were 371 deaths \nduring that time period. USA \nToday reporter Thomas Frank \nwrote that “the undercount is one \nof the most extreme examples of \nthe federal government’s inability \nto accurately track violent deaths \nand has led the FBI to minimize \nthe danger of police chasing \nmotorists.” Apparently, the FBI \nwas categorizing these deaths \nas automobile accidents instead \nof designating them as police \ndeaths that occurred during a car \nchase.\nStatdisk\n","page_start":85,"page_end":85,"token_count":662,"section_type":"other","chapter_number":3,"chapter_title":"DESCRIBING, EXPLORING, AND COMPARING DATA","chunk_index":115}
{"chunk_id":"2c78115f5e96391b","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"68 \nCHAPTER 2 Exploring Data with Tables and Graphs\nIn Example 3, we know from the Statdisk display that using the five pairs of data from \nTable 2-10, the linear correlation coefficient is computed to be r = 0.591. The value \nof r = 0.591 is not very close to 0 or 1, so based on that value and the displayed scat-\nterplot, it does not appear that there is a strong correlation between shoeprint lengths \nand heights of males.\nEXAMPLE 4   Correlation Between Shoe Print Lengths  \nand Heights?\nExample 3 used only five pairs of data from Data Set 7 “Foot and Height” in Appendix B. \nIf we use the shoe print lengths and heights from all of the 40 subjects listed in Data Set 7 \nin Appendix B, we get the scatterplot shown in Figure 2-16 and we get the Minitab results \nshown in the accompanying display. The scatterplot does show a distinct pattern instead of \nhaving points scattered about willy-nilly. Also, we see that the value of the linear correla-\ntion coefficient is r = 0.813. Because r = 0.813 is reasonably close to 1 and because of \nthe pattern of points in the scatterplot, it appears that there is a linear  correlation between \nshoe print lengths and heights.\nIn Example 3 with only five pairs of data, we did not have enough evidence to \nconclude that there is a linear correlation, but in this example with 40 pairs of data, it \ndoes appear that there is a linear correlation between shoe print lengths and heights.\nPART 3\n Regression \nWhen we do conclude that there appears to be a linear correlation between two vari-\nables (as in Example 4), we can find the equation of the straight line that best fits the \nsample data, and that equation can be used to predict the value of one variable when \ngiven a specific value of the other variable. Based on the results from Example 4, we \ncan predict someone’s height given the length of their shoe print (which may have \nbeen found at a crime scene).\nInstead of using the straight-line equation format of y = mx + b that we have all \nlearned in prior math courses, we use the format that follows.\nFIGURE 2-16 Scatterplot of 40 Pairs of Data\nMinitab\n","page_start":86,"page_end":86,"token_count":506,"section_type":"other","chapter_number":3,"chapter_title":"DESCRIBING, EXPLORING, AND COMPARING DATA","chunk_index":116}
{"chunk_id":"f5eb4dc030f62e12","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"2-4 Scatterplots, Correlation, and Regression \n69\nThe regression equation\nyn = b0 + b1x\nalgebraically describes the regression line.\nSection 10-2 gives a good reason for using the format of yn = b0 + b1x instead of \nthe format of y = mx + b. Section 10-2 also provides formulas that could be used to \nidentify the values of the y-intercept b0 and the slope b1, but those values are usually \nfound by using technology.\nDEFINITION\nGiven a collection of paired sample data, the regression line (or line of  best fit or \nleast-squares line) is the straight line that “best” fits the scatterplot of the data. (The \nspecific criterion for the “best”-fitting straight line is the “least squares” property \ndescribed in Section 10-2.)\nFIGURE 2-17 Regression Line\nEXAMPLE 5  Regression Line\nExample 4 included a scatterplot of the 40 pairs of shoe print lengths and heights \nfrom Data Set 7 “Foot and Height” in Appendix B. Figure 2-17 shown here is that \nsame scatterplot with the graph of the regression line included. Also shown is the \nStatdisk display from the 40 pairs of data.\nFrom the Statdisk display, we see that the general form of the regression equa-\ntion has a y-intercept of b0 = 80.9 (rounded) and slope b1 = 3.22 (rounded), so the \nequation of the regression line shown in Figure 2-17 is yn = 80.9 + 3.22x. It might \nbe helpful to express that equation more clearly by using the names of the variables:\nHeight = 80.9 + 3.22 1Shoe Print Length2\nNote that the equation shows the y-intercept of 80.9 that does not appear on the ver-\ntical scale in the graph. The leftmost vertical scale in Figure 2-19 is not the actual \ny-axis that passes through 0 on the x-axis. If the graph were extended to the left, the \nregression line would intercept the actual y-axis at the height of y = 80.9 cm.\nStatdisk\n","page_start":87,"page_end":87,"token_count":480,"section_type":"other","chapter_number":3,"chapter_title":"DESCRIBING, EXPLORING, AND COMPARING DATA","chunk_index":117}
{"chunk_id":"ba8e52dd0a28867c","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"70 \nCHAPTER 2 Exploring Data with Tables and Graphs\nStatistical Literacy and Critical Thinking\n1. Linear Correlation In this section we use r to denote the value of the linear correlation co-\nefficient. Why do we refer to this correlation coefficient as being linear?\n2. Causation A study has shown that there is a correlation between body weight and blood \npressure. Higher body weights are associated with higher blood pressure levels. Can we con-\nclude that gaining weight is a cause of increased blood pressure?\n3. Scatterplot What is a scatterplot and how does it help us?\n4. Estimating r For each of the following, estimate the value of the linear correlation coeffi-\ncient r for the given paired data obtained from 50 randomly selected adults.\na. Their heights are measured in inches (x) and those same heights are recorded in centimeters (y).\nb. Their IQ scores (x) are measured and their heights (y) are measured in centimeters.\nc. Their pulse rates (x) are measured and their IQ scores are measured (y).\nd. Their heights (x) are measured in centimeters and those same heights are listed again, but \nwith negative signs (y) preceding each of these second listings.\nScatterplot. In Exercises 5–8, use the sample data to construct a scatterplot. Use the first vari-\nable for the x-axis. Based on the scatterplot, what do you conclude about a linear correlation?\n5. Brain Volume and IQ The table lists brain volumes (cm3) and IQ scores of five males (from \nData Set 9 “IQ and Brain Size” in Appendix B).\nBrain volume (cm3)\n1173\n1067\n1347\n1029\n1204\nIQ\n 101\n  93\n  94\n  97\n 113\n6. Bear Measurements The table lists chest sizes (distance around chest in inches) and \nweights (pounds) of anesthetized bears that were measured (from Data Set 11 in Appendix B).\nChest (in.)\n26\n 45\n 54\n 49\n 35\n 41\n 41\nWeight (lb)\n80\n344\n416\n348\n166\n220\n262\n7. Body Temperatures The table lists body temperatures (°F) of seven healthy adults at 8 AM on \none day and at 8 AM  on the following day (from Data Set 2 “Body Temperatures” in Appendix B).\nDay 1  98.6  97.4  98.2  98.2  98.2  96.6  97.4\nDay 2  97.8  97.0  97.0  96.6  97.0  96.8  96.6\n8. Heights of Fathers and Sons The table lists heights (in.) of fathers and the heights (in.) of \ntheir first sons (from Francis Galton).\nHeight of father (in.)\n73.0\n75.5\n75.0\n75.0\n75.0\n74.0\n74.0\n73.0","page_start":88,"page_end":88,"token_count":668,"section_type":"other","chapter_number":3,"chapter_title":"DESCRIBING, EXPLORING, AND COMPARING DATA","chunk_index":118}
{"chunk_id":"a3cb5bd13d9aaaf3","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"8. Heights of Fathers and Sons The table lists heights (in.) of fathers and the heights (in.) of \ntheir first sons (from Francis Galton).\nHeight of father (in.)\n73.0\n75.5\n75.0\n75.0\n75.0\n74.0\n74.0\n73.0\n73.0\n78.5\nHeight of first son (in.)\n74.0\n73.5\n71.0\n70.5\n72.0\n76.5\n74.0\n71.0\n72.0\n73.2\nLinear Correlation Coefficient. In Exercises 9–12, the linear correlation coefficient r is \nprovided. What do you conclude about a linear correlation?\n9. Using the data from Exercise 5 “Brain Volume and IQ,” the linear correlation coefficient is \nr = 0.127.\n10. Using the data from Exercise 6 “Bear Measurements,” the linear correlation coefficient is \nr = 0.980.\n2-4 Basic Skills and Concepts","page_start":88,"page_end":88,"token_count":219,"section_type":"other","chapter_number":3,"chapter_title":"DESCRIBING, EXPLORING, AND COMPARING DATA","chunk_index":119}
{"chunk_id":"72285e327294dbe8","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"11. Using the data from Exercise 7 “Body Temperatures,” the linear correlation coefficient is \nr = 0.520.\n12. Using the data from Exercise 8 “Heights of Fathers and Sons,” the linear correlation coef-\nficient is r = -0.017.\nChapter Quick Quiz\n1. BAC When constructing a table representing the frequency distribution of blood alcohol \ncontent (g>dL) of drunk drivers involved in fatal car crashes, the first two classes of a fre-\nquency distribution are 0.08 – 0.11 and 0.12 – 0.15. What is the class width?\n2. BAC Using the same first two classes from Exercise 1, identify the class boundaries of the \nfirst class.\n3. BAC The first class described in Exercise 1 has a frequency of 36. If you know only the class \nlimits given in Exercise 1 and the frequency of 36, can you identify the original 36 data values?\n4. BAC A stemplot is created from the ages of drunk drivers involved in fatal car crashes and \nthe first row is 1 | 67889. Identify the values represented by that row.\n5. Reaction Times A large sample is randomly selected from a normally distributed popula-\ntion of reaction times, and a histogram is constructed from a frequency distribution. What is the \nshape of the histogram?\n6. Tylenol In testing samples of regular Tylenol pills to verify that they have close to the de-\nsired amount of 325 mg of acetaminophen, which important characteristic of data is missing \nfrom this list: center, distribution, outliers, changes over time?\n7. Tylenol A quality control manager wants to monitor the production of regular Tylenol pills \nto be sure that the mean amount of acetaminophen does not change over time. Which of the fol-\nlowing graphs is most helpful for that purpose: histogram, Pareto chart, pie chart, scatterplot, \ntime-series graph, dotplot?\n8. Blood Pressure In an investigation of the relationship between systolic blood pressure and \ndiastolic blood pressure, which of the following graphs is most helpful: histogram; pie chart; \nscatterplot; stemplot; dotplot?\n9. Blood Pressure Thing The W. A. Baum Company manufactures sphygmomanometers \nused to measure blood pressure. Quality control managers at such companies monitor defects \nand identify various causes, including worn machinery, human error, bad supplies, and packag-\ning mistreatment. Which of the following graphs would be best for describing the causes of \ndefects: histogram, scatterplot, Pareto chart, dotplot, stemplot?\n10. Frequency Distribution and Histogram What is the basic difference between a fre-\nquency distribution and a histogram?\n1. Frequency Distribution of Body Temperatures Construct a frequency distribution of the \n20 body temperatures 1°F2 listed below. (These data are from Data Set 2 “Body Temperatures” \nin Appendix B.) Use a class width of 0.5°F and a starting value of 97.0°F.","page_start":89,"page_end":89,"token_count":645,"section_type":"other","chapter_number":3,"chapter_title":"DESCRIBING, EXPLORING, AND COMPARING DATA","chunk_index":120}
{"chunk_id":"8281f70381ac0dc4","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"10. Frequency Distribution and Histogram What is the basic difference between a fre-\nquency distribution and a histogram?\n1. Frequency Distribution of Body Temperatures Construct a frequency distribution of the \n20 body temperatures 1°F2 listed below. (These data are from Data Set 2 “Body Temperatures” \nin Appendix B.) Use a class width of 0.5°F and a starting value of 97.0°F.\n97.1 97.2 97.5 97.6 97.6 97.8 98.0 98.0 98.2 98.2\n98.2 98.3 98.4 98.6 98.6 98.7 98.7 98.9 99.1 99.4\nReview Exercises\nCHAPTER 2 Review Exercises \n71","page_start":89,"page_end":89,"token_count":177,"section_type":"other","chapter_number":3,"chapter_title":"DESCRIBING, EXPLORING, AND COMPARING DATA","chunk_index":121}
{"chunk_id":"69018e039d986484","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"72 \nCHAPTER 2 Exploring Data with Tables and Graphs\n2. Histogram of Body Temperatures Construct the histogram that corresponds to the fre-\nquency distribution from Exercise 1. Use class midpoint values for the horizontal scale. Does \nthe histogram suggest that the data are from a population having a normal distribution? Why or \nwhy not?\n3. Dotplot of Body Temperatures Construct a dotplot of the body temperatures listed in \n Exercise 1. Which does a better job of illustrating the distribution of the data: the histogram \nfrom Exercise 2 or the dotplot?\n4. Stemplot of Body Temperatures Construct a stemplot of the body temperatures listed in \nExercise 1. Are there any outliers?\n5. Bears Listed below are the neck sizes (in.) and weights (lb) of bears (from Data Set 11 \n“Bear Measurements” in Appendix B). Construct a scatterplot. Based on the graph, does there \nappear to be a relationship between neck sizes and weights of bears?\nNeck Size (in.)   16   28   31   31.5   22   21   26.5    27   20   18\nWeight (lb)     80  344  416  348.0  166  220  262.0  360  204  144\n6. Monitoring Weight\na. After collecting the average (mean) weight of adult males in the United States for each of the \nmost recent 100 years, we want to construct the graph that is most appropriate for these data. \nWhich graph is best?\nb. After collecting the average (mean) weight and height of males for the most recent 100 years, \nwe want to construct a graph to investigate the association between those two variables. Which \ngraph is best?\nc. An investigation of health problems associated with overweight males includes heart dis-\nease, stroke, high blood pressure, diabetes, and breathing problems. If we want to construct a \ngraph that illustrates the relative importance of these adverse effects, which graph is best?\n7. Medical School Enrollees The accompanying graph illustrates male and female enrollees \nin U.S. medical schools in a recent year. What is wrong with the graph?\nCumulative Review Exercises\n1. Hygiene Listed below are times (minutes) spent on hygiene and grooming in the morning \nby randomly selected subjects (based on data from a Svenska Cellulosa Aktiebolaget survey). \nConstruct a table representing the frequency distribution. Use the classes 0–9, 10–19, and so on.\n0  5  12  15  15  20  22  24  25  25  25  27  27  28  30  30  35  35  40  45\n2. Hygiene Histogram Use the frequency distribution from Exercise 1 to construct a histo-\ngram. Use class midpoint values for the horizontal scale. Based on the result, do the data ap-\npear to be from a population with a normal distribution? Explain.","page_start":90,"page_end":90,"token_count":655,"section_type":"other","chapter_number":3,"chapter_title":"DESCRIBING, EXPLORING, AND COMPARING DATA","chunk_index":122}
{"chunk_id":"a84e2345985d469e","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"2. Hygiene Histogram Use the frequency distribution from Exercise 1 to construct a histo-\ngram. Use class midpoint values for the horizontal scale. Based on the result, do the data ap-\npear to be from a population with a normal distribution? Explain.\n3. Hygiene Stemplot Use the data from Exercise 1 to construct a stemplot.\n4. Analysis of Last Digits Use the data from Exercise 1 and construct a frequency distribution \nof the last digits of the grooming times. What does the result suggest about the grooming times?\n5. Hygiene Refer to the grooming times given in Exercise 1.\na. What is the level of measurement of those times? (nominal, ordinal, interval, ratio)\nb. Are the exact unrounded grooming times discrete data or continuous data?\nc. Are the grooming times categorical data?\nd. The average (mean) of the grooming times is 24.3 minutes. Is that value a statistic or a \n parameter?","page_start":90,"page_end":90,"token_count":199,"section_type":"other","chapter_number":3,"chapter_title":"DESCRIBING, EXPLORING, AND COMPARING DATA","chunk_index":123}
{"chunk_id":"a09e8bdc463dee96","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"6. Mother, Daughter Heights Refer to the following list of heights of mothers and the heights \nof their first daughters (from Data Set 6 “Family Heights” in Appendix B). What issue would \nbe investigated with these data? Construct the best graph for investigating that issue. What does \nthat graph suggest?\nMother’s Height (in.)    67.0  66.5  64  64  58.5  68.0  62  66.5  65.0  64.5\nDaughter’s Height (in.)  69.2  65.5  68  67  66.5  70.5  68  66.7  68.7  66.5\nTechnology Project\nIt was stated in this chapter that the days of charming and primitive hand-drawn graphs are well \nbehind us, and technology now provides us with powerful tools for generating a wide variety of \ndifferent graphs. This project therefore serves as a good preparation for professional presenta-\ntions that will be inevitably made in the future.\nThe complete data sets in Appendix B can be downloaded from www.TriolaStats.com. \nThey can be opened by statistical software packages, such as Minitab, Excel, SPSS, and JMP. \nStatdisk already includes the data sets. Use a statistical software package to open Data Set 1 \n“Body Data.” Use this statistical software with the methods of this chapter to describe, explore, \nand compare the ages of males and females. Does there appear to be a difference? Reports \nof randomized clinical trials typically include “baseline characteristics” of the subjects in the \ndifferent groups so that we can see whether the groups are similar in ways that are important. \nBased on ages, do the males and females in Data Set 1 appear to be similar? (Later chapters \nwill present more formal methods for making such comparisons.)\nFROM DATA TO DECISION\nCar crash fatalities are tragic losses of lives and they are \ndevastating to the families involved. Listed below are the \nages of 100 randomly selected drivers who were killed in car \ncrashes. Also given is a frequency distribution of licensed \ndrivers by age (based on recent data from the Insurance Insti-\ntute for Highway Safety).\nAges (in years) of Drivers Killed in Car Crashes\nAge\nLicensed Drivers  \n(millions)\n41 43 38 31 57 29 65 18 42 47\n16–19\n 9.7\n69 50 22 60 30 30 34 18 18 42\n20–29\n33.6\n18 16 74 25 41 43 50 34 54 45\n30–39\n40.2\n32 20 50 36 27 59 19 23 57 74\n40–49\n40.3\n27 38 29 24 56 72 21 22 74 20\n50–59\n29.6\n43 34 38 62 39 45 56 70 68 75\n60–69\n18.3","page_start":91,"page_end":91,"token_count":670,"section_type":"other","chapter_number":3,"chapter_title":"DESCRIBING, EXPLORING, AND COMPARING DATA","chunk_index":124}
{"chunk_id":"67383200fb4ebe00","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"18 16 74 25 41 43 50 34 54 45\n30–39\n40.2\n32 20 50 36 27 59 19 23 57 74\n40–49\n40.3\n27 38 29 24 56 72 21 22 74 20\n50–59\n29.6\n43 34 38 62 39 45 56 70 68 75\n60–69\n18.3\n37 49 25 24 21 25 31 21 76 69\n70–79\n13.4\n28 62 69 26 22 62 64 24 56 70\n80–89\n 5.4\n21 52 32 30 38 73 35 52 38 29\n23 17 44 25 24 70 16 49 45 34\nAnalysis\nConvert the given frequency distribution to a relative fre-\nquency distribution, then create a relative frequency distri-\nbution using the 100 ages of drivers killed in car crashes. \nCompare the two relative frequency distributions. Which age \ncategories appear to have substantially greater proportions \nof fatalities than the proportions of licensed drivers? If you \nwere responsible for establishing the rates for auto insurance, \nwhich age categories would you select for higher rates? Con-\nstruct a graph that is effective in identifying age categories \nthat are more prone to fatal car crashes.\nCHAPTER 2 Technology Project \n73","page_start":91,"page_end":91,"token_count":328,"section_type":"other","chapter_number":3,"chapter_title":"DESCRIBING, EXPLORING, AND COMPARING DATA","chunk_index":125}
{"chunk_id":"519f8d4ca44eeb5e","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"74 \nCHAPTER 2 Exploring Data with Tables and Graphs\nCooperative Group Activities\n1. In-class activity In class, each student should record two pulse rates by counting the \nnumber of heartbeats in 1 minute. The first pulse rate should be measured while the student \nis seated, and the second pulse rate should be measured while the student is standing. Us-\ning the pulse rates measured while seated, construct a frequency distribution and histogram \nfor the pulse rates of males, and then construct another frequency distribution and histo-\ngram for the pulse rates of females. Using the pulse rates measured while standing, construct \na frequency distribution and histogram for the pulse rates of males, and then construct another \nfrequency distribution and histogram for the pulse rates of females. Compare the results. Do \nmales and females appear to have different pulse rates? Do pulse rates measured while seated \nappear to be different from pulse rates measured while standing? Use an appropriate graph to \ndetermine whether there is a relationship between sitting pulse rate and standing pulse rate.\n2. In-class activity Given below are the ages of motorcyclists at the time they were fatally \ninjured in traffic accidents (based on data from the U.S. Department of Transportation). If your \nobjective is to dramatize the dangers of motorcycles for young people, which graph would be \nmost effective: histogram, Pareto chart, pie chart, dotplot, stemplot, frequency polygon, time-\nseries graph? Construct the graph that best meets that objective. Is it okay to deliberately distort \ndata if the objective is one such as saving lives of motorcyclists?\n17 38 27 14 18 34 16 42 28 24 40 20 23 31\n37 21 30 25 17 28 33 25 23 19 51 18 29\n3. Out-of-class activity In each group of three or four students, select one of the following \nitems and construct a graph that is effective in addressing the question:\na. Is there a difference between the body mass index (BMI) values for men and for women? \n(See Data Set 1 “Body Data” in Appendix B.)\nb. Is there a relationship between the heights of sons (or daughters) and the heights of their \nfathers (or mothers)? (See Data Set 6 “Family Heights” in Appendix B.)\n4. Out-of-class activity Search the Internet to find an example of a graph that is misleading. \nDescribe how the graph is misleading. Redraw the graph so that it depicts the information cor-\nrectly. If possible, please submit your graph to www.TriolaStats.com.\n5. Out-of-class activity Find Charles Joseph Minard’s graph describing Napoleon’s march to \nMoscow and back, and explain why Edward Tufte says that “it may well be the best graphic \never drawn.” (See The Visual Display of Quantitative Information by Edward Tufte, Graphics \nPress). Minard’s graph can be seen at www.TriolaStats.com under “Textbook Supplements.”\n6. Out-of-class activity In The Visual Display of Quantitative Information by Edward Tufte ","page_start":92,"page_end":92,"token_count":657,"section_type":"other","chapter_number":3,"chapter_title":"DESCRIBING, EXPLORING, AND COMPARING DATA","chunk_index":126}
{"chunk_id":"4f4ae2cca6cf1393","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"Moscow and back, and explain why Edward Tufte says that “it may well be the best graphic \never drawn.” (See The Visual Display of Quantitative Information by Edward Tufte, Graphics \nPress). Minard’s graph can be seen at www.TriolaStats.com under “Textbook Supplements.”\n6. Out-of-class activity In The Visual Display of Quantitative Information by Edward Tufte \n(Graphics Press), find the graph that appeared in American Education, and explain why Tufte \nsays that “this may well be the worst graphic ever to find its way into print.” The graph can be \nseen at www.TriolaStats.com under “Textbook Supplements.” Construct a graph that is effec-\ntive in depicting the same data.","page_start":92,"page_end":92,"token_count":157,"section_type":"other","chapter_number":3,"chapter_title":"DESCRIBING, EXPLORING, AND COMPARING DATA","chunk_index":127}
{"chunk_id":"db5b99ddc2e71e4a","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"75\nCHAPTER \nPROBLEM\nData Set 1 “Body Data” in Appendix B includes pulse rates \nof men and women. The full data set contains measurements \nfrom 300 adults, and the first 5 cases are printed in Appendix B. \nFigure 3-1 shows dotplots of the pulse rates categorized ac-\ncording to gender. Close examination of Figure 3-1 reveals \nthat the pulse rates consist of even numbers only. This sug-\ngests that the pulse rates were measured for 30 seconds, \nand the result was doubled to provide a pulse rate in beats \nper minute. Examine Figure 3-1 closely to see that the pulse \nrates of males tend to be generally a little lower (farther to \nthe left) than the pulse rates of females. This observation \nsuggests a hypothesis: Males have lower pulse rates than \nfemales. A conclusion about such a hypothesis should not \nbe made on the basis of a graph alone. We should consider \nDo men and women have the same pulse rates?\nMeasures of Center\nMeasures of Variation\nMeasures of Relative \nStanding and Boxplots\n3-1\n3-2\n3-3\nDescribing, Exploring, \nand Comparing Data\n3 \n","page_start":93,"page_end":93,"token_count":262,"section_type":"other","chapter_number":3,"chapter_title":"DESCRIBING, EXPLORING, AND COMPARING DATA","chunk_index":128}
{"chunk_id":"055f0a062fc41df1","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":">>>\nwhether the sample data were collected with an appropriate \nmethod. We should also consider whether the apparent dif-\nference between male pulse rates and female pulse rates is \nactually a significant difference and not just a random chance \nanomaly.\nInstead of relying solely on subjective interpretations of a \ngraph like Figure 3-1, this chapter introduces measures that \nare essential to any study of statistics. This chapter introduces \nthe mean, median, standard deviation, and variance, which \nare among the most important statistics presented in this book, \nand they are among the most important statistics in the study \nof statistics. We will use these statistics for describing, explor-\ning, and comparing the measured pulse rates for males and \nfemales in Data Set 1 “Body Data.”\nCHAPTER OBJECTIVES\nCritical Thinking and Interpretation: Going Beyond Formulas and Arithmetic\nIn this modern biostatistics course, it isn’t so important to memorize formulas or manu-\nally do messy arithmetic. We can get results with a calculator or software so that we \ncan focus on making practical sense of results through critical thinking. Although this \nchapter includes detailed steps for important procedures, it isn’t always necessary to \nmaster those steps. It is, however, generally helpful to perform a few manual calcula-\ntions before using technology, so that understanding is enhanced.\nThe methods and tools presented in this chapter are often called methods of \ndescriptive statistics, because they summarize or describe relevant characteristics of \ndata. In later chapters we use inferential statistics to make inferences, or generaliza-\ntions, about populations. Here are the chapter objectives:\nMeasures of Center\n• Develop the ability to measure the center of data by finding the mean, median, \nmode, and midrange.\n• Determine whether an outlier has a substantial effect on the mean and median.\nMeasures of Variation\n• Develop the ability to measure variation in a set of sample data by finding values of \nthe range, variance, and standard deviation.\n3-1\n3-2\nFIGURE 3-1 Dotplot of Pulse Rates of Males and Females\n76 \nCHAPTER 3 Describing, Exploring, and Comparing Data\n","page_start":94,"page_end":94,"token_count":451,"section_type":"other","chapter_number":3,"chapter_title":"DESCRIBING, EXPLORING, AND COMPARING DATA","chunk_index":129}
{"chunk_id":"fe6c79bbfd00a004","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"3-1 Measures of Center \n77\nThere are different approaches for measuring the center, so we have different defi-\nnitions for those different approaches. We begin with the mean.\nMean\nThe mean (or arithmetic mean) is generally the most important of all numerical mea-\nsurements used to describe data, and it is what many people call an average.\nKey Concept The focus of this section is to obtain a value that measures the center of \na data set. We present measures of center, including mean and median. Our objective \nhere is not only to find the value of each measure of center, but also to interpret and \nmake sense of those values. Part 1 of this section includes core concepts that should \nbe understood before considering Part 2.\nPART 1\n Basic Concepts of Measures of Center \nIn Part 1 of this section, we introduce the mean, median, mode, and midrange as dif-\nferent measures of center. Measures of center are widely used to provide representa-\ntive values that “summarize” data sets.\n3-1 \nMeasures of Center\nDEFINITION\nA measure of center is a value at the center or middle of a data set.\nDEFINITION\nThe mean (or arithmetic mean) of a set of data is the measure of center found by \nadding all of the data values and dividing the total by the number of data values.\nImportant Properties of the Mean\n \n■Sample means drawn from the same population tend to vary less than other mea-\nsures of center.\n \n■The mean of a data set uses every data value.\n• Develop the ability to interpret values of the standard deviation by applying the \nrange rule of  thumb to determine whether a particular value is significantly low or \nsignificantly high.\nMeasures of Relative Standing and Boxplots\n• Develop the ability to compute a z score and use the result to determine whether a \ngiven value x is significantly low or significantly high.\n• Identify percentile values and quartile values from a set of data.\n• Develop the ability to construct a boxplot from a set of data.\n3-3\n• Develop the ability to interpret values of the standard deviation by applying the\nrange rule of  thumb to determine whether a particular value is significantly low or \nw\nsignificantly high.\nMeasures of Relative Standing and Boxplots\n• Develop the ability to compute a z score and use the result to determine whether a\nz z\ngiven value x is \nx\nsignificantly low or \nw\nsignificantly high.\n• Identify percentile\nrc\nr\nvalues and quartile values from a set of data.\n• Develop the ability to construct a boxplot from a set of data.\ncontinued\n","page_start":95,"page_end":95,"token_count":557,"section_type":"other","chapter_number":3,"chapter_title":"DESCRIBING, EXPLORING, AND COMPARING DATA","chunk_index":130}
{"chunk_id":"a0bb891b8f2f0f93","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"78 \nCHAPTER 3 Describing, Exploring, and Comparing Data\nCalculation and Notation of the Mean\nThe definition of the mean can be expressed as Formula 3-1, in which the Greek letter \nΣ (uppercase sigma) indicates that the data values should be added, so Σ  x represents \nthe sum of all data values. The symbol n denotes the sample size, which is the number \nof data values.\nFORMULA 3-1\nMean = Σ  x\nn  d sum of all data values\nd number of data values\nIf the data are a sample from a population, the mean is denoted by x (pronounced \n“x-bar”); if the data are the entire population, the mean is denoted by m (lowercase \nGreek mu).\nDEFINITION\nA statistic is resistant if the presence of extreme values (outliers) does not cause it \nto change very much.\n \n■A disadvantage of the mean is that just one extreme value (outlier) can change \nthe value of the mean substantially. (Using the following definition, we say that \nthe mean is not resistant.)\nNOTATION Hint: Sample statistics are usually represented by English letters, \nsuch as x, and population parameters are usually represented by Greek letters, \nsuch as m.\nΣ \ndenotes the sum of a set of data values.\nx \nis the variable usually used to represent the individual data values.\nn \nrepresents the number of data values in a sample.\nN \nrepresents the number of data values in a population.\nx = Σ  x\nn  \nis the mean of a set of sample values.\nm = Σ  x\nN  \nis the mean of all values in a population.\nEXAMPLE 1  Mean\nData Set 1 “Body Data” in Appendix B includes measures of pulse rates. Find the \nmean of the first five pulse rates for males: 84, 74, 50, 60, 52 (all in beats per minute, \nor BPM).\nSOLUTION\nThe mean is computed by using Formula 3-1. First add the data values, then divide \nby the number of data values:\n x = Σx\nn\n= 84 + 74 + 50 + 60 + 52\n5\n= 320\n5\n = 64.0 BPM\nThe mean of the first five male pulse rates is 64.0 BPM.\n","page_start":96,"page_end":96,"token_count":512,"section_type":"other","chapter_number":3,"chapter_title":"DESCRIBING, EXPLORING, AND COMPARING DATA","chunk_index":131}
{"chunk_id":"31505c706c4c126d","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"3-1 Measures of Center \n79\nMedian\nThe median can be thought of loosely as a “middle value” in the sense that about half \nof the values in a data set are less than the median and half are greater than the me-\ndian. The following definition is more precise.\nCAUTION Never use the term average when referring to a measure of center. \nThe word average is often used for the mean, but it is sometimes used for other \nmeasures of center. The term average is not used by statisticians, it is not used in \nprofessional journals, and it will not be used throughout the remainder of this book \nwhen referring to a specific measure of center.\nDEFINITION\nThe median of a data set is the measure of center that is the middle value when the \noriginal data values are arranged in order of increasing (or decreasing) magnitude.\nImportant Properties of the Median\n■The median does not change by large amounts when we include just a few ex-\ntreme values, so the median is a resistant measure of center.\n■The median does not directly use every data value. (For example, if the largest \nvalue is changed to a much larger value, the median does not change.)\nCalculation and Notation of the Median\nThe median of a sample is sometimes denoted by x∼ (pronounced “x-tilde”) or M or \nMed; there isn’t a commonly accepted notation and there isn’t a special symbol for \nthe median of a population. To find the median, first sort the values (arrange them in \norder), and then follow one of these two procedures:\n1. If the number of data values is odd, the median is the number located in the ex-\nact middle of the sorted list.\n2. If the number of data values is even, the median is found by computing the \nmean of the two middle numbers in the sorted list.\nEXAMPLE 2  Median with an Odd Number of Data Values\nFind the median of the first five pulse rates for males: 84, 74, 50, 60, 52 (all in \nBPM).\nSOLUTION\nFirst sort the data values by arranging them in ascending order, as shown below:\n50 52 60 74 84\nBecause there are 5 data values, the number of data values is an odd number (5), \nso the median is the number located in the exact middle of the sorted list, which is \n60.0 BPM. The median is therefore 60.0 BPM. Note that the median of 60.0 BPM \nis different from the mean of 64.0 BPM found in Example 1.\nWhat the Median Is Not\nHarvard  \nbiologist Ste-\nphen Jay Gould \nwrote, “The \nMedian Isn’t the \nMessage.” In \nit, he describes \nhow he learned that he had ab-\ndominal mesothelioma, a form of \ncancer. He went to the library to \nlearn more, and he was shocked \nto find that mesothelioma was \nincurable, with a median survival \ntime of only eight months after ","page_start":97,"page_end":97,"token_count":650,"section_type":"other","chapter_number":3,"chapter_title":"DESCRIBING, EXPLORING, AND COMPARING DATA","chunk_index":132}
{"chunk_id":"62ae7e6f4cff92db","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"What the Median Is Not\nHarvard  \nbiologist Ste-\nphen Jay Gould \nwrote, “The \nMedian Isn’t the \nMessage.” In \nit, he describes \nhow he learned that he had ab-\ndominal mesothelioma, a form of \ncancer. He went to the library to \nlearn more, and he was shocked \nto find that mesothelioma was \nincurable, with a median survival \ntime of only eight months after \nit was discovered. Gould wrote \nthis: “I suspect that most people, \nwithout training in statistics, \nwould read such a statement as \n‘I will probably be dead in eight \nmonths’ the very conclusion that \nmust be avoided, since it isn’t \nso, and since attitude (in fighting \nthe cancer) matters so much.” \nGould went on to carefully \ninterpret the value of the median. \nHe knew that his chance of liv-\ning longer than the median was \ngood because he was young, his \ncancer was diagnosed early, and \nhe would get the best medical \ntreatment. He also reasoned that \nsome could live much longer \nthan eight months, and he saw \nno reason why he could not be \nin that group. Armed with this \nthoughtful interpretation of the \nmedian and a strong positive \nattitude, Gould lived for 20 years \nafter his diagnosis. He died of \nanother cancer not related to the \nmesothelioma.","page_start":97,"page_end":97,"token_count":304,"section_type":"other","chapter_number":3,"chapter_title":"DESCRIBING, EXPLORING, AND COMPARING DATA","chunk_index":133}
{"chunk_id":"14d74486d9427184","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"80 \nCHAPTER 3 Describing, Exploring, and Comparing Data\nMode\nThe mode isn’t used much with quantitative data, but it’s the only measure of center \nthat can be used with qualitative data (consisting of names, labels, or categories only).\nEXAMPLE 3  Median with an Even Number of Data Values\nRepeat Example 2 after including the sixth pulse rate of 62 BPM. That is, find the \nmedian of these pulse rates: 84, 74, 50, 60, 52, 62 (all in BPM).\nSOLUTION\nFirst arrange the values in ascending order: 50, 52, 60, 62, 74, 84.\nBecause the number of data values is an even number (6), the median is found by \ncomputing the mean of the two middle numbers, which are 60 and 62.\nMedian = 60 + 62\n2\n= 122\n2\n= 61.0 BPM\nThe median is 61.0 BPM.\nDEFINITION\nThe mode of a data set is the value(s) that occurs with the greatest frequency.\nImportant Properties of the Mode\n \n■The mode can be found with qualitative data.\n \n■A data set can have no mode or one mode or multiple modes.\nFinding the Mode: A data set can have one mode, more than one mode, or no mode.\n \n■When two data values occur with the same greatest frequency, each one is a \nmode and the data set is said to be bimodal.\n \n■When more than two data values occur with the same greatest frequency, each is \na mode and the data set is said to be multimodal.\n \n■When no data value is repeated, we say that there is no mode.\nEXAMPLE 4  Mode\nFind the mode of these pulse rates (in BPM):\n58 58 58 58 60 60 62 64\nSOLUTION\nThe mode is 58 BPM, because it is the pulse rate occurring most often (four times).\nIn Example 4, the mode is a single value. Here are other possible circumstances:\nTwo modes:  The pulse rates (BPM) of 58, 58, 58, 60, 60, 60, 62, 64 have two \nmodes: 58 BPM and 60 BPM.\nNo mode: \n The pulse rates of 58, 60, 64, 68, 72 have no mode because no \nvalue is repeated.\n","page_start":98,"page_end":98,"token_count":524,"section_type":"other","chapter_number":3,"chapter_title":"DESCRIBING, EXPLORING, AND COMPARING DATA","chunk_index":134}
{"chunk_id":"13d65f8724bd47b4","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"3-1 Measures of Center \n81\nMidrange\nAnother measure of center is the midrange.\nDEFINITION\nThe midrange of a data set is the measure of center that is the value midway be-\ntween the maximum and minimum values in the original data set. It is found by add-\ning the maximum data value to the minimum data value and then dividing the sum \nby 2, as in the following formula:\nMidrange = maximum data value + minimum data value\n2\nImportant Properties of the Midrange\n \n■Because the midrange uses only the maximum and minimum values, it is very \nsensitive to those extremes so the midrange is not resistant.\n \n■In practice, the midrange is rarely used, but it has three redeeming features:\n1. The midrange is very easy to compute.\n2. The midrange helps reinforce the very important point that there are several \ndifferent ways to define the center of a data set.\n3. The value of the midrange is sometimes used incorrectly for the median, so con-\nfusion can be reduced by clearly defining the midrange along with the median.\nEXAMPLE 5  Midrange\nFind the midrange of these five pulse rates for males used in Example 1: 84, 74, 50, \n60, 52 (BPM).\nSOLUTION\nThe midrange is found as follows:\n Midrange = maximum data value + minimum data value\n2\n = 84 + 50\n2\n= 67.0 BPM\nThe midrange is 67.0 BPM.\nRounding Measures of Center\nWhen calculating measures of center, we often need to round the result. We use the \nfollowing rule.\nROUND-OFF RULES FOR MEASURES OF CENTER:\n \n■For the mean, median, and midrange, carry one more decimal place than is \npresent in the original set of values.\n \n■For the mode, leave the value as is without rounding (because values of the \nmode are the same as some of the original data values).\n","page_start":99,"page_end":99,"token_count":421,"section_type":"other","chapter_number":3,"chapter_title":"DESCRIBING, EXPLORING, AND COMPARING DATA","chunk_index":135}
{"chunk_id":"6d4e730c35387c10","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"82 \nCHAPTER 3 Describing, Exploring, and Comparing Data\nWhen applying any rounding rules, round only the final answer, not intermedi-\nate values that occur during calculations. For example, the mean of 2, 3, and 5 is \n3.333333. . . , which is rounded to 3.3, which has one more decimal place than the origi-\nnal values of 2, 3, and 5. As another example, the mean of 80.4 and 80.6 is 80.50 (one \nmore decimal place than was used for the original values). Because the mode is one or \nmore of the original data values, we do not round values of the mode; we simply use \nthe same original values that are modes.\nCritical Thinking\nWe can always calculate measures of center from a sample of numbers, but we should \nalways think about whether it makes sense to do that. In Section 1-2 we noted that it \nmakes no sense to do numerical calculations with data at the nominal level of mea-\nsurement, because those data consist of names, labels, or categories only, so statistics \nsuch as the mean and median are meaningless for such data. We should also think \nabout the sampling method used to collect the data. If the sampling method is not \nsound, the statistics we obtain may be very misleading.\nEXAMPLE 6  Critical Thinking and Measures of Center\nEach of the following illustrates data for which the mean and median are not mean-\ningful statistics.\na. Zip codes of the hospitals in the United States. (The zip codes don’t measure \nor count anything. The numbers are just labels for geographic locations.)\nb. Ranks of selected medical schools: 2, 3, 7, 10, 14. (The ranks reﬂect an order-\ning, but they don’t measure or count anything.)\nc. Numbers on the jerseys of the starting defense for the Seattle Seahawks when \nthey won Super Bowl XLVIII: 31, 28, 41, 56, 25, 54, 69, 50, 91, 72, 29. (The \nnumbers on the football jerseys don’t measure or count anything; they are just \nsubstitutes for names.)\nd. Top 5 incomes of hospital chief executive oﬃcers. (Such “top 5” or “top 10” \nlists include data that are not at all representative of the larger population.)\ne. The 50 mean ages computed from the means in each of the 50 states. (If you \ncalculate the mean of those 50 values, the result is not the mean age of people \nin the entire United States. The population sizes of the 50 diﬀerent states must \nbe taken into account, as described in the weighted mean introduced in Part 2 \nof this section.)\nIn the spirit of describing, exploring, and comparing data, we provide Table 3-1, \nwhich summarizes the different measures of center for the 300 pulse rates referenced ","page_start":100,"page_end":100,"token_count":646,"section_type":"other","chapter_number":3,"chapter_title":"DESCRIBING, EXPLORING, AND COMPARING DATA","chunk_index":136}
{"chunk_id":"7209af3845627c1b","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"calculate the mean of those 50 values, the result is not the mean age of people \nin the entire United States. The population sizes of the 50 diﬀerent states must \nbe taken into account, as described in the weighted mean introduced in Part 2 \nof this section.)\nIn the spirit of describing, exploring, and comparing data, we provide Table 3-1, \nwhich summarizes the different measures of center for the 300 pulse rates referenced \nin the Chapter Problem. Figure 3-1 on page 76 suggests that males have lower pulse \nrates, and comparison of the means and medians in Table 3-1 also suggests that males \nhave lower pulse rates. The following chapters will describe other tools that can be \nused for an effective comparison.","page_start":100,"page_end":100,"token_count":162,"section_type":"other","chapter_number":3,"chapter_title":"DESCRIBING, EXPLORING, AND COMPARING DATA","chunk_index":137}
{"chunk_id":"5e8af81c02e17a08","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"3-1 Measures of Center \n83\nPART 2\n Beyond the Basics of Measures of Center\nCalculating the Mean from a Frequency Distribution\nFormula 3-2 is the same calculation for the mean that was presented in Part 1, but it \nincorporates this approach: When working with data summarized in a frequency dis-\ntribution, we make calculations possible by pretending that all sample values in each \nclass are equal to the class midpoint. Formula 3-2 is not really a new concept; it is \nsimply a variation of Formula 3-1 for the mean.\nFORMULA 3-2 MEAN FROM A FREQUENCY DISTRIBUTION\nFirst multiply each frequency and\nclass midpoint; then add the products. \n T \nx = Σ 1f ·x2\nΣ f   1Result is an approximation2\n c \nSum of frequencies\n(equal to n)\nExample 7 illustrates the procedure for finding the mean from a frequency distribution.\nTABLE 3-1 Male and Female Pulse Rates\nMale\nFemale\nMean\n69.6\n  74.0\nMedian\n68.0\n  74.0\nMode\n    66\n72, 74, 82\nMidrange\n72.0\n  70.0\nEXAMPLE 7  Computing the Mean from a Frequency Distribution\nThe first two columns of Table 3-2 on the next page constitute a frequency distribution \nsummarizing the pulse rates from males in Data Set 1 “Body Data” from Appendix B. \nUse the frequency distribution in the first two columns to find the mean.\nSOLUTION\nRemember, when working with data summarized in a frequency distribution, we \nmake calculations possible by pretending that all sample values in each class are \nequal to the class midpoint. For example, see Table 3-2 and consider the first class \ninterval of 40–54 with a frequency of 15. We pretend that each of the 15 pulse rates \nis 47 (the class midpoint). With the pulse rate of 47 repeated 15 times, we have a \ntotal of 47 # 15 = 705, as shown in the last column of Table 3-2. We can then add \nthose results to find the sum of all sample values.\nThe bottom row of Table 3-2 shows the two components we need for the cal-\nculation of the mean (as in Formula 3-2): Σf = 153 and Σ1f # x2 =  10,611. We \ncalculate the mean using Formula 3-2 as follows:\nx = Σ1 f # x2\nΣf\n= 10,611\n153\n= 69.4 BPM\ncontinued\n","page_start":101,"page_end":101,"token_count":573,"section_type":"other","chapter_number":3,"chapter_title":"DESCRIBING, EXPLORING, AND COMPARING DATA","chunk_index":138}
{"chunk_id":"1d5a48ba605a1936","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"84 \nCHAPTER 3 Describing, Exploring, and Comparing Data\nCalculating a Weighted Mean\nWhen different x data values are assigned different weights w, we can compute a \nweighted mean. Formula 3-3 can be used to compute the weighted mean.\nFORMULA 3-3\nWeighted mean: x = Σ(w # x)\nΣw\nFormula 3-3 tells us to first multiply each weight w by the corresponding value \nx, then to add the products, and then finally to divide that total by the sum of the \nweights, Σw.\nThe result of x = 69.4 BPM is an approximation because it is based on the use  \nof class midpoint values instead of the original list of pulse rates. The mean of \n69.6 BPM found by using all of the original pulse rates for males is a more accu-\nrate result.\nTABLE 3-2 Pulse Rates (BPM) of Males\nPulse Rate\nFrequency f\nClass Midpoint x\nf ~ x\n40–54\n15\n 47\n 705\n55–69\n63\n 62\n3906\n70–84\n62\n 77\n4774\n85–99\n11\n 92\n1012\n100–114\n 2\n107\n 214\nTotals:\n횺f =  153\n횺1f ~ x2 = 10,611\nEXAMPLE 8  Computing Grade-Point Average\nIn her first semester of college, a student of one of the authors took five courses. \nHer final grades along with the number of credits for each course were A (3 cred-\nits), A (4 credits), B (3 credits), C (3 credits), and F (1 credit). The grading system \nassigns quality points to letter grades as follows: A = 4; B = 3; C = 2; D = 1; \nF = 0. Compute her grade-point average.\nSOLUTION\nUse the numbers of credits as weights: w = 3, 4, 3, 3, 1. Replace the letter grades \nof A, A, B, C, and F with the corresponding quality points: x = 4, 4, 3, 2, and 0. \nWe now use Formula 3-3 as shown below. The result is a first-semester grade-point \naverage of 3.07. (In using the preceding round-off rule, the result should be rounded \nto 3.1, but it is common to round grade-point averages to two decimal places.)\n x = Σ1w # x2\nΣw\n = 13 * 42 + 14 * 42 + 13 * 32 + 13 * 22 + 11 * 02\n3 + 4 + 3 + 3 + 1\n = 43\n14 = 3.07\n","page_start":102,"page_end":102,"token_count":622,"section_type":"other","chapter_number":3,"chapter_title":"DESCRIBING, EXPLORING, AND COMPARING DATA","chunk_index":139}
{"chunk_id":"475ff1951a308509","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"3-1 Measures of Center \n85\nDescriptive Statistics\nAccess tech instructions, videos, and data sets at www.TriolaStats.com\nTECH CENTER \nStatistical Literacy and Critical Thinking \n1. Average A report includes a statement that the “average” Medical College Admission Test \n(MCAT) score of applicants to medical schools is 28.4. What is the role of the term average in \nstatistics? Should another term be used in place of average?\n2. What’s Wrong? The Centers for Disease Control and Prevention (CDC) publishes a list of \nsmoking rates in each state. If we add the 50 percentages and then divide by 50, we get 19.67%. \nIs the value of 19.67% the mean smoking rate for all of the United States? Why or why not?\n3. Measures of Center In what sense are the mean, median, mode, and midrange measures \nof “center”?\n4. Resistant Measures Here are five pulse rates (BPM) of females: 80, 94, 58, 66, 56. Find \nthe mean and median of these five values. Then find the mean and median after including a \nsixth value of 740, which is an outlier. (One of the female pulse rates is 74, but 740 is used here \nas an error resulting from an incorrect data entry.) Compare the two sets of results. How much \nwas the mean affected by the inclusion of the outlier? How much is the median affected by the \ninclusion of the outlier?\nCritical Thinking. Each of Exercises 5–16 involves some feature that is somewhat tricky. \nFind the (a) mean, (b) median, (c) mode, and (d) midrange, and then answer the given \nquestion.\n5. Charges for Births Data Set 3 “Births” in Appendix B includes total charges for births at \nfour hospitals in New York State, and the top 10 highest amounts (in dollars) are listed below. \nWhat do the results tell us about the population of all such charges?\n471,062 359,091 290,837 271,863 255,788\n247,477 232,782 197,912 183,271 155,857\n6. MCAT Score Listed below are mean MCAT scores listed in order by year, starting with the \nyear 2002. What important feature of the data is not revealed by any of the measures of center?\n27.0 26.8 27.1 27.3 27.4 27.7 28.1 27.9 28.3 28.2 28.3 28.4\n7. Football Player Numbers Listed below are the jersey numbers of 11 players randomly \nselected from the roster of the Seattle Seahawks when they won Super Bowl XLVIII. What do \nthe results tell us?\n89 91 55 7 20 99 25 81 19 82 60\n8. Football Player Weights Listed below are the weights in pounds of 11 players randomly ","page_start":103,"page_end":103,"token_count":664,"section_type":"other","chapter_number":3,"chapter_title":"DESCRIBING, EXPLORING, AND COMPARING DATA","chunk_index":140}
{"chunk_id":"68a2a39ee3479a0d","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"7. Football Player Numbers Listed below are the jersey numbers of 11 players randomly \nselected from the roster of the Seattle Seahawks when they won Super Bowl XLVIII. What do \nthe results tell us?\n89 91 55 7 20 99 25 81 19 82 60\n8. Football Player Weights Listed below are the weights in pounds of 11 players randomly \nselected from the roster of the Seattle Seahawks when they won Super Bowl XLVIII (the same \nplayers from the preceding exercise). Are the results likely to be representative of all National \nFootball League (NFL) players?\n189 254 235 225 190 305 195 202 190 252 305\n9.  Peas in a Pod Biologists conducted experiments to determine whether a deficiency \nof carbon dioxide in the soil affects the phenotypes of peas. Listed below are the pheno-\ntype codes, where 1 = smooth@yellow, 2 = smooth@green, 3 = wrinkled@yellow, and \n3-1 Basic Skills and Concepts\ncontinued","page_start":103,"page_end":103,"token_count":226,"section_type":"other","chapter_number":3,"chapter_title":"DESCRIBING, EXPLORING, AND COMPARING DATA","chunk_index":141}
{"chunk_id":"3fc6ea6e9a134425","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"86 \nCHAPTER 3 Describing, Exploring, and Comparing Data\n4 = wrinkled@green. Can the measures of center be obtained for these values? Do the results \nmake sense?\n2 1 1 1 1 1 1 4 1 2 2 1 2 3 3 2 3 1 3 1 3 1 3 2 2\n10. TV Prices A physician plans to buy a television for her large waiting room. Listed below \nare selling prices in dollars of TVs that are 60 inches or larger and rated as a “best buy” by \nConsumer Reports magazine. Are the resulting statistics representative of the population of all \nTVs that are 60 inches and larger? If you decide to buy one of these TVs, what statistic is most \nrelevant, other than the measures of central tendency?\n1800 1500 1200 1500 1400 1600 1500 950 1600 1150 1500 1750\n11. Cell Phone Radiation Listed below are the measured radiation absorption rates (in W>kg) \ncorresponding to these cell phones: iPhone 5S, BlackBerry Z30, Sanyo Vero, Optimus V, Droid \nRazr, Nokia N97, Samsung Vibrant, Sony Z750a, Kyocera Kona, LG G2, and Virgin Mobile \nSupreme. The data are from the Federal Communications Commission (FCC). The media often \nreport about the dangers of cell phone radiation as a cause of cancer. The FCC has a standard \nthat a cell phone absorption rate must be 1.6 W>kg or less. If you are planning to purchase a cell \nphone, are any of the measures of center the most important statistic? Is there another statistic \nthat is most relevant? If so, which one?\n1.18 1.41 1.49 1.04 1.45 0.74 0.89 1.42 1.45 0.51 1.38\n12. Caffeine in Soft Drinks Listed below are measured amounts of caffeine (mg per 12 oz \nof drink) obtained in one can from each of 20 brands (7-UP, A&W Root Beer, Cherry Coke, \n. . . , Tab). Are the statistics representative of the population of all cans of the same 20 brands \nconsumed by Americans?\n0 0 34 34 34 45 41 51 55 36 47 41 0 0 53 54 38 0 41 47\n13. Firefighter Fatalities Listed below are the numbers of heroic firefighters who lost their \nlives in the United States each year while fighting forest fires. The numbers are listed in order \nby year, starting with the year 2000. What important feature of the data is not revealed by any \nof the measures of center?\n20 18 23 30 20 12 24 9 25 15 8 11 15 34\n14. Foot Lengths Listed below are foot lengths in inches of randomly selected Army women ","page_start":104,"page_end":104,"token_count":675,"section_type":"other","chapter_number":3,"chapter_title":"DESCRIBING, EXPLORING, AND COMPARING DATA","chunk_index":142}
{"chunk_id":"15f0d3576985a891","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"lives in the United States each year while fighting forest fires. The numbers are listed in order \nby year, starting with the year 2000. What important feature of the data is not revealed by any \nof the measures of center?\n20 18 23 30 20 12 24 9 25 15 8 11 15 34\n14. Foot Lengths Listed below are foot lengths in inches of randomly selected Army women \nmeasured in the 1988 Anthropometric Survey (ANSUR). Are the statistics representative of the \ncurrent population of all Army women?\n10.4 9.3 9.1 9.3 10.0 9.4 8.6 9.8 9.9 9.1 9.1\n15. Medical School Tuition Listed below in dollars are the annual costs of tuition at the 10 \nmost expensive private medical schools in the United States for a recent year (based on data \nfrom U.S. News & World Report). What does this “top 10” list tell us about those costs for the \npopulation of all U.S. private medical school tuitions?\n57,261 56,784 55,196 54,976 54,653 54,528 54,268 54,050 53,581 53,323\n16. California Smokers In the California Health Interview Survey, randomly selected adults \nare interviewed. One of the questions asks how many cigarettes are smoked per day, and results \nare listed below for 50 randomly selected respondents. How well do the results reflect the \nsmoking behavior of California adults?\n9\n10\n10\n20\n40\n50\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0","page_start":104,"page_end":104,"token_count":446,"section_type":"other","chapter_number":3,"chapter_title":"DESCRIBING, EXPLORING, AND COMPARING DATA","chunk_index":143}
{"chunk_id":"d8d56d65cd392308","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"3-1 Measures of Center \n87\nIn Exercises 17–20, find the mean and median for each of the two samples, then compare \nthe two sets of results.\n17.  Blood Pressure A sample of blood pressure measurements is taken from Data Set \n1 “Body Data” in Appendix B, and those values (mm Hg) are listed below. The values are \nmatched so that 10 subjects each have systolic and diastolic measurements. (Systolic is a mea-\nsure of the force of blood being pushed through arteries, but diastolic is a measure of blood \npressure when the heart is at rest between beats.) Are the measures of center the best statistics \nto use with these data? What else might be better?\nSystolic:\n118\n128\n158\n96\n156\n122\n116\n136\n126\n120\nDiastolic:\n 80\n 76\n 74\n52\n 90\n 88\n 58\n 64\n 72\n 82\n18. White>Red Blood Counts Listed below are white blood cell counts (1000 cells>mL) \nand red blood cell counts (million cells>mL) from different subjects (from Data Set 1 “Body \nData” in Appendix B). The values are matched so that each of the 12 subjects has a white blood \ncell count and a red blood cell count. Are the measures of center the best statistics to use with \nthese data? What else might be better?\nWhite:\n8.7\n4.9\n6.9\n7.5\n6.1\n5.7\n4.1\n8.1\n8.0\n5.6\n8.3\n6.9\nRed:\n4.8\n4.7\n4.5\n4.3\n5.0\n4.0\n4.7\n4.6\n4.1\n5.5\n4.4\n4.2\n19. White Blood Counts Listed below are white blood cell counts (1000 cells>mL) from \nmales and females (from Data Set 1 “Body Data” in Appendix B). Do they appear to be  different?\nFemale:\n8.7\n6.9\n8.1\n8.0\n6.9\n8.1\n6.4\n6.3\n10.9\n4.8\n5.9\n7.2\nMale:\n4.9\n7.5\n6.1\n5.7\n4.1\n5.6\n8.3\n5.1\n 9.5\n6.1\n5.7\n5.4\n20. Queues A Providence Hospital experiment involves two different waiting line configura-\ntions for patients arriving for admission. The waiting times (in seconds) are recorded with a \nsingle line configuration that feeds four stations and another configuration with individual lines \nat the four stations. Determine whether there is a difference between the two data sets that is \nnot apparent from a comparison of the measures of center. If so, what is it?\nSingle Line\n390\n396\n402\n408\n426\n438\n444\n462\n462\n462","page_start":105,"page_end":105,"token_count":671,"section_type":"other","chapter_number":3,"chapter_title":"DESCRIBING, EXPLORING, AND COMPARING DATA","chunk_index":144}
{"chunk_id":"1094adfa01c0d0a4","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"20. Queues A Providence Hospital experiment involves two different waiting line configura-\ntions for patients arriving for admission. The waiting times (in seconds) are recorded with a \nsingle line configuration that feeds four stations and another configuration with individual lines \nat the four stations. Determine whether there is a difference between the two data sets that is \nnot apparent from a comparison of the measures of center. If so, what is it?\nSingle Line\n390\n396\n402\n408\n426\n438\n444\n462\n462\n462\nIndividual Lines\n252\n324\n348\n372\n402\n462\n462\n510\n558\n600\nLarge Data Sets from Appendix B. In Exercises 21–24, refer to the indicated data set in \nAppendix B. Use software or a calculator to find the means and medians.\n21. HDL Use the high-density lipoprotein (HDL) cholesterol measurements (mg>dL) from the \n300 subjects included in Data Set 1 “Body Data” in Appendix B. Identify the highest value. \nDoes it appear to be an outlier? Do the mean and median change much when that highest value \nis deleted?\n22. LDL Repeat the preceding exercise using the low-density lipoprotein (LDL) measurements \n(mg>dL).\n23. Body Temperatures Refer to Data Set 2 “Body Temperatures” in Appendix B and use \nthe body temperatures for 12:00 AM on day 2. Do the results support or contradict the common \nbelief that the mean body temperature is 98.6oF?\n24. Births Use the birth weights (grams) of the 400 babies listed in Data Set 3 “Births” in \n Appendix B. Examine the list of birth weights to make an observation about those numbers. \nHow does that observation affect the way that the results should be rounded?","page_start":105,"page_end":105,"token_count":393,"section_type":"other","chapter_number":3,"chapter_title":"DESCRIBING, EXPLORING, AND COMPARING DATA","chunk_index":145}
{"chunk_id":"e78612807b85e2b5","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"88 \nCHAPTER 3 Describing, Exploring, and Comparing Data\nIn Exercises 25 and 26, find the mean of the data summarized in the frequency distribution. \nAlso, compare the computed means to the actual means obtained by using the original list \nof data values, which are as follows: (Exercise 25) 224.3; (Exercise 26) 255.1.\n25. \nBlood Platelet \nCount of Males\nFrequency\n 0–99\n 1\n100–199\n51\n200–299\n90\n300–399\n10\n400–499\n 0\n500–599\n 0\n600–699\n 1\n26. \nBlood Platelet Count \nof Females\nFrequency\n100–199\n25\n200–299\n92\n300–399\n28\n400–499\n 0\n500–599\n 2\n27. Weighted Mean A student of one of the authors earned grades of A, C, B, A, and D. \nThose courses had these corresponding numbers of credit hours: 3, 3, 3, 4, and 1. The grad-\ning system assigns quality points to letter grades as follows: A = 4; B = 3; C = 2; D = 1;\nF = 0. Compute the grade-point average (GPA) and round the result with two decimal places. \nIf the dean’s list requires a GPA of 3.00 or greater, did this student make the dean’s list?\n28. Weighted Mean A student of one of the authors earned grades of 63, 91, 88, 84, and 79 \non her five regular statistics tests. She earned a grade of 86 on the final exam and 90 on her \nclass projects. Her combined homework grade was 70. The five regular tests count for 60% \nof the final grade, the final exam counts for 10%, the project counts for 15%, and homework \ncounts for 15%. What is her weighted mean grade? What letter grade did she earn (A, B, C, D, \nor F)? Assume that a mean of 90 or above is an A, a mean of 80 to 89 is a B, and so on.\n29. Degrees of Freedom Five pulse rates randomly selected from Data Set 1 “Body Data” in \nAppendix B have a mean of 78.0 beats per minute. Four of the pulse rates are 82, 78, 56, and 84.\na. Find the missing value.\nb. We need to create a list of n values that have a specific known mean. We are free to select \nany values we desire for some of the n values. How many of the n values can be freely assigned \nbefore the remaining values are determined? (The result is referred to as the number of degrees \nof freedom.)\n30. Censored Data Recently, five U.S. presidents were still alive and after their first inaugura-\ntion, they have lived 37 years, 25 years, 21 years, 13 years, and 5 years so far. We might use the ","page_start":106,"page_end":106,"token_count":672,"section_type":"other","chapter_number":3,"chapter_title":"DESCRIBING, EXPLORING, AND COMPARING DATA","chunk_index":146}
{"chunk_id":"dd4dfd6d51149f26","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"any values we desire for some of the n values. How many of the n values can be freely assigned \nbefore the remaining values are determined? (The result is referred to as the number of degrees \nof freedom.)\n30. Censored Data Recently, five U.S. presidents were still alive and after their first inaugura-\ntion, they have lived 37 years, 25 years, 21 years, 13 years, and 5 years so far. We might use the \nvalues of 37+, 25+, 21+, 13+, and 5+, where the positive signs indicate that the actual value \nis equal to or greater than the current value. (These values are said to be censored at the current \ntime that this list was compiled.) If we ignore the presidents who took office because of an as-\nsassination or resignation and if we ignore the five presidents who are still alive, the mean of \nthe 33 remaining presidents is 15.0 years. What do we know about the mean if we include the \ncensored values of 37+, 25+, 21+, 13+, and 5+? Do the two results differ by much?\n31. Trimmed Mean Because the mean is very sensitive to extreme values, we say that it is \nnot a resistant measure of center. By deleting some low values and high values, the trimmed \nmean (or truncated mean) is more resistant. To find the 10% trimmed mean for a data set, first \narrange the data in order, next delete the bottom 10% of the values and delete the top 10% of \nthe values, and then calculate the mean of the remaining values. Use the LDL measurements \nof the 300 subjects from Data Set 1 “Body Data” in Appendix B. Compare the mean, the 10% \ntrimmed mean, and the 20% trimmed mean.\n3-1 Beyond the Basics","page_start":106,"page_end":106,"token_count":396,"section_type":"other","chapter_number":3,"chapter_title":"DESCRIBING, EXPLORING, AND COMPARING DATA","chunk_index":147}
{"chunk_id":"79d024201d724274","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"3-2 Measures of Variation \n89\nPART 1\nBasic Concepts of Variation \nTo visualize the property of variation, see Figure 3-2, which illustrates pulse rates \n(beats per minute or BPM) for subjects given a treatment and subjects given a pla-\ncebo. (A high priority is placed on using real data, but these pulse rates are fabricated \nfor the purposes of making an important point here.) Verify this important observa-\ntion: The pulse rates in the treatment group (top dotplot) have more variation than \nthose in the placebo group (bottom dotplot). Both sets of pulse rates have the same \nmean of 70.2 BPM, they have the same median of 70.0 BPM, and they have the same \nmode of 70 BPM. Those measures of center do not “see” the difference in variation.\nTo keep our round-off rules as consistent and as simple as possible, we will round \nthe measures of variation using this rule:\nKey Concept Variation is the single most important topic in statistics, so this is the \nsingle most important section in this book. This section presents three important \nmeasures of variation: range, standard deviation, and variance. These statistics are \nnumbers, but our focus is not just computing those numbers but developing the abil-\nity to interpret and understand them. This section is not a study of arithmetic; it is \nabout understanding and interpreting measures of variation, especially the standard \ndeviation.\n3-2 \nMeasures of Variation\nSTUDY HINT: Part 1 of this section presents basic concepts of variation, and \nPart 2 presents additional concepts related to the standard deviation. Part 1 \nand Part 2 both include formulas for computation, but do not spend too much \ntime memorizing formulas or doing arithmetic calculations. Instead, focus on \nunderstanding and interpreting values of standard deviation.\nROUND-OFF RULE FOR MEASURES OF VARIATION When rounding the value \nof a measure of variation, carry one more decimal place than is present in the \noriginal set of data.\nFIGURE 3-2 Dotplots of Pulse Rates\n","page_start":107,"page_end":107,"token_count":437,"section_type":"other","chapter_number":3,"chapter_title":"DESCRIBING, EXPLORING, AND COMPARING DATA","chunk_index":148}
{"chunk_id":"456a980b2fd49fe4","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"90 \nCHAPTER 3 Describing, Exploring, and Comparing Data\nRange\nLet’s begin with the range because it is quick and easy to compute, but it is not as im-\nportant as other measures of variation.\nDEFINITION\nThe range of a set of data values is the difference between the maximum data \nvalue and the minimum data value.\nRange =  1maximum data value2 − 1minimum data value2\nImportant Properties of the Range\n■The range uses only the maximum and the minimum data values, so it is very \nsensitive to extreme values. The range is not resistant.\n■Because the range uses only the maximum and minimum values, it does not take \nevery value into account and therefore does not truly reflect the variation among \nall of the data values.\nEXAMPLE 1  Range\nFind the range of the first five pulse rates for males from Data Set 1 “Body Data” in \nAppendix B: 84, 74, 50, 60, 52 (all in BPM).\nSOLUTION\nThe range is found by subtracting the lowest value from the largest value, so we get\nRange = 1maximum value2 - 1minimum value2 = 84 - 50 = 34.0 BPM\nThe range of 34.0 BPM is shown with one more decimal place than is present in the \noriginal data values.\nStandard Deviation of a Sample\nThe standard deviation is the measure of variation most commonly used in statistics.\nDEFINITION\nThe standard deviation of a set of sample values, denoted by s, is a measure  \nof how much data values deviate away from the mean. It is calculated by using  \nFormula 3-4 or 3-5. Formula 3-5 is just a different version of Formula 3-4; both for-\nmulas are algebraically the same.\nThe standard deviation found from sample data is a statistic denoted by s, but the stan-\ndard deviation found from population data is a parameter denoted by s. The formula \nfor s is slightly different with division by the population size N used instead of divi-\nsion by n - 1. The population standard deviation s will be discussed later.\nNotation\ns = sample standard deviation\ns = population standard deviation\nR\nL\np\nGot a Second?\nThe time unit \nof 1 second \nis defined \nto be “the \nduration of \n9,192,631,770 \nperiods of the \nradiation corresponding to the \ntransition between the two hy-\nperfine levels of the ground state \nof the cesium-133 atom.” That \ndefinition redefines time to be \nbased on the behavior of atoms \ninstead of the earth’s motion. It \nresults in accuracy of ±1 second \nin 10,000,000 years, which is the \nmost accurate measurement we \nuse. Because it is so accurate, the \nsecond is being used to define \nother quantities, such as the me-\nter. The meter was once defined \nas 1>10,000,000 of the distance \nalong the surface of the earth ","page_start":108,"page_end":108,"token_count":653,"section_type":"other","chapter_number":3,"chapter_title":"DESCRIBING, EXPLORING, AND COMPARING DATA","chunk_index":149}
{"chunk_id":"910179fb3f9cdb51","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"based on the behavior of atoms \ninstead of the earth’s motion. It \nresults in accuracy of ±1 second \nin 10,000,000 years, which is the \nmost accurate measurement we \nuse. Because it is so accurate, the \nsecond is being used to define \nother quantities, such as the me-\nter. The meter was once defined \nas 1>10,000,000 of the distance \nalong the surface of the earth \nbetween the North Pole and the \nequator (passing through Paris). \nThe meter is now defined as the \nlength of the distance traveled by \nlight in a vacuum during a time \ninterval of 1>299,792,458 sec.\nWhen dealing with time mea-\nsurement devices, the traditional \nstandard deviation has been \nfound to be poor because of a \ntrend in which the mean changes \nover time. Instead, other special \nmeasures of variation are used, \nsuch as Allan variance, total vari-\nance, and TheoH.\nUnrelated to statistics but \nnonetheless interesting is the \nfact that ads for watches usually \nshow a watch with a time close \nto 10:10. That time allows the \nbrand name to be visible, and it \ncreates a subliminal image of a \nhappy face. The time of 10:10 \nhas been the industry standard \nsince the 1940s.","page_start":108,"page_end":108,"token_count":291,"section_type":"other","chapter_number":3,"chapter_title":"DESCRIBING, EXPLORING, AND COMPARING DATA","chunk_index":150}
{"chunk_id":"7da60bb3b1dc64d0","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"3-2 Measures of Variation \n91\nFORMULA 3-4\ns = B\nΣ1x - x2 2\nn - 1\n sample standard deviation\nFORMULA 3-5\ns = B\nn1Σ  x22 - 1Σ  x2 2\nn1n - 12\n shortcut formula for sample standard\n  deviation (used by calculators and software)\nLater we give the reasoning behind these formulas, but for now we recommend \nthat you use Formula 3-4 for an example or two, and then learn how to find standard \ndeviation values using a calculator or software.\nImportant Properties of Standard Deviation\n■The standard deviation is a measure of how much data values deviate away from \nthe mean.\n■The value of the standard deviation s is never negative. It is zero only when all of \nthe data values are exactly the same.\n■Larger values of s indicate greater amounts of variation.\n■The standard deviation s can increase dramatically with one or more outliers.\n■The units of the standard deviation s (such as minutes, feet, pounds) are the same \nas the units of the original data values.\n■The sample standard deviation s is a biased estimator of the population standard \ndeviation s, which means that values of the sample standard deviation s do not \ncenter around the value of s. (This is explained in Part 2.)\nExample 2 illustrates a calculation using Formula 3-4 because that formula better \nillustrates that the standard deviation is based on deviations of sample values away \nfrom the mean.\nEXAMPLE 2  Calculating Standard Deviation with Formula 3-4\nUse Formula 3-4 to find the standard deviation of the first five pulse rates for males \nfrom Data Set 1 “Body Data” in Appendix B: 84, 74, 50, 60, 52 (all in BPM).\nSOLUTION\nThe left column of Table 3-3 on the next page summarizes the general procedure \nfor finding the standard deviation using Formula 3-4, and the right column illus-\ntrates that procedure using the sample values 84, 74, 50, 60, 52. The result shown \nin Table 3-3 is 14.6 BPM, which is rounded to one more decimal place than is \npresent in the original list of sample values. Also, the units for the standard devia-\ntion are the same as the units of the original data. Because the original data values \nare all in units of BPM, the standard deviation is 14.6 BPM.\nVariation in Faces\nResearchers \ncommented \nthat “if everyone \nlooked more or \nless the same, \nthere would be \ntotal chaos.” \nThey studied \nhuman body measurements and \nfound that facial traits varied \nmore than other body traits, \nand the greatest variation oc-\ncurred within the triangle formed \nby the eyes and mouth. They \nlearned that facial traits vary \nindependently of each other. For \nexample, there is no relationship \nbetween the distance between ","page_start":109,"page_end":109,"token_count":648,"section_type":"other","chapter_number":3,"chapter_title":"DESCRIBING, EXPLORING, AND COMPARING DATA","chunk_index":151}
{"chunk_id":"5b3d8faa5eb6ba97","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"Researchers \ncommented \nthat “if everyone \nlooked more or \nless the same, \nthere would be \ntotal chaos.” \nThey studied \nhuman body measurements and \nfound that facial traits varied \nmore than other body traits, \nand the greatest variation oc-\ncurred within the triangle formed \nby the eyes and mouth. They \nlearned that facial traits vary \nindependently of each other. For \nexample, there is no relationship \nbetween the distance between \nyour eyes and how big your \nmouth is. The researchers stated \nthat our facial variation played an \nimportant role in human evolu-\ntion. (See “Morphological and \nPopulation Genomic Evidence \nThat Human Faces Have Evolved \nto Signal Individual Identity,” by \nSheehan and Nachman, Nature \nCommunications, Vol. 5,  \nNo. 4800.)","page_start":109,"page_end":109,"token_count":179,"section_type":"other","chapter_number":3,"chapter_title":"DESCRIBING, EXPLORING, AND COMPARING DATA","chunk_index":152}
{"chunk_id":"b6ce0d23a96b2f43","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"92 \nCHAPTER 3 Describing, Exploring, and Comparing Data\nTABLE 3-3\nGeneral Procedure for Finding Standard  \nDeviation with Formula 3-4\nSpecific Example Using These Sample  \nValues: 84, 74, 50, 60, 52\nStep 1: Compute the mean x.\nThe sum of 84, 74, 50, 60, 52 is 320; therefore:\n x = Σ  x\nn\n= 84 + 74 + 50 + 60 + 52\n5\n = 320\n5\n= 64.0\nStep 2: Subtract the mean from each individual \nsample value. [The result is a list of deviations \nof the form 1x - x2.]\nSubtract the mean of 64.0 from each sample \nvalue to get these deviations away from the \nmean: 20, 10, −14, −4, −12.\nStep 3: Square each of the deviations obtained \nfrom Step 2. [This produces numbers of the \nform 1x - x2 2.]\nThe squares of the deviations from Step 2 are: \n400, 100, 196, 16, 144.\nStep 4: Add all of the squares obtained from \nStep 3. The result is Σ1x - x2 2.\nThe sum of the squares from Step 3 is 856.\nStep 5: Divide the total from Step 4 by the num-\nber n - 1, which is 1 less than the total number \nof sample values present.\nWith n = 5 data values, n - 1 = 4, so we \ndivide 856 by 4 to get this result:\n856\n4\n= 214\nStep 6: Find the square root of the result of \nStep 5. The result is the standard deviation, \ndenoted by s.\nThe standard deviation is 2214 = 14.6287. \nRounding the result, we get s = 14.6 BPM.\nEXAMPLE 3  Calculating Standard Deviation with Formula 3-5\nUse Formula 3-5 to find the standard deviation of the first five pulse rates of males \nfrom Data Set 1 “Body Data”: 84, 74, 50, 60, 52.\nSOLUTION\nHere are the components needed in Formula 3-5.\nn = 5 (because there are 5 values in the sample)\nΣ  x = 320 (found by adding the original sample values)\nΣ  x2 = 21,336 (found by adding the squares of the sample values, as in\n842 + 742 + 502 + 602 + 522 = 21,336)\nUsing Formula 3-5, we get\ns = B\nn1Σ  x22 - 1Σ  x2 2\nn1n - 12\n= B\n5121,3362 - 13202 2\n515 - 12\n= B\n4280\n20\n= 14.6 BPM","page_start":110,"page_end":110,"token_count":662,"section_type":"other","chapter_number":3,"chapter_title":"DESCRIBING, EXPLORING, AND COMPARING DATA","chunk_index":153}
{"chunk_id":"6583243a61051bec","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"842 + 742 + 502 + 602 + 522 = 21,336)\nUsing Formula 3-5, we get\ns = B\nn1Σ  x22 - 1Σ  x2 2\nn1n - 12\n= B\n5121,3362 - 13202 2\n515 - 12\n= B\n4280\n20\n= 14.6 BPM\nThe result of s = 14.6 BPM is the same as the result in Example 2.\nRange Rule of Thumb for Understanding Standard Deviation\nThe range rule of thumb is a crude but simple tool for understanding and interpreting \nstandard deviation. It is based on the principle that for many data sets, the vast major-\nity (such as 95%) of sample values lie within 2 standard deviations of the mean. We \ncould improve the accuracy of this rule by taking into account such factors as the size \nof the sample and the distribution, but here we sacrifice accuracy for the sake of sim-\nplicity. The concept of significance as given below will be enhanced in later chapters, \nespecially those that include the topic of hypothesis tests, which are also called tests ","page_start":110,"page_end":110,"token_count":250,"section_type":"other","chapter_number":3,"chapter_title":"DESCRIBING, EXPLORING, AND COMPARING DATA","chunk_index":154}
{"chunk_id":"2c0f0342807ef7d9","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"3-2 Measures of Variation \n93\nof significance. The following range rule of thumb is based on the population mean m\nand the population standard deviation s, but for large and representative samples, we \ncould use x and s instead.\nRange Rule of Thumb for Identifying Significant Values\nSigniﬁcantly low values are m - 2s or lower.\nSignificantly high values are m + 2s or higher.\nValues not signiﬁcant: Between 1m - 2s2 and 1m + 2s2\nSee Figure 3-3, which illustrates the above criteria.\nValues not signiﬁcant\nSigniﬁcantly\nlow values\nSigniﬁcantly\nhigh values\nm\nm − 2s\nm + 2s\nFIGURE 3-3  Range Rule of Thumb for Identifying \nSignificant Values\nRange Rule of Thumb for Estimating a Value of the Standard Deviation s\nTo roughly estimate the standard deviation from a collection of known sample \ndata, use\ns ≈range\n4\nEXAMPLE 4  Range Rule of Thumb for Interpreting s\nUsing the 153 pulse rates of males listed in Data Set 1 “Body Data” in Appendix B, \nthe mean is x = 69.6 BPM and the standard deviation is s = 11.3 BPM. Use x and \ns as estimates of m and s, and use the range rule of thumb to find the limits separat-\ning values that are significantly low or significantly high. Then determine whether a \nmale pulse rate of 100 BPM is significantly high.\nSOLUTION\nWith a mean of 69.6 and a standard deviation of 11.3, we use the range rule of \nthumb to find values that are significantly low or significantly high as follows:\nSignificantly low values are 169.6 - 2 * 11.32 or lower, \nso significantly low values are 47.0 BPM or lower.\nSignificantly high values are 169.6 + 2 * 11.32 or higher, \nso significantly high values are 92.2 BPM or higher.\nValues not significant: Between 47.0 and 92.2 BPM\nINTERPRETATION\nBased on these results, we expect that typical pulse rates of males are between \n47.0 BPM and 92.2 BPM. Because the given value of 100 BPM falls above \n92.2 BPM, we consider it to be a significantly high pulse rate for a male.\n","page_start":111,"page_end":111,"token_count":531,"section_type":"other","chapter_number":3,"chapter_title":"DESCRIBING, EXPLORING, AND COMPARING DATA","chunk_index":155}
{"chunk_id":"d669092337ca4abb","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"94 \nCHAPTER 3 Describing, Exploring, and Comparing Data\nStandard Deviation of a Population\nThe definition of standard deviation and Formulas 3-4 and 3-5 apply to the standard \ndeviation of sample data. A slightly different formula is used to calculate the standard \ndeviation s (lowercase sigma) of a population: Instead of dividing by n - 1, we di-\nvide by the population size N, as shown here:\nPopulation standard deviation s = B\nΣ1x - m2 2\nN\nBecause we generally deal with sample data, we will usually use Formula 3-4, in \nwhich we divide by n - 1. Many calculators give both the sample standard deviation \nand the population standard deviation, but they use a variety of different notations.\nEXAMPLE 5  Range Rule of Thumb for Estimating s\nUse the range rule of thumb to estimate the standard deviation of the sample of \n153 pulse rates of males listed in Data Set 1 “Body Data” in Appendix B. Those \n153 values have a minimum of 40 BPM and a maximum of 104 BPM.\nSOLUTION\nThe range rule of thumb indicates that we can estimate the standard deviation by \nfinding the range and dividing it by 4. With a minimum of 40 BPM and a maximum \nof 104 BPM, the range rule of thumb can be used to estimate the standard deviation \ns as follows:\ns ≈range\n4\n= 104 - 40\n4\n= 16.0 BPM\nINTERPRETATION\nThe actual value of the standard deviation is s = 11.3 BPM, so the estimate of \n16.0 BPM is very roughly in the general neighborhood of the exact result. Because \nthis estimate is based on only the minimum and maximum values, it might be off by \na considerable amount.\nCAUTION When using a calculator to find standard deviation, identify the notation \nused by your particular calculator so that you get the sample standard deviation, \nnot the population standard deviation.\nVariance of a Sample and a Population\nSo far, we have used the term variation as a general description of the amount that val-\nues vary among themselves. (The terms dispersion and spread are sometimes used in-\nstead of variation.) Unlike the term variation, the term variance has a specific meaning.\nDEFINITION\nThe variance of a set of values is a measure of variation equal to the square of the \nstandard deviation.\n•  Sample variance: s2 =  square of the standard deviation s.\n•  Population variance: s2 =  square of the population standard deviation s.\n","page_start":112,"page_end":112,"token_count":559,"section_type":"other","chapter_number":3,"chapter_title":"DESCRIBING, EXPLORING, AND COMPARING DATA","chunk_index":156}
{"chunk_id":"d4ebc26b47b5b62a","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"3-2 Measures of Variation \n95\nNotation Here is a summary of notation for the standard deviation and variance:\ns = sample standard deviation\ns2 = sample variance\ns = population standard deviation\ns2 = population variance\nNote: Articles in professional journals and reports often use SD for standard deviation \nand VAR for variance.\nImportant Properties of Variance\n \n■The units of the variance are the squares of the units of the original data values. \n(If the original data values are in feet, the variance will have units of ft2; if the \noriginal data values are in seconds, the variance will have units of  sec2.)\n \n■The value of the variance can increase dramatically with the inclusion of outliers. \n(The variance is not resistant.)\n \n■The value of the variance is never negative. It is zero only when all of the data \nvalues are the same number.\n \n■The sample variance s2 is an unbiased estimator of the population variance s2, \nas described in Part 2 of this section. (The sample standard deviation s is a biased \nestimator of the population standard deviation s.)\nThe variance is a statistic used in some statistical methods, but for our present pur-\nposes, the variance has the serious disadvantage of using units that are different than \nthe units of the original data set. This makes it difficult to understand variance as it \nrelates to the original data set. Because of this property, it is better to first focus on the \nstandard deviation when trying to develop an understanding of variation.\nPART 2\nBeyond the Basics of Variation\nIn Part 2, we focus on making sense of the standard deviation so that it is not some \nmysterious number devoid of any practical significance. We begin by addressing com-\nmon questions that relate to the standard deviation.\nWhy Is Standard Deviation Defined as in Formula 3-4?\nIn measuring variation in a set of sample data, it makes sense to begin with the indi-\nvidual amounts by which values deviate from the mean. For a particular data value x, \nthe amount of deviation is x - x. It makes sense to somehow combine those devia-\ntions into one number that can serve as a measure of the variation. Adding the devia-\ntions isn’t good, because the sum will always be zero. To get a statistic that measures \nvariation, it’s necessary to avoid the canceling out of negative and positive numbers. \nOne approach is to add absolute values, as in Σ\u001ax - x \u001a. If we find the mean of that \nsum, we get the mean absolute deviation (or MAD), which is the mean distance of \nthe data from the mean:\nMean absolute deviation = Σ\u001ax - x \u001a\nn\nWhy Not Use the Mean Absolute Deviation Instead of the Standard \nDeviation? Computation of the mean absolute deviation uses absolute values, \nso it uses an operation that is not “algebraic.” (The algebraic operations include \n","page_start":113,"page_end":113,"token_count":616,"section_type":"other","chapter_number":3,"chapter_title":"DESCRIBING, EXPLORING, AND COMPARING DATA","chunk_index":157}
{"chunk_id":"fbbbd7db93ec7173","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"96 \nCHAPTER 3 Describing, Exploring, and Comparing Data\naddition, multiplication, extracting roots, and raising to powers that are integers \nor fractions.) The use of absolute values would be simple, but it would create \nalgebraic difficulties in inferential methods of statistics discussed in later chap-\nters. The standard deviation has the advantage of using only algebraic opera-\ntions. Because it is based on the square root of a sum of squares, the standard \ndeviation closely parallels distance formulas found in algebra. There are many \ninstances where a statistical procedure is based on a similar sum of squares. \nConsequently, instead of using absolute values, we square all deviations 1x - x2\nso that they are nonnegative, and those squares are used to calculate the standard \ndeviation.\nWhy Divide by n −1? After finding all of the individual values of 1x - x2 2 we \ncombine them by finding their sum. We then divide by n - 1 because there are only \nn - 1 values that can assigned without constraint. With a given mean, we can use any \nnumbers for the first n - 1 values, but the last value will then be automatically deter-\nmined. With division by n - 1, sample variances s2 tend to center around the value of \nthe population variance s2; with division by n, sample variances s2 tend to underesti-\nmate the value of the population variance s2.\nComparing Variation in Different Samples or Populations\nIt’s a good practice to compare two sample standard deviations only when the sample \nmeans are approximately the same. When comparing variation in samples or popula-\ntions with very different means, it is better to use the coefficient of variation. Also use \nthe coefficient of variation to compare variation from two samples or populations with \ndifferent scales or units of values, such as the comparison of variation of pulse rates of \nmen and heights of men. (See Example 6.)\nDEFINITION\nThe coefficient of variation (or CV) for a set of nonnegative sample or popula-\ntion data, expressed as a percent, describes the standard deviation relative to the \nmean, and is given by the following:\n \nSample \nPopulation\n \nCV = s\nx # 100% \nCV = s\nm # 100%\nROUND-OFF RULE FOR THE COEFFICIENT OF VARIATION Round the \ncoefficient of variation to one decimal place (such as 25.3%).\nEXAMPLE 6  Pulse Rates and Heights\nCompare the variation of the 153 male pulse rates listed in Data Set 1 “Body \nData” in Appendix B and the heights of the same males. For the male pulse \nrates, x = 69.6 BPM and s = 11.3 BPM; for their heights, x = 174.12 cm and \ns = 7.10 cm. Note that we want to compare variation among pulse rates to varia-\ntion among heights.\n","page_start":114,"page_end":114,"token_count":622,"section_type":"other","chapter_number":3,"chapter_title":"DESCRIBING, EXPLORING, AND COMPARING DATA","chunk_index":158}
{"chunk_id":"add7e34b716d3608","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"3-2 Measures of Variation \n97\nBiased and Unbiased Estimators\nThe sample standard deviation s is a biased estimator of the population standard de-\nviation s, which means that values of the sample standard deviation s do not tend \nto center around the value of the population standard deviation s. While individual \nvalues of s could equal or exceed s, values of s generally tend to underestimate the \nvalue of s. For example, consider an IQ test designed so that the population standard \ndeviation is 15. If you repeat the process of randomly selecting 100 subjects, giving \nthem IQ tests, and calculating the sample standard deviation s in each case, the sample \nstandard deviations that you get will tend to be less than 15, which is the population \nstandard deviation. There is no correction that allows us to fix the bias for all distribu-\ntions of data. There is a correction that allows us to fix the bias for normally distrib-\nuted populations, but it is rarely used because it is too complex and makes relatively \nminor corrections.\nThe sample variance s2 is an unbiased estimator of the population variance s2,\nwhich means that values of s2 tend to center around the value of s2 instead of system-\natically tending to overestimate or underestimate s2. Consider an IQ test designed so \nthat the population variance is 225. If you repeat the process of randomly selecting \n100 subjects, giving them IQ tests, and calculating the sample variance s2 in each \ncase, the sample variances that you obtain will tend to center around 225, which is the \npopulation variance.\nBiased estimators and unbiased estimators will be discussed more in Section 6-3.\nSOLUTION\nWe can compare the standard deviations if the same scales and units are used and \nthe two means are approximately equal, but here we have different scales and differ-\nent units of measurement, so we use the coefficients of variation:\n Male Pulse Rates:   CV = s\nx # 100% = 11.3 BPM\n69.6 BPM # 100% = 16.2%\n Male Heights:  \n CV = s\nx # 100% =\n7.10 cm\n174.12 cm # 100% = 4.1%\nWe can now see that the male pulse rates (with CV = 16.2%) vary more than male \nheights (with CV = 4.1%).\nMeasures of Variation\nAccess tech instructions, videos, and data sets at www.TriolaStats.com\nTECH CENTER \nStatistical Literacy and Critical Thinking \n1. Range Rule of Thumb for Estimating s The 20 brain volumes (cm3) from Data Set 9 \n“IQ and Brain Size” in Appendix B vary from a low of 963 cm3 to a high of 1439 cm3. Use \nthe range rule of thumb to estimate the standard deviation s and compare the result to the exact \nstandard deviation of 124.9 cm3.\n3-2 Basic Skills and Concepts\n","page_start":115,"page_end":115,"token_count":627,"section_type":"other","chapter_number":3,"chapter_title":"DESCRIBING, EXPLORING, AND COMPARING DATA","chunk_index":159}
{"chunk_id":"3504da98285267f6","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"98 \nCHAPTER 3 Describing, Exploring, and Comparing Data\n2. Range Rule of Thumb for Interpreting s The 20 brain volumes (cm3) from Data Set 9 \n“IQ and Brain Size” in Appendix B have a mean of 1126.0 cm3 and a standard deviation of \n124.9 cm3. Use the range rule of thumb to identify the limits separating values that are signifi-\ncantly low or significantly high. For such data, would a brain volume of 1440 cm3 be signifi-\ncantly high?\n3.  Variance The 20 subjects used in Data Set 9 “IQ and Brain Size” in Appendix B have \nweights with a standard deviation of 20.0414 kg. What is the variance of their weights? Include \nthe appropriate units with the result.\n4. Symbols Identify the symbols used for each of the following: (a) sample standard devia-\ntion; (b) population standard deviation; (c) sample variance; (d) population variance.\nIn Exercises 5–20, find the range, variance, and standard deviation for the given sample \ndata. Include appropriate units (such as “minutes”) in your results. (The same data were \nused in Section 3-1 where we found measures of center. Here we find measures of varia-\ntion.) Then answer the given questions.\n5. Charges for Births Data Set 3 “Births” in Appendix B includes total charges for births at \nfour hospitals in New York State, and the top 10 highest amounts (in dollars) are listed below. \nWhat do the results tell us about the population of all such charges?\n471,062 359,091 290,837 271,863 255,788\n247,477 232,782 197,912 183,271 155,857\n6. MCAT Score Listed below are mean MCAT scores listed in order by year, starting with the \nyear 2002. What important feature of the data is not revealed by any of the measures of center?\n27.0 26.8 27.1 27.3 27.4 27.7 28.1 27.9 28.3 28.2 28.3 28.4\n7. Football Player Numbers Listed below are the jersey numbers of 11 players randomly \nselected from the roster of the Seattle Seahawks when they won Super Bowl XLVIII. What do \nthe results tell us?\n89 91 55 7 20 99 25 81 19 82 60\n8. Football Player Weights Listed below are the weights (lb) of 11 players randomly selected \nfrom the roster of the Seattle Seahawks when they won Super Bowl XLVIII (the same players \nfrom the preceding exercise). Are the results likely to be representative of all NFL players?\n189 254 235 225 190 305 195 202 190 252 305\n9.  Peas in a Pod Biologists conducted experiments to determine whether a deficiency \nof carbon dioxide in the soil affects the phenotypes of peas. Listed below are the pheno-","page_start":116,"page_end":116,"token_count":669,"section_type":"other","chapter_number":3,"chapter_title":"DESCRIBING, EXPLORING, AND COMPARING DATA","chunk_index":160}
{"chunk_id":"aca834189d896ae8","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"from the roster of the Seattle Seahawks when they won Super Bowl XLVIII (the same players \nfrom the preceding exercise). Are the results likely to be representative of all NFL players?\n189 254 235 225 190 305 195 202 190 252 305\n9.  Peas in a Pod Biologists conducted experiments to determine whether a deficiency \nof carbon dioxide in the soil affects the phenotypes of peas. Listed below are the pheno-\ntype codes, where 1 = smooth @ yellow, 2 = smooth @ green, 3 = wrinkled @yellow, and \n4 = wrinkled @ green. Do the results make sense?\n2  1  1  1  1  1  1  4  1  2  2  1  2  3  3  2  3  1  3  1  3  1  3  2  2\n10. TV Prices A physician plans to buy a television for her large waiting room. Listed below \nare selling prices (in dollars) of TVs that are 60 inches or larger and rated as a “best buy” by \nConsumer Reports magazine. Are the resulting statistics representative of the population of all \nTVs that are 60 inches and larger?\n1800 1500 1200 1500 1400 1600 1500 950 1600 1150 1500 1750\n11. Cell Phone Radiation Listed below are the measured radiation absorption rates (in W>kg) \ncorresponding to these cell phones: iPhone 5S, BlackBerry Z30, Sanyo Vero, Optimus V, Droid \nRazr, Nokia N97, Samsung Vibrant, Sony Z750a, Kyocera Kona, LG G2, and Virgin Mobile \nSupreme. The data are from the Federal Communications Commission. If one of each model of \ncell phone is measured for radiation and the results are used to find the measures of variation, \nare the results typical of the population of cell phones that are in use?\n1.18 1.41 1.49 1.04 1.45 0.74 0.89 1.42 1.45 0.51 1.38","page_start":116,"page_end":116,"token_count":497,"section_type":"other","chapter_number":3,"chapter_title":"DESCRIBING, EXPLORING, AND COMPARING DATA","chunk_index":161}
{"chunk_id":"0a80820d8a269e05","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"3-2 Measures of Variation \n99\n12. Caffeine in Soft Drinks Listed below are measured amounts of caffeine (mg per 12 oz of \ndrink) obtained in one can from each of 20 brands (7-UP, A&W Root Beer, Cherry Coke, . . . , \nTab). Are the statistics representative of the population of all cans of the same 20 brands consumed \nby Americans?\n0  0  34  34  34  45  41  51  55  36  47  41 0  0  53  54  38  0  41  47\n13. Firefighter Fatalities Listed below are the numbers of heroic firefighters who lost their \nlives in the United States each year while fighting forest fires. The numbers are listed in order \nby year, starting with the year 2000. What important feature of the data is not revealed by any \nof the measures of variation?\n20 18 23 30 20 12 24 9 25 15 8 11 15 34\n14. Foot Lengths Listed below are foot lengths in inches of randomly selected Army women \nmeasured in the 1988 Anthropometric Survey (ANSUR). Are the statistics representative of the \ncurrent population of all Army women?\n10.4 9.3 9.1 9.3 10.0 9.4 8.6 9.8 9.9 9.1 9.1\n15. Medical School Tuition Listed below in dollars are the annual costs of tuition at the 10 \nmost expensive private medical schools in the United States for a recent year (based on data \nfrom U.S. News & World Report). What does this “top 10” list tell us about those costs for the \npopulation of all U.S. private medical school tuitions?\n57,261 56,784 55,196 54,976 54,653 54,528 54,268 54,050 53,581 53,323\n16. California Smokers In the California Health Interview Survey, randomly selected adults \nare interviewed. One of the questions asks how many cigarettes are smoked per day, and results \nare listed below for 50 randomly selected respondents. How well do the results reflect the \nsmoking behavior of California adults?\n9 10 10 20 40 50 1Plus 44 other values that are all 02\nIn Exercises 17–20, find the coefficient of variation for each of the two samples; then com-\npare the variation. (The same data were used in Section 3-1.)\n17.  Blood Pressure A sample of blood pressure measurements is taken from Data Set \n1 “Body Data” in Appendix B, and those values (mm Hg) are listed below. The values are \nmatched so that 10 subjects each have systolic and diastolic measurements.\nSubject:\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\nSystolic:\n118\n128\n158\n96\n156\n122\n116\n136","page_start":117,"page_end":117,"token_count":672,"section_type":"other","chapter_number":3,"chapter_title":"DESCRIBING, EXPLORING, AND COMPARING DATA","chunk_index":162}
{"chunk_id":"4bfcdcd22e30be89","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"pare the variation. (The same data were used in Section 3-1.)\n17.  Blood Pressure A sample of blood pressure measurements is taken from Data Set \n1 “Body Data” in Appendix B, and those values (mm Hg) are listed below. The values are \nmatched so that 10 subjects each have systolic and diastolic measurements.\nSubject:\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\nSystolic:\n118\n128\n158\n96\n156\n122\n116\n136\n126\n120\nDiastolic:\n 80\n 76\n 74\n52\n 90\n 88\n 58\n 64\n 72\n 82\n18. White , Red Blood Counts Listed below are white blood cell counts (1000 cells>mL) \nand red blood cell counts (million cells>mL) from different subjects (from Data Set 1 “Body \nData” in Appendix B). The values are matched so that each of the 12 subjects has a white blood \ncell count and a red blood cell count.\nWhite:\n8.7\n4.9\n6.9\n7.5\n6.1\n5.7\n4.1\n8.1\n8.0\n5.6\n8.3\n6.9\nRed:\n4.8\n4.7\n4.5\n4.3\n5.0\n4.0\n4.7\n4.6\n4.1\n5.5\n4.4\n4.2\n19.  White Blood Counts Listed below are white blood cell counts (1000 cells>mL) from \nmales and females (from Data Set 1 “Body Data” in Appendix B). Do they appear to be different?\nFemale:\n8.7\n6.9\n8.1\n8.0\n6.9\n8.1\n6.4\n6.3\n10.9\n4.8\n5.9\n7.2\nMale:\n4.9\n7.5\n6.1\n5.7\n4.1\n5.6\n8.3\n5.1\n 9.5\n6.1\n5.7\n5.4","page_start":117,"page_end":117,"token_count":479,"section_type":"other","chapter_number":3,"chapter_title":"DESCRIBING, EXPLORING, AND COMPARING DATA","chunk_index":163}
{"chunk_id":"66014008213f9663","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"100 \nCHAPTER 3 Describing, Exploring, and Comparing Data\n20. Queues A Providence Hospital experiment involves two different waiting line configura-\ntions for patients arriving for admission. The waiting times (in seconds) are recorded with a \nsingle line configuration that feeds four stations and another configuration with individual lines \nat the four stations.\nSingle Line\n390\n396\n402\n408\n426\n438\n444\n462\n462\n462\nIndividual Lines\n252\n324\n348\n372\n402\n462\n462\n510\n558\n600\nLarge Data Sets from Appendix B. In Exercises 21–24, refer to the indicated data set in \nAppendix B. Use software or a calculator to find the range, variance, and standard devia-\ntion. Express answers using appropriate units, such as “minutes.”\n21. HDL Use the HDL cholesterol measurements (mg>dL) from the 300 subjects included in \nData Set 1 “Body Data” in Appendix B. Identify the highest value. Does it appear to be an out-\nlier? Do the measures of variation change much when that highest value is deleted?\n22. LDL Repeat the preceding exercise using the LDL measurements (mg>dL).\n23. Body Temperatures Refer to Data Set 2 “Body Temperatures” in Appendix B and use \nthe body temperatures for 12:00 AM on day 2.\n24. Births Use the birth weights (grams) of the 400 babies listed in Data Set 3 “Births” in \n Appendix B. Examine the list of birth weights to make an observation about those numbers. \nHow does that observation affect the way that the results should be rounded?\nEstimating Standard Deviation with the Range Rule of Thumb. In Exercises 25–28, \nrefer to the data in the indicated exercise. After finding the range of the data, use the range \nrule of thumb to estimate the value of the standard deviation. Compare the result to the \nstandard deviation computed with all of the data.\n25. HDL Exercise 21\n26. LDL Exercise 22\n27. Body Temperatures Exercise 23\n28. Births Exercise 24\nIdentifying Significant Values with the Range Rule of Thumb. In Exercises 29–32, \nuse the range rule of thumb to identify the limits separating values that are significantly low \nor significantly high.\n29. Pulse Rates of Females Based on Data Set 1 “Body Data” in Appendix B, females \nhave pulse rates with a mean of 74.0 beats per minute and a standard deviation of 12.5 beats \nper minute. Is a female pulse rate of 44 beats per minute significantly low or significantly high? \n(All of these pulse rates are measured at rest.)\n30. Pulse Rates of Males Based on Data Set 1 “Body Data” in Appendix B, males have \npulse rates with a mean of 69.6 beats per minute and a standard deviation of 11.3 beats per \nminute. Is a male pulse rate of 50 beats per minute significantly low or significantly high? (All \nof these pulse rates are measured at rest.) Explain.","page_start":118,"page_end":118,"token_count":667,"section_type":"other","chapter_number":4,"chapter_title":"PROBABILITY","chunk_index":164}
{"chunk_id":"73c8b58c85e109a3","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"(All of these pulse rates are measured at rest.)\n30. Pulse Rates of Males Based on Data Set 1 “Body Data” in Appendix B, males have \npulse rates with a mean of 69.6 beats per minute and a standard deviation of 11.3 beats per \nminute. Is a male pulse rate of 50 beats per minute significantly low or significantly high? (All \nof these pulse rates are measured at rest.) Explain.\n31. Foot Lengths Based on Data Set 7 “Foot and Height” in Appendix B, adult males have \nfoot lengths with a mean of 27.32 cm and a standard deviation of 1.29 cm. Is the adult male \nfoot length of 30 cm significantly low or significantly high? Explain.\n32. Body Temperatures Based on Data Set 2 “Body Temperatures” in Appendix B, body \ntemperatures of adults have a mean of 98.20oF and a standard deviation of 0.62oF. Is an adult \nbody temperature of 100oF significantly low or significantly high?","page_start":118,"page_end":118,"token_count":228,"section_type":"other","chapter_number":4,"chapter_title":"PROBABILITY","chunk_index":165}
{"chunk_id":"3d11796616fe0964","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"3-2 Measures of Variation \n101\nFinding Standard Deviation from a Frequency Distribution. In Exercises 33 and 34, \nrefer to the frequency distribution in the given exercise and find the standard deviation by \nusing the formula below, where x represents the class midpoint, f represents the class fre-\nquency, and n represents the total number of sample values. Also, compare the computed \nstandard deviations to these standard deviations obtained by using Formula 3-4 with the \noriginal list of data values: (Exercise 33) 59.5; (Exercise 34) 65.4.\ns = B\nn3Σ1f # x22 4 - 3Σ1f # x2 42\nn1n - 12\n33. \nBlood Platelet \nCount of Males\n \nFrequency\n 0–99\n 1\n100–199\n51\n200–299\n90\n300–399\n10\n400–499\n 0\n500–599\n 0\n600–699\n 1\n34. \nBlood Platelet \nCount of Females\n \nFrequency\n100–199\n25\n200–299\n92\n300–399\n28\n400–499\n 0\n500–599\n 2\n35. Why Divide by n −1? Let a population consist of these values: 9 cigarettes, 10 \ncigarettes, and 20 cigarettes smoked in a day (based on data from the California Health \nInterview Survey). Assume that samples of two values are randomly selected with replace-\nment from this population. (That is, a selected value is replaced before the second selection \nis made.)\na. Find the variance s2 of the population {9 cigarettes, 10 cigarettes, 20 cigarettes}.\nb. After listing the nine different possible samples of two values selected with replacement, \nfind the sample variance s2 (which includes division by n - 1) for each of them; then find the \nmean of the nine sample variances s2.\nc. For each of the nine different possible samples of two values selected with replacement, find \nthe variance by treating each sample as if it is a population (using the formula for population \nvariance, which includes division by n); then find the mean of those nine population variances.\nd. Which approach results in values that are better estimates of s2: part (b) or part (c)? Why? \nWhen computing variances of samples, should you use division by n or n - 1?\ne. The preceding parts show that s2 is an unbiased estimator of s2. Is s an unbiased estimator \nof s? Explain.\n36. Mean Absolute Deviation Use the same population of {9 cigarettes, 10 cigarettes, \n20 cigarettes} from Exercise 35. Show that when samples of size 2 are randomly selected \nwith replacement, the samples have mean absolute deviations that do not center about the \nvalue of the mean absolute deviation of the population. What does this indicate about a \nsample mean absolute deviation being used as an estimator of the mean absolute deviation \nof a population?\n3-2  Beyond the Basics\n","page_start":119,"page_end":119,"token_count":653,"section_type":"other","chapter_number":4,"chapter_title":"PROBABILITY","chunk_index":166}
{"chunk_id":"57160d06994274a1","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"102 \nCHAPTER 3 Describing, Exploring, and Comparing Data\nKey Concept This section introduces measures of relative standing, which are num-\nbers showing the location of data values relative to the other values within the same \ndata set. The most important concept in this section is the z score, which will be used \noften in following chapters. We also discuss percentiles and quartiles, which are com-\nmon statistics, as well as another statistical graph called a boxplot.\nPART 1\n  Basics of z Scores, Percentiles, Quartiles, \nand Boxplots \nz Scores\nA z score is found by converting a value to a standardized scale, as given in the fol-\nlowing definition. This definition shows that a z score is the number of standard devia-\ntions that a data value is away from the mean. The z score is used often in Chapter 6 \nand later chapters.\n3-3 \nMeasures of Relative Standing and Boxplots\nDEFINITION\nA z score (or standard score or standardized value) is the number of standard \ndeviations that a given value x is above or below the mean. The z score is calcu-\nlated by using one of the following:\nSample\nPopulation\nz = x - x\ns\nor\nz = x - m\ns\nROUND-OFF RULE FOR z SCORES Round z scores to two decimal places  \n(such as 2.31).\nThis round-off rule is motivated by the format of standard tables in which z scores \nare expressed with two decimal places, as in Table A-2 in Appendix A. Example 1 il-\nlustrates how z scores can be used to compare values, even if they come from different \npopulations.\nImportant Properties of z Scores\n1. A z score is the number of standard deviations that a given value x is above or \nbelow the mean.\n2. z Scores are expressed as numbers with no units of measurement.\n3. A data value is significantly low if its z score is less than or equal to -2 or the \nvalue is significantly high if its z score is greater than or equal to +2.\n4. If an individual data value is less than the mean, its corresponding z score \nis a negative number.\n","page_start":120,"page_end":120,"token_count":466,"section_type":"other","chapter_number":4,"chapter_title":"PROBABILITY","chunk_index":167}
{"chunk_id":"42bd1c29310abba6","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"3-3 Measures of Relative Standing and Boxplots \n103\nUsing z Scores to Identify Significant Values In Section 3-2 we used the range \nrule of thumb to conclude that a value is significantly low or significantly high if it is \nat least 2 standard deviations away from the mean. It follows that significantly low \nvalues have z scores less than or equal to -2 and significantly high values have z \nscores greater than or equal to +2, as illustrated in Figure 3-4. Using this criterion \nwith the two individual values used in Example 1 above, we see that neither value is \nsignificant because both z scores are between -2 and +2.\nEXAMPLE 1   Comparing a Baby’s Weight and  \nAdult Body Temperature\nWhich of the following two data values is more extreme relative to the data set from \nwhich it came?\n \n■The 4000 g weight of a newborn baby (among 400 weights with sample mean \nx = 3152.0 g and sample standard deviation s = 693.4 g)\n \n■The 99°F temperature of an adult (among 106 adults with sample mean \nx = 98.20°F and sample standard deviation s = 0.62°F)\nSOLUTION\nThe 4000 g weight and the 99°F body temperature can be standardized by convert-\ning each of them to z scores as shown below.\n4000 g birth weight:\nz = x - x\ns\n= 4000 g - 3152.0 g\n693.4 g\n= 1.22\n99°F body temperature:\nz = x - x\ns\n= 99°F - 98.20°F\n0.62°F\n= 1.29\nINTERPRETATION\nThe z scores show that the 4000 g birth weight is 1.22 standard deviations above the \nmean, and the 99°F body temperature is 1.29 standard deviations above the mean. \nBecause the body temperature is farther above the mean, it is the more extreme \nvalue, but not by much. A 99°F body temperature is slightly more extreme than a \nbirth weight of 4000 g.\nValues not signiﬁcant\nSigniﬁcantly\nlow values\nSigniﬁcantly\nhigh values\nz\n−2\n−1\n2\n−3\n3\n0\n1\nFIGURE 3-4  Interpreting z Scores \nSignificant values are those with z scores …  -2.00 or Ú 2.00.\n","page_start":121,"page_end":121,"token_count":534,"section_type":"other","chapter_number":4,"chapter_title":"PROBABILITY","chunk_index":168}
{"chunk_id":"a20aedd3f845dac2","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"104 \nCHAPTER 3 Describing, Exploring, and Comparing Data\nA z score is a measure of position, in the sense that it describes the location of a \nvalue (in terms of standard deviations) relative to the mean. Percentiles and quartiles \nare other measures of position useful for comparing values within the same data set or \nbetween different sets of data.\nPercentiles\nPercentiles are one type of quantiles—or fractiles—which partition data into groups \nwith roughly the same number of values in each group.\nEXAMPLE 2  Is a Platelet Count of 75 Significantly Low?\nThe lowest platelet count in Data Set 1 “Body Data” in Appendix B is 75. (The \nplatelet counts are measured in 1000 cells>mL). Is that value significantly low? \nBased on the platelet counts from Data Set 1 in Appendix B, assume that platelet \ncounts have a mean of x = 239.4 and a standard deviation of s = 64.2.\nSOLUTION\nThe platelet count of 75 is converted to a z score as shown below:\nz = x - x\ns\n= 75 - 239.4\n64.2\n= -2.56\nINTERPRETATION\nThe platelet count of 75 converts to the z score of -2.56. Refer to Figure 3-4 to \nsee that z = -2.56 is less than -2, so the platelet count of 75 is significantly low. \n(Low platelet counts are called thrombocytopenia. What a wonderful name.)\nDEFINITION\nPercentiles are measures of location, denoted P1, P2, . . . , P99, which divide a set of \ndata into 100 groups with about 1% of the values in each group.\nThe 50th percentile, denoted P50, has about 50% of the data values below it and about \n50% of the data values above it, so the 50th percentile is the same as the median. \nThere is not universal agreement on a single procedure for calculating percentiles, but \nwe will describe relatively simple procedures for (1) finding the percentile of a data \nvalue and (2) converting a percentile to its corresponding data value. We begin with \nthe first procedure.\nFinding the Percentile of a Data Value\nThe process of finding the percentile that corresponds to a particular data value x \nis given by the following (round the result to the nearest whole number):\nPercentile of value x = number of values less than x\ntotal number of values\n# 100\nDetecting Phony Data\nA class is \ngiven the \nhomework \nassignment of \nrecording the \nresults when a \ncoin is tossed \n500 times. One dishonest stu-\ndent decides to save time by just \nmaking up the results instead of \nactually flipping a coin. Because \npeople generally cannot make \nup results that are really random, \nwe can often identify such phony \ndata. With 500 tosses of an ac-\ntual coin, it is extremely likely that ","page_start":122,"page_end":122,"token_count":651,"section_type":"other","chapter_number":4,"chapter_title":"PROBABILITY","chunk_index":169}
{"chunk_id":"9e904cf08f6d9412","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"A class is \ngiven the \nhomework \nassignment of \nrecording the \nresults when a \ncoin is tossed \n500 times. One dishonest stu-\ndent decides to save time by just \nmaking up the results instead of \nactually flipping a coin. Because \npeople generally cannot make \nup results that are really random, \nwe can often identify such phony \ndata. With 500 tosses of an ac-\ntual coin, it is extremely likely that \nyou will get a run of six heads or \nsix tails, but people almost never \ninclude such a run when they \nmake up results.\nAnother way to detect fab-\nricated data is to establish that \nthe results violate Benford’s law: \nFor many collections of data, the \nleading digits are not uniformly \ndistributed. Instead, the leading \ndigits of 1, 2,…, 9 occur with \nrates of 30%, 18%, 12%, 10%, \n8%, 7%, 6%, 5%, and 5%, re-\nspectively. (See “The Difficulty of \nFaking Data,” by Theodore Hill, \nChance, Vol. 12, No. 3.)","page_start":122,"page_end":122,"token_count":246,"section_type":"other","chapter_number":4,"chapter_title":"PROBABILITY","chunk_index":170}
{"chunk_id":"0b86fd509a4957bb","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"3-3 Measures of Relative Standing and Boxplots \n105\nExample 3 shows how to convert from a given sample value to the corresponding \npercentile. There are several different methods for the reverse procedure of converting \na given percentile to the corresponding value in the data set. The procedure we will \nuse is summarized in Figure 3-5 on the next page, which uses the following notation.\nNotation\nn \ntotal number of values in the data set\nk \npercentile being used (Example: For the 25th percentile, k = 25.)\nL \n locator that gives the position of a value (Example: For the 12th value in \nthe sorted list, L = 12.)\nPk \nkth percentile (Example: P25 is the 25th percentile.)\nTABLE 3-4 Sorted Cotinine Measures of Smokers\n  0\n  1\n  1\n  3\n 17\n 32\n 35\n 44\n 48\n 86\n 87\n103\n112\n121\n123\n130\n131\n149\n164\n167\n173\n173\n198\n208\n210\n222\n227\n234\n245\n250\n253\n265\n266\n277\n284\n289\n290\n313\n477\n491\nEXAMPLE 3  Finding a Percentile\nTable 3-4 lists the 40 cotinine measures (ng>mL) of smokers from Data Set 14 \n“Passive and Active Smoke” in Appendix B, and they are listed in order. Find the \npercentile for the cotinine level of 198 ng>mL.\nSOLUTION\nFrom the sorted list of cotinine levels in Table 3-4, we see that there are 22 values \nless than 198 ng>mL, so\nPercentile of 198 ng>mL = 22\n40 # 100 = 55\nINTERPRETATION\nA cotinine level of 198 ng>mL is in the 55th percentile. This can be interpreted \nloosely as this: A cotinine level of 198 ng>mL separates the lowest 55% of values \nfrom the highest 45% of values. We have P55 = 198 ng>mL.\nEXAMPLE 4  Converting a Percentile to a Data Value\nRefer to the sorted cotinine levels of smokers in Table 3-4 and use the procedure in \nFigure 3-5 to find the value of the 33rd percentile, P33.\ncontinued\n","page_start":123,"page_end":123,"token_count":526,"section_type":"other","chapter_number":4,"chapter_title":"PROBABILITY","chunk_index":171}
{"chunk_id":"17ba215649af1558","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"106 \nCHAPTER 3 Describing, Exploring, and Comparing Data\nThe value of Pk is the Lth\nvalue, counting from\nthe lowest.\nIs L a whole\nnumber?\nYes\nNo\nChange L by rounding it\nup to the next larger\nwhole number.\nCompute\nn 5 number of values\nk 5 percentile in question\nSort the data.\n(Arrange the data in order\nof lowest to highest.)\nStart\nL 5\nn   where\nk\n100\nThe value of the kth percentile is \nmidway between the Lth value \nand the next value in the sorted \nset of data. Find Pk by adding \nthe Lth value and the next value \nand dividing the total by 2. \nFIGURE 3-5  Converting from the kth percentile to the \ncorresponding data value\nSOLUTION\nFrom Figure 3-5, we see that the sample data are already sorted, so we can proceed \nto find the value of the locator L. In this computation we use k = 33 because we are \ntrying to find the value of the 33rd percentile. We use n = 40 because there are 40 \ndata values.\nL =\nk\n100 # n = 33\n100 # 40 = 13.2\nSince L = 13.2 is not a whole number, we proceed to the next lower box in Figure 3-5 \nwhere we change L by rounding it up from 13.2 to the next larger whole number: 14. \n(In this book we typically round off the usual way, but this is one of two cases where \nwe round up instead of rounding off.) From the bottom box we see that the value of P33 \nis the 14th value, counting from the lowest. In Table 3-4, the 14th value is 121. That is, \nP33 = 121 ng>mL. Roughly speaking, about 33% of the cotinine levels in Table 3-4 \nare less than 121 ng>mL and 67% of them are more than 121 ng>mL.\n","page_start":124,"page_end":124,"token_count":454,"section_type":"other","chapter_number":4,"chapter_title":"PROBABILITY","chunk_index":172}
{"chunk_id":"952f77ed84e1d5a3","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"3-3 Measures of Relative Standing and Boxplots \n107\nQuartiles\nJust as there are 99 percentiles that divide the data into 100 groups, there are three \nquartiles that divide the data into four groups.\nEXAMPLE 5  Converting a Percentile to a Data Value\nRefer to the sorted pulse rates in Table 3-4. Use Figure 3-5 to find the 25th percen-\ntile, denoted by P25.\nSOLUTION\nReferring to Figure 3-5, we see that the sample data are already sorted, so we can \nproceed to compute the value of the locator L. In this case, we use k = 25 because \nwe are attempting to find the value of the 25th percentile, and we use n = 40 be-\ncause there are 40 data values.\nL =\nk\n100 # n = 25\n100 # 40 = 10\nSince L = 10 is a whole number, we proceed to the box in Figure 3-5 located at the \nright. We now see that the value of the 25th percentile is midway between the Lth \n(10th) value and the next higher value in the original set of data. That is, the value \nof the 25th percentile is midway between the 10th value and the 11th value. The \n10th value in Table 3-4 is 86 and the 11th value is 87, so the value midway between \nthem is 86.5 ng>mL. We conclude that the 25th percentile is P25 = 86.5 ng>mL.\nDEFINITION\nQuartiles are measures of location, denoted Q1, Q2, and Q3,which divide a set of \ndata into four groups with about 25% of the values in each group.\nHere are descriptions of quartiles that are more accurate than those given in the \npreceding definition:\nQ1 (First quartile): \n Same value as P25. It separates the bottom 25% of the \nsorted values from the top 75%. (To be more precise, \nat least 25% of the sorted values are less than or equal \nto Q1, and at least 75% of the values are greater than or \nequal to Q1.)\nQ2 (Second quartile):  Same as P50 and same as the median. It separates the \nbottom 50% of the sorted values from the top 50%.\nQ3 (Third quartile): \n Same as P75. It separates the bottom 75% of the sorted val-\nues from the top 25%. (To be more precise, at least 75% of \nthe sorted values are less than or equal to Q3, and at least \n25% of the values are greater than or equal to Q3.)\nFinding values of quartiles can be accomplished with the same procedure used for \nfinding percentiles. Simply use the relationships shown in the margin. In Example 4 \nwe found that P25 = 86.5 ng>mL, so it follows that Q1 = 86.5 ng>mL.\nQ1 = P25\nQ2 = P50\nQ3 = P75\n","page_start":125,"page_end":125,"token_count":683,"section_type":"other","chapter_number":4,"chapter_title":"PROBABILITY","chunk_index":173}
{"chunk_id":"1ab90fd5f53a2fb3","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"108 \nCHAPTER 3 Describing, Exploring, and Comparing Data\nIn earlier sections of this chapter we described several statistics, including the \nmean, median, mode, range, and standard deviation. Some other statistics are defined \nusing quartiles and percentiles, as in the following:\nInterquartile range (or IQR) \n= Q3 - Q1\nSemi-interquartile range \n= Q3 - Q1\n2\nMidquartile \n= Q3 + Q1\n2\n10–90 percentile range \n= P90 - P10\n5-Number Summary and Boxplot\nThe values of the minimum, maximum and three quartiles 1Q1, Q2, Q32 are used for \nthe 5-number summary and the construction of boxplot graphs.\nCAUTION Just as there is not universal agreement on a procedure for finding \npercentiles, there is not universal agreement on a single procedure for calculating \nquartiles, and different technologies often yield different results. If you use a \ncalculator or software for exercises involving quartiles, you may get results that differ \nsomewhat from the answers obtained by using the procedures described here.\nDEFINITION\nFor a set of data, the 5-number summary consists of these five values:\n1. Minimum\n2. First quartile, Q1\n3. Second quartile, Q2 (same as the median)\n4. Third quartile, Q3\n5. Maximum\nEXAMPLE 6  Finding a 5-Number Summary\nUse the cotinine measurements in Table 3-4 to find the 5-number summary.\nSOLUTION\nBecause the cotinine measurements in Table 3-4 are sorted, it is easy to see that \nthe minimum is 0 ng>mL and the maximum is 491 ng>mL. The value of the first \nquartile is Q1 = 86.5 ng>mL (from Example 5). The median is equal to Q2, and it \nis 170.0 ng>mL. Also, we can find that Q3 = 251.5 ng>mL by using the procedure \nfor finding P75 (as summarized in Figure 3-5). The 5-number summary is therefore \n0, 86.5, 170.0, 251.5, and 491 (all in units of ng>mL).\nDEFINITION\nA boxplot (or box-and-whisker diagram) is a graph of a data set that consists of a \nline extending from the minimum value to the maximum value, and a box with lines \ndrawn at the first quartile Q1, the median, and the third quartile Q3. (See Figure 3-6.)\n","page_start":126,"page_end":126,"token_count":570,"section_type":"other","chapter_number":4,"chapter_title":"PROBABILITY","chunk_index":174}
{"chunk_id":"d4d6f2af0d94fad4","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"3-3 Measures of Relative Standing and Boxplots \n109\nProcedure for Constructing a Boxplot\n1. Find the 5-number summary (minimum value, Q1, Q2, Q3, maximum value).\n2. Construct a line segment extending from the minimum data value to the maxi-\nmum data value.\n3. Construct a box (rectangle) extending from Q1 to Q3, and draw a line in the \nbox at the value of Q2 (median).\nCAUTION Because there is not universal agreement on procedures for finding \nquartiles, and because boxplots are based on quartiles, different technologies may \nyield different boxplots.\nEXAMPLE 7  Constructing a Boxplot\nUse the cotinine measurements listed in Table 3-4 to construct a boxplot.\nSOLUTION\nThe boxplot uses the 5-number summary found in Example 6: 0, 86.5, 170.0, 251.5, \nand 491 (all in units of ng>mL). Figure 3-6 is the boxplot representing the cotinine \nmeasurements listed in Table 3-4.\nFIGURE 3-6 Boxplot of Cotinine Measurements (ng, mL)\nSkewness A boxplot can often be used to identify skewness (discussed in \n Section 2-2). The boxplot in Figure 3-6 isn’t exactly symmetric; it shows that the \ndata are slightly skewed to the right.\nBecause the shape of a boxplot is determined by the five values from the 5-number \nsummary, a boxplot is not a graph of the distribution of the data, and it doesn’t show \nas much detailed information as a histogram or stemplot. However, boxplots are often \ngreat for comparing two or more data sets. When using two or more boxplots for com-\nparing different data sets, graph the boxplots on the same scale so that comparisons \ncan be easily made. Methods discussed later in this book allow us to analyze com-\nparisons of data sets more formally than subjective conclusions based on a graph. It is \nalways wise to construct suitable graphs, such as histograms, dotplots, and boxplots, \nbut we should not rely solely on subjective judgments based on graphs.\nEXAMPLE 8  Comparing the Pulse Rates of Men and Women\nThe Chapter Problem involves pulse rates of men and women, and the data are \nfound in Data Set 1 “Body Data” in Appendix B. Construct boxplots of those two \ndifferent sets of pulse rates.\ncontinued\n","page_start":127,"page_end":127,"token_count":526,"section_type":"other","chapter_number":4,"chapter_title":"PROBABILITY","chunk_index":175}
{"chunk_id":"bee0d951262533fc","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"110 \nCHAPTER 3 Describing, Exploring, and Comparing Data\nOutliers\nWhen analyzing data, it is important to identify and consider outliers because they \ncan strongly affect values of some important statistics (such as the mean and standard \ndeviation), and they can also strongly affect important methods discussed later in this \nbook. In Chapter 2 we described outliers as sample values that lie very far away from \nthe vast majority of the other values in a set of data, but that description is vague and \nit does not provide specific objective criteria. Part 2 of this section includes a descrip-\ntion of modified boxplots along with a more precise definition of outliers used in the \ncontext of creating modified boxplots.\nSOLUTION\nThe Statdisk-generated boxplots are shown in Figure 3-7. The three quartiles for \nmales are all lower than the corresponding three quartiles for females, which sug-\ngests that males generally have lower pulse rates than females. The minimums and \nmaximums are not very different in the two boxplots, and we shouldn’t place too \nmuch importance on those differences because they are not very reliable measures.\nFIGURE 3-7 Boxplots of Pulse Rates of Men and Women\nCAUTION When analyzing data, always identify outliers and consider their effects, \nwhich can be substantial.\nPART 2\n Outliers and Modified Boxplots \nWe noted that the description of outliers is somewhat vague, but for the purposes of \nconstructing modified boxplots, we can consider outliers to be data values meeting \nspecific criteria based on quartiles and the interquartile range. (The interquartile range \nis often denoted by IQR, and IQR = Q3 - Q1.)\nIdentifying Outliers for Modified Boxplots\n1. Find the quartiles Q1, Q2, and Q3.\n2. Find the interquartile range (IQR), where IQR = Q3 - Q1.\n3. Evaluate 1.5 * IQR.\n4. In a modified boxplot, a data value is an outlier if it is\nabove Q3, by an amount greater than 1.5 : IQR\nor below Q1, by an amount greater than 1.5 : IQR\nModified Boxplots\nThe boxplots described earlier in Part 1 are called skeletal (or regular) boxplots, but \nsome statistical software packages provide modified boxplots, which represent outliers as \n","page_start":128,"page_end":128,"token_count":509,"section_type":"other","chapter_number":4,"chapter_title":"PROBABILITY","chunk_index":176}
{"chunk_id":"5f540e4789ee1ae2","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"3-3 Measures of Relative Standing and Boxplots \n111\nspecial points. A modified boxplot is a regular boxplot constructed with these modifi-\ncations: (1) A special symbol (such as an asterisk or point) is used to identify outliers \nas defined above, and (2) the solid horizontal line extends only as far as the minimum \ndata value that is not an outlier and the maximum data value that is not an outlier. \n(Note: Exercises involving modified boxplots are found in the “Beyond the Basics” \nexercises only.)\nEXAMPLE 9  Constructing Modified Boxplots\nUse the pulse rates of males in Data Set 1 “Body Data” from Appendix B to con-\nstruct a modified boxplot. The five-number summary is 40, 62.0, 68.0, 76.0, 104 (all \nin BPM).\nSOLUTION\nLet’s begin with the four steps for identifying outliers in a modified boxplot.\n1. Using the pulse rates of males, the three quartiles are Q1 = 62.0, the median \nis Q2 = 68.0, and Q3 = 76.0.\n2. The interquartile range is IQR = Q3 - Q1 = 76.0 - 62.0 = 14.0.\n3. 1.5 * IQR = 1.5 * 14.0 = 21.0.\n \n4. Any outliers are\n \n■Greater than Q3 = 76.0 by more than 21.0 or\n \n■Less than Q1 = 62.0 by more than 21.0.\nThis means that any outliers are greater than 97.0 or less than 41.0. We can now \nexamine the original pulse rates of males to identify any that are greater than 97.0 or \nless than 41.0. We find that the pulse rates of 102 and 104 are greater than 97.0, and \nthe pulse rate of 40 is less than 41.0. The outliers are 102, 104, and 40.\nWe can now construct the modified boxplot shown in Figure 3-8. In Figure 3-8, \nthe three outliers (40, 102, 104) are identified as special points, the three quartiles \n(62.0, 68.0, 76.0) are shown as in a regular boxplot, and the horizontal line extends \nfrom the lowest data value that is not an outlier (42) to the highest data value that is \nnot an outlier (96).\nFIGURE 3-8 Modified Boxplot of Male Pulse Rates (BPM)\nCAUTION Because there is not universal agreement on procedures for finding \nquartiles, and because modified boxplots are based on quartiles, different \ntechnologies may yield different modified boxplots.\n","page_start":129,"page_end":129,"token_count":608,"section_type":"other","chapter_number":4,"chapter_title":"PROBABILITY","chunk_index":177}
{"chunk_id":"77c15edda2c49ac7","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"112 \nCHAPTER 3 Describing, Exploring, and Comparing Data\nBoxplots, 5-Number Summary, Outliers\nAccess tech instructions, videos, and data sets at www.TriolaStats.com\nTECH CENTER \nStatistical Literacy and Critical Thinking \n1.  z Scores LeBron James, one of the most successful basketball players of all time, has \na height of 6 feet 8 inches, or 203 cm. Based on statistics from Data Set 1 “Body Data” in \n Appendix B, his height converts to the z score of 4.07. How many standard deviations is his \nheight above the mean?\n2. Heights The boxplot shown below results from the heights (cm) of males listed in Data Set \n1 “Body Data” in Appendix B. What do the numbers in that boxplot tell us?\n3. Boxplot Comparison Refer to the boxplots shown below that are drawn on the same scale. \nOne boxplot represents weights of men and the other boxplot represents weights of women. \nWhich boxplot represents weights of women? Explain.\n4. z Scores If your score on your next statistics test is converted to a z score, which of these z \nscores would you prefer: -2.00,-1.00, 0, 1.00, 2.00? Why?\nz Scores. In Exercises 5–8, express all z scores with two decimal places.\n5. Female Pulse Rates For the pulse rates of females listed in Data Set 1 “Body Data” in \nAppendix B, the mean is 74.0 BPM, the standard deviation is 12.5 BPM, and the maximum is \n104 BPM.\na. What is the difference between the maximum and the mean?\nb. How many standard deviations is that [the difference found in part (a)]?\nc. Convert the maximum pulse rate to a z score.\nd. If we consider pulse rates that convert to z scores between -2 and 2 to be neither signifi-\ncantly low nor significantly high, is the maximum pulse rate significant?\n6. Female Pulse Rates For the pulse rates of females listed in Data Set 1 “Body Data” in \nAppendix B, the mean is 74.0 BPM, the standard deviation is 12.5 BPM, and the minimum is \n36 BPM.\na. What is the difference between the minimum and the mean?\nb. How many standard deviations is that [the difference found in part (a)]?\n3-3 Basic Skills and Concepts\n","page_start":130,"page_end":130,"token_count":532,"section_type":"other","chapter_number":4,"chapter_title":"PROBABILITY","chunk_index":178}
{"chunk_id":"2c8f3849e9eb7125","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"3-3 Measures of Relative Standing and Boxplots \n113\nc. Convert the minimum pulse rate to a z score.\nd. If we consider pulse rates that convert to z scores between -2 and 2 to be neither significantly \nlow nor significantly high, is the minimum pulse rate significantly low or significantly high?\n7. Body Temperatures For the body temperatures at 12 AM on day 2 (listed in Data Set 2 \n“Body Temperatures” in Appendix B), the mean is 98.20oF, the standard deviation is 0.62oF, \nand the minimum is 96.5oF.\na. What is the difference between the minimum and the mean?\nb. How many standard deviations is that [the difference found in part (a)]?\nc. Convert the minimum temperature to a z score.\nd. If we consider body temperatures that convert to z scores between -2 and 2 to be neither \nsignificantly low nor significantly high, is the minimum body temperature significant?\n8. Body Temperatures For the body temperatures at 12 AM on day 2 (listed in Data Set 2 \n“Body Temperatures” in Appendix B), the mean is 98.20°F, the standard deviation is 0.62°F,\nand Q3 = 98.60°F.\na. What is the difference between Q3 and the mean?\nb. How many standard deviations is that [the difference found in part (a)]?\nc. Convert Q3 to a z score.\nd. If we consider temperatures that convert to z scores between -2 and 2 to be neither signifi-\ncantly low nor significantly high, is Q3 significant?\nSignificant Values. In Exercises 9–12, consider a value to be significantly low if its z \nscore is less than or equal to −2 or consider the value to be significantly high if its z score \nis greater than or equal to 2.\n9. ACT The ACT test is used to assess readiness for college. In a recent year, the mean ACT \nscore was 21.1 and the standard deviation was 5.1. Identify the ACT scores that are signifi-\ncantly low or significantly high.\n10. MCAT In a recent year, scores on the MCAT had a mean of 25.2 and a standard deviation \nof 6.4. Identify the MCAT scores that are significantly low or significantly high.\n11. Birth Weights Data Set 3 “Births” lists birth weights (g) of 400 babies. Those weights \nhave a mean of 3152.0 g and a standard deviation of 693.4 g. Identify birth weights that are \nsignificantly low or significantly high.\n12. Ergonomics in Aircraft Seats In the process of designing aircraft seats, it was found \nthat men have hip breadths with a mean of 36.6 cm and a standard deviation of 2.5 cm (based \non anthropometric survey data from Gordon, Clauser, et al.). Identify the hip breadths of men \nthat are significantly low or significantly high.","page_start":131,"page_end":131,"token_count":648,"section_type":"other","chapter_number":4,"chapter_title":"PROBABILITY","chunk_index":179}
{"chunk_id":"22f78f6483cbd229","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"significantly low or significantly high.\n12. Ergonomics in Aircraft Seats In the process of designing aircraft seats, it was found \nthat men have hip breadths with a mean of 36.6 cm and a standard deviation of 2.5 cm (based \non anthropometric survey data from Gordon, Clauser, et al.). Identify the hip breadths of men \nthat are significantly low or significantly high.\nComparing Values. In Exercises 13–16, use z scores to compare the given values.\n13. Tallest and Shortest Men The tallest living man at the time of this writing is Sultan \nKosen, who has a height of 251 cm. The shortest living man is Chandra Bahadur Dangi, who \nhas a height of 54.6 cm. Heights of men have a mean of 174.12 cm and a standard deviation of \n7.10 cm. Which of these two men has the height that is more extreme?\n14. Red Blood Cell Counts Based on Data Set 1 “Body Data” in Appendix B, males have \nred blood cell counts with a mean of 4.719 and a standard deviation of 0.490, while females \nhave red blood cell counts with a mean of 4.349 and a standard deviation of 0.402. Who has the \nhigher count relative to the sample from which it came: a male with a count of 5.58 or a female \nwith a count of 5.23? Explain.\n15. Birth Weights Based on Data Set 3 “Births” in Appendix B, newborn males have weights \nwith a mean of 3272.8 g and a standard deviation of 660.2 g. Newborn females have weights \nwith a mean of 3037.1 g and a standard deviation of 706.3 g. Who has the weight that is more \ncontinued","page_start":131,"page_end":131,"token_count":396,"section_type":"other","chapter_number":4,"chapter_title":"PROBABILITY","chunk_index":180}
{"chunk_id":"3ad10bd6a79ab719","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"114 \nCHAPTER 3 Describing, Exploring, and Comparing Data\nextreme relative to the group from which they came: a male who weighs 1500 g or a female \nwho weighs 1500 g? Who has the larger weight relative to the group from which they came?\n16. Oscars In the 87th Academy Awards, Eddie Redmayne won for best actor at the age of \n33 and Julianne Moore won for best actress at the age of 54. For all best actors, the mean age \nis 44.1 years and the standard deviation is 8.9 years. For all best actresses, the mean age is \n36.2 years and the standard deviation is 11.5 years. (All ages are determined at the time of the \nawards ceremony.) Relative to their genders, who had the more extreme age when winning the \nOscar: Eddie Redmayne or Julianne Moore? Explain.\nPercentiles. In Exercises 17–20, use the following lengths (inches) of bears (from Data \nSet 11 “Bear Measurements” in Appendix B). Find the percentile corresponding to the \ngiven length.\n36.0 37.0 40.0 40.0 41.0 43.0 43.5 46.0 46.0 47.0 48.0 48.0\n49.0 50.0 52.0 52.5 53.0 53.0 54.0 57.3 57.5 58.0 59.0 59.0\n59.0 60.0 60.5 61.0 61.0 61.5 62.0 63.0 63.0 63.0 63.5 64.0\n64.0 64.0 65.0 65.0 66.5 67.0 67.5 68.5 70.0 70.5 72.0 72.0\n72.0 72.0 73.0 73.5 75.0 76.5\n17. 61.0 in.  18. 47.0 in.  19. 70.0 in.  20. 58.0 in.\nIn Exercises 21–28, use the same list of bear lengths (in.) given for Exercises 17–20. Find \nthe indicated percentile or quartile.\n21. P60   22. Q1\n23. Q3   24. P40\n25. P50   26. P75\n27. P25   28. P85\nBoxplots. In Exercises 29–32, use the given data to construct a boxplot and identify the \n5-number summary.\n29. Foot Lengths The following are the foot lengths (cm) of 19 males (from Data Set 7 “Foot \nand Height” in Appendix B).","page_start":132,"page_end":132,"token_count":645,"section_type":"other","chapter_number":4,"chapter_title":"PROBABILITY","chunk_index":181}
{"chunk_id":"0702f5bc6218c2ed","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"23. Q3   24. P40\n25. P50   26. P75\n27. P25   28. P85\nBoxplots. In Exercises 29–32, use the given data to construct a boxplot and identify the \n5-number summary.\n29. Foot Lengths The following are the foot lengths (cm) of 19 males (from Data Set 7 “Foot \nand Height” in Appendix B).\n 25.1 25.4 25.7 25.9 26.4 26.7 26.7 26.7 26.8 27.5\n 27.8 27.9 27.9 28.1 28.6 28.7 28.8 29.2 29.2\n30.  Cell Phone Radiation Listed below are the measured radiation absorption rates (in \nW>kg) corresponding to these cell phones: iPhone 5S, BlackBerry Z30, Sanyo Vero, Optimus \nV, Droid Razr, Nokia N97, Samsung Vibrant, Sony Z750a, Kyocera Kona, LG G2, and Virgin \nMobile Supreme. The data are from the Federal Communications Commission.\n1.18 1.41 1.49 1.04 1.45 0.74 0.89 1.42 1.45 0.51 1.38\n31. Radiation in Baby Teeth Listed below are amounts of strontium-90 (in millibecquerels, \nor mBq) in a simple random sample of baby teeth obtained from Pennsylvania residents born \nafter 1979 (based on data from “An Unexpected Rise in Strontium-90 in U.S. Deciduous Teeth \nin the 1990s,” by Mangano et. al., Science of the Total Environment).\n 128 130 133 137 138 142 142 144 147 149 151 151 151 155\n 156 161 163 163 166 172\n32. Blood Pressure Measurements Fourteen different second-year medical students \nat  Bellevue Hospital measured the blood pressure of the same person. The systolic readings \n(mm Hg) are listed below.\n138 130 135 140 120 125 120 130 130 144 143 140 130 150","page_start":132,"page_end":132,"token_count":516,"section_type":"other","chapter_number":4,"chapter_title":"PROBABILITY","chunk_index":182}
{"chunk_id":"d63c7a3ebd47067f","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"Boxplots from Large Data Sets in Appendix B. In Exercises 33 and 34, use the given \ndata sets from Appendix B. Use the boxplots to compare the two data sets.\n33. BMI Use the body mass indexes (BMI) for males and use the BMI measures for females \nlisted in Data Set 1 “Body Data.”\n34. Lead and IQ Use the same scale to construct boxplots for the full IQ scores (IQF) for the \nlow lead level group and the high lead level group in Data Set 8 “IQ and Lead” in Appendix B.\n35. Outliers and Modified Boxplots Repeat Exercise 33 “BMI” using modified boxplots. \nIdentify any outliers as defined in Part 2 of this section.\n3-3 Beyond the Basics\nChapter Quick Quiz\n1. Sleep Mean As part of the National Health and Nutrition Examination Survey, subjects \nwere asked how long they slept the preceding night and the following times (hours) were re-\nported: 8, 7, 5, 7, 4, 7, 6, 7, 8, 8, 8, 6. Find the mean.\n2. Sleep Median What is the median of the sample values listed in Exercise 1?\n3. Sleep Mode What is the mode of the sample values listed in Exercise 1?\n4. Sleep Variance The standard deviation of the sample values in Exercise 1 is 1.3 hours. \nWhat is the variance (including units)?\n5. Sleep Outlier If the sleep time of 0 hours is included with the sample data given in Exercise 1, \nis it an outlier? Why or why not?\n6. Sleep z Score A larger sample of 50 sleep times (hours) has a mean of 6.3 hours and a stan-\ndard deviation of 1.4 hours. What is the z score for a sleep time of 5 hours?\n7. Sleep Q3 For a sample of 80 sleep times, approximately how many of those times are less \nthan Q3?\n8. Sleep 5-Number Summary For a sample of 100 sleep times, give the names of the val-\nues that constitute the 5-number summary. (The actual values can’t be identified; just give the \nnames of those values.)\n9. Estimating s A large sample of sleep times includes values ranging from a low of 4 hours \nto a high of 10 hours. Use the range rule of thumb to estimate the standard deviation.\n10. Sleep Notation Consider a sample of sleep times taken from the population of all adults \nliving in Alaska. Identify the symbols used for the sample mean, population mean, sample stan-\ndard deviation, population standard deviation, sample variance, and the population variance.\nReview Exercises\n1. Ergonomics When designing an eye-recognition security device, engineers must consider \nthe eye heights of standing women. (It’s easy for men to bend lower, but it’s more difficult for \nwomen to rise higher.) Listed below are the eye heights (in millimeters) obtained from a simple ","page_start":133,"page_end":133,"token_count":652,"section_type":"other","chapter_number":4,"chapter_title":"PROBABILITY","chunk_index":183}
{"chunk_id":"0e27c3322000bc33","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"dard deviation, population standard deviation, sample variance, and the population variance.\nReview Exercises\n1. Ergonomics When designing an eye-recognition security device, engineers must consider \nthe eye heights of standing women. (It’s easy for men to bend lower, but it’s more difficult for \nwomen to rise higher.) Listed below are the eye heights (in millimeters) obtained from a simple \nrandom sample of standing adult women (based on anthropometric survey data from Gordon, \nChurchill, et al.). Use the given eye heights to find the (a) mean; (b) median; (c) mode; (d) mid-\nrange; (e) range; (f) standard deviation; (g) variance.\n1550 1642 1538 1497 1571\nCHAPTER 3 Review Exercises \n115","page_start":133,"page_end":133,"token_count":175,"section_type":"other","chapter_number":4,"chapter_title":"PROBABILITY","chunk_index":184}
{"chunk_id":"25ad7949d224a5f8","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"116 \nCHAPTER 3 Describing, Exploring, and Comparing Data\n2. z Score Using the sample data from Exercise 1, find the z score corresponding to the eye \nheight of 1642 mm. Is that eye height significantly low or significantly high? Why or why not?\n3. ER Codes In an analysis of activities that resulted in brain injuries presenting at hospital \nemergency rooms (ERs), the following activities were identified by the code shown in paren-\ntheses: bicycling (12); football (14); playground (22); basketball (27); swimming (40). Find the \nmean of 12, 14, 22, 27, and 40. What is wrong with this result?\n4. Comparing Birth Weights The birth weights of a sample of males have a mean of 3273 g and \na standard deviation of 660 g. The birth weights of a sample of females have a mean of 3037 g \nand a standard deviation of 706 g (based on Data Set 3 “Births” in Appendix B). When consid-\nered among members of the same gender, which baby has the relatively larger birth weight: a \nboy with a birth weight of 3400 g or a girl with a birth weight of 3200 g? Why?\n5. Effects of an Outlier Listed below are platelet counts (1000 cells>mL) from subjects in-\ncluded in Data Set 1 “Body Data.” Identify the outlier and then comment on the effect it has \non the mean and standard deviation by finding the values of those statistics with the outlier \nincluded and then with the outlier excluded.\n263 206 185 246 188 191 308 262 198 253 646\n6. Interpreting a Boxplot Shown below is a boxplot of a sample of 30 maximal skull breadths \n(mm) measured from Egyptian skulls from around 4000 B.C. What do the numbers in the box-\nplot represent?\n7. Interpreting Standard Deviation A physician routinely makes physical examinations of \nchildren. She is concerned that a three-year-old girl has a height of only 87.8 cm. Heights of \nthree-year-old girls have a mean of 97.5 cm and a standard deviation of 6.9 cm (based on data \nfrom the National Health and Nutrition Examination Survey). Use the range rule of thumb to \nfind the limits separating heights of three-year-old girls that are significantly low or signifi-\ncantly high. Based on the result, is the height of 87.8 cm significant? Should the physician be \nconcerned?\n8. Mean or Median? A biostatistics class consists of 30 students with no income, 10 students \nwith small incomes from part-time jobs, plus a professor with a very large income that is well \ndeserved. Which is better for describing the income of a typical person in this class: mean or \nmedian? Explain.\nCumulative Review Exercises\n1. Arsenic in Rice Listed below are measured amounts (mg per serving) of arsenic in a sample ","page_start":134,"page_end":134,"token_count":650,"section_type":"other","chapter_number":4,"chapter_title":"PROBABILITY","chunk_index":185}
{"chunk_id":"10328090849a5ee1","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"8. Mean or Median? A biostatistics class consists of 30 students with no income, 10 students \nwith small incomes from part-time jobs, plus a professor with a very large income that is well \ndeserved. Which is better for describing the income of a typical person in this class: mean or \nmedian? Explain.\nCumulative Review Exercises\n1. Arsenic in Rice Listed below are measured amounts (mg per serving) of arsenic in a sample \nof servings of brown rice [data from the Food and Drug Administration (FDA)]. Construct a \nfrequency distribution. Use a class width of 2 mg, and use 0 mg as the lower class limit of the \nfirst class.\n6.1 5.4 6.9 4.9 6.6 6.3 6.7 8.2 7.8 1.5 5.4 7.3\n2. Histogram Use the frequency distribution from Exercise 1 to construct a histogram. Use \nclass midpoint values for the horizontal scale.\n3. Stemplot Use the amounts of arsenic from Exercise 1 to construct a stemplot.\n4. Descriptive Statistics Use amounts of arsenic in Exercise 1 and find the following: (a) \nmean; (b) median; (c) standard deviation; (d) variance; (e) range. Include the appropriate units \nof measurement.","page_start":134,"page_end":134,"token_count":296,"section_type":"other","chapter_number":4,"chapter_title":"PROBABILITY","chunk_index":186}
{"chunk_id":"97917b54d43b95af","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"CHAPTER 3 Cooperative Group Activities \n117\n5. a. A medical researcher has a collection of data at the nominal level of measurement and she \nwants to obtain a representative data value. Which of the following is most appropriate: mean, \nmedian, mode, or midrange? Why?\nb. A botanist wants to obtain data about the plants being grown in homes. If a sample is ob-\ntained by telephoning the first 250 people listed in the local telephone directory, what type of \nsampling is being used? (random, stratified, systematic, cluster, convenience)\nc. A botanist is experimenting with fertilizer sticks used for growing plants. She finds that the \namounts of fertilizer placed in the sticks are not very consistent, so that some fertilization lasts \nlonger than claimed, but others don’t last long enough. She wants to improve quality by making \nthe amounts of fertilizer in the sticks more consistent. When analyzing the amounts of fertil-\nizer for that purpose, which of the following statistics is most relevant: mean, median, mode, \nmidrange, standard deviation, first quartile, third quartile? Should the value of that statistic be \nraised, lowered, or left unchanged?\nTechnology Project\nFreshman 15 Refer to Data Set 10 “Freshman 15” in Appendix B, which includes results from \na study of the legend that college freshmen tend to gain around 15 pounds (or 6.8 kilograms) \nduring their freshman year. That data set includes 5 columns of data from 67 subjects. Use the \nmethods of this chapter to make relevant comparisons, then form a subjective conclusion about \nthe 15-pound (or 6.8-kilogram) weight gain. Write a brief report including your conclusions \nwith supporting graphs and statistics.\nFROM DATA TO DECISION\nSecond-Hand Smoke\nData Set 14 “Passive and Active Smoke” in Appendix B \nlists measures of cotinine from three groups of subjects: \n(1) smokers; (2) nonsmokers exposed to environmental to-\nbacco smoke; and (3) nonsmokers not exposed to environ-\nmental tobacco smoke. Cotinine is an indicator of nicotine \nabsorption.\nCritical Thinking\nUse the methods from this chapter to explore and compare \nthe cotinine measures in the three groups. Are there any \nnotable differences? Are there any outliers? What do you \nconclude about the effects that smokers have on nonsmok-\ners? Write a brief report of your conclusions, and provide \nsupporting statistical evidence.\nCooperative Group Activities\n1. In-class activity In class, each student should record two pulse rates by counting the num-\nber of heartbeats in 1 minute. The first pulse rate should be measured while the student is \nseated, and the second pulse rate should be measured while the student is standing. Use the \nmethods of this chapter to compare results. Do males and females appear to have different \npulse rates? Do pulse rates measured while seated appear to be different from pulse rates mea-\nsured while standing?\n2. Out-of-class activity Appendix B includes many real and interesting data sets. In each ","page_start":135,"page_end":135,"token_count":659,"section_type":"other","chapter_number":4,"chapter_title":"PROBABILITY","chunk_index":187}
{"chunk_id":"0f938c3033b046bc","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"seated, and the second pulse rate should be measured while the student is standing. Use the \nmethods of this chapter to compare results. Do males and females appear to have different \npulse rates? Do pulse rates measured while seated appear to be different from pulse rates mea-\nsured while standing?\n2. Out-of-class activity Appendix B includes many real and interesting data sets. In each \ngroup of three or four students, select a data set from Appendix B and analyze it using the \nmethods discussed so far in this book. Write a brief report summarizing key conclusions.\n3. Out-of-class activity In each group of three or four students, collect an original data set of \nvalues at the interval or ratio level of measurement. Provide the following: (1) a list of sample \nvalues; (2) printed software results of descriptive statistics and graphs; and (3) a written de-\nscription of the nature of the data, the method of collection, and important characteristics.","page_start":135,"page_end":135,"token_count":202,"section_type":"other","chapter_number":4,"chapter_title":"PROBABILITY","chunk_index":188}
{"chunk_id":"ef70a113dd9d5121","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"118\nBasic Concepts of \nProbability\nAddition Rule and \nMultiplication Rule\nComplements, \nConditional Probability, \nand Bayes’ Theorem\nRisks and Odds\nRates of Mortality, \nFertility, and Morbidity\nCounting\n4-1\n4-2\n4-3\n4-4\n4-5\n4-6\nDrug Testing of Job Applicants\nCHAPTER \nPROBLEM\nProbability\nApproximately 85% of U. S. companies test employees  \nand>or job applicants for drug use. A common and inexpen-\nsive (around $50) urine test is the EMIT (enzyme multiplied \nimmunoassay technique) test, which tests for the presence of \nany of five drugs: marijuana, cocaine, amphetamines, opiates, \nor phencyclidine. Most companies require that positive test \nresults be confirmed by a more reliable GC-MS (gas chroma-\ntography mass spectrometry) test.\nLike nearly all medical tests, drug tests are sometimes \nwrong. Wrong results are of two different types: (1) false posi-\ntive results and (2) false negative results. In today’s society, \nthese terms should be clearly understood. A job applicant or \n4 \n","page_start":136,"page_end":136,"token_count":264,"section_type":"other","chapter_number":4,"chapter_title":"PROBABILITY","chunk_index":189}
{"chunk_id":"428cd8668e2fe0f2","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"employee who gets a false positive result is someone who \nincorrectly appears to be using drugs when he or she is not \nactually using drugs. This type of mistake can unfairly result in \njob denial or termination of employment.\nAnalyzing the Results\nTable 4-1 includes results from 555 adults in the United States. \nIf one of the subjects from Table 4-1 is randomly selected \nfrom those who do not use drugs, what is the probability of a \nfalse positive result? If one of the subjects from Table 4-1 is \nrandomly selected from those who do not use drugs, what is \nthe probability of a true negative result? We will address such \nquestions in this chapter.\n• Prevalence: Proportion of the population having the condi-\ntion (such as drug use or disease) being considered.\n• False positive: Wrong test result that incorrectly indicates \nthat the subject has a condition when the subject does not \nhave that condition.\n• False negative: Wrong test result that incorrectly indicates \nthat the subject does not have a condition when the subject \ndoes have that condition.\n• True positive: Correct test result that indicates that a \n subject has a condition when the subject does have the \ncondition.\n• True negative: Correct test result that indicates that a sub-\nject does not have a condition when the subject does not \nhave the condition.\n• Test sensitivity: The probability of a true positive test \n result, given that the subject actually has the condition \n being tested.\n• Test specificity: The probability of a true negative test \n result, given that the subject does not have the condition \nbeing tested.\n• Positive predictive value: Probability that a subject actu-\nally has the condition, given that the test yields a positive \nresult (indicating that the condition is present).\n• Negative predictive value: Probability that the subject \ndoes not actually have the condition, given that the test \nyields a negative result (indicating that the condition is not \npresent).\nChapter Objectives \n119\nTABLE 4-1 Results from Drug Tests of Job Applicants\nPositive Test Result \n(Test shows drug use.)\nNegative Test Result \n(Test shows no drug use.)\nSubject Uses Drugs\n45\n(True Positive)\n5\n(False Negative)\nSubject Does Not Use Drugs\n25\n(False Positive)\n480\n(True Negative)\nThe main objective of this chapter is to develop a sound understanding of probability \nvalues, because those values constitute the underlying foundation on which methods \nof inferential statistics are built. The important methods of hypothesis testing com-\nmonly use P-values, which are probability values expressed as numbers between 0 \nand 1, inclusive. Smaller probability values, such as 0.01, correspond to events that \nare very unlikely. Larger probability values, such as 0.99, correspond to events that are \nvery likely. Here are the chapter objectives:\nBasic Concepts of Probability\n• Identify probabilities as values between 0 and 1, and interpret those values as \n expressions of likelihood of events.\n• Develop the ability to calculate probabilities of events.\n• Define the complement of an event and calculate the probability of that \n complement.\n4-1\nCHAPTER OBJECTIVES\n>>>\n","page_start":137,"page_end":137,"token_count":652,"section_type":"other","chapter_number":4,"chapter_title":"PROBABILITY","chunk_index":190}
{"chunk_id":"57c9e3357d21dba3","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"120 \nCHAPTER 4 Probability\nKey Concept The single most important objective of this section is to learn how to \ninterpret probability values, which are expressed as values between 0 and 1. A small \nprobability, such as 0.001, corresponds to an event that rarely occurs.\nRole of Probability in Statistics\nProbability plays a central role in the important statistical method of hypothesis \ntesting introduced later in Chapter 8. Statisticians make decisions using data by \nrejecting explanations (such as chance) based on very low probabilities. See the \nfollowing example illustrating the role of probability and a fundamental way that \nstatisticians think.\n4-1 \nBasic Concepts of Probability\nAddition Rule and Multiplication Rule\n• Develop the ability to calculate the probability that in a single trial, some event A oc-\ncurs or some event B occurs or they both occur. Apply the addition rule by correctly \nadjusting for events that are not disjoint (or are overlapping).\n• Develop the ability to calculate the probability of an event A occurring in a first trial \nand an event B occurring in a second trial. Apply the multiplication rule by adjusting \nfor events that are not independent.\n• Distinguish between independent events and dependent events.\nComplements, Conditional Probability, and Bayes’ Theorem\n• Compute the probability of “at least one” occurrence of an event A.\n• Apply the multiplication rule by computing the probability of some event, given that \nsome other event has already occurred.\nRisks and Odds\n• Compare two probabilities using measures of absolute risk reduction and  \nrelative risk.\n• Obtain a measure of risk by calculating the odds ratio.\n• Measure the practical effectiveness of a treatment by determining the “number \nneeded to treat,” which is the number of subjects that must be treated in order to \nprevent one occurrence of some event.\nRates of Mortality, Fertility, and Morbidity\n• Use rates to describe the likelihood of an event.\n• Determine mortality rates, fertility rates, and morbidity rates.\nCounting\n• Develop the ability to apply the fundamental counting rule, factorial rule, permuta-\ntions rule, and combinations rule.\n• Distinguish between circumstances requiring the permutations rule and those \n requiring the combinations rule.\n4-2\n4-3\n4-4\n4-5\n4-6\nAddition Rule and Multiplication Rule\n• Develop the ability to calculate the probability that in a single trial, some event A oc-\ncurs or some event B occurs or they both occur. Apply the addition rule by correctly\nadjusting for events that are not disjoint (or are overlapping).\n• Develop the ability to calculate the probability of an event A occurring in a first trial\nand an event B occurring in a second trial. Apply the multiplication rule by adjusting\nfor events that are not independent.\n• Distinguish between independent events and dependent events.\nComplements, Conditional Probability, and Bayes’ Theorem\n• Compute the probability of “at least one” occurrence of an event A.\n• Apply the multiplication rule by computing the probability of some event, given that\nsome other event has already occurred.\nRisks and Odds\n• Compare two probabilities using measures of absolute risk reduction and  \nrelative risk.","page_start":138,"page_end":138,"token_count":659,"section_type":"other","chapter_number":4,"chapter_title":"PROBABILITY","chunk_index":191}
{"chunk_id":"19105f4c79d7669f","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"for events that are not independent.\n• Distinguish between independent events and dependent events.\nComplements, Conditional Probability, and Bayes’ Theorem\n• Compute the probability of “at least one” occurrence of an event A.\n• Apply the multiplication rule by computing the probability of some event, given that\nsome other event has already occurred.\nRisks and Odds\n• Compare two probabilities using measures of absolute risk reduction and  \nrelative risk.\n• Obtain a measure of risk by calculating the odds ratio.\n• Measure the practical effectiveness of a treatment by determining the “number \nneeded to treat,” which is the number of subjects that must be treated in order to\nprevent one occurrence of some event.\nRates of Mortality, Fertility, and Morbidity\n• Use rates to describe the likelihood of an event.\n• Determine mortality rates, fertility rates, and morbidity rates.\nCounting\n• Develop the ability to apply the fundamental counting rule, factorial rule, permuta-\ntions rule, and combinations rule.\n• Distinguish between circumstances requiring the permutations rule and those\nrequiring the combinations rule.","page_start":138,"page_end":138,"token_count":224,"section_type":"other","chapter_number":4,"chapter_title":"PROBABILITY","chunk_index":192}
{"chunk_id":"5376c76962dbdc0b","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"4-1 Basic Concepts of Probability \n121\nINTERPRETATION\nAmong the 100 babies, 75 girls and 55 girls are both greater than the 50 girls that \nwe typically expect, but only the event of 75 girls leads us to believe that the gender \nselection method is effective. Even though there is a chance of getting 75 girls (or \nmore) in 100 births with no special treatment, the probability of that happening is so \nsmall (0.0000003) that we should reject chance as a reasonable explanation. Instead, \nit would be generally recognized that the results provide strong support for the claim \nthat the gender selection method is effective. This is exactly how statisticians think: \nThey reject explanations (such as chance) based on very low probabilities.\nEXAMPLE 1  Analyzing a Claim\nResearchers have made this claim (really, they have):\nClaim: “We have developed a gender selection method that greatly increases \nthe likelihood of a baby being a girl.”\nHypothesis Used When Testing the Preceding Claim: The method of gender \nselection has no eﬀect, so that for couples using this method, about 50% of the \nbirths result in girls.\n(The probability of a girl in the United States is actually 0.488, but here we assume \nthat boys and girls are equally likely.)\nFigure 4-1 shows the sample data from two tests of 100 couples using the \n gender selection method and the conclusion reached for each test.\n75\nGirls\nStatisticians reject explanations based on\nvery low probabilities\nTest A Result\nProbability of 75 (or more) Girls by\nchance 5 3 in 10,000,000\n5 0.0000003\nChance rejected as\nreasonable explanation\nGender selection method\nappears to be eﬀective\n25\nBoys\n55\nGirls\nTest B Result\nProbability of 55 (or more) Girls by\nchance 5 184 in 1,000\n5 0.184\nChance not rejected as\nreasonable explanation\nCannot conclude gender\nselection method is eﬀective\n45\nBoys\nDiﬀerent Gender Selection Methods\nTested with 100 Births\nFIGURE 4-1 Gender Selection Method Test Data and Conclusions\nBasics of Probability\nIn probability, we deal with procedures (such as generating male>female births or \nmanufacturing defective>nondefective pregnancy test kits) that produce outcomes.\nProbabilities That \nChallenge Intuition\nIn certain cases, \nour subjective \nestimates of \nprobability val-\nues are dramati-\ncally different \nfrom the actual \nprobabilities. \nHere is a classical example: If \nyou take a deep breath, there is \nbetter than a 99% chance that \nyou will inhale a molecule that \nwas exhaled in dying Caesar’s \nlast breath. In that same morbid \nand unintuitive spirit, if Socrates’ \nfatal cup of hemlock was mostly \nwater, then the next glass of \nwater you drink will likely contain \none of those same molecules. ","page_start":139,"page_end":139,"token_count":655,"section_type":"other","chapter_number":4,"chapter_title":"PROBABILITY","chunk_index":193}
{"chunk_id":"cd30e4138a3617ea","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"from the actual \nprobabilities. \nHere is a classical example: If \nyou take a deep breath, there is \nbetter than a 99% chance that \nyou will inhale a molecule that \nwas exhaled in dying Caesar’s \nlast breath. In that same morbid \nand unintuitive spirit, if Socrates’ \nfatal cup of hemlock was mostly \nwater, then the next glass of \nwater you drink will likely contain \none of those same molecules. \nHere’s another, less morbid \nexample that can be verified: In \nclasses of 25 students, there is \nbetter than a 50% chance that \nat least 2 students will share the \nsame birthday (day and month).","page_start":139,"page_end":139,"token_count":149,"section_type":"other","chapter_number":4,"chapter_title":"PROBABILITY","chunk_index":194}
{"chunk_id":"c433ce5e5ed3795e","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"122 \nCHAPTER 4 Probability\nExample 2 illustrates the concepts defined above.\nDEFINITIONS\nAn event is any collection of results or outcomes of a procedure.\nA simple event is an outcome or an event that cannot be further broken down into \nsimpler components.\nThe sample space for a procedure consists of all possible simple events. That is, \nthe sample space consists of all outcomes that cannot be broken down any further.\nEXAMPLE 2  Simple Event and Sample Spaces\nIn the following display, we use “b” to denote a baby boy and “g” to denote a \nbaby girl.\n \nProcedure\n \nExample of Event\nSample Space: Complete \nList of Simple Events\nSingle birth\n1 girl (simple event)\n{b, g}\n3 births\n2 boys and 1 girl (bbg, \nbgb, and gbb are all \nsimple events resulting in \n2 boys and 1 girl)\n{bbb, bbg, bgb, bgg, gbb, \ngbg, ggb, ggg}\nSimple Events:\n \n■With one birth, the result of 1 girl is a simple event and the result of 1 boy is \nanother simple event. They are individual simple events because they cannot be \nbroken down any further.\n \n■With three births, the result of 2 girls followed by a boy (ggb) is a simple event.\n \n■When rolling a single die, the outcome of 5 is a simple event, but the outcome \nof an even number is not a simple event.\nNot a Simple Event: With three births, the event of “2 girls and 1 boy” is not  \na simple event because it can occur with these diﬀerent simple events: ggb,  \ngbg, bgg.\nSample Space: With three births, the sample space consists of the eight  diﬀerent \nsimple events listed in the above table.\nThree Common Approaches to Finding the Probability of an Event\nWe first list some basic notation, and then we present three common approaches to \nfinding the probability of an event.\nNotation for Probabilities\nP denotes a probability.\nA, B, and C denote specific events.\nP(A) denotes the “probability of event A occurring.”\nThe following three approaches for finding probabilities result in values between 0 \nand 1: 0 … P1A2 … 1. Figure 4-2 shows the possible values of probabilities and the \nmore familiar and common expressions of likelihood.\nCertain\nLikely\n50–50 Chance\nUnlikely\nImpossible\n0\n0.5\n1\nFIGURE 4-2 Possible \nValues for Probabilities\n","page_start":140,"page_end":140,"token_count":555,"section_type":"other","chapter_number":4,"chapter_title":"PROBABILITY","chunk_index":195}
{"chunk_id":"290475bf8f119c6e","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"4-1 Basic Concepts of Probability \n123\n1. Relative Frequency Approximation of Probability Conduct (or observe) a \nprocedure and count the number of times that event A occurs. P(A) is then ap-\nproximated as follows:\nP1A2 =\nnumber of times A occurred\nnumber of times the procedure was repeated\nWhen referring to relative frequency approximations of probabilities, this text \nwill not distinguish between results that are exact probabilities and those that \nare approximations, so an instruction to “find the probability” could actually \nmean “estimate the probability.”\n2. Classical Approach to Probability (Requires Equally Likely Outcomes) \nIf a procedure has n different simple events that are equally likely, and if \nevent A can occur in s different ways, then\nP1A2 =\nnumber of ways A occurs\nnumber of different simple events = s\nn\nCAUTION When using the classical approach, always confirm that the outcomes \nare equally likely.\n3. Subjective Probabilities P(A), the probability of event A, is estimated by \nusing knowledge of the relevant circumstances.\nFigure 4-3 illustrates the approaches of the preceding three definitions.\n1. Relative Frequency Approach: When trying to de-\ntermine the probability that an individual car crashes in a \nyear, we must examine past results to determine the num-\nber of cars in use in a year and the number of them that \ncrashed; then we ﬁnd the ratio of the number of cars that \ncrashed to the total number of cars. For a recent year, the \nresult is a probability of 0.0480. (See Example 3.)\n2. Classical Approach: When trying to determine the \nprobability of randomly selecting three children who are \nof the same gender, there are two ways to get the same \ngenders (boy/boy/boy and girl/girl/girl) among the eight \nequally likely outcomes, so the probability is 2/8 or 1/4. \n(See Example 4.)\n3. Subjective Probability: When trying to estimate the \nprobability of someone with an appendix getting acute \nappendicitis in the next year, we know from personal ex-\nperience that the probability is quite small. Let’s estimate \nit to be, say, 0.001 (equivalent to 1 chance in 1000). (See \nExample 5.)\nFIGURE 4-3 Three Approaches to Finding a Probability\n","page_start":141,"page_end":141,"token_count":506,"section_type":"other","chapter_number":4,"chapter_title":"PROBABILITY","chunk_index":196}
{"chunk_id":"01e9b58a8fad29b0","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"124 \nCHAPTER 4 Probability\nSimulations Sometimes none of the preceding three approaches can be used. A simu-\nlation of a procedure is a process that behaves in the same ways as the procedure itself \nso that similar results are produced. Probabilities can sometimes be found by using a \nsimulation. See the Technology Project near the end of this chapter.\nRounding Probabilities Although it is difficult to develop a universal rule for round-\ning off probabilities, the following guide will apply to most problems in this text.\nROUNDING PROBABILITIES\nWhen expressing the value of a probability, either give the exact fraction or deci-\nmal or round off final decimal results to three significant digits. (Suggestion: When \na probability is not a simple fraction such as 2>3 or 5>9, express it as a decimal so \nthat the number can be better understood.) All digits in a number are significant ex-\ncept for the zeros that are included for proper placement of the decimal point. See \nthe following examples.\n■The probability of 0.4450323339 (from Example 6) has ten significant digits \n(4450323339), and it can be rounded to three significant digits as 0.445.\n■The probability of 1>3 can be left as a fraction or rounded to 0.333. (Do not \nround to 0.3.)\n■The probability of 2>8 can be expressed as 1>4 or 0.25. (Because 0.25 is exact, \nthere’s no need to express it with three significant digits as 0.250.)\nProbabilities Expressed as Percentages? Mathematically, a probability of 0.25 is \nequivalent to 25%, but there are good reasons for sticking with fractions and decimals \nand not using percentages. Professional journals almost universally express probabili-\nties as decimals, not as percentages. Later in this book, we will use probability values \ngenerated from statistical software, and they will always be in the form of decimals.\nWhen finding probabilities with the relative frequency approach, we obtain an ap-\nproximation instead of an exact value. As the total number of observations increases, \nthe corresponding approximations tend to get closer to the actual probability. This \nproperty is commonly referred to as the law of large numbers.\nLAW OF LARGE NUMBERS\nAs a procedure is repeated again and again, the relative frequency probability of \nan event tends to approach the actual probability.\nThe law of large numbers tells us that relative frequency approximations tend to get \nbetter with more observations. This law reflects a simple notion supported by common \nsense: A probability estimate based on only a few trials can be off by a substantial amount, \nbut with a very large number of trials, the estimate tends to be much more accurate.\nCAUTIONS\n1.  The law of large numbers applies to behavior over a large number of trials, and it \ndoes not apply to any one individual outcome. Gamblers sometimes foolishly lose \nlarge sums of money by incorrectly thinking that a string of losses increases the \nchances of a win on the next bet, or that a string of wins is likely to continue.","page_start":142,"page_end":142,"token_count":657,"section_type":"other","chapter_number":4,"chapter_title":"PROBABILITY","chunk_index":197}
{"chunk_id":"1d5b733bea7289ce","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"but with a very large number of trials, the estimate tends to be much more accurate.\nCAUTIONS\n1.  The law of large numbers applies to behavior over a large number of trials, and it \ndoes not apply to any one individual outcome. Gamblers sometimes foolishly lose \nlarge sums of money by incorrectly thinking that a string of losses increases the \nchances of a win on the next bet, or that a string of wins is likely to continue.\n2.  If we know nothing about the likelihood of different possible outcomes, we \nshould not assume that they are equally likely. For example, we should not think \nthat the probability of passing the next statistics test is 1>2, or 0.5 (because we \neither pass the test or do not). The actual probability depends on factors such \nas the amount of preparation and the difficulty of the test.","page_start":142,"page_end":142,"token_count":181,"section_type":"other","chapter_number":4,"chapter_title":"PROBABILITY","chunk_index":198}
{"chunk_id":"42948942f1952d3f","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"4-1 Basic Concepts of Probability \n125\nEXAMPLE 3  Relative Frequency Probability: Skydiving\nFind the probability of dying when making a skydiving jump.\nSOLUTION\nIn a recent year, there were about 3,000,000 skydiving jumps and 21 of them \n resulted in deaths. We use the relative frequency approach as follows:\nP1skydiving death2 =\nnumber of skydiving deaths\ntotal number of skydiving jumps =\n21\n3,000,0000 = 0.000007\nHere the classical approach cannot be used because the two outcomes (dying, \n surviving) are not equally likely. A subjective probability can be estimated in the \nabsence of historical data.\nEXAMPLE 4   Classical Probability: Three Children of the  \nSame Gender\nWhen three children are born, the sample space of genders is as shown in Example 1: \n{bbb, bbg, bgb, bgg, gbb, gbg, ggb, ggg}. If boys and girls are equally likely, then \nthose eight simple events are equally likely. Assuming that boys and girls are equally \nlikely, find the probability of getting three children all of the same gender when three \nchildren are born. (In reality, the probability of a boy is 0.512 instead of 0.5.)\nSOLUTION\nThe sample space {bbb, bbg, bgb, bgg, gbb, gbg, ggb, ggg} includes eight equally \nlikely outcomes, and there are exactly two outcomes in which the three children are \nof the same gender: bbb and ggg. We can use the classical approach to get\nP1three children of the same gender2 = 2\n8 = 1\n4  or  0.25\nEXAMPLE 5  Subjective Probability: Acute Appendicitis\nWhat is the probability that you will get acute appendicitis next year?\nSOLUTION\nWe could probably find past results and use the relative frequency approach, but for \nnow, in the absence of historical data on acute appendicitis, we make a subjective \nestimate. Experience suggests that the probability is quite small. Let’s estimate it to \nbe, say, 0.001 (equivalent to 1 chance in 1000). Depending on our knowledge of the \nrelevant circumstances, that subjective estimate might be reasonably accurate or it \nmight be grossly wrong.\nCAUTION Don’t make the common mistake of finding a probability value by \nmindlessly dividing a smaller number by a larger number. Instead, think carefully \nabout the numbers involved and what they represent. Carefully identify the total \nnumber of items being considered, as illustrated in Example 6.\n","page_start":143,"page_end":143,"token_count":564,"section_type":"other","chapter_number":4,"chapter_title":"PROBABILITY","chunk_index":199}
{"chunk_id":"0217d122b6e8e726","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"126 \nCHAPTER 4 Probability\nInstead of trying to determine an answer directly from the given statement, first sum-\nmarize the information in a format that allows clear understanding, such as this format:\n 3785 texted while driving\n 4720 did not text while driving\n 8505 total number of drivers in the sample\nWe can now use the relative frequency approach as follows:\n P1texting while driving2 = number of drivers who texted while driving\ntotal number of drivers in the sample\n= 3785\n8505\n = 0.445\nINTERPRETATION\nThere is a 0.445 probability that if a high school driver is randomly selected, he or \nshe texted while driving during the previous 30 days.\nEXAMPLE 6  Texting and Driving\nIn a study of U.S. high school drivers, it was found that 3785 texted while driving \nduring the previous 30 days, and 4720 did not text while driving during that same \ntime period (based on data from “Texting While Driving . . . . ,” by Olsen, Shults, \nEaton, Pediatrics, Vol. 131, No. 6). Based on these results, if a high school driver is \nrandomly selected, find the probability that he or she texted while driving during the \nprevious 30 days.\nSOLUTION\nCAUTION A common mistake is to blindly plug in numbers to get the wrong \nprobability of 3785>4720 = 0.802. We should think about what we are doing, as \nfollows.\nEXAMPLE 7  Thanksgiving Day\nIf a year is selected at random, find the probability that Thanksgiving Day in the \nUnited States will be (a) on a Wednesday or (b) on a Thursday.\nSOLUTION\na. In the United States, Thanksgiving Day always falls on the fourth Thursday  \nin November. It is therefore impossible for Thanksgiving to be on \na  Wednesday. When an event is impossible, its probability is 0. \nP(Thanksgiving on Wednesday) = 0.\nb. It is certain that a Thanksgiving Day in the United States will be on \na  Thursday. When an event is certain to occur, its probability is 1. \nP(Thanksgiving on Thursday) = 1.\nBecause any event imaginable is impossible, certain, or somewhere in between, \nit follows that the mathematical probability of any event A is 0, 1, or a number \nbetween 0 and 1 (as shown in Figure 4-2). That is, 0 … P1A2 … 1.\n","page_start":144,"page_end":144,"token_count":549,"section_type":"other","chapter_number":4,"chapter_title":"PROBABILITY","chunk_index":200}
{"chunk_id":"3b23038ffc2746a6","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"4-1 Basic Concepts of Probability \n127\nComplementary Events\nSometimes we need to find the probability that an event A does not occur.\nDEFINITION\nThe complement of event A, denoted by A, consists of all outcomes in which event \nA does not occur.\nEXAMPLE 8  Complement of Death from Skydiving\nExample 3 shows that in a recent year, there were 3,000,000 skydiving jumps and \n21 of them resulted in death. Find the probability of not dying when making a \nskydiving jump.\nSOLUTION\nAmong 3,000,000 jumps there were 21 deaths, so it follows that the other 2,999,979 \njumps were survived. We get\nP1not dying when making a skydiving jump2 = 2,999,979\n3,000,000 = 0.999993\nINTERPRETATION\nThe probability of not dying when making a skydiving jump is 0.999993.\nRelationship Between P1A2 and P1A2 If we denote the event of dying in a \n skydiving jump by D, Example 3 showed that P1D2 = 0.000007 and Example 8 \nshowed that P1D2 = 0.999993. The probability of P1D2 could be found by just sub-\ntracting P(D) from 1.\nIdentifying Significant Results with Probabilities:  \nThe Rare Event Rule for Inferential Statistics\nIf, under a given assumption, the probability of a particular observed event is \nvery small and the observed event occurs signiﬁcantly less than or signiﬁcantly \ngreater than what we typically expect with that assumption, we conclude that \nthe assumption is probably not correct.\nWe can use probabilities to identify values that are significantly low or significantly \nhigh as follows.\nUsing Probabilities to Determine When Results Are Significantly High or \nSignificantly Low\n \n■Significantly high number of successes: x successes among n trials is a signifi-\ncantly high number of successes if the probability of x or more successes is un-\nlikely with a probability of 0.05 or less. That is, x is a significantly high number \nof successes if P(x or more) … 0.05.*\n \n■Significantly low number of successes: x successes among n trials is a sig-\nnificantly low number of successes if the probability of x or fewer successes is \nunlikely with a probability of 0.05 or less. That is, x is a significantly low number \nof successes if P(x or fewer) … 0.05.*\n*The value 0.05 is not absolutely rigid. Other values, such as 0.01, could be used to distinguish between results \nthat can easily occur by chance and events that are significant.\n","page_start":145,"page_end":145,"token_count":591,"section_type":"other","chapter_number":4,"chapter_title":"PROBABILITY","chunk_index":201}
{"chunk_id":"ba0d3f56637daf9f","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"128 \nCHAPTER 4 Probability\nSee Example 1 on page 121, which illustrates the following:\n■Among 100 births, 75 girls is significantly high because the probability of 75 \nor more girls is 0.0000003, which is less than or equal to 0.05 (so the gender \nselection method appears to be effective).\n■Among 100 births, 55 girls is not significantly high because the probability of 55 \nor more girls is 0.184, which is greater than 0.05 (so the gender selection does \nnot appear to be effective).\nProbability Review\nImportant Principles and Notation for Probability\n■The probability of an event is a fraction or decimal number between 0 and 1 \ninclusive.\n■The probability of an impossible event is 0.\n■The probability of an event that is certain to occur is 1.\n■Notation: P1A2 = the probability of event A.\n■Notation: P1A2 = the probability that event A does not occur.\nStatistical Literacy and Critical Thinking \n1. Probability Rewrite the following statement with the probability expressed as a number \nwith a decimal format: “The probability of selecting someone with blue eyes is 35%.”\n2. Probability Given that the following statement is incorrect, rewrite it correctly: “The prob-\nability of a baby being born a boy is 50-50.”\n3. Births In Example 4 “Three Children of the Same Gender” it was noted that in reality, the \nprobability of a boy is 0.512 instead of 0.5. Let A denote the event of getting a boy when a baby \nis born. What is the value of P1A2?\n4. Subjective Probability Estimate the probability that the next time a physician walks into \na patient’s room and turns on a light switch, she discovers that the light bulb does work.\n5. Identifying Probability Values Which of the following are probabilities?\n0 3>5 5>3 -0.25 250% 7:3 1 50@50 5:1 0.135 2.017\n6. Penicillin “Who discovered penicillin: Sean Penn, William Penn, Penn Jillette, Alexander \nFleming, or Louis Pasteur?” If you make a random guess for the answer to that question, what \nis the probability that your answer is the correct answer of Alexander Fleming?\n7. Avogadro Constant If you are asked on a quiz to give the first (leftmost) nonzero digit \nof the Avogadro constant and, not knowing the answer, you make a random guess, what is the \nprobability that your answer is the correct answer of 6?\n8. Births Example 2 in this section includes the sample space for genders from three births. \nIdentify the sample space for the genders from two births.\nIn Exercises 9–12, assume that 50 births are randomly selected. Use subjective judgment to \ndescribe the given number of girls as (a) significantly low, (b) significantly high, or (c) nei-\nther significantly low nor significantly high.","page_start":146,"page_end":146,"token_count":662,"section_type":"other","chapter_number":4,"chapter_title":"PROBABILITY","chunk_index":202}
{"chunk_id":"06ab3c94e8015769","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"probability that your answer is the correct answer of 6?\n8. Births Example 2 in this section includes the sample space for genders from three births. \nIdentify the sample space for the genders from two births.\nIn Exercises 9–12, assume that 50 births are randomly selected. Use subjective judgment to \ndescribe the given number of girls as (a) significantly low, (b) significantly high, or (c) nei-\nther significantly low nor significantly high.\n9. 47 girls.   10. 26 girls.   11. 23 girls.   12. 5 girls.\n4-1 Basic Skills and Concepts","page_start":146,"page_end":146,"token_count":136,"section_type":"other","chapter_number":4,"chapter_title":"PROBABILITY","chunk_index":203}
{"chunk_id":"08fc1d8ac0a2de24","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"4-1 Basic Concepts of Probability \n129\nIn Exercises 13–20, express the indicated degree of likelihood as a probability value \nbetween 0 and 1.\n13. Testing If you make a random guess for the answer to a true>false test question, there is a \n50-50 chance of being correct.\n14. MCAT Test When making a random guess for an answer to a multiple-choice question on \nan MCAT test, the possible answers are a, b, c, d, e, so there is 1 chance in 5 of being correct.\n15. Genes One of the four DNA bases of A, G, C, and T is randomly selected, and the result is \nG. Assume that the four DNA bases are equally likely.\n16. Sleepwalking Based on a report in Neurology magazine, 29.2% of survey respondents \nhave sleepwalked.\n17. Randomness When using a computer to randomly generate the last digit of a phone \nnumber to be called for a survey, there is 1 chance in 10 that the last digit is zero.\n18.  Job Applicant Mistakes Based on an Adecco survey of hiring managers who were \nasked to identify the biggest mistakes that job candidates make during an interview, there is a \n50-50 chance that they will identify “inappropriate attire.”\n19. Square Peg Sydney Smith wrote in “On the Conduct of the Understanding” that it is im-\npossible to fit a square peg in a round hole.\n20. Death and Taxes Benjamin Franklin said that death is a certainty of life.\nIn Exercises 21–24, refer to the sample data in Table 4-1, which is included with the \n Chapter Problem. Assume that 1 of the 555 subjects included in Table 4-1 is randomly selected.\nTABLE 4-1 Results from Drug Tests of Job Applicants\nPositive Test Result \n(Test shows drug use.)\nNegative Test Result\n(Test shows no drug use.)\nSubject Uses Drugs\n45\n(True Positive)\n5\n(False Negative)\nSubject Does Not Use Drugs\n25\n(False Positive)\n480\n(True Negative)\n21. Drug Testing Job Applicants Find the probability of selecting someone who got a re-\nsult that is a false negative. Who would suffer from a false negative result? Why?\n22. Drug Testing Job Applicants Find the probability of selecting someone who got a re-\nsult that is a false positive. Who would suffer from a false positive result? Why?\n23.  Drug Testing Job Applicants Find the probability of selecting someone who uses \ndrugs. Does the result appear to be reasonable as an estimate of the “prevalence rate” described \nin the Chapter Problem?\n24. Drug Testing Job Applicants Find the probability of selecting someone who does not \nuse drugs. Does the result appear to be reasonable as an estimate of the proportion of the adult \npopulation that does not use drugs?\nIn Exercises 25–32, find the probability and answer the questions.\n25. XSORT Gender Selection MicroSort’s XSORT gender selection technique was designed \nto increase the likelihood that a baby will be a girl. At one point before clinical trials of the ","page_start":147,"page_end":147,"token_count":655,"section_type":"other","chapter_number":4,"chapter_title":"PROBABILITY","chunk_index":204}
{"chunk_id":"b250f0d031f615e9","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"24. Drug Testing Job Applicants Find the probability of selecting someone who does not \nuse drugs. Does the result appear to be reasonable as an estimate of the proportion of the adult \npopulation that does not use drugs?\nIn Exercises 25–32, find the probability and answer the questions.\n25. XSORT Gender Selection MicroSort’s XSORT gender selection technique was designed \nto increase the likelihood that a baby will be a girl. At one point before clinical trials of the \nXSORT gender selection technique were discontinued, 945 births consisted of 879 baby girls \nand 66 baby boys (based on data from the Genetics & IVF Institute). Based on these results, \nwhat is the probability of a girl born to a couple using MicroSort’s XSORT method? Does it ap-\npear that the technique is effective in increasing the likelihood that a baby will be a girl?","page_start":147,"page_end":147,"token_count":179,"section_type":"other","chapter_number":4,"chapter_title":"PROBABILITY","chunk_index":205}
{"chunk_id":"3a64f6620095d0f2","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"130 \nCHAPTER 4 Probability\n26.  YSORT Gender Selection MicroSort’s YSORT gender-selection technique is de-\nsigned to increase the likelihood that a baby will be a boy. At one point before clinical trials \nof the YSORT gender-selection technique were discontinued, 291 births consisted of 239 \nbaby boys and 52 baby girls (based on data from the Genetics & IVF Institute). Based on \nthese results, what is the probability of a boy born to a couple using MicroSort’s YSORT \nmethod? Does it appear that the technique is effective in increasing the likelihood that a baby \nwill be a boy?\n27. Mendelian Genetics When Mendel conducted his famous genetics experiments with \npeas, one sample of offspring consisted of 428 green peas and 152 yellow peas. Based on those \nresults, estimate the probability of getting an offspring pea that is green. Is the result reasonably \nclose to the expected value of 3>4, as Mendel claimed?\n28. Guessing Birthdays On their first date, Kelly asks Mike to guess the date of her birth, \nnot including the year.\na. What is the probability that Mike will guess correctly? (Ignore leap years.)\nb. Would it be unlikely for him to guess correctly on his first try?\nc. If you were Kelly, and Mike did guess correctly on his first try, would you believe his claim \nthat he made a lucky guess, or would you be convinced that he already knew when you were \nborn?\nd. If Kelly asks Mike to guess her age, and Mike’s guess is too high by 15 years, what is the \nprobability that Mike and Kelly will have a second date?\n29. Online Medicine In a survey, 933 respondents say that they seek medical information \nonline and 139 other respondents say that they never seek medical information online. What is \nthe probability that a randomly selected person never seeks medical information online? Is it \nunlikely for someone to never seek medical information online? How are these results affected \nby the fact that the responses are from subjects who decided to respond to the survey posted on \nthe Internet by AOL?\n30. Car Rollovers In a recent year in the United States, 83,600 passenger cars rolled over \nwhen they crashed, and 5,127,400 passenger cars did not roll over when they crashed. Find the \nprobability that a randomly selected passenger car crash results in a rollover. Is it unlikely for a \ncar to roll over in a crash?\n31. Genetics: Eye Color Each of two parents has the genotype brown>blue, which con-\nsists of the pair of alleles that determine eye color, and each parent contributes one of those \nalleles to a child. Assume that if the child has at least one brown allele, that color will domi-\nnate and the eyes will be brown. (The actual determination of eye color is more complicated \nthan that.)\na. List the different possible outcomes. Assume that these outcomes are equally likely.\nb. What is the probability that a child of these parents will have the blue>blue genotype?\nc. What is the probability that the child will have brown eyes?","page_start":148,"page_end":148,"token_count":658,"section_type":"other","chapter_number":4,"chapter_title":"PROBABILITY","chunk_index":206}
{"chunk_id":"8a028d637519ff2c","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"alleles to a child. Assume that if the child has at least one brown allele, that color will domi-\nnate and the eyes will be brown. (The actual determination of eye color is more complicated \nthan that.)\na. List the different possible outcomes. Assume that these outcomes are equally likely.\nb. What is the probability that a child of these parents will have the blue>blue genotype?\nc. What is the probability that the child will have brown eyes?\n32. X-Linked Genetic Disease Men have XY (or YX) chromosomes and women have XX \nchromosomes. X-linked recessive genetic diseases (such as juvenile retinoschisis) occur when \nthere is a defective X chromosome that occurs without a paired X chromosome that is not defec-\ntive. In the following, represent a defective X chromosome with lowercase x, so a child with the \nxY or Yx pair of chromosomes will have the disease and a child with XX or XY or YX or xX or \nXx will not have the disease. Each parent contributes one of the chromosomes to the child.\na. If a father has the defective x chromosome and the mother has good XX chromosomes, \nwhat is the probability that a son will inherit the disease?\nb. If a father has the defective x chromosome and the mother has good XX chromosomes, \nwhat is the probability that a daughter will inherit the disease?\ncontinued","page_start":148,"page_end":148,"token_count":290,"section_type":"other","chapter_number":4,"chapter_title":"PROBABILITY","chunk_index":207}
{"chunk_id":"cc71a4211510277e","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"4-2 Addition Rule and Multiplication Rule \n131\nc. If a mother has one defective x chromosome and one good X chromosome and the father \nhas good XY chromosomes, what is the probability that a son will inherit the disease?\nd. If a mother has one defective x chromosome and one good X chromosome and the father \nhas good XY chromosomes, what is the probability that a daughter will inherit the disease?\nProbability from a Sample Space. In Exercises 33–36, use the given sample space or \nconstruct the required sample space to find the indicated probability.\n33. Three Children Use this sample space listing the eight simple events that are possible when \na couple has three children (as in Example 2 on page 122): {bbb, bbg, bgb, bgg, gbb, gbg, ggb, \nggg}. Assume that boys and girls are equally likely, so that the eight simple events are equally \nlikely. Find the probability that when a couple has three children, there is exactly one girl.\n34. Three Children Using the same sample space and assumption from Exercise 33, find the \nprobability that when a couple has three children, there are exactly two girls.\n35. Four Children Exercise 33 lists the sample space for a couple having three children. After \nidentifying the sample space for a couple having four children, find the probability of getting \nthree girls and one boy (in any order).\n36. Four Children Using the same sample space and assumption from Exercise 35, find the \nprobability that when a couple has four children, all four are of the same gender.\nUsing Probability to Form Conclusions. In Exercises 37–40, use the given probability value \nto determine whether the sample results could easily occur by chance, then form a conclusion.\n37. Predicting Gender A study addressed the issue of whether pregnant women can cor-\nrectly predict the gender of their baby. Among 104 pregnant women, 57 correctly predicted the \ngender of their baby (based on data from “Are Women Carrying ‘Basketballs’…,” by Perry, \nDiPietro, Constigan, Birth, Vol. 26, No. 3). If pregnant women have no such ability, there is a \n0.327 probability of getting such sample results by chance. What do you conclude?\n38. Clinical Trial of Tamiflu Clinical trials involved the use of Tamiflu (oseltamivir phos-\nphate) for treating flu patients. Among 724 patients treated with Tamiflu, 72 (or about 10%) \nexperienced nausea. (An untreated group experienced a 6% rate of nausea.) If Tamiflu really \nhas no effect on nausea, there is a 0.00000246 probability of getting these sample results by \nchance. What do you conclude about the effect of Tamiflu on nausea?\n39. Sleepiness In a clinical trial of OxyContin (oxycodone) used for pain relief, 227 sub-\njects were treated with OxyContin and 52 of them experienced sleepiness (based on data from ","page_start":149,"page_end":149,"token_count":649,"section_type":"other","chapter_number":4,"chapter_title":"PROBABILITY","chunk_index":208}
{"chunk_id":"4765b2671cf41ae4","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"has no effect on nausea, there is a 0.00000246 probability of getting these sample results by \nchance. What do you conclude about the effect of Tamiflu on nausea?\n39. Sleepiness In a clinical trial of OxyContin (oxycodone) used for pain relief, 227 sub-\njects were treated with OxyContin and 52 of them experienced sleepiness (based on data from \nPurdue Pharma L.P.). If OxyContin has no effect on sleepiness, the probability of getting these \nsample results by chance is less than 0.001 (when comparing this sample group with another \ngroup not treated with OxyContin). What do you conclude?\n40. Cell Phones and Cancer A study of 420,095 Danish cell phone users resulted in 135 \nwho developed cancer of the brain or nervous system (based on data from the Journal of the \nNational Cancer Institute). When comparing this sample group to another group of people who \ndid not use cell phones, it was found that there is a probability of 0.512 of getting such sample \nresults by chance. What do you conclude?\nKey Concepts In this section we present the addition rule as a tool for finding \nP(A or B), which is the probability that either event A occurs or event B occurs (or they \nboth occur) as the single outcome of a procedure. To find P(A or B), we begin by add-\ning the number of ways that A can occur and the number of ways that B can occur, but \nadd without double counting. The word “or” in the addition rule is associated with the \naddition of probabilities.\n4-2 \nAddition Rule and Multiplication Rule","page_start":149,"page_end":149,"token_count":355,"section_type":"other","chapter_number":4,"chapter_title":"PROBABILITY","chunk_index":209}
{"chunk_id":"b041f522e2f78d4c","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"132 \nCHAPTER 4 Probability\nThis section also presents the basic multiplication rule used for finding P(A and B), \nwhich is the probability that event A occurs and event B occurs. If the outcome of \nevent A somehow affects the probability of event B, it is important to adjust the prob-\nability of B to reflect the occurrence of event A. The rule for finding P(A and B) is \ncalled the multiplication rule because it involves the multiplication of the probability \nof event A and the probability of event B (where, if necessary, the probability of event \nB is adjusted because of the outcome of event A). The word “and” in the multiplica-\ntion rule is associated with the multiplication of probabilities.\nIn Section 4-1 we considered only simple events, but in this section we consider \ncompound events.\nDEFINITION\nA compound event is any event combining two or more simple events.\nAddition Rule\nNotation for Addition Rule\nP1A or B2 = P1in a single trial, event A occurs or event B occurs or they \nboth occur2\nThe word “or” used in the preceding notation is the inclusive or, which means ei-\nther one or the other or both. The formal addition rule is often presented as a formula, \nbut blind use of formulas is not recommended. Instead, understand the spirit of the \nrule and use that understanding, as in the intuitive addition rule that follows.\nINTUITIVE ADDITION RULE\nTo find P(A or B), add the number of ways event A can occur and the number of \nways event B can occur, but add in such a way that every outcome is counted only \nonce. P(A or B) is equal to that sum, divided by the total number of outcomes in the \nsample space.\nFORMAL ADDITION RULE\nP1A or B2 = P1A2 + P1B2 - P1A and B2\nwhere P(A and B) denotes the probability that A and B both occur at the same time \nas an outcome in a trial of a procedure.\nOne way to apply the addition rule is to add the probability of event A and the \nprobability of event B and, if there is any overlap that causes double-counting, com-\npensate for it by subtracting the probability of outcomes that are included twice. This \napproach is reflected in the above formal addition rule.\nEXAMPLE 1  Drug Testing of Job Applicants\nRefer to Table 4-1, reproduced here for your convenience and viewing pleasure. \nIf 1 subject is randomly selected from the 555 subjects given a drug test, find the \nprobability of selecting a subject who had a positive test result or uses drugs.\nw\nev\nab\nProportions of  \nMales, Females\nIt is well \nknown that \nwhen a baby is \nborn, boys and \ngirls are not \nequally likely. It \nis currently be-\nlieved that 105 boys are born for \nevery 100 girls, so the probability \nof a boy is 0.512. Kristen Navara \nof the University of Georgia \nconducted a study showing that ","page_start":150,"page_end":150,"token_count":651,"section_type":"other","chapter_number":4,"chapter_title":"PROBABILITY","chunk_index":210}
{"chunk_id":"d61bdd629e29703c","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"w\nev\nab\nProportions of  \nMales, Females\nIt is well \nknown that \nwhen a baby is \nborn, boys and \ngirls are not \nequally likely. It \nis currently be-\nlieved that 105 boys are born for \nevery 100 girls, so the probability \nof a boy is 0.512. Kristen Navara \nof the University of Georgia \nconducted a study showing that \naround the world, more boys are \nborn than girls, but the difference \nbecomes smaller as people are \nlocated closer to the equator. \nShe used latitudes, tempera-\ntures, unemployment rates, and \ngross national products from \n200 countries and conducted a \nstatistical analysis showing that \nthe proportions of boys appear \nto be affected only by latitude \nand its related weather. So far, no \none has identified a reasonable \nexplanation for this phenomenon.","page_start":150,"page_end":150,"token_count":191,"section_type":"other","chapter_number":4,"chapter_title":"PROBABILITY","chunk_index":211}
{"chunk_id":"93d34f8690b9dd8a","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"4-2 Addition Rule and Multiplication Rule \n133\nDisjoint Events and the Addition Rule\nThe addition rule is simplified when the events are disjoint.\nTABLE 4-1 Results from Drug Tests of Job Applicants\nPositive Test Result\n(Test shows drug use.)\nNegative Test Result\n(Test shows no drug use.)\nSubject Uses Drugs\n45\n(True Positive)\n5\n(False Negative)\nSubject Does Not Use Drugs\n25\n(False Positive)\n480\n(True Negative)\n*Numbers in red correspond to positive test results or subjects who use drugs, and the total of  \nthose numbers is 75.\nSOLUTION\nRefer to Table 4-1 and carefully count the number of subjects who tested positive \n(first column) or use drugs (first row), but be careful to count subjects exactly once, \nnot twice. When adding the frequencies from the first column and the first row, \ninclude the frequency of 45 only once. In Table 4-1, there are 45 + 25 + 5 = 75 \nsubjects who had positive test results or use drugs. We get this result:\nP1positive test result or subject uses drugs2 = 75>555 = 0.135\nDEFINITION\nEvents A and B are disjoint (or mutually exclusive) if they cannot occur at the \nsame time. (That is, disjoint events do not overlap.)\nEXAMPLE 2  Disjoint Events\nDisjoint events:\nEvent A—Randomly selecting someone \nfor a clinical trial who is a male\nEvent B—Randomly selecting someone \nfor a clinical trial who is a female\n(The selected person cannot be both.)\nEvents that are not disjoint:\nEvent A—Randomly selecting someone \ntaking a statistics course\nEvent B—Randomly selecting someone \nwho is a female\n(The selected person can be both.)\nWhenever A and B are disjoint, P(A and B) becomes zero in the formal addition \nrule, so for disjoint events A and B we have P1A or B2 = P1A2 + P1B2. But again, \ninstead of blind use of a formula, it is better to understand and use the intuitive addi-\ntion rule.\nHere is a summary of the key points of the addition rule:\n1. To find P(A or B), first associate the word or with addition.\n2. To find the value of P(A or B), add the number of ways A can occur and the \nnumber of ways B can occur, but be careful to add without double counting.\n","page_start":151,"page_end":151,"token_count":513,"section_type":"other","chapter_number":4,"chapter_title":"PROBABILITY","chunk_index":212}
{"chunk_id":"985acb6a74f9dd92","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"134 \nCHAPTER 4 Probability\nComplementary Events and the Addition Rule\nIn Section 4-1 we used A to indicate that event A does not occur. Common sense dic-\ntates this principle: We are certain (with probability 1) that either an event A occurs or \nit does not occur, so it follows that P1A or A2 = 1. Because events A and A must be \ndisjoint, we can use the addition rule to express this principle as follows:\nP1A or A2 = P1A2 + P1A2 = 1\nThis result of the addition rule leads to the following three expressions that are “equiv-\nalent” in the sense that they are just different forms of the same principle.\nRULE OF COMPLEMENTARY EVENTS\nP1A2 + P1A2 = 1   P1A2 = 1 - P1A2  P1A2 = 1 - P1A2\nEXAMPLE 3  Sleepwalking\nBased on a journal article, the probability of randomly selecting someone who has \nsleepwalked is 0.292, so P(sleepwalked) = 0.292 (based on data from “Prevalence \nand Comorbidity of Nocturnal Wandering in the U.S. General Population,” by \nOhayon et al., Neurology, Vol. 78, No. 20). If a person is randomly selected, find the \nprobability of getting someone who has not sleepwalked.\nSOLUTION\nUsing the rule of complementary events, we get\nP1has not sleepwalked2 = 1 - P1sleepwalked2 = 1 - 0.292 = 0.708\nThe probability of randomly selecting someone who has not sleepwalked is 0.708.\nMultiplication Rule\nNotation for Multiplication Rule\nWe begin with basic notation followed by the multiplication rule. We strongly suggest \nusing the intuitive multiplication rule, because it is based on understanding instead of \nblind use of a formula.\nNotation\nP1A and B2 = P1event A occurs in one trial and event B occurs in a  \n      different trial2\nP1B\u001eA2 represents the probability of event B occurring after it is assumed that \nevent A has already occurred. (Interpret B\u001eA as “event B occurs after event A has \nalready occurred.”)\nCAUTION The notation P(A and B) has two meanings, depending on its context. \nFor the multiplication rule, P(A and B) denotes that event A occurs in one trial and \nevent B occurs in another trial; for the addition rule we use P(A and B) to denote \nthat events A and B both occur in the same trial.\n","page_start":152,"page_end":152,"token_count":571,"section_type":"other","chapter_number":4,"chapter_title":"PROBABILITY","chunk_index":213}
{"chunk_id":"f43f04e78e6e5a08","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"4-2 Addition Rule and Multiplication Rule \n135\nINTUITIVE MULTIPLICATION RULE\nTo find the probability that event A occurs in one trial and event B occurs in an-\nother trial, multiply the probability of event A by the probability of event B, but be \nsure that the probability of event B is found by assuming that event A has already \noccurred.\nFORMAL MULTIPLICATION RULE\nP1A and B2 = P1A2 # P1B\u001e A2\nIndependence and the Multiplication Rule\nWhen applying the multiplication rule and considering whether the probability of \nevent B must be adjusted to account for the previous occurrence of event A, we are \nfocusing on whether events A and B are independent.\nDEFINITIONS\nTwo events A and B are independent if the occurrence of one does not affect the \nprobability of the occurrence of the other. (Several events are independent if the \noccurrence of any does not affect the probabilities of the occurrence of the oth-\ners.) If A and B are not independent, they are said to be dependent.\nCAUTION Don’t think that dependence of two events means that one is the direct \ncause of the other. Having a working light in your kitchen and having a working \nlight in your bedroom are dependent events because they share the same power \nsource. One of the lights may stop working for many reasons, but if one light is out, \nthere is a higher probability that the other light will be out (because of the common \npower source).\nExample 4 illustrates the basic multiplication rule, with independent events in part (a) \nand dependent events in part (b).\nEXAMPLE 4  Drug Screening and the Basic Multiplication Rule\nLet’s use only the 50 test results from the subjects who use drugs (from Table 4-1), \nas shown below:\nPositive Test Results: \n45\nNegative Test Results: \n5\nTotal: \n50\na. If 2 of these 50 subjects are randomly selected with replacement, ﬁnd the \n probability that the ﬁrst selected person had a positive test result and the sec-\nond selected person had a negative test result.\n \nb. Repeat part (a) by assuming that the two subjects are selected without \n replacement.\ncontinued\n","page_start":153,"page_end":153,"token_count":466,"section_type":"other","chapter_number":4,"chapter_title":"PROBABILITY","chunk_index":214}
{"chunk_id":"d841b46ec83498ad","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"136 \nCHAPTER 4 Probability\nThe key point of part (b) in Example 4 is this: We must adjust the probability of the \nsecond event to reflect the outcome of the first event. Because selection of the second \nsubject is made without replacement of the first subject, the second probability must \ntake into account the fact that the first selection removed a subject who tested positive, \nso only 49 subjects are available for the second selection, and 5 of them had a negative \ntest result. Part (a) of Example 4 involved sampling with replacement, so the events \nare independent; part (b) of Example 4 involved sampling without replacement, so the \nevents are dependent. See the following.\nSampling In the wonderful world of statistics, sampling methods are critically impor-\ntant, and the following relationships hold:\n \n■Sampling with replacement: Selections are independent events.\n \n■Sampling without replacement: Selections are dependent events.\nException: Treating Dependent Events as Independent\nSome cumbersome calculations can be greatly simplified by using the common prac-\ntice of treating events as independent when small samples are drawn without replace-\nment from large populations. (In such cases, it is rare to select the same item twice.) \nHere is a common guideline routinely used with applications such as analyses of sur-\nvey results:\nTREATING DEPENDENT EVENTS AS INDEPENDENT:  \n5% GUIDELINE FOR CUMBERSOME CALCULATIONS\nWhen sampling without replacement and the sample size is no more than 5% of the \nsize of the population, treat the selections as being independent (even though they \nare actually dependent).\nSOLUTION\na. With Replacement: First selection (with 45 positive results among 50 total \nresults):\nP1positive test result2 = 45\n50\nSecond selection (with 5 negative test results among the same 50 total results):\nP1negative test result2 = 5\n50\nWe now apply the multiplication rule as follows:\nP11st selection is positive and 2nd is negative2 = 45\n50 # 5\n50 = 0.0900\nb. Without Replacement: Without replacement of the ﬁrst subject, the calcula-\ntions are the same as in part (a), except that the second probability must be \nadjusted to reﬂect the fact that the ﬁrst selection was positive and is not avail-\nable for the second selection. After the ﬁrst positive result is selected, we have \n49 test results remaining, and 5 of them are negative. The second probability \nis therefore 5>49, as shown below:\nP11st selection is positive and 2nd is negative2 = 45\n50 # 5\n49 = 0.0918\n","page_start":154,"page_end":154,"token_count":575,"section_type":"other","chapter_number":4,"chapter_title":"PROBABILITY","chunk_index":215}
{"chunk_id":"cc759b7fd578707d","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"4-2 Addition Rule and Multiplication Rule \n137\nExample 5 illustrates use of the 5% guideline for cumbersome calculations and it also \nillustrates that the basic multiplication rule extends easily to three or more events.\nEXAMPLE 5   Drug Screening and the 5% Guideline for  \nCumbersome Calculations\nAssume that three adults are randomly selected without replacement from the \n247,436,830 adults in the United States. Also assume that 10% of adults in the United \nStates use drugs. Find the probability that the three selected adults all use drugs.\nSOLUTION\nBecause the three adults are randomly selected without replacement, the three \nevents are dependent, but here we can treat them as being independent by applying \nthe 5% guideline for cumbersome calculations. The sample size of 3 is clearly no \nmore than 5% of the population size of 247,436,830. We get\n P1all 3 adults use drugs2 = P1first uses drugs and second uses drugs and\n third uses drugs2\n = P1first uses drugs2 #  P1second uses drugs2 #  \nP1third uses drugs2\n = 10.10210.10210.102 = 0.00100\nThere is a 0.00100 probability that all three selected adults use drugs.\nCAUTION In any probability calculation, it is extremely important to carefully \nidentify the event being considered. See Example 6, where parts (a) and (b) might \nseem quite similar but their solutions are very different.\nEXAMPLE 6  Birthdays\nWhen two different people are randomly selected from those in your class, find the \nindicated probability by assuming that birthdays occur on the days of the week with \nequal frequencies.\n \na. Find the probability that the two people are born on the same day of the week.\n \nb. Find the probability that the two people are both born on Monday.\nIn Example 5, if we treat the events as dependent without using the 5% guideline, \nwe get the following cumbersome calculation that begins with 247,436,830 adults, \nwith 10% of them (or 24,743,683) using drugs:\n a 24,743,683\n247,436,830ba 24,743,682\n247,436,829ba 24,743,681\n247,436,828b = 0.0009999998909\n = 0.00100 1rounded2\nJust imagine randomly selecting 1000 adults instead of just 3, as is commonly done \nin typical polls. Extending the above calculation to include 1000 factors instead of 3 \nfactors would be what statisticians refer to as “painful.”\ncontinued\n","page_start":155,"page_end":155,"token_count":571,"section_type":"other","chapter_number":4,"chapter_title":"PROBABILITY","chunk_index":216}
{"chunk_id":"975496e8948b6513","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"138 \nCHAPTER 4 Probability\nRedundancy: Important Application of Multiplication Rule\nThe principle of redundancy is used to increase the reliability of many systems. Our \neyes have passive redundancy in the sense that if one of them fails, we continue to see. \nAn important finding of modern biology is that genes in an organism can often work \nin place of each other. Engineers often design redundant components so that the whole \nsystem will not fail because of the failure of a single component, as in the following \nexample.\nSOLUTION\na. Because no particular day of the week is speciﬁed, the ﬁrst person can be \nborn on any one of the seven weekdays. The probability that the second \n person is born on the same day as the ﬁrst person is 1>7. The probability that \ntwo people are born on the same day of the week is therefore 1>7.\n \nb. The probability that the ﬁrst person is born on Monday is 1>7 and the prob-\nability that the second person is also born on Monday is 1>7. Because the two \nevents are independent, the probability that both people are born on Monday is\n1\n7 # 1\n7 = 1\n49\nWATCH YOUR LANGUAGE! Example 6 illustrates that finding correct or relevant \nprobability values often requires greater language skills than computational skills. \nIn Example 6, what exactly do we mean by “same day of the week”? See how parts \n(a) and (b) in Example 6 are very different.\nEXAMPLE 7  Airbus 310: Redundancy for Better Safety\nModern aircraft are now highly reliable, and one design feature contributing to that \nreliability is the use of redundancy, whereby critical components are duplicated so \nthat if one fails, the other will work. For example, the Airbus 310 twin-engine air-\nliner has three independent hydraulic systems, so if any one system fails, full flight \ncontrol is maintained with another functioning system. For this example, we will as-\nsume that for a typical flight, the probability of a hydraulic system failure is 0.002.\n \na. If the Airbus 310 were to have one hydraulic system, what is the probability \nthat the aircraft’s ﬂight control would work for a ﬂight?\n \nb. Given that the Airbus 310 actually has three independent hydraulic systems, \nwhat is the probability that on a typical ﬂight, control can be maintained with \na working hydraulic system?\nSOLUTION\n \na. The probability of a hydraulic system failure is 0.002, so the probability that \nit does not fail is 0.998. That is, the probability that ﬂight control can be main-\ntained is as follows:\nP11 hydraulic system does not fail2\n     \n= 1 - P1failure2 = 1 - 0.002 = 0.998\n","page_start":156,"page_end":156,"token_count":609,"section_type":"other","chapter_number":4,"chapter_title":"PROBABILITY","chunk_index":217}
{"chunk_id":"b65bb04a766b1142","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"4-2 Addition Rule and Multiplication Rule \n139\nRationale for the Multiplication Rule\nTo see the reasoning that underlies the multiplication rule, consider a pop quiz consist-\ning of these two questions:\n1. True or false: A pound of feathers is heavier than a pound of gold.\n2. Who said, “By a small sample, we may judge of the whole piece”?  \n(a) Judge Judy; (b) Judge Dredd; (c) Miguel de Cervantes; (d) George \nGallup; (e) Gandhi\nThe answers are T (true) and c. (The first answer is true, because weights of feath-\ners are in avoirdupois units where a pound is 453.59 g, but weights of gold and other \nprecious metals are in troy units where a pound is 373.24 g. The second answer is \nfrom Don Quixote by Cervantes.)\nHere is the sample space for the different possible answers:\nTa Tb Tc Td Te Fa Fb Fc Fd Fe\nIf both answers are random guesses, then the above 10 possible outcomes are equally \nlikely, so\nP1both correct2 = P1T and c2 = 1\n10 = 0.1\nWith P1T and c2 = 1>10, P1T2 = 1>2, and P1c2 = 1>5, we see that\n1\n10 = 1\n2 # 1\n5\nA tree diagram is a graph of the possible outcomes of a procedure, as in Figure 4-4. \nFigure 4-4 shows that if both answers are random guesses, all 10 branches are equally \nlikely and the probability of getting the correct pair (T, c) is 1>10. For each response to \nthe first question, there are 5 responses to the second. The total number of outcomes is 5 \ntaken 2 times, or 10. The tree diagram in Figure 4-4 therefore provides a visual illustra-\ntion for using multiplication.\nb. With three independent hydraulic systems, ﬂight control will be maintained if \nthe three systems do not all fail. The probability of all three hydraulic systems \nfailing is 0.002 #  0.002 #  0.002 = 0.000000008. It follows that the probabil-\nity of maintaining ﬂight control is as follows:\nP1it does not happen that all three hydraulic systems fail2\n= 1 - 0.000000008 = 0.999999992\nINTERPRETATION\nWith only one hydraulic system we have a 0.002 probability of failure, but with \nthree independent hydraulic systems, there is only a 0.000000008 probability that \nflight control cannot be maintained because all three systems failed. By using three \nhydraulic systems instead of only one, risk of failure is decreased not by a factor of \n1>3, but by a factor of 1>250,000. By using three independent hydraulic systems, \nrisk is dramatically decreased and safety is dramatically increased.\nTa\nTb\nTc","page_start":157,"page_end":157,"token_count":670,"section_type":"other","chapter_number":4,"chapter_title":"PROBABILITY","chunk_index":218}
{"chunk_id":"1c90bfb271fbd0f2","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"three independent hydraulic systems, there is only a 0.000000008 probability that \nflight control cannot be maintained because all three systems failed. By using three \nhydraulic systems instead of only one, risk of failure is decreased not by a factor of \n1>3, but by a factor of 1>250,000. By using three independent hydraulic systems, \nrisk is dramatically decreased and safety is dramatically increased.\nTa\nTb\nTc\nTd\nTe\nFa\nFb\nFc\nFd\nFe\na\nb\nc\nd\ne\na\nb\nc\nd\ne\nT\nF\n10\n5\n5\n2\n3\nFIGURE 4-4 Tree Diagram \nof Test Answers","page_start":157,"page_end":157,"token_count":155,"section_type":"other","chapter_number":4,"chapter_title":"PROBABILITY","chunk_index":219}
{"chunk_id":"0e6d9d39d0f58be2","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"140 \nCHAPTER 4 Probability\nSummary of Addition Rule and Multiplication Rule\nAddition Rule for P(A or B): The word or suggests addition, and when adding \nP(A) and P(B), we must add in such a way that every outcome is counted only \nonce.\nMultiplication Rule for P(A and B): The word and for two trials suggests \nmultiplication, and when multiplying P(A) and P(B), we must be sure that the \nprobability of event B takes into account the previous occurrence of event A.\nStatistical Literacy and Critical Thinking\n1. Notation When randomly selecting an adult, A denotes the event of selecting someone with \nblue eyes. What do P(A) and P1A2 represent?\n2. Notation When randomly selecting adults, let M denote the event of randomly selecting \na male and let B denote the event of randomly selecting someone with blue eyes. What does \nP1M0 B2 represent? Is P1M0 B2 the same as P1B0 M2?\n3. Sample for a Poll There are 15,524,971 adults in Florida. If The Gallup organization ran-\ndomly selects 1068 adults without replacement, are the selections independent or dependent? \nIf the selections are dependent, can they be treated as being independent for the purposes of \ncalculations?\n4. Rule of Complements When randomly selecting an adult, let B represent the event of \nrandomly selecting someone with Group B blood. Write a sentence describing what the rule of \ncomplements is telling us: P1B or B2 = 1.\nFinding Complements. In Exercises 5–8, find the indicated complements.\n5. LOL A U.S. Cellular survey of smartphone users showed that 26% of respondents answered \n“yes” when asked if abbreviations (such as LOL) are annoying when texting. What is the prob-\nability of randomly selecting a smartphone user and getting a response other than “yes”?\n6. Color Blindness Women have a 0.25% rate of red>green color blindness. If a woman is \nrandomly selected, what is the probability that she does not have red>green color blindness?\n7. Clinical Test When the drug Viagra (sildenafil citrate) was clinically tested, 117 patients \nreported headaches and 617 did not. If one of these patients is randomly selected, find the prob-\nability of getting one who did not report a headache.\n8.  Sobriety Checkpoint When one of the authors observed a sobriety checkpoint con-\nducted by the Dutchess County Sheriff Department, he saw that 676 drivers were screened \nand 6 were arrested for driving while intoxicated. Based on those results, we can estimate that \nP1I2 = 0.000888, where I denotes the event of screening a driver and getting someone who is \nintoxicated. What does P1I2 denote, and what is its value?\nIn Exercises 9–20, use the data in the following table, which summarizes blood groups and \nRh types for randomly selected subjects. Assume that subjects are randomly selected from \nthose included in the table.\nO\nA\nB","page_start":158,"page_end":158,"token_count":664,"section_type":"other","chapter_number":4,"chapter_title":"PROBABILITY","chunk_index":220}
{"chunk_id":"01d77e2791170027","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"P1I2 = 0.000888, where I denotes the event of screening a driver and getting someone who is \nintoxicated. What does P1I2 denote, and what is its value?\nIn Exercises 9–20, use the data in the following table, which summarizes blood groups and \nRh types for randomly selected subjects. Assume that subjects are randomly selected from \nthose included in the table.\nO\nA\nB\nAB\nType\nRh+\n59\n53\n12\n6\nRh−\n 9\n 8\n 3\n2\n4-2 Basic Skills and Concepts","page_start":158,"page_end":158,"token_count":127,"section_type":"other","chapter_number":4,"chapter_title":"PROBABILITY","chunk_index":221}
{"chunk_id":"93aa618498d60bac","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"4-2 Addition Rule and Multiplication Rule \n141\n9. Blood Groups and Types If one person is selected, find the probability of getting some-\none who is not Group A.\n10.  Blood Groups and Types If one person is selected, find the probability of getting \nsomeone who is not type Rh+.\n11.  Blood Groups and Types If one person is selected, find the probability of getting \nsomeone who is Group A or type Rh+. Are the events of selecting someone who is Group A and \nthe event of someone who is type Rh+ disjoint events?\n12.  Blood Groups and Types If one person is selected, find the probability of getting \nsomeone who is type Rh− or Group AB. Are the events of selecting someone who is type Rh−\nand the event of someone who is Group AB disjoint events?\n13. Blood Groups and Types If two people are selected, find the probability that they are \nboth Group B.\na. Assume that the selections are made with replacement. Are the events independent?\nb. Assume that the selections are made without replacement. Are the events independent?\n14. Blood Groups and Types If two people are selected, find the probability that they are \nboth type Rh−.\na. Assume that the selections are made with replacement. Are the events independent?\nb. Assume that the selections are made without replacement. Are the events independent?\n15. Blood Groups and Types If two people are selected, find the probability that they are \nboth type Rh+.\na. Assume that the selections are made with replacement. Are the events independent?\nb. Assume that the selections are made without replacement. Are the events independent?\n16. Blood Groups and Types If two people are selected, find the probability that they are \nboth Group AB.\na. Assume that the selections are made with replacement. Are the events independent?\nb. Assume that the selections are made without replacement. Are the events independent?\n17.  Blood Groups and Types If one person is selected, find the probability of getting \nsomeone who is Group A or Group B or type Rh-.\n18.  Blood Groups and Types If one person is selected, find the probability of getting \nsomeone who is Group O or Group AB or type Rh+.\n19. Blood Groups and Types If three different people are selected, find the probability that \nthey are all Group A.\n20. Blood Groups and Types If three different people are selected, find the probability that \nthey are all type Rh-.\nIn Exercises 21–24, use these results from the “1-Panel-THC” test for marijuana use, \nwhich is provided by the company Drug Test Success: Among 143 subjects with positive \ntest results, there are 24 false positive results; among 157 negative results, there are 3 false \nnegative results. (Hint: Construct a table similar to Table 4-1, which is included with the \nChapter Problem.)\n21. Testing for Marijuana Use\na. How many subjects are included in the study?\nb. How many of the subjects had a true negative result?\nc. What is the probability that a randomly selected test subject had a true negative result?\n","page_start":159,"page_end":159,"token_count":654,"section_type":"other","chapter_number":4,"chapter_title":"PROBABILITY","chunk_index":222}
{"chunk_id":"488c63e444e1dab7","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"142 \nCHAPTER 4 Probability\n22. Testing for Marijuana Use If one of the test subjects is randomly selected, find the \nprobability that the subject tested negative or used marijuana.\n23. Testing for Marijuana Use If one of the test subjects is randomly selected, find the \nprobability that the subject tested positive or did not use marijuana.\n24. Testing for Marijuana Use If one of the test subjects is randomly selected, find the \nprobability that the subject used marijuana. Do you think that the result reflects the general \npopulation rate of subjects who use marijuana?\nRedundancy. Exercises 25 and 26 involve redundancy.\n25. Redundancy in Computer Hard Drives It is generally recognized that it is wise to \nback up computer data. Assume that there is a 3% rate of disk drive failure in a year (based on \ndata from various sources including lifehacker.com).\na. If you store all of your computer data on a single hard disk drive, what is the probability that \nthe drive will fail during a year?\nb. If all of your computer data are stored on a hard disk drive with a copy stored on a second \nhard disk drive, what is the probability that both drives will fail during a year?\nc. If copies of all of your computer data are stored on three independent hard disk drives, what \nis the probability that all three will fail during a year?\nd. Describe the improved reliability that is gained with backup drives.\n26. Redundancy in Hospital Generators Hospitals typically require backup generators to \nprovide electricity in the event of a power outage. Assume that emergency backup generators \nfail 22% of the times when they are needed (based on data from Arshad Mansoor, senior vice \npresident with the Electric Power Research Institute). A hospital has two backup generators so \nthat power is available if one of them fails during a power outage.\na. Find the probability that both generators fail during a power outage.\nb. Find the probability of having a working generator in the event of a power outage. Is that \nprobability high enough for the hospital?\nAcceptance Sampling. With one method of a procedure called acceptance sampling, a \nsample of items is randomly selected without replacement and the entire batch is accepted \nif every item in the sample is found to be okay (or conforming). Exercises 27 and 28 involve \nacceptance sampling.\n27. Defective Pacemakers Among 8834 cases of heart pacemaker malfunctions, 504 were \nfound to be caused by firmware, which is software programmed into the device (based on data \nfrom “Pacemaker and ICD Generator Malfunctions,” by Maisel et al., Journal of the American \nMedical Association, Vol. 295, No. 16). If the firmware is tested in three different pacemak-\ners randomly selected from this batch of 8834 and the entire batch is accepted if there are no \nfailures, what is the probability that the firmware in the entire batch will be accepted? Is this \nprocedure likely to result in the entire batch being accepted?\n28. Defective Ultrasound Transducers Among 676 ultrasound transducers tested, 269 ","page_start":160,"page_end":160,"token_count":654,"section_type":"other","chapter_number":4,"chapter_title":"PROBABILITY","chunk_index":223}
{"chunk_id":"083fc69f9743d35b","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"Medical Association, Vol. 295, No. 16). If the firmware is tested in three different pacemak-\ners randomly selected from this batch of 8834 and the entire batch is accepted if there are no \nfailures, what is the probability that the firmware in the entire batch will be accepted? Is this \nprocedure likely to result in the entire batch being accepted?\n28. Defective Ultrasound Transducers Among 676 ultrasound transducers tested, 269 \nwere defective with transducer errors (based on data from “High Incidence of Defective Ultra-\nsound Transducers in Use in Routine Clinical Practice,” by Martensson et al., European Jour-\nnal of Cardiology, Vol. 10). If four different units are randomly selected and tested, what is the \nprobability that the entire batch will be accepted? Does that probability seem adequate?\nIn Exercises 29 and 30, find the probabilities and indicate when the “5% guideline for cum-\nbersome calculations” is used.\n29. Medical Helicopters In a study of helicopter usage and patient survival, results were \nobtained from 47,637 patients transported by helicopter and 111,874 patients transported by \nground (based on data from “Association Between Helicopter vs Ground Emergency Medical ","page_start":160,"page_end":160,"token_count":263,"section_type":"other","chapter_number":4,"chapter_title":"PROBABILITY","chunk_index":224}
{"chunk_id":"c89a31a1e31e671c","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"4-2 Addition Rule and Multiplication Rule \n143\nServices and Survival for Adults with Major Trauma,” by Galvagno et al., Journal of the Ameri-\ncan Medical Association, Vol. 307, No. 15).\na. If 1 of the 159,511 patients in the study is randomly selected, what is the probability that the \nsubject was transported by helicopter?\nb. If 5 of the subjects in the study are randomly selected without replacement, what is the prob-\nability that all of them were transported by helicopter?\n30. Medical Helicopters In the same study cited in the preceding exercise, among the 47,637 \npatients transported by helicopter, 188 of them left the treatment center against medical advice, \nand the other 47,449 did not leave against medical advice. If 40 of the subjects transported by \nhelicopter are randomly selected without replacement, what is the probability that none of them \nleft the treatment center against medical advice?\n31. MRI Reliability Refer to the accompanying figure showing surge protectors p and q used \nto protect an expensive magnetic resonance imaging (MRI) scanner used in a hospital. If there \nis a surge in the voltage, the surge protector reduces it to a safe level. Assume that each surge \nprotector has a 0.985 probability of working correctly when a voltage surge occurs.\na. If the two surge protectors are arranged in series, what is the probability that a voltage surge \nwill not damage the MRI? (Do not round the answer.)\nb. If the two surge protectors are arranged in parallel, what is the probability that a voltage \nsurge will not damage the MRI? (Do not round the answer.)\nc. Which arrangement should be used for better protection?\nSeries conﬁguration\np\nq\nMRI\nParallel conﬁguration\np\nq\nMRI\n32. Same Birthdays If 25 people are randomly selected, find the probability that no 2 of them \nhave the same birthday. Ignore leap years.\n33. Exclusive Or The exclusive or means either one or the other events occurs, but not both.\na. For the formal addition rule, rewrite the formula for P(A or B) assuming that the addition \nrule uses the exclusive or instead of the inclusive or.\nb. Repeat Exercise 11 “Blood Groups and Types” using the exclusive or instead of the inclu-\nsive or.\n34. Complements and the Addition Rule Refer to the table of blood groups and types used \nfor Exercises 9–20. Assume that one subject is randomly selected. Let A represent the event \nof getting someone with Group A blood and let B represent the event of getting someone with \nGroup B blood. Find P1A or B2, find P1A or B2, and then compare the results. In general, does \nP1A or B2 = P1A or B2?\n4-2 Beyond the Basics\n","page_start":161,"page_end":161,"token_count":612,"section_type":"other","chapter_number":4,"chapter_title":"PROBABILITY","chunk_index":225}
{"chunk_id":"5d598d6d114ca1d5","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"144 \nCHAPTER 4 Probability\nKey Concept In Part 1 of this section we extend the use of the multiplication rule to \ninclude the probability that among several trials, we get at least one of some specified \nevent. In Part 2 we consider conditional probability: the probability of an event occur-\nring when we have additional information that some other event has already occurred. \nIn Part 3 we provide a brief introduction to the use of Bayes’ theorem.\nPART 1\n  Complements: The Probability  \nof “At Least One” \nWhen finding the probability of some event occurring “at least once,” we should un-\nderstand the following:\n \n■“At least one” has the same meaning as “one or more.”\n \n■The complement of getting “at least one” particular event is that you get no \noccurrences of that event.\nFor example, not getting at least 1 girl in 10 births is the same as getting no girls, \nwhich is also the same as getting 10 boys.\nNot getting at least 1 girl in 10 births = Getting no girls = Getting 10 boys\nThe following steps describe the details of this backward method of finding the \nprobability of getting at least one of some event:\nFinding the probability of getting at least one of some event:\n1. Let A = getting at least one of some event.\n2. Then A = getting none of the event being considered.\n3. Find P1A2 = probability that event A does not occur. (This is relatively \neasy using the multiplication rule.)\n4. Subtract the result from 1. That is, evaluate this expression:\nP1at least one occurrence of event A2\n  = 1 −P1no occurrences of event A2\n4-3\n \nComplements, Conditional Probability,  \nand Bayes’ Theorem\nEXAMPLE 1  At Least One Subject with Group AB Blood\nThe probability of randomly selecting someone with Group AB blood is 0.0526 \n(based on the table given with Exercises 9–20 in the preceding section). A re-\nsearcher needs at least one subject having Group AB blood. If 20 subjects are ran-\ndomly selected, find the probability of getting at least one with Group AB blood. Is \nthe probability high enough so that the researcher can be reasonably sure of getting \nsomeone with Group AB blood?\nSOLUTION\nStep 1: Let A = at least 1 of the 20 subjects has Group AB blood.\nStep 2: Identify the event that is the complement of A.\n A = not getting at least 1 subject with Group AB blood among 20\n = all 20 subjects have blood that is not Group AB\n","page_start":162,"page_end":162,"token_count":556,"section_type":"other","chapter_number":4,"chapter_title":"PROBABILITY","chunk_index":226}
{"chunk_id":"246081a2a2e7eee1","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"4-3 Complements, Conditional Probability, and Bayes’ Theorem  \n145\nPART 2\n Conditional Probability \nWe now consider the principle that the probability of an event is often affected by \nknowledge that some other event has occurred. For example, the probability of a \ngolfer making a hole in one is 1>12,000 (based on past results), but if you have the \nadditional knowledge that the selected person is a professional golfer, the probability \nchanges to 1>2375 (based on data from USA Today).\nStep 3: Find the probability of the complement by evaluating P1A2 If there is \na 0.0526 probability of a person having Group AB blood, it follows that there \nis a 0.9474 probability of a person not having Group AB blood, and we get the \n following:\n P1A2 = P1all 20 subjects have blood that is not Group AB2\n = 0.9474 # 0.9474 #  g # 0.9474\n = 0.947420 = 0.339365436\nStep 4: Find P(A) by evaluating 1 - P1A2.\nP1A2 = 1 - P1A2 = 1 - 0.339365436 = 0.661 1rounded2\nINTERPRETATION\nFor a group of 20 subjects, there is a 0.661 probability of getting at least 1 person \nwith Group AB blood. This probability is not very high, so if the researcher needs a \nperson with Group AB blood, more than 20 subjects should be used.\nDEFINITION\nA conditional probability of an event is a probability obtained with the additional \ninformation that some other event has already occurred.\nNotation\nP1B\u001eA2 denotes the conditional probability of event B occurring, given that event A \nhas already occurred.\nINTUITIVE APPROACH FOR FINDING P1B∣A2\nThe conditional probability of B occurring given that A has occurred can be found \nby assuming that event A has occurred and then calculating the probability that \nevent B will occur, as illustrated in Example 2.\nFORMAL APPROACH FOR FINDING P1B∣A2\nThe probability P1B\u001e A2 can be found by dividing the probability of events A and B \nboth occurring by the probability of event A:\nP1B\u001e A2 = P1A and B2\nP1A2\nProsecutor’s Fallacy\nThe prosecu-\ntor’s fallacy is \nmisunderstand-\ning or confusion \nof two different \nconditional \nprobabilities:  \n(1) the probability \nthat a defendant is innocent, giv-\nen that forensic evidence shows \na match; (2) the probability that \nforensics shows a match, given \nthat a person is innocent. The \nprosecutor’s fallacy has led to \nwrong convictions and imprison-\nment of some innocent people.\nLucia de Berk was a nurse \nwho was convicted of murder \nand sentenced to prison in the \nNetherlands. Hospital administra-","page_start":163,"page_end":163,"token_count":653,"section_type":"other","chapter_number":4,"chapter_title":"PROBABILITY","chunk_index":227}
{"chunk_id":"ff451e75d8417d28","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"(1) the probability \nthat a defendant is innocent, giv-\nen that forensic evidence shows \na match; (2) the probability that \nforensics shows a match, given \nthat a person is innocent. The \nprosecutor’s fallacy has led to \nwrong convictions and imprison-\nment of some innocent people.\nLucia de Berk was a nurse \nwho was convicted of murder \nand sentenced to prison in the \nNetherlands. Hospital administra-\ntors observed suspicious deaths \nthat occurred in hospital wards \nwhere de Berk had been present. \nAn expert testified that there was \nonly 1 chance in 342 million that \nher presence was a coincidence. \nHowever, mathematician Richard \nGill calculated the probability to \nbe closer to 1>150, or possibly as \nlow as 1>5. The court used the \nprobability that the suspicious \ndeaths could have occurred with \nde Berk present, given that she \nwas innocent. The court should \nhave considered the probability \nthat de Berk is innocent, given \nthat the suspicious deaths oc-\ncurred when she was present. \nThis error of the prosecutor’s \nfallacy is subtle and can be \nvery difficult to understand and \nrecognize, yet it can lead to the \nimprisonment of innocent people.","page_start":163,"page_end":163,"token_count":270,"section_type":"other","chapter_number":4,"chapter_title":"PROBABILITY","chunk_index":228}
{"chunk_id":"141d644ec67a3136","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"146 \nCHAPTER 4 Probability\nThe preceding formula is a formal expression of conditional probability, but blind use \nof formulas is not recommended. Instead, we recommend the intuitive approach, as \nillustrated in Example 2.\nTABLE 4-1 Results from Drug Tests of Job Applicants\nPositive Test Result\n(Test shows drug use.)\nNegative Test Result \n(Test shows no drug use.)\nSubject Uses Drugs\n45\n(True Positive)\n5\n(False Negative)\nSubject Does Not Use Drugs\n25\n(False Positive)\n480\n(True Negative)\nEXAMPLE 2  Pre-Employment Drug Screening\nRefer to Table 4-1 to find the following:\n \na. If 1 of the 555 test subjects is randomly selected, ﬁnd the probability that the \nsubject had a positive test result, given that the subject actually uses drugs. \nThat is, ﬁnd P(positive test result \u001e subject uses drugs).\n \nb. If 1 of the 555 test subjects is randomly selected, ﬁnd the probability that the \nsubject actually uses drugs, given that he or she had a positive test result. That \nis, ﬁnd P(subject uses drugs \u001e positive test result).\nSOLUTION\na. Intuitive Approach: We want P(positive test result \u001e subject uses drugs), the \nprobability of getting someone with a positive test result, given that the se-\nlected subject uses drugs. Here is the key point: If we assume that the selected \nsubject actually uses drugs, we are dealing only with the 50 subjects in the \nﬁrst row of Table 4-1. Among those 50 subjects, 45 had positive test results, \nso we get this result:\nP1positive test result \u001esubject uses drugs2 = 45\n50 = 0.900\n \n Formal Approach: The same result can be found by using the formula for \nP1B\u001eA2given with the formal approach. We use the following notation.\nP1B\u001eA2 = P1positive test result \u001esubject uses drugs2\nwhere B = positive test result and A = subject uses drugs.\n \n  \nIn the following calculation, we use P(subject uses drugs and had a posi-\ntive test result) = 45>555 and P(subject uses drugs) = 50>555 to get the \nfollowing results:\nP1B\u001eA2 = P1A and B2\nP1A2\nbecomes\nP1positive test result \u001esubject uses drugs2\n = P1subject uses drugs and had a positive test result2\nP1subject uses drugs2\n = 45>555\n50>555 = 0.900\n","page_start":164,"page_end":164,"token_count":551,"section_type":"other","chapter_number":4,"chapter_title":"PROBABILITY","chunk_index":229}
{"chunk_id":"4fef3882c458b09e","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"4-3 Complements, Conditional Probability, and Bayes’ Theorem  \n147\nConfusion of the Inverse\nNote that in Example 2, P(positive test result \u001e subject uses drugs) ≠P(subject uses \ndrugs \u001e positive test result). This example proves that in general, P1B\u001eA2 ≠P1A\u001eB2.\n(There could be individual cases where P1A\u001eB2 and P1B\u001eA2 are equal, but they are \ngenerally not equal.) To incorrectly think that P1B\u001eA2 and P1A\u001eB2 are equal or to \nincorrectly use one value in place of the other is called confusion of the inverse.\n \n By comparing the intuitive approach to the formal approach, it should be clear \nthat the intuitive approach is much easier to use, and it is also less likely to \nresult in errors. The intuitive approach is based on an understanding of condi-\ntional probability, instead of manipulation of a formula, and understanding is \nso much better.\n \nb. Here we want P(subject uses drugs \u001e positive test result). If we assume that the \nsubject had a positive test result, we are dealing with the 70 subjects in the \nﬁrst column of Table 4-1. Among those 70 subjects, 45 use drugs, so\nP1subject uses drugs \u001epositive test result2 = 45\n70 = 0.643\nAgain, the same result can be found by applying the formula for conditional \nprobability, but we will leave that for those with a special fondness for ma-\nnipulations with formulas.\nINTERPRETATION\nThe first result of P(positive test result \u001e subject uses drugs) = 0.900 indicates that \na subject who uses drugs has a 0.900 probability of getting a positive test result. \nThe second result of P(subject uses drugs \u001e positive test result) = 0.643 indicates \nthat for a subject who gets a positive test result, there is a 0.643 probability that this \nsubject actually uses drugs. Note that P1positive test result \u001esubject uses drugs2\nP1subject uses drugs \u001epositive test result2. See “Confusion of the Inverse” that \nfollows.\nEXAMPLE 3  Confusion of the Inverse\nConsider these events:\nD: It is dark outdoors.\nM: It is midnight.\nIn the following, we conveniently ignore the Alaskan winter and other such \nanomalies.\nP1D\u001eM2 = 1 1It is certain to be dark given that it is midnight.2\nP1M \u001eD2 = 0 1The probability that it is exactly midnight given\nthat it is dark is almost zero.2\nHere, P1D\u001eM2 ≠P1M \u001eD2. Confusion of the inverse occurs when we incorrectly \nswitch those probability values or think that they are equal.\n","page_start":165,"page_end":165,"token_count":616,"section_type":"other","chapter_number":4,"chapter_title":"PROBABILITY","chunk_index":230}
{"chunk_id":"1d09747ff9bf8534","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"148 \nCHAPTER 4 Probability\nPART 3\nBayes’ Theorem\nIn this section we extend the discussion of conditional probability to include applica-\ntions of Bayes’ theorem (or Bayes’ rule), which we use for revising a probability value \nbased on additional information that is later obtained.\nLet’s consider a study showing that physicians often give very misleading in-\nformation when they experience confusion of the inverse. They tended to confuse \nP(cancer \u001f positive test result) with P(positive test result \u001f cancer). About 95% of physi-\ncians estimated P(cancer \u001f positive test result) to be about 10 times too high, with the \nresult that patients were given diagnoses that were very misleading, and patients were \nunnecessarily distressed by the incorrect information. Let’s take a closer look at this \nclassic example, and let’s hope that we can give physicians information in a better \nformat that is easy to understand.\nEXAMPLE 4  Interpreting Medical Test Results\nAssume cancer has a 1% prevalence rate, meaning that 1% of the population has \ncancer. Denoting the event of having a cancer by C, we have P1C2 = 0.01 for a \nsubject randomly selected from the population. This result is included with the fol-\nlowing performance characteristics of the test for cancer (based on Probabilistic \nReasoning in Clinical Medicine, by David Eddy, Cambridge University Press).\n■There is a 1% prevalence rate of the cancer. That is, P1C2 = 0.01.\n■The false positive rate is 10%. That is, P(positive test result given that cancer is \nnot present) = 0.10.\n■The true positive rate is 80%. That is, P(positive test result given that cancer is \npresent) = 0.80.\nFind P1C\u001fpositive test result2. That is, find the probability that a subject actually \nhas cancer given that he or she has a positive test result.\nSOLUTION\nUsing the given information, we can construct a hypothetical population with the above \ncharacteristics. We can find the entries in Table 4-2 on the next page, as follows.\n■Assume that we have 1000 subjects. With a 1% prevalence rate, 10 of the sub-\njects are expected to have cancer. The sum of the entries in the first row of val-\nues is therefore 10.\n■The other 990 subjects do not have cancer. The sum of the entries in the second \nrow of values is therefore 990.\n■Among the 990 subjects without cancer, 10% get positive test results, so 10% \nof the 990 cancer-free subjects in the second row get positive test results. See \nthe entry of 99 in the second row.\n■For the 990 subjects in the second row, 99 test positive, so the other 891 must \ntest negative. See the entry of 891 in the second row.\n■Among the 10 subjects with cancer in the first row, 80% of the test results are ","page_start":166,"page_end":166,"token_count":655,"section_type":"other","chapter_number":4,"chapter_title":"PROBABILITY","chunk_index":231}
{"chunk_id":"81fbfee979d7d471","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"of the 990 cancer-free subjects in the second row get positive test results. See \nthe entry of 99 in the second row.\n■For the 990 subjects in the second row, 99 test positive, so the other 891 must \ntest negative. See the entry of 891 in the second row.\n■Among the 10 subjects with cancer in the first row, 80% of the test results are \npositive, so 80% of the 10 subjects in the first row test positive. See the entry of \n8 in the first row.\n■The other 2 subjects in the first row test negative. See the entry of 2 in the \nfirst row.\nIn\nti\nGroup Testing\nDuring World \nWar II, the U.S. \nArmy tested \nfor syphilis \nby giving \neach soldier \nan individual \nblood test that was analyzed \nseparately. One researcher sug-\ngested mixing pairs of blood \nsamples. After the mixed pairs \nwere tested, those with syphilis \ncould be identified by retest-\ning the few blood samples that \nwere in the pairs that tested \npositive. Since the total number \nof analyses was reduced by pair-\ning blood specimens, why not \ncombine them in groups of three \nor four or more? This technique \nof combining samples in groups \nand retesting only those groups \nthat test positive is known as \ngroup testing or pooled testing, or \ncomposite testing. University of \nNebraska statistician Christopher \nBilder wrote an article about this \ntopic in Chance magazine, and \nhe cited some real applications. \nHe noted that the American \nRed Cross uses group testing \nto screen for specific diseases, \nsuch as hepatitis, and group \n testing is used by veterinarians \nwhen cattle are tested for the \nbovine viral diarrhea virus.","page_start":166,"page_end":166,"token_count":378,"section_type":"other","chapter_number":4,"chapter_title":"PROBABILITY","chunk_index":232}
{"chunk_id":"3d2d96bd52d3986e","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"4-3 Complements, Conditional Probability, and Bayes’ Theorem  \n149\nThe solution in Example 4 is not very difficult. Another approach is to compute the \nprobability using this formula commonly given with Bayes’ theorem:\nP1A\u001eB2 =\nP1A2 # P1B\u001eA2\n3P1A2 # P1B\u001eA2 4 + 3P1A2 # P1B\u001eA2 4\nIf we replace A with C and replace B with “positive,” we get this solution for Example 4:\n P1C\u001epositive2 =\nP1C2 # P1positive \u001eC2\nP1C2 # P1positive \u001eC2 + P1C2 # P1Positive \u001eC2\n =\n0.01 # 0.80\n10.01 # 0.802 + 10.99 # 0.102 = 0.0748\nStudy Results Here is a truly fascinating fact: When 100 physicians were given \nthe information in Example 4, 95 of them estimated P(C \u001e positive) to be around \n0.70 to 0.80, so they were wrong by a factor of 10. Physicians are extremely intel-\nligent, but here they likely suffered from confusion of the inverse. The given rate \nof 80% for positive test results among those who are true positives implies that \nP1positive \u001eC2 = 0.80, but this is very different from P1C\u001epositive2. The physi-\ncians would have done much better if they had seen the given information in the form \nof a table like Table 4-2.\nThe importance and usefulness of Bayes’ theorem is that it can be used with se-\nquential events, whereby new additional information is obtained for a subsequent \nevent, and that new information is used to revise the probability of the initial event. In \nthis context, the terms prior probability and posterior probability are commonly used.\nTo find P1C\u001epositive test result2, see that the first column of values includes the \npositive test results. In that first column, the probability of randomly selecting a \nsubject with cancer is 8>107 or 0.0748, so P1C\u001epositive test result2 = 0.0748.\nINTERPRETATION\nFor the data given in this example, a randomly selected subject has a 1% chance \nof cancer, but for a randomly selected subject given a test with a positive result, \nthe chance of cancer increases to 7.48%. Based on the data given in this example, \na positive test result should not be devastating news, because there is still a good \nchance that the test is wrong.\nTABLE 4-2 Test Results\nPositive Test Result\n(Test shows cancer.)\nNegative Test Result \n(Test shows no cancer.)\n \nTotal\nCancer\n8\n(True Positive)\n2\n(False Negative)\n10\nNo Cancer\n99\n(False Positive)\n891\n(True Negative)\n990\nDEFINITIONS\nA prior probability is an initial probability value originally obtained before any ad-\nditional information is obtained.\nA posterior probability is a probability value that has been revised by using addi-\ntional information that is later obtained.\n","page_start":167,"page_end":167,"token_count":683,"section_type":"other","chapter_number":4,"chapter_title":"PROBABILITY","chunk_index":233}
{"chunk_id":"a49b583a0c5ddfdf","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"150 \nCHAPTER 4 Probability\nRelative to Example 4, P1C2 = 0.01, which is the probability that a randomly se-\nlected subject has cancer. P(C) is an example of a prior probability. Using the ad-\nditional information that the subject has received a positive test result, we found that \nP1C\u001epositive test result2 = 0.0748, and this is a posterior probability because it uses \nthat additional information of the positive test result.\nStatistical Literacy and Critical Thinking\n1. Language: Complement of “At Least One” Let A = the event of getting at least one \ndefective pacemaker battery when 3 batteries are randomly selected with replacement from a \nbatch. Write a statement describing event A.\n2. Probability of At Least One Let A = the event of getting at least 1 defective pacemaker \nbattery when 3 batteries are randomly selected with replacement from a batch. If 5% of the \nbatteries in a batch are defective and the other 95% are all good, which of the following are \ncorrect?\na. P1A2 = 10.95210.95210.952 = 0.857\nb. P1A2 = 1 - 10.95210.95210.952 = 0.143\nc. P1A2 = 10.05210.05210.052 = 0.000125\n3. Notation Let event G = subject has glaucoma (disorder of the eye) and let event Y = test \nindicates that “yes,” the subject has glaucoma. Use your own words to translate the notation \nP1Y \u001e G2 into a verbal statement.\n4. Confusion of the Inverse Using the same events G and Y described in Exercise 3, de-\nscribe confusion of the inverse.\nAt Least One. In Exercises 5–12, find the probability.\n5. Three Girls Find the probability that when a couple has three children, at least one of them \nis a girl. (Assume that boys and girls are equally likely.)\n6. Probability of a Girl Assuming that boys and girls are equally likely, find the probability \nof a couple having a boy when their third child is born, given that the first two children were \nboth girls.\n7. Births in the United States In the United States, the true probability of a baby being a \nboy is 0.512 (based on the data available at this writing). Among the next six randomly selected \nbirths in the United States, what is the probability that at least one of them is a girl?\n8. Births in China In China, where many couples were allowed to have only one child, the \nprobability of a baby being a boy was 0.545. Among six randomly selected births in China, \nwhat is the probability that at least one of them is a girl? Could this system continue to work \nindefinitely? (Phasing out of this policy was begun in 2015.)\n9. Phone Survey Subjects for the California Health Interview Survey are contacted using ","page_start":168,"page_end":168,"token_count":659,"section_type":"other","chapter_number":4,"chapter_title":"PROBABILITY","chunk_index":234}
{"chunk_id":"73579bdbd63332a4","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"8. Births in China In China, where many couples were allowed to have only one child, the \nprobability of a baby being a boy was 0.545. Among six randomly selected births in China, \nwhat is the probability that at least one of them is a girl? Could this system continue to work \nindefinitely? (Phasing out of this policy was begun in 2015.)\n9. Phone Survey Subjects for the California Health Interview Survey are contacted using \ntelephone numbers in which the last four digits are randomly selected (with replacement). Find \nthe probability that for one such phone number, the last four digits include at least one 0.\n10. At Least One Correct Answer If you make random guesses for 10 multiple-choice \nMCAT test questions (each with five possible answers), what is the probability of getting at \nleast 1 correct? If these questions are part of a practice test and an instructor says that you must \nget at least one correct answer before continuing, is there a good chance you will continue?\n11. At Least One Defective Ultrasound Transducer A study showed that 39.8% of ultra-\nsound transducers are defective (based on data from “High Incidence of Defective  Ultrasound \n4-3 Basic Skills and Concepts","page_start":168,"page_end":168,"token_count":267,"section_type":"other","chapter_number":4,"chapter_title":"PROBABILITY","chunk_index":235}
{"chunk_id":"ccf709b92400c7eb","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"4-3 Complements, Conditional Probability, and Bayes’ Theorem  \n151\nTransducers in Use in Routine Clinical Practice,” by Martensson et al., European Journal of \nEchocardiography, Vol. 10, No. 1093.) An engineer needs at least one defective ultrasound \ntransducer so she can try to identify the problem. If she randomly selects 10 ultrasound trans-\nducers from a very large batch, what is the probability that she will get at least one that is de-\nfective? Is that probability high enough so that she can be reasonably sure of getting a defective \ntransducer for her work?\n12. Fruit Flies An experiment with fruit flies involves one parent with normal wings and one \nparent with vestigial wings. When these parents have an offspring, there is a 3>4 probability \nthat the offspring has normal wings and a 1>4 probability of vestigial wings. If the parents give \nbirth to five offspring, what is the probability that at least one of the offspring has vestigial \nwings? If researchers need at least one offspring with vestigial wings, can they be quite confi-\ndent of getting one?\nIdentical and Fraternal Twins. In Exercises 13–16, use the data in the following table. \nInstead of summarizing observed results, the entries reflect the actual probabilities based \non births of twins (based on data from the Northern California Twin Registry and the ar-\nticle “Bayesians, Frequentists, and Scientists,” by Bradley Efron, Journal of the American \nStatistical Association, Vol. 100, No. 469). Identical twins come from a single egg that splits \ninto two embryos, and fraternal twins are from separate fertilized eggs. The table entries \nreflect the principle that among sets of twins, 1 , 3 are identical and 2 , 3 are fraternal. Also, \nidentical twins must be of the same gender and the genders are equally likely (approxi-\nmately), and genders of fraternal twins are equally likely.\nBoy>boy\nBoy>girl\nGirl>boy\nGirl>girl\nIdentical Twins\n5\n0\n0\n5\nFraternal Twins\n5\n5\n5\n5\n13. Identical Twins\na. After having a sonogram, a pregnant woman learns that she will have twins. What is the \nprobability that she will have identical twins?\nb. After studying the sonogram more closely, the physician tells the pregnant woman that she \nwill give birth to twin boys. What is the probability that she will have identical twins? That is, \nfind the probability of identical twins given that the twins consist of two boys.\n14. Fraternal Twins\na. After having a sonogram, a pregnant woman learns that she will have twins. What is the \nprobability that she will have fraternal twins?\nb. After studying the sonogram more closely, the physician tells the pregnant woman that she \nwill give birth to twins consisting of one boy and one girl. What is the probability that she will \nhave fraternal twins?","page_start":169,"page_end":169,"token_count":654,"section_type":"other","chapter_number":4,"chapter_title":"PROBABILITY","chunk_index":236}
{"chunk_id":"d0ba90e92ffddc78","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"find the probability of identical twins given that the twins consist of two boys.\n14. Fraternal Twins\na. After having a sonogram, a pregnant woman learns that she will have twins. What is the \nprobability that she will have fraternal twins?\nb. After studying the sonogram more closely, the physician tells the pregnant woman that she \nwill give birth to twins consisting of one boy and one girl. What is the probability that she will \nhave fraternal twins?\n15. Fraternal Twins If a pregnant woman is told that she will give birth to fraternal twins, \nwhat is the probability that she will have one child of each gender?\n16. Fraternal Twins If a pregnant woman is told that she will give birth to fraternal twins, \nwhat is the probability that she will give birth to two girls?","page_start":169,"page_end":169,"token_count":174,"section_type":"other","chapter_number":4,"chapter_title":"PROBABILITY","chunk_index":237}
{"chunk_id":"b785a9a16b4ec990","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"152 \nCHAPTER 4 Probability\nIn Exercises 17–20, refer to the accompanying table showing results from a Chembio test \nfor hepatitis C among HIV-infected patients (based on data from a variety of sources).\nPositive Test Result\nNegative Test Result\nHepatitis C\n335\n  10\nNo Hepatitis C\n  2\n1153\n17. False Positive Find the probability of selecting a subject with a positive test result, given \nthat the subject does not have hepatitis C. Why is this case problematic for test subjects?\n18. False Negative Find the probability of selecting a subject with a negative test result, \ngiven that the subject has hepatitis C. What would be an unfavorable consequence of this error?\n19. Positive Predictive Value Find the positive predictive value for the test. That is, find the \nprobability that a subject has hepatitis C, given that the test yields a positive result. Does the \nresult make the test appear to be effective?\n20. Negative Predictive Value Find the negative predictive value for the test. That is, find \nthe probability that a subject does not have hepatitis C, given that the test yields a negative re-\nsult. Does the result make the test appear to be effective?\n21. Redundancy in Computer Hard Drives Assume that there is a 3% rate of disk drive \nfailures in a year (based on data from various sources including lifehacker.com).\na. If all of your computer data are stored on a hard disk drive with a copy stored on a second \nhard disk drive, what is the probability that during a year, you can avoid catastrophe with at \nleast one working drive? Express the result with four decimal places.\nb. If copies of all of your computer data are stored on three independent hard disk drives, what \nis the probability that during a year, you can avoid catastrophe with at least one working drive? \nExpress the result with six decimal places. What is wrong with using the usual round-off rule \nfor probabilities in this case?\n22. Redundancy in Hospital Generators Assume that emergency backup generators fail \n22% of the times when they are needed (based on data from Arshad Mansoor, senior vice presi-\ndent with the Electric Power Research Institute). A hospital has three backup generators so \nthat power is available if at least one of them works in a power failure. Find the probability of \nhaving at least one of the backup generators working, given that a power failure has occurred. \nDoes the result appear to be adequate for the hospital’s needs?\n23. Composite Drug Test Based on the data in Table 4-1 on page 146, assume that the prob-\nability of a randomly selected person testing positive for drug use is 0.126. If drug screening \nsamples are collected from 5 random subjects and combined, find the probability that the com-\nbined sample will reveal a positive result. Is that probability low enough so that further testing \nof the individual samples is rarely necessary?\n24. Composite Water Samples The Fairfield County Department of Public Health tests \nwater for the presence of E. coli (Escherichia coli) bacteria. To reduce laboratory costs, water ","page_start":170,"page_end":170,"token_count":664,"section_type":"other","chapter_number":4,"chapter_title":"PROBABILITY","chunk_index":238}
{"chunk_id":"35ebdbe025603d69","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"samples are collected from 5 random subjects and combined, find the probability that the com-\nbined sample will reveal a positive result. Is that probability low enough so that further testing \nof the individual samples is rarely necessary?\n24. Composite Water Samples The Fairfield County Department of Public Health tests \nwater for the presence of E. coli (Escherichia coli) bacteria. To reduce laboratory costs, water \nsamples from 10 public swimming areas are combined for one test, and further testing is done \nonly if the combined sample tests positive. Based on past results, there is a 0.005 probability of \nfinding E. coli bacteria in a public swimming area. Find the probability that a combined sample \nfrom 10 public swimming areas will reveal the presence of E. coli bacteria. Is that probability \nlow enough so that further testing of the individual samples is rarely necessary?\n25. Shared Birthdays Find the probability that of 25 randomly selected people, at least 2 \nshare the same birthday.\n4-3 Beyond the Basics","page_start":170,"page_end":170,"token_count":211,"section_type":"other","chapter_number":4,"chapter_title":"PROBABILITY","chunk_index":239}
{"chunk_id":"f8d93937f989dc8e","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"4-4 Risks and Odds \n153\nKey Concept This section introduces absolute risk reduction, relative risk, and odds \nratio as measures helpful for comparing probability values and measuring risk. This \nsection also introduces “number needed to treat” as a measure of the number of sub-\njects that must be treated in order to prevent the single occurrence of some event, such \nas a disease.\nOne simple way to measure risk is to use a probability value. For example, in one \nof the largest medical experiments ever conducted, it was found that among 200,745 \nchildren injected with the Salk vaccine, 33 developed paralytic polio (poliomyelitis). \nIt follows that for this treatment group, P1polio2 = 33>200,745 = 0.000164. How-\never, that single measure does not give us any information about the rate of polio for \nthose children who were injected with a placebo. The risk of polio for children treated \nwith the Salk vaccine should be somehow compared to the risk of polio for those chil-\ndren given a placebo. Let’s consider the data summarized in Table 4-3.\n4-4 \nRisks and Odds\nTABLE 4-3 Prospective Study of Polio and the Salk Vaccine\nPolio\nNo polio\nTotal\nSalk Vaccine\n 33\n200,712\n200,745\nPlacebo\n115\n201,114\n201,229\nBased on the data in Table 4-3, we can identify the following probabilities:\n Polio rate for treatment group: P1polio \u001eSalk vaccine2 =\n33\n200,745 = 0.000164\n Polio rate for placebo group: P1polio \u001eplacebo2 =\n115\n201,229 = 0.00571\nInformal comparison of the preceding two probabilities likely suggests that there is a \nsubstantial difference between the two polio rates. Later chapters will use more effec-\ntive methods for determining whether the apparent difference is actually significant, \nbut in this section we introduce some simple measures for comparing the two rates.\nThe preceding table can be generalized with the following format:\nTABLE 4-4 Generalized Table Summarizing Results of a Prospective Study\nDisease\nNo Disease\nTreatment\na\nb\nPlacebo\nc\nd\nWe noted above that this section introduces some simple measures for comparing \ntwo rates, such as the polio rate for the Salk vaccine treatment group and the polio \nrate for the placebo group, as summarized in Table 4-3. We begin with the absolute \nrisk reduction.\n","page_start":171,"page_end":171,"token_count":554,"section_type":"other","chapter_number":4,"chapter_title":"PROBABILITY","chunk_index":240}
{"chunk_id":"f7617a6029a51588","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"154 \nCHAPTER 4 Probability\nAbsolute Risk Reduction\nDEFINITION\nWhen comparing two probabilities or rates, the absolute risk reduction is simply \nthe absolute value of the following difference.\nAbsolute risk reduction = \u001eP1event occurring in treatment group2\n- P1event occurring in control group2 \u001e\nIf the data are in the generalized format of Table 4−4, we can express the absolute \nrisk reduction as follows:\nAbsolute risk reduction = \u001eP1event occurring in treatment group2\n- P1event occurring in control group2 \u001e\n= `\na\na + b -\nc\nc + d `\n(In the above expression, “treatment” might be replaced by the “presence of some \ncondition” or some other equivalent description.)\nCAUTION: The above definition of absolute risk reduction always results in the \npositive difference between a probability in the treatment group and a probability \nin the control group. Consider this when interpreting the effectiveness of the \ntreatment in terms of being helpful or harmful. See Exercises 13−16, where those \nin an atorvastatin treatment group have a higher rate of infections than those in the \nplacebo group. Be careful to interpret the results correctly.\nEXAMPLE 1  Finding Absolute Risk Reduction\nUsing the data summarized in Table 4-3, find the absolute risk reduction, which can \nbe used to measure the effectiveness of the Salk vaccine.\nSOLUTION\nBased on the data in Table 4-3, we have already found that P(polio \u001e Salk vaccine) \n= 0.000164 and P(polio \u001e placebo) = 0.000571. It follows that:\n Absolute risk reduction = \u001eP1polio\u001eSalk vaccine2 - P1polio\u001eplacebo2 \u001e\n = \u001e0.000164 - 0.000571\u001e = 0.000407\nFor a subject treated with the Salk vaccine, there is an absolute risk reduction of \n0.000407 when compared to a subject given a placebo. That is, there are 0.0407% \nfewer events of polio for subjects treated with the Salk vaccine than for subjects given \na placebo. This doesn’t seem like much of a reduction, but when considered in the con-\ntext of the number of polio events in a large population, it is a significant reduction.\nRelative Risk\nSection 1-3 included definitions of retrospective and prospective studies:\n■Retrospective Study: Data are collected from a past time period by going back in \ntime (through examinations of records, interviews, etc.).\n■Prospective Study: Data are collected in the future from groups or “cohorts” that \nshare common factors.\nA\nMonkey Typists\nA classical \nclaim is that \na monkey \nrandomly \nhitting a key-\nboard would \neventually \nproduce the complete works of \nShakespeare, assuming that it \ncontinues to type century after \ncentury. The multiplication rule \nfor probability has been used to \nfind such estimates. One  \nresult of 1,000,000,000,000,000, ","page_start":172,"page_end":172,"token_count":653,"section_type":"other","chapter_number":4,"chapter_title":"PROBABILITY","chunk_index":241}
{"chunk_id":"198bf22e618c6df2","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"share common factors.\nA\nMonkey Typists\nA classical \nclaim is that \na monkey \nrandomly \nhitting a key-\nboard would \neventually \nproduce the complete works of \nShakespeare, assuming that it \ncontinues to type century after \ncentury. The multiplication rule \nfor probability has been used to \nfind such estimates. One  \nresult of 1,000,000,000,000,000, \n000,000,000,000,000,000,000 \nyears is considered by some to \nbe too short. In the same spirit, \nSir Arthur Eddington wrote this \npoem: “There once was a brainy \nbaboon, who always breathed \ndown a bassoon. For he said, ‘It \nappears that in billions of years, I \nshall certainly hit on a tune.’”","page_start":172,"page_end":172,"token_count":177,"section_type":"other","chapter_number":4,"chapter_title":"PROBABILITY","chunk_index":242}
{"chunk_id":"99a5f55ef33bb567","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"4-4 Risks and Odds \n155\nIn a prospective study, a commonly used measure for comparing risk is relative risk. \nWe first introduce the following notation, and then we define relative risk.\nNotation\npt = proportion (or incidence rate) of some characteristic in a treatment group\npc = proportion (or incidence rate) of some characteristic in a control group\nDEFINITION\nIn a prospective study, the relative risk (or risk ratio or RR) of a characteristic \nis the ratio pt>pc, where pt is the proportion of the characteristic in the treatment \n(or exposed) group and pc is the proportion in the control group (or group not ex-\nposed). If the data are in the same format as the generalized Table 4-4, then the \nrelative risk is found by evaluating\npt\npc\n=\na\na + b\nc\nc + d\nInterpreting Relative Risk A relative risk value of 1 shows that the risk is the same \nfor the treatment group and the control (or placebo) group. A relative risk value much \ngreater than 1 shows that there is a much greater risk for the treatment group. The fol-\nlowing example illustrates how the relative risk of 0.287 shows that the risk of polio in \nthe treatment group is much less than the risk of polio in the placebo group.\nEXAMPLE 2  Computing Relative Risk\nUsing the data in Table 4-3, find the relative risk.\nSOLUTION\nFor the sample data in Table 4-3, we will consider the treatment group to be the \ngroup of children given the Salk vaccine, and the control group is the group of chil-\ndren given a placebo. Using the preceding notation, we have\npt = proportion of polio in treatment group =\n33\n33 + 200,712 = 0.000164\npc = proportion of polio in control 1placebo2 group =\n115\n115 + 201,114 =  0.000571\nUsing the above values, we can now find the relative risk as follows.\nRelative risk = pt\npc\n= 0.000164\n0.000571 = 0.287\nINTERPRETATION\nWe can interpret this result as follows: The polio rate for children given the Salk \nvaccine is 0.287 of the polio rate for children given a placebo. (A relative risk less \nthan 1 indicates that the treatment results in a reduced risk.) If we were to consider \nthe reciprocal value of 0.000571>0.000164 = 3.48, we see that children in the \n placebo group are 3.48 times more likely to get polio.\n","page_start":173,"page_end":173,"token_count":566,"section_type":"other","chapter_number":4,"chapter_title":"PROBABILITY","chunk_index":243}
{"chunk_id":"b9b311c522e6ba32","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"156 \nCHAPTER 4 Probability\nNumber Needed to Treat\nOne problem with relative risk is that it may be misleading by suggesting that a treat-\nment is superior or inferior, even when the absolute difference between rates is not \nvery large. For example, if 3 out of 10,000 aspirin users were to experience an imme-\ndiate cure of a cold compared to only 1 out of 10,000 placebo users, the relative risk \nof 3.00 correctly indicates that the incidence of immediate cold cures is three times as \nhigh for aspirin users, but the cure rates of 0.0003 and 0.0001 are so close that, for all \npractical purposes, aspirin should not be considered as a factor affecting the immedi-\nate cure of a cold. With cure rates of 0.0003 and 0.0001, the absolute risk reduction is \n0.0002. Because the absolute risk reduction is so small, the effectiveness of the aspirin \ntreatment would be negligible. In such a situation, the number needed to treat would \nbe a more effective measure that is not so misleading.\nCAUTION: When interpreting relative risk, consider the incidence rates. If the \nprobability of disease in an exposed group is 5>1,000,000 and the probability \nof disease in an unexposed group is 1>1,000,000, the relative risk is 5.0, which \nsounds really bad, but the very low incidence rates suggest that there isn’t much \nrisk in either group.\nDEFINITION\nThe number needed to treat (NNT) is the number of subjects that must be treated \nin order to prevent one event, such as a disease or adverse reaction. It is calcu-\nlated by dividing 1 by the absolute risk reduction.\nnumber needed to treat =\n1\nabsolute risk reduction\nRound-Off Rule If the calculated value of the number needed to treat is not a whole \nnumber, round it up to the next larger whole number.\nIf the sample data are in the format of the generalized Table 4-4, then:\nNumber needed to treat =\n1\n`\na\na + b -\nc\nc + d `\n 1rounded up to the next\nlarger whole number2\nIf 3 out of 10,000 aspirin users were to experience an immediate cure of a cold \ncompared to only 1 out of 10,000 placebo users, the absolute risk reduction is \n\u001e0.0003 - 0.0001\u001e = 0.0002, and the number needed to treat is 1>0.0002 = 5000.\nThis means that we would need to treat 5000 subjects with colds to get one person \nwho experiences an immediate cure.\nEXAMPLE 3  Computing the Number Needed to Treat\nUsing the polio data in Table 4-3, find the number needed to treat, then interpret the \nresult.\nSOLUTION\nIn Example 1 we found that the absolute risk reduction is 0.000407. It is now easy \nto find the number needed to treat.\n","page_start":174,"page_end":174,"token_count":652,"section_type":"other","chapter_number":4,"chapter_title":"PROBABILITY","chunk_index":244}
{"chunk_id":"fca4a16a5ebb4d4b","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"4-4 Risks and Odds \n157\nOdds\nSo far in this chapter, we have used probability values to express likelihood of various \nevents. Probability values are numbers between 0 and 1 inclusive. However, expres-\nsions of likelihood are often given as odds, such as 50:1 (or “50 to 1”).\n Number needed to treat =\n1\nabsolute risk reduction =\n1\n0.000407 = 2457.002457\n = 2458 1rounded up2\nINTERPRETATION\nThe result of 2458 can be interpreted as follows: We would need to vaccinate 2458 \nchildren with the Salk vaccine (instead of a placebo) to prevent one of the children \nfrom getting polio. Given the extremely serious consequences of polio, the Salk \nvaccine has been found to be very effective and important.\nDEFINITIONS\nThe actual odds against event A occurring are the ratio P1A2>P1A2, usually ex-\npressed in the form of a:b (or “a to b”), where a and b are integers. (Reduce using \nthe largest common factor; if a = 16 and b = 4, express the odds as 4:1 instead \nof 16:4.)\nThe actual odds in favor of event A occurring are the ratio P1A2>P1A2, which is \nthe reciprocal of the actual odds against that event. If the odds against an event \nare a:b, then the odds in favor are b:a.\nNote that in the two preceding definitions, the actual odds against and the actual odds \nin favor describe the actual likelihood of some event. (Gambling situations typically \nuse payoff odds, which describe the amount of profit relative to the amount of a bet. \nFor example, if you bet on the number 7 in roulette, the actual odds against winning \nare 37:1, but the payoff odds are 35:1. Racetracks and casinos are in business to make \na profit, so the payoff odds will usually differ from the actual odds.)\nTABLE 4-5 Retrospective Study of Newborn Discharge and Rehospitalization\nRehospitalized \nwithin a week\nNot rehospitalized \nwithin a week\n \nTotal\nEarly discharge  \n(*30 hours)\n457\n3199\n3656\nLate discharge  \n(30+ hours)\n260\n2860\n3120\nEXAMPLE 4  Rehospitalization and Discharge\nConsider the data in Table 4-5 (based on results from “The Safety of Newborn Early \nDischarge,” by Liu, Clemens, Shay, Davis, and Novack, Journal of the American \nMedical Association, Vol. 278, No. 4).\n \na. For those babies discharged early, ﬁnd the probability of being rehospitalized \nwithin a week.\n \nb. For those babies discharged early, ﬁnd the odds in favor of being rehospital-\nized early.\ncontinued\n","page_start":175,"page_end":175,"token_count":622,"section_type":"other","chapter_number":4,"chapter_title":"PROBABILITY","chunk_index":245}
{"chunk_id":"0ed73ba03facea5e","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"158 \nCHAPTER 4 Probability\nOdds Ratio\nFor the data in Table 4-5, how does the likelihood of rehospitalization differ between the \nearly discharge group and the late discharge group? One way to address that question is \nto use the odds ratio.\nSOLUTION\na. There were 3656 babies discharged early, and 457 of them were rehospital-\nized within a week, so\nP1rehospitalized2 = 457\n3656 = 1\n8\n \nb. Because P(rehospitalized) = 1>8, it follows that P1rehospitalized2 =\n1 - 1>8= 7>8. We can now ﬁnd the odds in favor of rehospitalization as follows:\nOdds in favor of rehospitalization for the early discharge group\n= P1rehospitalized2\nP1rehospitalized2 = 1>8\n7>8 = 1\n7\nThis result is often expressed as 1:7.\nWith odds of 1:7 in favor of rehospitalization for babies discharged early, it \n follows that the odds against rehospitalization for early discharge are 7:1.\nDEFINITION\nIn a retrospective or prospective study, the odds ratio (OR or relative odds) is a \nmeasure of risk found by evaluating the ratio of the odds in favor of the treatment \ngroup (or case group exposed to the risk factor) to the odds in favor of the control \ngroup, evaluated as follows:\nOdds ratio =\nodds in favor of treatment 1or exposed2 group\nodds in favor of control group\nIf the data are in the format of the generalized Table 4-4 on page 153, then the \nodds ratio can be computed as follows:\nOdds ratio = ad\nbc\nEXAMPLE 5  Computing Odds Ratio\nUsing the data in Table 4-5, find the odds ratio for rehospitalization.\nSOLUTION\nFor this example, we consider the case group to be the babies discharged early, and \nwe consider the control group to be the babies discharged late. The preceding exam-\nple showed that for the early discharge group, the odds in favor of rehospitalization \nare 1:7. Using similar calculations for the late discharge group, we get odds in favor \nof rehospitalization of 1>11 or 1:11. We can now find the odds ratio.\n Odds ratio = odds in favor of rehospitalization in early discharge group\nodds in favor of rehospitalization in late discharge group = 1>7\n1>11\n =  11\n7  or 1.571\n","page_start":176,"page_end":176,"token_count":555,"section_type":"other","chapter_number":4,"chapter_title":"PROBABILITY","chunk_index":246}
{"chunk_id":"03fd668c8de30e8e","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"4-4 Risks and Odds \n159\nWhy Not Use Relative Risk for Retrospective Studies?\nRelative risk makes sense only if the involved probabilities are good estimates of \nthe actual incidence rates, as in a prospective study. Using relative risk for a retro-\nspective study could incorrectly involve a situation in which researchers can choose \ndisease cases that are very different from actual incidence rates, with the result that \nthe relative risk can be very wrong. That is the reason that relative risk is defined for \nprospective studies only. The odds ratio is defined for prospective and retrospective \nstudies.\n Relative Risk: Prospective study\n Odds Ratio:\n Prospective study or retrospective study\nTable 4–6 includes the results from a prospective study of 1000 randomly selected sub-\njects, which is conducted to investigate the risk of lung cancer from smoking.  Table 4-6 \ncontains entries that are realistic based on current incidence rates. However, Table 4-7 \nbelow is based on a retrospective study in which the researcher went back in time to \nfind 985 subjects with lung cancer and 985 subjects without lung cancer, so Table 4-7 \ndoes not reflect actual incidence rates. See the following.\nFrom Table 4-6: P1lung cancer \u001esmoker2 = 13>180 = 0.0722\nFrom Table 4-7: P1lung cancer \u001esmoker2 = 854>1021 = 0.836\nThe above probabilities are very different, so both of them cannot be good estimates of \nthe likelihood of getting lung cancer from smoking. The above probability of 0.0722 \nis a good estimate because it is based on a prospective study with realistic incidence \nrates, but the probability of 0.836 is a poor estimate because it is based on the retro-\nspective study designed to include an equal number of subjects with lung cancer and \nsubjects without lung cancer.\nNow compare the relative risk values and the odds ratio values from Tables 4-6 \nand 4-7. See that the odds ratio values are approximately the same, but the relative risk \nvalues are dramatically different. The relative risk value of 29.6 from the prospective \nstudy is a good measure, but the relative risk of 6.1 from the retrospective study is a \npoor measure.\nIf we take advantage of the fact that Table 4-5 does correspond to the generalized \nTable 4-4 on page 153, then the odds ratio can also be calculated as follows:\nOdds ratio = ad\nbc = 14572128602\n13199212602 = 1.571\nINTERPRETATION\nThis result indicates that the odds in favor of rehospitalization are 1.571 times \nhigher for babies discharged early when compared to those discharged late. This \nsuggests that newborns discharged early are at substantially increased risk of rehos-\npitalization.\nTABLE 4-6 Prospective Study\nRR = 29.6; OR = 31.8\nLung Cancer\nNo Lung Cancer\nSmoker\n13\n167\nNonsmoker\n 2\n818\nTABLE 4-7 Retrospective Study","page_start":177,"page_end":177,"token_count":665,"section_type":"other","chapter_number":4,"chapter_title":"PROBABILITY","chunk_index":247}
{"chunk_id":"b7bc9d07690f2d94","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"This result indicates that the odds in favor of rehospitalization are 1.571 times \nhigher for babies discharged early when compared to those discharged late. This \nsuggests that newborns discharged early are at substantially increased risk of rehos-\npitalization.\nTABLE 4-6 Prospective Study\nRR = 29.6; OR = 31.8\nLung Cancer\nNo Lung Cancer\nSmoker\n13\n167\nNonsmoker\n 2\n818\nTABLE 4-7 Retrospective Study\nRR = 6.1; OR = 31.9\nLung Cancer\nNo Lung Cancer\nSmoker\n854\n167\nNonsmoker\n131\n818\nTotal\n985\n985","page_start":177,"page_end":177,"token_count":154,"section_type":"other","chapter_number":4,"chapter_title":"PROBABILITY","chunk_index":248}
{"chunk_id":"2ad1c40dd2770dd6","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"160 \nCHAPTER 4 Probability\nSUMMARY OF KEY POINTS\nDisease\nNo Disease\nTreatment\na\nb\nPlacebo\nc\nd\nStatistical Literacy and Critical Thinking \n1. Notation The relative risk of a characteristic is the ratio pt>pc. What do pt and pc represent?\n2.  Relative Risk Identify an important disadvantage of relative risk used with a relatively \nsmall difference between the rates in the treatment and control groups.\n3. Number Needed to Treat A measure of the effectiveness of an influenza vaccine is the \nnumber needed to treat, which is 37 (under certain conditions). Interpret that number. Does the \nresult apply to every particular group of 37 subjects?\n4. Retrospective , Prospective The odds ratio is a measure used in retrospective or pro-\nspective studies. Describe retrospective and prospective studies.\nHeadaches and Viagra In Exercises 5−12, use the data in the accompanying table \n(based on data from Pfizer, Inc.). That table describes results from a clinical trial of the \ndrug Viagra. Some subjects were treated with Viagra while others were given a placebo; \nthen headache events were recorded.\nHeadache\nNo Headache\nViagra Treatment\n117\n617\nPlacebo\n 29\n696\n5. Type of Study Is the study retrospective or prospective?\n4-4 Basic Skills and Concepts\n \n■Absolute risk reduction = `\na\na + b -\nc\nc + d `\n \n■Number Needed to Treat (NNT) =\n1\nAbsolute Risk Reduction\n \n■Actual odds against event A = P1A2\nP1A2\n \n■Actual odds in favor of event A = P1A2\nP1A2\nRelative risk 1RR2 = pt\npc\n=\na\na + b\nc\nc + d\nOdds ratio 1OR2 = ad\nbc\n(for prospective only)\n","page_start":178,"page_end":178,"token_count":394,"section_type":"other","chapter_number":4,"chapter_title":"PROBABILITY","chunk_index":249}
{"chunk_id":"d24188678032115d","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"4-4 Risks and Odds \n161\n6. Probability For those in the Viagra treatment group, find the probability that the subject \nexperienced a headache.\n7. Comparing Probabilities Compare P(headache \u001fViagra treatment) and  \nP(headache \u001f placebo).\n8. Absolute Risk Reduction Find the value of the absolute risk reduction for headaches in \nthe treatment and placebo groups.\n9. Number Needed to Treat Find the number of Viagra users that would need to stop using \nViagra in order to prevent a single headache.\n10. Odds For those in the Viagra treatment group, find the odds in favor of a headache, then \nfind the odds against a headache.\n11. Relative Risk Find the relative risk of a headache for those in the treatment group com-\npared to those in the placebo group. Interpret the result.\n12. Odds Ratio Find the odds ratio for headaches in the treatment group compared to the \nplacebo group, then interpret the result. Should Viagra users be concerned about headaches as \nan adverse reaction?\nClinical Trial of Atorvastatin (Lipitor). In Exercises 13−16, use the data in the accom-\npanying table that summarizes results from a clinical trial of atorvastatin (based on data \nfrom Parke-Davis).\nInfection\nNo Infection\nAtorvastatin (10 mg)\n89\n774\nPlacebo\n27\n243\n13. Absolute Risk Reduction\na. What is the probability of infection in the atorvastatin treatment group?\nb. What is the probability of infection in the placebo group?\nc. Find the value of the absolute risk reduction for infection in the placebo group and the atorv-\nastatin treatment group. Write a brief statement interpreting the result.\n14. Number Needed to Treat Calculate the number needed to treat and interpret the result.\n15. Odds For those who were treated with atorvastatin, find the odds in favor of an infection. \nAlso find the odds in favor of an infection for those given a placebo. Is there much of a differ-\nence between these two results?\n16. Odds Ratio and Relative Risk Find the odds ratio and relative risk for an infection in \nthe group treated with atorvastatin compared to the placebo group. Based on this result, does \natorvastatin appear to increase the risk of an infection? Why or why not?\n17. Odds Ratio and Relative Risk In a clinical trial of 2103 subjects treated with Nasonex \n(mometasone), 26 reported headaches. In a control group of 1671 subjects given a placebo, 22 \nreported headaches. Find the relative risk and odds ratio for the headache data. What do the \nresults suggest about the risk of a headache from the Nasonex treatment?\n18. Design of Experiments You would like to conduct a study to determine the effective-\nness of seat belts in saving lives in car crashes.\na. What would be wrong with randomly selecting 2000 drivers, then randomly assigning half \nof them to a group that uses seat belts and another group that does not wear seat belts?","page_start":179,"page_end":179,"token_count":659,"section_type":"other","chapter_number":4,"chapter_title":"PROBABILITY","chunk_index":250}
{"chunk_id":"254550d9afb44ec4","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"results suggest about the risk of a headache from the Nasonex treatment?\n18. Design of Experiments You would like to conduct a study to determine the effective-\nness of seat belts in saving lives in car crashes.\na. What would be wrong with randomly selecting 2000 drivers, then randomly assigning half \nof them to a group that uses seat belts and another group that does not wear seat belts?\nb. If 2000 drivers are randomly selected and separated into two groups according to whether \nthey use seat belts, what is a practical obstacle in conducting a prospective study of the effec-\ntiveness of seat belts in car crashes?","page_start":179,"page_end":179,"token_count":131,"section_type":"other","chapter_number":4,"chapter_title":"PROBABILITY","chunk_index":251}
{"chunk_id":"7d1adc6ca6c42ead","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"162 \nCHAPTER 4 Probability\nIn the biological and health sciences, rates are often used to describe the likelihood of \nan event. Rates are used by researchers and health professionals to monitor the health \nstatus of a community or population. Although any specific time interval could be \nused, we assume a time interval of one year throughout this section.\n4-5 \nRates of Mortality, Fertility, and Morbidity\nDEFINITION\nA rate describes the frequency of occurrence of some event. It is the relative fre-\nquency of an event, multiplied by some number, typically a value such as 1000 or \n100,000. A rate can be expressed as\naa\nb bk\nwhere\na = frequency count of the number of people for whom the event occurred\nb = total number of people exposed to the risk of the event occurring\nk = multiplier number, such as 1000 or 100,000\nThe above general definition is commonly applied to measures of mortality, fertility, \nand morbidity. For the following rates, mortality refers to deaths, fertility refers to \nbirths, and morbidity refers to diseases. Here are additional terms and their meanings:\n \n■Infants: Babies who were born alive\n \n■Neonates: Infants under the age of 28 days\n \n■Fetal Death: Occurs when a fetus is delivered without life after 20 weeks of gestation\n \n■Neonatal Death: Occurs when an infant dies under 28 days of age\nMortality Rates\nCrude 1or unadjusted2 mortality rate = a\ndeaths\npopulation size bk\nInfant mortality rate = adeaths of infants under 1 year of age\nnumber of live births\nbk\nNeonatal mortality rate = adeaths of infants under 28 days of age\nnumber of live births\nbk\nFetal mortality rate =\na\nfetuses delivered without life after 20 weeks of gestation \nnumber of live births +  \n fetuses delivered without life after 20 weeks of gestation bk\nPerinatal mortality rate = afetal deaths + neonatal deaths\nlive births + fetal deaths\nbk\nFertility Rates\nCrude birthrate = a\nlive births\npopulation size bk\nGeneral fertility rate = a\nlive births\nnumber of women aged 15 - 44 bk\n","page_start":180,"page_end":180,"token_count":482,"section_type":"other","chapter_number":5,"chapter_title":"DISCRETE PROBABILITY DISTRIBUTIONS","chunk_index":252}
{"chunk_id":"3b5ef37976ae6d32","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"4-5 Rates of Mortality, Fertility, and Morbidity \n163\nMorbidity (Disease) Rates\nIncidence rate = areported new cases of disease\npopulation size\nbk\nPrevalence rate = anumber of people with disease at a given time\npopulation size at the given point in time\nbk\nEXAMPLE 1  Crude Mortality Rate\nFor a recent year in the United States, there were 2,515,458 deaths in a population \nof 312,799,495 people. Use those values with a multiplier of 1000 to find the crude \nmortality rate.\nSOLUTION\nWith 2,515,458 people who died, with 312,799,495 people in the population, and \nletting k = 1000, we compute the crude mortality rate as follows:\n Crude mortality rate = a\ndeaths\npopulation size bk = a 2,515,458\n312,799,495b1000\n = 8.0 1rounded2\nINTERPRETATION\nFor this particular year, the death rate is 8.0 people for each 1000 people in the \n population. Using the relative frequency definition of probability given in Section 4-1, \nwe might also say that for a randomly selected person, the probability of death in \nthis year is 2,515,458>312,799,495 = 0.00804. One important advantage of the \nmortality rate of 8.0 people (per 1000 people in the population) is that it results in a \nvalue that uses fewer decimal places and is generally easier to use and understand.\nEXAMPLE 2  Infant Mortality Rate\nThe infant mortality rate is a very important measure of the health of a region. \n (According to the United Nations, the worldwide infant mortality rate is 49.4 per \n1000 live births.) For a recent year, there were 3,953,590 live births in the United \nStates, and there were 23,910 deaths of infants under 1 year of age. Using a mul-\ntiplying factor of k = 1000, find the infant mortality rate of the United States and \ncompare it to the rate of 2.1 for Japan.\nSOLUTION\nThe infant mortality rate is computed as shown below.\n Infant mortality rate = adeaths of infants under 1 year of age\nnumber of live births\nbk\n = a 23,910\n3,953,590b1000\n =  6.0 1rounded2\ncontinued\n","page_start":181,"page_end":181,"token_count":538,"section_type":"other","chapter_number":5,"chapter_title":"DISCRETE PROBABILITY DISTRIBUTIONS","chunk_index":253}
{"chunk_id":"b5137d77c5504726","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"164 \nCHAPTER 4 Probability\nA crude rate, as defined, is a single value based on crude totals. When compar-\ning two different regions, such as Florida and Colorado, a comparison of rates can be \nmisleading because of differences in factors such as age that might affect the rates. In \na recent year, the crude mortality rates (per 1000 population) were 9.1 in Florida and \n6.4 in Colorado. This is not too surprising, considering that in Florida, roughly 18% of \nthe population is over the age of 65, compared to only 11% for Colorado. The higher \nmortality rate for Florida does not mean that Florida is less healthy; in this case, it \nappears that Florida has a higher death rate largely because it has a higher proportion \nof older residents. Instead of using crude rates, we might use either specific rates or \nadjusted rates.\nSpecific rates are rates specific for some particular group, such as people aged \n18–24, or rates specific for some particular cause of death, such as deaths due to myo-\ncardial infarction.\nAdjusted rates involve calculations that can be quite complicated, but they basi-\ncally make adjustments for important factors, such as age, gender, or race.\nBecause age is the characteristic that typically affects mortality the most, it is the \nmost common factor used as the basis for adjustment. Calculations of adjusted rates \ninvolve the creation of a theoretical standardized population that is used for the re-\ngions being compared. A population of 1,000,000 people with the same composition \nas the United States is often used as the standardized population. Adjusted rates are \nvaluable for comparing different regions, but they do not necessarily reflect the true \ncrude death rates. Adjusted rates should not be used as death rates and they should not \nbe compared to crude rates.\nWhen assessing the accuracy of rates, we should consider the source. Mortality \nrates found in a source such as the Statistical Abstract of the United States (compiled \nby the U.S. Bureau of the Census) are likely to be quite accurate, because each state \nnow has a mandatory death reporting system, although official government reports \nseem to take years to produce. However, morbidity rates are likely to be less accurate, \nbecause some diseases are known to be underreported or not reported at all. Some \nmorbidity rates might be the result of very questionable surveys. However, some sur-\nveys, such as the annual National Health Survey, involve large samples of people who \nare very carefully chosen, so that results are likely to be very accurate.\nStatistical Literacy and Critical Thinking \n1. Birth Rate The birth rate in China is 12.3 per 1000. What exactly does that mean?\n2. Rates Exercise 1 describes the birth rate in China as 12.3 per 1000. Another way to describe \nthe birth rate is to give the rate as a proportion or probability of 0.0123. What advantage does \nthe rate of “12.3 per 1000” have over the rate expressed as 0.0123?","page_start":182,"page_end":182,"token_count":656,"section_type":"other","chapter_number":5,"chapter_title":"DISCRETE PROBABILITY DISTRIBUTIONS","chunk_index":254}
{"chunk_id":"d2d81f3a506809d4","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"2. Rates Exercise 1 describes the birth rate in China as 12.3 per 1000. Another way to describe \nthe birth rate is to give the rate as a proportion or probability of 0.0123. What advantage does \nthe rate of “12.3 per 1000” have over the rate expressed as 0.0123?\n3. Expected Births Given that China has a birth rate of 12.3 per 1000 and a population of \n1,360,762,587, about how many births are expected in a year?\n4. Incidence and Prevalence What is the difference between a disease incidence rate and a \ndisease prevalence rate?\n4-5 Basic Skills and Concepts\nINTERPRETATION\nThe infant mortality rate of 6.0 deaths per 1000 infants under 1 year of age is sub-\nstantially greater than the infant mortality rate of 2.1 in Japan.","page_start":182,"page_end":182,"token_count":200,"section_type":"other","chapter_number":5,"chapter_title":"DISCRETE PROBABILITY DISTRIBUTIONS","chunk_index":255}
{"chunk_id":"5062271c2bd7b07a","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"4-5 Rates of Mortality, Fertility, and Morbidity \n165\nFinding Rates. In Exercises 5−12, use the data in the accompanying table (based on data \nfor a recent year from various sources, including the U.S. Census Bureau and the National \nInstitutes of Health) to find the indicated rates. Round results to one decimal place, and use \na multiplying factor of k = 1000 unless indicated otherwise.\nVital Statistics for the United States in One Year\nPopulation: 312,799,495\nDeaths: 2,515,458\nWomen aged 15–44: 61,488,227\nMotor vehicle deaths: 33,783\nLive births: 3,953,590\nFetuses delivered without life after 20 weeks of \ngestation: 26,148\nDeaths of infants under 1 year of age: 23,910\nDeaths of infants under 28 days of age: 15,973\nHIV-infected persons: 1,155,792\nDeaths from HIV infections: 7683\n5. Find the neonatal mortality rate.\n6. Find the fetal mortality rate.\n7. Find the perinatal mortality rate.\n8. Find the crude birth rate.\n9. Find the general fertility rate.\n10. Using a multiplier of k = 100,000, find the motor vehicle death incidence rate.\n11. Find the HIV infection prevalence rate.\n12. Find the HIV infection mortality rate for HIV-infected persons.\n13. Finding Probability An example in this section involved the crude mortality rate, which \nwas found to be 8.0 persons per 1000 population. Find the probability of randomly selecting \nsomeone and getting a person who died within the year. What advantage does the crude mortal-\nity rate have over the probability value?\n14. Finding Probability The crude death rate for China was recently 7.4, and that rate was \ncomputed using a multiplier of k = 1000.\na. Find the probability that a randomly selected Chinese person died within the year.\nb. If two Chinese people are randomly selected, find the probability that they both died within \nthe year, and express the result using three significant digits.\nc. If two Chinese people are randomly selected, find the probability that neither of them died \nwithin the year, and express the result using three significant digits.\n15. Finding Probability The crude death rate for Spain was recently 8.3, and that rate was \ncomputed using a multiplier of k = 1000.\na. Find the probability that a randomly selected Spaniard died within the year.\nb. If two Spaniards are randomly selected, find the probability that they both died within the \nyear, and express the result using three significant digits.\nc. If two Spaniards are randomly selected, find the probability that at least one of them sur-\nvived the year, and express the result using six decimal places. What would be wrong with \nexpressing the answer using three significant digits?\ncontinued\n","page_start":183,"page_end":183,"token_count":635,"section_type":"other","chapter_number":5,"chapter_title":"DISCRETE PROBABILITY DISTRIBUTIONS","chunk_index":256}
{"chunk_id":"6f7bf887d9fb5c09","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"166 \nCHAPTER 4 Probability\n16. Finding Probability In a recent year in the United States, there were 787,650 deaths due \nto cardiovascular disease, and the population was 312,799,495.\na. Find the crude mortality rate for cardiovascular disease. (This result is sometimes called the \ncause-specific death rate.)\nb. Find the probability that a randomly selected person died of cardiovascular disease and \n express the result using three significant digits.\nc. Find the probability that when three people are randomly selected, none of them died \n because of cardiovascular disease.\n17.  Cause-of-Death Ratio In a recent year in the United States, there were 2,515,458 \ndeaths, and 787,650 of them were due to cardiovascular disease. The cause-of-death ratio is \nexpressed as follows:\nadeaths due to specific disease\ntotal number of deaths\nbk where k = 100\na. Find the cause-of-death ratio for cardiovascular disease.\nb. If three of the deaths are randomly selected, find the probability that none of them are due to \ncardiovascular disease.\n18. Crude Mortality Rates The table below lists numbers of deaths and population sizes for \ndifferent age groups for Florida and the United States for a recent year.\na. Find the crude mortality rate for Florida and the crude mortality rate for the United States. Al-\nthough we should not compare crude mortality rates, what does the comparison suggest in this case?\nb. Using only the age group of 65 and older, find the mortality rates for Florida and the United \nStates. Compare the results.\nc. What percentage of the Florida population is made up of people aged 65 and older? What is \nthe percentage for the United States? What do the results suggest about the crude mortality for \nFlorida compared to the United States?\nAge\n0–24\n25–64\n65 and older\nFlorida deaths\n      3625\n     39,820\n   129,395\nFlorida population\n  5,716,861\n   9,842,031\n 3,375,303\nU.S. deaths\n     63,208\n    619,982\n 1,832,268\nU.S. population\n103,542,603\n163,960,163\n45,296,729\n19. Number of Deaths The number of deaths in the United States has been steadily increas-\ning each year. Does this mean that the health of the nation is declining? Why or why not?\n20. Comparing Rates In a recent year, the crude mortality rate of the United States was 8.0 \n(per 1000 population), and the corresponding crude mortality rate for China was 7.4. What is a \nmajor problem with comparing the crude mortality rates of the United States and China?\n21. Adjusted Mortality Rate Refer to the data listed in Exercise 18. Change the Florida popula-\ntion sizes for the three age categories so that they fit the same age distribution as the U.S. popu-\nlation. Next, adjust the corresponding numbers of deaths proportionately. (Use the same Florida ","page_start":184,"page_end":184,"token_count":654,"section_type":"other","chapter_number":5,"chapter_title":"DISCRETE PROBABILITY DISTRIBUTIONS","chunk_index":257}
{"chunk_id":"0d0eb8d369fdaab9","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"major problem with comparing the crude mortality rates of the United States and China?\n21. Adjusted Mortality Rate Refer to the data listed in Exercise 18. Change the Florida popula-\ntion sizes for the three age categories so that they fit the same age distribution as the U.S. popu-\nlation. Next, adjust the corresponding numbers of deaths proportionately. (Use the same Florida \nmortality rates for the individual age categories, but apply those rates to the adjusted population \nsizes.) Finally, compute the Florida mortality rate using the adjusted values. The result is a mortal-\nity rate adjusted for the variable of age. (Better results could be obtained by using more age catego-\nries.) How does this adjusted mortality rate for Florida compare to the mortality rate for the United \nStates? (Note: There are other methods for computing adjusted rates than the one used here.)\n4-5 Beyond the Basics","page_start":184,"page_end":184,"token_count":184,"section_type":"other","chapter_number":5,"chapter_title":"DISCRETE PROBABILITY DISTRIBUTIONS","chunk_index":258}
{"chunk_id":"79fe6dfc9cc9d5e2","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"4-6 Counting \n167\nMULTIPLICATION COUNTING RULE: For a sequence of events in which the first \nevent can occur n1 ways, the second event can occur n2 ways, the third event can \noccur n3 ways, and so on, the total number of possibilities is n1 # n2 # n3 . . ..\nEXAMPLE 1  Multiplication Counting Rule: DNA\nIn a linear triplet of three DNA nucleotides, each of the nucleotides can be any one \nof these four bases (with repetition allowed): A (adenine); C (cytosine); G (guanine); \nT (thymine). Two different examples of triplets are CTA and TTG. What is the total \nnumber of different possible triplets? Given that the four nucleotides are equally \nlikely, what is the probability of getting the triplet of AAA?\nSOLUTION\nThere are 4 different possibilities for each of the three nucleotides, so the total num-\nber of different possible triplets is n1 # n2 # n3 = 4 # 4 # 4 = 64.\nIf the four nucleotides are equally likely, the probability of getting the triplet of \nAAA is 1>64 or 0.0156.\n2. Factorial Rule\nThe factorial rule is used to find the total number of ways that n different items can \nbe rearranged with different arrangements of the same items counted separately. The \nfactorial rule uses the following notation.\nNOTATION\nThe factorial symbol (!) denotes the product of decreasing positive whole num-\nbers. For example, 4! = 4 # 3 # 2 # 1 = 24. By special definition, 0! = 1.\nFACTORIAL RULE The number of different arrangements (order matters) of n \ndifferent items when all n of them are selected is n!.\nThe factorial rule is based on the principle that the first item may be selected n differ-\nent ways, the second item may be selected n - 1 ways, and so on.\nRouting problems often involve applications of the factorial rule, as in the follow-\ning example.\nKey Concept Probability problems typically require that we know the total number of \nsimple events, but finding that number often requires one of the five rules presented in \nthis section. In Section 4-2, with the addition rule, multiplication rule, and conditional \nprobability, we encouraged intuitive rules based on understanding and we discour-\naged blind use of formulas, but this section requires much greater use of formulas as \nwe consider five different methods for counting the number of possible outcomes in a \nvariety of situations. Not all counting problems can be solved with these five methods, \nbut they do provide a strong foundation for the most common real applications.\n1. Multiplication Counting Rule\nThe multiplication counting rule is used to find the total number of possibilities from \nsome sequence of events.\n4-6 \nCounting\n","page_start":185,"page_end":185,"token_count":616,"section_type":"other","chapter_number":5,"chapter_title":"DISCRETE PROBABILITY DISTRIBUTIONS","chunk_index":259}
{"chunk_id":"8ec4eda98c86f38c","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"168 \nCHAPTER 4 Probability\nPermutations and Combinations: Does Order Count?\nWhen using different counting methods, it is essential to know whether different ar-\nrangements of the same items are counted only once or are counted separately. The \nterms permutations and combinations are standard in this context, and they are de-\nfined as follows:\nEXAMPLE 2  Factorial Rule: Travel Itinerary\nQuest Diagnostics collects blood specimens from different laboratories. A driver is \ndispatched to make collections at 5 different locations. How many different routes \nare possible?\nSOLUTION\nFor those 5 different locations, the number of different routes is 5! =\n5 # 4 # 3 # 2 # 1 = 120.\nNote that this solution could have been done by applying the multiplica-\ntion counting rule. The first stop can be any one of the 5 locations, the second \nstop can be any one of the 4 remaining locations, and so on. The result is again \n5 # 4 # 3 # 2 # 1 = 120. Use of the factorial rule has the advantage of including the \nfactorial symbol, which is sure to impress.\nDEFINITIONS\nPermutations of items are arrangements in which different sequences of the same \nitems are counted separately. (The letter arrangements of abc, acb, bac, bca, cab, \nand cba are all counted separately as six different permutations.)\nCombinations of items are arrangements in which different sequences of the \nsame items are counted as being the same. (The letter arrangements of abc, acb, \nbac, bca, cab, and cba are all considered to be the same single combination.)\nMnemonics for Permutations and Combinations\n \n■Remember “Permutations Position,” where the alliteration reminds us that with \npermutations, the positions of the items makes a difference.\n \n■Remember “Combinations Committee,” which reminds us that with members of \na committee, rearrangements of the same members result in the same committee, \nso order does not count.\n3. Permutations Rule (When All of the Items Are Different)\nThe permutations rule is used when there are n different items available for selection, \nwe must select r of them without replacement, and the sequence of the items matters. \nThe result is the total number of arrangements (or permutations) that are possible. (Re-\nmember: Rearrangements of the same items are counted as different permutations.)\nPERMUTATIONS RULE: When n different items are available and r of them are \nselected without replacement, the number of different permutations (order counts) \nis given by\nnPr =\nn!\n1n - r2!\n","page_start":186,"page_end":186,"token_count":558,"section_type":"other","chapter_number":5,"chapter_title":"DISCRETE PROBABILITY DISTRIBUTIONS","chunk_index":260}
{"chunk_id":"633e47ffba170345","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"4-6 Counting \n169\n4. Permutations Rule (When Some Items Are Identical to Others)\nWhen n items are all selected without replacement, but some items are identical, the \nnumber of possible permutations (order matters) is found by using the following rule.\nEXAMPLE 3   Permutations Rule (with Different Items):  \nClinical Trial of New Drug\nWhen testing a new drug, Phase I requires only 5 volunteers, and the objective is \nto assess the drug’s safety. To be very cautious, we plan to treat the 5 subjects in \nsequence, so that any particularly adverse effect can allow us to stop the treatments \nbefore any other subjects are treated. If 8 volunteers are available, how many differ-\nent sequences of 5 subjects are possible?\nSOLUTION\nWe need to select r = 5 subjects from n = 8 volunteers that are available. The num-\nber of different sequences of arrangements is found as shown:\nnPr =\nn!\n1n - r2! =\n8!\n18 - 52! = 6720\nThere are 6720 different possible arrangements of 5 subjects selected from the 8 \nthat are available.\nPERMUTATIONS RULE (WHEN SOME ITEMS ARE IDENTICAL TO OTHERS)\nThe number of different permutations (order counts) when n items are available \nand all n of them are selected without replacement, but some of the items are iden-\ntical to others, is found as follows:\nn!\nn1!n2! . . . nk! where n1 are alike, n2 are alike,…, and nk are alike.\nEXAMPLE 4   Permutations Rule (with Some Identical Items):  \nDesigning Surveys\nWhen designing surveys, pollsters sometimes repeat a question to see if a subject \nis thoughtlessly providing answers just to finish quickly. For one particular survey \nwith 10 questions, 2 of the questions are identical to each other, and 3 other ques-\ntions are also identical to each other. For this survey, how many different arrange-\nments are possible? Is it practical to survey enough subjects so that every different \npossible arrangement is used?\nSOLUTION\nWe have 10 questions with 2 that are identical to each other and 3 others that are \nalso identical to each other, and we want the number of permutations. Using the rule \nfor permutations with some items identical to others, we get\nn!\nn1!n2! . . . nk! = 10!\n2!3! = 3,628,800\n2 # 6\n= 302,400\ncontinued\n","page_start":187,"page_end":187,"token_count":539,"section_type":"other","chapter_number":5,"chapter_title":"DISCRETE PROBABILITY DISTRIBUTIONS","chunk_index":261}
{"chunk_id":"56fe5a0e5418859a","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"170 \nCHAPTER 4 Probability\n5. Combinations Rule\nThe combinations rule is used when there are n different items available for selection, \nonly r of them are selected without replacement, and order does not matter. The result \nis the total number of combinations that are possible. (Remember: Rearrangements of \nthe same items are considered to be the same combination.)\nINTERPRETATION\nThere are 302,400 different possible arrangements of the 10 questions. It is not \npractical to accommodate every possible permutation. For typical surveys, the num-\nber of respondents is somewhere around 1000.\nCOMBINATIONS RULE:\nWhen n different items are available, but only r of them are selected without replace-\nment, the number of different combinations (order does not matter) is found as follows:\nnCr =\nn!\n1n - r2!r!\nEXAMPLE 5  Combinations Rule: Phase I of a Clinical Trial\nWhen testing a new drug on humans, a clinical test is normally done in three \nphases. Phase I is conducted with a relatively small number of healthy volunteers. \nAssume that we want to treat 20 healthy humans with a new drug, and we have  \n30 suitable volunteers available. If 20 subjects are selected from the 30 that are \navailable, and the 20 selected subjects are all treated at the same time, how many \ndifferent treatment groups are possible?\nSOLUTION\nBecause all subjects are treated at the same time, order is irrelevant, so we need to \nfind the number of different possible combinations. With n = 30 subjects available \nand with r = 20 subjects selected, the number of combinations is found as follows.\nnCr =\nn!\n1n - r2!r! =\n30!\n130 - 202!20! =\n30!\n10! # 20! = 30,045,015\nINTERPRETATION\nThere are 30,045,015 different possible combinations.\nPermutations or Combinations? Because choosing between permutations and com-\nbinations can often be tricky, we provide the following example that emphasizes the \ndifference between them.\nEXAMPLE 6   Permutations and Combinations:  \nOfficers and Committees\nThe Portland Medical Center must appoint three corporate officers: chief executive \nofficer (CEO), executive chairperson, and chief operating officer (COO). It must \nalso appoint a planning committee with three different members. There are eight \nqualified candidates, and officers can also serve on the planning committee.\n","page_start":188,"page_end":188,"token_count":510,"section_type":"other","chapter_number":5,"chapter_title":"DISCRETE PROBABILITY DISTRIBUTIONS","chunk_index":262}
{"chunk_id":"b019f7cfc0ed19d0","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"4-6 Counting \n171\n \na. How many diﬀerent ways can the oﬃcers be appointed?\n \nb. How many diﬀerent ways can the committee be appointed?\nSOLUTION\nNote that in part (a), order is important because the officers have very different \nfunctions. However, in part (b), the order of selection is irrelevant because the com-\nmittee members all serve the same function.\n \na. Because order does count, we want the number of permutations of r = 3 \npeople selected from the n = 8 available people. We get\nnPr =\nn!\n1n - r2! =\n8!\n18 - 32! = 336\n \nb. Because order does not count, we want the number of combinations of r = 3 \npeople selected from the n = 8 available people. We get\nnCr =\nn!\n1n - r2!r! =\n8!\n18 - 32!3! = 56\nWith order taken into account, there are 336 different ways that the officers can be \nappointed, but without order taken into account, there are 56 different possible com-\nmittees.\nStatistical Literacy and Critical Thinking \n1. Notation What does the symbol ! represent? Six different patients can be scheduled for \nX-ray films 6! different ways, so what is the actual number of ways that six people can be \nscheduled for X-ray films?\n2.  Permutations, Combinations What is the basic difference between permutations and \ncombinations?\n3. Notation Evaluate 9C4. What does the result represent?\n4. Notation Evaluate 9P4. What does the result represent?\nIn Exercises 5–30, express all probabilities as fractions.\n5. Pin Numbers The Kinsale Medical Supply Company issues pin numbers to its employees \nso that they can access an online database. A hacker must randomly guess the correct pin code \nfor the Information Technology supervisor, and that pin code consists of four digits (each 0 \nthrough 9) that must be entered in the correct order. Repetition of digits is allowed. What is the \nprobability of a correct guess on the first try?\n6. Social Security Numbers A Social Security number consists of nine digits in a particular \norder, and repetition of digits is allowed. After seeing the last four digits printed on a receipt, if \nyou randomly select the other digits, what is the probability of getting the correct Social Secu-\nrity number of the person who was given the receipt?\n7. Assigning Shifts The staff supervisor at the Wellington Medical Center must assign a \nteam of two physicians to work the emergency room on Saturday night. If there are 19 physi-\ncians available and two of them are randomly selected, what is the probability of getting the \ntwo youngest physicians?\n4-6 Basic Skills and Concepts\n","page_start":189,"page_end":189,"token_count":609,"section_type":"other","chapter_number":5,"chapter_title":"DISCRETE PROBABILITY DISTRIBUTIONS","chunk_index":263}
{"chunk_id":"fe2241e1b889d6b7","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"172 \nCHAPTER 4 Probability\n8. Review Board The supervisor at the Wellington Medical Center must select three nurses \nfrom 11 who are available for a review board. How many different ways can that be done?\n9. Blood Test Quest Diagnostics has just received 8 different blood samples. If they are tested \nin random order, what is the probability that they are tested in the alphabetical order of the sub-\njects who provided the samples?\n10. Radio Station Call Letters If radio station call letters must begin with either K or W and \nmust contain a total of either three or four letters, how many different possibilities are there?\n11. Scheduling Routes A new director of the Veterans Health Administration plans to visit \none hospital in each of five different states. If the five states are randomly selected from all 50 \nstates without replacement and the order is also random, what is the probability that she visits \nIdaho, Oregon, Alaska, New Jersey, and Ohio, in that order?\n12. Survey Reliability A health survey with 12 questions is designed so that 3 of the ques-\ntions are identical and 4 other questions are identical (except for minor changes in wording). \nHow many different ways can the 12 questions be arranged?\n13. Safety with Numbers A safe “combination” consists of four numbers between 0 and 99, \nand the safe is designed so that numbers can be repeated. If someone tries to gain access to the \nsafe, what is the probability that he or she will get the correct combination on the first attempt? \nAssume that the numbers are randomly selected. Given the number of possibilities, does it \nseem feasible to try opening the safe by making random guesses for the combination?\n14. Electricity The control panel for an MRI device uses five color-coded wires. If we trou-\nbleshoot by testing two wires at a time, how many different tests are required for every possible \npairing of two wires?\n15. Clinical Trial In a clinical trial of the drug atorvastatin (Lipitor), one group of subjects \nwas given placebos, a second group was given treatments of 10 mg, a third group was given \ntreatments of 20 mg, a fourth group was given treatments of 40 mg, and a fifth group was given \ntreatments of 80 mg. If the Phase I trial involved 15 subjects randomly assigned to the five \ngroups with three in each group, how many different ways can the groups be formed?\n16. Emergency Room Instead of treating emergency room patients in the order that they \narrive, it is common to treat those with more serious problems first. If an emergency room has \nseven different patients, how many ways can they be arranged in sequence?\n17. ZIP Code If you randomly select five digits, each between 0 and 9, with repetition allowed, \nwhat is the probability you will get the ZIP code of the Secretary of Health and Human Services?\n18. FedEx Deliveries With a short time remaining in the day, a FedEx driver has time to make \ndeliveries at 6 locations among the 9 locations remaining. How many different routes are possible?","page_start":190,"page_end":190,"token_count":663,"section_type":"other","chapter_number":5,"chapter_title":"DISCRETE PROBABILITY DISTRIBUTIONS","chunk_index":264}
{"chunk_id":"3db705cc39ff90c8","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"17. ZIP Code If you randomly select five digits, each between 0 and 9, with repetition allowed, \nwhat is the probability you will get the ZIP code of the Secretary of Health and Human Services?\n18. FedEx Deliveries With a short time remaining in the day, a FedEx driver has time to make \ndeliveries at 6 locations among the 9 locations remaining. How many different routes are possible?\n19. Phone Numbers Current rules for telephone area codes allow the use of digits 2–9 for \nthe first digit and 0–9 for the second and third digits. How many different area codes are pos-\nsible with these rules? That same rule applies to the exchange numbers, which are the three \ndigits immediately preceding the last four digits of a phone number. Given both of those rules, \nhow many ten-digit phone numbers are possible? Given that these rules apply to the United \nStates and Canada and a few islands, are there enough possible phone numbers? (Assume that \nthe combined population is about 400,000,000.)\n20. Classic Counting Problem A classic counting problem is to determine the number of \ndifferent ways that the letters of “Mississippi” can be arranged. Find that number.\n21. Corporate Officers and Committees The Newport Medical Supply Company must \nappoint a president, chief executive officer (CEO), chief operating officer (COO), and chief \nfinancial officer (CFO). It must also appoint a strategic planning committee with four different \nmembers. There are 10 qualified candidates, and officers can also serve on the committee.\na. How many different ways can the four officers be appointed?\nb. How many different ways can a committee of four be appointed?\ncontinued","page_start":190,"page_end":190,"token_count":356,"section_type":"other","chapter_number":5,"chapter_title":"DISCRETE PROBABILITY DISTRIBUTIONS","chunk_index":265}
{"chunk_id":"c0b8f278b791e389","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"4-6 Counting \n173\nc. What is the probability of randomly selecting the committee members and getting the four \nyoungest of the qualified candidates?\n22. Card Access You have an identification card used for access to a secure area of the Wel-\nlington Medical Center. It’s dark and you can’t see your card when you insert it. The card must \nbe inserted with the front side up and the printing configured so that the beginning of your \nname enters first.\na. What is the probability of selecting a random position and inserting the card with the result \nthat the card is inserted correctly?\nb. What is the probability of randomly selecting the card’s position and finding that it is incor-\nrectly inserted on the first attempt, but it is correctly inserted on the second attempt?\nc. How many random selections are required to be absolutely sure that the card works because \nit is inserted correctly?\n23. Amino Acids With 8 different amino acids available, 5 are to be selected to form a chain \n(called a polypeptide chain) in which order counts. How many different chains are possible?\n24. Identity Theft with Credit Cards Credit card numbers typically have 16 digits, but not \nall of them are random.\na. What is the probability of randomly generating 16 digits and getting your MasterCard number?\nb. Receipts often show the last four digits of a credit card number. If only those last four digits are \nknown, what is the probability of randomly generating the other digits of your MasterCard number?\nc. Discover cards begin with the digits 6011. If you know that the first four digits are 6011 and \nyou also know the last four digits of a Discover card, what is the probability of randomly gener-\nating the other digits and getting all of them correct? Is this something to worry about?\n25. What a Word! One of the longest words in standard statistics terminology is “homosce-\ndasticity.” How many ways can the letters in that word be arranged?\n26. Phase I of a Clinical Trial A clinical test on humans of a new drug is normally done \nin three phases. Phase I is conducted with a relatively small number of healthy volunteers. For \nexample, a Phase I test of bexarotene involved only 14 subjects. Assume that we want to treat \n14 healthy humans with this new drug and we have 16 suitable volunteers available.\na. If the subjects are selected and treated one at a time in sequence, how many different sequen-\ntial arrangements are possible if 14 people are selected from the 16 that are available?\nb. If 14 subjects are selected from the 16 that are available, and the 14 selected subjects are all \ntreated at the same time, how many different treatment groups are possible?\nc. If 14 subjects are randomly selected and treated at the same time, what is the probability of \nselecting the 14 youngest subjects?\n27. Lightning and Lottery As of this writing, the Mega Millions lottery is run in 44 states. \nWinning the jackpot requires that you select the correct five different numbers between 1 and ","page_start":191,"page_end":191,"token_count":654,"section_type":"other","chapter_number":5,"chapter_title":"DISCRETE PROBABILITY DISTRIBUTIONS","chunk_index":266}
{"chunk_id":"5ede7f75d77a94e9","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"treated at the same time, how many different treatment groups are possible?\nc. If 14 subjects are randomly selected and treated at the same time, what is the probability of \nselecting the 14 youngest subjects?\n27. Lightning and Lottery As of this writing, the Mega Millions lottery is run in 44 states. \nWinning the jackpot requires that you select the correct five different numbers between 1 and \n75 and, in a separate drawing, you must also select the correct single number between 1 and 15. \nFind the probability of winning the jackpot if you buy one ticket. How does the result compare \nto the probability of being struck by lightning in a year, which the National Weather Service \nestimates to be 1>960,000?\n28. Designing Experiment Clinical trials of Nasonex involved a group given placebos and \nanother group given treatments of Nasonex. Assume that a preliminary Phase I trial is to be \nconducted with 12 subjects, including 6 men and 6 women. If 6 of the 12 subjects are randomly \nselected for the treatment group, find the probability of getting 6 subjects of the same gender. \nWould there be a problem with having members of the treatment group all of the same gender?","page_start":191,"page_end":191,"token_count":264,"section_type":"other","chapter_number":5,"chapter_title":"DISCRETE PROBABILITY DISTRIBUTIONS","chunk_index":267}
{"chunk_id":"deb0f49b437fa71a","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"174 \nCHAPTER 4 Probability\n29. Morse Codes The International Morse code is a way of transmitting coded text by using \nsequences of on>off tones. Each character is 1 or 2 or 3 or 4 or 5 segments long, and each seg-\nment is either a dot or a dash. For example, the letter G is transmitted as two dashes followed \nby a dot, as in — — •. How many different characters are possible with this scheme? Are there \nenough characters for the alphabet and numbers?\n30. Mendel’s Peas Mendel conducted some his famous experiments with peas that were \neither smooth yellow plants or wrinkly green plants. If four peas are randomly selected from a \nbatch consisting of four smooth yellow plants and four wrinkly green plants, find the probabil-\nity that the four selected peas are of the same type.\n31. Computer Variable Names A common computer programming rule is that names of \nvariables must be between one and eight characters long. The first character can be any of the \n26 letters, while successive characters can be any of the 26 letters or any of the 10 digits. For \nexample, allowable variable names include A, BBB, and M3477K. How many different vari-\nable names are possible? (Ignore the difference between uppercase and lowercase letters.)\n32. Handshakes\na. Five physicians gather for a meeting about a patient. If each physician shakes hands with \neach other physician exactly once, what is the total number of handshakes?\nb. If n physicians shake hands with each other exactly once, what is the total number of hand-\nshakes?\nc. How many different ways can five physicians be seated at a round table? (Assume that if \neveryone moves to the right, the seating arrangement is the same.)\nd. How many different ways can n physicians be seated at a round table?\n4-6 Beyond the Basics\n1. Standard Tests Standard tests, such as the MCAT, tend to make extensive use of multiple-\nchoice questions because they are easy to grade using software. If one such multiple-choice \nquestion has possible correct answers of a, b, c, d, e, what is the probability of a wrong answer \nif the answer is a random guess?\n2.  Likelihood of Disease After obtaining a patient’s positive test result, a physician con-\ncludes that there is a 30% chance that the subject has a disease. What is the probability that the \nsubject does not have the disease?\n3. Months If a month is randomly selected after mixing the pages from a calendar, what is the \nprobability that it is a month containing the letter y?\n4.  Sigmoidoscopy, Colonoscopy Based on data from the Centers for Disease Control, \n67.7% of males over the age of 50 have had a sigmoidoscopy or colonoscopy. If two males over \nthe age of 60 are randomly selected, what is the probability that they both have had a sigmoid-\noscopy or colonoscopy?\n5. Subjective Probability Estimate the probability that the next time you get a cut, it requires \nstitches.\nChapter Quick Quiz\n","page_start":192,"page_end":192,"token_count":660,"section_type":"other","chapter_number":5,"chapter_title":"DISCRETE PROBABILITY DISTRIBUTIONS","chunk_index":268}
{"chunk_id":"7458ab4c06fa80d7","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"In Exercises 6–10, use the following results from tests of an experiment to test the effective-\nness of an experimental vaccine for children (based on data from USA Today). Express all \nprobabilities in decimal form.\nDeveloped Flu\nDid Not Develop Flu\nVaccine Treatment\n14\n1056\nPlacebo\n95\n 437\n6. If 1 of the 1602 subjects is randomly selected, find the probability of getting 1 that devel-\noped flu.\n7. If 1 of the 1602 subjects is randomly selected, find the probability of getting 1 who had the \nvaccine treatment or developed flu.\n8. If 1 of the 1602 subjects is randomly selected, find the probability of getting 1 who had the \nvaccine treatment and developed flu.\n9. Find the probability of randomly selecting 2 subjects without replacement and finding that \nthey both developed flu.\n10. Find the probability of randomly selecting 1 of the subjects and getting 1 who developed \nflu, given that the subject was given the vaccine treatment.\nIn Exercises 1–10, use the data in the accompanying table and express all results in decimal \nform. (The results are based on “Splinting vs Surgery in the Treatment of Carpal Tunnel Syn-\ndrome,” by Gerritsen et al., Journal of the American Medical Association, Vol. 288, No. 10.)\nTreatment for Carpal Tunnel Syndrome\nSuccessful Treatment\nUnsuccessful Treatment\nSplint Treatment\n60\n23\nSurgery Treatment\n67\n 6\n1. Success If 1 of the patients is randomly selected, find the probability of selecting someone \nwith a successful treatment.\n2. Success Find the probability of randomly selecting a patient and getting one with a suc-\ncessful treatment, given that the patient was treated with splinting.\n3. Success Find the probability of randomly selecting a patient and getting one with a suc-\ncessful treatment, given that the patient was treated with surgery.\n4. Success or Surgery If 1 of the patients is randomly selected, find the probability of get-\nting a patient who had a successful treatment or was treated with surgery.\n5. No Success or Splint If 1 of the patients is randomly selected, find the probability of get-\nting someone who had an unsuccessful treatment or was treated with a splint.\n6. Both Successful If 2 patients are randomly selected without replacement, find the prob-\nability that they both had successful treatments.\n7. Both Successful If 2 patients are randomly selected with replacement, find the probability \nthat they both had successful treatments.\n8. Complement If A represents the event of randomly selecting one patient included in the \ntable and getting someone who was treated with surgery, what does A represent? Find the value \nof P1A2.\nReview Exercises\nCHAPTER 4 Review Exercises \n175\n","page_start":193,"page_end":193,"token_count":593,"section_type":"other","chapter_number":5,"chapter_title":"DISCRETE PROBABILITY DISTRIBUTIONS","chunk_index":269}
{"chunk_id":"7626183edbd4f93d","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"176 \nCHAPTER 4 Probability\n9. Complement If A represents the event of randomly selecting one patient included in the \ntable and getting someone who had a successful treatment, what does A represent? Find the \nvalue of P1A2.\n10. All Three Successful If 3 patients are randomly selected without replacement, find the \nprobability that all three had successful treatments.\n11. Vision Correction About 75% of the U.S. population uses some type of vision correction \n(such as glasses or contact lenses).\na. If someone is randomly selected, what is the probability that he or she does not use vision \ncorrection?\nb. If four different people are randomly selected, what is the probability that they all use vision \ncorrection?\nc. Would it be unlikely to randomly select four people and find that they all use vision correc-\ntion? Why or why not?\n12. National Statistics Day\na. If a person is randomly selected, find the probability that his or her birthday is October 18, \nwhich is National Statistics Day in Japan. Ignore leap years.\nb. If a person is randomly selected, find the probability that his or her birthday is in October. \nIgnore leap years.\nc. Estimate a subjective probability for the event of randomly selecting an adult American and \ngetting someone who knows that October 18 is National Statistics Day in Japan.\nd. Is it unlikely to randomly select an adult American and get someone who knows that Octo-\nber 18 is National Statistics Day in Japan?\n13. Composite Sampling for Diabetes Currently, the rate for new cases of diabetes in a year \nis 3.4 per 1000 (based on data from the Centers for Disease Control and Prevention). When \ntesting for the presence of diabetes, the Portland Diagnostics Laboratory saves money by com-\nbining blood samples for tests. The combined sample tests positive if at least one person has \ndiabetes. If the combined sample tests positive, then the individual blood tests are performed. \nIn a test for diabetes, blood samples from 10 randomly selected subjects are combined. Find \nthe probability that the combined sample tests positive with at least 1 of the 10 people having \ndiabetes. Is it likely that such combined samples test positive?\n14. Redundancy Using battery-powered alarm clocks, it is estimated that the probability of \nfailure on any given day is 1>1000.\na. What is the probability that the alarm clock works for an important event?\nb. When using two alarm clocks for an important event, what is the probability that at least one \nof them works?\nCumulative Review Exercises\n1. Fatal Drunk Driving Listed below are the blood alcohol concentrations (g>dL) of drivers \nconvicted of drunk driving in fatal car crashes (based on data from the National Highway Traf-\nfic Safety Administration).\n0.09 0.11 0.11 0.13 0.14 0.15 0.17 0.17 0.18 0.18 0.23 0.35\nFind the value of the following statistics and include appropriate units.\na. mean         b. median   c. midrange   d. range\ne. standard deviation   f. variance\n","page_start":194,"page_end":194,"token_count":667,"section_type":"other","chapter_number":5,"chapter_title":"DISCRETE PROBABILITY DISTRIBUTIONS","chunk_index":270}
{"chunk_id":"8cd407b73d48e903","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"2. Fatal Drunk Driving Use the same data given in Exercise 1.\na. Identify the 5-number summary and also identify any values that appear to be outliers.\nb. Construct a boxplot.  c. Construct a stemplot.\n3. Organ Donors USA Today provided information about a survey (conducted for Donate Life \nAmerica) of 5100 adult Internet users. Of the respondents, 2346 said they are willing to donate \norgans after death. In this survey, 100 adults were surveyed in each state and the District of Co-\nlumbia, and results were weighted to account for the different state population sizes.\na. What percentage of respondents said that they are willing to donate organs after death?\nb. Based on the poll results, what is the probability of randomly selecting an adult who is will-\ning to donate organs after death?\nc. What term is used to describe the sampling method of randomly selecting 100 adults from \neach state and the District of Columbia?\n4. Sampling Eye Color Based on a study by Dr. P. Sorita Soni, eye colors in the United States \nare as follows: 40% brown, 35% blue, 12% green, 7% gray, 6% hazel.\na. A statistics instructor collects eye color data from her students. What is the name for this \ntype of sample?\nb. Identify one factor that might make the sample from part (a) biased and not representative of \nthe general population of people in the United States.\nc. What is the probability that a randomly selected person will have brown or blue eyes?\nd. If two people are randomly selected, what is the probability that at least one of them has \nbrown eyes?\n5. Blood Pressure and Platelets Given below are the systolic blood pressure measurements \n(mm Hg) and blood platelet counts (1000 cells>mL) of the first few subjects included in Data \nSet 1 “Body Data” in Appendix B. Construct a graph suitable for exploring an association be-\ntween systolic blood pressure and blood platelet count. What does the graph suggest about that \nassociation?\nSystolic\n100\n112\n134\n126\n114\n134\n118\n138\n114\n124\nPlatelet\n319\n187\n297\n170\n140\n192\n191\n286\n263\n193\nCHAPTER 4 Technology Project \n177\nSimulations Calculating probabilities are sometimes painfully difficult, but simulations pro-\nvide us with a very practical alternative to calculations based on formal rules. A simulation \nof a procedure is a process that behaves the same way as the procedure so that similar results \nare produced. Instead of calculating the probability of getting exactly 5 boys in 10 births, you \ncould repeatedly toss 10 coins and count the number of times that exactly 5 heads (or simulated \n“boys”) occur. Better yet, you could do the simulation with a random number generator on a \ncomputer or calculator to randomly generate 1s (or simulated “boys”) and 0s (or simulated \n“girls”). Let’s consider this probability exercise:\nFind the probability that among 50 randomly selected people, at least 3 have  ","page_start":195,"page_end":195,"token_count":661,"section_type":"other","chapter_number":5,"chapter_title":"DISCRETE PROBABILITY DISTRIBUTIONS","chunk_index":271}
{"chunk_id":"577f4ff4ac3d77fd","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"could repeatedly toss 10 coins and count the number of times that exactly 5 heads (or simulated \n“boys”) occur. Better yet, you could do the simulation with a random number generator on a \ncomputer or calculator to randomly generate 1s (or simulated “boys”) and 0s (or simulated \n“girls”). Let’s consider this probability exercise:\nFind the probability that among 50 randomly selected people, at least 3 have  \nthe same birthday.\nFor the above problem, a simulation begins by representing birthdays by integers from \n1 through 365, where 1 represents a birthday of January 1, and 2 represents January 2, \nand so on. We can simulate 50 birthdays by using a calculator or computer to generate 50 \nTechnology Project\ncontinued","page_start":195,"page_end":195,"token_count":161,"section_type":"other","chapter_number":5,"chapter_title":"DISCRETE PROBABILITY DISTRIBUTIONS","chunk_index":272}
{"chunk_id":"d57a326eb66fa26a","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"178 \nCHAPTER 4 Probability\nrandom numbers (with repetition allowed) between 1 and 365. Those numbers can then be \nsorted, so it becomes easy to examine the list to determine whether any 3 of the simulated \nbirth dates are the same. (After sorting, equal numbers are adjacent.) We can repeat the \nprocess as many times as we wish, until we are satisfied that we have a good estimate of the \nprobability. Use technology to simulate 20 different groups of 50 birthdays. Use the results \nto estimate the probability that among 50 randomly selected people, at least 3 have the same \nbirthday.\nSummary of Simulation Functions:\nStatdisk: \n Select Data from the top menu, select Uniform Generator from the \ndropdown menu.\nExcel: \n Click Insert Function fx, select Math & Trig, select  \nRANDBETWEEN. Copy to additional cells.\nTI-83 , 84 Plus:  Press L, select PROB from the top menu, select randInt from the menu.\nStatCrunch: \n Select Data from the top menu, select Simulate from the dropdown \nmenu, select Discrete Uniform from the submenu.\nMinitab: \n Select Calc from the top menu, select Random Data from the drop-\ndown menu, select Integer from the submenu.\nFROM DATA TO DECISION \nCritical Thinking:  \nInterpreting results from a test for smoking\nIt is estimated that roughly half of patients who smoke lie \nwhen asked if they smoke. Pulse CO-oximeters may be a \nway to get information about smoking without relying on pa-\ntients’ statements. Pulse CO-oximeters use light that shines \nthrough a fingernail, and it measures carboxyhemoglobin \n(carbon monoxide in blood). These devices are used by fire-\nmen and emergency departments to detect carbon monoxide \npoisoning, but they can also be used to identify smokers. The \naccompanying table lists results from people aged 18–44 \nwhen the pulse CO-oximeter is set to detect a 6% or higher \nlevel of carboxyhemoglobin (based on data from “Carbon \nMonoxide Test Can Be Used to Identify Smoker,” by Patrice \nWendling, Internal Medicine News, Vol. 40., No. 1, and \nCenters for Disease Control and Prevention).\nCO-Oximetry Test for Smoking\nPositive Test Result\nNegative Test Result\nSmoker\n49\n 57\nNonsmoker\n24\n370\nAnalyzing the Results\n1. False Positive Based on the results in the table, find the \nprobability that a subject is not a smoker, given that the test \nresult is positive.\n2. True Positive Based on the results in the table, find the \nprobability that a subject smokes, given that the test result is \npositive.\n3. False Negative Based on the results in the table, find the \nprobability that a subject smokes, given that the test result is \nnegative.\n4. True Negative Based on the results in the table, find the \nprobability that a subject does not smoke, given that the test \nresult is negative.","page_start":196,"page_end":196,"token_count":649,"section_type":"other","chapter_number":5,"chapter_title":"DISCRETE PROBABILITY DISTRIBUTIONS","chunk_index":273}
{"chunk_id":"e68c041987d24494","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"result is positive.\n2. True Positive Based on the results in the table, find the \nprobability that a subject smokes, given that the test result is \npositive.\n3. False Negative Based on the results in the table, find the \nprobability that a subject smokes, given that the test result is \nnegative.\n4. True Negative Based on the results in the table, find the \nprobability that a subject does not smoke, given that the test \nresult is negative.\n5. Sensitivity Find the sensitivity of the test by finding the \nprobability of a true positive, given that the subject actually \nsmokes.\n6. Specificity Find the specificity of the test by finding the \nprobability of a true negative, given that the subject does not \nsmoke.\n7. Positive Predictive Value Find the positive predictive \nvalue of the test by finding the probability that the subject \nsmokes, given that the test yields a positive result.\n8. Negative Predictive Value Find the negative predictive \nvalue of the test by finding the probability that the subject \ndoes not smoke, given that the test yields a negative result.\n9. Confusion of the Inverse Find the following values, \nthen compare them. In this case, what is confusion of the \ninverse?\n• P(smoker \u001f positive test result)\n• P(positive test result \u001f smoker)","page_start":196,"page_end":196,"token_count":278,"section_type":"other","chapter_number":5,"chapter_title":"DISCRETE PROBABILITY DISTRIBUTIONS","chunk_index":274}
{"chunk_id":"0e999b5f3a9577bd","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"Cooperative Group Activities\n1. In-class activity Divide into groups of three or four and use coin flipping to develop a simula-\ntion that emulates the kingdom that abides by this decree: After a mother gives birth to a son, she \nwill not have any other children. If this decree is followed, does the proportion of girls increase?\n2. In-class activity Divide into groups of three or four and use actual thumbtacks or Hershey’s \nKisses candies, or paper cups, to estimate the probability that when dropped, they will land \nwith the point (or open side) up. How many trials are necessary to get a result that appears to be \nreasonably accurate when rounded to the first decimal place?\n3. Out-of-class activity Marine biologists often use the capture-recapture method as a way \nto estimate the size of a population, such as the number of fish in a lake. This method involves \ncapturing a sample from the population, tagging each member in the sample, and then return-\ning it to the population. A second sample is later captured, and the tagged members are counted \nalong with the total size of this second sample. The results can be used to estimate the size of \nthe population.\nInstead of capturing real fish, simulate the procedure using some uniform collection of \nitems such as colored beads, M&Ms, or index cards. Start with a large collection of at least \n200 of such items. Collect a sample of 50 and use a marker to “tag” each one. Replace the \ntagged items, mix the whole population, then select a second sample and proceed to estimate \nthe population size. Compare the result to the actual population size obtained by counting all \nof the items.\n4. Out-of-class activity In Cumulative Review Exercise 4, it was noted that eye colors in \nthe United States are distributed as follows: 40% brown, 35% blue, 12% green, 7% gray, 6% \nhazel. That distribution can form the basis for probabilities. Conduct a survey by asking fellow \nstudents to identify the color of their eyes. Does the probability of 0.4 for brown eyes appear to \nbe consistent with your results? Why would a large sample be required to confirm that P(hazel \neyes) = 0.06?\nCHAPTER 4 Cooperative Group Activities \n179\n","page_start":197,"page_end":197,"token_count":490,"section_type":"other","chapter_number":5,"chapter_title":"DISCRETE PROBABILITY DISTRIBUTIONS","chunk_index":275}
{"chunk_id":"92337030e5753aa8","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"180\nProbability Distributions\nBinomial Probability \nDistributions\nPoisson Probability \nDistributions\n5-1\n5-2\n5-3\nIs the XSORT Gender Selection Method Effective?\nCHAPTER \nPROBLEM\nDiscrete Probability \nDistributions\nWe live in a time with incredible advances in technology, med-\nicine, and health care. Cloning is no longer science  fiction. We \nhave iPads, iPhones, virtual-reality headsets, and self-driving \ncars. We carry calculators that can instantly execute many \ncomplex statistical calculations. Heart  pacemakers have defi-\nbrillators capable of shocking and restarting stopped hearts. \nCouples use procedures that are claimed to greatly increase \nthe chance of having a baby with a desired gender.\nSome people argue that gender selection methods should \nbe banned, regardless of the reason, while others enthusiasti-\ncally support the use of such methods. Lisa Belkin asked in the \nNew York Times Magazine, “If we allow parents to choose the \nsex of their child today, how long will it be before they order up \neye color, hair color, personality traits, and IQ?” There are some \nconvincing arguments in favor of at least limited use of gender \nselection. One such argument involves couples carrying  \n5 \n","page_start":198,"page_end":198,"token_count":268,"section_type":"other","chapter_number":5,"chapter_title":"DISCRETE PROBABILITY DISTRIBUTIONS","chunk_index":276}
{"chunk_id":"1675241cd8cc1833","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"X-linked recessive genes. For some of these couples, any male \nchildren have a 50% chance of inheriting a disorder, but none \nof the female children will inherit the disorder. These couples \nmay want to use gender selection as a way to ensure that they \nhave baby girls, thereby guaranteeing that a disorder will not \nbe inherited by any of their children.\nThe Genetics & IVF Institute in Fairfax, Virginia, devel-\noped a technique called MicroSort and claimed that it in-\ncreases the chances of a couple having a baby with a desired \ngender. (Clinical trials of MicroSort have been discontinued.) \nThe  MicroSort XSORT method is claimed to increase the \nchances of a couple having a baby girl, and the MicroSort \nYSORT method is claimed to increase the chances of a \nbaby boy. The latest results for the XSORT method consist \nof 945 couples who wanted to have baby girls. After using \nthe XSORT technique, 879 of those couples had baby girls. \n(See Figure 5-1 for a bar graph illustrating these results.) \nWe usually expect that in 945 births, the number of girls \nshould be somewhere around 472 or 473. Given that 879 out \nof 945 couples had girls, can we conclude that the XSORT \ntechnique is effective, or might we explain the outcome as \njust a chance sample result? In answering that question, we \nwill use principles of probability to determine whether the \nobserved birth  results differ significantly from results that we \nwould expect from random chance. This is a common goal \nof inferential statistics: Determine whether results can be \nreasonably  explained by random chance or whether random \nchance doesn’t appear to be a feasible explanation, so that \nother  factors are influencing results. In this chapter we pres-\nent methods that allow us to find the probabilities we need \nfor  determining whether the XSORT results are significant, \n suggesting that the method is effective.\nFigure 5-2 on the next page provides a visual illustration of what this chapter accom-\nplishes. When investigating the numbers of heads in two coin tosses, we can use the \nfollowing two different approaches:\n• Use real sample data to find actual results: The approach of Chapters 2 and 3 is \nto collect sample data from actual coin tosses, then summarize the results in a table \nrepresenting the frequency distribution, and then find statistics, such as the sample \nmean x and the sample standard deviation s.\n• Use probabilities to find expected results: Using principles of probability from \nChapter 4, we can find the probability for each possible number of heads in two \ntosses. Then we could summarize the results in a table representing a probability \ndistribution.\nIn this chapter we merge the above two approaches as we create a table de-\nscribing what we expect to happen (instead of what did happen), then we find the \npopulation mean m and population standard deviation s. The table at the extreme \nright in Figure 5-2 is a probability distribution, because it describes the distribution ","page_start":199,"page_end":199,"token_count":640,"section_type":"other","chapter_number":5,"chapter_title":"DISCRETE PROBABILITY DISTRIBUTIONS","chunk_index":277}
{"chunk_id":"8f33193c6a0867e4","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"tosses. Then we could summarize the results in a table representing a probability \ndistribution.\nIn this chapter we merge the above two approaches as we create a table de-\nscribing what we expect to happen (instead of what did happen), then we find the \npopulation mean m and population standard deviation s. The table at the extreme \nright in Figure 5-2 is a probability distribution, because it describes the distribution \nusing probabilities instead of frequency counts. The remainder of this book and  \nthe core of inferential statistics are based on some knowledge of probability  \ndistributions. In this chapter we focus on discrete probability distributions.  \nChapter Objectives \n181\nCHAPTER OBJECTIVES\n>>>\nFIGURE 5-1 Results from the XSORT Method of \nGender Selection","page_start":199,"page_end":199,"token_count":157,"section_type":"other","chapter_number":5,"chapter_title":"DISCRETE PROBABILITY DISTRIBUTIONS","chunk_index":278}
{"chunk_id":"9b1f7ec948308f4b","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"182 \nCHAPTER 5 Discrete Probability Distributions\nKey Concept This section introduces the concept of a random variable and the con-\ncept of a probability distribution. We illustrate how a probability histogram is a graph \nthat visually depicts a probability distribution. We show how to find the important \nparameters of mean, standard deviation, and variance for a probability distribution. \nMost importantly, we describe how to determine whether outcomes are significant \n(significantly low or significantly high). We begin with the related concepts of random \nvariable and probability distribution.\n5-1 \n Probability Distributions\nCount numbers of\nheads in tosses of\ntwo coins.\nCollect sample\ndata from two coin\ntosses, then ﬁnd\nstatistics and\ncreate graphs.\nNumber\nof heads\nx\n0\n1\n2\nf\n27\n56\n17\nCreate a theoretical model\nof the expected results,\nthen ﬁnd parameters.\nFind the probability for\neach possible number of\nheads in two coin tosses.\nP(0) 5 0.25\nP(1) 5 0.50\nP(2) 5 0.25\nChapters\n2 and 3\nChapter 4\nChapters 2 and 3\nChapter 5\nChapter 4\nx 5 0.9\ns 5 0.7\nNumber of\nheads in two\ncoin tosses\nx\n0\n1\n2\nP(x)\n0.25\n0.50\n0.25\nm 5 1.0\ns 5 0.7\nFIGURE 5-2\nHere are the chapter objectives:\nProbability Distributions\n• Define random variable and probability distribution.\n• Determine when a potential probability distribution actually satisfies the necessary \nrequirements.\n• Given a probability distribution, compute the mean and standard deviation, then use \nthose results to determine whether results are significantly low or significantly high.\nBinomial Probability Distributions\n• Describe a binomial probability distribution and find probability values for a binomial \ndistribution.\n• Compute the mean and standard deviation for a binomial distribution, then use \nthose results to determine whether results are significantly low or significantly high.\nPoisson Probability Distributions\n• Describe a Poisson probability distribution and find probability values for a Poisson \ndistribution.\n5-1\n5-2\n5-3\nCollect sample\ndata from two coin\ntosses, then ﬁnd\nstatistics and\ncreate graphs.\nNumber\nof heads\nx\n0\n1\n2\nf\n27\n56\n17\nCreate a theoretical model\nof the expected results,\nthen ﬁnd parameters.\nFind the probability for\neach possible number of\nheads in two coin tosses.\nP(0) 5 0.25\nP(1) 5 0.50\nP(2) 5 0.25\nChapters 2 and 3\nChapter 5\nChapter 4\nx 5 0.9\ns 5 0.7\nNumber of\nheads in two\ncoin tosses\nx\n0\n1\n2\nP(x)x)x\n0.25\n0.50\n0.25","page_start":200,"page_end":200,"token_count":666,"section_type":"other","chapter_number":5,"chapter_title":"DISCRETE PROBABILITY DISTRIBUTIONS","chunk_index":279}
{"chunk_id":"d07690d11f6c85eb","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"Find the probability for\neach possible number of\nheads in two coin tosses.\nP(0) 5 0.25\nP(1) 5 0.50\nP(2) 5 0.25\nChapters 2 and 3\nChapter 5\nChapter 4\nx 5 0.9\ns 5 0.7\nNumber of\nheads in two\ncoin tosses\nx\n0\n1\n2\nP(x)x)x\n0.25\n0.50\n0.25\nm 5 1.0\ns 5 0.7\nHere are the chapter objectives:\nProbability Distributions\n• Define random variable and probability distribution.\n• Determine when a potential probability distribution actually satisfies the necessary \nrequirements.\n• Given a probability distribution, compute the mean and standard deviation, then use\nthose results to determine whether results are significantly low or significantly high.\nBinomial Probability Distributions\n• Describe a binomial probability distribution and find probability values for a binomial\ndistribution.\n• Compute the mean and standard deviation for a binomial distribution, then use \nthose results to determine whether results are significantly low or \nw \nw\nsignificantly high.\nPoisson Probability Distributions\n• Describe a Poisson probability distribution and find probability values for a Poisson \ndistribution.","page_start":200,"page_end":200,"token_count":279,"section_type":"other","chapter_number":5,"chapter_title":"DISCRETE PROBABILITY DISTRIBUTIONS","chunk_index":280}
{"chunk_id":"e6e4042327d00c3b","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"5-1 Probability Distributions \n183\nPART 1\nBasic Concepts of a Probability Distribution\nDEFINITIONS\nA random variable is a variable (typically represented by x) that has a single nu-\nmerical value, determined by chance, for each outcome of a procedure.\nA probability distribution is a description that gives the probability for each value \nof the random variable. It is often expressed in the format of a table, formula, or \ngraph.\nIn Section 1-2 we made a distinction between discrete and continuous data. \n Random variables may also be discrete or continuous, and the following two defini-\ntions are consistent with those given in Section 1-2.\nDEFINITIONS\nA discrete random variable has a collection of values that is finite or countable. \n(If there are infinitely many values, the number of values is countable if it is pos-\nsible to count them individually, such as the number of tosses of a coin before \ngetting heads.)\nA continuous random variable has infinitely many values, and the collec-\ntion of values is not countable. (That is, it is impossible to count the individual \nitems because at least some of them are on a continuous scale, such as body \ntemperatures.)\nThis chapter deals exclusively with discrete random variables, but the following \nchapters deal with continuous random variables.\nProbability Distribution: Requirements\nEvery probability distribution must satisfy each of the following three requirements.\n1. There is a numerical (not categorical) random variable x, and its number values \nare associated with corresponding probabilities.\n2. ΣP(x)  =   1 where x assumes all possible values. (The sum of all probabilities \nmust be 1, but sums such as 0.999 or 1.001 are acceptable because they result \nfrom rounding errors.)\n3. 0 … P(x) … 1 for every individual value of the random variable x. (That is, \neach probability value must be between 0 and 1 inclusive.)\nThe second requirement comes from the simple fact that the random variable x \nrepresents all possible events in the entire sample space, so we are certain (with prob-\nability 1) that one of the events will occur. The third requirement comes from the basic \nprinciple that any probability value must be 0 or 1 or a value between 0 and 1.\nEXAMPLE 1  Genetics\nAlthough the Chapter Problem involves 945 births, let’s consider a simpler example \nthat involves only two births with the following random variable:\nx = number of girls in two births\nThe above x is a random variable because its numerical values depend on chance. \nWith two births, the number of girls can be 0, 1, or 2, and Table 5-1 is a probability \ncontinued\n","page_start":201,"page_end":201,"token_count":580,"section_type":"other","chapter_number":5,"chapter_title":"DISCRETE PROBABILITY DISTRIBUTIONS","chunk_index":281}
{"chunk_id":"88eea4c7c620ecae","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"184 \nCHAPTER 5 Discrete Probability Distributions\nNotation for 0+\nIn tables such as Table 5-1 or the binomial probabilities listed in Table A-1 in \nAppendix A, we sometimes use 0+ to represent a probability value that is positive \nbut very small, such as 0.000000123. When rounding a probability value for inclu-\nsion in such a table, rounding to 0 would be misleading because it would incor-\nrectly suggest that the event is impossible.\nProbability Histogram: Graph of a Probability Distribution\nThere are various ways to graph a probability distribution, but for now we will con-\nsider only the probability histogram. Figure 5-3 is a probability histogram corre-\nsponding to Table 5-1. Notice that it is similar to a relative frequency histogram (de-\nscribed in Section 2-2), but the vertical scale shows probabilities instead of relative \nfrequencies based on actual sample results.\ndistribution because it gives the probability for each value of the random variable x \nand it satisfies the three requirements listed earlier:\n \n1. The variable x is a numerical random variable and its values are associated \nwith probabilities, as in Table 5-1.\n \n2. ΣP(x) = 0.25 + 0.50 + 0.25 = 1\n3. Each value of P(x) is between 0 and 1. (Speciﬁcally, 0.25 and 0.50 and 0.25 \nare each between 0 and 1 inclusive.)\nThe random variable x in Table 5-1 is a discrete random variable, because it has \nthree possible values (0, 1, 2), and 3 is a finite number, so this satisfies the require-\nment of being finite or countable.\nTABLE 5-1 Probability \n Distribution for the Number of \nGirls in Two Births\nx: Number  \nof Girls\n \nP(x)\n0\n0.25\n1\n0.50\n2\n0.25\nFIGURE 5-3  Probability Histogram for Number of \nGirls in Two Births\nIn Figure 5-3, we see that the values of 0, 1, 2 along the horizontal axis are lo-\ncated at the centers of the rectangles. This implies that the rectangles are each 1 unit \nwide, so the areas of the rectangles are 0.25, 0.50, and 0.25. The areas of these rectan-\ngles are the same as the probabilities in Table 5-1. We will see in Chapter 6 and future \nchapters that such a correspondence between areas and probabilities is very useful.\nProbability Formula Example 1 involves a table, but a probability distribution \ncould also be in the form of a formula. Consider the formula P(x) =\n1\n2(2 - x)! x!\n","page_start":202,"page_end":202,"token_count":608,"section_type":"other","chapter_number":5,"chapter_title":"DISCRETE PROBABILITY DISTRIBUTIONS","chunk_index":282}
{"chunk_id":"f35fd5f10b0a639f","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"5-1 Probability Distributions \n185\n(where x can be 0, 1, or 2). Using that formula, we find that P102 = 0.25, P112 = 0.50,\nand P122 = 0.25. The probabilities found using this formula are the same as those in \nTable 5-1. This formula does describe a probability distribution because the three re-\nquirements are satisfied, as shown in Example 1.\nTABLE 5-2 Hospital Job Interview Mistakes\nx\nP(x)\nInappropriate attire\n0.50\nBeing late\n0.44\nLack of eye contact\n0.33\nChecking phone or texting\n0.30\nTotal\n1.57\nEXAMPLE 2  Hospital Job Interview Mistakes\nHiring managers were asked to identify the biggest mistakes that job applicants \nmake during an interview, and Table 5-2 is based on their responses (based on data \nfrom an Adecco survey). Does Table 5-2 describe a probability distribution?\nSOLUTION\nTable 5-2 violates the first requirement because x is not a numerical random vari-\nable. Instead, the “values” of x are categorical data, not numbers. Table 5-2 also \nviolates the second requirement because the sum of the probabilities is 1.57, but that \nsum should be 1. Because the three requirements are not all satisfied, we conclude \nthat Table 5-2 does not describe a probability distribution.\nParameters of a Probability Distribution\nRemember that with a probability distribution, we have a description of a population \ninstead of a sample, so the values of the mean, standard deviation, and variance are \nparameters, not statistics. The mean, variance, and standard deviation of a discrete \nprobability distribution can be found with the following formulas:\nFORMULA 5-1 Mean M for a probability distribution\nm = Σ3x # P1x24 \nFORMULA 5-2 Variance S2 for a probability distribution\ns2 = Σ3 1x - m2 2 # P1x24 (This format is easier to understand.)\nFORMULA 5-3 Variance S2 for a probability distribution\ns2 = Σ3x2 # P1x24 - m2 (This format is easier for manual calculations.)\nFORMULA 5-4 Standard deviation S for a probability distribution\ns = 2Σ3x2 # P1x24 - m2 \n","page_start":203,"page_end":203,"token_count":518,"section_type":"other","chapter_number":5,"chapter_title":"DISCRETE PROBABILITY DISTRIBUTIONS","chunk_index":283}
{"chunk_id":"9ba655936541f806","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"186 \nCHAPTER 5 Discrete Probability Distributions\nWhen applying Formulas 5-1 through 5-4, use the following rule for rounding results.\nRound-Off Rule For m, s, And s2 From A Probability Distribution\nRound results by carrying one more decimal place than the number of decimal \nplaces used for the random variable x. If the values of x are integers, round m, s, \nand s2 to one decimal place.\nExceptions to Round-Off Rule In some special cases, the above round-off rule re-\nsults in values that are misleading or inappropriate. For example, with four-engine \njets the mean number of jet engines working successfully throughout a flight is \n3.999714286, which becomes 4.0 when rounded, but that is misleading because it \nsuggests that all jet engines always work successfully. Here we need more precision to \ncorrectly  reflect the true mean, such as the precision in 3.999714.\nExpected Value\nThe mean of a discrete random variable x is the theoretical mean outcome for infinitely \nmany trials. We can think of that mean as the expected value in the sense that it is the \naverage value that we would expect to get if the trials could continue indefinitely.\nDEFINITION\nThe expected value of a discrete random variable x is denoted by E, and it is the \nmean value of the outcomes, so E = m and E can also be found by evaluating \nΣ 3x # P1x24, as in Formula 5-1.\nCAUTION An expected value need not be a whole number, even if the different \npossible values of x might all be whole numbers. The expected number of girls in \nfive births is 2.5, even though five particular births can never result in 2.5 girls. If we \nwere to survey many couples with five children, we expect that the mean number of \ngirls will be 2.5.\nEXAMPLE 3   Finding the Mean, Variance, and  \nStandard Deviation\nTable 5-1 on page 184 describes the probability distribution for the number of girls \nin two births (assuming that boys and girls are equally likely). Find the mean, vari-\nance, and standard deviation for the probability distribution described in Table 5-1 \nfrom Example 1.\nSOLUTION\nIn Table 5-3, the two columns at the left describe the probability distribution given \nearlier in Table 5-1. We create the two columns at the right for the purposes of the \ncalculations required.\nUsing Formulas 5-1 and 5-2 and the table results, we get\nMean: m = Σ3x # P1x2 4 = 1.0\nVariance: s2 = Σ3 1x - m2 2 # P1x2 4 = 0.5\n","page_start":204,"page_end":204,"token_count":601,"section_type":"other","chapter_number":5,"chapter_title":"DISCRETE PROBABILITY DISTRIBUTIONS","chunk_index":284}
{"chunk_id":"a1f4f807acc9e266","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"5-1 Probability Distributions \n187\nINTERPRETATION\nAssuming that boys and girls are equally likely in two births, the mean number of \ngirls is 1.0, the variance is 0.50 girls2, and the standard deviation is 0.7 girl. Also, \nthe expected value for the number of girls in two births is 1.0 girl, which is the same \nvalue as the mean. If we were to collect data on a large number of trials with two \nbirths in each trial, we expect to get a mean of 1.0 girl.\nThe standard deviation is the square root of the variance, so\nStandard deviation: s = 20.5 = 0.707107 = 0.7 1rounded2\nRounding: In Table 5-3, we use m = 1.0. If m had been the value of 1.23456, we \nmight round m to 1.2, but we should use its unrounded value of 1.23456 in \nTable 5-3 calculations. Rounding in the middle of calculations can lead to results \nwith errors that are too large.\nTABLE 5-3 Calculating m and s for a Probability Distribution\nx\nP1x2\nx # P1x2\n1x −m 22 # P1x2\n0\n0.25\n0 # 0.25 = 0.00\n10 - 12 2 # 0.25 =  0.25\n1\n0.50\n1 # 0.50 = 0.50\n11 - 12 2 # 0.50 = 0.00\n2\n0.25\n2 # 0.25 = 0.50\n12 - 12 2 # 0.25 =  0.25\nTotal\n  1.00\n   c\nm = Σ3x # P1x24\n       0.50\nc\ns2 = Σ 31x - m2 2 # P1x24\nMaking Sense of Results: Significant Values\nWe present the following two different approaches for determining whether a value of \na random variable x is significantly low or high.\nIdentifying Significant Results with the Range Rule of Thumb\nThe range rule of thumb (introduced in Section 3-2) may be helpful in interpreting the \nvalue of a standard deviation. According to the range rule of thumb, the vast major-\nity of values should lie within 2 standard deviations of the mean, so we can consider \na value to be significant if it is at least 2 standard deviations away from the mean. We \ncan therefore identify “significant” values as follows:\nRange Rule of Thumb for Identifying Significant Values\nSigniﬁcantly low values are 1m - 2s2 or lower.\nSignificantly high values are 1m + 2s2 or higher.\nValues not signiﬁcant: Between 1m -  2s2 and 1m + 2s2\nFigure 3-3 from Section 3-2 illustrates the above criteria:\nValues not signiﬁcant","page_start":205,"page_end":205,"token_count":676,"section_type":"other","chapter_number":5,"chapter_title":"DISCRETE PROBABILITY DISTRIBUTIONS","chunk_index":285}
{"chunk_id":"68f8b5b5c262e514","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"Range Rule of Thumb for Identifying Significant Values\nSigniﬁcantly low values are 1m - 2s2 or lower.\nSignificantly high values are 1m + 2s2 or higher.\nValues not signiﬁcant: Between 1m -  2s2 and 1m + 2s2\nFigure 3-3 from Section 3-2 illustrates the above criteria:\nValues not signiﬁcant\nSigniﬁcantly\nlow values\nSigniﬁcantly\nhigh values\nm\nm − 2s\nm + 2s\nHINT Know that the use of the number 2 in the range rule of thumb is somewhat \narbitrary, and this is a guideline, not an absolutely rigid rule.","page_start":205,"page_end":205,"token_count":167,"section_type":"other","chapter_number":5,"chapter_title":"DISCRETE PROBABILITY DISTRIBUTIONS","chunk_index":286}
{"chunk_id":"c82bda53f8580327","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"188 \nCHAPTER 5 Discrete Probability Distributions\nIdentifying Significant Results with Probabilities:\n \n■Significantly high number of successes: x successes among n trials is a signifi-\ncantly high number of successes if the probability of x or more successes is 0.05 or \nless. That is, x is a significantly high number of successes if P(x or more) … 0.05.*\n \n■Significantly low number of successes: x successes among n trials is a significantly \nlow number of successes if the probability of x or fewer successes is 0.05 or less. \nThat is, x is a significantly low number of successes if P(x or fewer) … 0.05.*\nEXAMPLE 4   Identifying Significant Results with the  \nRange Rule of Thumb\nIn Example 3 we found that with two births, the mean number of girls is m = 1.0 \ngirl and the standard deviation is s = 0.7 girl. Use those results and the range rule \nof thumb to determine whether 2 girls is a significantly high number of girls.\nSOLUTION\nUsing the range rule of thumb, the value of 2 girls is significantly high if it is greater \nthan or equal to m + 2s. With m = 1.0 girl and s = 0.7 girl, we get\nm + 2s = 1 + 210.72 = 2.4 girls\nSignificantly high numbers of girls are 2.4 and above.\nINTERPRETATION\nBased on these results, we conclude that 2 girls is not a significantly high number of \ngirls (because 2 is not greater than or equal to 2.4).\n*The value 0.05 is not absolutely rigid. Other values, such as 0.01, could be used to distinguish between results \nthat are signiﬁcant and those that are not signiﬁcant.\nIdentification of significantly low or significantly high numbers of successes is some-\ntimes used for the purpose of rejecting assumptions, as stated in the following rare \nevent rule.\nThe Rare Event Rule for Inferential Statistics\nIf, under a given assumption, the probability of a particular outcome is \nvery small and the outcome occurs signiﬁcantly less than or signiﬁcantly \ngreater than what we expect with that assumption, we conclude that the \nassumption is probably not correct.\nFor example, if testing the assumption that boys and girls are equally likely, the out-\ncome of 20 girls in 100 births is significantly low and would be a basis for rejecting \nthat assumption.\nEXAMPLE 5  Identifying Significant Results with Probabilities\nIs 879 girls in 945 births a signiﬁcantly high number of girls?\nWhat does the result suggest about the Chapter Problem, which includes results \nfrom the XSORT method of gender selection? (Among 945 births from parents us-\ning the XSORT method, there were 879 girls. Is 879 girls in those 945 births  \nsigniﬁcantly high?)\n","page_start":206,"page_end":206,"token_count":635,"section_type":"other","chapter_number":5,"chapter_title":"DISCRETE PROBABILITY DISTRIBUTIONS","chunk_index":287}
{"chunk_id":"5ec7e98159eb58c3","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"5-1 Probability Distributions \n189\nNot Exactly, but “At Least as Extreme”\nIt should be obvious that among 945 births, 879 girls is significantly high, whereas \n475 girls is not significantly high. What makes 879 girls significant while 475 girls \nis not significant? It is not probabilities of exactly 879 girls and 475 girls (they are \nboth less than 0.026). It is the fact that the probability of 879 or more girls is very low \n(0.0000), but the probability of 475 or more girls is not low (0.448).\nPART 2  Expected Value and Rationale for Formulas\nExpected Value\nIn Part 1 of this section we noted that the expected value of a random variable x is equal \nto the mean m. We can therefore find the expected value by computing Σ3x # P1x2 4, \njust as we do for finding the value of m.\nSOLUTION\nA result of 879 girls in 945 births is greater than we expect with random chance, \nbut we need to determine whether 879 girls is significantly high. Here, the relevant \nprobability is the probability of getting 879 or more girls in 945 births. Using \nmethods covered later in Section 5-2, we can find that P(879 or more girls in 945 \nbirths) = 0.0000 (rounded). Because the probability of getting 879 or more girls is \nless than or equal to 0.05, we conclude that 879 girls in 945 births is a significantly \nhigh number of girls. See Figure 5-4, which is a probability histogram showing the \nprobability for the different numbers of girls.\nFIGURE 5-4 Probability Histogram of Girls in 945 Births\nEXAMPLE 6  Births\nAssuming that boys and girls are equally likely, find the expected number of girls in \n945 births. Instead of using Formula 5-1, just think about the number of girls  \nexpected in 945 births.\nSOLUTION\nThe expected number of girls in 945 births is 472.5 girls.\ncontinued\nINTERPRETATION\nIt is unlikely that we would get 879 or more girls in 945 births by chance. It follows \nthat 879 girls in 945 births is significantly high, so the XSORT method appears to \nbe effective (but this does not prove that the XSORT method is responsible for the \nlarge number of girls).\nDo Boys or Girls Run in \nthe Family?\nOne of the \nauthors of \nthis book, his \nsiblings, and \nhis siblings’ \nchildren consist \nof 11 males and \nonly 1 female. \nIs this an example of a phenom-\nenon whereby one particular \ngender runs in a family? This \nissue was studied by examin-\ning a random sample of 8770 \nhouseholds in the United States. \nThe results were reported in the \nChance magazine article “Does \nHaving Boys or Girls Run in the \nFamily?” by  Joseph Rodgers \nand Debby Doughty. Part of \ntheir analysis involves use of the \nbinomial probability distribution \ndiscussed in this section. Their \nconclusion is that “We found no \ncompelling evidence that sex \nbias runs in the family.”\n","page_start":207,"page_end":207,"token_count":688,"section_type":"other","chapter_number":5,"chapter_title":"DISCRETE PROBABILITY DISTRIBUTIONS","chunk_index":288}
{"chunk_id":"0fd7ed93ebeb9598","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"190 \nCHAPTER 5 Discrete Probability Distributions\nRationale for Formulas 5-1 Through 5-4\nInstead of blindly accepting and using formulas, it is much better to have some un-\nderstanding of why they work. When computing the mean from a frequency distribu-\ntion, f represents class frequency and N represents population size. In the expression \nbelow, we rewrite the formula for the mean of a frequency table so that it applies to a \npopulation. In the fraction f>N, the value of f is the frequency with which the value x \noccurs and N is the population size, so f>N is the probability for the value of x. When \nwe replace f>N with P(x), we make the transition from relative frequency based on \na limited number of observations to probability based on infinitely many trials. This \nresult shows why Formula 5-1 is as given earlier in this section.\nm = Σ1f # x2\nN\n= Σc f # x\nN d = Σcx # f\nN d = Σ3x # P1x2 4\nSimilar reasoning enables us to take the variance formula from Chapter 3 and \n apply it to a random variable for a probability distribution; the result is Formula 5-2. \nFormula 5-3 is a shortcut version that will always produce the same result as Formula 5-2. \nAlthough Formula 5-3 is usually easier to work with, Formula 5-2 is easier to under-\nstand directly. Based on Formula 5-2, we can express the standard deviation as\ns = 2Σ3 1x - m2 2 # P1x2 4\nor as the equivalent form given in Formula 5-4.\nINTERPRETATION\nIn any specific sample of 945 births, we can never get 472.5 girls, but 472.5 girls \nis the expected value in the sense that it would be the mean from many samples of \n945 births.\nStatistical Literacy and Critical Thinking \n1. Random Variable The accompanying table lists probabilities for the corresponding num-\nbers of girls in four births. What is the random variable, what are its possible values, and are its \nvalues numerical?\n5-1 Basic Skills and Concepts\nNumber of Girls in Four Births\nNumber of \nGirls x\nP(x)\n0\n0.063\n1\n0.250\n2\n0.375\n3\n0.250\n4\n0.063\n2. Discrete or Continuous? Is the random variable given in the accompanying table discrete \nor continuous? Explain.\n3. Probability Distribution For the accompanying table, is the sum of the values of P(x) \nequal to 1, as required for a probability distribution? Does the table describe a probability \ndistribution?\n4. Significant For 100 births, P(exactly 56 girls) = 0.0390 and P(56 or more girls) = 0.136. \nIs 56 girls in 100 births a significantly high number of girls? Which probability is relevant to \nanswering that question?","page_start":208,"page_end":208,"token_count":658,"section_type":"other","chapter_number":5,"chapter_title":"DISCRETE PROBABILITY DISTRIBUTIONS","chunk_index":289}
{"chunk_id":"561233539bbd0654","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"equal to 1, as required for a probability distribution? Does the table describe a probability \ndistribution?\n4. Significant For 100 births, P(exactly 56 girls) = 0.0390 and P(56 or more girls) = 0.136. \nIs 56 girls in 100 births a significantly high number of girls? Which probability is relevant to \nanswering that question?\nIdentifying Discrete and Continuous Random Variables. In Exercises 5 and 6, refer \nto the given values, then identify which of the following is most appropriate: discrete ran-\ndom variable, continuous random variable, or not a random variable.\n5. a. Exact weights of the next 100 babies born in the United States\nb. Responses to the survey question “Which health plan do you have?”\ncontinued","page_start":208,"page_end":208,"token_count":171,"section_type":"other","chapter_number":5,"chapter_title":"DISCRETE PROBABILITY DISTRIBUTIONS","chunk_index":290}
{"chunk_id":"70ab1e6c1eee4dd2","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"5-1 Probability Distributions \n191\nc. Numbers of families that must be surveyed before finding one with 10 children\nd. Exact foot lengths of humans\ne. Shoe sizes (such as 8 or 8½) of humans\n6. a. Grades (A, B, C, D, F) earned in biostatistics classes\nb. Heights of students in biostatistics classes\nc. Numbers of students in biostatistics classes\nd. Eye colors of biostatistics students\ne. Numbers of times biostatistics students must toss a coin before getting heads\nIdentifying Probability Distributions. In Exercises 7–14, determine whether a prob-\nability distribution is given. If a probability distribution is given, find its mean and standard \ndeviation. If a probability distribution is not given, identify the requirements that are not \nsatisfied.\n7. Genetic Disorder Five males with an X-linked genetic disorder \nhave one child each. The random variable x is the number of children \namong the five who inherit the X-linked genetic disorder.\nx\nP(x)\n0\n0.031\n1\n0.156\n2\n0.313\n3\n0.313\n4\n0.156\n5\n0.031\n8.  Male Color Blindness When conducting research on color \nblindness in males, a researcher forms random groups with five \nmales in each group. The random variable x is the number of males \nin the group who have a form of color blindness (based on data from \nthe National Institutes of Health).\nx\nP(x)\n0\n0.659\n1\n0.287\n2\n0.050\n3\n0.004\n4\n0.001\n5\n0+\n9.  Genetics Experiment A genetics experiment involves off-\nspring peas in groups of four. A researcher reports that for one \ngroup, the number of peas with white flowers has a probability dis-\ntribution as given in the accompanying table.\nx\nP(x)\n0\n0.04\n1\n0.26\n2\n0.36\n3\n0.20\n4\n0.08\n10. Mortality Study For a group of four men, the probability dis-\ntribution for the number x who live through the next year is as given \nin the accompanying table.\nx\nP(x)\n0\n0.0000\n1\n0.0001\n2\n0.0006\n3\n0.0387\n4\n0.9606\n","page_start":209,"page_end":209,"token_count":529,"section_type":"other","chapter_number":5,"chapter_title":"DISCRETE PROBABILITY DISTRIBUTIONS","chunk_index":291}
{"chunk_id":"a5cf79b75de0df69","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"192 \nCHAPTER 5 Discrete Probability Distributions\n11. Genetic Disorder Three males with an X-linked genetic dis-\norder have one child each. The random variable x is the number of \nchildren among the three who inherit the X-linked genetic disorder.\nx\nP(x)\n0\n0.4219\n1\n0.4219\n2\n0.1406\n3\n0.0156\n12. Diseased Seedlings An experiment involves groups of four \nseedlings grown under controlled conditions. The random variable x \nis the number of seedlings in a group that meet specific criteria for \nbeing classified as “diseased.”\nx\nP(x)\n0\n0.805\n1\n0.113\n2\n0.057\n3\n0.009\n4\n0.002\nGenetics. In Exercises 13–18, refer to the accompanying table, \nwhich describes results from groups of 8 births from 8 different \nsets of parents. The random variable x represents the number of \ngirls among 8 children.\nNumber \nof Girls x\n \nP(x)\n0\n0.004\n1\n0.031\n2\n0.109\n3\n0.219\n4\n0.273\n5\n0.219\n6\n0.109\n7\n0.031\n8\n0.004\n13. Mean and Standard Deviation Find the mean and standard \ndeviation for the numbers of girls in 8 births.\n14. Range Rule of Thumb for Significant Events Use the \nrange rule of thumb to determine whether 1 girl in 8 births is a sig-\nnificantly low number of girls.\n15. Range Rule of Thumb for Significant Events Use the \nrange rule of thumb to determine whether 6 girls in 8 births is a sig-\nnificantly high number of girls.\n16. Using Probabilities for Significant Events\na. Find the probability of getting exactly 7 girls in 8 births.\nb. Find the probability of getting 7 or more girls in 8 births.\nc. Which probability is relevant for determining whether 7 is a significantly high number of \ngirls in 10 births: the result from part (a) or part (b)?\nd. Is 7 a significantly high number of girls in 8 births? Why or why not?\n17. Using Probabilities for Significant Events \na. Find the probability of getting exactly 6 girls in 8 births.\nb. Find the probability of getting 6 or more girls in 8 births.\nc. Which probability is relevant for determining whether 6 is a significantly high number of \ngirls in 8 births: the result from part (a) or part (b)?\nd. Is 6 a significantly high number of girls in 8 births? Why or why not?\n18. Using Probabilities for Significant Events \na. Find the probability of getting exactly 1 girl in 8 births.\nb. Find the probability of getting 1 or fewer girls in 8 births.\nc. Which probability is relevant for determining whether 1 is a significantly low number of \ngirls in 8 births: the result from part (a) or part (b)?\nd. Is 1 a significantly low number of girls in 8 births? Why or why not?\n","page_start":210,"page_end":210,"token_count":686,"section_type":"other","chapter_number":5,"chapter_title":"DISCRETE PROBABILITY DISTRIBUTIONS","chunk_index":292}
{"chunk_id":"8857fc365735512f","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"5-2 Binomial Probability Distributions \n193\nSleepwalking. In Exercises 19–23, refer to the accompanying \ntable, which describes the numbers of adults in groups of five \nwho reported sleepwalking (based on data from “Prevalence and \nComorbidity of Nocturnal Wandering In the U.S. Adult General \nPopulation,” by Ohayon et al., Neurology, Vol. 78, No. 20).\n19. Mean and Standard Deviation Find the mean and standard \ndeviation for the numbers of sleepwalkers in groups of five.\nx\nP(x)\n0\n0.172\n1\n0.363\n2\n0.306\n3\n0.129\n4\n0.027\n5\n0.002\n20. Range Rule of Thumb for Significant Events Use the \nrange rule of thumb to determine whether 4 is a significantly high \nnumber of sleepwalkers in a group of 5 adults.\n21. Range Rule of Thumb for Significant Events Use the \nrange rule of thumb to determine whether 3 is a significantly high \nnumber of sleepwalkers in a group of 5 adults.\nKey Concept Section 5-1 introduced the important concept of a discrete proba-\nbility distribution. Among the various discrete probability distributions that exist, \nthe focus of this section is the binomial probability distribution. Part 1 of this sec-\ntion introduces the binomial probability distribution along with methods for find-\ning probabilities. Part 2 presents easy methods for finding the mean and standard \ndeviation of a binomial distribution. As in other sections, we stress the importance \nof interpreting probability values to determine whether events are significantly low \nor significantly high.\nPART 1\n Basics of Binomial Probability Distribution\nBinomial probability distributions allow us to deal with circumstances in which the \noutcomes belong to two categories, such as cured>not cured or acceptable>defective \nor survived>died.\n5-2 \nBinomial Probability Distributions\n22. Using Probabilities for Identifying Significant Events\na. Find the probability of getting exactly 4 sleepwalkers among 5 adults.\nb. Find the probability of getting 4 or more sleepwalkers among 5 adults.\nc. Which probability is relevant for determining whether 4 is a significantly high number of \nsleepwalkers among 5 adults: the result from part (a) or part (b)?\nd. Is 4 a significantly high number of sleepwalkers among 5 adults? Why or why not?\n23. Using Probabilities for Identifying Significant Events\na. Find the probability of getting exactly 1 sleepwalker among 5 adults.\nb. Find the probability of getting 1 or fewer sleepwalkers among 5 adults.\nc. Which probability is relevant for determining whether 1 is a significantly low number of \nsleepwalkers among 5 adults: the result from part (a) or part (b)?\nd. Is 1 a significantly low number of sleepwalkers among 5 adults? Why or why not?\n","page_start":211,"page_end":211,"token_count":633,"section_type":"other","chapter_number":5,"chapter_title":"DISCRETE PROBABILITY DISTRIBUTIONS","chunk_index":293}
{"chunk_id":"5f8b2d9a56cfd886","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"194 \nCHAPTER 5 Discrete Probability Distributions\nNotation For Binomial Probability Distributions\nS and F (success and failure) denote the two possible categories of all outcomes.\nP1S2 = p \n1p = probability of a success2\nP1F2 = 1 - p = q \n1q = probability of a failure2\nn\nthe fixed number of trials\nx \na specific number of successes in n trials, so x can be any \nwhole number between 0 and n, inclusive\np\nprobability of success in one of the n trials\nq\nprobability of failure in one of the n trials\nP(x) \nprobability of getting exactly x successes among the n trials\nThe word success as used here is arbitrary and does not necessarily represent \nsomething good. Either of the two possible categories may be called the success S \nas long as its probability is identified as p. (The value of q can always be found from \nq = 1 - p. If p = 0.95, then q = 1 - 0.95 = 0.05.)\nDEFINITION\nA binomial probability distribution results from a procedure that meets these four \nrequirements:\n 1.  The procedure has a ﬁxed number of  trials. (A trial is a single observation.)\n 2.  The trials must be independent, meaning that the outcome of any individual trial \ndoesn’t aﬀect the probabilities in the other trials.\n 3.  Each trial must have all outcomes classiﬁed into exactly two categories, com-\nmonly referred to as success and failure.\n 4.  The probability of a success remains the same in all trials.\nCAUTION When using a binomial probability distribution, always be sure that x \nand p are consistent in the sense that they both refer to the same category being \ncalled a success.\nEXAMPLE 1  Hybridization Experiments\nWhen Gregor Mendel conducted his famous hybridization experiments, he used \npeas with green pods and peas with yellow pods. Because green is dominant and \nyellow is recessive, when crossing two parents with the green>yellow pair of genes, \nwe expect that 3>4 of the offspring peas should have green pods. That is, P(green \npod) = 3>4. Assume that all parents have the green>yellow combination of genes, \nand we want to find the probability that exactly three of five offspring peas have \ngreen pods.\n \na. Does this procedure result in a binomial distribution?\n \nb. If this procedure does result in a binomial distribution, identify the values of \nn, x, p, and q.\n","page_start":212,"page_end":212,"token_count":556,"section_type":"other","chapter_number":5,"chapter_title":"DISCRETE PROBABILITY DISTRIBUTIONS","chunk_index":294}
{"chunk_id":"cfc8bc0df1a9861c","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"5-2 Binomial Probability Distributions \n195\nTreating Dependent Events as Independent\nWhen selecting a sample (as in a survey), we usually sample without replacement. \nSampling without replacement results in dependent events, which violates a require-\nment of a binomial distribution. However, we can often treat the events as if they were \nindependent by applying the following 5% guideline introduced in Section 4-2:\n5% Guideline for Cumbersome Calculations\nWhen sampling without replacement and the sample size is no more than \n5% of the size of the population, treat the selections as being independent \n(even though they are actually dependent).\nMethods for Finding Binomial Probabilities\nWe now proceed with three methods for finding the probabilities corresponding to the \nrandom variable x in a binomial distribution. The first method involves calculations \nusing the binomial probability formula and is the basis for the other two methods. \nThe second method involves the use of software or a calculator, and the third method \ninvolves the use of the Appendix Table A-1. (With technology so widespread, such \ntables are becoming obsolete.) If using technology that automatically produces bino-\nmial probabilities, we recommend that you solve one or two exercises using Method 1 \nto better understand the basis for the calculations.\nSOLUTION\na. This procedure does satisfy the requirements for a binomial distribution, as \nshown below.\n 1. The number of trials (5) is ﬁxed.\n 2. The 5 trials are independent because the probability of any oﬀspring \npea having a green pod is not aﬀected by the outcome of any other \n oﬀspring pea.\n 3. Each of the 5 trials has two categories of outcomes: The pea has a green \npod or it does not.\n 4. For each oﬀspring pea, the probability that it has a green pod is 3>4 or \n0.75, and that probability remains the same for each of the 5 peas.\nb. Having concluded that the given procedure does result in a binomial distribu-\ntion, we now proceed to identify the values of n, x, p, and q.\n 1. With 5 oﬀspring peas, we have n = 5.\n2. We want the probability of exactly 3 peas with green pods, so x = 3.\n3. The probability of success (getting a pea with a green pod) for one selec-\ntion is 0.75, so p = 0.75.\n4. The probability of failure (not getting a green pod) is 0.25, so q = 0.25.\nAgain, it is very important to be sure that x and p both refer to the same concept of \n“success.” In this example, we use x to count the number of peas with green pods, \nso p must be the probability that a pea has a green pod. Therefore, x and p do use \nthe same concept of success (green pod) here.\nNot at Home\nPollsters cannot \nsimply ignore \nthose who were \nnot at home ","page_start":213,"page_end":213,"token_count":658,"section_type":"other","chapter_number":5,"chapter_title":"DISCRETE PROBABILITY DISTRIBUTIONS","chunk_index":295}
{"chunk_id":"4f6048e99c7fed7b","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"Again, it is very important to be sure that x and p both refer to the same concept of \n“success.” In this example, we use x to count the number of peas with green pods, \nso p must be the probability that a pea has a green pod. Therefore, x and p do use \nthe same concept of success (green pod) here.\nNot at Home\nPollsters cannot \nsimply ignore \nthose who were \nnot at home \nwhen they \nwere called \nthe first time. \nOne solution \nis to make repeated callback \nattempts until the person can \nbe reached.  Alfred Politz and \nWillard Simmons describe a way \nto compensate for those missed \ncalls without making repeated \ncallbacks. They suggest weight-\ning results based on how often \npeople are not at home. For \nexample, a person at home only \ntwo days out of six will have a  \n2>6 or 1>3 probability of being at \nhome when called the first time. \nWhen such a person is reached \nthe first time, his or her results \nare weighted to count three \ntimes as much as someone who \nis always home. This weighting \nis a compensation for the other \nsimilar people who are home two \ndays out of six and were not at \nhome when called the first time. \nThis clever solution was first \npresented in 1949.","page_start":213,"page_end":213,"token_count":288,"section_type":"other","chapter_number":5,"chapter_title":"DISCRETE PROBABILITY DISTRIBUTIONS","chunk_index":296}
{"chunk_id":"9e8fa4ae2ccaff0f","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"196 \nCHAPTER 5 Discrete Probability Distributions\nFORMULA 5-5  Binomial Probability Formula\nP1x2 =\nn!\n1n - x2!x! # px # qn-x  for x = 0, 1, 2, c, n\nwhere\n n = number of trials\n x = number of successes among n trials\n p = probability of success in any one trial\n q = probability of failure in any one trial 1q = 1 - p2\nFormula 5-5 can also be expressed as P1x2 = nCx # px # qn-x. With x items identi-\ncal to themselves, and n - x other items identical to themselves, the number of \npermutations is nCx = n!3 1n - x2!x!4, so the two sides of this equation are inter-\nchangeable. The factorial symbol !, introduced in Section 4-6, denotes the product \nof decreasing factors. Two examples of factorials are 3! = 3 # 2 # 1 = 6 and 0! = 1 \n(by definition).\nEXAMPLE 2  Hybridization Experiment \nAssuming that the probability of a pea having a green pod is 0.75 (as in Example 1), \nuse the binomial probability formula to find the probability of getting exactly 3 peas \nwith green pods when 5 offspring peas are generated. That is, find P(3) given that \nn = 5, x = 3, p = 0.75, and q = 0.25.\nSOLUTION\nUsing the given values of n, x, p, and q in the binomial probability formula \n (Formula 5-5), we get\n P132 =\n5!\n15 - 32!3! # 0.753 # 0.255-3\n =\n5!\n2!3! # 0.421875 # 0.0625\n = 110210.421875210.06252 = 0.263671875\nThe probability of getting exactly 3 peas with green pods among 5 offspring peas is \n0.264 (rounded to three significant digits).\nCalculation hint: When computing a probability with the binomial probability for-\nmula, it’s helpful to get a single number for n!> 3 1n - x2!x!4 or nCx, a single num-\nber for px, and a single number for qn-x, and then simply multiply the three factors \ntogether as shown in the third line of the calculation in the preceding example. Don’t \nround when you find those three factors; round only at the end, and round to three \nsignificant digits.\nMethod 1: Using the Binomial Probability Formula In a binomial probability \ndistribution, probabilities can be calculated by using Formula 5-5.\n","page_start":214,"page_end":214,"token_count":605,"section_type":"other","chapter_number":5,"chapter_title":"DISCRETE PROBABILITY DISTRIBUTIONS","chunk_index":297}
{"chunk_id":"569a7fc95cd257c3","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"5-2 Binomial Probability Distributions \n197\nMethod 2: Using Technology Technology can be used to find binomial probabili-\nties. The screen displays listing binomial probabilities for n = 5 and p = 0.75, as in \nExample 2, are given. Notice that in each display, the probability distribution is given \nas a table.\nStatdisk\nMinitab\nExcel\nTI-83>84 Plus\nMethod 3: Using Table A-1 in Appendix A This method can be skipped if tech-\nnology is available. Table A-1 in Appendix A lists binomial probabilities for select \nvalues of n and p. It cannot be used if n > 8 or if the probability p is not one of the 13 \nvalues included in the table.\nTo use the table of binomial probabilities, we must first locate n and the desired \ncorresponding value of x. At this stage, one row of numbers should be isolated. Now \nalign that row with the desired probability of p by using the column across the top. \nThe isolated number represents the desired probability. A very small probability, such \nas 0.000064, is indicated by 0+.\nEXAMPLE 3  Births \nAssuming that boys and girls are equally likely, find the probability of getting ex-\nactly 5 boys in 8 randomly selected births.\ncontinued\n","page_start":215,"page_end":215,"token_count":289,"section_type":"other","chapter_number":5,"chapter_title":"DISCRETE PROBABILITY DISTRIBUTIONS","chunk_index":298}
{"chunk_id":"9eed2e530b810f23","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"198 \nCHAPTER 5 Discrete Probability Distributions\nPART 2\nUsing Mean and Standard Deviation for \nCritical Thinking \nSection 5-1 included formulas for finding the mean, variance, and standard deviation \nfrom any discrete probability distribution. A binomial distribution is a particular type \nof discrete probability distribution, so we could use those same formulas, but if we \nknow the values of n and p, it is much easier to use the following:\nSOLUTION\nBecause boys and girls are assumed to be equally likely, we have p = 0.5. Because \nthere are 8 births we have n = 8. Because we want the probability of exactly 5 \nboys, we have x = 5.\nRefer to Table A-1with n = 8, x = 0.5, and p = 0.5. Locate n = 8 at the left, \nthen find the row of probabilities for x = 5. Next, look across the top row to find \nthe column of values under p = 0.50. Table A-1 shows that P(5 boys) = 0.219.\nFor Binomial Distributions\nFormula 5-6 Mean: \nm = np\nFormula 5-7 Variance: \ns2 = npq\nFormula 5-8 Standard Deviation:    s = 1npq\nAs in earlier sections, finding values for m and s can be great fun, but it is especially \nimportant to interpret and understand those values, so the range rule of thumb and the \nrare event rule for inferential statistics can be very helpful. Here is a brief summary \nof the range rule of thumb: Values are significantly low or high if they differ from the \nmean by more than 2 standard deviations, as described by the following:\nRange Rule of Thumb\nSigniﬁcantly low values … 1m - 2s2\nSigniﬁcantly high values Ú 1m + 2s2\nValues not signiﬁcant: Between 1m - 2s2 and 1m + 2s2\nEXAMPLE 4  Hybridization Experiment\nUse Formulas 5-6 and 5-8 to find the mean and standard deviation for the numbers \nof peas with green pods when groups of 5 offspring peas are generated. Assume that \nthere is a 0.75 probability that an offspring pea has a green pod.\nSOLUTION\nUsing the values n = 5, p = 0.75, and q = 0.25, Formulas 5-6 and 5-8 can be \n applied as follows:\n        m = np = 15210.752 = 3.8\ns = 1npq = 215210.75210.252 = 1.0 1rounded2\n","page_start":216,"page_end":216,"token_count":598,"section_type":"other","chapter_number":6,"chapter_title":"NORMAL PROBABILITY DISTRIBUTIONS","chunk_index":299}
{"chunk_id":"d66a5129036d8dd0","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"5-2 Binomial Probability Distributions \n199\nFormula 5-6 for the mean makes sense intuitively. If 75% of peas have green pods \nand five offspring peas are generated, we expect to get around 5 # 0.75 = 3.8 peas \nwith green pods. This result can be generalized as m = np. The variance and standard \ndeviation are not so easily justified, and we omit the complicated algebraic manipula-\ntions that lead to Formulas 5-7 and 5-8. Instead, refer again to the preceding example \nand Table 5-3 on page 187 to verify that for a binomial distribution, Formulas 5-6, 5-7, \nand 5-8 will produce the same results as Formulas 5-1, 5-3, and 5-4.\nEXAMPLE 5  Genetics\nIn an actual experiment, Mendel generated 580 offspring peas. He claimed that \n75%, or 435, of them would have green pods. The actual experiment resulted in \n428 peas with green pods.\na. Assuming that groups of 580 oﬀspring peas are generated, ﬁnd the mean and \nstandard deviation for the numbers of peas with green pods.\nb. Use the range rule of thumb to ﬁnd the numbers of peas with green pods that \nseparate signiﬁcantly low values and signiﬁcantly high values from values that \nare not signiﬁcant. Based on those numbers, can we conclude that Mendel’s \nactual result of 428 peas with green pods is signiﬁcantly low or signiﬁcantly \nhigh? Does this suggest that Mendel’s value of 75% is wrong?\nSOLUTION\na. With n = 580 oﬀspring peas, with p = 0.75, and q = 0.25, we can ﬁnd \nthe mean and standard deviation for the numbers of peas with green pods as \n follows:\n         m = np = 1580210.752 = 435.0\ns = 1npq = 21580210.75210.252 = 10.4\nFor groups of 580 oﬀspring peas, the mean number of peas with green pods is \n435.0 and the standard deviation is 10.4.\nb. We must now interpret the results to determine whether Mendel’s actual result \nof 428 peas is a result that could easily occur by chance, or whether that result \nis so unlikely that the assumed rate of 75% is wrong. We will use the range \nrule of thumb as follows:\nSignificantly low values … 1m - 2s2 = 435.0 - 2110.42 = 414.2\nSignificantly high values Ú 1m + 2s2 = 435.0 + 2110.42 = 455.8\nINTERPRETATION\nBased on these results, significantly low values are 414.2 or lower, and significantly ","page_start":217,"page_end":217,"token_count":653,"section_type":"other","chapter_number":6,"chapter_title":"NORMAL PROBABILITY DISTRIBUTIONS","chunk_index":300}
{"chunk_id":"ac77bc8a2d6c058d","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"rule of thumb as follows:\nSignificantly low values … 1m - 2s2 = 435.0 - 2110.42 = 414.2\nSignificantly high values Ú 1m + 2s2 = 435.0 + 2110.42 = 455.8\nINTERPRETATION\nBased on these results, significantly low values are 414.2 or lower, and significantly \nhigh values are 455.8 or higher. That is, if Mendel generated many groups of 580 \noffspring peas and if his 75% rate is correct, the numbers of peas with green pods \nshould usually fall between 414.2 and 455.8. Mendel actually got 428 peas with \ngreen pods, and that value is neither significantly low nor significantly high, so the \nexperimental results are consistent with the 75% rate. The results do not suggest \nthat Mendel’s claimed rate of 75% is wrong.","page_start":217,"page_end":217,"token_count":205,"section_type":"other","chapter_number":6,"chapter_title":"NORMAL PROBABILITY DISTRIBUTIONS","chunk_index":301}
{"chunk_id":"e9f390a210314c78","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"200 \nCHAPTER 5 Discrete Probability Distributions\nVariation in Statistics Example 5 is a good illustration of the importance of variation \nin statistics. In a traditional algebra course, we might conclude that 428 is not 75% \nof 580 simply because 428 does not equal 435 (which is 75% of 580). However, in \nstatistics we recognize that sample results vary. We don’t expect to get exactly 75% of \nthe peas with green pods. We recognize that as long as the results don’t vary too far \naway from the claimed rate of 75%, they are consistent with that claimed rate of 75%.\nIn this section we presented easy procedures for finding values of the mean m and \nstandard deviation s from a binomial probability distribution. However, it is really \nimportant to be able to interpret those values by using such tools as the range rule of \nthumb for distinguishing values that are significantly low or significantly high from \nvalues that are not significant.\nInstead of the range rule of thumb, we could also use probabilities to determine \nwhen values are significantly high or significantly low.\nUsing Probabilities to Determine When Results Are Significantly High or Low\n■Significantly high number of successes: x successes among n trials is a \n significantly high number of successes if the probability of x or more successes \nis 0.05 or less. That is, x is a significantly high number of successes if  \nP(x or more) … 0.05.*\n■Significantly low number of successes: x successes among n trials is a \n significantly low number of successes if the probability of x or fewer successes  \nis 0.05 or less. That is, x is a significantly low number of successes if  \nP(x or fewer) … 0.05.*\n*The value 0.05 is not absolutely rigid. Other values, such as 0.01, could be used to distinguish between results \nthat are signiﬁcant and those that are not signiﬁcant.\nRationale for the Binomial Probability Formula\nThe binomial probability formula is the basis for all three methods presented in this \nsection. Instead of accepting and using that formula blindly, let’s see why it works.\nIn Example 2, we used the binomial probability formula to find the probability \nof getting exactly 3 peas with green pods when 5 offspring peas are generated. With \nP(green pod) = 0.75, we can use the multiplication rule from Section 4-2 to find the \nprobability that the first 3 peas have green pods while the last 2 peas do not have green \npods. We get the following result:\nP13 peas with green pods followed by 2 peas with pods that are not green2\n = 0.75 # 0.75 # 0.75 # 0.25 # 0.25\n = 0.753 # 0.252\n = 0.0264\nThis result gives a probability of generating five offspring in which three have green pods. \nHowever, it does not give the probability of getting exactly three peas with green pods be-\ncause it assumes a particular arrangement for three offspring peas with green pods. Other ","page_start":218,"page_end":218,"token_count":666,"section_type":"other","chapter_number":6,"chapter_title":"NORMAL PROBABILITY DISTRIBUTIONS","chunk_index":302}
{"chunk_id":"12da441a362697a5","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":" = 0.75 # 0.75 # 0.75 # 0.25 # 0.25\n = 0.753 # 0.252\n = 0.0264\nThis result gives a probability of generating five offspring in which three have green pods. \nHowever, it does not give the probability of getting exactly three peas with green pods be-\ncause it assumes a particular arrangement for three offspring peas with green pods. Other \narrangements for generating three offspring peas with green pods are possible.\nIn Section 4-6 we saw that with three subjects identical to each other (such as peas \nwith green pods) and two other subjects identical to each other (such as peas without \ngreen pods), the total number of arrangements, or permutations, is 5!> 3 15 - 32!3!4, \nor 10. Each of those 10 different arrangements has a probability of 0.753 # 0.252, so the \ntotal probability is as follows:\nP13 peas with green pods among 52 =\n5!\n15 - 32!3! # 0.753 # 0.252","page_start":218,"page_end":218,"token_count":241,"section_type":"other","chapter_number":6,"chapter_title":"NORMAL PROBABILITY DISTRIBUTIONS","chunk_index":303}
{"chunk_id":"6c6890c12bc2ca78","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"5-2 Binomial Probability Distributions \n201\nThis particular result can be generalized as the binomial probability formula \n(Formula 5-5). That is, the binomial probability formula is a combination of the \nmultiplication rule of probability and the counting rule for the number of arrange-\nments of n items when x of them are identical to each other and the other n - x are \nidentical to each other.\nP (x) =\nn!\n(n - x)!x! # px # qn-x\nThe number of outcomes with  \nexactly x successes among n trials\nThe probability of x successes among  \nn trials for any one particular order\n2   2\nBinomial Distributions\nAccess tech instructions, videos, and data sets at www.TriolaStats.com\nTECH CENTER \nStatistical Literacy and Critical Thinking \n1.  Hybridization Assume that 75% of offspring peas have green pods. Suppose we want \nto find the probability that when five offspring peas are randomly selected, exactly two \nof them are green. What is wrong with using the multiplication rule to find the prob-\nability of getting two peas with green pods followed by three peas with yellow pods: \n(0.75)(0.75)(0.25)(0.25)(0.25) = 0.00879?\n2. Variation and Notation Assume that we want to find the probability that among five off-\nspring peas, exactly two of them have green pods. Also assume that 75% of offspring peas have \ngreen pods (and the others have yellow pods).\na. Identify the values of n, x, p, and q.\nb. For groups of 5 randomly selected offspring peas, find the mean, standard deviation, and \nvariance for the numbers of peas among five that have green pods. Include appropriate units.\n3.  Independent Events Based on a KRC Research survey, when 1020 adults were asked \nabout hand hygiene, 44% said that they wash their hands after using public transportation. Con-\nsider the probability that among 30 different adults randomly selected from the 1020 who were \nsurveyed, there are at least 10 who wash their hands after using public transportation. Given \nthat these subjects were selected without replacement, are the 30 selections independent? Can \nthey be treated as being independent? Can the probability be found using the binomial prob-\nability formula?\n4.  Notation of 0+ Using the same survey from Exercise 3, the probability of randomly \n selecting 30 of the 1020 adults and getting exactly 24 who wash hands after using public trans-\nportation is represented as 0+. What does 0+ indicate? Does 0+ indicate that it is impossible to \nget exactly 24 adults who wash their hands after using public transportation?\n5-2 Basic Skills and Concepts\n","page_start":219,"page_end":219,"token_count":594,"section_type":"other","chapter_number":6,"chapter_title":"NORMAL PROBABILITY DISTRIBUTIONS","chunk_index":304}
{"chunk_id":"839256a8dc9a9ab2","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"202 \nCHAPTER 5 Discrete Probability Distributions\nIdentifying Binomial Distributions. In Exercises 5–12, determine whether the given \nprocedure results in a binomial distribution (or a distribution that can be treated as bino-\nmial). For those that are not binomial, identify at least one requirement that is not satisfied.\n5.  Clinical Trial of YSORT The YSORT method of gender selection, developed by the \n Genetics & IVF Institute, was designed to increase the likelihood that a baby will be a boy. \nWhen 291 couples used the YSORT method and gave birth to 291 babies, the weights of the \nbabies were recorded.\n6.  Clinical Trial of YSORT The YSORT method of gender selection, developed by the \n Genetics & IVF Institute, was designed to increase the likelihood that a baby will be a boy. \nWhen 291 couples use the YSORT method and give birth to 291 babies, the genders of the \nbabies are recorded.\n7. Clinical Trial of Lipitor Treating 863 subjects with Lipitor (atorvastatin) and recording \nwhether there is a “yes” response when they are each asked if they experienced a headache \n(based on data from Pfizer, Inc.).\n8. Clinical Trial of Lipitor Treating 863 subjects with Lipitor (atorvastatin) and asking each \nsubject how their head feels (based on data from Pfizer, Inc.).\n9.  Nicorette Treating 50 smokers with Nicorette and asking them how their mouth and \nthroat feel.\n10. Nicorette Treating 50 smokers with Nicorette and recording whether there is a “yes” re-\nsponse when they are asked if they experience any mouth or throat soreness.\n11. Defibrillators Determining whether each of 500 defibrillators is acceptable or defective.\n12. Defibrillators Counting the numbers of defects in each of 500 defibrillators.\nBinomial Probability Formula. In Exercises 13 and 14, answer the questions designed to \nhelp understand the rationale for the binomial probability formula.\n13. Guessing Answers Standard tests, such as the SAT, ACT, or Medical College Admis-\nsion Test (MCAT) typically use multiple choice questions, each with five possible answers \n(a, b, c, d, e), one of which is correct. Assume that you guess the answers to the first three ques-\ntions.\na. Use the multiplication rule to find the probability that the first two guesses are wrong and \nthe third is correct. That is, find P(WWC), where W denotes a wrong answer and C denotes a \ncorrect answer.\nb. Beginning with WWC, make a complete list of the different possible arrangements of two \nwrong answers and one correct answer; then find the probability for each entry in the list.\nc. Based on the preceding results, what is the probability of getting exactly one correct answer \nwhen three guesses are made?\n14. Vision Correction 53% of adults use eyeglasses for vision correction (based on data \nfrom a Vision Council survey). Four adults are randomly selected.","page_start":220,"page_end":220,"token_count":659,"section_type":"other","chapter_number":6,"chapter_title":"NORMAL PROBABILITY DISTRIBUTIONS","chunk_index":305}
{"chunk_id":"d7cea6b92f49ab9c","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"correct answer.\nb. Beginning with WWC, make a complete list of the different possible arrangements of two \nwrong answers and one correct answer; then find the probability for each entry in the list.\nc. Based on the preceding results, what is the probability of getting exactly one correct answer \nwhen three guesses are made?\n14. Vision Correction 53% of adults use eyeglasses for vision correction (based on data \nfrom a Vision Council survey). Four adults are randomly selected.\na. Use the multiplication rule to find the probability that the first three use eyeglasses and the \nfourth does not use eyeglasses. That is, find P(EEEN), where E denotes an adult who uses eye-\nglasses and N denotes an adult who does not use eyeglasses.\nb. Beginning with EEEN, make a complete list of the different possible arrangements of three \nadults who use eyeglasses and one who does not use eyeglasses; then find the probability for \neach entry in the list.\nc. Based on the preceding results, what is the probability of getting exactly three adults who \nuse eyeglasses and one who does not?","page_start":220,"page_end":220,"token_count":239,"section_type":"other","chapter_number":6,"chapter_title":"NORMAL PROBABILITY DISTRIBUTIONS","chunk_index":306}
{"chunk_id":"fba7e7208922f65d","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"5-2 Binomial Probability Distributions \n203\nMCAT Test. In Exercises 15–20, assume that random guesses are made for eight multiple \nchoice questions on an MCAT test, so that there are n = 8 trials, each with probability \nof success (correct) given by p = 0.20. Find the indicated probability for the number of \n correct answers.\n15. Find the probability that the number x of correct answers is exactly 7.\n16. Find the probability that the number x of correct answers is at least 4.\n17. Find the probability that the number x of correct answers is fewer than 3.\n18. Find the probability that the number x of correct answers is no more than 2.\n19. Find the probability of no correct answers.\n20. Find the probability that at least one answer is correct.\nIn Exercises 21–24, assume that when adults are randomly selected, 21% do not require \n vision correction (based on data from a Vision Council survey).\n21. If 8 adults are randomly selected, find the probability that exactly 2 of them do not require \nvision correction.\n22. If 20 adults are randomly selected, find the probability that exactly 5 of them do not require \nvision correction.\n23. If 10 adults are randomly selected, find the probability that at least 3 of them do not require \nvision correction.\n24. If 12 adults are randomly selected, find the probability that fewer than 3 of them do not \nrequire vision correction.\nSignificance with Range Rule of Thumb. In Exercises 25 and 26, assume that different \ngroups of couples use the XSORT method of gender selection and each couple gives birth \nto one baby. The XSORT method is designed to increase the likelihood that a baby will be a \ngirl, but assume that the method has no effect, so the probability of a girl is 0.5.\n25. Gender Selection Assume that the groups consist of 36 couples.\na. Find the mean and standard deviation for the numbers of girls in groups of 36 births.\nb. Use the range rule of thumb to find the values separating results that are significantly low or \nsignificantly high.\nc. Is the result of 26 girls a result that is significantly high? What does it suggest about the ef-\nfectiveness of the XSORT method?\n26. Gender Selection Assume that the groups consist of 16 couples.\na. Find the mean and standard deviation for the numbers of girls in groups of 16 births.\nb. Use the range rule of thumb to find the values separating results that are significantly low or \nsignificantly high.\nc. Is the result of 11 girls a result that is significantly high? What does it suggest about the ef-\nfectiveness of the XSORT method?\nSignificance with Range Rule of Thumb. In Exercises 27 and 28, assume that hybrid-\nization experiments are conducted with peas having the property that for offspring, there is \na 0.75 probability that a pea has green pods (as in one of Mendel’s famous experiments).\n27. Hybrids Assume that offspring peas are randomly selected in groups of 10.\na. Find the mean and standard deviation for the numbers of peas with green pods in the groups \nof 10.\ncontinued\n","page_start":221,"page_end":221,"token_count":691,"section_type":"other","chapter_number":6,"chapter_title":"NORMAL PROBABILITY DISTRIBUTIONS","chunk_index":307}
{"chunk_id":"965255b6aba54d0a","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"204 \nCHAPTER 5 Discrete Probability Distributions\nb. Use the range rule of thumb to find the values separating results that are significantly low or \nsignificantly high.\nc. Is the result of 9 peas with green pods a result that is significantly high? Why or why not?\n28. Hybrids Assume that offspring peas are randomly selected in groups of 16.\na. Find the mean and standard deviation for the numbers of peas with green pods in the groups \nof 16.\nb. Use the range rule of thumb to find the values separating results that are significantly low or \nsignificantly high.\nc. Is a result of 7 peas with green pods a result that is significantly low? Why or why not?\nComposite Sampling. Exercises 29 and 30 involve the method of composite sampling, \nwhereby a medical testing laboratory saves time and money by combining blood samples for \ntests so that only one test is conducted for several people. A combined sample tests positive \nif at least one person has the disease. If a combined sample tests positive, then individual \nblood tests are used to identify the individual with the disease.\n29. HIV It is estimated that worldwide, 1% of those aged 15–49 are infected with the human \nimmunodeficiency virus (HIV) (based on data from the National Institutes of Health). In tests \nfor HIV, blood samples from 36 people are combined. What is the probability that the com-\nbined sample tests positive for HIV? Is it unlikely for such a combined sample to test positive?\n30. Blood Donor Testing The American Red Cross tests every unit of donated blood for \nseveral infectious diseases, including hepatitis B, hepatitis C, HIV, syphilis, and West Nile virus \ninfection. Blood samples from 16 donors are combined and tested, and all 16 individual samples \nare approved only if the combined sample passes all tests. If there is 1.4% chance that a random \nindividual fails any of the tests, find the probability that the combined sample is not approved.\nAcceptance Sampling. Exercises 31 and 32 involve the method of acceptance sampling, \nwhereby a shipment of a large number of items is accepted based on test results from a \nsample of the items.\n31. Aspirin The MedAssist Pharmaceutical Company receives large shipments of aspirin tab-\nlets and uses this acceptance sampling plan: Randomly select and test 40 tablets, and then ac-\ncept the whole batch if there is only one or none that doesn’t meet the required specifications. \nIf one shipment of 5000 aspirin tablets actually has a 3% rate of defects, what is the probability \nthat this whole shipment will be accepted? Will almost all such shipments be accepted, or will \nmany be rejected?\n32. AAA Batteries AAA batteries are made by companies including Duracell, Energizer, \nEveready, and Panasonic, and they are used to power Prestige Medical Xenon pocket otoscopes \n(those things that physicians use to look in your ears). When purchasing bulk orders of AAA \nbatteries, a manufacturer of otoscopes uses this acceptance sampling plan: Randomly select 50 ","page_start":222,"page_end":222,"token_count":662,"section_type":"other","chapter_number":6,"chapter_title":"NORMAL PROBABILITY DISTRIBUTIONS","chunk_index":308}
{"chunk_id":"dc63c5b8dcf58312","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"many be rejected?\n32. AAA Batteries AAA batteries are made by companies including Duracell, Energizer, \nEveready, and Panasonic, and they are used to power Prestige Medical Xenon pocket otoscopes \n(those things that physicians use to look in your ears). When purchasing bulk orders of AAA \nbatteries, a manufacturer of otoscopes uses this acceptance sampling plan: Randomly select 50 \nbatteries and determine whether each is within specifications. The entire shipment is accepted \nif at most 2 batteries do not meet specifications. A shipment contains 2000 AAA batteries, and \n2% of them do not meet specifications. What is the probability that this whole shipment will be \naccepted? Will almost all such shipments be accepted, or will many be rejected?\nUltimate Binomial Exercises! Exercises 33−36 involve finding binomial probabilities, \nfinding parameters, and determining whether values are significantly high or low by using \nthe range rule of thumb and probabilities.\n33. Gender Selection At an early stage of clinical trials of the XSORT method of gender \nselection, 14 couples using that method gave birth to 13 girls and 1 boy.\na. Assuming that the XSORT method has no effect and boys and girls are equally likely, use \nthe range rule of thumb to identify the limits separating values that are significantly low and ","page_start":222,"page_end":222,"token_count":282,"section_type":"other","chapter_number":6,"chapter_title":"NORMAL PROBABILITY DISTRIBUTIONS","chunk_index":309}
{"chunk_id":"7eca627e354847c2","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"5-2 Binomial Probability Distributions \n205\nthose that are significantly high (for the number of girls in 14 births). Based on the results, is \nthe result of 13 girls significantly high?\nb. Find the probability of exactly 13 girls in 14 births, assuming that the XSORT method has \nno effect.\nc. Find the probability of 13 or more girls in 14 births, assuming that the XSORT method has \nno effect.\nd. Which probability is relevant for determining whether 13 girls is significantly high: the \nprobability from part (b) or part (c)? Based on the relevant probability, is the result of 13 girls \nsignificantly high?\ne. What do the results suggest about the effectiveness of the XSORT method?\n34. Clinical Trial A treatment for hypertension has been found to be successful in 60% of the \npatient population. In a test of a new treatment, 40 subjects are treated for hypertension and 29 \nof these subjects experience success with the new treatment.\na. Assuming that the old success rate of 60% still applies, use the range rule of thumb to iden-\ntify the limits separating numbers of successes that are significantly low or significantly high. \nBased on the results, is 29 successes among the 40 subjects significantly high?\nb. Find the probability that exactly 29 of the 40 cases are successes, assuming that the general \nsuccess rate is 60%.\nc. Find the probability that 29 or more of the cases are successes, assuming that the general \nsuccess rate is 60%.\nd. Which probability is relevant for determining whether 29 successes is significantly high: the \nprobability from part (b) or part (c)? Based on the relevant probability, is the result of 29 suc-\ncesses significantly high?\ne. What do the results suggest about the effectiveness of the new treatment?\n35. Hybrids One of Mendel’s famous experiments with peas included 47 offspring, and 34 of \nthem had long stems. Mendel claimed that under the same conditions, 75% of offspring peas \nwould have long stems. Assume that Mendel’s claim of 75% is true, and assume that a sample \nconsists of 47 offspring peas.\na. Use the range rule of thumb to identify the limits separating values that are significantly low \nand those that are significantly high. Based on the results, is the result of 34 peas with long \nstems either significantly low or significantly high?\nb. Find the probability of exactly 34 peas with long stems.\nc. Find the probability of 34 or fewer peas with long stems.\nd. Which probability is relevant for determining whether 34 peas with long stems is signifi-\ncantly low: the probability from part (b) or part (c)? Based on the relevant probability, is the \nresult of 34 peas with long stems significantly low?\ne. What do the results suggest about Mendel’s claim of 75%?\n36. Vaccine For a specific group of subjects, there is a 5% chance of influenza (“flu”). When \n80 subjects were treated with a vaccine, only one of them presented with influenza.","page_start":223,"page_end":223,"token_count":662,"section_type":"other","chapter_number":6,"chapter_title":"NORMAL PROBABILITY DISTRIBUTIONS","chunk_index":310}
{"chunk_id":"1de355d801e00ff1","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"cantly low: the probability from part (b) or part (c)? Based on the relevant probability, is the \nresult of 34 peas with long stems significantly low?\ne. What do the results suggest about Mendel’s claim of 75%?\n36. Vaccine For a specific group of subjects, there is a 5% chance of influenza (“flu”). When \n80 subjects were treated with a vaccine, only one of them presented with influenza.\na. Use the range rule of thumb to identify the limits separating values that are significantly low \nand those that are significantly high. Based on the results, is the result of one subject getting \ninfluenza either significantly low or significantly high?\nb. Find the probability of exactly one subject experiencing influenza, assuming that the vaccine \nhas no effect.\nc. Find the probability of one or fewer subjects experiencing influenza, assuming that the \n vaccine has no effect.\ncontinued","page_start":223,"page_end":223,"token_count":189,"section_type":"other","chapter_number":6,"chapter_title":"NORMAL PROBABILITY DISTRIBUTIONS","chunk_index":311}
{"chunk_id":"688c737320e87f53","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"206 \nCHAPTER 5 Discrete Probability Distributions\nd. Which probability is relevant for determining whether one subject experiencing influenza is \nsignificantly low: the probability from part (b) or part (c)? Based on the relevant probability, is \nthe result of one subject experiencing influenza significantly low?\ne. What do the results suggest about the effectiveness of the vaccine?\n37. Geometric Distribution If a procedure meets all the conditions of a binomial distribution \nexcept that the number of trials is not fixed, then the geometric distribution can be used. The \nprobability of getting the first success on the xth trial is given by P1x2 = p11 - p2 x-1, where \np is the probability of success on any one trial. Subjects are randomly selected for the National \nHealth and Nutrition Examination Survey conducted by the National Center for Health Statis-\ntics, Centers for Disease Control and Prevention. The probability that someone is a universal \ndonor (with group O and type Rh negative blood) is 0.06. Find the probability that the first \nsubject to be a universal blood donor is the fifth person selected.\n38. Multinomial Distribution The binomial distribution applies only to cases involving two \ntypes of outcomes, whereas the multinomial distribution involves more than two categories. \nSuppose we have three types of mutually exclusive outcomes denoted by A, B, and C. Let \nP1A2 = p1, P1B2 = p2, and P1C2 = p3. In n independent trials, the probability of x1 out-\ncomes of type A, x2 outcomes of type B, and x3 outcomes of type C is given by\nn!\n1x12!1x22!1x32! # px11 # px22 # px33\nData Set 8 “IQ and Lead” in Appendix B includes 78 subjects from a low lead exposure group, \n22 subjects from a medium lead exposure group, and 21 subjects from a high lead exposure \ngroup. Find the probability of randomly selecting 10 subjects for a follow-up study and getting \n5 from the low lead group, 2 from the medium lead group, and 3 from the high lead group. \nAssume that the selections are made with replacement. Can we use the above expression for \nfinding the probability if the sampling is done without replacement?\n39. Hypergeometric Distribution If we sample from a small finite population without re-\nplacement, the binomial distribution should not be used because the events are not indepen-\ndent. If sampling is done without replacement and the outcomes belong to one of two types, \nwe can use the hypergeometric distribution. If a population has A objects of one type, while \nthe remaining B objects are of the other type, and if n objects are sampled without replacement, \nthen the probability of getting x objects of type A and n - x objects of type B is\nP1x2 =\nA!\n1A - x2!x! #\nB!\n1B - n + x2!1n - x2! ,\n1A + B2!\n1A + B - n2!n!","page_start":224,"page_end":224,"token_count":650,"section_type":"other","chapter_number":6,"chapter_title":"NORMAL PROBABILITY DISTRIBUTIONS","chunk_index":312}
{"chunk_id":"a706e7ee072a1ed1","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"the remaining B objects are of the other type, and if n objects are sampled without replacement, \nthen the probability of getting x objects of type A and n - x objects of type B is\nP1x2 =\nA!\n1A - x2!x! #\nB!\n1B - n + x2!1n - x2! ,\n1A + B2!\n1A + B - n2!n!\nIn a medical research project, there are 20 subjects available and 4 of them are infected with \nHIV, while the other 16 are not infected. If 8 of the subjects are randomly selected without re-\nplacement, what is the probability that 3 of the subjects are infected with HIV, while the other 5 \nare not infected? What is the probability if the sampling is done with replacement?\n5-2 Beyond the Basics\nKey Concept In Section 5-1 we introduced general discrete probability distributions \nand in Section 5-2 we considered binomial probability distributions, which is one \nparticular category of discrete probability distributions. In this section we introduce \nPoisson probability distributions, which are another category of discrete probability \ndistributions.\n5-3 \nPoisson Probability Distributions","page_start":224,"page_end":224,"token_count":254,"section_type":"other","chapter_number":6,"chapter_title":"NORMAL PROBABILITY DISTRIBUTIONS","chunk_index":313}
{"chunk_id":"0e17e9f173718c31","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"5-3 Poisson Probability Distributions \n207\nThe following definition states that Poisson distributions are used with occur-\nrences of an event over a specified interval, and here are some applications:\n \n■Number of Internet users logging onto WebMD in one day\n \n■Number of patients arriving at an emergency room in one hour\n \n■Number of Atlantic hurricanes in one year\nDEFINITION\nA Poisson probability distribution is a discrete probability distribution that ap-\nplies to occurrences of some event over a specified interval. The random variable \nx is the number of occurrences of the event in an interval. The interval can be time, \ndistance, area, volume, or some similar unit. The probability of the event occurring \nx times over an interval is given by Formula 5-9.\nFORMULA 5-9  Poisson Probability Distribution\nP1x2 = mx # e-m\nx!\nwhere\ne ≈2.71828\nm = mean number of occurrences of the event in the intervals\nRequirements for the Poisson Probability Distribution\n1.  The random variable x is the number of occurrences of an event in some \n interval.\n2. The occurrences must be random.\n3. The occurrences must be independent of each other.\n4. The occurrences must be uniformly distributed over the interval being used.\nParameters of the Poisson Probability Distribution\n \n■The mean is m.\n \n■The standard deviation is s = 1m.\nProperties of the Poisson Probability Distribution\n1. A particular Poisson distribution is determined only by the mean μ.\n2. A Poisson distribution has possible x values of 0, 1, 2, . . . with no upper limit.\nEXAMPLE 1  Hospital Births\nIn a recent year, there were 4229 births at NYU Langone Medical Center (based on \ndata from the NYU Langone website). Assume that the number of births each day is \nabout the same, and assume that the Poisson distribution is a suitable model.\n \na. Find m, the mean number of births per day.\n \nb. Find the probability that on a randomly selected day, there are exactly 10 \nbirths. That is, ﬁnd P(10), where P(x) is the probability of x births in a day.\ncontinued\n","page_start":225,"page_end":225,"token_count":472,"section_type":"other","chapter_number":6,"chapter_title":"NORMAL PROBABILITY DISTRIBUTIONS","chunk_index":314}
{"chunk_id":"5418925251ba11ea","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"208 \nCHAPTER 5 Discrete Probability Distributions\nPoisson Distribution as Approximation to Binomial\nThe Poisson distribution is sometimes used to approximate the binomial distribution \nwhen n is large and p is small. One rule of thumb is to use such an approximation \nwhen the following two requirements are both satisfied.\nRequirements for Using Poisson as an Approximation to Binomial\n1. n Ú 100\n2. np … 10\nIf both requirements are satisfied and we want to use the Poisson distribution as an \napproximation to the binomial distribution, we need a value for m. That value can be \ncalculated by using Formula 5-6 (from Section 5-2):\nSOLUTION\na. The Poisson distribution applies because we are dealing with the occurrences \nof an event (births) over some interval (a day). The mean number of births per \nday is\nm = Number of births\nNumber of days = 4229\n365 = 11.5863\n \nb. Using Formula 5-9, the probability of x = 10 births in a day is found as \nshown here (with x = 10, m = 11.5863, and e = 2.71828):\nP1102 = mx # e-m\nx!\n= 11.586310 # 2.71828-11.5863\n10!\n= 0.112\nThe probability of exactly 10 births in a day is 0.112.\nFORMULA 5-6 Mean for Poisson as an Approximation to Binomial\nm = np\nEXAMPLE 2  Influenza\nIn one year, the rate of influenza is 5%. If 120 people are randomly selected, find \nthe probability of getting at least one who contracts influenza.\nSOLUTION\nThe time interval is a year. With n = 120 and p = 0.05, the conditions n Ú 100 \nand np … 10 are both satisfied, so we can use the Poisson distribution as an approx-\nimation to the binomial distribution. We first need the value of m, which is found as \nfollows:\nm = np = 1120210.052 = 6\nHaving found the value of m, we can proceed to find the probability for specific \nvalues of x. Because we want the probability that x is “at least 1,” we will use the \nclever strategy of first finding P(0), the probability of no subjects getting influenza. \n","page_start":226,"page_end":226,"token_count":526,"section_type":"other","chapter_number":6,"chapter_title":"NORMAL PROBABILITY DISTRIBUTIONS","chunk_index":315}
{"chunk_id":"2785cd7ba2ebf245","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"5-3 Poisson Probability Distributions \n209\nThe probability of at least one subject getting influenza can then be found by sub-\ntracting that result from 1. We find P(0) by using x = 0, m = 6, and e = 2.71828, \nas shown here:\nP102 = mx # e-m\nx !\n= 60 # 2.71828-6\n0!\n= 1 # 0.00248\n1\n= 0.00248\nUsing the Poisson distribution as an approximation to the binomial distribution, we \nfind that there is a 0.00248 probability of no subjects with influenza, so the prob-\nability of at least one subject with influenza is 1 - 0.00248 = 0.998. If we use the \nbinomial distribution, we again get a probability of 0.998, so the Poisson approxi-\nmation is quite good here.\nPoisson Distributions\nAccess tech instructions, videos, and data sets at www.TriolaStats.com\nTECH CENTER \nStatistical Literacy and Critical Thinking\n1. Notation In analyzing patient admissions at NYU Langone Medical Center, we find that \n31,645 patients were admitted in a recent year (based on data from the NYU Langone website). \nAssume that we want to find the probability of exactly 85 patient admissions in a randomly \nselected day. In applying Formula 5-9, identify the values of m, x, and e. Also, briefly describe \nwhat each of those symbols represents.\n2. Patient Admissions Use the same patient admission data given in Exercise 1. Let the ran-\ndom variable x represent the number of patient admissions in one day, and assume that it has \na Poisson distribution. What is the standard deviation for the values of the random variable x? \nWhat is the variance?\n3. Poisson Probability Distribution The random variable x represents the number of pa-\ntient admissions in a day, as described in Exercise 1. Assume that the random variable x has a \nPoisson distribution. What are the possible values of x? Is a value of x = 90.3 possible? Is x a \ndiscrete random variable or a continuous random variable?\n4. Probability if 0 For Formula 5-9, what does P(0) represent? Simplify Formula 5-9 for the \ncase in which x = 0.\nBirths. In Exercises 5–8, assume that the Poisson distribution applies, assume that the \nmean number of births at the NYU Langone Medical Center is 11.5863 per day, and \n proceed to find the probability that in a randomly selected day, the number of births is the \nvalue given.\n5. Births Find the probability that in a day, there will be exactly 12 births.\n6. Births Find the probability that in a day, there will be exactly 9 births.\n7. Births Find the probability that in a day, there will be at least 1 birth.","page_start":227,"page_end":227,"token_count":653,"section_type":"other","chapter_number":6,"chapter_title":"NORMAL PROBABILITY DISTRIBUTIONS","chunk_index":316}
{"chunk_id":"c0878ede49bfee85","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":" proceed to find the probability that in a randomly selected day, the number of births is the \nvalue given.\n5. Births Find the probability that in a day, there will be exactly 12 births.\n6. Births Find the probability that in a day, there will be exactly 9 births.\n7. Births Find the probability that in a day, there will be at least 1 birth.\n8. Births Find the probability that in a day, there will be at least 2 births.\n9. Murders In a recent year, there were 333 murders in New York City. Find the mean number \nof murders per day; then use that result to find the probability that in a day, there are no mur-\nders. Does it appear that there are expected to be many days with no murders?\n5-3 Basic Skills and Concepts","page_start":227,"page_end":227,"token_count":180,"section_type":"other","chapter_number":6,"chapter_title":"NORMAL PROBABILITY DISTRIBUTIONS","chunk_index":317}
{"chunk_id":"4c5e495bb21587b6","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"210 \nCHAPTER 5 Discrete Probability Distributions\n10. Deaths from Horse Kicks A classical example of the Poisson distribution involves the \nnumber of deaths caused by horse kicks to men in the Prussian Army between 1875 and 1894. \nData for 14 corps were combined for the 20-year period, and the 280 corps-years included a to-\ntal of 196 deaths. After finding the mean number of deaths per corps-year, find the probability \nthat a randomly selected corps-year has the following numbers of deaths: (a) 0, (b) 1, (c) 2, (d) 3, \n(e) 4. The actual results consisted of these frequencies: 0 deaths (in 144 corps-years); 1 death \n(in 91 corps-years); 2 deaths (in 32 corps-years); 3 deaths (in 11 corps-years); 4 deaths (in \n2 corps-years). Compare the actual results to those expected by using the Poisson probabilities. \nDoes the Poisson distribution serve as a good tool for predicting the actual results?\n11.  World War II Bombs In analyzing hits by V-1 buzz bombs in World War II, South \n London was partitioned into 576 regions, each with an area of 0.25 km2. A total of 535 bombs \nhit the combined area of 576 regions.\na. Find the probability that a randomly selected region had exactly 2 hits.\nb. Among the 576 regions, find the expected number of regions with exactly 2 hits.\nc. How does the result from part (b) compare to this actual result: There were 93 regions that \nhad exactly 2 hits?\n12. Disease Cluster Neuroblastoma, a rare form of cancer, occurs in 11 children in a  million, \nso its probability is 0.000011. Four cases of neuroblastoma occurred in Oak Park, Illinois, \nwhich had 12,429 children.\na. Assuming that neuroblastoma occurs as usual, find the mean number of cases in groups of \n12,429 children.\nb. Using the unrounded mean from part (a), find the probability that the number of neuroblas-\ntoma cases in a group of 12,429 children is 0 or 1.\nc. What is the probability of more than one case of neuroblastoma?\nd. Does the cluster of four cases appear to be attributable to random chance? Why or why not?\n13. Car Fatalities The recent rate of car fatalities was 33,561 fatalities for 2969 billion miles \ntraveled (based on data from the National Highway Traffic Safety Administration). Find the \nprobability that for the next billion miles traveled, there will be at least one fatality. What does \nthe result indicate about the likelihood of at least one fatality?\n14. Dandelions Dandelions are studied for their effects on crop production and lawn growth. \nIn one region, the mean number of dandelions per square meter was found to be 7.0 (based on \ndata from Manitoba Agriculture and Food).","page_start":228,"page_end":228,"token_count":654,"section_type":"other","chapter_number":6,"chapter_title":"NORMAL PROBABILITY DISTRIBUTIONS","chunk_index":318}
{"chunk_id":"e9727dc3f9a3199b","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"probability that for the next billion miles traveled, there will be at least one fatality. What does \nthe result indicate about the likelihood of at least one fatality?\n14. Dandelions Dandelions are studied for their effects on crop production and lawn growth. \nIn one region, the mean number of dandelions per square meter was found to be 7.0 (based on \ndata from Manitoba Agriculture and Food).\na. Find the probability of no dandelions in an area of 1 m2.\nb. Find the probability of at least one dandelion in an area of 1 m2.\nc. Find the probability of at most two dandelions in an area of 1 m2.\n15. Rubella During the last 13 years in the United States, there were 138 cases of rubella.\na. Find the mean number of cases of rubella per year. Round the result to four decimal places.\nb. Find the probability of no cases of rubella in a year.\nc. Find the probability of exactly 9 cases of rubella in a year. How does it compare to the \n2 years among 13 that had exactly 9 cases of rubella?\n16.  Diphtheria During the past 34 years, there were 56 cases of diphtheria in the United \nStates.\na. Find the mean number of cases of diphtheria per year. Express the result with five decimal places.\nb. Find the probability of no cases of diphtheria in a year.\nc. Find the probability that the number of diphtheria cases in a year is 5 or fewer. If a year has \nmore than 5 cases of diphtheria, is that a significantly high number?","page_start":228,"page_end":228,"token_count":369,"section_type":"other","chapter_number":6,"chapter_title":"NORMAL PROBABILITY DISTRIBUTIONS","chunk_index":319}
{"chunk_id":"b161ddb18eee1be4","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"6. Drinking Does the table describe a probability distribution? Why or why not?\n7. Drinking Find the mean of the number of heavy drinkers in groups of five randomly se-\nlected adult males.\n8. Drinking Based on the table, the standard deviation is 0.5 male. What is the variance? In-\nclude appropriate units.\n9. Drinking What does the probability of 0+ indicate? Does it indicate that among five ran-\ndomly selected adult males, it is impossible for all of them to be heavy drinkers?\n10. Drinking What is the probability that fewer than three of the five adult males are heavy \ndrinkers? If we were to find that among 5 randomly selected adult males, there are 4 heavy \ndrinkers, is 4 significantly high?\n17. Probability Histogram for a Poisson Distribution Construct the probability histogram \nfor Exercise 16. Is the Poisson probability distribution a normal distribution or is it skewed?\n5-3 Beyond the Basics\nIn Exercises 1–10, use the following: Based on data from the National Center for Health \nStatistics, 20.6% of adult males smoke. A random sample of 64 male adults is obtained.\n1. Smoking Find the mean number of smokers in groups of 64 randomly selected adult males.\n2. Smoking Find the standard deviation of the number of smokers in groups of 64 randomly \nselected adult males.\n3. Smoking Are the results from Exercises 1 and 2 statistics or parameters?\n4. Smoking For a random sample of 64 males, find the numbers separating the outcomes that \nare significantly high or significantly low.\n5. Smoking Find the probability that the first 8 randomly selected males include exactly 3 \nwho smoke.\nIn Exercises 6–10, use the following: Five male adults are randomly selected, and the table \nin the margin lists the probabilities for the number that are heavy drinkers (based on data \nfrom the National Center for Health Statistics). Males are considered to be heavy drinkers if \nthey have at least 14 drinks per week “on average.”\nChapter Quick Quiz\nx\nP(x)\n0\n0.762\n1\n0.213\n2\n0.024\n3\n0.001\n4\n   0+\n5\n 0+\nIn Exercises 1–5, assume that 28% of randomly selected adults have high cholesterol (with \na level of at least 240 mg , dL or are taking medicine to reduce cholesterol), based on results \nfrom the National Center for Health Statistics. Assume that a group of five adults is ran-\ndomly selected.\n1. Cholesterol Find the probability that exactly two of the five adults have high cholesterol.\n2. Cholesterol Find the probability that at least one of the five adults has high cholesterol. \nDoes the result apply to five adults from the same family? Why or why not?\n3. Cholesterol Find the mean and standard deviation for the numbers of adults in groups of \nfive who have high cholesterol.\n4. Cholesterol If all five of the adults have high cholesterol, is five significantly high? Why \nor why not?\nReview Exercises\nCHAPTER 5 Review Exercises \n211\n","page_start":229,"page_end":229,"token_count":672,"section_type":"other","chapter_number":6,"chapter_title":"NORMAL PROBABILITY DISTRIBUTIONS","chunk_index":320}
{"chunk_id":"cadd092f62b24ff7","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"212 \nCHAPTER 5 Discrete Probability Distributions\n5. Cholesterol If the group of five adults includes exactly 1 with high cholesterol, is that \nvalue of 1 significantly low?\n6. Security Survey In a USA Today poll, subjects were asked if passwords should be re-\nplaced with biometric security, such as fingerprints. The results from that poll have been used \nto create the accompanying table. Does this table describe a probability distribution? Why or \nwhy not?\nResponse\nP(x)\nYes\n0.53\nNo\n0.17\nNot sure\n0.30\n7. Condom Failure Rate According to the Department of Health and Human Services, the \nfailure rate for male condoms is 18%. The accompanying table is based on the failure rate of \n18%, where x represents the number of condoms that fail when six are tested.\na. Does the table describe a probability distribution? Why or why not?\nb. Assuming that the table does describe a probability distribution, find its mean.\nc. Assuming that the table does describe a probability distribution, find its standard deviation.\nd. If 6 condoms are tested and 5 of them fail, is 5 a significantly high number of failures? Why \nor why not?\ne. What does the symbol 0+ represent?\nx\nP(x)\n0\n0.304\n1\n0.400\n2\n0.220\n3\n0.064\n4\n0.011\n5\n0.001\n6\n0+\n8.  Poisson: Deaths Currently, an average of 143 residents of Madison, CT (population \n17,858), die each year (based on data from the U.S. National Center for Health Statistics).\na. Find the mean number of deaths per day.\nb. Find the probability that on a given day, there are no deaths.\nc. Find the probability that on a given day, there are more than two deaths.\nd. Based on the preceding results, should Madison have a contingency plan to handle more \nthan two deaths per day? Why or why not?\nCumulative Review Exercises\n1. Manatee Deaths Listed below are the annual numbers of manatee deaths from boats in \nFlorida for each of the past 10 years, listed in chronological order.\n69 79 92 73 90 97 83 88 81 72\na. Find the mean.\nb. Find the median.\nc. Find the range.\nd. Find the standard deviation.\ne. Find the variance.\nf. Describe an important characteristic of the data that is not addressed by the statistics found in \nparts (a) through (e).\ng. Use the range rule of thumb to identify the values separating significant values from those \nthat are not significant.\nh. Based on the result from part (f), do any of the years have a number of manatee deaths that is \nsignificantly low or significantly high?\ni. What is the level of measurement of the data: nominal, ordinal, interval, or ratio?\nj. Are the data discrete or continuous?\n","page_start":230,"page_end":230,"token_count":635,"section_type":"other","chapter_number":6,"chapter_title":"NORMAL PROBABILITY DISTRIBUTIONS","chunk_index":321}
{"chunk_id":"565a38bdebbb103b","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"2. Analysis of Last Digits The accompanying table lists the last or rightmost digits of weights \nof the females listed in Data Set 1 “Body Data” in Appendix B. The last digits of a data set can \nsometimes be used to determine whether the data have been measured or simply reported. The \npresence of disproportionately more 0s and 5s is often a sure sign that the data have been re-\nported instead of measured.\na. Using the table, find the mean and standard deviation of those last digits. Are the results \nstatistics or parameters?\nb. Examine the given table to determine if there is anything about the sample data (such as \ndisproportionately more 0s and 5s) suggesting that the given last digits are not random? Or do \nthey appear to be random?\nc. Does the table describe a probability distribution? Why or why not?\nx\nf\n0\n11\n1\n11\n2\n16\n3\n14\n4\n16\n5\n24\n6\n13\n7\n14\n8\n19\n9\n  9\n3. Government Health Plan Fox News broadcast a graph similar to the one shown here. The \ngraph is intended to compare the number of people actually enrolled in a government health \nplan (left bar) and the goal for the number of enrollees (right bar). Does the graph depict the \ndata correctly or is it somehow misleading? Explain.\n4. Diabetes Among adults in the United States, 11.5% have diabetes (based on data from the \nNational Center for Health Statistics).\na. Find the probability that a randomly selected adult does not have diabetes.\nb. Find the probability that two randomly selected adults both have diabetes.\nc. Find the probability that among three randomly selected adults, at least one has diabetes.\nd. For groups of 40 randomly selected adults, find the mean and standard deviation for the \nnumbers of adults having diabetes. Are these results statistics or parameters?\ne. If 40 adults are randomly selected and 10 of them have diabetes, is 10 a result that is signifi-\ncantly low or significantly high? Why?\n\t\nCHAPTER 5  Cumulative Review Exercises\t\n213\n","page_start":231,"page_end":231,"token_count":464,"section_type":"other","chapter_number":6,"chapter_title":"NORMAL PROBABILITY DISTRIBUTIONS","chunk_index":322}
{"chunk_id":"12b068bdc4703edc","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"214 \nCHAPTER 5 Discrete Probability Distributions\nFROM DATA TO DECISION\nCritical Thinking: Determining criteria for concluding \nthat a gender selection method is effective\nYou are responsible for analyzing results from a clinical trial \nof the effectiveness of a new method of gender selection. \nAssume that the sample size of n = 75 couples has already \nbeen established, and each couple will have one child. Fur-\nther assume that each of the couples will be subjected to a \ntreatment that supposedly increases the likelihood that the \nchild will be a girl. Assume that with no treatment, the prob-\nability of a baby being a girl is 0.488, which is currently the \ncorrect value in the United States.\nThere is a danger in obtaining results first, then making \nconclusions about the results. If the results are close to show-\ning the effectiveness of a treatment, it might be tempting to \n conclude that there is an effect when, in reality, there is no ef-\nfect. It is better to establish criteria before obtaining results.\na. Using the methods of this chapter, identify the criteria that \nshould be used for concluding that the treatment is effective in in-\ncreasing the likelihood of a girl. Among the 75 births, how many \ngirls would you require in order to conclude that the gender selec-\ntion procedure is effective? Explain how you arrived at this result.\nb. If 60% of the 75 babies are girls, is that result high enough \nto conclude that the gender selection method is effective? \nWhy or why not?\nc. If 64% of the 75 babies are girls, is that result high enough \nto conclude that the gender selection method is effective? \nWhy or why not?\nCooperative Group Activities\n1. In-class activity Win $1,000,000! The James Randi Educational Foundation offers a \n$1,000,000 prize to anyone who can show “under proper observing conditions, evidence of \nany paranormal, supernatural, or occult power or event.” Divide into groups of three. Select \none person who will be tested for extrasensory perception (ESP) by trying to correctly identify \na digit (0–9) randomly selected by another member of the group. Conduct at least 20 trials. \nAnother group member should record the randomly selected digit, the digit guessed by the \nsubject, and whether the guess was correct or wrong. Construct the table for the probability \ndistribution of randomly generated digits, construct the relative frequency table for the ran-\ndom digits that were actually obtained, and construct a relative frequency table for the guesses \nthat were made. After comparing the three tables, what do you conclude? What proportion of \nguesses is correct? Does it seem that the subject has the ability to select the correct digit signifi-\ncantly more often than would be expected by chance?\nMendel’s Hybrid Experiments One of Mendel’s famous experiments with peas included \n1064 offspring, and 787 of them had long stems. Mendel claimed that under the same condi-\ntions, 75% of offspring peas would have long stems. Assume that Mendel’s claim of 75% is ","page_start":232,"page_end":232,"token_count":652,"section_type":"other","chapter_number":6,"chapter_title":"NORMAL PROBABILITY DISTRIBUTIONS","chunk_index":323}
{"chunk_id":"15f9616786d0e2e8","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"guesses is correct? Does it seem that the subject has the ability to select the correct digit signifi-\ncantly more often than would be expected by chance?\nMendel’s Hybrid Experiments One of Mendel’s famous experiments with peas included \n1064 offspring, and 787 of them had long stems. Mendel claimed that under the same condi-\ntions, 75% of offspring peas would have long stems. Assume that Mendel’s claim of 75% is \ntrue, and assume that a sample consists of 1064 offspring peas.\n• Use the range rule of thumb to identify the limits separating values that are significantly low \nand those that are significantly high. Based on the results, is the result of 787 peas with long \nstems either significantly low or significantly high?\n• Find the probability of exactly 787 peas with long stems.\n• Find the probability of 787 or fewer peas with long stems.\n• Which probability is relevant for determining whether 787 peas with long stems is signifi-\ncantly low: the probability from part (b) or part (c)? Based on the relevant probability, is the \nresult of 787 peas with long stems significantly low?\n• What do the results suggest about Mendel’s claim of 75%?\nTechnology Project","page_start":232,"page_end":232,"token_count":262,"section_type":"other","chapter_number":6,"chapter_title":"NORMAL PROBABILITY DISTRIBUTIONS","chunk_index":324}
{"chunk_id":"2c6d0d262f54fe61","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"2. In-class activity See the preceding activity and design an experiment that would be ef-\nfective in testing someone’s claim that he or she has the ability to identify the color of a card \nselected from a standard deck of playing cards. Describe the experiment with great detail. Be-\ncause the prize of $1,000,000 is at stake, we want to be careful to avoid the serious mistake of \nconcluding that the person has a paranormal power when that power is not actually present. \nThere will likely be some chance that the subject could make random guesses and be correct \nevery time, so identify a probability that is reasonable for the event of the subject passing the \ntest with random guesses. Be sure that the test is designed so that this probability is equal to or \nless than the probability value selected.\n3. In-class activity Suppose we want to identify the probability distribution for the number \nof children in families with at least one child. For each student in the class, find the number \nof brothers and sisters and record the total number of children (including the student) in each \nfamily. Construct the relative frequency table for the result obtained. (The values of the random \nvariable x will be 1, 2, 3, . . . .) What is wrong with using this relative frequency table as an es-\ntimate of the probability distribution for the number of children in randomly selected families?\n4. Out-of-class activity The analysis of the last digits of data can sometimes reveal whether \nthe data have been collected through actual measurements or reported by the subjects. Refer \nto an almanac or the Internet and find a collection of data (such as lengths of rivers in the \nworld), then analyze the distribution of last digits to determine whether the values were ob-\ntained through actual measurements.\n5. Out-of-class activity The photos shown below depict famous statisticians with first names \nof David and John, not necessarily in the order shown. Conduct a survey by asking this ques-\ntion: “Which man is named David and which man is named John?” Do the respondents ap-\npear to give results significantly different from what is expected with random guesses? (See \n“Who Do You Look Like? Evidence of Facial Stereotypes for Male Names” by Lea, Thomas, \nLamkin, and Bell, Psychonomic Bulletin & Review, Vol. 14, Issue 5.)\nCHAPTER 5 Cooperative Group Activities \n215\n","page_start":233,"page_end":233,"token_count":504,"section_type":"other","chapter_number":6,"chapter_title":"NORMAL PROBABILITY DISTRIBUTIONS","chunk_index":325}
{"chunk_id":"b069f46d2470f7f5","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"216\nThe Standard Normal \nDistribution\nReal Applications of \nNormal Distributions\nSampling Distributions \nand Estimators\nThe Central Limit \nTheorem\nAssessing Normality\nNormal as \nApproximation to \nBinomial\n6-1\n6-2\n6-3\n6-4\n6-5\n6-6\nWhat Is a Normal Pulse Rate?\nCHAPTER \nPROBLEM\nNormal Probability \nDistributions\nExploring the pulse rates of adult males and females in Data \nSet 1 “Body Data” from Appendix B reveals the  following:\n• Adult males have pulse rates with a mean of 69.6 bpm \n(beats per minute), a standard deviation of 11.3 bpm, and a \ndistribution that is approximately normal.\n• Adult females have pulse rates with a mean of 74.0 bpm, \na standard deviation of 12.5 bpm, and a distribution that is \napproximately normal.\n• There appears to be a significant difference between pulse \nrates of males and females.\nFor the purposes of this chapter, we will use the above results as \nreasonable estimates of population parameters. See the following:\nm \ns \nDistribution\nMale Adult Pulse Rates (bpm) \n69.6 \n11.3 \nNormal\nFemale Adult Pulse Rates (bpm) \n74.0 \n12.5 \nNormal\n6 \n","page_start":234,"page_end":234,"token_count":281,"section_type":"other","chapter_number":6,"chapter_title":"NORMAL PROBABILITY DISTRIBUTIONS","chunk_index":326}
{"chunk_id":"88ee31f92117ca01","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"Physicians routinely measure pulse rates of patients, and the \nnormal range is generally considered to be between 60 bpm and \n100 bpm. Here are conditions for pulse rates outside that range:\nTachycardia: Pulse rate greater than 100 bpm.\nBradycardia: Pulse rate less than 60 bpm\nAn excessively high pulse rate (tachycardia) is generally more \nof a problem than an excessively low pulse rate (bradycar-\ndia). An excessively high pulse rate can indicate a high risk of \nstroke, heart disease, or can even cause death. An excessively \nlow pulse can occur with an athlete in peak physical condition, \nand some drugs such as beta blockers can also cause an  \nexcessively low pulse rate.\nHere are some questions that can be addressed with the \nmethods of this chapter:\n• What is the proportion of adult males who are expected to \nhave pulse rates greater than 100 bpm?\n• What is the proportion of adult males who are expected to \nhave pulse rates less than 60 bpm.\n• For males, if we introduce a criterion whereby the highest \n1% of pulse rates are considered to be significantly high, \nwhat is the cutoff?\n• For males, if we introduce a criterion whereby the lowest 1% \nof pulse rates are considered to be significantly low, what is \nthe cutoff?\nThese same questions can be posed for adult females, and we will \naddress such questions using the methods in this chapter.\nChapter 5 introduced discrete probability distributions, but in this chapter we introduce \ncontinuous probability distributions, and most of this chapter focuses on normal distri-\nbutions. Here are the chapter objectives:\nThe Standard Normal Distribution\n• Describe the characteristics of a standard normal distribution.\n• Find the probability of some range of z values in a standard normal distribution.\n• Find z scores corresponding to regions under the curve representing a standard \nnormal distribution.\nReal Applications of Normal Distributions\n• Develop the ability to describe a normal distribution (not necessarily a standard \n normal distribution).\n• Find the probability of some range of values in a normal distribution.\n• Find x scores corresponding to regions under the curve representing a normal \n distribution.\nSampling Distributions and Estimators\n• Develop the ability to describe a sampling distribution of  a statistic.\n• Determine whether a statistic serves as a good estimator of the corresponding \npopulation parameter.\nThe Central Limit Theorem\n• Describe what the central limit theorem states.\n• Apply the central limit theorem by finding the probability that a sample mean falls \nwithin some specified range of values.\n• Identify conditions for which it is appropriate to use a normal distribution for the \n distribution of sample means.\n6-1\n6-2\n6-3\n6-4\nChapter Objectives \n217\nCHAPTER OBJECTIVES\n>>>\ncontinued\n","page_start":235,"page_end":235,"token_count":572,"section_type":"other","chapter_number":6,"chapter_title":"NORMAL PROBABILITY DISTRIBUTIONS","chunk_index":327}
{"chunk_id":"3c1081fa4453987a","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"218 \nCHAPTER 6 Normal Probability Distributions\nKey Concept In this section we present the standard normal distribution, which is a \nspecific normal distribution having the following three properties:\n1. Bell-shaped: The graph of the standard normal distribution is bell-shaped (as in \nFigure 6-1).\n2. m = 0: The standard normal distribution has a mean equal to 0.\n3. s = 1: The standard normal distribution has a standard deviation equal to 1.\nIn this section we develop the skill to find areas (or probabilities or relative frequen-\ncies) corresponding to various regions under the graph of the standard normal distri-\nbution. In addition, we find z scores that correspond to areas under the graph. These \nskills become important in the next section as we study nonstandard normal distribu-\ntions and the real and important applications that they involve.\nNormal Distributions\nThere are infinitely many different normal distributions, depending on the values used \nfor the mean and standard deviation. We begin with a brief introduction to this general \nfamily of normal distributions.\n6-1 \nThe Standard Normal Distribution\nAssessing Normality\n• Develop the ability to examine histograms, outliers, and normal quantile plots to \ndetermine whether sample data appear to be from a population having a distribution \nthat is approximately normal.\nNormal as Approximation to Binomial\n• Identify conditions for which it is appropriate to use a normal distribution as an ap-\nproximation to a binomial probability distribution.\n• Use the normal distribution for approximating probabilities for a binomial distribution.\n6-5\n6-6\nAssessing Normality\n• Develop the ability to examine histograms, outliers, and normal quantile plots to \ndetermine whether sample data appear to be from a population having a distribution\nthat is approximately normal.\nNormal as Approximation to Binomial\n• Identify conditions for which it is appropriate to use a normal distribution as an ap-\nfo\nf\nproximation to a binomial probability distribution.\n• Use the normal distribution for approximating probabilities for a binomial distribution.\nDEFINITION\nIf a continuous random variable has a distribution with a graph that is symmetric \nand bell-shaped, as in Figure 6-1, and it can be described by the equation given as \nFormula 6-1, we say that it has a normal distribution.\nFORMULA 6-1\ny = e- 1\n21\nx - m\ns 22\ns22p\nIn this book, we won’t actually use Formula 6-1, but examining the right side of the \nequation reveals that any particular normal distribution is determined by two parame-\nters: the population mean, m, and population standard deviation, s. (In Formula 6-1, x is \na variable that can change, p = 3.14159, and e = 2.71828.) Once specific values are \nselected for m and s, Formula 6-1 is an equation relating x and y, and we can graph \nm\nValue\nCurve is bell-shaped\nand symmetric\nFIGURE 6-1  The Normal \nDistribution\n","page_start":236,"page_end":236,"token_count":651,"section_type":"other","chapter_number":6,"chapter_title":"NORMAL PROBABILITY DISTRIBUTIONS","chunk_index":328}
{"chunk_id":"380cdc7ab0e5d567","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"6-1 The Standard Normal Distribution \n219\nthat equation to get a result that will look like Figure 6-1. And that’s about all we need \nto know about Formula 6-1!\nUniform Distributions\nThe major focus of this chapter is the concept of a normal probability distribution, but \nwe begin with a uniform distribution so that we can see the following two very impor-\ntant properties:\n1. The area under the graph of a continuous probability distribution is equal to 1.\n2. There is a correspondence between area and probability, so probabilities \ncan be found by identifying the corresponding areas in the graph using this \nformula for the area of a rectangle:\nArea = height * width\nEXAMPLE 1  Waiting Times for Emergency Room Check-In\nDuring certain time periods at a hospital in New York City, patients arriving at the \nemergency room have waiting times that are uniformly distributed between 0 minutes \nand 5 minutes, as illustrated in Figure 6-2.\nRefer to Figure 6-2 to see these properties:\n \n■All of the different possible waiting times are equally likely.\n \n■Waiting times can be any value between 0 min and 5 min, so it is possible to \nhave a waiting time of 1.234567 min.\n \n■By assigning the probability of 0.2 to the height of the vertical line in Figure 6-2, \nthe enclosed area is exactly 1. (In general, we should make the height of the ver-\ntical line in a uniform distribution equal to 1>range.)\n0\n0.2\n1\n2\nArea 5 1\n3\n4\n5\nx (waiting time in minutes)\nP(x)\nFIGURE 6-2 Uniform Distribution of Waiting Time\nDEFINITION\nA continuous random variable has a uniform distribution if its values are spread \nevenly over the range of possibilities. The graph of a uniform distribution results in \na rectangular shape.\nDensity Curve The graph of any continuous probability distribution is called a \ndensity curve, and any density curve must satisfy the requirement that the total area \nunder the curve is exactly 1. This requirement that the area must equal 1 simplifies \nprobability problems, so the following statement is really important:\nBecause the total area under any density curve is equal to 1, there is a \n correspondence between area and probability.\n","page_start":237,"page_end":237,"token_count":489,"section_type":"other","chapter_number":6,"chapter_title":"NORMAL PROBABILITY DISTRIBUTIONS","chunk_index":329}
{"chunk_id":"56b184ac7773f031","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"220 \nCHAPTER 6 Normal Probability Distributions\nStandard Normal Distribution\nThe density curve of a uniform distribution is a horizontal straight line, so we can find \nthe area of any rectangular region by applying this formula:\nArea = height * width\nBecause the density curve of a normal distribution has a more complicated bell shape \nas shown in Figure 6-1, it is more difficult to find areas. However, the basic principle \nis the same: There is a correspondence between area and probability. In Figure 6-4 \nwe show that for a standard normal distribution, the area under the density curve is \nequal to 1. In Figure 6-4, we use “z Score” as a label for the horizontal axis, and this is \ncommon for the standard normal distribution, defined as follows.\nEXAMPLE 2  Waiting Times at an Emergency Room\nGiven the uniform distribution illustrated in Figure 6-2, find the probability that a \nrandomly selected patient has a waiting time of at least 2 minutes.\nSOLUTION\nThe shaded area in Figure 6-3 represents waiting times of at least 2 minutes. Because the \ntotal area under the density curve is equal to 1, there is a correspondence between area \nand probability. We can easily find the desired probability by using areas as follows:\n P1wait time of at least 2 min2 = height *  width of shaded area in Figure 6@3\n = 0.2 * 3\n = 0.6\n0\n0.2\n1\n2\nArea 5 0.2 3 3\n \n5 0.6\n3\n4\n5\nx (waiting time in minutes)\nP(x)\nFIGURE 6-3 Using Area to Find Probability\nINTERPRETATION\nThe probability of randomly selecting a patient with a waiting time of at least  \n2 minutes is 0.6.\n1\n2\n3\n0\nz Score\nArea 5 1\n21\n22\n23\nFIGURE 6-4\nStandard Normal Distribution\n","page_start":238,"page_end":238,"token_count":428,"section_type":"other","chapter_number":6,"chapter_title":"NORMAL PROBABILITY DISTRIBUTIONS","chunk_index":330}
{"chunk_id":"f5a8aed2bf5b215b","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"6-1 The Standard Normal Distribution \n221\nFinding Probabilities When Given z Scores\nIt is not easy to manually find areas in Figure 6-4, but we can find areas (or prob-\nabilities) for many different regions in Figure 6-4 by using technology, or we can also \nuse Table A-2 (in Appendix A and the Formulas and Tables insert card). Key features \nof the different methods are summarized in Table 6-1, which follows. (StatCrunch \nprovides options for a cumulative left region, a cumulative right region, or the region \nbetween two boundaries.) Because calculators and software generally give more ac-\ncurate results than Table A-2, we strongly recommend using technology. (When there \nare discrepancies, answers in Appendix D will generally include results based on tech-\nnology as well as answers based on Table A-2.)\nTABLE 6-1 Formats Used for Finding Normal Distribution Areas\nCumulative Area from the Left\nThe following provide the cumulative area \nfrom the left up to a vertical line above a \nspecific value of z:\n• Table A-2 \n• Statdisk \n• Minitab \n• Excel \n• StatCrunch \nz\nCumulative Left Region\nArea Between Two Boundaries\nThe following provide the area bounded on \nthe left and bounded on the right by vertical \nlines above specific values.\n• TI-83, 84 Plus calculator \n• StatCrunch \nUpper\nLower\nArea Between Two Boundaries\nDEFINITION\nThe standard normal distribution is a normal distribution with the parameters of \nm = 0 and s = 1. The total area under its density curve is equal to 1 (as in Figure 6-4).\nTable A-2: If using Table A-2, it is essential to understand these points:\n1. Table A-2 is designed only for the standard normal distribution, which is a nor-\nmal distribution with a mean of 0 and a standard deviation of 1.\n2. Table A-2 is on two pages, with the left page for negative z scores and the right \npage for positive z scores.\n3. Each value in the body of the table is a cumulative area from the left up to a \nvertical boundary above a specific z score.\ncontinued\n","page_start":239,"page_end":239,"token_count":475,"section_type":"other","chapter_number":6,"chapter_title":"NORMAL PROBABILITY DISTRIBUTIONS","chunk_index":331}
{"chunk_id":"0b1bd6274a395da1","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"222 \nCHAPTER 6 Normal Probability Distributions\nThe following examples illustrate procedures that can be used with real and im-\nportant applications introduced in the following sections.\nCAUTION When working with a normal distribution, be careful to avoid confusion \nbetween z scores and areas.\nz 5 1.27\n0\nArea 5 0.8980\n(from Table A-2)\nFIGURE 6-5\nFinding Area to the Left of z = 1.27\nEXAMPLE 3  Bone Density Test\nA bone mineral density test can be helpful in identifying the presence or likelihood \nof osteoporosis, a disease causing bones to become more fragile and more likely \nto break. The result of a bone density test is commonly measured as a z score. The \npopulation of z scores is normally distributed with a mean of 0 and a standard de-\nviation of 1, so these test results meet the requirements of a standard normal distri-\nbution, and the graph of the bone density test scores is as shown in Figure 6-5.\nA randomly selected adult undergoes a bone density test. Find the probability \nthat this person has a bone density test score less than 1.27.\nSOLUTION\nNote that the following are the same (because of the aforementioned correspon-\ndence between probability and area):\n \n■Probability that the bone density test score is less than 1.27\n \n■Shaded area shown in Figure 6-5\nSo we need to find the area in Figure 6-5 below z = 1.27. If using Table A-2, \n begin with the z score of 1.27 by locating 1.2 in the left column; next find the \nvalue in the adjoining row of probabilities that is directly below 0.07, as shown in \nthe excerpt on the top of the following page. Table A-2 shows that there is an area \nof 0.8980 corresponding to z = 1.27. We want the area below 1.27, and Table A-2 \ngives the cumulative area from the left, so the desired area is 0.8980. Because of \nthe correspondence between area and probability, we know that the probability of a \nz score below 1.27 is 0.8980.\n4. When working with a graph, avoid confusion between z scores and areas.\nz score: \n Distance along the horizontal scale of the standard normal dis-\ntribution (corresponding to the number of standard deviations \nabove or below the mean); refer to the leftmost column and top \nrow of Table A-2.\nArea: \n Region under the curve; refer to the values in the body of Table A-2.\n5. The part of the z score denoting hundredths is found across the top row of \nTable A-2.\n","page_start":240,"page_end":240,"token_count":593,"section_type":"other","chapter_number":6,"chapter_title":"NORMAL PROBABILITY DISTRIBUTIONS","chunk_index":332}
{"chunk_id":"c295f030af622a3f","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"6-1 The Standard Normal Distribution \n223\nTABLE A-2 (continued) Cumulative Area from the LEFT\nz\n.00\n.01\n.02\n.03\n.04\n.05\n.06\n.07\n.08\n.09\n0.0\n.5000\n.5040\n.5080\n.5120\n.5160\n.5199\n.5239\n.5279\n.5319\n.5359\n0.1\n.5398\n.5438\n.5478\n.5517\n.5557\n.5596\n.5636\n.5675\n.5714\n.5753\n0.2\n.5793\n.5832\n.5871\n.5910\n.5948\n.5987\n.6026\n.6064\n.6103\n.6141\n1.0\n.8413\n.8438\n.8461\n.8485\n.8508\n.8531\n.8554\n.8577\n.8599\n.8621\n1.1\n.8643\n.8665\n.8686\n.8708\n.8729\n.8749\n.8770\n.8790\n.8810\n.8830\n1.2\n.8849\n.8869\n.8888\n.8907\n.8925\n.8944\n.8962\n.8980\n.8997\n.9015\n1.3\n.9032\n.9049\n.9066\n.9082\n.9099\n.9115\n.9131\n.9147\n.9162\n.9177\n1.4\n.9192\n.9207\n.9222\n.9236\n.9251\n.9265\n.9279\n.9292\n.9306\n.9319\nINTERPRETATION\nThe probability that a randomly selected person has a bone density test result below \n1.27 is 0.8980, shown as the shaded region in Figure 6-5. Another way to interpret \nthis result is to conclude that 89.80% of people have bone density levels below 1.27.\nEXAMPLE 4   Bone Density Test: Finding the Area to the Right  \nof a Value\nUsing the same bone density test from Example 3, find the probability that a ran-\ndomly selected person has a result above -1.00. A value above -1.00 is considered \nto be in the “normal” range of bone density readings.\nSOLUTION\nWe again find the desired probability by finding a corresponding area. We are look-\ning for the area of the region to the right of z = -1.00 that is shaded in Figure 6-6. \nThe Statdisk display on the top of the following page shows that the area to the \nright of z = -1.00 is 0.841345.\nIf we use Table A-2, we should know that it is designed to apply only to cumu-\nlative areas from the left. Referring to the page with negative z scores, we find that ","page_start":241,"page_end":241,"token_count":674,"section_type":"other","chapter_number":6,"chapter_title":"NORMAL PROBABILITY DISTRIBUTIONS","chunk_index":333}
{"chunk_id":"1ed4a8c3a2a33a81","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"The Statdisk display on the top of the following page shows that the area to the \nright of z = -1.00 is 0.841345.\nIf we use Table A-2, we should know that it is designed to apply only to cumu-\nlative areas from the left. Referring to the page with negative z scores, we find that \nthe cumulative area from the left up to z = -1.00 is 0.1587, as shown in Figure \n6-6. Because the total area under the curve is 1, we can find the shaded area by \nsubtracting 0.1587 from 1. The result is 0.8413. Even though Table A-2 is designed \nonly for cumulative areas from the left, we can use it to find cumulative areas from \nthe right, as shown in Figure 6-6.\n0.1587\nz 5 –1.00\n1. Use z 5 21.00\nin Table A-2 to\nﬁnd this area.\n2. Because\nthe total area\nis 1, this area is\n1 2 0.1587 5 0.8413\nFIGURE 6-6  Finding the Area to the \nRight of z = −1\ncontinued","page_start":241,"page_end":241,"token_count":274,"section_type":"other","chapter_number":6,"chapter_title":"NORMAL PROBABILITY DISTRIBUTIONS","chunk_index":334}
{"chunk_id":"cec229c45f6499c1","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"224 \nCHAPTER 6 Normal Probability Distributions\nExample 4 illustrates a way that Table A-2 can be used indirectly to find a cumu-\nlative area from the right. The following example illustrates another way that we can \nfind an area indirectly by using Table A-2.\nINTERPRETATION\nBecause of the correspondence between probability and area, we conclude that \nthe probability of randomly selecting someone with a bone density reading above \n-1 is 0.8413 (which is the area to the right of z = -1.00). We could also say that \n84.13% of people have bone density levels above -1.00.\nz 5 21.00\n0.1587\nThis area\n0.1587\n \nz 5 22.50\n0.0062\nminus this area\n2 0.0062\n \n22.50 21.00\n0.1525\nequals this area\n5 0.1525\nFIGURE 6-7 Finding the Area Between Two z Scores\nEXAMPLE 5   Bone Density Test: Finding the Area Between  \nTwo Values\nA bone density test reading between -1.00 and -2.50 indicates that the subject has \nosteopenia, which is some bone loss. Find the probability that a randomly selected \nsubject has a reading between -1.00 and -2.50.\nSOLUTION\nWe are again dealing with normally distributed values having a mean of 0 and a \nstandard deviation of 1. The values between -1.00 and -2.50 correspond to the \nshaded region in the third graph included in Figure 6-7. Table A-2 cannot be used to \nfind that area directly, but we can use this table to find the following:\n \n1. The area to the left of z = -1.00 is 0.1587.\n \n2. The area to the left of z = -2.50 is 0.0062.\n \n3. The area between z = -2.50 and z = -1.00 (the shaded area at the far right in \nFigure 6-7) is the diﬀerence between the areas found in the preceding two steps:\n \n Statdisk\n","page_start":242,"page_end":242,"token_count":472,"section_type":"other","chapter_number":6,"chapter_title":"NORMAL PROBABILITY DISTRIBUTIONS","chunk_index":335}
{"chunk_id":"6c76ae8ded7b6fe9","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"6-1 The Standard Normal Distribution \n225\nExample 5 can be generalized as the following rule:\nThe area corresponding to the region between two z scores can be found by \nﬁnding the diﬀerence between the two areas found in Table A-2.\nFigure 6-8 illustrates this general rule. The shaded region B can be found by calculat-\ning the difference between two areas found from Table A-2.\nINTERPRETATION\nUsing the correspondence between probability and area, we conclude that there is \na probability of 0.1525 that a randomly selected subject has a bone density read-\ning between -1.00 and -2.50. Another way to interpret this result is to state that \n15.25% of people have osteopenia, with bone density readings between -1.00\nand -2.50.\nHINT Don’t try to memorize a rule or formula for this case. Focus on understanding \nby using a graph. Draw a graph, shade the desired area, and then get creative \nto think of a way to find the desired area by working with cumulative areas from \nthe left.\n0\nz Left\nz Right\nA\nB\nShaded area B 5 (areas A and B combined) — (area A)\nFIGURE 6-8 Finding the Area Between Two z Scores\nProbabilities such as those in the preceding examples can also be expressed with \nthe following notation.\nNotation\nP1a 6 z 6 b2 \ndenotes the probability that the z score is between a and b.\nP1z 7 a2 \ndenotes the probability that the z score is greater than a.\nP1z 6 a2 \ndenotes the probability that the z score is less than a.\nWith this notation, P1-2.50 6 z 6 -1.002 = 0.1525 states in symbols that the \nprobability of a z score falling between -2.50 and -1.00 is 0.1525 (as in Example 5).\nFinding z Scores from Known Areas\nExamples 3, 4, and 5 all involved the standard normal distribution, and they were all \nexamples with this same format: Given z scores, find areas (or probabilities). In many \ncases, we need a method for reversing the format: Given a known area (or probability), \nfind the corresponding z score. In such cases, it is really important to avoid  confusion \nbetween z scores and areas. Remember, z scores are distances along the horizontal \n","page_start":243,"page_end":243,"token_count":537,"section_type":"other","chapter_number":6,"chapter_title":"NORMAL PROBABILITY DISTRIBUTIONS","chunk_index":336}
{"chunk_id":"8b417578f84edad0","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"226 \nCHAPTER 6 Normal Probability Distributions\nscale, but areas (or probabilities) are regions under the density curve. (Table A-2 lists \nz-scores in the left column and across the top row, but areas are found in the body of \nthe table.) We should also remember that z scores positioned in the left half of the \ncurve are always negative. If we already know a probability and want to find the cor-\nresponding z score, we use the following procedure.\nProcedure for Finding a z Score from a Known Area\n1. Draw a bell-shaped curve and identify the region under the curve that corre-\nsponds to the given probability. If that region is not a cumulative region from the \nleft, work instead with a known region that is a cumulative region from the left.\n2. Use technology or Table A-2 to find the z score. With Table A-2, use the cu-\nmulative area from the left, locate the closest probability in the body of the \ntable, and identify the corresponding z score.\nSpecial Cases In the solution to Example 6 that follows, Table A-2 leads to a z score \nof 1.645, which is midway between 1.64 and 1.65. When using Table A-2, we can \nusually avoid interpolation by simply selecting the closest value. The accompanying \ntable lists special cases that are often used in a wide variety of applications. (For one \nof those special cases, the value of z = 2.576 gives an area slightly closer to the area \nof 0.9950, but z = 2.575 has the advantage of being the value exactly midway be-\ntween z = 2.57 and z = 2.58.) Except in these special cases, we can usually select \nthe closest value in the table. (If a desired value is midway between two table values, \nselect the larger value.) For z scores above 3.49, we can use 0.9999 as an approxima-\ntion of the cumulative area from the left; for z scores below -3.49, we can use 0.0001 \nas an approximation of the cumulative area from the left.\nSpecial Cases in Table A-2\nz Score\nCumulative  \nArea from  \nthe Left\n 1.645\n0.9500\n-1.645\n0.0500\n 2.575\n0.9950\n-2.575\n0.0050\nAbove 3.49\n0.9999\nBelow -3.49\n0.0001\n0\nArea 5 0.95\nz 5 ?\nFIGURE 6-9  Finding the 95th Percentile\nEXAMPLE 6  Bone Density Test: Finding a Test Score \nUse the same bone density test scores used in earlier examples. Those scores are \nnormally distributed with a mean of 0 and a standard deviation of 1, so they meet \nthe requirements of a standard normal distribution. Find the bone density score cor-\nresponding to P95, the 95th percentile. That is, find the bone density score that sepa-","page_start":244,"page_end":244,"token_count":659,"section_type":"other","chapter_number":6,"chapter_title":"NORMAL PROBABILITY DISTRIBUTIONS","chunk_index":337}
{"chunk_id":"2642174d7b51dc25","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"EXAMPLE 6  Bone Density Test: Finding a Test Score \nUse the same bone density test scores used in earlier examples. Those scores are \nnormally distributed with a mean of 0 and a standard deviation of 1, so they meet \nthe requirements of a standard normal distribution. Find the bone density score cor-\nresponding to P95, the 95th percentile. That is, find the bone density score that sepa-\nrates the bottom 95% from the top 5%. See Figure 6-9.\nSOLUTION\nFigure 6-9 shows the z score that is the 95th percentile, with 95% of the area (or \n0.95) below it.\nTechnology: We could find the z score using technology. The following Excel  \ndisplay shows that the z score with an area of 0.95 to its left is z = 1.644853627, or \n1.645 when rounded.","page_start":244,"page_end":244,"token_count":194,"section_type":"other","chapter_number":6,"chapter_title":"NORMAL PROBABILITY DISTRIBUTIONS","chunk_index":338}
{"chunk_id":"e6a524a8b42ecc26","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"6-1 The Standard Normal Distribution \n227\nExcel\nTable A-2: If using Table A-2, search for the area of 0.95 in the body of the table and \nthen find the corresponding z score. In Table A-2 we find the areas of 0.9495 and \n0.9505, but there’s an asterisk with a special note indicating that 0.9500 corresponds \nto a z score of 1.645. We can now conclude that the z score in Figure 6-9 is 1.645, so \nthe 95th percentile is z = 1.645.\nINTERPRETATION\nFor bone density test scores, 95% of the scores are less than or equal to 1.645, and \n5% of them are greater than or equal to 1.645.\nINTERPRETATION\nFor the population of bone density test scores, 2.5% of the scores are equal to or \nless than -1.96 and 2.5% of the scores are equal to or greater than 1.96. Another in-\nterpretation is that 95% of all bone density test scores are between -1.96 and 1.96.\n0\nz 5 1.96\nz 5 21.96\nArea 5 0.025\nArea 5 0.025\nTo ﬁnd this z score,\nlocate the cumulative\narea to the left in \nTable A–2. Locate 0.975 \nin the body of Table A–2.\nFIGURE 6-10 Finding z Scores\nEXAMPLE 7  Bone Density Test \nUsing the same bone density test described in Example 3, we have a standard normal \ndistribution with a mean of 0 and a standard deviation of 1. Find the bone density test \nscore that separates the bottom 2.5% and find the score that separates the top 2.5%.\nSOLUTION\nThe required z scores are shown in Figure 6-10. Those z scores can be found  using \ntechnology. If using Table A-2 to find the z score located to the left, we search \nthe body of the table for an area of 0.025. The result is z = -1.96. To find the \nz score located to the right, we search the body of Table A-2 for an area of 0.975. \n (Remember that Table A-2 always gives cumulative areas from the left.) The result \nis z = 1.96. The values of z = -1.96 and z = 1.96 separate the bottom 2.5% and \nthe top 2.5%, as shown in Figure 6-10.\n","page_start":245,"page_end":245,"token_count":583,"section_type":"other","chapter_number":6,"chapter_title":"NORMAL PROBABILITY DISTRIBUTIONS","chunk_index":339}
{"chunk_id":"18bac8aaf6256e72","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"228 \nCHAPTER 6 Normal Probability Distributions\nCritical Values For a normal distribution, a critical value is a z score on the bor-\nderline separating those z scores that are significantly low or significantly high. Com-\nmon critical values are z = -1.96 and z = 1.96, and they are obtained as shown in \nExample 7. In Example 7, values of z = -1.96 or lower are significantly low because \nonly 2.5% of the population have scores at or below -1.96, and the values at or above \nz = 1.96 are significantly high because only 2.5% of the population have scores at or \nabove 1.96. Critical values will become extremely important in subsequent chapters. \nThe following notation is used for critical z values found by using the standard normal \ndistribution.\nDEFINITION \nFor the standard normal distribution, a critical value is a z score on the borderline \nseparating those z scores that are significantly low or significantly high.\nCAUTION When finding a value of za for a particular value of a, note that a is the \narea to the right of za, but Table A-2 and some technologies give cumulative areas \nto the left of a given z score. To find the value of za, resolve that conflict by using \nthe value of 1 - a. For example, to find z0.1, refer to the z score with an area of 0.9 \nto its left.\nNotation \nThe expression za denotes the z score with an area of a to its right. (a is the Greek \nletter alpha.)\nEXAMPLE 8  Finding the Critical Value zA \nFind the value of z0.025. (Let a = 0.025 in the expression za.)\nSOLUTION\nThe notation of z0.025 is used to represent the z score with an area of 0.025 to its \nright. Refer to Figure 6-10 and note that the value of z = 1.96 has an area of 0.025 \nto its right, so z0.025 = 1.96. Note that z0.025 corresponds to a cumulative left area \nof 0.975.\nExamples 3 through 7 in this section are based on the real application of the bone \ndensity test, with scores that are normally distributed with a mean of 0 and standard \ndeviation of 1, so that these scores have a standard normal distribution. Apart from \nthe bone density test scores, it is rare to find such convenient parameters, because \ntypical normal distributions have means different from 0 and standard deviations dif-\nferent from 1. In the next section we present methods for working with such normal \ndistributions.\nFinding z Scores>Areas (Standard Normal)\nAccess tech instructions, videos, and data sets at www.TriolaStats.com\nTECH CENTER \n","page_start":246,"page_end":246,"token_count":605,"section_type":"other","chapter_number":6,"chapter_title":"NORMAL PROBABILITY DISTRIBUTIONS","chunk_index":340}
{"chunk_id":"d9c2ad1f178e198f","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"6-1 The Standard Normal Distribution \n229\n5. Greater than 3.00 minutes. \n6. Less than 4.00 minutes.\n7. Between 2 minutes and 3 minutes. \n8. Between 2.5 minutes and 4.5 minutes.\nStandard Normal Distribution. In Exercises 9–12, find the area of the shaded region. \nThe graph depicts the standard normal distribution of bone density scores with mean 0 and \nstandard deviation 1.\n9. \nz 5 0.44\n \n10. \nz 5 21.04\n11. \nz 5 20.84\nz 5 1.28\n \n12. \nz 5 21.07\nz 5 0.67\nStatistical Literacy and Critical Thinking\n1. Normal Distribution What’s wrong with the following statement? “Because the digits 0, 1, \n2, . . . , 9 are the normal results from lottery drawings, such randomly selected numbers have a \nnormal distribution.”\n2. Normal Distribution A normal distribution is informally described as a probability dis-\ntribution that is “bell-shaped” when graphed. Draw a rough sketch of a curve having the bell \nshape that is characteristic of a normal distribution.\n3. Standard Normal Distribution Identify the two requirements necessary for a normal dis-\ntribution to be a standard normal distribution.\n4. Notation What does the notation za indicate?\nContinuous Uniform Distribution. In Exercises 5–8, refer to the continuous uniform \ndistribution depicted in Figure 6-2 and described in Example 1. Assume that a patient is \nrandomly selected, and find the probability that the waiting time is within the given range.\n6-1 Basic Skills and Concepts \n0\n0.2\n1\n2\nArea 5 1\n3\n4\n5\nx (waiting time in minutes)\nP(x)\nFIGURE 6-2  Uniform Distribution of  \nWaiting Time\n","page_start":247,"page_end":247,"token_count":416,"section_type":"other","chapter_number":6,"chapter_title":"NORMAL PROBABILITY DISTRIBUTIONS","chunk_index":341}
{"chunk_id":"665a316e10f1f62d","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"230 \nCHAPTER 6 Normal Probability Distributions\nStandard Normal Distribution. In Exercises 13–16, find the indicated z score. The \ngraph depicts the standard normal distribution of bone density scores with mean 0 and \n standard deviation 1.\n13. \n0\n0.8907\nz\n \n14. \nz 0\n0.3050\n15. \nz\n0\n0.9265\n \n16. \nz\n0\n0.2061\nStandard Normal Distribution. In Exercises 17–36, assume that a randomly selected \nsubject is given a bone density test. Those test scores are normally distributed with a mean \nof 0 and a standard deviation of 1. In each case, draw a graph, then find the probability of \nthe given bone density test scores. If using technology instead of Table A-2, round answers \nto four decimal places.\n17. Less than -1.23. \n18. Less than -1.96.\n19. Less than 1.28. \n20. Less than 2.56.\n21. Greater than 0.25. \n22. Greater than 0.18.\n23. Greater than -2.00. \n24. Greater than –3.05.\n25. Between 2.00 and 3.00. \n26. Between 1.50 and 2.50.\n27. Between and -2.55 and -2.00. \n28. Between -2.75 and –0.75.\n29. Between -2.00 and 2.00. \n30. Between -3.00 and 3.00.\n31. Between -1.00 and 5.00. \n32. Between -4.27 and 2.34.\n33. Less than 4.55. \n34. Greater than -3.75.\n35. Greater than 0. \n36. Less than 0.\nFinding Bone Density Scores. In Exercises 37–40 assume that a randomly selected sub-\nject is given a bone density test. Bone density test scores are normally distributed with a mean \nof 0 and a standard deviation of 1. In each case, draw a graph, and then find the bone den-\nsity test score corresponding to the given information. Round results to two decimal places.\n37. Find P99, the 99th percentile. This is the bone density score separating the bottom 99% \nfrom the top 1%.\n38. Find P10, the 10th percentile. This is the bone density score separating the bottom 10% \nfrom the top 90%.\n39. If bone density scores in the bottom 2% and the top 2% are used as cutoff points for levels \nthat are too low or too high, find the two readings that are cutoff values.\n40. Find the bone density scores that can be used as cutoff values separating the lowest 3% and \nhighest 3%.\n","page_start":248,"page_end":248,"token_count":640,"section_type":"other","chapter_number":6,"chapter_title":"NORMAL PROBABILITY DISTRIBUTIONS","chunk_index":342}
{"chunk_id":"5a358231185716aa","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"6-2 Real Applications of Normal Distributions \n231\nCritical Values. In Exercises 41–44, find the indicated critical value. Round results to two \ndecimal places.\n41. z0.10    42. z0.02    43. z0.04    44. z0.15\nBasis for the Range Rule of Thumb and the Empirical Rule. In Exercises 45–48, find \nthe indicated area under the curve of the standard normal distribution; then convert it to a \npercentage and fill in the blank. The results form the basis for the range rule of thumb and \nthe empirical rule introduced in Section 3-2.\n45. About t \n % of the area is between z = -1 and z = 1 (or within 1 standard devia-\ntion of the mean).\n46. About % of the area is between z = -2 and z = 2 (or within 2 standard deviations of the \nmean).\n47. About % \n of the area is between z = -3 and z = 3 (or within 3 standard devia-\ntions of the mean).\n48. About %  \n of the area is between z = -3.5 and z = 3.5 (or within 3.5 standard \ndeviations of the mean).\n49. Significance For bone density scores that are normally distributed with a mean of 0 and a \nstandard deviation of 1, find the percentage of scores that are\na. significantly high (or at least 2 standard deviations above the mean).\nb. significantly low (or at least 2 standard deviations below the mean).\nc. not significant (or less than 2 standard deviations away from the mean).\n50. Distributions In a continuous uniform distribution,\nm = minimum +  \n maximum\n2\n and s = range\n212\na. Find the mean and standard deviation for the distribution of the waiting times represented in \nFigure 6-2, which accompanies Exercises 5–8.\nb. For a continuous uniform distribution with m = 0 and s = 1, the minimum is - 23 and \nthe maximum is 23. For this continuous uniform distribution, find the probability of randomly \nselecting a value between -1 and 1, and compare it to the value that would be obtained by in-\ncorrectly treating the distribution as a standard normal distribution. Does the distribution affect \nthe results very much?\n6-1 Beyond the Basics \nKey Concept Now we really get real as we extend the methods of the previous section \nso that we can work with any nonstandard normal distribution (with a mean different \nfrom 0 and>or a standard deviation different from 1). The key is a simple conversion \n(Formula 6-2) that allows us to “standardize” any normal distribution so that x values \ncan be transformed to z scores; then the methods of the preceding section can be used.\n6-2 \nReal Applications of Normal Distributions\n","page_start":249,"page_end":249,"token_count":629,"section_type":"other","chapter_number":6,"chapter_title":"NORMAL PROBABILITY DISTRIBUTIONS","chunk_index":343}
{"chunk_id":"7b6cee3fbd6df537","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"232 \nCHAPTER 6 Normal Probability Distributions\nFORMULA 6-2\nz = x - m\ns\n  (round z scores to 2 decimal places)\nFigure 6-11 illustrates the conversion from a nonstandard to a standard normal \ndistribution. The area in any normal distribution bounded by some score x (as in \nFigure 6-11a) is the same as the area bounded by the corresponding z score in the \nstandard normal distribution (as in Figure 6-11b).\nx\nm\nm\ns\nz 5 x 2\nz\nP\nP\n0\n(b) Standard\n \nNormal Distribution\n(a) Nonstandard\n \nNormal Distribution\nFIGURE 6-11 Converting Distributions\nSome calculators and software do not require the use of Formula 6-2 to convert to \nz scores because probabilities can be found directly. However, if using Table A-2, we \nmust first convert values to standard z scores.\nWhen finding areas with a nonstandard normal distribution, use the following \nprocedure.\nProcedure for Finding Areas with a Nonstandard Normal Distribution\n1. Sketch a normal curve, label the mean and any specific x values, and then shade \nthe region representing the desired probability.\n2. For each relevant value x that is a boundary for the shaded region, use Formula 6-2 \nto convert that value to the equivalent z score. (With many technologies, this step \ncan be skipped.)\n3. Use technology (software or a calculator) or Table A-2 to find the area of \nthe shaded region. This area is the desired probability.\nThe following example illustrates the above procedure.\nEXAMPLE 1   What Is the Proportion of Adult Males with Pulse \nRates Greater Than 100 Bpm?\nIn the Chapter Problem we noted that pulse rates of adult males are normally dis-\ntributed with a mean of 69.6 bpm and a standard deviation of 11.3 bpm. Find the \nproportion of adult males with a pulse rate greater than 100 bpm. These males are \nconsidered to be at a high risk of stroke, heart disease, or cardiac death.\nSOLUTION\nStep 1: See Figure 6-12, which incorporates this information: Men have pulse rates \nthat are normally distributed with a mean of 69.6 bpm and a standard deviation of \n11.3 bpm. The shaded region represents the men with pulse rates above 100 bpm.\n","page_start":250,"page_end":250,"token_count":506,"section_type":"other","chapter_number":6,"chapter_title":"NORMAL PROBABILITY DISTRIBUTIONS","chunk_index":344}
{"chunk_id":"598a15568e3f1561","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"6-2 Real Applications of Normal Distributions \n233\n \n0.0036\n100\nm 5 69.6\nx (pulse rate)\nz 5 0\nz 5 2.69\nz scale\nFIGURE 6-12 Pulse Rates of Men\nStep 2: We can convert a pulse rate of 100 bpm to the z score of 2.69 by using \n Formula 6-2 as follows:\nz = x - m\ns\n= 100 - 69.6\n11.3\n= 2.69 1rounded to two decimal places2\nStep 3: Technology: Technology can be used to find that the area to the right \nof 100 bpm in Figure 6-12 is 0.0036. (With many technologies, Step 2 can be \nskipped.)\nTable A-2: Use Table A-2 to find that the cumulative area to the left of z = 2.69 \nis 0.9964. (Remember, Table A-2 is designed so that all areas are cumulative areas \nfrom the left.) Because the total area under the curve is 1, it follows that the shaded \narea in Figure 6-12 is 1 - 0.9964 = 0.0036.\nINTERPRETATION\nThe proportion of men with pulse rates above 100 bpm is 0.0036, which is roughly \n4 men in a thousand. This is a very rare event, so an adult male presenting with a \npulse rate above 100 bpm is extremely rare, or there is some medical condition that \nis causing the high pulse rate.\nEXAMPLE 2  Normal Pulse Rates\nNormal pulse rates are generally considered to be between 60 bpm and 100 bpm.\nGiven that pulse rates of adult males are normally distributed with a mean of \n69.6 bpm and a standard deviation of 11.3 bpm, find the percentage of males with \nnormal pulse rates.\nSOLUTION\nFigure 6-13 shows the shaded region representing men with pulse rates between \n60 bpm and 100 bpm.\nStep 1: See Figure 6-13 on the next page, which incorporates this information:  \nMen have pulse rates that are normally distributed with a mean of 69.6 bpm and a \nstandard deviation of 11.3 bpm. The shaded region represents the men with pulse \nrates between 60 bpm and 100 bpm.\ncontinued\nHigh Cost of Low Quality\nThe Federal \nDrug Adminis-\ntration recently \nreached an \nagreement \nwhereby a \npharmaceutical \ncompany, the Schering-Plough \nCorporation, would pay a record \n$500 million for failure to cor-\nrect problems in manufactur-\ning drugs. According to a New \nYork Times article by Melody \nPetersen, “Some of the problems \nrelate to the lack of controls that \nwould identify faulty medicines, \nwhile others stem from outdated \nequipment. They involve some \n200 medicines, including Claritin, \nthe allergy medicine that is \nSchering’s top-selling product.”\nh\ni\nPl\nh\n","page_start":251,"page_end":251,"token_count":659,"section_type":"other","chapter_number":6,"chapter_title":"NORMAL PROBABILITY DISTRIBUTIONS","chunk_index":345}
{"chunk_id":"4056d1f5cb5db638","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"234 \nCHAPTER 6 Normal Probability Distributions\nStep 2: With some technologies, the shaded area in Figure 6-13 can be found \n directly and it is not necessary to convert the x scores of 60 bpm and 100 bpm to  \nz scores. (See Step 3.)\nIf using Table A-2, we cannot find the shaded area directly, but we can find it \nindirectly by using the same procedures from Section 6-1, as follows: (1) Find the \ncumulative area from the left up to 100 bpm (or z = 2.69); (2) find the cumulative \narea from the left up to 60 bpm (or z = -0.85); (3) find the difference between \nthose two areas. The pulse rates of 100 bpm and 60 bpm are converted to z scores \nby using Formula 6-2 as follows:\nFor x = 100 bpm: z = x - m\ns\n= 100 - 69.6\n11.3\n= 2.69 \n1z = 2.69 yields an area of 0.9964.2\nFor x = 60 bpm: z = x - m\n11.3\n= 60 - 69.6\n11.3\n= -0.85\n1z = -0.85 yields an area of 0.1977.2\nStep 3: Technology: Technology will show that the shaded area in Figure 6-13 is \n0.7986.\nTable A-2: Refer to Table A-2 with z = 2.69 and find that the cumulative area to \nthe left of z = 2.69 is 0.9964. (Remember, Table A-2 is designed so that all areas \nare cumulative areas from the left.) Table A-2 also shows that z = -0.85 corre-\nsponds to an area of 0.1977. Because the areas of 0.9964 and 0.1977 are cumulative \nareas from the left, we find the shaded area in Figure 6-13 as follows:\nShaded area in Figure 6@13 = 0.9964 - 0.1977 = 0.7987\nThere is a small discrepancy between the area of 0.7986 found from technology \nand the area of 0.7987 found from Table A-2. The area obtained from technology \nis more accurate because it is based on unrounded z scores, whereas Table A-2 \nrequires z scores rounded to two decimal places.\nINTERPRETATION\nExpressing the result as a percentage, we conclude that about 80% of men have \npulse rates between 60 bpm and 100 bpm.\n 0.7986\n100\n60\nm 5 69.6\nx (pulse rate)\nz 5 0\nz 5 2.69\nz 5 20.85\nz scale\nFIGURE 6-13 Pulse Rates of Men\n","page_start":252,"page_end":252,"token_count":642,"section_type":"other","chapter_number":6,"chapter_title":"NORMAL PROBABILITY DISTRIBUTIONS","chunk_index":346}
{"chunk_id":"5643ba7a8543b8d6","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"6-2 Real Applications of Normal Distributions \n235\nFinding Values from Known Areas\nHere are helpful hints for those cases in which the area (or probability or percentage) \nis known and we must find the relevant value(s):\n1. Graphs are extremely helpful in visualizing, understanding, and successfully \nworking with normal probability distributions, so they should always be \nused.\n2. Don’t confuse z scores and areas. Remember, z scores are distances along the \nhorizontal scale, but areas are regions under the normal curve. Table A-2 lists \nz scores in the left columns and across the top row, but areas are found in the \nbody of the table.\n3. Choose the correct (right>left) side of the graph. A value separating the top \n10% from the others will be located on the right side of the graph, but a value \nseparating the bottom 10% will be located on the left side of the graph.\n4. A z score must be negative whenever it is located in the left half of the normal \ndistribution.\n5. Areas (or probabilities) are always between 0 and 1, and they are never \nnegative.\nProcedure for Finding Values from Known Areas or Probabilities\n1. Sketch a normal distribution curve, write the given probability or percent-\nage in the appropriate region of the graph, and identify the x value(s) being \nsought.\n2. Use technology. If technology is not available, use Table A-2 by referring to \nthe body of Table A-2 to find the area to the left of x; then identify the z score \ncorresponding to that area.\n3. If you know z and must convert to the equivalent x value, use Formula 6-2 by \nentering the values for m, s, and the z score found in Step 2; then solve for x. \nBased on Formula 6-2, we can solve for x as follows:\nx = m + 1z # s2  \n1another form of Formula 6@22\nc\n(If z is located to the left of the mean, be sure that it is a negative number.)\n4. Refer to the sketch of the curve to verify that the solution makes sense in \nthe context of the graph and in the context of the problem.\nThe following example uses this procedure for finding a value from a known area.\nEXAMPLE 3  Pulse Rates\nGiven that pulse rates of adult males are normally distributed with a mean of \n69.6 bpm and a standard deviation of 11.3 bpm, find the pulse rate that separates the \nhighest 1% from the lowest 99%. That is, find P99.\nSOLUTION\nStep 1: Figure 6-14 on the next page shows the normal distribution with the pulse \nrate x that we want to identify. The shaded area represents the lowest 99% of the \npulse rates.\ncontinued\n","page_start":253,"page_end":253,"token_count":607,"section_type":"other","chapter_number":6,"chapter_title":"NORMAL PROBABILITY DISTRIBUTIONS","chunk_index":347}
{"chunk_id":"0bc387eeac3bd893","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"236 \nCHAPTER 6 Normal Probability Distributions\nTable A-2: If using Table A-2, search for an area of 0.9900 in the body of the table. \nThe area of 0.9900 corresponds to z = 2.33.\nStep 3: With z = 2.33, m = 69.6 bpm, and s = 11.3 bpm, we can solve for x by us-\ning Formula 6-2:\nz = x - m\ns  becomes 2.33 = x - 69.6\n11.3\nThe result of x = 95.929 bpm can be found directly or by using the following ver-\nsion of Formula 6-2:\nx = m + 1z # s2 = 69.6 + 12.33 # 11.32 = 95.929 bpm\nStep 4: The solution of x = 95.9 bpm (rounded) in Figure 6-14 is reasonable be-\ncause it is greater than the mean of 69.6 bpm.\nINTERPRETATION\nThe male pulse rate of 95.9 (rounded) separates the top 1% from the bottom 99%.\n \n0.99\nx 5 ?\nm 5 69.6\nx (pulse rate)\nz 5 0\nz 5 2.83\nz scale\nFIGURE 6-14 Finding the 99th Percentile\nStep 2: Technology: Technology will provide the value of x in Figure 6-14. For \nexample, see the accompanying Excel display showing that x = 95.88773098 bpm, \nor 95.9 bpm when rounded.\n Excel\nSignificance\nIn Chapter 4 we saw that probabilities can be used to determine whether values are \nsignificantly high or significantly low. Chapter 4 referred to x successes among n tri-\nals, but we can adapt those criteria to apply to continuous variables as follows:\nSigniﬁcantly high: The value x is signiﬁcantly high if P(x or greater) … 0.05.*\nSigniﬁcantly low: The value x is signiﬁcantly low if P(x or less) … 0.05.*\n*The value of 0.05 is not absolutely rigid, and other values such as 0.01 could be used instead.\n","page_start":254,"page_end":254,"token_count":508,"section_type":"other","chapter_number":6,"chapter_title":"NORMAL PROBABILITY DISTRIBUTIONS","chunk_index":348}
{"chunk_id":"b45c83e02d628a4e","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"6-2 Real Applications of Normal Distributions \n237\nStep 2: Technology: Technology will show that the values of x in Figure 6-15 are \n53.4 beats per minute and 94.6 beats per minute when rounded.\nTable A-2: If using Table A-2, we must work with cumulative areas from the left. \nFor the leftmost value of x, the cumulative area from the left is 0.05, so search for \nan area of 0.05 in the body of the table to get z = -1.645 (identified by the aster-\nisk between 0.0505 and 0.0495). For the rightmost value of x, the cumulative area \nfrom the left is 0.95, so search for an area of 0.9500 in the body of the table to get \nz = 1.645 (identified by the asterisk between 0.9495 and 0.9505). Having found \nthe two z scores, we now proceed to convert them to pulse rates.\nStep 3: We now solve for the two values of x by using Formula 6-2 directly or by \nusing the following version of Formula 6-2:\nLeftmost value of x:  \nx = m + 1z # s2 = 74.0 + 1-1.645 # 12.52 = 53.4\nRightmost value of x: x = m + 1z # s2 = 74.0 + 11.645 # 12.52 = 94.6\nStep 4: Referring to Figure 6-15, we see that the leftmost value of x = 53.4 is rea-\nsonable because it is less than the mean of 74.0. Also, the rightmost value of 94.6 is \nreasonable because it is above the mean of 74.0.\nINTERPRETATION\nHere are the pulse rates of women that are significant:\n \n■Significantly low: 53.4 beats per minute or lower\n \n■Significantly high: 94.6 beats per minute or higher\nPhysicians could use these results to investigate health issues that could cause pulse \nrates to be significantly low or significantly high.\n0.05\nx 5 ?\nx 5 ?\nm 5 74.0\n0.05\nFIGURE 6-15 Pulse Rates of Women\nEXAMPLE 4   Significantly Low or Significantly High Female \nPulse Rates\nUse the preceding criteria to identify pulse rates of women that are significantly low \nor significantly high. Based on Data Set 1 “Body Data” in Appendix B, assume that \nwomen have normally distributed pulse rates with a mean of 74.0 beats per minute \nand a standard deviation of 12.5 beats per minute.\nSOLUTION\nStep 1: We begin with the graph shown in Figure 6-15. We have entered the mean of \n74.0, and we have identified the x values separating the lowest 5% and the highest 5%.\n","page_start":255,"page_end":255,"token_count":648,"section_type":"other","chapter_number":6,"chapter_title":"NORMAL PROBABILITY DISTRIBUTIONS","chunk_index":349}
{"chunk_id":"f9f5f866b8ec4732","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"238 \nCHAPTER 6 Normal Probability Distributions\nFinding x Values>Areas\nAccess tech instructions, videos, and data sets at www.TriolaStats.com\nTECH CENTER \nStatistical Literacy and Critical Thinking \n1. Birth Weights Based on Data Set 3 “Births” in Appendix B, birth weights are normally \ndistributed with a mean of 3152.0 g and a standard deviation of 693.4 g.\na. What are the values of the mean and standard deviation after converting all birth weights to \nz scores using z = 1x - m2>s?\nb. The original birth weights are in grams. What are the units of the corresponding z scores?\n2. Birth Weights Based on Data Set 3 “Births” in Appendix B, birth weights are normally \ndistributed with a mean of 3152.0 g and a standard deviation of 693.4 g.\na. For the bell-shaped graph, what is the area under the curve?\nb. What is the value of the median?\nc. What is the value of the mode?\nd. What is the value of the variance?\n3. Normal Distributions What is the difference between a standard normal distribution and a \nnonstandard normal distribution?\n4. Random Digits Computers are commonly used to randomly generate digits of telephone \nnumbers to be called when conducting the California Health Survey. Can the methods of this \nsection be used to find the probability that when one digit is randomly generated, it is less than \n3? Why or why not? What is the probability of getting a digit less than 3?\nIQ Scores. In Exercises 5–8, find the area of the shaded region. The graphs depict IQ \nscores of adults, and those scores are normally distributed with a mean of 100 and a stan-\ndard deviation of 15 (as on the Wechsler IQ test).\n5. \n118\n \n6. \n91\n7. \n79\n133\n \n8. \n124\n112\n6-2 Basic Skills and Concepts\n","page_start":256,"page_end":256,"token_count":425,"section_type":"other","chapter_number":6,"chapter_title":"NORMAL PROBABILITY DISTRIBUTIONS","chunk_index":350}
{"chunk_id":"1c1cf5f98bbfb1ea","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"6-2 Real Applications of Normal Distributions \n239\nIQ Scores. In Exercises 9–12, find the indicated IQ score and round to the nearest whole \nnumber. The graphs depict IQ scores of adults, and those scores are normally distributed \nwith a mean of 100 and a standard deviation of 15 (as on the Wechsler IQ test).\n9. \nx\n0.9918\n \n10. \nx\n0.1587\n11. \nx\n0.9798\n \n12. \nx\n0.9099\nFemale Pulse Rates. In Exercises 13–20, assume that an adult female is randomly \n selected. Females have pulse rates that are normally distributed with a mean of 74.0 beats \nper minute and a standard deviation of 12.5 beats per minute (based on Data Set 1 “Body \nData” in Appendix B). (Hint: Draw a graph in each case.)\n13. Find the probability of a pulse rate less than 100 beats per minute.\n14. Find the probability of a pulse rate greater than 80 beats per minute.\n15. Find the probability of a pulse rate between 60 beats per minute and 70 beats per minute.\n16. Find the probability of a pulse rate between 70 beats per minute and 90 beats per minute.\n17. Find P90, which is the pulse rate separating the bottom 90% from the top 10%.\n18.  Find the first quartile Q1, which is the pulse rate separating the bottom 25% from the \ntop 75%.\n19. Significance Instead of using 0.05 for identifying significant values, use the criteria \nthat a value x is significantly high if P(x or greater) … 0.01 and a value is significantly low \nif P(x or less) … 0.01. Find the pulse rates separating significant values from those that are \nnot significant. Using these criteria, is a pulse rate of 102 beats per minute significantly high?\n20. Significance Instead of using 0.05 for identifying significant values, use the criteria \nthat a value x is significantly high if P(x or greater) … 0.025 and a value is significantly low \nif P(x or less) … 0.025. Find the pulse rates separating significant values from those that are \nnot significant. Using these criteria, is a pulse rate of 48 beats per minute significantly low?\n21. Eye Contact In a study of facial behavior, people in a control group are timed for eye con-\ntact in a 5-minute period. Their times are normally distributed with a mean of 184.0  seconds \nand a standard deviation of 55.0 seconds (based on data from “Ethological Study of Facial \n Behavior in Nonparanoid and Paranoid Schizophrenic Patients,” by Pittman, Olk, Orr, and \nSingh, Psychiatry, Vol. 144, No. 1). For a randomly selected person from the control group, \nfind the probability that the eye contact time is greater than 230.0 seconds, which is the mean \nfor paranoid schizophrenics. Based on personal experience, does the result appear to be the \nproportion of people who are paranoid schizophrenics?\n","page_start":257,"page_end":257,"token_count":682,"section_type":"other","chapter_number":6,"chapter_title":"NORMAL PROBABILITY DISTRIBUTIONS","chunk_index":351}
{"chunk_id":"0cb4042b92457663","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"240 \nCHAPTER 6 Normal Probability Distributions\n22. Body Temperatures Based on sample results in Data Set 2 “Body Temperatures” in \nAppendix B, assume that human body temperatures are normally distributed with a mean of \n98.20°F and a standard deviation of 0.62°F.\na. According to emedicinehealth.com, a body temperature of 100.4oF or above is considered \nto be a fever. What percentage of normal and healthy persons would be considered to have a \nfever? Does this percentage suggest that a cutoff of 100.4oF is appropriate?\nb. Physicians want to select a minimum temperature for requiring further medical tests. What \nshould that temperature be if we want only 2.0% of healthy people to exceed it? (Such a result \nis a false positive, meaning that the test result is positive, but the subject is not really sick.)\n23.  Low Birth Weight The University of Maryland Medical Center considers “low birth \nweights” to be those less than 5.5 lb or 2495 g. Birth weights are normally distributed with a mean \nof 3152.0 g and a standard deviation of 693.4 g (based on Data Set 3 “Births” in Appendix B).\na. If a birth weight is randomly selected, what is the probability that it is a “low birth weight”?\nb. Find the weights considered to be significantly low using the criterion of a probability of \n0.05 or less. How do these results compare to the criterion of 2495 g?\nc. Compare the results from parts (a) and (b).\n24. Durations of Pregnancies The lengths of pregnancies are normally distributed with a \nmean of 268 days and a standard deviation of 15 days.\na. In a letter to “Dear Abby,” a wife claimed to have given birth 308 days after a brief visit from \nher husband, who was working in another country. Find the probability of a pregnancy lasting \n308 days or longer. What does the result suggest?\nb. If we stipulate that a baby is premature if the duration of pregnancy is in the lowest 3%, \nfind the duration that separates premature babies from those who are not premature. Premature \nbabies often require special care, and this result could be helpful to hospital administrators in \nplanning for that care.\nLarge Data Sets. In Exercises 25 and 26, refer to the data sets in Appendix B and use \nsoftware or a calculator.\n25. Diastolic Blood Pressure of Males Refer to Data Set 1 in Appendix B and use the \ndiastolic blood pressures of males.\na. Find the mean and standard deviation, and verify that the data have a distribution that is \nroughly normal. Round the results using three decimal places.\nb. Treating the unrounded values of the mean and standard deviation as parameters, and assum-\ning that male diastolic blood pressures are normally distributed, find diastolic blood pressures \nseparating the lowest 2.5% and the highest 2.5%. These values could be helpful when physi-","page_start":258,"page_end":258,"token_count":652,"section_type":"other","chapter_number":6,"chapter_title":"NORMAL PROBABILITY DISTRIBUTIONS","chunk_index":352}
{"chunk_id":"be14f87757118b9b","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"a. Find the mean and standard deviation, and verify that the data have a distribution that is \nroughly normal. Round the results using three decimal places.\nb. Treating the unrounded values of the mean and standard deviation as parameters, and assum-\ning that male diastolic blood pressures are normally distributed, find diastolic blood pressures \nseparating the lowest 2.5% and the highest 2.5%. These values could be helpful when physi-\ncians try to determine whether diastolic blood pressures are significantly low or significantly \nhigh.\n26.  Diastolic Blood Pressure of Females Repeat the preceding exercise using females \ninstead of males.\n27. Outliers For the purposes of constructing modified boxplots as described in Section 3-3, \noutliers are defined as data values that are above Q3 by an amount greater than 1.5 *  IQR or \nbelow Q1 by an amount greater than 1.5 *  IQR, where IQR is the interquartile range. Using \nthis definition of outliers, find the probability that when a value is randomly selected from a \nnormal distribution, it is an outlier.\n6-2 Beyond the Basics","page_start":258,"page_end":258,"token_count":250,"section_type":"other","chapter_number":6,"chapter_title":"NORMAL PROBABILITY DISTRIBUTIONS","chunk_index":353}
{"chunk_id":"8cff85e4f7ed07c3","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"6-3 Sampling Distributions and Estimators \n241\nA Short Story Among the population of all adults, exactly 40% have brown eyes (the \nauthors just know this). In a survey of 1000 adults, 42% of the subjects were observed \nto have brown eyes. Being so intrigued by this, 50,000 people became so enthusias-\ntic that they each conducted their own individual survey of 1000 randomly selected \nadults. Each of these 50,000 new surveyors reported the percentage that they found, \nwith results such as 38%, 39%, and 43%. The authors obtained each of the 50,000 \nKey Concept We now consider the concept of a sampling distribution of a statistic. \nInstead of working with values from the original population, we want to focus on \nthe values of statistics (such as sample proportions or sample means) obtained from \nthe population. Figure 6-16 shows the key points that we need to know, so try really, \nreally hard to understand the story that Figure 6-16 tells.\n6-3 \nSampling Distributions and Estimators\nProportions\nSample 1\nSample 2\nSample 3\n(Population Proportion is p)\nDistribution of\nSample Proportions\nSample\nProportions\nSample\nSample proportions tend to\nhave a normal distribution\npˆ pˆ pˆ pˆ pˆ\npˆ pˆ pˆ\npˆ pˆ\npˆ\npˆ\npˆ\npˆ\npˆ pˆ pˆ pˆ pˆ\npˆ\np\nˆ\n•\n•\n•\n1pˆ\n2pˆ\n3pˆ\nSampling\nProcedure:\nRandomly select n\nvalues and ﬁnd\nthe proportion p for\neach sample.\nˆ\nMeans\nSample 1\nSample 2\nSample 3\n(Population Mean is m)\nDistribution of\nSample Means\nSample Means\nSample\nSample means tend to\nhave a normal distribution\n•\n•\n•\nSampling\nProcedure:\nRandomly select n\nvalues and ﬁnd\nthe mean x for\neach sample.\nx x x x x x\nx x x x\nx x x\nx x\nx\nx\nX1\nX2\nX3\nx\nx\nx\nx\nx\nVariances\nSample 1\nSample 2\nSample 3\n(Population Variance is s2)\nDistribution of\nSample Variances\nSample\nVariances\nSample\nSample variances tend to\nhave a skewed distribution\n•\n•\n•\nSampling\nProcedure:\nRandomly select n\nvalues and ﬁnd\nthe variance s2 for\neach sample.\ns2\n1\ns2\n2\ns2\n3\ns2\ns2 s2\ns2 s2 s2\ns2s2s2s2s2s2\ns2s2s2s2s2s2\ns2 s2 s2 s2\ns2s2s2s2s2\nFIGURE 6-16 General Behavior of Sampling Distributions\ncontinued\n","page_start":259,"page_end":259,"token_count":688,"section_type":"other","chapter_number":6,"chapter_title":"NORMAL PROBABILITY DISTRIBUTIONS","chunk_index":354}
{"chunk_id":"3ed112310c4aec96","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"242 \nCHAPTER 6 Normal Probability Distributions\nsample percentages, changed them to proportions, and then they constructed the his-\ntogram shown in Figure 6-17. Notice anything about the shape of the histogram? It’s \nnormal. Notice anything about the mean of the sample proportions? They are centered \nabout the value of 0.40, which happens to be the population proportion. Moral: When \nsamples of the same size are taken from the same population, the following two prop-\nerties apply:\n1. Sample proportions tend to be normally distributed.\n2. The mean of sample proportions is the same as the population mean.The \nimplications of the preceding properties will be extensive in the chapters \nthat follow.\nFIGURE 6-17 Histogram of 50,000 Sample Proportions\nLet’s formally define sampling distribution, the main character in the preceding short \nstory.\nDEFINITION\nThe sampling distribution of a statistic (such as a sample proportion or sample \nmean) is the distribution of all values of the statistic when all possible samples of \nthe same size n are taken from the same population. (The sampling distribution of a \nstatistic is typically represented as a probability distribution in the format of a prob-\nability histogram, formula, or table.)\nSampling Distribution of Sample Proportion\nThe preceding general definition of a sampling distribution of a statistic can now be \nrestated for the specific case of a sample proportion:\nDEFINITION\nThe sampling distribution of the sample proportion is the distribution of sample \nproportions (or the distribution of the variable pn), with all samples having the same \nsample size n taken from the same population. (The sampling distribution of the \nsample proportion is typically represented as a probability distribution in the format \nof a probability histogram, formula, or table.)\nWe need to distinguish between a population proportion p and a sample proportion, \nand the following notation is common and will be used throughout the remainder of \nthis book, so it’s very important.\n","page_start":260,"page_end":260,"token_count":405,"section_type":"other","chapter_number":6,"chapter_title":"NORMAL PROBABILITY DISTRIBUTIONS","chunk_index":355}
{"chunk_id":"ba5d32dc264880b1","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"6-3 Sampling Distributions and Estimators \n243\nNotation for Proportions\np = population proportion\npn = sample proportion\nHINT pn is pronounced “p-hat.” When symbols are used above a letter, as in x and \npn, they represent statistics, not parameters.\nBehavior of Sample Proportions\n1. The distribution of sample proportions tends to approximate a normal distribution.\n2. Sample proportions target the value of the population proportion in the \nsense that the mean of all of the sample proportions pn is equal to the popu-\nlation proportion p; the expected value of the sample proportion is equal to \nthe population proportion.\nEXAMPLE 1  Sampling Distribution of the Sample Proportion\nConsider repeating this process: Roll a die 5 times and find the proportion of odd \nnumbers (1 or 3 or 5). What do we know about the behavior of all sample propor-\ntions that are generated as this process continues indefinitely?\nSOLUTION\nFigure 6-18 illustrates a process of rolling a die 5 times and finding the proportion of \nodd numbers. (Figure 6-18 shows results from repeating this process 10,000 times, \nbut the true sampling distribution of the sample proportion involves repeating the \nprocess indefinitely.) Figure 6-18 shows that the sample proportions are approxi-\nmately normally distributed. (Because the values of 1, 2, 3, 4, 5, 6 are all equally \nlikely, the proportion of odd numbers in the population is 0.5, and Figure 6-18 shows \nthat the sample proportions have a mean of 0.50.)\nProportions\nSample 1\nSample 2\nSample 3\n(Population Proportion is p 5 0.5)\nDistribution of\nSample Proportions\nSample\nProportions\nSample\np 5 0.5\nSample proportions are\napproximately normal\n•\n•\n•\n0.2\n0.4\n0.8\nSampling Procedure:\nRoll a die 5 times and\nﬁnd the proportion p\nof odd numbers for\neach sample.\nˆ\nFIGURE 6-18 Sample Proportions from 10,000 Trials\n","page_start":261,"page_end":261,"token_count":465,"section_type":"other","chapter_number":6,"chapter_title":"NORMAL PROBABILITY DISTRIBUTIONS","chunk_index":356}
{"chunk_id":"2f52fb88208e5464","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"244 \nCHAPTER 6 Normal Probability Distributions\nBehavior of Sample Means\n1. The distribution of sample means tends to be a normal distribution. (This will \nbe discussed further in the following section, but the distribution tends to be-\ncome closer to a normal distribution as the sample size increases.)\n2. The sample means target the value of the population mean. (That is, the \nmean of the sample means is the population mean. The expected value of \nthe sample mean is equal to the population mean.)\nDEFINITION\nThe sampling distribution of the sample mean is the distribution of all possible \nsample means (or the distribution of the variable x), with all samples having the \nsame sample size n taken from the same population. (The sampling distribution of \nthe sample mean is typically represented as a probability distribution in the format \nof a probability histogram, formula, or table.)\nEXAMPLE 2  Sampling Distribution of the Sample Mean\nA pediatrician has three patients with measles and they are ages 4, 5, and 9.  \nConsider the population of {4, 5, 9}. If two ages are randomly selected with replace-\nment from the population {4, 5, 9}, identify the sampling distribution of the sample \nmean by creating a table representing the probability distribution of the sample mean. \nDo the values of the sample mean target the value of the population mean?\nSOLUTION\nIf two values are randomly selected with replacement from the population {4, 5, 9}, \nthe leftmost column of Table 6-2 lists the nine different possible samples. The second \ncolumn lists the corresponding sample means. The nine samples are equally likely \nwith a probability of 1>9. We saw in Section 5-1 that a probability distribution gives \nthe probability for each value of a random variable, as in the second and third col-\numns of Table 6-2. The second and third columns of Table 6-2 represent the sampling \ndistribution of the sample mean. In Table 6-2, some of the sample mean values are \nrepeated, so we combined them in Table 6-3.\nTABLE 6-2 Sampling Distribution  \nof Mean\nSample\nSample Mean x\nProbability\n4, 4\n4.0\n1>9\n4, 5\n4.5\n1>9\n4, 9\n6.5\n1>9\n5, 4\n4.5\n1>9\n5, 5\n5.0\n1>9\n5, 9\n7.0\n1>9\n9, 4\n6.5\n1>9\n9, 5\n7.0\n1>9\n9, 9\n9.0\n1>9\nTABLE 6-3 Sampling Distribution \nof Mean (Condensed)\nSample Mean x\nProbability\n4.0\n1>9\n4.5\n2>9\n5.0\n1>9\n6.5\n2>9\n7.0\n2>9\n9.0\n1>9\nSampling Distribution of the Sample Mean\nWe now consider sample means.\n","page_start":262,"page_end":262,"token_count":661,"section_type":"other","chapter_number":6,"chapter_title":"NORMAL PROBABILITY DISTRIBUTIONS","chunk_index":357}
{"chunk_id":"394cfbe9b39b552e","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"6-3 Sampling Distributions and Estimators \n245\nIf we were to create a probability histogram from Table 6-2, it would not have \nthe bell shape that is characteristic of a normal distribution, but that’s because we are \nworking with such small samples. If the population of {4, 5, 9} were much larger \nand if we were selecting samples much larger than n = 2, as in this example, we \nwould get a probability histogram that is much closer to being bell-shaped, indicat-\ning a normal distribution, as in Example 3.\nINTERPRETATION\nBecause Table 6-3 lists the possible values of the sample mean along with their cor-\nresponding probabilities, Table 6-3 is an example of a sampling distribution of a \nsample mean.\nThe value of the mean of the population {4, 5, 9} is m = 6.0. Using either \nTable 6-2 or 6-3, we could calculate the mean of the sample values and we get 6.0. \nBecause the mean of the sample means (6.0) is equal to the mean of the population \n(6.0), we conclude that the values of the sample mean do target the value of the \npopulation mean. It’s unfortunate that this sounds so much like doublespeak, but \nthis illustrates that the mean of the sample means is equal to the population mean m.\nHINT Read the last sentence of the above paragraph a few times until it makes sense.\nEXAMPLE 3  Sampling Distribution of the Sample Mean\nConsider repeating this process: Roll a die 5 times to randomly select 5 values from \nthe population {1, 2, 3, 4, 5, 6}, then find the mean x of the results. What do we \nknow about the behavior of all sample means that are generated as this process con-\ntinues indefinitely?\nSOLUTION\nFigure 6-19 illustrates a process of rolling a die 5 times and finding the mean of the \nresults. Figure 6-19 shows results from repeating this process 10,000 times, but the true \nsampling distribution of the mean involves repeating the process indefinitely. Because \nthe values of 1, 2, 3, 4, 5, 6 are all equally likely, the population has a mean of m = 3.5. \nThe 10,000 sample means included in Figure 6-19 have a mean of 3.5. If the process \nis continued indefinitely, the mean of the sample means will be 3.5. Also, Figure 6-19 \nshows that the distribution of the sample means is approximately a normal distribution.\nMeans\nSample 1\nSample 2\nSample 3\n(Population Mean is m 5 3.5)\nDistribution of\nSample Means\nSample\nMeans\nSample\nm 5 3.5\nSample means are\napproximately normal\n•\n•\n•\n3.4\n4.4\n2.8\nSampling Procedure:\nRoll a die 5 times and\nﬁnd the mean x for\neach sample.\nFIGURE 6-19 Sample Means from 10,000 Trials\n","page_start":263,"page_end":263,"token_count":677,"section_type":"other","chapter_number":6,"chapter_title":"NORMAL PROBABILITY DISTRIBUTIONS","chunk_index":358}
{"chunk_id":"5bacf7ad9ac690e6","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"246 \nCHAPTER 6 Normal Probability Distributions\nSampling Distribution of the Sample Variance\nLet’s now consider the sampling distribution of sample variances.\nDEFINITION\nThe sampling distribution of the sample variance is the distribution of sample \nvariances (the variable s2), with all samples having the same sample size n taken \nfrom the same population. (The sampling distribution of the sample variance is typi-\ncally represented as a probability distribution in the format of a table, probability \nhistogram, or formula.)\nCAUTION When working with population standard deviations or variances, be \nsure to evaluate them correctly. In Section 3-2 we saw that the computations for \npopulation standard deviations or variances involve division by the population size \nN instead of n - 1, as shown here.\n Population standard deviation:  s = B\nΣ1x - m2 2\nN\n \n Population variance: \n s2 = Σ1x - m2 2\nN\nBecause the calculations are typically performed with software or calculators, be care-\nful to correctly distinguish between the variance of a sample and the variance of a \npopulation.\nBehavior of Sample Variances\n1. The distribution of sample variances tends to be a distribution skewed to the \nright.\n2. The sample variances target the value of the population variance. (That is, \nthe mean of the sample variances is the population variance. The expected \nvalue of the sample variance is equal to the population variance.)\nEXAMPLE 4  Sampling Distribution of the Sample Variance\nConsider repeating this process: Roll a die 5 times and find the variance s2 of the \nresults. What do we know about the behavior of all sample variances that are gener-\nated as this process continues indefinitely?\nSOLUTION\nFigure 6-20 illustrates a process of rolling a die 5 times and finding the variance of \nthe results. Figure 6-20 shows results from repeating this process 10,000 times, but \nthe true sampling distribution of the sample variance involves repeating the process \nindefinitely. Because the values of 1, 2, 3, 4, 5, 6 are all equally likely, the popu-\nlation has a variance of s2 = 2.9, and the 10,000 sample variances included in \nFigure 6-20 have a mean of 2.9. If the process is continued indefinitely, the mean \nof the sample variances will be 2.9. Also, Figure 6-20 shows that the distribution \nof the sample variances is a skewed distribution, not a normal distribution with its \ncharacteristic bell shape.\n","page_start":264,"page_end":264,"token_count":552,"section_type":"other","chapter_number":6,"chapter_title":"NORMAL PROBABILITY DISTRIBUTIONS","chunk_index":359}
{"chunk_id":"ebc67f43c5fa405d","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"6-3 Sampling Distributions and Estimators \n247\nEstimators: Unbiased and Biased\nThe preceding examples show that sample proportions, means, and variances tend to \ntarget the corresponding population parameters. More formally, we say that sample \nproportions, means, and variances are unbiased estimators. See the following two \ndefinitions.\nDEFINITIONS\nAn estimator is a statistic used to infer (or estimate) the value of a population \nparameter.\nAn unbiased estimator is a statistic that targets the value of the corresponding \npopulation parameter in the sense that the sampling distribution of the statistic has \na mean that is equal to the corresponding population parameter.\nUnbiased Estimators These statistics are unbiased estimators. That is, they each \ntarget the value of the corresponding population parameter (with a sampling distribu-\ntion having a mean equal to the population parameter):\n \n■Proportion pn\n \n■Mean x\n \n■Variance s2\nBiased Estimators These statistics are biased estimators. That is, they do not target \nthe value of the corresponding population parameter:\n \n■Median\n \n■Range\n \n■Standard deviation s\nImportant Note: The sample standard deviations do not target the population \nstandard deviation s, but the bias is relatively small in large samples, so  \ns is often used to estimate S even though s is a biased estimator of s.\nVariances\nSample 1\nSample 2\nSample 3\n(Population Variance is s2 5 2.9)\nDistribution of\nSample Variances\nSample\nVariances\nSample\ns2 5 2.9\nSample variances tend to\nhave a skewed distribution\n•\n•\n•\n1.8\n2.3\n2.2\nSampling Procedure:\nRoll a die 5 times and\nﬁnd the variance s2\nfor each sample.\nFIGURE 6-20 Sample Variances from 10,000 Trials\n","page_start":265,"page_end":265,"token_count":399,"section_type":"other","chapter_number":6,"chapter_title":"NORMAL PROBABILITY DISTRIBUTIONS","chunk_index":360}
{"chunk_id":"177abf7cdb9b31c6","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"248 \nCHAPTER 6 Normal Probability Distributions\nb. The last two columns of Table 6-4 list the values of the range along with the \ncorresponding probabilities, so the last two columns constitute a table summa-\nrizing the probability distribution. Table 6-4 therefore describes the sampling \ndistribution of the sample range.\n \nc. The mean of the sample ranges in Table 6-4 is 20>9, or 2.2. The population of \n{4, 5, 9} has a range of 9 - 4 = 5. Because the mean of the sample ranges \n(2.2) is not equal to the population range (5), the sample ranges do not target \nthe value of the population range.\n \nd. Because the sample ranges do not target the population range, the sample \nrange is a biased estimator of the population range.\nINTERPRETATION\nBecause the sample range is a biased estimator of the population range, a sample \nrange should generally not be used to estimate the value of the population range.\nEXAMPLE 5  Sampling Distribution of the Sample Range\nAs in Example 2, consider samples of size n = 2 randomly selected from the \n population {4, 5, 9}.\n \na. List the diﬀerent possible samples along with the probability of each sample, \nthen ﬁnd the range for each sample.\n \nb. Describe the sampling distribution of the sample range in the format of a table \nsummarizing the probability distribution.\n \nc. Based on the results, do the sample ranges target the population range, which \nis 9 - 4 = 5?\n \nd. What do these results indicate about the sample range as an estimator of the \npopulation range?\nSOLUTION\na. In Table 6-4 we list the nine diﬀerent possible samples of size n = 2 selected \nwith replacement from the population {4, 5, 9}. The nine samples are equally \nlikely, so each has probability 1>9. Table 6-4 also shows the range for each of \nthe nine samples.\nTABLE 6-4 Sampling Distribution of Range\nSample\nSample Range\nProbability\n4, 4\n0\n1>9\n4, 5\n1\n1>9\n4, 9\n5\n1>9\n5, 4\n1\n1>9\n5, 5\n0\n1>9\n5, 9\n4\n1>9\n9, 4\n5\n1>9\n9, 5\n4\n1>9\n9, 9\n0\n1>9\n","page_start":266,"page_end":266,"token_count":565,"section_type":"other","chapter_number":6,"chapter_title":"NORMAL PROBABILITY DISTRIBUTIONS","chunk_index":361}
{"chunk_id":"018d124b825b8367","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"6-3 Sampling Distributions and Estimators \n249\nWhy Sample with Replacement? All of the examples in this section involved sam-\npling with replacement. Sampling without replacement would have the very practi-\ncal advantage of avoiding wasteful duplication whenever the same item is selected \nmore than once. Many of the statistical procedures discussed in the following chapters \nare based on the assumption that sampling is conducted with replacement because of \nthese two very important reasons:\n1. When selecting a relatively small sample from a large population, it makes no \nsignificant difference whether we sample with replacement or without replace-\nment.\n2. Sampling with replacement results in independent events that are unaf-\nfected by previous outcomes, and independent events are easier to analyze \nand result in simpler calculations and formulas.\nStatistical Literacy and Critical Thinking\n1. Births There are about 11,000 births each day in the United States, and the proportion of \nboys born in the United States is 0.512. Assume that each day, 100 births are randomly selected \nand the proportion of boys is recorded.\na. What do you know about the mean of the sample proportions?\nb. What do you know about the shape of the distribution of the sample proportions?\n2.  Sampling with Replacement The Orangetown Medical Research Center randomly se-\nlects 100 births in the United States each day, and the proportion of boys is recorded for each \nsample.\na. Do you think the births are randomly selected with replacement or without replacement?\nb. Give two reasons why statistical methods tend to be based on the assumption that sampling \nis conducted with replacement, instead of without replacement.\n3.  Unbiased Estimators Data Set 3 “Births” in Appendix B includes birth weights of \n400 babies. If we compute the values of sample statistics from that sample, which of the \nfollowing statistics are unbiased estimators of the corresponding population parameters: \nsample mean; sample median; sample range; sample variance; sample standard deviation; \nsample proportion?\n4. Sampling Distribution Data Set 3 “Births” in Appendix B includes a sample of birth \nweights. If we explore this sample of 400 birth weights by constructing a histogram and find-\ning the mean and standard deviation, do those results describe the sampling distribution of the \nmean? Why or why not?\n5.  Good Sample? A geneticist is investigating the proportion of boys born in the world \npopulation. Because she is based in China, she obtains sample data from that country. Is the \nresulting sample proportion a good estimator of the population proportion of boys born world-\nwide? Why or why not?\n6. Physicians There are about 900,000 active physicians in the United States, and they have \nannual incomes with a distribution that is skewed instead of being normal. Many different sam-\nples of 40 physicians are randomly selected, and the mean annual income is computed for each \nsample.\na. What is the approximate shape of the distribution of the sample means (uniform, normal, \nskewed, other)?\nb. What value do the sample means target? That is, what is the mean of all such sample means?\n6-3 Basic Skills and Concepts \n","page_start":267,"page_end":267,"token_count":658,"section_type":"other","chapter_number":6,"chapter_title":"NORMAL PROBABILITY DISTRIBUTIONS","chunk_index":362}
{"chunk_id":"d1e2b69e55143940","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"250 \nCHAPTER 6 Normal Probability Distributions\nIn Exercises 7–10, use the same population of {4, 5, 9} that was used in Examples 2 and 5. As in \nExamples 2 and 5, assume that samples of size n = 2 are randomly selected with replacement.\n7. Sampling Distribution of the Sample Variance\na. Find the value of the population variance s2.\nb. Table 6-2 describes the sampling distribution of the sample mean. Construct a similar table \nrepresenting the sampling distribution of the sample variance s2. Then combine values of s2 that \nare the same, as in Table 6-3 (Hint: See Example 2 on page 244 for Tables 6-2 and 6-3, which \ndescribe the sampling distribution of the sample mean.)\nc. Find the mean of the sampling distribution of the sample variance.\nd. Based on the preceding results, is the sample variance an unbiased estimator of the popula-\ntion variance? Why or why not?\n8. Sampling Distribution of the Sample Standard Deviation For the following, round \nresults to three decimal places.\na. Find the value of the population standard deviation s.\nb. Table 6-2 describes the sampling distribution of the sample mean. Construct a similar table \nrepresenting the sampling distribution of the sample standard deviation s. Then combine values \nof s that are the same, as in Table 6-3. (Hint: See Example 2 on page 244 for Tables 6-2 and 6-3, \nwhich describe the sampling distribution of the sample mean.)\nc. Find the mean of the sampling distribution of the sample standard deviation.\nd. Based on the preceding results, is the sample standard deviation an unbiased estimator of the \npopulation standard deviation? Why or why not?\n9. Sampling Distribution of the Sample Median\na. Find the value of the population median.\nb. Table 6-2 describes the sampling distribution of the sample mean. Construct a similar table \nrepresenting the sampling distribution of the sample median. Then combine values of the me-\ndian that are the same, as in Table 6-3. (Hint: See Example 2 on page 244 for Tables 6-2 and \n6-3, which describe the sampling distribution of the sample mean.)\nc. Find the mean of the sampling distribution of the sample median.\nd. Based on the preceding results, is the sample median an unbiased estimator of the popula-\ntion median? Why or why not?\n10. Sampling Distribution of the Sample Proportion \na. For the population, find the proportion of odd numbers.\nb. Table 6-2 describes the sampling distribution of the sample mean. Construct a similar table \nrepresenting the sampling distribution of the sample proportion of odd numbers. Then combine \nvalues of the sample proportion that are the same, as in Table 6-3. (Hint: See Example 2 on \npage 244 for Tables 6-2 and 6-3, which describe the sampling distribution of the sample mean.)\nc. Find the mean of the sampling distribution of the sample proportion of odd numbers.","page_start":268,"page_end":268,"token_count":660,"section_type":"other","chapter_number":6,"chapter_title":"NORMAL PROBABILITY DISTRIBUTIONS","chunk_index":363}
{"chunk_id":"bbcd0468e6cd736d","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"representing the sampling distribution of the sample proportion of odd numbers. Then combine \nvalues of the sample proportion that are the same, as in Table 6-3. (Hint: See Example 2 on \npage 244 for Tables 6-2 and 6-3, which describe the sampling distribution of the sample mean.)\nc. Find the mean of the sampling distribution of the sample proportion of odd numbers.\nd. Based on the preceding results, is the sample proportion an unbiased estimator of the popu-\nlation proportion? Why or why not?\nIn Exercises 11–14, use the population of {34, 36, 41, 51} of the amounts of caffeine  \n(mg , 12 oz) in Coca-Cola Zero, Diet Pepsi, Dr Pepper, and Mellow Yello Zero. Assume that \nrandom samples of size n = 2 are selected with replacement.\n11. Sampling Distribution of the Sample Mean\na. After identifying the 16 different possible samples, find the mean of each sample, then \nconstruct a table representing the sampling distribution of the sample mean. In the table, ","page_start":268,"page_end":268,"token_count":230,"section_type":"other","chapter_number":6,"chapter_title":"NORMAL PROBABILITY DISTRIBUTIONS","chunk_index":364}
{"chunk_id":"29cdfc497f2d20d2","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"6-3 Sampling Distributions and Estimators \n251\ncombine values of the sample mean that are the same. (Hint: See Table 6-3 in Example 2 on \npage 244.)\nb. Compare the mean of the population {34, 36, 41, 51} to the mean of the sampling distribu-\ntion of the sample mean.\nc. Do the sample means target the value of the population mean? In general, do sample means \nmake good estimators of population means? Why or why not?\n12. Sampling Distribution of the Median Repeat Exercise 11 using medians instead of means.\n13. Sampling Distribution of the Range Repeat Exercise 11 using ranges instead of means.\n14. Sampling Distribution of the Variance Repeat Exercise 11 using variances instead \nof means.\n15. Births: Sampling Distribution of Sample Proportion When two births are ran-\ndomly selected, the sample space for genders is bb, bg, gb, and gg (where b = boy and g =\ngirl). Assume that those four outcomes are equally likely. Construct a table that describes the \nsampling distribution of the sample proportion of girls from two births. Does the mean of the \nsample proportions equal the proportion of girls in two births? Does the result suggest that a \nsample proportion is an unbiased estimator of a population proportion?\n16. Births: Sampling Distribution of Sample Proportion For three births, assume that \nthe genders are equally likely. Construct a table that describes the sampling distribution of the \nsample proportion of girls from three births. Does the mean of the sample proportions equal the \nproportion of girls in three births? (Hint: See Exercise 15 for two births.)\n17. MCAT Tests Because they enable efficient procedures for evaluating answers, multiple choice \nquestions are commonly used on standardized tests, such as the MCAT or the GRE Biology test. \nSuch questions typically have five choices, one of which is correct. Assume that you must make \nrandom guesses for two such questions. Assume that both questions have correct answers of “a.”\na. After listing the 25 different possible samples, find the proportion of correct answers in each \nsample; then construct a table that describes the sampling distribution of the sample propor-\ntions of correct responses.\nb. Find the mean of the sampling distribution of the sample proportion.\nc. Is the mean of the sampling distribution [from part (b)] equal to the population proportion of \ncorrect responses? Does the mean of the sampling distribution of proportions always equal the \npopulation proportion?\n18. Hybridization A hybridization experiment begins with four peas having yellow pods and \none pea having a green pod. Two of the peas are randomly selected with replacement from this \npopulation.\na. After identifying the 25 different possible samples, find the proportion of peas with yellow \npods in each of them; then construct a table to describe the sampling distribution of the propor-\ntions of peas with yellow pods.\nb. Find the mean of the sampling distribution.\nc. Is the mean of the sampling distribution [from part (b)] equal to the population proportion of ","page_start":269,"page_end":269,"token_count":642,"section_type":"other","chapter_number":6,"chapter_title":"NORMAL PROBABILITY DISTRIBUTIONS","chunk_index":365}
{"chunk_id":"ebb07029ae923dad","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"one pea having a green pod. Two of the peas are randomly selected with replacement from this \npopulation.\na. After identifying the 25 different possible samples, find the proportion of peas with yellow \npods in each of them; then construct a table to describe the sampling distribution of the propor-\ntions of peas with yellow pods.\nb. Find the mean of the sampling distribution.\nc. Is the mean of the sampling distribution [from part (b)] equal to the population proportion of \npeas with yellow pods? Does the mean of the sampling distribution of proportions always equal \nthe population proportion?\n19. Using a Formula to Describe a Sampling Distribution Exercise 15 “Births” re-\nquires the construction of a table that describes the sampling distribution of the proportions of \ngirls from two births. Consider the formula shown here, and evaluate that formula using sample \n6-3 Beyond the Basics \ncontinued","page_start":269,"page_end":269,"token_count":183,"section_type":"other","chapter_number":6,"chapter_title":"NORMAL PROBABILITY DISTRIBUTIONS","chunk_index":366}
{"chunk_id":"cf47a90033600696","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"252 \nCHAPTER 6 Normal Probability Distributions\nproportions (represented by x) of 0, 0.5, and 1. Based on the results, does the formula describe \nthe sampling distribution? Why or why not?\nP1x2 =\n1\n212 - 2x2!12x2! where x =  0, 0.5, 1\n20. Mean Absolute Deviation Is the mean absolute deviation of a sample a good statistic for \nestimating the mean absolute deviation of the population? Why or why not? (Hint: See Example 5.)\nKey Concept In the preceding section we saw that the sampling distribution of sample \nmeans tends to be a normal distribution as the sample size increases. In this section we \nintroduce and apply the central limit theorem. The central limit theorem allows us to \nuse a normal distribution for some very meaningful and important applications.\n6-4 \nThe Central Limit Theorem\nCENTRAL LIMIT THEOREM\nFor all samples of the same size n with n 7 30, the sampling distribution of x can be \napproximated by a normal distribution with mean m and standard deviation s> 1n.\nGiven any population with any distribution (uniform, skewed, whatever), the dis-\ntribution of sample means x can be approximated by a normal distribution when the \nsamples are large enough with n 7 30. (There are some special cases of very non-\nnormal distributions for which the requirement of n 7 30 isn’t quite enough, so the \nnumber 30 should be higher in those cases, but those cases are relatively rare.)\nEXAMPLE 1  HDL Cholesterol of Females\nFigures 6-21 and 6-22 illustrate the central limit theorem.\n \n■Original data: Figure 6-21 is a histogram of the high-density lipoprotein \n(HDL) cholesterol measures (mg>dL) of the 147 females listed in Data Set \n1 “Body Data” in Appendix B, and those measures have a distribution that is \nskewed to the right instead of being normal.\n \n■Sample means: Figure 6-22 is a histogram of 100 sample means. Each sample \nincludes 100 HDL cholesterol measures of females, and this histogram shows \nthat the sample means have a distribution that is very close to being normal.\nFIGURE 6-21  Nonnormal Distribution: \nHDL Cholesterol from \n147 Women\nFIGURE 6-22  Approximately Normal \nDistribution: Means from \nSamples of Size n = 100 \nof HDL Cholesterol from \nFemales\n","page_start":270,"page_end":270,"token_count":539,"section_type":"other","chapter_number":6,"chapter_title":"NORMAL PROBABILITY DISTRIBUTIONS","chunk_index":367}
{"chunk_id":"ecd5e22de3c96c5c","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"6-4 The Central Limit Theorem \n253\nA Universal Truth Example 1 and the central limit theorem are truly remarkable be-\ncause they describe a rule of nature that works throughout the universe. If we could \nsend a spaceship to a distant planet “in a galaxy far, far away,” and if we collect samples \nof rocks (all of the same large sample size) and weigh them, the sample means would \nhave a distribution that is approximately normal. Think about the significance of that!\nThe following key points form the foundation for estimating population param-\neters and hypothesis testing—topics discussed at length in the following chapters.\nINTERPRETATION\nThe original HDL cholesterol measurements depicted in Figure 6-21 have a skewed \ndistribution, but when we collect samples and compute their means, those sample \nmeans tend to have a distribution that is normal.\nThe Central Limit Theorem and the Sampling Distribution of x\nGiven\n1. Population (with any distribution) has mean m and standard deviation s.\n2. Simple random samples all of the same size n are selected from the population.\nPractical Rules for Real Applications Involving a Sample Mean x\nRequirements: Population has a normal distribution or n + 30:\nMean of all values of x: \n \n  mx = m\nStandard deviation of all values of x: \n \n \nsx =\ns\n1n\nz score conversion of x: \n \n \n  z = x - m\ns\n1n\nOriginal population is not normally distributed and n \" 30: The distribution of x might not be approximated well \nby a normal distribution, and the methods of this section might not apply. Use other methods, such as nonparametric \nmethods or bootstrapping methods (Section 7-4).\nConsiderations for Practical Problem Solving\n1. Check Requirements: When working with the mean from a sample, verify that the normal distribution can be used \nby confirming that the original population has a normal distribution or the sample size is n 7 30.\n2. Individual Value or Mean from a Sample? Determine whether you are using a normal distribution with a single \nvalue x or the mean x from a sample of n values. See the following.\n • Individual value: When working with an individual value from a normally distributed population, use the methods of \nSection 6-2 with z = x - m\ns\n.\n • Mean from a sample of values: When working with a mean for some sample of n values, be sure to use the value of \ns> 1n for the standard deviation of the sample means, so use z = x - m\ns\n1n\n.\nKEY ELEMENTS \n","page_start":271,"page_end":271,"token_count":546,"section_type":"other","chapter_number":6,"chapter_title":"NORMAL PROBABILITY DISTRIBUTIONS","chunk_index":368}
{"chunk_id":"1738d9879b169a11","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"254 \nCHAPTER 6 Normal Probability Distributions\nThe following new notation is used for the mean and standard deviation of the \ndistribution of x.\nNOTATION FOR THE SAMPLING DISTRIBUTION OF x\nIf all possible simple random samples of size n are selected from a population with \nmean m and standard deviation s, the mean of all sample means is denoted by mx \nand the standard deviation of all sample means is denoted by sx.\nMean of all values of x: \nmx = m\nStandard deviation of all values of x: \nsx =\ns\n1n\nNote: sx is called the standard error of  the mean and is sometimes denoted as SEM.\nApplying the Central Limit Theorem\nMany practical problems can be solved with the central limit theorem. Example 2 \nis a good illustration of the central limit theorem because we can see the difference \nbetween working with an individual value in part (a) and working with the mean for \na sample in part (b). Study Example 2 carefully to understand the fundamental differ-\nence between the procedures used in parts (a) and (b). In particular, note that when\nworking with an individual value, we use z = x - m\ns\n, but when working with the \nmean x for a collection of sample values, we use z = x - m\ns> 1n.\nEXAMPLE 2  Pulse Rates of Women\nIn the Chapter Problem it was noted that women have normally distributed pulse \nrates with a mean of 74.0 bpm and a standard deviation of 12.5 bpm.\n \na. Find the probability that 1 randomly selected woman has a pulse rate greater \nthan 80 bpm.\n \nb. Find the probability that a sample of 16 randomly selected women have a \nmean pulse rate greater than 80 bpm.\n \nc. Given that part (b) involves a sample size that is not larger than 30, why can \nthe central limit theorem be used?\nSOLUTION\n \na. Approach Used for an Individual Value: Use the methods presented in \nSection 6-2 because we are dealing with an individual value from a nor-\nmally distributed population. We seek the area of the green-shaded region in \nFigure 6-23(a).\n \n Technology: If using technology (as described at the end of Section 6-2), we \nﬁnd that the green-shaded area in the graph at the left is 0.3156.\n \n Table A-2: If using Table A-2, we convert the pulse rate of 80 bpm to the cor-\nresponding z score, as shown here:\nz = x - m\ns\n= 80 - 74.0\n12.5\n= 0.48\n \n  \nWe refer to Table A-2 to ﬁnd that the cumulative area to the left of z = 0.48 \nis 0.6844, so the green-shaded area in Figure 6-23(a) is 1 - 0.6844 = 0.3156.\n","page_start":272,"page_end":272,"token_count":634,"section_type":"other","chapter_number":6,"chapter_title":"NORMAL PROBABILITY DISTRIBUTIONS","chunk_index":369}
{"chunk_id":"0eeb185c7eb6081a","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"6-4 The Central Limit Theorem \n255\n \nb. Approach Used for the Mean of Sample Values: Use the central limit theo-\nrem because we are dealing with the mean of a sample of 16 women, not an \nindividual woman.\n \n Requirement check for part b We can use the normal distribution if the \noriginal population is normally distributed or n 7 30. The sample size is not \ngreater than 30, but the original population of pulse rates of women has a \nnormal distribution, so samples of any size will yield means that are normally \ndistributed. \n \n  \nBecause we are now dealing with a distribution of sample means, we \nmust use the parameters mx and sx, which are evaluated as follows:\nmx = m = 74.0\nsx =\ns\n1n = 12.5\n116 = 3.125\n \n We want to ﬁnd the green-shaded area shown in Figure 6-23(b).\n \n Technology: If using technology, the green-shaded area in Figure 6-23(b) is \n0.0274.\n \n Table A-2: If using Table A-2, we convert the value of x = 80 bpm to the \ncorresponding z score of z = 1.92, as shown here:\nz = x - mx\nsx\n= 80 - 74.0\n12.5\n116\n=\n6\n3.125 = 1.92\n \n From Table A-2 we ﬁnd that the cumulative area to the left of z = 1.92 is \n0.9726, so the green-shaded area of Figure 6-23(b) is 1 - 0.9726 = 0.0274.\n \nc. Even though the sample size is not greater than 30, we can use the central \nlimit theorem because the population of pulse rates of women is normally \ncontinued\nThe Fuzzy Central  \nLimit Theorem\nIn The Cartoon \nGuide to Statis-\ntics, by Gonick \nand Smith, \nthe authors \ndescribe the \nFuzzy Central \nLimit Theorem as follows: “Data \nthat are influenced by many small \nand unrelated random effects \nare approximately normally \ndistributed. This explains why \nthe normal is everywhere: stock \nmarket fluctuations, student \nweights, yearly temperature \naverages, SAT scores: All are the \nresult of many different effects.” \nPeople’s heights, for example, \nare the results of hereditary \nfactors, environmental factors, \nnutrition, health care, geographic \nregion, and other influences, \nwhich, when combined, produce \nnormally distributed values.\nf ll\n“D\nx 5 80\n(s 5 12.5)\nm 5 74.0\nIndividual women\npulse rates\nMeans of\npulse rates\nfrom samples\nof women\n(16 in each\nsample)\nx 5 80\nmx 5 74.0\n(sx 5 3.125)\nFIGURE 6-23 Female Pulse Rates\n(a)\n(b)\n","page_start":273,"page_end":273,"token_count":637,"section_type":"other","chapter_number":6,"chapter_title":"NORMAL PROBABILITY DISTRIBUTIONS","chunk_index":370}
{"chunk_id":"91854d46843062ed","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"256 \nCHAPTER 6 Normal Probability Distributions\nExample 2 shows that we can use the same basic procedures from Section 6-2, \nbut we must remember to correctly adjust the standard deviation when working with a \nsample mean instead of an individual sample value.\nIntroduction to Hypothesis Testing\nCarefully examine the conclusions that are reached in the next example illustrating \nthe type of thinking that is the basis for the important procedure of hypothesis testing \n(formally introduced in Chapter 8). Example 3 uses the rare event rule for inferential \nstatistics, first presented in Section 4-1:\nIdentifying Significant Results with Probabilities: The Rare Event Rule for \nInferential Statistics\nIf, under a given assumption, the probability of a particular observed \nevent is very small and the observed event occurs signiﬁcantly less than or \nsigniﬁcantly greater than what we typically expect with that assumption, \nwe conclude that the assumption is probably not correct.\nThe following example illustrates the above rare event rule.\n distributed. As noted in the requirement check for part (b), samples of any \nsize will yield means that are normally distributed.\nINTERPRETATION\nThere is a 0.3156 probability that an individual woman will have a pulse rate greater \nthan 80 bpm, and there is a 0.0274 probability that 16 randomly selected women \nwill have pulse rates with a mean greater than 80 bpm.\nEXAMPLE 3  Body Temperatures\nAssume that the population of human body temperatures has a mean of 98.6°F, \nas is commonly believed. Also assume that the population standard deviation is \n0.62°F (based on data from University of Maryland researchers). If a sample of size \nn = 106 is randomly selected, find the probability of getting a mean of 98.2°F or \nlower. (The value of 98.2°F was actually obtained from researchers; see the mid-\nnight temperatures for Day 2 in Data Set 2 “Body Temperatures” in Appendix B.)\nSOLUTION\nWe work under the assumption that the population of human body temperatures has \na mean of 98.6°F. We weren’t given the distribution of the population, but because \nthe sample size n = 106 exceeds 30, we use the central limit theorem and conclude \nthat the distribution of sample means is a normal distribution with these parameters:\n \nmx = m = 98.6 1by assumption2\nsx =\ns\n1n =\n0.62\n1106 = 0.0602197\nFigure 6-24 shows the shaded area (see the tiny left tail of the graph) correspond-\ning to the probability we seek. Having already found the parameters that apply to \nthe distribution shown in Figure 6-24, we can now find the shaded area by using the \nsame procedures developed in Section 6-2.\n","page_start":274,"page_end":274,"token_count":601,"section_type":"other","chapter_number":6,"chapter_title":"NORMAL PROBABILITY DISTRIBUTIONS","chunk_index":371}
{"chunk_id":"5578ad872f64cf04","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"6-4 The Central Limit Theorem \n257\nINTERPRETATION\nThe result shows that if the mean of our body temperatures is really 98.6°F, as we as-\nsumed, then there is an extremely small probability of getting a sample mean of 98.2°F \nor lower when 106 subjects are randomly selected. University of Maryland researchers \ndid obtain such a sample mean, and after confirming that the sample is sound, there are \ntwo feasible explanations: (1) The population mean really is 98.6°F and their sample \nrepresents a chance event that is extremely rare; (2) the population mean is actually lower \nthan the assumed value of 98.6°F and so their sample is typical. Because the probability  \nis so low, it is more reasonable to conclude that the population mean is lower than \n98.6°F. In reality it appears that the true mean body temperature is closer to 98.2°F!\nThis is the type of reasoning used in hypothesis testing, to be introduced in \nChapter 8. For now, we should focus on the use of the central limit theorem for \nfinding the probability of 0.0001, but we should also observe that this theorem will \nbe used later in applying some very important concepts in statistics.\nTechnology: If we use technology to find the shaded area in Figure 6-24, we get \n0.0000000000155, which can be expressed as 0+.\nTable A-2: If we use Table A-2 to find the shaded area in Figure 6-24, we must first \nconvert the score of x = 98.20°F to the corresponding z score:\nz = x - mx\nsx\n= 98.20 - 98.6\n0.0602197\n= -6.64\nReferring to Table A-2 we find that z = -6.64 is off the chart, but for values \nof z below -3.49, we use an area of 0.0001 for the cumulative left area up to \nz = -3.49. We therefore conclude that the shaded region in Figure 6-24 is 0.0001.\n0\nz\nmx 5 98.6\n26.64\nx 5 98.2\n0.0001\nFIGURE 6-24  Means of Body Temperatures from \nSamples of Size n = 106\nCorrection for a Finite Population\nIn applying the central limit theorem, our use of sx = s> 1n assumes that the popula-\ntion has infinitely many members. When we sample with replacement, the population \nis effectively infinite. When sampling without replacement from a finite population, we \nmay need to adjust sx. Here is a common rule of thumb:\nWhen sampling without replacement and the sample size n is greater than \n5% of the ﬁnite population size N (that is, n + 0.05N), adjust the standard \ndeviation of sample means Sx by multiplying it by this ﬁnite population \n correction factor:\nA\nN - n\nN - 1\n","page_start":275,"page_end":275,"token_count":653,"section_type":"other","chapter_number":6,"chapter_title":"NORMAL PROBABILITY DISTRIBUTIONS","chunk_index":372}
{"chunk_id":"638dad56ee9d2e6e","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"258 \nCHAPTER 6 Normal Probability Distributions\nExcept for Exercise 21 “Correcting for a Finite Population,” the examples and exer-\ncises in this section assume that the finite population correction factor does not apply, \nbecause we are sampling with replacement, or the population is infinite, or the sample \nsize doesn’t exceed 5% of the population size.\nStatistical Literacy and Critical Thinking\n1. Requirements A researcher collects a simple random sample of grade-point averages of \nbiostatistics students and she calculates the mean of this sample. Under what conditions can \nthat sample mean be treated as a value from a population having a normal distribution?\n2. Small Sample Weights of adult human brains are normally distributed. Samples of weights \nof adult human brains, each of size n = 15, are randomly collected and the sample means are \nfound. Is it correct to conclude that the sample means cannot be treated as being from a normal \ndistribution because the sample size is too small? Explain.\n3. Notation In general, what do the symbols mx and sx represent? What are the values of mx\nand sx for samples of size 64 randomly selected from the population of IQ scores with popula-\ntion mean of 100 and standard deviation of 15?\n4.  Annual Incomes Annual incomes of physicians are known to have a distribution that is \nskewed to the right instead of being normally distributed. Assume that we collect a large 1n 7 302\nrandom sample of annual incomes of physicians. Can the distribution of those incomes in that \nsample be approximated by a normal distribution because the sample is large? Why or why not?\nUsing the Central Limit Theorem. In Exercises 5–8, assume that females have pulse \nrates that are normally distributed with a mean of 74.0 beats per minute and a standard \n deviation of 12.5 beats per minute (based on Data Set 1 “Body Data” in Appendix B).\n5. a. If 1 adult female is randomly selected, find the probability that her pulse rate is less than \n80 beats per minute.\nb. If 16 adult females are randomly selected, find the probability that they have pulse rates with \na mean less than 80 beats per minute.\nc. Why can the normal distribution be used in part (b), even though the sample size does not \nexceed 30?\n6. a. If 1 adult female is randomly selected, find the probability that her pulse rate is greater \nthan 70 beats per minute.\nb. If 25 adult females are randomly selected, find the probability that they have pulse rates with \na mean greater than 70 beats per minute.\nc. Why can the normal distribution be used in part (b), even though n 6 30?\n7. a. If 1 adult female is randomly selected, find the probability that her pulse rate is between \n72 beats per minute and 76 beats per minute.\nb. If 4 adult females are randomly selected, find the probability that they have pulse rates with \na mean between 72 beats per minute and 76 beats per minute.","page_start":276,"page_end":276,"token_count":647,"section_type":"other","chapter_number":6,"chapter_title":"NORMAL PROBABILITY DISTRIBUTIONS","chunk_index":373}
{"chunk_id":"23600553eb6a092a","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"c. Why can the normal distribution be used in part (b), even though n 6 30?\n7. a. If 1 adult female is randomly selected, find the probability that her pulse rate is between \n72 beats per minute and 76 beats per minute.\nb. If 4 adult females are randomly selected, find the probability that they have pulse rates with \na mean between 72 beats per minute and 76 beats per minute.\nc. Why can the normal distribution be used in part (b), even though the sample size does not \nexceed 30?\n8. a. If 1 adult female is randomly selected, find the probability that her pulse rate is between \n78 beats per minute and 90 beats per minute.\nb. If 16 adult females are randomly selected, find the probability that they have pulse rates with \na mean between 78 beats per minute and 90 beats per minute.\nc. Why can the normal distribution be used in part (b), even though n 6 30?\n6-4 Basic Skills and Concepts","page_start":276,"page_end":276,"token_count":218,"section_type":"other","chapter_number":6,"chapter_title":"NORMAL PROBABILITY DISTRIBUTIONS","chunk_index":374}
{"chunk_id":"173ab44dabe420ca","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"6-4 The Central Limit Theorem \n259\n9. Hemoglobin in Men Hemoglobin levels in adult males are normally distributed with a \nmean of 14.7 g>dL and a standard deviation of 1.3 g>dL (based on data from the National \nHealth and Nutrition Examination Survey).\na. The normal hemoglobin range for men is 13.6 g>dL to 17.7 g>dL. What percentage of men \nhave hemoglobin levels in the normal range?\nb. If we randomly collect samples of men with 9 in each sample, what percentage of those \nsamples have a mean hemoglobin level that is within the normal range?\n10. Hemoglobin in Women Hemoglobin levels in adult females are normally distributed \nwith a mean of 13.0 g>dL and a standard deviation of 1.3 g>dL (based on data from the Na-\ntional Health and Nutrition Examination Survey).\na. The normal hemoglobin range for women is 12.1 g>dL to 15.1 g>dL. What percentage of \nwomen have hemoglobin levels in the normal range?\nb. If we randomly collect samples of women with 9 in each sample, what percentage of those \nsamples have a mean hemoglobin level that is within the normal range?\n11. Diastolic BP in Women Diastolic blood pressure is a measure of the pressure when \narteries rest between heartbeats. Diastolic blood pressure levels in women are normally distrib-\nuted with a mean of 70.2 mm Hg and a standard deviation of 11.2 mm Hg (based on Data Set 1 \n“Body Data” in Appendix B).\na. A diastolic blood pressure level above 90 mm Hg is considered to be hypertension. What \npercentage of women have hypertension?\nb. If we randomly collect samples of women with 4 in each sample, what percentage of those \nsamples have a mean above 90 mm Hg?\n12. Diastolic BP in Men Diastolic blood pressure is a measure of the pressure when arteries \nrest between heartbeats. Diastolic blood pressure levels in men are normally distributed with \na mean of 71.3 mm Hg and a standard deviation of 12.0 mm Hg (based on Data Set 1 “Body \nData” in Appendix B).\na. A diastolic blood pressure level above 90 mm Hg is considered to be hypertension. What \npercentage of men have hypertension?\nb. If we randomly collect samples of men with 4 in each sample, what percentage of those \nsamples have a mean above 90 mm Hg?\n13. Mensa Membership in Mensa requires a score in the top 2% on a standard intelligence \ntest. The Wechsler IQ test is designed for a mean of 100 and a standard deviation of 15, and \nscores are normally distributed.\na. Find the minimum Wechsler IQ test score that satisfies the Mensa requirement.\nb. If 4 randomly selected adults take the Wechsler IQ test, find the probability that their mean \nscore is at least 131.","page_start":277,"page_end":277,"token_count":659,"section_type":"other","chapter_number":6,"chapter_title":"NORMAL PROBABILITY DISTRIBUTIONS","chunk_index":375}
{"chunk_id":"a23c37c029c7e01c","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"test. The Wechsler IQ test is designed for a mean of 100 and a standard deviation of 15, and \nscores are normally distributed.\na. Find the minimum Wechsler IQ test score that satisfies the Mensa requirement.\nb. If 4 randomly selected adults take the Wechsler IQ test, find the probability that their mean \nscore is at least 131.\nc. If 4 subjects take the Wechsler IQ test and they have a mean of 132, but the individual scores \nare lost, can we conclude that all 4 of them are eligible for Mensa?\n14. Sleep The amounts of times that adults sleep are normally distributed with a mean of \n6.8 hours and a standard deviation of 1.4 hours (based on data from multiple sources, includ-\ning a Gallup poll and the American Journal of Epidemiology). A common recommendation is \nthat we get between 7 and 9 hours of sleep each night.\na. For someone randomly selected, find the probability that they get between 7 and 9 hours of \nsleep in a night.\nb. If we randomly collect a sample of 5 adults, what is the probability that the sample mean is \nbetween 7 hours and 9 hours?","page_start":277,"page_end":277,"token_count":258,"section_type":"other","chapter_number":6,"chapter_title":"NORMAL PROBABILITY DISTRIBUTIONS","chunk_index":376}
{"chunk_id":"abb5863d5122d7f1","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"260 \nCHAPTER 6 Normal Probability Distributions\nErgonomics. Exercises 15–20 involve applications of ergonomics, which is a discipline \nfocused on the design of tools and equipment so that they can be used safely, comfortably, \nand efficiently.\n15. Water Taxi Safety Passengers died when a water taxi sank in Baltimore’s Inner Harbor. \nMen are typically heavier than women and children, so when loading a water taxi, assume a \nworst-case scenario in which all passengers are men. Assume that weights of men are normally \ndistributed with a mean of 189 lb and a standard deviation of 39 lb (based on Data Set 1 “Body \nData” in Appendix B). The water taxi that sank had a stated capacity of 25 passengers, and the \nboat was rated for a load limit of 3500 lb.\na. Given that the water taxi that sank was rated for a load limit of 3500 lb, what is the maxi-\nmum mean weight of the passengers if the boat is filled to the stated capacity of 25 passengers?\nb. If the water taxi is filled with 25 randomly selected men, what is the probability that their \nmean weight exceeds the value from part (a)?\nc. After the water taxi sank, the weight assumptions were revised so that the new capacity be-\ncame 20 passengers. If the water taxi is filled with 20 randomly selected men, what is the prob-\nability that their mean weight exceeds 175 lb, which is the maximum mean weight that does \nnot cause the total load to exceed 3500 lb?\nd. Is the new capacity of 20 passengers safe?\n16. Designing Manholes According to the website www.torchmate.com, “manhole covers \nmust be a minimum of 22 in. in diameter, but can be as much as 60 in. in diameter.” Assume \nthat a manhole is constructed to have a circular opening with a diameter of 22 in. Men have \nshoulder breadths that are normally distributed with a mean of 18.2 in. and a standard deviation \nof 1.0 in. (based on data from the National Health and Nutrition Examination Survey).\na. What percentage of men will fit into the manhole?\nb. Assume that Connecticut’s Eversource company employs 36 men who work in manholes. If \n36 men are randomly selected, what is the probability that their mean shoulder breadth is less \nthan 18.5 in.? Does this result suggest that money can be saved by making smaller manholes \nwith a diameter of 18.5 in.? Why or why not?\n17. Southwest Airlines Seats Southwest Airlines currently has a seat width of 17 in. Men \nhave hip breadths that are normally distributed with a mean of 14.4 in. and a standard deviation \nof 1.0 in. (based on anthropometric survey data from Gordon, Churchill, et al.).\na. Find the probability that if an individual man is randomly selected, his hip breadth will be \ngreater than 17 in.\nb. Southwest Airlines uses a Boeing 737 for some of its flights, and that aircraft seats 122 pas-","page_start":278,"page_end":278,"token_count":660,"section_type":"other","chapter_number":6,"chapter_title":"NORMAL PROBABILITY DISTRIBUTIONS","chunk_index":377}
{"chunk_id":"b27462ba2decb18d","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"have hip breadths that are normally distributed with a mean of 14.4 in. and a standard deviation \nof 1.0 in. (based on anthropometric survey data from Gordon, Churchill, et al.).\na. Find the probability that if an individual man is randomly selected, his hip breadth will be \ngreater than 17 in.\nb. Southwest Airlines uses a Boeing 737 for some of its flights, and that aircraft seats 122 pas-\nsengers. If the plane is full with 122 randomly selected men, find the probability that these men \nhave a mean hip breadth greater than 17 in.\nc. Which result should be considered for any changes in seat design: the result from part (a) or \npart (b)?\n18. Redesign of Ejection Seats When women were finally allowed to become pilots of \nfighter jets, engineers needed to redesign the ejection seats because they had been originally \ndesigned for men only. The ACES-II ejection seats were designed for men weighing between \n140 lb and 211 lb. Weights of women are now normally distributed with a mean of 171 lb and a \nstandard deviation of 46 lb (based on Data Set 1 “Body Data” in Appendix B).\na. If 1 woman is randomly selected, find the probability that her weight is between 140 lb and \n211 lb.\nb. If 25 different women are randomly selected, find the probability that their mean weight is \nbetween 140 lb and 211 lb.\nc. When redesigning the fighter jet ejection seats to better accommodate women, which \n probability is more relevant: the result from part (a) or the result from part (b)? Why?","page_start":278,"page_end":278,"token_count":352,"section_type":"other","chapter_number":6,"chapter_title":"NORMAL PROBABILITY DISTRIBUTIONS","chunk_index":378}
{"chunk_id":"a8ff75397bd8f2fe","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"6-5 Assessing Normality \n261\n19. Doorway Height The Boeing 757-200 ER airliner carries 200 passengers and has doors \nwith a height of 72 in. Heights of men are normally distributed with a mean of 68.6 in. and a \nstandard deviation of 2.8 in. (based on Data Set 1 “Body Data” in Appendix B).\na. If a male passenger is randomly selected, find the probability that he can fit through the \ndoorway without bending.\nb. If half of the 200 passengers are men, find the probability that the mean height of the 100 men \nis less than 72 in.\nc. When considering the comfort and safety of passengers, which result is more relevant: the \nprobability from part (a) or the probability from part (b)? Why?\nd. When considering the comfort and safety of passengers, why are women ignored in this \ncase?\n20. Loading Aircraft Before every flight, the pilot must verify that the total weight of the \nload is less than the maximum allowable load for the aircraft. The Bombardier Dash 8 aircraft \ncan carry 37 passengers, and a flight has fuel and baggage that allows for a total passenger load \nof 6200 lb. The pilot sees that the plane is full and all passengers are men. The aircraft will be \noverloaded if the mean weight of the passengers is greater than 6200 lb>37 = 167.6 lb. What is \nthe probability that the aircraft is overloaded? Should the pilot take any action to correct for an \noverloaded aircraft? Assume that weights of men are normally distributed with a mean of 189 lb \nand a standard deviation of 39 lb (based on Data Set 1 “Body Data” in Appendix B).\n21. Correcting for a Finite Population In a study of babies born with very low birth weights, \n275 children were given IQ tests at age 8, and their scores approximated a normal distribution \nwith m = 95.5 and s = 16.0 (based on data from “Neurobehavioral Outcomes of School-Age \nChildren Born Extremely Low Birth Weight or Very Preterm,” by Anderson et al., Journal of \nthe American Medical Association, Vol. 289, No. 24). Fifty of those children are to be ran-\ndomly selected without replacement for a follow-up study.\na. When considering the distribution of the mean IQ scores for samples of 50 children, should \nsx be corrected by using the finite population correction factor? Why or why not? What is the \nvalue of sx?\nb. Find the probability that the mean IQ score of the follow-up sample is between 95 and 105.\n6-4 Beyond the Basics\nKey Concept The following chapters include important statistical methods requiring \nthat sample data are from a population having a normal distribution. In this section we \npresent criteria for determining whether the requirement of a normal distribution is \nsatisfied. The criteria involve (1) visual inspection of a histogram to see if it is roughly \nbell-shaped; (2) identifying any outliers; and (3) constructing a normal quantile plot.\nPART 1","page_start":279,"page_end":279,"token_count":659,"section_type":"other","chapter_number":6,"chapter_title":"NORMAL PROBABILITY DISTRIBUTIONS","chunk_index":379}
{"chunk_id":"481c24a3841be4d9","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"6-4 Beyond the Basics\nKey Concept The following chapters include important statistical methods requiring \nthat sample data are from a population having a normal distribution. In this section we \npresent criteria for determining whether the requirement of a normal distribution is \nsatisfied. The criteria involve (1) visual inspection of a histogram to see if it is roughly \nbell-shaped; (2) identifying any outliers; and (3) constructing a normal quantile plot.\nPART 1\nBasic Concepts of Assessing Normality\nWhen trying to determine whether a collection of data has a distribution that is \napproximately normal, we can visually inspect a histogram to see if it is approxi-\nmately bell-shaped (as discussed in Section 2-2), we can identify outliers, and we can \nalso use a normal quantile plot (discussed briefly in Section 2-2).\n6-5 \nAssessing Normality","page_start":279,"page_end":279,"token_count":184,"section_type":"other","chapter_number":6,"chapter_title":"NORMAL PROBABILITY DISTRIBUTIONS","chunk_index":380}
{"chunk_id":"f7d7ec5c4f7f2fbc","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"262 \nCHAPTER 6 Normal Probability Distributions\nProcedure for Determining Whether It Is Reasonable to Assume That Sample \nData Are from a Population Having a Normal Distribution\n1. Histogram: Construct a histogram. If the histogram departs dramatically from a \nbell shape, conclude that the data do not have a normal distribution.\n2. Outliers: Identify outliers. If there is more than one outlier present, conclude \nthat the data might not have a normal distribution. (Just one outlier could be an \nerror or the result of chance variation, but be careful, because even a single out-\nlier can have a dramatic effect on results.)\n3. Normal quantile plot: If the histogram is basically symmetric and the num-\nber of outliers is 0 or 1, use technology to generate a normal quantile plot. \nApply the following criteria to determine whether the distribution is nor-\nmal. (These criteria can be used loosely for small samples, but they should \nbe used more strictly for large samples.)\n Normal Distribution: The population distribution is normal if the pattern of \nthe points is reasonably close to a straight line and the points do not show some \nsystematic pattern that is not a straight-line pattern.\n Not a Normal Distribution: The population distribution is not normal if either \nor both of these two conditions apply:\n • The points do not lie reasonably close to a straight line.\n • The points show some systematic pattern that is not a straight-line pattern.\nHistograms and Normal Quantile Plots\nIn Part 2 of this section we describe the process of constructing a normal quantile plot, \nbut for now we focus on interpreting a normal quantile plot. The following displays \nshow histograms of data along with the corresponding normal quantile plots.\nNormal: The first case shows a histogram of IQ scores that is close to being bell-\nshaped, so the histogram suggests that the IQ scores are from a normal distribution. \nThe corresponding normal quantile plot shows points that are reasonably close to a \nstraight-line pattern, and the points do not show any other systematic pattern that is \nnot a straight line. It is safe to assume that these IQ scores are from a population that \nhas a normal distribution.\nDEFINITION\nA normal quantile plot (or normal probability plot) is a graph of points (x, y) \nwhere each x value is from the original set of sample data, and each y value is the \ncorresponding z score that is expected from the standard normal distribution.\n","page_start":280,"page_end":280,"token_count":507,"section_type":"other","chapter_number":6,"chapter_title":"NORMAL PROBABILITY DISTRIBUTIONS","chunk_index":381}
{"chunk_id":"7a18193d152aefc7","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"6-5 Assessing Normality \n263\nUniform: The second case shows a histogram of data having a uniform (flat) distribu-\ntion. The corresponding normal quantile plot suggests that the data are not normally \ndistributed. Although the pattern of points is reasonably close to a straight-line pattern, \nthere is another systematic pattern that is not a straight-line pattern. We conclude that \nthese sample values are from a population having a distribution that is not normal.\nSkewed: The third case shows a histogram of the HDL cholesterol measurements. \nThe shape of the histogram is skewed to the right. The corresponding normal quantile \nplot shows points that are not close to a straight-line pattern. These HDL cholesterol \nmeasurements are from a population having a distribution that is not normal.\nTools for Determining Normality\n \n■Histogram, Outliers: If the requirement of a normal distribution is not too \nstrict, simply look at a histogram and find the number of outliers. If the histo-\ngram is roughly bell-shaped and the number of outliers is 0 or 1, treat the popula-\ntion as if it has a normal distribution.\n \n■Normal Quantile Plot: Normal quantile plots can be difficult to construct on \nyour own, but they can be generated with suitable technology.\n \n■Advanced Methods: In addition to the procedures discussed in this section, \nthere are other more advanced procedures for assessing normality, such as the \nchi-square goodness-of-fit test, the Lilliefors test, the Anderson-Darling test, the \nJarque-Bera test, and the Ryan-Joiner test (discussed briefly in Part 2).\nPART 2\nManual Construction of Normal  \nQuantile Plots\nThe following is a relatively simple procedure for manually constructing a normal \nquantile plot, and it is the same procedure used by Statdisk and the TI-83>84 Plus cal-\nculator. Some statistical packages use various other approaches, but the interpretation \nof the graph is essentially the same.\nu-\ny\nn,\nat \nThe Placebo Effect\nIt has long been \nbelieved that \nplacebos actu-\nally help some \npatients. In fact, \nsome formal \nstudies have \nshown that when given a placebo \n(a treatment with no medicinal \nvalue), many test subjects show \nsome improvement. Estimates of \nimprovement rates have typically \nranged between one-third and \ntwo-thirds of patients. However, \na more recent study suggests \nthat placebos have no real ef-\nfect. An article in New England \nJournal of Medicine (Vol. 334, \nNo. 21) was based on research \nof 114 medical studies over \n50 years. The authors of the \narticle concluded that placebos \nappear to have some effect only \nfor relieving pain, but not for \nother physical conditions. They \nconcluded that apart from clinical \ntrials, the use of placebos “can-\nnot be recommended.”\n","page_start":281,"page_end":281,"token_count":611,"section_type":"other","chapter_number":6,"chapter_title":"NORMAL PROBABILITY DISTRIBUTIONS","chunk_index":382}
{"chunk_id":"58846c277b6e56c0","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"264 \nCHAPTER 6 Normal Probability Distributions\nManual Construction of a Normal Quantile Plot\nStep 1: First sort the data by arranging the values in order from lowest to highest.\nStep 2:  With a sample of size n, each value represents a proportion of 1>n of the \nsample. Using the known sample size n, find the values of 1\n2n, 3\n2n, 5\n2n, and so \non, until you get n values. These values are the cumulative areas to the left \nof the corresponding sample values.\nStep 3:  Use the standard normal distribution (software or a calculator or Table A-2) \nto find the z scores corresponding to the cumulative left areas found in Step 2. \n(These are the z scores that are expected from a normally distributed sample.)\nStep 4:  Match the original sorted data values with their corresponding z scores \nfound in Step 3; then plot the points (x, y), where each x is an original sam-\nple value and y is the corresponding z score.\nStep 5:  Examine the normal quantile plot and use the criteria given in Part 1. Con-\nclude that the population has a normal distribution if the pattern of the \npoints is reasonably close to a straight line and the points do not show some \nsystematic pattern that is not a straight-line pattern.\nEXAMPLE 1  Platelet Counts\nConsider this sample of five patient platelet counts (1000 cells>mL): 125, 229, 236, \n257, 234. With only five values, a histogram will not be very helpful in revealing the \ndistribution of the data. Instead, construct a normal quantile plot for these five val-\nues and determine whether they appear to come from a population that is normally \ndistributed.\nSOLUTION\nThe following steps correspond to those listed in the procedure above for construct-\ning a normal quantile plot.\nStep 1: First, sort the data by arranging them in order. We get 125, 229, 234, \n236, 257.\nStep 2: With a sample of size n = 5, each value represents a proportion of 1>5 \nof the sample, so we proceed to identify the cumulative areas to the left of the \ncorresponding sample values. The cumulative left areas, which are expressed in \ngeneral as 1\n2n, 3\n2n, 5\n2n, and so on, become these specific areas for this example with \nn = 5: 1\n10, 3\n10, 5\n10, 7\n10, 9\n10. These cumulative left areas expressed in decimal form are 0.1, \n0.3, 0.5, 0.7, and 0.9.\nStep 3: We now use technology (or Table A-2) with the cumulative left areas of \n0.1000, 0.3000, 0.5000, 0.7000, and 0.9000 to find these corresponding z scores: ","page_start":282,"page_end":282,"token_count":653,"section_type":"other","chapter_number":7,"chapter_title":"ESTIMATING PARAMETERS AND DETERMINING SAMPLE SIZES","chunk_index":383}
{"chunk_id":"e04253944abed5a9","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"10, 9\n10. These cumulative left areas expressed in decimal form are 0.1, \n0.3, 0.5, 0.7, and 0.9.\nStep 3: We now use technology (or Table A-2) with the cumulative left areas of \n0.1000, 0.3000, 0.5000, 0.7000, and 0.9000 to find these corresponding z scores: \n-1.28, -0.52, 0, 0.52, and 1.28. (For example, the z score of -1.28 has an area of \n0.1000 to its left.)\nStep 4: We now pair the original sorted platelet counts with their corresponding \nz scores. We get these (x, y) coordinates, which are plotted in the following  \nStatdisk display:\n1125, -1.282, 1229, -0.522, 1234, 02, 1236, 0.522, 1257, 1.282","page_start":282,"page_end":282,"token_count":233,"section_type":"other","chapter_number":7,"chapter_title":"ESTIMATING PARAMETERS AND DETERMINING SAMPLE SIZES","chunk_index":384}
{"chunk_id":"236c1d82e36c9e3a","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"6-5 Assessing Normality \n265\nRyan-Joiner Test The Ryan-Joiner test is one of several formal tests of normality, \neach having its own advantages and disadvantages. Statdisk has a feature of Normal-\nity Assessment that displays a histogram, normal quantile plot, the number of poten-\ntial outliers, and results from the Ryan-Joiner test.\n Statdisk\nINTERPRETATION\nWe examine the normal quantile plot in the Statdisk display. The points do not ap-\npear to lie reasonably close to the straight line, so we conclude that the sample of \nfive platelet counts does not appear to be from a normally distributed population.\nEXAMPLE 2  Platelet Counts \nExample 1 used a sample of five platelet counts. We can use the Normality Assess-\nment feature of Statdisk with a different sample of the 300 platelet counts listed in \nData Set 1 “Body Data” in Appendix B.\nStatdisk\ncontinued\n","page_start":283,"page_end":283,"token_count":204,"section_type":"other","chapter_number":7,"chapter_title":"ESTIMATING PARAMETERS AND DETERMINING SAMPLE SIZES","chunk_index":385}
{"chunk_id":"6b8301568ca450e3","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"266 \nCHAPTER 6 Normal Probability Distributions\nData Transformations Many data sets have a distribution that is not normal, but \nwe can transform the data so that the modified values have a normal distribution. One \ncommon transformation is to transform each value of x by taking its logarithm. (You \ncan use natural logarithms or logarithms with base 10. If any original values are 0, \ntake logarithms of values of x + 1). If the distribution of the logarithms of the values \nis a normal distribution, the distribution of the original values is called a lognormal \ndistribution. (See Exercises 19 “Transformations” and 20 “Lognormal Distribu-\ntion”.) In addition to transformations with logarithms, there are other transformations, \nsuch as replacing each x value with 1x, or 1>x, or x2. In addition to getting a required \nnormal distribution when the original data values are not normally distributed, such \ntransformations can be used to correct deficiencies, such as a requirement (found in \nlater chapters) that different data sets have the same variance.\nLet’s use the display with the three criteria for assessing normality.\n1. Histogram: We can see that the histogram is skewed to the left instead of  \nbeing bell-shaped.\n2. Outliers: The display shows that there are 20 possible outliers. If we examine \na sorted list of the 300 platelet counts, there are platelet counts that appear to \nbe outliers.\n3. Normal quantile plot: The points in the normal quantile plot do not ﬁt a \nstraight-line pattern very well. We conclude that the 300 platelet counts do not \nappear to be from a population with a normal distribution.\nNormal Quantile Plots\nAccess tech instructions, videos, and data sets at www.TriolaStats.com\nTECH CENTER \nStatistical Literacy and Critical Thinking\n1. Normal Quantile Plot Data Set 1 “Body Data” in Appendix B includes the heights of 147 \nrandomly selected women, and heights of women are normally distributed. If you were to con-\nstruct a histogram of the 147 heights of women in Data Set 1, what shape do you expect the \nhistogram to have? If you were to construct a normal quantile plot of those same heights, what \npattern would you expect to see in the graph?\n2. Normal Quantile Plot After constructing a histogram of the ages of the 147 women in-\ncluded in Data Set 1 “Body Data” in Appendix B, you see that the histogram is far from being \nbell-shaped. What do you now know about the pattern of points in the normal quantile plot?\n3. Small Sample An article includes elapsed times (hours) to lumbar puncture for 19 patients \nwho entered emergency rooms with sudden and severe “thunderclap” headaches (based on data \nfrom “Thunderclap Headache and Normal Computed Tomographic Results: Value of Cerebro-\nspinal Fluid Analysis,” by DuPont et al., Mayo Clinic Proceedings, Vol. 83, No. 12). Given ","page_start":284,"page_end":284,"token_count":649,"section_type":"other","chapter_number":7,"chapter_title":"ESTIMATING PARAMETERS AND DETERMINING SAMPLE SIZES","chunk_index":386}
{"chunk_id":"658a88ae24b7f161","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"3. Small Sample An article includes elapsed times (hours) to lumbar puncture for 19 patients \nwho entered emergency rooms with sudden and severe “thunderclap” headaches (based on data \nfrom “Thunderclap Headache and Normal Computed Tomographic Results: Value of Cerebro-\nspinal Fluid Analysis,” by DuPont et al., Mayo Clinic Proceedings, Vol. 83, No. 12). Given \nthat the sample size is less than 30, what requirement must be met in order to treat the sample \nmean as a value from a normally distributed population? Identify three tools for verifying that \nrequirement.\n6-5 Basic Skills and Concepts ","page_start":284,"page_end":284,"token_count":141,"section_type":"other","chapter_number":7,"chapter_title":"ESTIMATING PARAMETERS AND DETERMINING SAMPLE SIZES","chunk_index":387}
{"chunk_id":"b9924312fef47b4b","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"6-5 Assessing Normality \n267\n4. Assessing Normality The accompanying histogram is constructed from the diastolic blood \npressure measurements of the 147 women included in Data Set 1 “Body Data” in  Appendix B. If \nyou plan to conduct further statistical tests and there is a loose requirement of a normally distrib-\nuted population, what do you conclude about the population distribution based on this histogram?\n Minitab\nInterpreting Normal Quantile Plots. In Exercises 5–8, examine the normal quantile \nplot and determine whether the sample data appear to be from a population with a normal \ndistribution.\n5. Head Lengths of Bears The normal quantile plot represents the head lengths (in.) of \nbears listed in Data Set 11 “Bear Measurements.”\n6. Diet Pepsi The normal quantile plot represents weights (pounds) of the contents of cans of \nDiet Pepsi.\n7. Patient Service Times The normal quantile plot represents service times (minutes) of \nrandomly selected patients.\n","page_start":285,"page_end":285,"token_count":219,"section_type":"other","chapter_number":7,"chapter_title":"ESTIMATING PARAMETERS AND DETERMINING SAMPLE SIZES","chunk_index":388}
{"chunk_id":"4c02973c7fcc720b","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"268 \nCHAPTER 6 Normal Probability Distributions\n8. Visual Acuity Data Set 5 “Vision” includes measures of visual acuity. Shown here is the nor-\nmal quantile plot resulting from the listed measurements from the right eye of the 300 subjects.\nDetermining Normality. In Exercises 9–12, refer to the indicated sample data and deter-\nmine whether they appear to be from a population with a normal distribution. Assume that \nthis requirement is loose in the sense that the population distribution need not be exactly \nnormal, but it must be a distribution that is roughly bell-shaped.\n9. Irises The petal lengths of irises, as listed in Data Set 16 “Iris Measurements” in Appendix B.\n10. Births The lengths of stay (days) of newborn babies, as listed in Data Set 3 “Births” in \nAppendix B.\n11. Cuckoo Egg Lengths The lengths of cuckoo eggs in wren nests, as listed in Data Set 17 \n“Cuckoo Egg Lengths” in Appendix B.\n12. Bears The neck sizes of bears, as listed in Data Set 11 “Bear Measurements” in Appendix B.\nUsing Technology to Generate Normal Quantile Plots. In Exercises 13–16, use tech-\nnology to generate a normal quantile plot. Then determine whether the data come from a \nnormally distributed population.\n13.  Birth weights from Data Set 3 “Births” in Appendix B.\n14.  Lengths of stay from Data Set 3 “Births” in Appendix B.\n15.  White blood cell counts of females from Data Set 1 “Body Data” in Appendix B.\n16.  Red blood cell counts of females from Data Set 1 “Body Data” in Appendix B.\nConstructing Normal Quantile Plots. In Exercises 17 and 18, use the given data values to \nidentify the corresponding z scores that are used for a normal quantile plot; then identify the \ncoordinates of each point in the normal quantile plot. Construct the normal quantile plot, then \ndetermine whether the sample data appear to be from a population with a normal distribution.\n17. Female Arm Circumferences A sample of arm circumferences (cm) of females from \nData Set 1 “Body Data” in Appendix B: 40.7, 44.3, 34.2, 32.5, 38.5.\n18. Brain Volumes A sample of human brain volumes (cm3) is obtained from those listed \nin Data Set 9 “IQ and Brain Size” from Appendix B: 1272, 1051, 1079, 1034, 1070, 1173, \n1079, 1067.\n19. Transformations The heights (in inches) of men listed in Data Set 1 “Body Data” in \n Appendix B have a distribution that is approximately normal, so it appears that those heights \nare from a normally distributed population.\n6-5 Beyond the Basics \ncontinued\n","page_start":286,"page_end":286,"token_count":640,"section_type":"other","chapter_number":7,"chapter_title":"ESTIMATING PARAMETERS AND DETERMINING SAMPLE SIZES","chunk_index":389}
{"chunk_id":"810a65912e526f30","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"6-6 Normal as Approximation to Binomial \n269\na. If 2 inches is added to each height, are the new heights also normally distributed?\nb. If each height is converted from inches to centimeters, are the heights in centimeters also \nnormally distributed?\nc. Are the logarithms of normally distributed heights also normally distributed?\n20. Lognormal Distribution The following are costs (dollars) of treating patients. Test these \nvalues for normality, then take the logarithm of each value and test for normality. What do you \nconclude?\n237,592 160,680 153,500 117,120 7304 6037 4483 4367 2658 1361 311\nKey Concept Section 5-2 introduced binomial probability distributions, and this sec-\ntion presents a method for using a normal distribution as an approximation to a bi-\nnomial probability distribution, so that some problems involving proportions can be \nsolved by using a normal distribution. Here are the two main points of this section:\n \n■Given probabilities p and q (where q = 1 - p) and sample size n, if the condi-\ntions np Ú 5 and nq Ú 5 are both satisfied, then probabilities from a binomial \nprobability distribution can be approximated reasonably well by using a normal \ndistribution having these parameters:\n m = np\n s = 1npq.\n \n■The binomial probability distribution is discrete (with whole numbers for the \nrandom variable x), but the normal approximation is continuous. To compensate, \nwe use a “continuity correction” with a whole number x represented by the inter-\nval from x - 0.5 to x + 0.5.\nBrief Review of Binomial Probability Distribution In Section 5-2 we saw that \na binomial probability distribution has (1) a fixed number of trials; (2) trials that are \nindependent; (3) trials that are each classified into two categories commonly referred \nto as success and failure; and (4) trials with the property that the probability of success \nremains constant. Section 5-2 also introduced the following notation.\nNotation\nn = the ﬁxed number of trials\nx = the specific number of successes in n trials\np = probability of success in one of the n trials\nq = probability of failure in one of the n trials (so q = 1 - p)\nRationale for Using a Normal Approximation We saw in Section 6-3 that the \nsampling distribution of a sample proportion tends to approximate a normal distribu-\ntion. Also, see the probability histogram on the next page for the binomial distribution \nwith n = 580 and p = 0.25. (In one of Mendel’s famous hybridization experiments, \nhe expected 25% of his 580 peas to be yellow.) The bell shape of this graph suggests \nthat we can use a normal distribution to approximate the binomial distribution.\n6-6 \nNormal as Approximation to Binomial\n","page_start":287,"page_end":287,"token_count":634,"section_type":"other","chapter_number":7,"chapter_title":"ESTIMATING PARAMETERS AND DETERMINING SAMPLE SIZES","chunk_index":390}
{"chunk_id":"c80ecfad1fab73ff","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"270 \nCHAPTER 6 Normal Probability Distributions\n Minitab\nNormal Distribution as an Approximation to the Binomial Distribution\nRequirements\n1. The sample is a simple random sample of size n from a population in which the proportion of successes is p, or the \nsample is the result of conducting n independent trials of a binomial experiment in which the probability of success is p.\n2. np Ú 5 and nq Ú 5.\n(The requirements of np Ú 5 and nq Ú 5 are common, but some recommend using 10 instead of 5.)\nNormal Approximation\nIf the above requirements are satisfied, then the probability distribution of the random variable x can be approximated by \na normal distribution with these parameters:\n • m = np\n • s = 1npq\nContinuity Correction\nWhen using the normal approximation, adjust the discrete whole number x by using a continuity correction so that any \nindividual value x is represented in the normal distribution by the interval from x - 0.5 to x + 0.5.\nKEY ELEMENTS \nProcedure for Using a Normal Distribution to Approximate a  \nBinomial Distribution\n1. Check the requirements that np Ú 5 and nq Ú 5.\n2. Find m = np and s = 1npq to be used for the normal distribution.\n3. Identify the discrete whole number x that is relevant to the binomial probability \nproblem being considered, and represent that value by the region bounded by \nx - 0.5 and x + 0.5.\n4. Graph the normal distribution and shade the desired area bounded by \nx - 0.5 or x + 0.5 as appropriate.\nEXAMPLE 1  Was Mendel Wrong? \nIn one of Mendel’s famous hybridization experiments, he expected that among 580 \noffspring peas, 145 of them (or 25%) would be yellow, but he actually got 152 yellow \npeas. Assuming that Mendel’s rate of 25% is correct, find the probability of  \n","page_start":288,"page_end":288,"token_count":428,"section_type":"other","chapter_number":7,"chapter_title":"ESTIMATING PARAMETERS AND DETERMINING SAMPLE SIZES","chunk_index":391}
{"chunk_id":"e5636c22e77ae2fa","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"6-6 Normal as Approximation to Binomial \n271\n(s 5 10.4283)\n151.5\nm 5 145\nArea 5 0.2665\nProbability\nNormal\nBinomial\n151.5\n152.5\n0.00\n0.01\n0.02\n0.03\n0.04\nFIGURE 6-25 Number of Yellow Peas Among 580\ngetting 152 or more yellow peas by random chance. That is, given n = 580 and \np = 0.25, find P(at least 152 yellow peas). Is 152 yellow peas significantly high?\nSOLUTION\nStep 1: Requirement check: With n = 580 and p = 0.25, we get np =  \n(580)(0.25) = 145 and nq = (580)(0.75) = 435, so the requirements that  \nnp Ú 5 and nq Ú 5 are both satisfied.\nStep 2: We now find m and s needed for the normal distribution:\nm = np = 580 # 0.25 = 145\ns = 1npq = 2580 # 0.25 # 0.75 = 10.4283\nStep 3: We want the probability of at least 152 yellow peas, so the discrete whole \nnumber relevant to this example is x = 152. We use the continuity correction as \nwe represent the discrete value of 152 in the graph of the normal distribution by the \ninterval between 151.5 and 152.5 (as shown in the top portion of Figure 6-25).\nStep 4: See the bottom portion of Figure 6-25, which shows the normal distribution \nand the area to the right of 151.5 (representing “152 or more” yellow peas).\ncontinued\n","page_start":289,"page_end":289,"token_count":395,"section_type":"other","chapter_number":7,"chapter_title":"ESTIMATING PARAMETERS AND DETERMINING SAMPLE SIZES","chunk_index":392}
{"chunk_id":"2427ff6f43e2df09","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"272 \nCHAPTER 6 Normal Probability Distributions\nContinuity Correction\nWe want the area to the right of 151.5 in the bottom portion of Figure 6-25.\nTechnology: If using technology, we find that the shaded area is 0.2665.\nTable A-2: If using Table A-2, we must first find the z score using x = 151.5, \nm = 145, and s = 10.4283 as follows:\nz = x - m\ns\n= 151.5 - 145\n10.4283\n= 0.62\nUsing Table A-2, we find that z = 0.62 corresponds to a cumulative left \narea of 0.7324, so the shaded region in the bottom portion of Figure 6-25 is \n1 - 0.7324 = 0.2676. (The result of 0.2665 from technology is more accurate.)\nINTERPRETATION\nMendel’s result of 152 yellow peas is greater than the 145 yellow peas he expected \nwith his theory of hybrids, but with P(152 or more yellow peas) = 0.2665, we see \nthat 152 yellow peas is not significantly high. That is a result that could easily oc-\ncur with a true rate of 25% for yellow peas. This experiment does not contradict \n Mendel’s theory.\nDEFINITION\nWhen we use the normal distribution (which is a continuous probability distribution) \nas an approximation to the binomial distribution (which is discrete), a continuity \ncorrection is made to a discrete whole number x in the binomial distribution by \nrepresenting the discrete whole number x by the interval from x - 0.5 to x + 0.5 \n(that is, adding and subtracting 0.5).\nExample 1 used a continuity correction when the discrete value of 152 was repre-\nsented in the normal distribution by the area between 151.5 and 152.5. Because we \nwanted the probability of “152 or more” yellow peas, we used the area to the right of \n151.5. Here are other uses of the continuity correction:\nStatement About the Discrete Value\nArea of the Continuous Normal Distribution\nAt least 152 (includes 152 and above)\nTo the right of 151.5\nMore than 152 (doesn’t include 152)\nTo the right of 152.5\nAt most 152 (includes 152 and below)\nTo the left of 152.5\nFewer than 152 (doesn’t include 152)\nTo the left of 151.5\nExactly 152\nBetween 151.5 and 152.5\nEXAMPLE 2  Exactly 252 Yellow Peas\nUsing the same information from Example 1, find the probability of exactly 152 \nyellow peas among the 580 offspring peas. That is, given n = 580 and assuming \nthat p = 0.25, find P(exactly 152 yellow peas). Is this result useful for determining \nwhether 152 yellow peas is significantly high?\n","page_start":290,"page_end":290,"token_count":652,"section_type":"other","chapter_number":7,"chapter_title":"ESTIMATING PARAMETERS AND DETERMINING SAMPLE SIZES","chunk_index":393}
{"chunk_id":"b1182f6054165bf3","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"6-6 Normal as Approximation to Binomial \n273\nINTERPRETATION\nIn Section 4-1 we saw that x successes among n trials is significantly high if the \nprobability of x or more successes is unlikely with a probability of 0.05 or less. In \ndetermining whether Mendel’s result of 152 yellow peas contradicts his theory that \n25% of the offspring should be yellow peas, we should consider the probability \nof 152 or more yellow peas, not the probability of exactly 152 peas. The result of \n0.0305 is not the relevant probability; the relevant probability is 0.2665 found in Ex-\nample 1. In general, the relevant result is the probability of getting a result at least \nas extreme as the one obtained.\nSOLUTION\nSee Figure 6-26, which shows the normal distribution with m = 145 and s = 10.4283.\nThe shaded area approximates the probability of exactly 152 yellow peas. That region \nis the vertical strip between 151.5 and 152.5, as shown. We can find that area by using \nthe same methods introduced in Section 6-2.\nTechnology: Using technology, the shaded area is 0.0305.\nTable A-2: Using Table A-2, we convert 151.5 and 152.5 to z = 0.62 and z = 0.72,\nwhich yield cumulative left areas of 0.7324 and 0.7642. Because they are both cu-\nmulative left areas, the shaded region in Figure 6-26 is 0.7642 - 0.7324 = 0.0318.\nThe probability of exactly 152 yellow peas is 0.0318.\n(s 5 10.4283)\n152.5\nm 5 145\nThis shaded area\napproximates the\nprobability of exactly\n152 yellow peas.\n151.5\nFIGURE 6-26 Probability of Exactly 152 Yellow Peas\nTechnology for Binomial Probabilities\nThis topic of using a normal distribution to approximate a binomial distribution was \nonce quite important, but we can now use technology to find binomial probabilities \nthat were once beyond our capabilities. For example, see the following Statdisk dis-\nplay on the next page showing that for Example 1, the probability of 152 or more \nyellow peas is 0.2650, and for Example 2, the probability of exactly 152 yellow peas \nis 0.0301, so there is no real need to use a normal approximation. However, there are \ncases where we need to use a normal approximation, and Section 8-3 uses a normal \napproximation to a binomial distribution for an important statistical method intro-\nduced in that section.\n","page_start":291,"page_end":291,"token_count":588,"section_type":"other","chapter_number":7,"chapter_title":"ESTIMATING PARAMETERS AND DETERMINING SAMPLE SIZES","chunk_index":394}
{"chunk_id":"251e8deae4648690","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"274 \nCHAPTER 6 Normal Probability Distributions\nStatistical Literacy and Critical Thinking \n1.  Continuity Correction In testing the assumption that the probability of a baby boy is \n0.512, a geneticist obtains a random sample of 1000 births and finds that 502 of them are boys. \nUsing the continuity correction, describe the area under the graph of a normal distribution cor-\nresponding to the following. (For example, the area corresponding to “the probability of at least \n502 boys” is this: the area to the right of 501.5.)\na. The probability of 502 or fewer boys\nb. The probability of exactly 502 boys\nc. The probability of more than 502 boys\n2.  Checking Requirements Common tests such as the SAT, ACT, LSAT (Law School \n Admissions Test), and MCAT (Medical College Admissions Test) use multiple choice test \nquestions, each with possible answers of a, b, c, d, e, and each question has only one correct \nanswer. We want to find the probability of getting at least 25 correct answers for someone who \nmakes random guesses for answers to a block of 100 questions. If we plan to use the methods \nof this section with a normal distribution used to approximate a binomial distribution, are the \nnecessary requirements satisfied? Explain.\n3. Notation Common tests such as the SAT, ACT, LSAT, and MCAT tests use multiple choice \ntest questions, each with possible answers of a, b, c, d, e, and each question has only one cor-\nrect answer. For people who make random guesses for answers to a block of 100 questions, \nidentify the values of p, q, m, and s. What do m and s measure?\n4. Distribution of Proportions Each week, Nielsen Media Research conducts a survey of \n5000 households and records the proportion of households tuned to Sanjay Gupta MD. If we \nobtain a large collection of those proportions and construct a histogram of them, what is the ap-\nproximate shape of the histogram?\n6-6 Basic Skills and Concepts\n","page_start":292,"page_end":292,"token_count":444,"section_type":"other","chapter_number":7,"chapter_title":"ESTIMATING PARAMETERS AND DETERMINING SAMPLE SIZES","chunk_index":395}
{"chunk_id":"2878931fa46b5e2d","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"6-6 Normal as Approximation to Binomial \n275\nUsing Normal Approximation. In Exercises 5–8, do the following: If the requirements \nof np # 5 and nq # 5 are both satisfied, estimate the indicated probability by using the \nnormal distribution as an approximation to the binomial distribution; if np * 5 or nq * 5, \nthen state that the normal approximation should not be used.\n5. Births of Boys With n = 20 births and p = 0.512 for a boy, find P(fewer than 8 boys).\n6. Births of Boys With n = 8 births and p = 0.512 for a boy, find P(exactly 5 boys).\n7. Guessing on United States Medical Licensing Examinations With n = 20 guesses \nand p = 0.2 for a correct answer, find P(at least 6 correct answers).\n8. Guessing on United States Medical Licensing Examinations With n = 50 guesses \nand p = 0.2 for a correct answer, find P(exactly 12 correct answers).\nEye Colors. In Exercises 9–12, assume that eye colors are distributed as shown in the ac-\ncompanying display (based on data from a study by Dr. P. Sorita at Indiana University), and \nalso assume that 100 people are randomly selected.\n9.  Blue Eyes Find the probability that at least 40 of the 100 subjects have blue eyes. Is \n40 people with blue eyes significantly high?\n10. Blue Eyes Find the probability that at least 49 of the 100 subjects have blue eyes. Is \n49 people with blue eyes significantly high?\n11. Green Eyes Find the probability that fewer than 5 of the 100 subjects have green eyes. Is \n4 people with green eyes significantly low?\n12. Brown Eyes Find the probability that among the 100 subjects, 33 or fewer have brown \neyes. Is 33 people with brown eyes significantly low?\n13. Tamiflu Assume that 10% of subjects treated with Tamiflu (oseltamivir) experienced the \nadverse reaction of nausea (based on clinical trials).\na. Find the probability that among 250 randomly selected subjects treated with Tamiflu, ex-\nactly 17 of them experience nausea.\nb. Find the probability that among 250 randomly selected subjects treated with Tamiflu, the \nnumber who experience nausea is 17 or fewer.\nc. Does it appear that 17 cases of nausea among the 250 subjects is significantly low?\n14. Mendelian Genetics When Mendel conducted his famous genetics experiments with \npeas, one sample of offspring consisted of 929 peas, with 705 of them having red flowers. If \nwe assume, as Mendel did, that under these circumstances, there is a 3>4 probability that a pea \nwill have a red flower, we would expect that 696.75 (or about 697) of the peas would have red \nflowers, so the result of 705 peas with red flowers is more than expected.\na. If Mendel’s assumed probability is correct, find the probability of getting 705 or more peas \nwith red flowers.\ncontinued\n","page_start":293,"page_end":293,"token_count":676,"section_type":"other","chapter_number":7,"chapter_title":"ESTIMATING PARAMETERS AND DETERMINING SAMPLE SIZES","chunk_index":396}
{"chunk_id":"f1515fc066d59476","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"276 \nCHAPTER 6 Normal Probability Distributions\nb. Is 705 peas with red flowers significantly high?\nc. What do these results suggest about Mendel’s assumption that 3>4 of peas will have red \nflowers?\n15. Sleepwalking Assume that 29.2% of people have sleepwalked (based on “Prevalence \nand Comorbidity of Nocturnal Wandering in the U.S. Adult General Population,” by Ohayon \net al., Neurology, Vol. 78, No. 20). Assume that in a random sample of 1480 adults, 455 have \nsleepwalked.\na. Assuming that the rate of 29.2% is correct, find the probability that 455 or more of the 1480 \nadults have sleepwalked.\nb. Is that result significantly high?\nc. What does the result suggest about the rate of 29.2%?\n16. Cell Phones and Brain Cancer In a study of 420,095 cell phone users in Denmark, it \nwas found that 135 developed cancer of the brain or nervous system. For those not using cell \nphones, there is a 0.000340 probability of a person developing cancer of the brain or nervous \nsystem. We therefore expect about 143 cases of such cancers in a group of 420,095 randomly \nselected people.\na. Find the probability of 135 or fewer cases of such cancers in a group of 420,095 people.\nb. What do these results suggest about media reports that indicate cell phones cause cancer of \nthe brain or nervous system?\n17. Births The probability of a baby being born a boy is 0.512. Consider the problem of \nfinding the probability of exactly 7 boys in 11 births. Solve that problem using (1) normal ap-\nproximation to the binomial using Table A-2; (2) normal approximation to the binomial using \ntechnology instead of Table A-2; (3) using technology with the binomial distribution instead of \nusing a normal approximation. Compare the results. Given that the requirements for using the \nnormal approximation are just barely met, are the approximations off by very much?\n6-6 Beyond the Basics\nBone Density Test. In Exercises 1–4, assume that scores on a bone mineral density test \nare normally distributed with a mean of 0 and a standard deviation of 1.\n1. Bone Density Sketch a graph showing the shape of the distribution of bone density test \nscores.\n2. Bone Density Find the score separating the lowest 9% of scores from the highest 91%.\n3. Bone Density For a randomly selected subject, find the probability of a score greater than \n-2.93.\n4. Bone Density For a randomly selected subject, find the probability of a score between \n0.87 and 1.78.\n5. Notation \na. Identify the values of m and s for the standard normal distribution.\nb. What do the symbols mx and sx represent?\nChapter Quick Quiz\n","page_start":294,"page_end":294,"token_count":635,"section_type":"other","chapter_number":7,"chapter_title":"ESTIMATING PARAMETERS AND DETERMINING SAMPLE SIZES","chunk_index":397}
{"chunk_id":"6bd589696130dfd8","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"In Exercises 6–10, assume that women have diastolic blood pressure measures that are \nnormally distributed with a mean of 70.2 mm Hg and a standard deviation of 11.2 mm Hg \n(based on Data Set 1 “Body Data” in Appendix B).\n6. Diastolic Blood Pressure Find the probability that a randomly selected woman has a \nnormal diastolic blood pressure level, which is below 80 mm Hg.\n7. Diastolic Blood Pressure Find the probability that a randomly selected woman has a \ndiastolic blood pressure level between 60 mm Hg and 80 mm Hg.\n8. Diastolic Blood Pressure Find P90, the 90th percentile for the diastolic blood pressure \nlevels of women.\n9. Diastolic Blood Pressure If 16 women are randomly selected, find the probability that \nthe mean of their diastolic blood pressure levels is less than 75 mm Hg.\n10.  Diastolic Blood Pressure The accompanying normal quantile plot was constructed \nfrom the diastolic blood pressure levels of a sample of women. What does this graph suggest \nabout diastolic blood pressure levels of women?\n1. Bone Density Test A bone mineral density test is used to identify a bone disease. The re-\nsult of a bone density test is commonly measured as a z score, and the population of z scores is \nnormally distributed with a mean of 0 and a standard deviation of 1.\na. For a randomly selected subject, find the probability of a bone density test score less than 1.54.\nb. For a randomly selected subject, find the probability of a bone density test score greater than \n-1.54.\nc. For a randomly selected subject, find the probability of a bone density test score between \n-1.33 and 2.33.\nd. Find Q1, the bone density test score separating the bottom 25% from the top 75%.\ne. If the mean bone density test score is found for 9 randomly selected subjects, find the prob-\nability that the mean is greater than 0.50.\n2. Biometric Security In designing a security system based on eye (iris) recognition, we must \nconsider the standing eye heights of women, which are normally distributed with a mean of \n59.7 in. and a standard deviation of 2.5 in. (based on anthropometric survey data from Gordon, \nChurchill, et al.).\na. If an eye recognition security system is positioned at a height that is uncomfortable for \nwomen with standing eye heights less than 54 in., what percentage of women will find that \nheight uncomfortable?\nb. In positioning the eye recognition security system, we want it to be suitable for the lowest \n95% of standing eye heights of women. What standing eye height of women separates the low-\nest 95% of standing eye heights from the highest 5%?\nReview Exercises\nCHAPTER 6 Review Exercises \n277\n","page_start":295,"page_end":295,"token_count":626,"section_type":"other","chapter_number":7,"chapter_title":"ESTIMATING PARAMETERS AND DETERMINING SAMPLE SIZES","chunk_index":398}
{"chunk_id":"e62a14ae851e0330","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"278 \nCHAPTER 6 Normal Probability Distributions\n3. Biometric Security Standing eye heights of men are normally distributed with a mean of \n64.3 in. and a standard deviation of 2.6 in. (based on anthropometric survey data from Gordon, \nChurchill, et al.).\na. If an eye recognition security system is positioned at a height that is uncomfortable for men \nwith standing eye heights greater than 70 in., what percentage of men will find that height un-\ncomfortable?\nb. In positioning the eye recognition security system, we want it to be suitable for the tallest \n98% of standing eye heights of men. What standing eye height of men separates the tallest 98% \nof standing eye heights from the lowest 2%?\n4. Sampling Distributions Scores on the Gilliam Autism Rating Scale (GARS) are nor-\nmally distributed with a mean of 100 and a standard deviation of 15. A sample of 64 GARS \nscores is randomly selected and the sample mean is computed.\na. Describe the distribution of such sample means.\nb. What is the mean of all such sample means?\nc. What is the standard deviation of all such sample means?\n5. Unbiased Estimators\na. What is an unbiased estimator?\nb. For the following statistics, identify those that are unbiased estimators: mean, median, range, \nvariance, proportion.\nc. Determine whether the following statement is true or false: “The sample standard deviation is a \nbiased estimator, but the bias is relatively small in large samples, so s is often used to estimate s.”\n6. Disney Monorail The Mark VI monorail used at Disney World has doors with a height of \n72 in. Heights of men are normally distributed with a mean of 68.6 in. and a standard deviation \nof 2.8 in. (based on Data Set 1 “Body Data” in Appendix B).\na. What percentage of adult men can fit through the doors without bending? Does the door \ndesign with a height of 72 in. appear to be adequate? Explain.\nb. What doorway height would allow 99% of adult men to fit without bending?\n7. Disney Monorail Consider the same Mark VI monorail described in the preceding exer-\ncise. Again assume that heights of men are normally distributed with a mean of 68.6 in. and a \nstandard deviation of 2.8 in.\na. In determining the suitability of the monorail door height, why does it make sense to con-\nsider men while women are ignored?\nb. Mark VI monorail cars have a capacity of 60 passengers. If a car is loaded with 60 randomly \nselected men, what is the probability that their mean height is less than 72 in.?\nc. Why can’t the result from part (b) be used to determine how well the doorway height accom-\nmodates men?\n8.  Assessing Normality of BMI Data Listed below are measures of body mass index \n(BMI) for women listed in Data Set 1 “Body Data.”","page_start":296,"page_end":296,"token_count":650,"section_type":"other","chapter_number":7,"chapter_title":"ESTIMATING PARAMETERS AND DETERMINING SAMPLE SIZES","chunk_index":399}
{"chunk_id":"361afd039fa249e6","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"selected men, what is the probability that their mean height is less than 72 in.?\nc. Why can’t the result from part (b) be used to determine how well the doorway height accom-\nmodates men?\n8.  Assessing Normality of BMI Data Listed below are measures of body mass index \n(BMI) for women listed in Data Set 1 “Body Data.”\na. Do these measures appear to come from a population that has a normal distribution? Why or \nwhy not?\nb. Can the mean of this sample be treated as a value from a population having a normal distri-\nbution? Why or why not?\n15.9 18.7 24.2 28.7 28.8 28.9 28.9 28.9 29.0 29.1 29.3 31.4 59.0\n9. Hybridization Experiment In one of Mendel’s experiments with plants, 1064 offspring \nconsisted of 787 plants with long stems. According to Mendel’s theory, 3>4 of the offspring ","page_start":296,"page_end":296,"token_count":232,"section_type":"other","chapter_number":7,"chapter_title":"ESTIMATING PARAMETERS AND DETERMINING SAMPLE SIZES","chunk_index":400}
{"chunk_id":"dd7dcb4ee1dbe5bf","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"plants should have long stems. Assuming that Mendel’s proportion of 3>4 is correct, find the \nprobability of getting 787 or fewer plants with long stems among 1064 offspring plants. Based \non the result, is 787 offspring plants with long stems significantly low? What does the result \nimply about Mendel’s claimed proportion of 3>4?\n10. Tall Clubs The social organization Tall Clubs International has a requirement that women \nmust be at least 70 in. tall. Assume that women have normally distributed heights with a mean \nof 63.7 in. and a standard deviation of 2.9 in. (based on Data Set 1 in Appendix B).\na. Find the percentage of women who satisfy the height requirement.\nb. If the height requirement is to be changed so that the tallest 2.5% of women are eligible, \nwhat is the new height requirement?\nIn Exercises 1–3, use the following left threshold audiometry measures from females (from \nData Set 4 “Audiometry” in Appendix B).\n15.9 18.7 24.2 28.7 28.8 28.9 28.9 28.9 29.0 29.1 29.3 31.4\n1. Audiometry\na. Find the mean x.\nb. Find the median.\nc. Find the standard deviation s.\nd. Convert the highest measure to a z score.\ne. What level of measurement (nominal, ordinal, interval, ratio) describes this data set?\nf. Are the measures of hearing discrete data or continuous data?\n2. Audiometry\na. Find Q1, Q2, and Q3.\nb. Construct a boxplot.\nc. Based on the accompanying normal quantile plot of the audiometry measurements, what do \nyou conclude about these sample data?\n3. Left-Handedness According to data from the American Medical Association, 10% of us \nare left-handed.\na. If three people are randomly selected, find the probability that they are all left-handed.\nb. If three people are randomly selected, find the probability that at least one of them is \n left-handed.\nCumulative Review Exercises\nCHAPTER 6 Cumulative Review Exercises \n279\ncontinued\n","page_start":297,"page_end":297,"token_count":485,"section_type":"other","chapter_number":7,"chapter_title":"ESTIMATING PARAMETERS AND DETERMINING SAMPLE SIZES","chunk_index":401}
{"chunk_id":"b3fe8ed373a97905","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"280 \nCHAPTER 6 Normal Probability Distributions\nc. Why can’t we solve the problem in part (b) by using the normal approximation to the bino-\nmial distribution?\nd. If groups of 50 people are randomly selected, what is the mean number of left-handed peo-\nple in such groups?\ne. If groups of 50 people are randomly selected, what is the standard deviation for the numbers \nof left-handed people in such groups?\nf. Use the range rule of thumb to determine whether 8 left-handed people is a significantly high \nnumber of left-handed people in a randomly selected group of 50 people.\n4. Blue Eyes Assume that 35% of us have blue eyes (based on a study by Dr. P. Soria at \n Indiana University).\na. Let B denote the event of selecting someone who has blue eyes. What does the event B\n denote?\nb. Find the value of P1B2.\nc. Find the probability of randomly selecting three different people and finding that all of them \nhave blue eyes.\nd. Find the probability that among 100 randomly selected people, at least 45 have blue eyes.\ne. If 35% of us really do have blue eyes, is a result of 45 people with blue eyes among 100 ran-\ndomly selected people a result that is significantly high?\n5. Foot Lengths of Women Assume that foot lengths of women are normally distributed \nwith a mean of 9.6 in. and a standard deviation of 0.5 in., based on data from the U.S. Army \nAnthropometry Survey (ANSUR).\na. Find the probability that a randomly selected woman has a foot length less than 10.0 in.\nb. Find the probability that a randomly selected woman has a foot length between 8.0 in. and \n11.0 in.\nc. Find P95.\nd. Find the probability that 25 women have foot lengths with a mean greater than 9.8 in.\nSome methods in this chapter are easy with technology but very difficult without it. The two \nprojects that follow illustrate how easy it is to use technology for assessing normality and find-\ning binomial probabilities.\n1. Assessing Normality It is often necessary to determine whether sample data appear to \nbe from a normally distributed population, and that determination is helped with the construc-\ntion of a histogram and normal quantile plot. Refer to Data Set 1 “Body Data” in Appendix B. \nFor each of the 13 columns of data (not including age or gender), determine whether the data \nappear to be from a normally distributed population. Use Statdisk or any other technology. \n(Download a free copy of Statdisk from www.statdisk.org.)\n2. Binomial Probabilities Section 6-6 described a method for using a normal distribution to \napproximate a binomial distribution. Many technologies are capable of generating probabilities \nfor a binomial distribution. Instead of using a normal approximation to a binomial distribution, \nuse technology to find the exact binomial probabilities in Exercises 9–12 of Section 6-6.\nTechnology Projects\n","page_start":298,"page_end":298,"token_count":653,"section_type":"other","chapter_number":7,"chapter_title":"ESTIMATING PARAMETERS AND DETERMINING SAMPLE SIZES","chunk_index":402}
{"chunk_id":"c781e6271c870b2f","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"FROM DATA TO DECISION\nCritical Thinking: Designing a campus  \ndormitory elevator\nAn Ohio college student died when he tried to escape from \na dormitory elevator that was overloaded with 24 passen-\ngers. The elevator was rated for a maximum weight of 2500 \npounds. Let’s consider this elevator with an allowable weight \nof 2500 pounds. Let’s also consider parameters for weights \nof adults, as shown in the accompanying table (based on \nData Set 1 “Body Data” in Appendix B).\nWeights of Adults\nMales\nFemales\nm\n189 lb\n171 lb\ns\n39 lb\n46 lb\nDistribution\nNormal\nNormal\nWe could consider design features such as the type of music \nthat could be played on the elevator. We could select songs \nsuch as “Imagine” or “Daydream Believer.” Instead, we will \nfocus on the critical design feature of weight.\na. First, elevators commonly have a 25% margin of error, \nso they can safely carry a load that is 25% greater than the \nstated load. What amount is 25% greater than 2500 pounds? \nLet’s refer to this amount as “the maximum safe load,” \nwhile the 2500-pound limit is the “placard maximum load.”\nb. Now we need to determine the maximum number of pas-\nsengers that should be allowed. Should we base our calcula-\ntions on the maximum safe load or the 2500-pound placard \nmaximum load?\nc. The weights given in the accompanying table are weights \nof adults not including clothing or textbooks. Add another \n10 pounds for each student’s clothing and textbooks. What \nis the maximum number of elevator passengers that should \nbe allowed?\nd. Do you think that weights of college students are different \nfrom weights of adults from the general population? If so, \nhow? How would that affect the elevator design?\n1. In-class activity Divide into groups of three or four students and address these issues af-\nfecting the design of manhole covers.\n• Which of the following is most relevant for determining whether a manhole cover diameter of \n24 in. is large enough: weights of men, weights of women, heights of men, heights of women, \nhip breadths of men, hip breadths of women, shoulder breadths of men, shoulder breadths of \nwomen?\n• Why are manhole covers usually round? (This was once a popular interview question asked \nof applicants at IBM, and there are at least three good answers. One good answer is sufficient \nhere.)\n2. Out-of-class activity Divide into groups of three or four students. In each group, develop \nan original procedure to illustrate the central limit theorem. The main objective is to show that \nwhen you randomly select samples from a population, the means of those samples tend to be \nnormally distributed, regardless of the nature of the population distribution. For this illustra-\ntion, begin with some population of values that does not have a normal distribution.\n3. In-class activity Divide into groups of three or four students. Using a coin to simulate ","page_start":299,"page_end":299,"token_count":656,"section_type":"other","chapter_number":7,"chapter_title":"ESTIMATING PARAMETERS AND DETERMINING SAMPLE SIZES","chunk_index":403}
{"chunk_id":"49d127f8b751d8b6","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"an original procedure to illustrate the central limit theorem. The main objective is to show that \nwhen you randomly select samples from a population, the means of those samples tend to be \nnormally distributed, regardless of the nature of the population distribution. For this illustra-\ntion, begin with some population of values that does not have a normal distribution.\n3. In-class activity Divide into groups of three or four students. Using a coin to simulate \nbirths, each individual group member should simulate 25 births and record the number of simu-\nlated girls. Combine all results from the group and record n = total number of births and x =\nnumber of girls. Given batches of n births, compute the mean and standard deviation for the \nnumber of girls. Is the simulated result unusual? Why or why not?\n4. In-class activity Divide into groups of three or four students. Select a set of data from \n Appendix B (excluding Data Sets that were used in examples or exercises in Section 6-5). Use \nthe methods of Section 6-5 to construct a histogram and normal quantile plot, and then deter-\nmine whether the data set appears to come from a normally distributed population.\nCooperative Group Activities\nCHAPTER 6 Cooperative Group Activities \n281","page_start":299,"page_end":299,"token_count":257,"section_type":"other","chapter_number":7,"chapter_title":"ESTIMATING PARAMETERS AND DETERMINING SAMPLE SIZES","chunk_index":404}
{"chunk_id":"1575572c8882d062","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"282\nEstimating a Population \nProportion\nEstimating a Population \nMean\nEstimating a Population \nStandard Deviation or \nVariance\nBootstrapping: \nUsing Technology for \nEstimates\n7-1\n7-2\n7-3\n7-4\nDoes Touch Therapy Work?\nCHAPTER \nPROBLEM\nEstimating Parameters \nand Determining \nSample Sizes\nMany patients pay $30 to $60 for a session of touch therapy in \nwhich the touch therapist moves his or her hands within a few \ninches of the patient’s body without actually making physical \ncontact. The objective is to cure a wide variety of medical con-\nditions, including cancer, AIDS, asthma, heart disease, head-\naches, burns, and bone fractures. The intent is that a profes-\nsionally trained touch therapist can detect poor alignments in \nthe patient’s energy field, and can then reposition energy fields \nto create an energy balance that fosters the healing process.\nWhen she was in the fourth grade, nine-year old Emily \nRosa chose the topic of touch therapy for a science fair project. \nShe convinced 21 experienced touch therapists to participate \nin a simple test of their ability to detect a human energy field. \nEmily constructed a cardboard partition with two holes for \n7 \n","page_start":300,"page_end":300,"token_count":267,"section_type":"other","chapter_number":7,"chapter_title":"ESTIMATING PARAMETERS AND DETERMINING SAMPLE SIZES","chunk_index":405}
{"chunk_id":"cddc4430d53c68ec","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"hands. Each touch therapist would put both hands through the \ntwo holes, and Emily would place her hand just above one of \nthe therapist’s hands; then the therapist was asked to identify \nthe hand that Emily had selected. Emily used a coin toss to \nrandomly select the hand to be used. This test was repeated \n280 times. If the touch therapists really did have the ability to \nsense a human energy field, they should have identified the \ncorrect hand significantly more than 50% of the time. If they \ndid not have the ability to detect the energy field and they just \nguessed, they should have been correct about 50% of the time. \nHere are Emily’s results: Among the 280 trials, the touch thera-\npists identified the correct hand 123 times, for a success rate of \n43.9%. Emily, with the help of her mother, a statistician, and a \nphysician, submitted her findings for publication in the Journal \nof the American Medical Association. After a careful and thor-\nough review of the experimental design and results, the article \n“A Close Look at Therapeutic Touch” was published (Journal of \nthe American Medical Association, Vol. 279, No. 13). Emily be-\ncame the youngest researcher to be published in that journal. \nAnd she won a blue ribbon for her science fair project.\nLet’s consider the key results from Emily’s project. Among \nthe 280 trials, the touch therapists were correct 123 times. We \nhave a sample proportion with n = 280 and x = 123 suc-\ncesses. Arguments against the validity of the study might include \nthe claim that the number of trials is too small to be meaningful, \nor that the touch therapists just had a bad day and, because \nof chance, they were not as successful as the population of all \ntouch therapists. We will consider such issues in this chapter.\nIn this chapter we begin the study of methods of inferential statistics. Listed below are \nthe major activities of inferential statistics, and this chapter introduces methods for the \nfirst activity of using sample data to estimate population parameters. Chapter 8 will intro-\nduce the basic methods for testing claims (or hypotheses) about population  parameters.\nMajor Activities of Inferential Statistics\n1. Use sample data to estimate values of population parameters (such as a population \nproportion or population mean).\n2. Use sample data to test hypotheses (or claims) made about population parameters.\nHere are the chapter objectives.\nEstimating a Population Proportion\n• Construct a confidence interval estimate of a population proportion and interpret \nsuch confidence interval estimates.\n• Identify the requirements necessary for the procedure that is used, and determine \nwhether those requirements are satisfied.\n• Develop the ability to determine the sample size necessary to estimate a population \nproportion.\nEstimating a Population Mean\n• Construct a confidence interval estimate of a population mean, and be able to inter-\npret such confidence interval estimates.\n• Determine the sample size necessary to estimate a population mean.\nEstimating a Population Standard Deviation or Variance\n• Develop the ability to construct a confidence interval estimate of a population  standard \ndeviation or variance, and be able to interpret such confidence interval  estimates.\n7-1\n7-2\n7-3\nChapter Objectives \n283\nCHAPTER OBJECTIVES\n>>>\n","page_start":301,"page_end":301,"token_count":689,"section_type":"other","chapter_number":7,"chapter_title":"ESTIMATING PARAMETERS AND DETERMINING SAMPLE SIZES","chunk_index":406}
{"chunk_id":"ea37f1ccf3b2dd47","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"284 \nCHAPTER 7 Estimating Parameters and Determining Sample Sizes\nKey Concept This section presents methods for using a sample proportion to make \nan inference about the value of the corresponding population proportion. This section \nfocuses on the population proportion p, but we can also work with probabilities or \npercentages. When working with percentages, we will perform calculations with the \nequivalent proportion value. Here are the three main concepts included in this section:\n \n■Point Estimate: The sample proportion (denoted by pn) is the best point estimate \n(or single value estimate) of the population proportion p.\n \n■Confidence Interval: We can use a sample proportion to construct a confidence \ninterval estimate of the true value of a population proportion, and we should \nknow how to construct and interpret such confidence intervals.\n \n■Sample Size: We should know how to find the sample size necessary to estimate \na population proportion.\nThe concepts presented in this section are used in the following sections and chapters, \nso it is important to understand this section quite well.\nPART 1\n  Point Estimate, Confidence Interval,  \nand Sample Size \nPoint Estimate\nIf we want to estimate a population proportion with a single value, the best estimate \nis the sample proportion pn. Because pn consists of a single value that is equivalent to a \npoint on a line, it is called a point estimate.\n7-1 \nEstimating a Population Proportion\nBootstrapping: Using Technology for Estimates\n• Develop the ability to use technology along with the bootstrapping method to con-\nstruct a confidence interval estimate of a population proportion, population mean, \nand population standard deviation and population variance.\n7-4\nBootstrapping: Using Technology for Estimates\n• Develop the ability to use technology along with the bootstrapping method to con-\nstruct a confidence interval estimate of a population proportion, population mean,\nand population standard deviation and population variance.\nDEFINITION\nA point estimate is a single value used to estimate a population parameter.\nThe sample proportion pn is the best point estimate of the population \np roportion p.\nUnbiased Estimator We use pn as the point estimate of p because it is unbiased and \nit is the most consistent of the estimators that could be used. (An unbiased estima-\ntor is a statistic that targets the value of the corresponding population parameter in \nthe sense that the sampling distribution of the statistic has a mean that is equal to the \ncorresponding population parameter. The statistic pn targets the population proportion \np.) The sample proportion pn is the most consistent estimator of p in the sense that the \nstandard deviation of sample proportions tends to be smaller than the standard devia-\ntion of other unbiased estimators of p.\n","page_start":302,"page_end":302,"token_count":554,"section_type":"other","chapter_number":7,"chapter_title":"ESTIMATING PARAMETERS AND DETERMINING SAMPLE SIZES","chunk_index":407}
{"chunk_id":"8d3d2c96e86f7a4e","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"7-1 Estimating a Population Proportion \n285\nConfidence Interval\nWhy Do We Need Confidence Intervals? In Example 1 we saw that 0.439 is our best \npoint estimate of the population proportion p, but we have no indication of how good \nthat best estimate is. A confidence interval gives us a much better sense of how good \nan estimate is.\nEXAMPLE 1\nTouch Therapy\nThe Chapter Problem describes a test of touch therapy. If the touch therapists had \nthe ability to sense a human energy field, they should have identified the correct \nhand significantly more than 50% of the time. If they made random guesses, their \nsuccess rate should be around 50%. Using the result of 123 correct responses in the \n280 trials, find the best point estimate of the proportion of correct responses.\nSOLUTION\nBecause the sample proportion is the best point estimate of the population propor-\ntion, we conclude that the best point estimate of p is 123>280 or 0.439. (If using \nthe sample results to estimate the percentage of correct responses, the best point \n estimate is 43.9%.)\nDEFINITION\nA confidence interval (or interval estimate) is a range (or an interval) of values \nused to estimate the true value of a population parameter. A confidence interval is \nsometimes abbreviated as CI.\nDEFINITION\nThe confidence level is the probability 1 - a (such as 0.95, or 95%) that the con-\nfidence interval actually does contain the population parameter, assuming that the \nestimation process is repeated a large number of times. (The confidence level is \nalso called the degree of confidence, or the confidence coefficient.)\nThe following table shows the relationship between the confidence level and the cor-\nresponding value of a. The confidence level of 95% is the value used most often.\nMost Common Confidence Levels\nCorresponding Values of A\n90% (or 0.90) confidence level:\na = 0.10\n95% (or 0.95) confidence level:\na = 0.05\n99% (or 0.99) confidence level:\na = 0.01\nHere’s an example of a confidence interval found later in Example 3:\nThe 0.95 (or 95%) conﬁdence interval estimate of the population proportion \np is 0.381 * p * 0.497.\ne \nBias in Internet  \nSurveys?\nCapitalizing on \nthe widespread \nuse of technol-\nogy and social \nmedia, there is a \ngrowing trend to \nconduct surveys \nusing only the \nInternet instead of using in-\nperson interviews or phone calls \nto randomly selected subjects. \nInternet surveys are faster and \nmuch less expensive, and they \nprovide important advantages in \nsurvey design and administra-\ntion. But are Internet surveys \nbiased because they use only \nsubjects randomly selected from \nthe 90% of the U.S. population \nthat uses the Internet? The Pew \nResearch Center studied this \nissue by comparing results from \nonline polls to polls that included \nthe offline population. It was \nfound that the differences were \ngenerally quite small, but topics \nrelated to the Internet and tech-\nnology resulted in much larger \ndifferences. We should be careful \nto consider consequences of \nbias with Internet surveys.\n","page_start":303,"page_end":303,"token_count":700,"section_type":"other","chapter_number":7,"chapter_title":"ESTIMATING PARAMETERS AND DETERMINING SAMPLE SIZES","chunk_index":408}
{"chunk_id":"a641961aa4cd7608","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"286 \nCHAPTER 7 Estimating Parameters and Determining Sample Sizes\nInterpreting a Confidence Interval\nWe must be careful to interpret confidence intervals correctly. There is a correct inter-\npretation and many different and creative incorrect interpretations of the confidence \ninterval 0.381 6 p 6 0.497.\nCorrect: \n “We are 95% confident that the interval from 0.381 to 0.497 actu-\nally does contain the true value of the population proportion p.”\n This is a short and acceptable way of saying that if we were to \nselect many different random samples of size 280 (as in the Chapter \nProblem) and construct the corresponding confidence intervals, 95% \nof them would contain the population proportion p. In this correct \ninterpretation, the confidence level of 95% refers to the success rate \nof the process used to estimate the population proportion.\nWrong: \n “There is a 95% chance that the true value of p will fall between \n0.381 and 0.497.”\n This is wrong because p is a population parameter with a fixed \nvalue; it is not a random variable with values that vary.\nWrong: \n “95% of sample proportions will fall between 0.381 and 0.497.”\n This is wrong because the values of 0.381 and 0.497 result from one \nsample; they are not parameters describing the behavior of all samples.\nConfidence Level: The Process Success Rate A confidence level of 95% tells us that \nthe process we are using should, in the long run, result in confidence interval limits that \ncontain the true population proportion 95% of the time. Suppose that the true proportion \nof correct responses by the touch therapists is p = 0.50. See Figure 7-1, which shows \nthat 19 out of 20 (or 95%) different confidence intervals contain the assumed value of \np = 0.50. Figure 7-1 is trying to tell this story: With a 95% confidence level, we expect \nabout 19 out of 20 confidence intervals (or 95%) to contain the true value of p.\nThis conﬁdence interval\ndoes not contain p 5 0.50.\n0.45\np 5 0.50\n0.55\nFIGURE 7-1  Confidence Intervals from  \n20 Different Samples\nCritical Values\nCritical values are formally defined on the next page and they are based on the follow-\ning observations:\n1. When certain requirements are met, the sampling distribution of sample propor-\ntions can be approximated by a normal distribution, as shown in Figure 7-2.\n2. A z score associated with a sample proportion has a probability of a>2 of fall-\ning in the right tail portion of Figure 7-2.\n3. The z score at the boundary of the right-tail region is commonly denoted \nby za>2 and is referred to as a critical value because it is on the borderline \nseparating z scores that are significantly high.\nza/2\na/2\na/2\nFound from\ntechnology or\nTable A-2\nz 5 0\nFIGURE 7-2\nCritical \nValue zA,2 in the Standard \nNormal Distribution\n","page_start":304,"page_end":304,"token_count":689,"section_type":"other","chapter_number":7,"chapter_title":"ESTIMATING PARAMETERS AND DETERMINING SAMPLE SIZES","chunk_index":409}
{"chunk_id":"f0ff95c97af11913","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"7-1 Estimating a Population Proportion \n287\nExample 2 showed that a 95% confidence level results in a critical value of \nza>2 = 1.96. This is the most common critical value, and it is listed with two other \ncommon values in the table that follows.\nConfidence Level\na\nCritical Value, zA>2\n90%\n0.10\n1.645\n95%\n0.05\n     1.96\n99%\n0.01\n2.575\nDEFINITION\nA critical value is the number on the borderline separating sample statistics that \nare significantly high or low from those that are not significant. The number za>2 is a \ncritical value that is a z score with the property that it is at the border that separates \nan area of a>2 in the right tail of the standard normal distribution (as in Figure 7-2).\nEXAMPLE 2\nFinding a Critical Value\nFind the critical value za>2 corresponding to a 95% confidence level.\nSOLUTION\nA 95% confidence level corresponds to a = 0.05, so a>2 = 0.025. Figure 7-3 \nshows that the area in each of the green-shaded tails is a>2 = 0.025. We find \nza>2 = 1.96 by noting that the cumulative area to its left must be 1 - 0.025, or \n0.975. We can use technology or refer to Table A-2 to find that the cumulative left \narea of 0.9750 corresponds to z = 1.96. For a 95% confidence level, the critical \nvalue is therefore za>2 = 1.96.\nNote that when finding the critical z score for a 95% confidence level, we use a \ncumulative left area of 0.9750 (not 0.95). Think of it this way:\nThis is our \n The area in both  \nThe area in the right The cumulative area from the left,\nconfidence level: \ntails is: \n tail is: \nexcluding the right tail, is:\n95% \nu  A = 0.05 \nu  \nA,2 = 0.025 \nu  \n1 −0.025 = 0.975\nConﬁdence Level: 95%\nThe total area to the\nleft of this boundary\nis 0.975.\na/2 5 0.025\na/2 5 0.025\nz 5 0\nza/2 5 1.96\n2za/2 5 21.96\nFIGURE 7-3  Finding the Critical Value zA,2 for a 95%  \nConfidence Level\nHow the Poll Was \nConducted\nThe New York \nTimes is quite \ngood at report-\ning poll results. \nThat newspaper \noften reports on \npoll results with \nan accompanying article bearing \nthe headline “How the Poll Was \nConducted.” The description \ntypically includes the sample \nsize, the margin of error, and the ","page_start":305,"page_end":305,"token_count":652,"section_type":"other","chapter_number":7,"chapter_title":"ESTIMATING PARAMETERS AND DETERMINING SAMPLE SIZES","chunk_index":410}
{"chunk_id":"11d02ca978835abf","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"FIGURE 7-3  Finding the Critical Value zA,2 for a 95%  \nConfidence Level\nHow the Poll Was \nConducted\nThe New York \nTimes is quite \ngood at report-\ning poll results. \nThat newspaper \noften reports on \npoll results with \nan accompanying article bearing \nthe headline “How the Poll Was \nConducted.” The description \ntypically includes the sample \nsize, the margin of error, and the \nfollowing statement disclosing \nthat the confidence level is 95%: \n“In theory, in 19 cases out of 20, \noverall results based on such \nsamples will differ by no more \nthan. . . .” One recent report also \nprovided information that the poll \nincluded adults who were regis-\ntered to vote; landline telephone \nnumbers were randomly selected \nby a computer; cell phone num-\nbers were also randomly gener-\nated; and results were weighted \naccording to geographic region, \nsex, race, marital status, age, \nand education. The “How the Poll \nWas Conducted” descriptions \nare a model for all media who \nreport on polls.\ni l\nb\ni","page_start":305,"page_end":305,"token_count":242,"section_type":"other","chapter_number":7,"chapter_title":"ESTIMATING PARAMETERS AND DETERMINING SAMPLE SIZES","chunk_index":411}
{"chunk_id":"9b5d2e1d418647ae","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"288 \nCHAPTER 7 Estimating Parameters and Determining Sample Sizes\nDEFINITION\nWhen data from a simple random sample are used to estimate a population propor-\ntion p, the difference between the sample proportion pn and the population propor-\ntion p is an error. The maximum likely amount of that error is the margin of error, \ndenoted by E. There is a probability of 1 - a (such as 0.95) that the difference be-\ntween pn and p is E or less. The margin of error E is also called the maximum error \nof  the estimate and can be found by multiplying the critical value and the estimated \nstandard deviation of sample proportions, as shown in Formula 7-1.\nFORMULA 7-1\nE = za>2B\npnqn\nn  margin of error for proportions\nc \nc\nCritical value Estimated standard deviation of sample proportions\nConfidence Interval for Estimating a Population Proportion p\nObjective\nConstruct a confidence interval used to estimate a population proportion p.\nNotation\np =  population proportion\npn = sample proportion\nn = number of sample values\nE = margin of error\nza>2 =  critical value: the z score separating an area of a>2 \nin the right tail of the standard normal distribution\nKEY ELEMENTS\n1. The sample is a simple random sample.\n2. The conditions for the binomial distribution are satis-\nfied: There is a fixed number of trials, the trials are \nindependent, there are two categories of outcomes, and \nthe probabilities remain constant for each trial (as in \nSection 5-2).\n3. There are at least 5 successes and at least 5 failures. \n(This requirement is a way to verify that np Ú 5 and \nnq Ú 5, so the normal distribution is a suitable ap-\nproximation to the binomial distribution.)\nConfidence Interval Estimate of p\npn - E 6 p 6 pn + E  where  E = za>2B\npnqn\nn\nThe confidence interval is often expressed in the following two equivalent formats:\npn { E or \n1pn - E,  pn + E2\nRound-Off Rule for Confidence Interval Estimates of p\nRound the confidence interval limits for p to three significant digits.\nRequirements\nMargin of Error\nWe now formally define the margin of error E that we have all heard about so often in \nmedia reports.\n","page_start":306,"page_end":306,"token_count":509,"section_type":"other","chapter_number":7,"chapter_title":"ESTIMATING PARAMETERS AND DETERMINING SAMPLE SIZES","chunk_index":412}
{"chunk_id":"7cdabf6f5a604046","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"7-1 Estimating a Population Proportion \n289\nProcedure for Constructing a Confidence Interval for p\n1. Verify that the requirements in the preceding Key Elements box are satisfied.\n2. Use technology or Table A-2 to find the critical value za>2 that corresponds to \nthe desired confidence level.\n3. Evaluate the margin of error E = za>22pnqn>n.\n4. Using the value of the calculated margin of error E and the value of the sample \nproportion pn, find the values of the confidence interval limits pn - E and \npn + E. Substitute those values in the general format for the confidence interval.\n5. Round the resulting confidence interval limits to three significant digits.\nEXAMPLE 3  Constructing a Confidence Interval: Touch Therapy\nIn the Chapter Problem we noted that in an experiment with touch therapists, they \nmade correct responses in 123 of the 280 trials. The sample results are n = 280 and \npn = 123>280, or 0.439.\n \na. Find the margin of error E that corresponds to a 95% conﬁdence level.\n \nb. Find the 95% conﬁdence interval estimate of the population proportion p.\n \nc. Based on the results, can we safely conclude that the touch therapists had a \nsuccess rate equivalent to tossing a coin?\nSOLUTION\nREQUIREMENT CHECK (1) The experiment was examined and found to be sound, so \nwe will treat the results as simple random samples. (2) The conditions for a bino-\nmial experiment are satisfied, because there is a fixed number of trials (280), the \ntrials are independent (because the response from one touch therapist doesn’t affect \nthe probability of the response from another touch therapist), there are two catego-\nries of outcome (response was correct or incorrect), and the probability remains \nconstant and is not changing over time. (3) The number of successes (123 correct \nresponses) and the number of failures (157 incorrect responses) are both at least 5. \nThe check of requirements has been successfully completed. \nTechnology The confidence interval and margin of error can be easily found using \ntechnology. From the Statdisk display we can see the required entries on the left \nand the results displayed on the right. The results show that the margin of error is \nE = 0.0581 (rounded) and the confidence interval is 0.381 6 p 6 0.497 (round-\ned). (The Wilson score confidence interval included in the display will be discussed \nlater in Part 2 of this section.)\nStatdisk\ncontinued\n","page_start":307,"page_end":307,"token_count":546,"section_type":"other","chapter_number":7,"chapter_title":"ESTIMATING PARAMETERS AND DETERMINING SAMPLE SIZES","chunk_index":413}
{"chunk_id":"5d02e5212833e8ac","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"290 \nCHAPTER 7 Estimating Parameters and Determining Sample Sizes\nFinding the Point Estimate and E from a Confidence Interval\nSometimes we want to better understand a confidence interval that might have been \nobtained from a journal article or technology. If we already know the confidence inter-\nval limits, the sample proportion (or the best point estimate) pn and the margin of error \nE can be found as follows:\nPoint estimate of p: \npn = 1upper confidence interval limit2 + 1lower confidence interval limit2\n2\nMargin of error:\nE = 1upper confidence interval limit2 - 1lower confidence interval limit2\n2\nManual Calculation Here is how to find the confidence interval with manual cal-\nculations:\na. The margin of error is found by using Formula 7-1 with za>2 = 1.96 (as found \nin Example 2), pn = 0.439,  qn = 0.561, and n = 280.\nE = za>2 B\npnqn\nn = 1.96 B\n10.4392 10.5612\n280\n= 0.058129\n \nb. Constructing the conﬁdence interval is really easy now that we know that \npn = 0.439 and E = 0.058129. Simply substitute those values to obtain this \nresult:\n pn - E 6 p 6 pn + E\n 0.439 - 0.058129 6 p 6 0.439 + 0.058129\n 0.381 6 p 6 0.497 1rounded to three significant digits2\nThis same result could be expressed in the format of 0.439 { 0.058 or \n(0.381, 0.497). If we want the 95% conﬁdence interval for the true population \npercentage, we could express the result as 38.1% 6 p 6 49.7%.\n \nc. Based on the conﬁdence interval obtained in part (b), it appears that fewer \nthan 50% of the touch therapist responses are correct (because the interval of \nvalues from 0.381 to 0.497 is an interval that is completely below 0.50).\nEXAMPLE 4   Finding the Sample Proportion  \nand Margin of Error\nThe article “High-Dose Nicotine Patch Therapy,” by Dale, Hurt, et al. (Journal \nof the American Medical Association, Vol. 274, No. 17) includes this statement: \n “Of the 71 subjects, 70% were abstinent from smoking at 8 weeks (95% confidence \ninterval [CI], 58% to 81%).” Use that statement to find the point estimate pn and the \nmargin of error E.\n","page_start":308,"page_end":308,"token_count":596,"section_type":"other","chapter_number":7,"chapter_title":"ESTIMATING PARAMETERS AND DETERMINING SAMPLE SIZES","chunk_index":414}
{"chunk_id":"5fcf30cdefe64ef5","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"7-1 Estimating a Population Proportion \n291\nUsing Confidence Intervals for Hypothesis Tests\nA confidence interval can be used to informally address some claim made about a \npopulation proportion p. For example, if sample results consist of 70 girls in 100 \nbirths, the resulting 95% confidence interval of 0.610 6 p 6 0.790 can be used to \ninformally support a claim that the proportion of girls is different from 50% (because \n0.50 is not contained within the confidence interval).\nDetermining Sample Size\nIf we plan to collect sample data in order to estimate some population proportion, \nhow do we know how many sample units we must get? If we solve the formula for the \nmargin of error E (Formula 7-1) for the sample size n, we get Formula 7-2 that fol-\nlows. Formula 7-2 requires pn as an estimate of the population proportion p, but if no \nsuch estimate is known (as is often the case), we replace pn by 0.5 and replace qn by 0.5, \nwith the result given in Formula 7-3. Replacing pn and qn with 0.5 results in the largest \npossible sample size, so we are sure that the sample size is adequate for estimating p.\nSOLUTION\nWe get the 95% confidence interval of 0.58 6 p 6 0.81 from the given statement \nof “58% to 81%.” The point estimate pn is the value midway between the upper and \nlower confidence interval limits, so we get\n pn = 1upper confidence limit2 + 1lower confidence limit2\n2\n = 0.81 + 0.58\n2\n= 0.695\nThe margin of error can be found as follows:\n E = 1upper confidence limit2 - 1lower confidence limit2\n2\n = 0.81 - 0.58\n2\n= 0.115\nFinding the Sample Size Required to Estimate a Population Proportion\nObjective\nDetermine how large the sample size n should be in order to estimate the population proportion p.\nNotation\np = population proportion\npn = sample proportion\nn = number of sample values\nE = desired margin of error\nza>2 =  z score separating an area of a>2 in the right tail of the standard normal distribution\nKEY ELEMENTS\ncontinued\n","page_start":309,"page_end":309,"token_count":517,"section_type":"other","chapter_number":7,"chapter_title":"ESTIMATING PARAMETERS AND DETERMINING SAMPLE SIZES","chunk_index":415}
{"chunk_id":"f2130af02d861301","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"292 \nCHAPTER 7 Estimating Parameters and Determining Sample Sizes\nRequirements\nThe sample must be a simple random sample of independent sample units.\nWhen an estimate pn is known:  Formula 7-2  n =\n3za>242 pnqn\nE2\nWhen no estimate pn is known:  Formula 7-3  n =\n3za>242 0.25\nE2\nIf a reasonable estimate of pn can be made by using previous samples, a pilot study, or someone’s expert knowledge, use \nFormula 7-2. If nothing is known about the value of pn, use Formula 7-3.\nRound-Off Rule for Determining Sample Size\nIf the computed sample size n is not a whole number, round the value of n up to the next larger whole number, so the \nsample size is sufficient instead of being slightly insufficient. For example, round 384.16 to 385.\nEXAMPLE 5   What Percentage of Children Have Received \n Measles Vaccinations?\nIf we were to conduct a survey to determine the percentage of children (older than \n1 year) who have received measles vaccinations, how many children must be sur-\nveyed in order to be 95% confident that the sample percentage is in error by no \nmore than three percentage points?\n \na. Assume that a recent survey showed that 90% of children have received \nmeasles vaccinations.\n \nb. Assume that we have no prior information suggesting a possible value of the \npopulation proportion.\nSOLUTION\n \na. With a 95% conﬁdence level, we have a = 0.05, so za>2 = 1.96. Also, the \nmargin of error is E = 0.03, which is the decimal equivalent of “three per-\ncentage points.” The prior survey suggests that pn = 0.90, so qn = 0.10 (found \nfrom qn = 1 - 0.90). Because we have an estimated value of pn, we use \n Formula 7-2 as follows:\n n =\n3za>242 pnqn\nE2\n= 31.9642 10.90210.102\n0.032\n \n= 384.16 = 385 1rounded up2\n \n We must obtain a simple random sample that includes at least 385 children.\n \nb. With no prior knowledge of pn (or qn), we use Formula 7-3 as follows:\nn =\n3za>242 # 0.25\nE2\n= 31.9642 # 0.25\n0.032\n \n= 1067.11 = 1068 1rounded  up2\n \n We must obtain a simple random sample that includes at least 1068 children.\n","page_start":310,"page_end":310,"token_count":577,"section_type":"other","chapter_number":7,"chapter_title":"ESTIMATING PARAMETERS AND DETERMINING SAMPLE SIZES","chunk_index":416}
{"chunk_id":"fea5ef6276b83eac","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"7-1 Estimating a Population Proportion \n293\nRole of the Population Size N Formulas 7-2 and 7-3 are remarkable because they \nshow that the sample size does not depend on the size (N) of the population; the \nsample size depends on the desired confidence level, the desired margin of error, and \nsometimes the known estimate of pn. (See Exercise 37 for dealing with cases in which \na relatively large sample is selected without replacement from a finite population, so \nthe sample size n does depend on the population size N.)\nPART 2\nBetter-Performing Confidence Intervals \nDisadvantage of Wald Confidence Interval\nCoverage Probability The coverage probability of a confidence interval is the ac-\ntual proportion of such confidence intervals that contain the true population propor-\ntion. If we select a specific confidence level, such as 0.95 (or 95%), we would like to \nget the actual coverage probability equal to our desired confidence level. However, for \nthe confidence interval described in Part 1 (called a “Wald confidence interval”), the \nactual coverage probability is usually less than or equal to the confidence level that we \nselect, and it could be substantially less. For example, if we select a 95% confidence \nlevel, we usually get 95% or fewer of confidence intervals containing the population \nproportion p. (This is sometimes referred to as being “too liberal.”) For this reason, \nthe Wald confidence interval is rarely used in professional applications and profes-\nsional journals.\nBetter-Performing Confidence Intervals\nImportant note about exercises: Except for some Beyond the Basics exercises, the \nexercises for this Section 7-1 are based on the method for constructing a Wald con-\nfidence interval as described in Part 1, not the confidence intervals described here. It \nis recommended that students learn the methods presented earlier, but recognize that \nthere are better methods available, and they can be used with suitable technology.\nINTERPRETATION\nTo be 95% confident that our sample percentage is within three percentage points \nof the true percentage for all children, we should obtain a simple random sample of \n1068 children, assuming no prior knowledge. By comparing this result to the sam-\nple size of 385 found in part (a), we can see that if we have no knowledge of a prior \nstudy, a larger sample is required to achieve the same results compared to when the \nvalue of pn can be estimated.\nCAUTION Try to avoid these three common errors when calculating sample size:\n1.  Don’t make the mistake of using E = 3 as the margin of error corresponding to \n“three percentage points.” If the margin of error is three percentage points, use \nE = 0.03.\n2.  Be sure to substitute the critical z score for za>2. For example, when working with \n95% conﬁdence, be sure to replace za>2 with 1.96. Don’t make the mistake of \nreplacing za>2 with 0.95 or 0.05.\n3.  Be sure to round up to the next higher integer; don’t round oﬀ using the usual \nround-oﬀ rules. Round 1067.11to 1068.\n","page_start":311,"page_end":311,"token_count":682,"section_type":"other","chapter_number":7,"chapter_title":"ESTIMATING PARAMETERS AND DETERMINING SAMPLE SIZES","chunk_index":417}
{"chunk_id":"ff79ad52ce523f85","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"294 \nCHAPTER 7 Estimating Parameters and Determining Sample Sizes\nPlus Four Method The plus four confidence interval performs better than the Wald \nconfidence interval in the sense that its coverage probability is closer to the confi-\ndence level that is used. The plus four confidence interval uses this very simple pro-\ncedure: Add 2 to the number of successes x, add 2 to the number of failures (so that \nthe number of trials n is increased by 4), and then find the Wald confidence interval \nas described in Part 1 of this section. The plus four confidence interval is very easy to \ncalculate and it has coverage probabilities similar to those for the Wilson score confi-\ndence interval that follows.\nWilson Score Another confidence interval that performs better than the Wald CI is \nthe Wilson score confidence interval:\n pn +\nz2\na>2\n2n { za>2 B\npnqn +\nz2\na>2\n4n\nn\n1 +\nz2\na>2\nn\nThe Wilson score confidence interval performs better than the Wald CI in the sense \nthat the coverage probability is closer to the confidence level. With a confidence level \nof 95%, the Wilson score confidence interval would get us closer to a 0.95 probability \nof containing the parameter p. The complexity of the above expression can be circum-\nvented by using some technologies, such as Statdisk or XLSTAT, that provide Wilson \nscore confidence interval results.\nClopper-Pearson Method The Clopper-Pearson method is an “exact” method in \nthe sense that it is based on the exact binomial distribution instead of an approxima-\ntion of a distribution. It is criticized for being too conservative in this sense: When we \nselect a specific confidence level, the coverage probability is usually greater than or \nequal to the selected confidence level. Select a confidence level of 0.95, and the actual \ncoverage probability is usually 0.95 or greater, so that 95% or more of such confidence \nintervals will contain p. Calculations with this method are too messy to consider here.\nWhich Method Is Best? There are other methods for constructing confidence inter-\nvals that are not discussed here. There isn’t universal agreement on which method is \nbest for constructing a confidence interval estimate of p.\n \n■The Wald confidence interval is best as a teaching tool for introducing students \nto confidence intervals.\n \n■The plus four confidence interval is almost as easy as Wald and it performs bet-\nter than Wald by having a coverage probability closer to the selected confidence \nlevel.\nAgain, note that except for some Beyond the Basic exercises, the exercises that fol-\nlow are based on the Wald confidence interval given earlier, not the better-performing \nconfidence intervals discussed here.\nProportions: Confidence Intervals & Sample Size Determination\nAccess tech instructions, videos, and data sets at www.TriolaStats.com\nTECH CENTER \n","page_start":312,"page_end":312,"token_count":603,"section_type":"other","chapter_number":7,"chapter_title":"ESTIMATING PARAMETERS AND DETERMINING SAMPLE SIZES","chunk_index":418}
{"chunk_id":"8927c05f877c91b1","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"7-1 Estimating a Population Proportion \n295\nStatistical Literacy and Critical Thinking\n1. Reporting Results Here is a result stated in a format commonly used in the media: “In a \nclinical trial of 227 subjects treated with OxyContin (oxycodone), 13% of the subjects reported \ndizziness. The margin of error is {4 percentage points.” What important feature of the poll is \nomitted?\n2. Margin of Error For the poll described in Exercise 1, describe what is meant by the state-\nment that “the margin of error was given as {4 percentage points.”\n3. Notation For the poll described in Exercise 1, what values do pn, qn, n, E, and p represent? If \nthe confidence level is 95%, what is the value of a?\n4. Confidence Levels Given specific sample data, such as the data given in Exercise 1, which \nconfidence interval is wider: the 95% confidence interval or the 80% confidence interval? Why \nis it wider?\nFinding Critical Values. In Exercises 5–8, find the critical value zA, 2 that corresponds to \nthe given confidence level.\n5. 90%   6. 99%   7. 99.5%   8. 98%\nFormats of Confidence Intervals. In Exercises 9–12, express the confidence interval us-\ning the indicated format. (The confidence intervals are based on proportions of eye colors.)\n9. Brown Eyes Express 0.375 6  p 6 0.425 in the form of pn { E.\n10. Blue Eyes Express 0.275 6  p 6 0.425 in the form of pn { E.\n11. Green Eyes Express the confidence interval (0.0780, 0.162) in the form of \npn - E 6 p 6 pn + E.\n12. Gray Eyes Express the confidence interval 0.070 { 0.021 in the form of \npn - E 6 p 6 pn + E.\nConstructing and Interpreting Confidence Intervals. In Exercises 13–16, use the \ngiven sample data and confidence level. In each case, (a) find the best point estimate of the \npopulation proportion p; (b) identify the value of the margin of error E; (c) construct the \nconfidence interval; (d) write a statement that correctly interprets the confidence interval.\n13. OxyContin In a clinical trial of OxyContin (oxycodone), 16 subjects experienced head-\naches among the 227 subjects treated with OxyContin. Construct a 95% confidence interval for \nthe proportion of treated subjects who experience headaches.\n14. Eliquis The drug Eliquis (apixaban) is used to help prevent blood clots in certain patients. \nIn clinical trials, among 5924 patients treated with Eliquis, 153 developed the adverse reaction \nof nausea (based on data from Bristol-Myers Squibb Co.). Construct a 99% confidence interval \nfor the proportion of adverse reactions.","page_start":313,"page_end":313,"token_count":651,"section_type":"other","chapter_number":7,"chapter_title":"ESTIMATING PARAMETERS AND DETERMINING SAMPLE SIZES","chunk_index":419}
{"chunk_id":"b354d28ab64794b5","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"the proportion of treated subjects who experience headaches.\n14. Eliquis The drug Eliquis (apixaban) is used to help prevent blood clots in certain patients. \nIn clinical trials, among 5924 patients treated with Eliquis, 153 developed the adverse reaction \nof nausea (based on data from Bristol-Myers Squibb Co.). Construct a 99% confidence interval \nfor the proportion of adverse reactions.\n15. Survey Return Rate In a study of cell phone use and brain hemispheric dominance, an \nInternet survey was e-mailed to 5000 subjects randomly selected from an online group whose \nfocus is related to ears. 717 surveys were returned. Construct a 90% confidence interval for the \nproportion of returned surveys.\n16. Medical Malpractice In a study of 1228 randomly selected medical malpractice lawsuits, \nit was found that 856 of them were dropped or dismissed (based on data from the Physicians \nInsurers Association of America). Construct a 95% confidence interval for the proportion of \nmedical malpractice lawsuits that are dropped or dismissed.\n7-1 Basic Skills and Concepts ","page_start":313,"page_end":313,"token_count":231,"section_type":"other","chapter_number":7,"chapter_title":"ESTIMATING PARAMETERS AND DETERMINING SAMPLE SIZES","chunk_index":420}
{"chunk_id":"8b5c305f232a67cf","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"296 \nCHAPTER 7 Estimating Parameters and Determining Sample Sizes\nCritical Thinking. In Exercises 17–28, use the data and confidence level to construct a \nconfidence interval estimate of p, then address the given question.\n17. Births A random sample of 860 births in New York State included 426 boys. Construct \na 95% confidence interval estimate of the proportion of boys in all births. It is believed that \namong all births, the proportion of boys is 0.512. Do these sample results provide strong evi-\ndence against that belief?\n18. Mendelian Genetics One of Mendel’s famous genetics experiments yielded 580 peas, \nwith 428 of them green and 152 yellow.\na. Find a 99% confidence interval estimate of the percentage of green peas.\nb. Based on his theory of genetics, Mendel expected that 75% of the offspring peas would be \ngreen. Given that the percentage of offspring green peas is not 75%, do the results contradict \nMendel’s theory? Why or why not?\n19. OxyContin The drug OxyContin (oxycodone) is used to treat pain, but it is danger-\nous because it is addictive and can be lethal. In clinical trials, 227 subjects were treated with \n OxyContin and 52 of them developed nausea (based on data from Purdue Pharma L.P.).\na. Construct a 95% confidence interval estimate of the percentage of OxyContin users who \ndevelop nausea.\nb. Compare the result from part (a) to this 95% confidence interval for 5 subjects who developed \nnausea among the 45 subjects given a placebo instead of OxyContin: 1.93% 6 p 6 20.3%.\nWhat do you conclude?\n20. Medication Usage In a survey of 3005 adults aged 57 through 85 years, it was found that \n81.7% of them used at least one prescription medication (based on data from “Use of Prescrip-\ntion and Over-the-Counter Medications and Dietary Supplements Among Older Adults in the \nUnited States,” by Qato et al., Journal of the American Medical Association, Vol. 300, No. 24).\na. How many of the 3005 subjects used at least one prescription medication?\nb. Construct a 90% confidence interval estimate of the percentage of adults aged 57 through \n85 years who use at least one prescription medication.\nc. What do the results tell us about the proportion of college students who use at least one \n prescription medication?\n21. Cell Phones and Cancer A study of 420,095 Danish cell phone users found that 0.0321% \nof them developed cancer of the brain or nervous system. Prior to this study of cell phone use, \nthe rate of such cancer was found to be 0.0340% for those not using cell phones. The data are \nfrom the Journal of the National Cancer Institute.\na. Use the sample data to construct a 90% confidence interval estimate of the percentage of cell \nphone users who develop cancer of the brain or nervous system.","page_start":314,"page_end":314,"token_count":652,"section_type":"other","chapter_number":7,"chapter_title":"ESTIMATING PARAMETERS AND DETERMINING SAMPLE SIZES","chunk_index":421}
{"chunk_id":"d4bbfa1097fb1750","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"of them developed cancer of the brain or nervous system. Prior to this study of cell phone use, \nthe rate of such cancer was found to be 0.0340% for those not using cell phones. The data are \nfrom the Journal of the National Cancer Institute.\na. Use the sample data to construct a 90% confidence interval estimate of the percentage of cell \nphone users who develop cancer of the brain or nervous system.\nb. Do cell phone users appear to have a rate of cancer of the brain or nervous system that is dif-\nferent from the rate of such cancer among those not using cell phones? Why or why not?\n22. Lipitor In clinical trials of the drug Lipitor (atorvastatin), 270 subjects were given a pla-\ncebo and 7 of them had allergic reactions. Among 863 subjects treated with 10 mg of the drug, \n8 experienced allergic reactions. Construct the two 95% confidence interval estimates of the \npercentages of allergic reactions. Compare the results. What do you conclude?\n23. Gender Selection Before its clinical trials were discontinued, the Genetics & IVF In-\nstitute conducted a clinical trial of the XSORT method designed to increase the probability of \nconceiving a girl and, among the 945 babies born to parents using the XSORT method, there \nwere 879 girls. Construct the 95% confidence interval estimate of the percentage of success. \nWhat do you conclude?","page_start":314,"page_end":314,"token_count":297,"section_type":"other","chapter_number":7,"chapter_title":"ESTIMATING PARAMETERS AND DETERMINING SAMPLE SIZES","chunk_index":422}
{"chunk_id":"fb68c66521042131","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"7-1 Estimating a Population Proportion \n297\n 24. Gender Selection Before its clinical trials were discontinued, the Genetics & IVF In-\nstitute conducted a clinical trial of the YSORT method designed to increase the probability of \nconceiving a boy and, among the 291 babies born to parents using the YSORT method, there \nwere 239 boys. What do you conclude?\n25. Postponing Death An interesting hypothesis is that individuals can temporarily postpone \ntheir death to survive a major holiday or important event such as a birthday. In a study of this \nphenomenon, it was found that in the week before and the week after Thanksgiving, there were \n12,000 total deaths, and 6062 of them occurred in the week before Thanksgiving (based on data \nfrom “Holidays, Birthdays, and Postponement of Cancer Death,” by Young and Hade, Journal \nof the American Medical Association, Vol. 292, No. 24.) Construct a 95% confidence interval \nestimate of the proportion of number of deaths in the week before Thanksgiving to the total \ndeaths in the week before and the week after Thanksgiving. Based on the result, does there \nappear to be any indication that people can temporarily postpone their death to survive the \nThanksgiving holiday? Why or why not?\n26. Cloning Survey A Gallup poll included 1012 randomly selected adults who were asked \nwhether “cloning of humans should or should not be allowed.” Results showed that 901 of \nthose surveyed indicated that cloning should not be allowed. A news reporter wants to deter-\nmine whether these survey results constitute strong evidence that the majority (more than 50%) \nof people are opposed to such cloning. Construct a 99% confidence interval estimate of the \nproportion of adults believing that cloning of humans should not be allowed. Is there strong \nevidence supporting the claim that the majority is opposed to such cloning?\n27. Smoking Cessation In a program designed to help patients stop smoking, 198 patients \nwere given sustained care, and 82.8% of them were no longer smoking after one month. Among \n199 patients given standard care, 62.8% were no longer smoking after one month (based on \ndata from “Sustained Care Intervention and Postdischarge Smoking Cessation Among Hospi-\ntalized Adults,” by Rigotti et al., Journal of the American Medical Association, Vol. 312, No. \n7). Construct the two 95% confidence interval estimates of the percentages of success. Com-\npare the results. What do you conclude?\n28. Measured Results vs. Reported Results The same study cited in the preceding exer-\ncise produced these results after six months for the 198 patients given sustained care: 25.8% \nwere no longer smoking, and these results were biochemically confirmed, but 40.9% of these \npatients reported that they were no longer smoking. Construct the two 95% confidence inter-\nvals. Compare the results. What do you conclude?\nDetermining Sample Size. In Exercises 29–36, use the given data to find the minimum \nsample size required to estimate a population proportion or percentage.","page_start":315,"page_end":315,"token_count":660,"section_type":"other","chapter_number":7,"chapter_title":"ESTIMATING PARAMETERS AND DETERMINING SAMPLE SIZES","chunk_index":423}
{"chunk_id":"edbd6ae85de47505","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"were no longer smoking, and these results were biochemically confirmed, but 40.9% of these \npatients reported that they were no longer smoking. Construct the two 95% confidence inter-\nvals. Compare the results. What do you conclude?\nDetermining Sample Size. In Exercises 29–36, use the given data to find the minimum \nsample size required to estimate a population proportion or percentage.\n29. Lefties Find the sample size needed to estimate the percentage of California residents who \nare left-handed. Use a margin of error of three percentage points, and use a confidence level of \n99%.\na. Assume that pn and qn are unknown.\nb. Assume that based on prior studies, about 10% of Californians are left-handed.\nc. How do the results from parts (a) and (b) change if the entire United States is used instead \nof California?\n30. Chickenpox You plan to conduct a survey to estimate the percentage of adults who have \nhad chickenpox. Find the number of people who must be surveyed if you want to be 90% con-\nfident that the sample percentage is within two percentage points of the true percentage for the \npopulation of all adults.\na. Assume that nothing is known about the prevalence of chickenpox.\nb. Assume that about 95% of adults have had chickenpox.\nc. Does the added knowledge in part (b) have much of an effect on the sample size?","page_start":315,"page_end":315,"token_count":304,"section_type":"other","chapter_number":7,"chapter_title":"ESTIMATING PARAMETERS AND DETERMINING SAMPLE SIZES","chunk_index":424}
{"chunk_id":"0c7d23b47889f23b","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"298 \nCHAPTER 7 Estimating Parameters and Determining Sample Sizes\n 31. Bachelor’s Degree in Four Years In a study of government financial aid for college stu-\ndents, it becomes necessary to estimate the percentage of full-time college students who earn a \nbachelor’s degree in four years or less. Find the sample size needed to estimate that percentage. \nUse a 0.05 margin of error, and use a confidence level of 95%.\na. Assume that nothing is known about the percentage to be estimated.\nb. Assume that prior studies have shown that about 40% of full-time students earn bachelor’s \ndegrees in four years or less.\nc. Does the added knowledge in part (b) have much of an effect on the sample size?\n32. Astrology A sociologist plans to conduct a survey to estimate the percentage of health \ncare professionals who believe in astrology. How many health care professionals must be sur-\nveyed if we want a confidence level of 99% and a margin of error of four percentage points?\na. Assume that nothing is known about the percentage to be estimated.\nb. Use the information from a previous Harris survey in which 26% of respondents said that \nthey believed in astrology.\n33. Biometric Security In considering the use of biometric security (such as fingerprints) to \nreplace passwords, you want to estimate the percentage of adults who believe that passwords \nshould be replaced with biometric security. How many randomly selected adults must you sur-\nvey? Assume that you want to be 95% confident that the sample percentage is within 2.5 per-\ncentage points of the true population percentage.\na. Assume that nothing is known about the percentage of adults who believe that passwords \nshould be replaced with biometric security.\nb. Assume that a prior survey suggests that about 53% of adults believe that biometric security \nshould replace passwords (based on a USA Today report).\nc. Does the additional survey information from part (b) have much of an effect on the sample \nsize that is required?\n 34. Nicotine Patches You plan to conduct a clinical trial to test the effectiveness of nicotine \npatch therapy in helping smokers to stop smoking. How many smokers must be included in \norder to be 99% confident that the estimate is in error by no more than two percentage points?\na. Assume that nothing is known about the effectiveness of nicotine patch therapy.\nb. Assume that a prior clinical trial suggests that nicotine patch therapy has a success rate of \nabout 45% (based on data from “High-Dose Nicotine Patch Therapy,” by Dale et al., Journal of \nthe American Medical Association, Vol. 274, No. 17).\nc. Does the additional survey information from part (b) have much of an effect on the sample \nsize that is required?\n 35. Vision Correction A manufacturing company is considering entering the new market of \neyeglasses. How many people must be surveyed in order to be 90% confident that the estimated \npercentage of adults who wear eyeglasses is within three percentage points of the true popula-\ntion percentage?\na. Assume that nothing is known about the percentage of adults who wear eyeglasses.","page_start":316,"page_end":316,"token_count":659,"section_type":"other","chapter_number":7,"chapter_title":"ESTIMATING PARAMETERS AND DETERMINING SAMPLE SIZES","chunk_index":425}
{"chunk_id":"ad0b3a8d6d19b62f","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"size that is required?\n 35. Vision Correction A manufacturing company is considering entering the new market of \neyeglasses. How many people must be surveyed in order to be 90% confident that the estimated \npercentage of adults who wear eyeglasses is within three percentage points of the true popula-\ntion percentage?\na. Assume that nothing is known about the percentage of adults who wear eyeglasses.\nb. Assume that about 53% of adults wear eyeglasses (based on a Vision Council prior survey).\nc. Given that the required sample size is relatively small, could you simply survey the adults \nthat you know?\n36. Women Who Give Birth An epidemiologist plans to conduct a survey to estimate the \npercentage of women who give birth. How many women must be surveyed in order to be 99% \nconfident that the estimated percentage is in error by no more than two percentage points?\na. Assume that nothing is known about the percentage to be estimated.\ncontinued","page_start":316,"page_end":316,"token_count":200,"section_type":"other","chapter_number":7,"chapter_title":"ESTIMATING PARAMETERS AND DETERMINING SAMPLE SIZES","chunk_index":426}
{"chunk_id":"3d3a91a131f38a15","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"7-2 Estimating a Population Mean \n299\nb. Assume that a prior study conducted by the U.S. Census Bureau showed that 82% of women \ngive birth.\nc. What is wrong with surveying randomly selected adult women?\n37. Finite Population Correction Factor For Formulas 7-2 and 7-3 we assume that the pop-\nulation is infinite or very large and that we are sampling with replacement. When we sample \nwithout replacement from a relatively small population with size N, we modify E to include \nthe finite population correction factor shown here, and we can solve for n to obtain the result \nshown below. Use this result to repeat part (b) of Exercise 36, assuming that we limit our popu-\nlation to a county with 2500 women who have completed the time during which they can give \nbirth.\nE = za>2 B\npnqn\nn\n B\nN - n\nN - 1   n =\nNpnqn3za>242\npnqn 3za>242 + 1N - 12E2\n38. One-Sided Confidence Interval A one-sided claim about a population proportion is a \nclaim that the proportion is less than (or greater than) some specific value. Such a claim can \nbe formally addressed using a one-sided confidence interval for p, which can be expressed as \np 6 pn + E or p 7 pn - E, where the margin of error E is modified by replacing za>2 with \nza. (Instead of dividing a between two tails of the standard normal distribution, put all of it in \none tail.) Use the data given in Exercise 13 “OxyContin” to construct a one-sided 95% confi-\ndence interval that would be suitable for addressing the claim that the rate of headaches among \n OxyContin users is less than 10%.\n39. Coping with No Success According to the Rule of Three, when we have a sample size \nn with x = 0 successes, we have 95% confidence that the true population proportion has an \nupper bound of 3>n. (See “A Look at the Rule of Three,” by Jovanovic and Levy, American \nStatistician, Vol. 51, No. 2.)\na. If n independent trials result in no successes, why can’t we find confidence interval limits by \nusing the methods described in this section?\nb. If 40 couples use a method of gender selection and each couple has a baby girl, what is the \n95% upper bound for p, the proportion of all babies who are boys?\n7-1 Beyond the Basics \nKey Concept The main goal of this section is to present methods for using a sample \nmean x to make an inference about the value of the corresponding population mean m.\nThere are three main concepts included in this section:\n■Point Estimate: The sample mean x is the best point estimate (or single value \nestimate) of the population mean m.\n■Confidence Interval: Use sample data to construct and interpret a confidence \ninterval estimate of the true value of a population mean m.\n■Sample Size: Find the sample size necessary to estimate a population mean.","page_start":317,"page_end":317,"token_count":659,"section_type":"other","chapter_number":7,"chapter_title":"ESTIMATING PARAMETERS AND DETERMINING SAMPLE SIZES","chunk_index":427}
{"chunk_id":"56d1b280d21bccea","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"mean x to make an inference about the value of the corresponding population mean m.\nThere are three main concepts included in this section:\n■Point Estimate: The sample mean x is the best point estimate (or single value \nestimate) of the population mean m.\n■Confidence Interval: Use sample data to construct and interpret a confidence \ninterval estimate of the true value of a population mean m.\n■Sample Size: Find the sample size necessary to estimate a population mean.\nPart 1 of this section deals with the very realistic and commonly used case in which \nwe want to estimate m and the population standard deviation s is not known. Part 2 \nincludes a brief discussion of the procedure used when s is known, which is very rare.\n7-2 \nEstimating a Population Mean","page_start":317,"page_end":317,"token_count":158,"section_type":"other","chapter_number":7,"chapter_title":"ESTIMATING PARAMETERS AND DETERMINING SAMPLE SIZES","chunk_index":428}
{"chunk_id":"61cd335aa7aa0e7c","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"300 \nCHAPTER 7 Estimating Parameters and Determining Sample Sizes\nPART 1\nEstimating a Population Mean When S\nIs Not Known \nIt’s rare that we want to estimate the unknown value of a population mean m but we \nsomehow know the value of the population standard deviation s, so Part 1 focuses on \nthe realistic situation in which s is not known.\nPoint Estimate As discussed in Section 6-3, the sample mean x is an unbiased es-\ntimator of the population mean m. Also, for many populations, sample means tend to \nvary less than other measures of center. For these reasons, the sample mean x is usu-\nally the best point estimate of the population mean m.\nThe sample mean x is the best point estimate of the population mean M.\nBecause even the best point estimate gives us no indication of how accurate it is, we \nuse a confidence interval (or interval estimate), which consists of a range (or an inter-\nval) of values instead of just a single value.\nConfidence Interval The accompanying Key Elements box includes the key ele-\nments for constructing a confidence interval estimate of a population mean m in the \ncommon situation where s is not known.\nConfidence Interval for Estimating a Population Mean with s Not Known\nObjective\nConstruct a confidence interval used to estimate a population mean.\nNotation\nm = population mean \nn = number of sample values\nx = sample mean \nE = margin of error\ns = sample standard deviation\nRequirements\nKEY ELEMENTS\n1. The sample is a simple random sample.\n2. Either or both of these conditions are satisfied: The \npopulation is normally distributed or n 7 30.\nConfidence Interval\nFormats: x - E 6 m 6 x + E  or  x { E  or  \n1x - E, x + E2\n • Margin of Error: E = ta>2 #\ns\n1n (Use df = n - 1.)\n • Confidence Level: The confidence interval is associ-\nated with a confidence level, such as 0.95 (or 95%), \nand a is the complement of the confidence level. For \na 0.95 (or 95%) confidence level, a = 0.05.\n • Critical Value: ta>2 is the critical t value separating an \narea of a>2 in the right tail of the Student t distribution.\n • Degrees of Freedom: df = n - 1 is the number of \ndegrees of freedom. Used when finding the critical \nvalue.\nRound-Off Rule\n1. Original Data: When using an original set of data val-\nues, round the confidence interval limits to one more \ndecimal place than is used for the original set of data.\n2. Summary Statistics: When using the summary statistics \nof n, x, and s, round the confidence interval limits to the \nsame number of decimal places used for the sample mean.\n","page_start":318,"page_end":318,"token_count":603,"section_type":"other","chapter_number":7,"chapter_title":"ESTIMATING PARAMETERS AND DETERMINING SAMPLE SIZES","chunk_index":429}
{"chunk_id":"157e410c574dcb3c","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"7-2 Estimating a Population Mean \n301\nRequirement of “Normality or n + 30”\nNormality The method for finding a confidence interval estimate of m is robust \nagainst a departure from normality, which means that the normality requirement is \nloose. The distribution need not be perfectly bell-shaped, but it should appear to be \nsomewhat symmetric with one mode and no outliers.\nSample Size n + 30 This is a common guideline, but sample sizes of 15 to 30 are \nadequate if the population appears to have a distribution that is not far from being \nnormal and there are no outliers. For some population distributions that are extremely \nfar from normal, the sample size might need to be larger than 30. This text uses the \nsimplified criterion of n 7 30 as justification for treating the distribution of sample \nmeans as a normal distribution.\nStudent t Distribution\nIn this section we use a Student t distribution, which is commonly referred to as a t distri-\nbution. It was developed by William Gosset (1876–1937), who was a Guinness Brewery \nemployee who needed a distribution that could be used with small samples. The brewery \nprohibited publication of research results, but Gosset got around this by publishing under \nthe pseudonym “Student.” Here are some key points about the Student t distribution:\n■Student t Distribution If a population has a normal distribution, then the distri-\nbution of\nt = x - m\ns\n1n\nis a Student t distribution for all samples of size n. A Student t distribution is \ncommonly referred to as a t distribution.\n■Degrees of Freedom Finding a critical value ta>2 requires a value for the degrees \nof freedom (or df). In general, the number of degrees of freedom for a collection \nof sample data is the number of sample values that can vary after certain restric-\ntions have been imposed on all data values. (Example: If 10 test scores have the \nrestriction that their mean is 80, then their sum must be 800, and we can freely \nassign values to the first 9 scores, but the 10th score would then be determined, \nso in this case there are 9 degrees of freedom.) For the methods of this section, \nthe number of degrees of freedom is the sample size minus 1.\nDegrees of freedom = n −1\n■Finding Critical Value tA,2 A critical value ta>2 can be found using technology \nor Table A-3. Technology can be used with any number of degrees of freedom, \nbut Table A-3 can be used for select numbers of degrees of freedom only. If using \nTable A-3 to find a critical value of ta>2, but the table does not include the exact \nnumber of degrees of freedom, you could use the closest value, or you could be \nconservative by using the next lower number of degrees of freedom found in the \ntable, or you could interpolate.\n■The Student t distribution is different for different sample sizes. (See Figure 7-4 \non the next page for the cases n = 3 and n = 12.)","page_start":319,"page_end":319,"token_count":658,"section_type":"other","chapter_number":7,"chapter_title":"ESTIMATING PARAMETERS AND DETERMINING SAMPLE SIZES","chunk_index":430}
{"chunk_id":"52454e2349c6194a","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"number of degrees of freedom, you could use the closest value, or you could be \nconservative by using the next lower number of degrees of freedom found in the \ntable, or you could interpolate.\n■The Student t distribution is different for different sample sizes. (See Figure 7-4 \non the next page for the cases n = 3 and n = 12.)\n■The Student t distribution has the same general symmetric bell shape as the stan-\ndard normal distribution, but has more variability (with wider distributions), as \nwe expect with small samples.\n■The Student t distribution has a mean of t = 0 (just as the standard normal distri-\nbution has a mean of z = 0).\nst\nis\nbe \nre\nEstimating Wildlife \nPopulation Sizes\nThe National \nForest Man-\nagement \nAct protects \nendangered \nspecies, includ-\ning the northern \nspotted owl, \nwith the result that the for-\nestry industry was not allowed \nto cut vast regions of trees in \nthe Pacific Northwest. Biologists \nand statisticians were asked to \nanalyze the problem, and they \nconcluded that survival rates and \npopulation sizes were decreas-\ning for the female owls, known to \nplay an important role in species \nsurvival. Biologists and statisti-\ncians also studied salmon in the \nSnake and Columbia rivers in \nWashington State, and penguins \nin New Zealand. In the article \n“Sampling Wildlife Popula-\ntions” (Chance, Vol. 9, No. 2), \nauthors Bryan Manly and Lyman \nMcDonald comment that in such \nstudies, “biologists gain through \nthe use of modeling skills that are \nthe hallmark of good statistics. \nStatisticians gain by being intro-\nduced to the reality of problems \nby biologists who know what the \ncrucial issues are.”","page_start":319,"page_end":319,"token_count":394,"section_type":"other","chapter_number":7,"chapter_title":"ESTIMATING PARAMETERS AND DETERMINING SAMPLE SIZES","chunk_index":431}
{"chunk_id":"43d09c2aa39843ea","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"302 \nCHAPTER 7 Estimating Parameters and Determining Sample Sizes\n \n■The standard deviation of the Student t distribution varies with the sample size, \nbut it is greater than 1 (unlike the standard normal distribution, which has s = 1).\n \n■As the sample size n gets larger, the Student t distribution gets closer to the stan-\ndard normal distribution.\n0\nStandard\nnormal\ndistribution\nStudent t\ndistribution\nwith n 5 12\nStudent t\ndistribution\nwith n 5 3\nFIGURE 7-4 Student t Distributions for n = 3 and n = 12\nThe Student t distribution has the same general shape and \nsymmetry as the standard normal distribution, but it has the \ngreater variability that is expected with small samples.\nProcedure for Constructing a Confidence Interval for M\nConfidence intervals can be easily constructed with technology or they can be manu-\nally constructed by using the following procedure.\n1. Verify that the two requirements are satisfied: The sample is a simple random \nsample and the population is normally distributed or n 7 30.\n2. With s unknown (as is usually the case), use n - 1 degrees of freedom and use \ntechnology or a t distribution table (such as Table A-3) to find the critical value \nta>2 that corresponds to the desired confidence level.\n3. Evaluate the margin of error using E = ta>2 # s> 1n.\n4. Using the value of the calculated margin of error E and the value of the sample \nmean x, substitute those values in one of the formats for the confidence inter-\nval: x - E 6 m 6 x + E or x { E or \n1x - E, x + E2.\n5. Round the resulting confidence interval limits as follows: With an original \nset of data values, round the confidence interval limits to one more decimal \nplace than is used for the original set of data, but when using the summary \nstatistics of n, x, and s, round the confidence interval limits to the same \nnumber of decimal places used for the sample mean.\nEXAMPLE 1  Finding a Critical Value tA,2\nFind the critical value ta>2 corresponding to a 95% confidence level given that the \nsample has size n = 15.\nSOLUTION\nBecause n = 15, the number of degrees of freedom is n - 1 = 14. The 95% confi-\ndence level corresponds to a = 0.05, so there is an area of 0.025 in each of the two \ntails of the t distribution, as shown in Figure 7-5.\ncontinued\n","page_start":320,"page_end":320,"token_count":557,"section_type":"other","chapter_number":7,"chapter_title":"ESTIMATING PARAMETERS AND DETERMINING SAMPLE SIZES","chunk_index":432}
{"chunk_id":"fe2eaf454f12c29e","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"7-2 Estimating a Population Mean \n303\nUsing Technology Technology can be used to find that for 14 degrees of freedom \nand an area of 0.025 in each tail, the critical value is ta>2 = t0.025 = 2.145.\nUsing Table A-3 To find the critical value using Table A-3, use the column with \n0.05 for the “Area in Two Tails” (or use the same column with 0.025 for the “Area \nin One Tail”). The number of degrees of freedom is df = n - 1 = 14. We get \nta>2 = t0.025 = 2.145.\nt 5 0\nta/2 5 2.145\n 0.025\n 0.025\nFIGURE 7-5 Critical Value tA,2\nEXAMPLE 2  Confidence Interval Using Birth Weights\nListed below are weights (hectograms, or hg) of randomly selected girls at birth, \nbased on data from the National Center for Health Statistics. Here are the summary \nstatistics: n = 15, x = 30.9 hg, s = 2.9 hg. Use the sample data to construct a \n95% confidence interval for the mean birth weight of girls.\n33 28 33 37 31 32 31 28 34 28 33 26 30 31 28\nSOLUTION\nREQUIREMENT CHECK We must first verify that the requirements are satisfied.  \n(1) The sample is a simple random sample. (2) Because the sample size is n = 15, \nthe requirement that “the population is normally distributed or the sample size is \ngreater than 30” can be satisfied only if the sample data appear to be from a  \nnormally distributed population, so we need to investigate normality. The accompa-\nnying normal quantile plot shows that the sample data appear to be from a normally \ndistributed population, so this second requirement is satisfied. \ncontinued\n","page_start":321,"page_end":321,"token_count":428,"section_type":"other","chapter_number":7,"chapter_title":"ESTIMATING PARAMETERS AND DETERMINING SAMPLE SIZES","chunk_index":433}
{"chunk_id":"c2a2373d832e2a34","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"304 \nCHAPTER 7 Estimating Parameters and Determining Sample Sizes\nInterpreting the Confidence Interval The confidence interval is associated with \na confidence level, such as 0.95 (or 95%). When interpreting a confidence interval \nestimate of μ, know that the confidence level gives us the success rate of the procedure \nused to construct the confidence interval. For example, the 95% confidence interval \nestimate of 29.2 hg 6 m 6 32.5 hg can be interpreted as follows:\n“We are 95% conﬁdent that the interval from 29.2 hg to 32.5 hg actually \ndoes contain the true value of M.”\nBy “95% confident” we mean that if we were to select many different samples of the \nsame size and construct the corresponding confidence intervals, in the long run, 95% \nof the confidence intervals should actually contain the value of m.\nFinding a Point Estimate and Margin of Error E from a Confidence Interval\nTechnology and journal articles often express a confidence interval in a format such \nas (10.0, 30.0). The sample mean x is the value midway between those limits, and the \nUsing Technology Technology can be used to automatically construct the confi-\ndence interval. Shown here is the StatCrunch display resulting from the 15 birth \nweights. The display shows the lower confidence interval limit (29.247163) and \nthe upper confidence interval limit (32.486171). After rounding to one decimal \nplace (as in the sample mean), we can express the 95% confidence interval as \n29.2 hg 6 m 6 32.5 hg.\n StatCrunch\nUsing t Distribution Table Using Table A-3, the critical value is t0.025 = 2.145 as \nshown in Example 1. We now find the margin of error E as shown here:\nE = ta>2\n s\n1n = 2.145 # 2.9\n115 = 1.606126\nWith x = 30.9 hg and E = 1.606126 hg, we construct the confidence interval as \nfollows:\n x - E 6 m 6 x + E\n 30.9 - 1.606126 6 m 6 30.9 + 1.606126\n 29.3 hg 6 m 6 32.5 hg     1rounded to one decimal place2\nThe lower confidence interval limit of 29.3 hg is actually 29.2 hg if we use technol-\nogy or if we use summary statistics with more decimal places than the one decimal \nplace used in the preceding calculation.\nINTERPRETATION\nWe are 95% confident that the limits of 29.2 hg and 32.5 hg actually do contain \nthe value of the population mean m. If we were to collect many different random \nsamples of 15 newborn girls and find the mean weight in each sample, about 95% \nof the resulting confidence intervals should contain the value of the mean weight of \nall newborn girls.\nEstimating Sugar in \nOranges\nIn Florida, \nmembers \nof the citrus ","page_start":322,"page_end":322,"token_count":664,"section_type":"other","chapter_number":7,"chapter_title":"ESTIMATING PARAMETERS AND DETERMINING SAMPLE SIZES","chunk_index":434}
{"chunk_id":"73a3c9805cc64226","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"We are 95% confident that the limits of 29.2 hg and 32.5 hg actually do contain \nthe value of the population mean m. If we were to collect many different random \nsamples of 15 newborn girls and find the mean weight in each sample, about 95% \nof the resulting confidence intervals should contain the value of the mean weight of \nall newborn girls.\nEstimating Sugar in \nOranges\nIn Florida, \nmembers \nof the citrus \nindustry make \nextensive use \nof statistical \nmethods. One \nparticular application involves the \nway in which growers are paid \nfor oranges used to make orange \njuice. An arriving truckload of \noranges is first weighed at the re-\nceiving plant, and then a sample \nof about a dozen oranges is \nrandomly selected. The sample is \nweighed and then squeezed, and \nthe amount of sugar in the juice \nis measured. Based on the sam-\nple results, an estimate is made \nof the total amount of sugar in \nthe entire truckload. Payment \nfor the load of oranges is based \non the estimate of the amount of \nsugar because sweeter oranges \nare more valuable than those less \nsweet, even though the amounts \nof juice may be the same.\ni\nl\nli\ni","page_start":322,"page_end":322,"token_count":272,"section_type":"other","chapter_number":7,"chapter_title":"ESTIMATING PARAMETERS AND DETERMINING SAMPLE SIZES","chunk_index":435}
{"chunk_id":"a975a88915aa953f","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"7-2 Estimating a Population Mean \n305\nmargin of error E is one-half the difference between those limits (because the upper \nlimit is x + E and the lower limit is x - E, the distance separating them is 2E).\nPoint estimate of m:   x = 1upper confidence limit2 + 1lower confidence limit2\n2\nMargin of error:     E = 1upper confidence limit2 - 1lower confidence limit2\n2\nFor example, the confidence interval (10.0, 30.0) yields x = 20.0 and E = 10.0.\nUsing Confidence Intervals to Describe, Explore, or Compare Data\nIn some cases, confidence intervals might be among the different tools used to \ndescribe, explore, or compare data sets, as in the following example.\nEXAMPLE 3  Second-Hand Smoke\nFigure 7-6 shows graphs of confidence interval estimates of the mean cotinine level \nin each of three samples: (1) people who smoke; (2) people who don’t smoke but \nare exposed to tobacco smoke at home or work; (3) people who don’t smoke and \nare not exposed to smoke. (The sample data are listed in Data Set 14 “Passive and \nActive Smoke” in Appendix B.) Because cotinine is produced by the body when \nnicotine is absorbed, cotinine is a good indication of nicotine intake. Figure 7-6 \nhelps us see the effects of second-hand smoke. In Figure 7-6, we see that the con-\nfidence interval for smokers does not overlap the other confidence intervals, so it \nappears that the mean cotinine level of smokers is different from that of the other \ntwo groups. The two nonsmoking groups have confidence intervals that do overlap, \nso it is possible that they have the same mean cotinine level. It is helpful to compare \nconfidence intervals or their graphs, but such comparisons should not be used for \nmaking formal and final conclusions about equality of means. Chapters 9 and 12 \nintroduce better methods for formal comparisons of means.\n225\n0\n25\n50\n75\n100\n125\n150\n175\n200\n225\nCotinine (ng/mL)\nPeople not exposed to smoke\nSmokers\nPeople  exposed to smoke\nFIGURE 7-6 Comparing Confidence Intervals\nCAUTION Confidence intervals can be used informally to compare different data \nsets, but the overlapping of  confidence intervals should not be used for making \nformal and final conclusions about equality of  means.\nDetermining Sample Size\nIf we want to collect a sample to be used for estimating a population mean m, how \nmany sample values do we need? When determining the sample size needed to esti-\nmate a population mean, we must have an estimated or known value of the population \nstandard deviation s, so that we can use Formula 7-4 shown in the accompanying Key \nElements box.\n","page_start":323,"page_end":323,"token_count":617,"section_type":"other","chapter_number":7,"chapter_title":"ESTIMATING PARAMETERS AND DETERMINING SAMPLE SIZES","chunk_index":436}
{"chunk_id":"441ddad98f9832d1","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"306 \nCHAPTER 7 Estimating Parameters and Determining Sample Sizes\nPopulation Size Formula 7-4 does not depend on the size (N) of the population (ex-\ncept for cases in which a relatively large sample is selected without replacement from \na finite population).\nRounding The sample size must be a whole number because it is the number of sam-\nple values that must be found, but Formula 7-4 usually gives a result that is not a \nwhole number. The round-off rule is based on the principle that when rounding is \nnecessary, the required sample size should be rounded upward so that it is at least ad-\nequately large instead of being slightly too small.\nDealing with Unknown S When Finding Sample Size Formula 7-4 requires that \nwe substitute a known value for the population standard deviation s, but in reality, \nit is usually unknown. When determining a required sample size (not constructing a \nconfidence interval), here are some ways that we can work around the problem of not \nknowing the value of s:\n1. Use the range rule of thumb (see Section 3-2) to estimate the standard deviation \nas follows: s ≈range>4, where the range is determined from sample data. \n(With a sample of 87 or more values randomly selected from a normally distrib-\nuted population, range>4 will yield a value that is greater than or equal to s at \nleast 95% of the time.)\n2. Start the sample collection process without knowing s and, using the first \nseveral values, calculate the sample standard deviation s and use it in place of \ns. The estimated value of s can then be improved as more sample data are \nKEY ELEMENTS\nFinding the Sample Size Required to Estimate a Population Mean\nObjective\nDetermine the sample size n required to estimate the value of a population mean m.\nNotation\nm = population mean\ns = population standard deviation\nx = sample mean\nE = desired margin of error\nza>2 = z score separating an area of a>2 in the right \n   tail of the standard normal distribution\nRequirement\nThe sample must be a simple random sample.\nSample Size\nThe required sample size is found by using Formula 7-4.\nFORMULA 7-4    n = c\nza>2s\nE\nd\n2\nRound-Off Rule\nIf the computed sample size n is not a whole number, round the value of n up to the next larger whole number.\n","page_start":324,"page_end":324,"token_count":516,"section_type":"other","chapter_number":7,"chapter_title":"ESTIMATING PARAMETERS AND DETERMINING SAMPLE SIZES","chunk_index":437}
{"chunk_id":"cc1fe6aeea2bd0df","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"7-2 Estimating a Population Mean \n307\nobtained, and the required sample size can be adjusted as you collect more \nsample data.\n3. Estimate the value of s by using the results of some other earlier study. In \naddition, we can sometimes be creative in our use of other known results. \nFor example, Wechsler IQ tests are designed so that the standard deviation \nis 15. Biostatistics students have IQ scores with a standard deviation less \nthan 15, because they are a more homogeneous group than people randomly \nselected from the general population. We do not know the specific value \nof s for Biostatistics students, but we can be safe by using s = 15. Using \na value for s that is larger than the true value will make the sample size \nlarger than necessary, but using a value for s that is too small would result \nin a sample size that is inadequate. When determining the sample size n, \nany errors should always be conservative in the sense that they make the \nsample size too large instead of too small.\nEXAMPLE 4  IQ Scores of Smokers\nAssume that we want to estimate the mean IQ score for the population of adults \nwho smoke. How many smokers must be randomly selected for IQ tests if we want \n95% confidence that the sample mean is within 3 IQ points of the population mean?\nSOLUTION\nFor a 95% confidence interval, we have a = 0.05, so za>2 = 1.96. Because we \nwant the sample mean to be within 3 IQ points of m, the margin of error is E = 3. \nAlso, we can assume that s = 15 (see the discussion that immediately precedes \nthis example). Using Formula 7-4, we get\nn = c\nza>2s\nE\nd\n2\n= c 1.96 # 15\n3\nd\n2\n= 96.04 = 97 1rounded up2\nINTERPRETATION\nAmong the thousands of adults who smoke, we need to obtain a simple random \nsample of at least 97 of their IQ scores. With a simple random sample of only 97 \nadult smokers, we will be 95% confident that the sample mean x is within 3 IQ \npoints of the true population mean m.\nPART 2\nEstimating a Population Mean  \nWhen S Is Known \nIn the real world of professional statisticians and professional journals and reports, it \nis extremely rare that we want to estimate an unknown value of a population mean m \nbut we somehow know the value of the population standard deviation s. If we some-\nhow do know the value of s, the confidence interval is constructed using the standard \nnormal distribution instead of the Student t distribution, so the same procedure from \nPart 1 can be used with this margin of error:\nMargin of error: E = za>2 # s\n1n 1used with known s2\n","page_start":325,"page_end":325,"token_count":626,"section_type":"other","chapter_number":7,"chapter_title":"ESTIMATING PARAMETERS AND DETERMINING SAMPLE SIZES","chunk_index":438}
{"chunk_id":"97d0d27127e0a02f","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"308\t\nChapter 7  Estimating Parameters and Determining Sample Sizes\nChoosing the Appropriate Distribution\nWhen constructing a confidence interval estimate of the population mean m, it is \nimportant to use the correct distribution. Table 7-1 summarizes the key points to \nconsider.\nExample 5   Confidence Interval Estimate of M with Known S\nUse the same 15 birth weights of girls given in Example 2, for which n = 15 \nand x = 30.9 hg. Construct a 95% confidence interval estimate of the mean birth \nweight of all girls by assuming that s is known to be 2.9 hg.\nsolution\nRequirement check  The requirements were checked in Example 2. The require-\nments are satisfied. \nWith a 95% confidence level, we have a = 0.05, and we get za>2 = 1.96 (as in \nExample 2 from Section 7-1). Using za>2 = 1.96, s = 2.9 hg, and n = 15, we find \nthe value of the margin of error E:\n E = za>2 # s\n1n\n = 1.96 # 2.9\n115 = 1.46760\nWith x = 30.9 and E = 1.46760, we find the 95% confidence interval as follows:\n x - E 6 m 6 x + E\n 30.9 - 1.46760 6 m 6 30.9 + 1.46760\n 29.4 hg 6 m 6 32.4 hg 1rounded to one decimal place2\nThe confidence interval found here using the normal distribution is slightly nar-\nrower than the confidence interval found using the t distribution in Example 2. \nBecause za>2 = 1.96 is smaller than ta>2 = 2.145, the margin of error E is smaller \nand the confidence interval is narrower. The critical value ta>2 is larger because the \nt distribution incorporates the greater amount of variation that we get with smaller \nsamples.\nRemember, this example illustrates the situation in which the population \nstandard deviation s is known, which is rare. The more realistic situation with s \nunknown is considered in Part 1 of this section.\nTable 7-1  Choosing Between Student t and z (Normal) Distributions\nConditions\nMethod\ns not known and normally distributed population\nor\ns not known and n 7 30\nUse Student t distribution.\ns known and normally distributed population\nor\ns known and n 7 30 (In reality, s is rarely \nknown.)\nUse normal (z) distribution.\nPopulation is not normally distributed and \nn … 30.\nUse the bootstrapping method (Section 7-4) \nor a nonparametric method.\n","page_start":326,"page_end":326,"token_count":601,"section_type":"other","chapter_number":7,"chapter_title":"ESTIMATING PARAMETERS AND DETERMINING SAMPLE SIZES","chunk_index":439}
{"chunk_id":"27f30263b823501e","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"7-2 Estimating a Population Mean \n309\nMeans: Confidence Intervals & Sample Size Determination\nAccess tech instructions, videos, and data sets at www.TriolaStats.com\nTECH CENTER \nStatistical Literacy and Critical Thinking\nIn Exercises 1–3, refer to the accompanying screen display that results from measured \nhemoglobin levels (g , dL) in 100 randomly selected adult females. The confidence level of \n95% was used.\n7-2 Basic Skills and Concepts\nTI-83, 84 Plus\n1. Hemoglobin Refer to the accompanying screen display.\na. Express the confidence interval in the format that uses the “less than” symbol. If the original \nlisted data use two decimal places, round the confidence interval limits accordingly.\nb. Identify the best point estimate of m and the margin of error.\nc. In constructing the confidence interval estimate of m, why is it not necessary to confirm that \nthe sample data appear to be from a population with a normal distribution?\n2. Degrees of Freedom\na. What is the number of degrees of freedom that should be used for finding the critical \nvalue ta>2?\nb. Find the critical value ta>2 corresponding to a 95% confidence level.\nc. Give a brief general description of the number of degrees of freedom.\n3. Interpreting a Confidence Interval The results in the screen display are based on a 95% \nconfidence level. Write a statement that correctly interprets the confidence interval.\n4. Normality Requirement What does it mean when we say that the confidence interval \nmethods of this section are robust against departures from normality?\nUsing Correct Distribution. In Exercises 5–8, assume that we want to construct a confi-\ndence interval. Do one of the following, as appropriate: (a) Find the critical value tA,2,  \n(b) find the critical value zA,2, (c) state that neither the normal distribution nor the t distri-\nbution applies.\n5. Audiometry Confidence level is 95%, s is not known, and the normal quantile plot of \nmeasured right-ear hearing thresholds from 10 randomly selected adult females is shown on \nthe top of the next page.\ncontinued\n","page_start":327,"page_end":327,"token_count":464,"section_type":"other","chapter_number":7,"chapter_title":"ESTIMATING PARAMETERS AND DETERMINING SAMPLE SIZES","chunk_index":440}
{"chunk_id":"8788de053a73084d","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"310 \nCHAPTER 7 Estimating Parameters and Determining Sample Sizes\n6. Vision Confidence level is 90%, s is not known, and the histogram of right-eye vision mea-\nsurements is obtained from a random sample of 61 adult males.\n7. Vision Confidence level is 99%, s = 24.8, and the histogram of 61 right-eye vision mea-\nsurements from a random sample of 61 adult males is shown in Exercise 6.\n8. Birth Weights Here are summary statistics for randomly selected weights of newborn girls: \nn = 205, x = 30.4 hg, s = 7.1 hg (based on Data Set 3 “Births” in Appendix B). The confi-\ndence level is 95%.\nConfidence Intervals. In Exercises 9–24, construct the confidence interval estimate of \nthe mean.\n9. Birth Weights of Girls Use these summary statistics given in Exercise 8: n = 205,\nx = 30.4 hg, s = 7.1 hg. Use a 95% confidence level. Are the results very different from those \nfound in Example 2 with only 15 sample values?\n10. Birth Weights of Boys Use these summary statistics for birth weights of 195 boys: \nx = 32.7 hg, s = 6.6 hg (based on Data Set 3 “Births” in Appendix B). Use a 95% confidence \nlevel. Are the results very different from those found in Exercise 9? Does it appear that boys \nand girls have very different birth weights?\n11. Mean Body Temperature Data Set 2 “Body Temperatures” in Appendix B includes a \nsample of 106 body temperatures having a mean of 98.20°F and a standard deviation of 0.62°F. \nConstruct a 95% confidence interval estimate of the mean body temperature for the entire pop-\nulation. What does the result suggest about the common belief that 98.6°F is the mean body \ntemperature?\n12. Atkins Weight Loss Program In a test of weight loss programs, 40 adults used the \n Atkins weight loss program. After 12 months, their mean weight loss was found to be 2.1 lb, \nwith a standard deviation of 4.8 lb. Construct a 90% confidence interval estimate of the mean \nweight loss for all such subjects. Does the Atkins program appear to be effective? Does it ap-\npear to be practical?\n","page_start":328,"page_end":328,"token_count":519,"section_type":"other","chapter_number":7,"chapter_title":"ESTIMATING PARAMETERS AND DETERMINING SAMPLE SIZES","chunk_index":441}
{"chunk_id":"69b68edbf08313e4","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"7-2 Estimating a Population Mean \n311\n 13. Insomnia Treatment A clinical trial was conducted to test the effectiveness of the drug \nzopiclone for treating insomnia in older subjects. Before treatment with zopiclone, 16 subjects \nhad a mean wake time of 102.8 min. After treatment with zopiclone, the 16 subjects had a mean \nwake time of 98.9 min and a standard deviation of 42.3 min (based on data from “Cognitive \nBehavioral Therapy vs Zopiclone for Treatment of Chronic Primary Insomnia in Older Adults,” \nby Sivertsen et al., Journal of the American Medical Association, Vol. 295, No. 24). Assume \nthat the 16 sample values appear to be from a normally distributed population and construct a \n98% confidence interval estimate of the mean wake time for a population with zopiclone treat-\nments. What does the result suggest about the mean wake time of 102.8 min before the treat-\nment? Does zopiclone appear to be effective?\n14. Garlic for Reducing Cholesterol In a test of the effectiveness of garlic for lowering cho-\nlesterol, 49 subjects were treated with raw garlic. Cholesterol levels were measured before and \nafter the treatment. The changes (before minus after) in their levels of low-density lipoprotein \n(LDL) cholesterol (in mg>dL) had a mean of 0.4 and a standard deviation of 21.0 (based on \ndata from “Effect of Raw Garlic vs Commercial Garlic Supplements on Plasma Lipid Concen-\ntrations in Adults with Moderate Hypercholesterolemia,” by Gardner et al., Archives of Internal \nMedicine, Vol. 167). Construct a 98% confidence interval estimate of the mean net change in \nLDL cholesterol after the garlic treatment. What does the confidence interval suggest about the \neffectiveness of garlic in reducing LDL cholesterol?\n15. Genes Samples of DNA are collected, and the four DNA bases of A, G, C, and T are \ncoded as 1, 2, 3, and 4, respectively. The results are listed below. Construct a 95% confidence \ninterval estimate of the mean. What is the practical use of the confidence interval?\n2 2 1 4 3 3 3 3 4 1\n16. Arsenic in Rice Listed below are amounts of arsenic (mg, or micrograms, per serving) in \nsamples of brown rice from California (based on data from the Food and Drug Administration). \nUse a 90% confidence level. The Food and Drug Administration also measured amounts of ar-\nsenic in samples of brown rice from Arkansas. Can the confidence interval be used to describe \narsenic levels in Arkansas?\n5.4 5.6 8.4 7.3 4.5 7.5 1.5 5.5 9.1 8.7\n17. Cell Phone Radiation Listed below are the measured radiation emissions (in W>kg) ","page_start":329,"page_end":329,"token_count":647,"section_type":"other","chapter_number":7,"chapter_title":"ESTIMATING PARAMETERS AND DETERMINING SAMPLE SIZES","chunk_index":442}
{"chunk_id":"7f43db210f99ace8","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"senic in samples of brown rice from Arkansas. Can the confidence interval be used to describe \narsenic levels in Arkansas?\n5.4 5.6 8.4 7.3 4.5 7.5 1.5 5.5 9.1 8.7\n17. Cell Phone Radiation Listed below are the measured radiation emissions (in W>kg) \ncorresponding to these cell phones: Samsung SGH-tss9, Blackberry Storm, Blackberry Curve, \nMotorola Moto, T-Mobile Sidekick, Sanyo Katana Eclipse, Palm Pre, Sony Ericsson, Nokia \n6085, Apple iPhone 3GS, Kyocera Neo E1100. The data are from the Environmental Working \nGroup. The media often present reports about the dangers of cell phone radiation as a cause of \ncancer. Construct a 90% confidence interval estimate of the population mean. What does the \nresult suggest about the Federal Communications Commission (FCC) standard that cell phone \nradiation must be 1.6 W>kg or less?\n0.38 0.55 1.54 1.55 0.50 0.60 0.92 0.96 1.00 0.86 1.46\n18. Lead in Medicine Listed below are the lead concentrations (in mg>g) measured in dif-\nferent Ayurveda medicines. Ayurveda is a traditional medical system commonly used in India. \nThe lead concentrations listed here are from medicines manufactured in the United States. The \ndata are based on the article “Lead, Mercury, and Arsenic in US and Indian Manufactured \nAyurvedic Medicines Sold via the Internet,” by Saper et al., Journal of the American Medical \nAssociation, Vol. 300, No. 8. Use the sample data to construct a 95% confidence interval esti-\nmate of the mean of the lead concentrations for the population of all such medicines. If a safety \nstandard requires lead concentrations less than 7 mg>g, does it appear that the population mean \nis less than that level?\n3.0 6.5 6.0 5.5 20.5 7.5 12.0 20.5 11.5 17.5\n19. Mercury in Sushi A Food and Drug Administration (FDA) guideline is that the mer-\ncury in fish should be below 1 part per million (ppm). Listed below are the amounts of mer-\ncury (ppm) found in tuna sushi sampled at different stores in New York City. The study was \ncontinued","page_start":329,"page_end":329,"token_count":552,"section_type":"other","chapter_number":7,"chapter_title":"ESTIMATING PARAMETERS AND DETERMINING SAMPLE SIZES","chunk_index":443}
{"chunk_id":"eb6c701ebb4cce17","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"312 \nCHAPTER 7 Estimating Parameters and Determining Sample Sizes\nsponsored by the New York Times, and the stores (in order) are D’Agostino, Eli’s Manhattan, \nFairway, Food Emporium, Gourmet Garage, Grace’s Marketplace, and Whole Foods. Construct \na 98% confidence interval estimate of the mean amount of mercury in the population. Given \nthat the FDA guideline is that fish should have a maximum of 1 ppm of mercury, what does the \nconfidence interval suggest?\n0.56 0.75 0.10 0.95 1.25 0.54 0.88\n20. Years in College Listed below are the numbers of years it took for a random sample of \ncollege students to earn bachelor’s degrees (based on data from the National Center for Educa-\ntion Statistics). Construct a 95% confidence interval estimate of the mean time required for all \ncollege students to earn bachelor’s degrees. Does it appear that college students typically earn \nbachelor’s degrees in four years? Is there anything about the data that would suggest that the \nconfidence interval might not be a good result?\n4 4 4 4 4 4 4.5 4.5 4.5 4.5 4.5 4.5 6 6 8 9 9 13 13 15\n21. Caffeine in Soft Drinks Listed below are measured amounts of caffeine (mg per 12 oz of \ndrink) obtained in one can from each of 20 brands (7-UP, A&W Root Beer, Cherry Coke,…, \nTaB). Use a confidence level of 99%. Does the confidence interval give us good information \nabout the population of all cans of the same 20 brands that are consumed? Does the sample ap-\npear to be from a normally distributed population? If not, how are the results affected?\n0 0 34 34 34 45 41 51 55 36 47 41 0 0 53 54 38 0 41 47\n22. Shoveling Heart Rates Because cardiac deaths appear to increase after heavy snow-\nfalls, an experiment was designed to compare cardiac demands of snow shoveling to those \nof using an electric snow thrower. Ten subjects cleared tracts of snow using both meth-\nods, and their maximum heart rates (beats per minute, or BPM) were recorded during both \nactivities. The following results were obtained (based on data from “Cardiac Demands of \nHeavy Snow Shoveling,” by Franklin et al., Journal of the American Medical Association, \nVol. 273, No. 11):\nManual Snow Shoveling Maximum Heart Rates: n = 10, x = 175 BPM, s = 15 BPM\nElectric Snow Thrower Maximum Heart Rates: n = 10, x = 124 BPM, s = 18 BPM\na. Find the 95% confidence interval estimate of the population mean for those people who \nshovel snow manually.\nb. Find the 95% confidence interval estimate of the population mean for those people who use \nthe electric snow thrower.","page_start":330,"page_end":330,"token_count":665,"section_type":"other","chapter_number":7,"chapter_title":"ESTIMATING PARAMETERS AND DETERMINING SAMPLE SIZES","chunk_index":444}
{"chunk_id":"058e3b84d47900c6","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"Manual Snow Shoveling Maximum Heart Rates: n = 10, x = 175 BPM, s = 15 BPM\nElectric Snow Thrower Maximum Heart Rates: n = 10, x = 124 BPM, s = 18 BPM\na. Find the 95% confidence interval estimate of the population mean for those people who \nshovel snow manually.\nb. Find the 95% confidence interval estimate of the population mean for those people who use \nthe electric snow thrower.\nc. If you are a physician with concerns about cardiac deaths fostered by manual snow shovel-\ning, what single value in the confidence interval from part (a) would be of greatest concern?\nd. Compare the confidence intervals from parts (a) and (b) and interpret your findings.\n23. Echinacea Treatment In a study designed to test the effectiveness of echinacea for treat-\ning upper respiratory tract infections in children, 337 children were treated with echinacea and \n370 other children were given a placebo. The numbers of days of peak severity of symptoms \nfor the echinacea treatment group had a mean of 6.0 and a standard deviation of 2.3. The num-\nbers of days of peak severity of symptoms for the placebo group had a mean of 6.1 days and a \nstandard deviation of 2.4 days (based on data from “Efficacy and Safety of Echinacea in Treat-\ning Upper Respiratory Tract Infections in Children,” by Taylor et al., Journal of the American \nMedical Association, Vol. 290, No. 21).\na. Construct the 95% confidence interval for the mean number of days of peak severity of \nsymptoms for those who receive echinacea treatment.\nb. Construct the 95% confidence interval for the mean number of days of peak severity of \nsymptoms for those who are given a placebo.\nc. Compare the two confidence intervals. What do the results suggest about the effectiveness \nof echinacea?","page_start":330,"page_end":330,"token_count":413,"section_type":"other","chapter_number":7,"chapter_title":"ESTIMATING PARAMETERS AND DETERMINING SAMPLE SIZES","chunk_index":445}
{"chunk_id":"6f2f8a0f7acbe8ee","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"7-2 Estimating a Population Mean \n313\n24. Acupuncture for Migraines In a study designed to test the effectiveness of acupuncture \nfor treating migraine, 142 subjects were treated with acupuncture and 80 subjects were given \na sham treatment. The numbers of migraine attacks for the acupuncture treatment group had \na mean of 1.8 and a standard deviation of 1.4. The numbers of migraine attacks for the sham \ntreatment group had a mean of 1.6 and a standard deviation of 1.2.\na. Construct the 95% confidence interval estimate of the mean number of migraine attacks for \nthose treated with acupuncture.\nb. Construct the 95% confidence interval estimate of the mean number of migraine attacks for \nthose given a sham treatment.\nc. Compare the two confidence intervals. What do the results suggest about the effectiveness \nof acupuncture?\nAppendix B Data Sets. In Exercises 25 and 26, use the Appendix B data sets to construct \nthe confidence interval estimates of the mean.\n25. Pulse Rates Refer to Data Set 1 “Body Data” in Appendix B and construct a 95% con-\nfidence interval estimate of the mean pulse rate of adult females; then do the same for adult \nmales. Compare the results.\n26. Nicotine in Cigarettes Refer to Data Set 15 “Cigarette Contents” in Appendix B and as-\nsume that the samples are simple random samples obtained from normally distributed popula-\ntions.\na. Construct a 95% confidence interval estimate of the mean amount of nicotine in cigarettes \nthat are king size, non-filtered, non-menthol, and non-light.\nb. Construct a 95% confidence interval estimate of the mean amount of nicotine in cigarettes \nthat are 100 mm, filtered, non-menthol, and non-light.\nc. Compare the results. Do filters on cigarettes appear to be effective?\nSample Size. In Exercises 27–34, find the sample size required to estimate the population \nmean.\n27. Mean IQ of Nurses The Wechsler IQ test is designed so that the mean is 100 and the \nstandard deviation is 15 for the population of normal adults. Find the sample size necessary to \nestimate the mean IQ score of nurses. We want to be 99% confident that our sample mean is \nwithin 4 IQ points of the true mean. The mean for this population is clearly greater than 100. \nThe standard deviation for this population is less than 15 because it is a group with less varia-\ntion than a group randomly selected from the general population; therefore, if we use s = 15 \nwe are being conservative by using a value that will make the sample size at least as large as \nnecessary. Assume then that s = 15 and determine the required sample size. Does the sample \nsize appear to be practical?\n28. Mean IQ of Psychologists See the preceding exercise, in which we can assume that \ns = 15 for the IQ scores. Psychologists are a group with IQ scores that vary less than the IQ \nscores of the general population. Find the sample size needed to estimate the mean IQ of psy-","page_start":331,"page_end":331,"token_count":655,"section_type":"other","chapter_number":7,"chapter_title":"ESTIMATING PARAMETERS AND DETERMINING SAMPLE SIZES","chunk_index":446}
{"chunk_id":"b843d6a87e0199c1","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"necessary. Assume then that s = 15 and determine the required sample size. Does the sample \nsize appear to be practical?\n28. Mean IQ of Psychologists See the preceding exercise, in which we can assume that \ns = 15 for the IQ scores. Psychologists are a group with IQ scores that vary less than the IQ \nscores of the general population. Find the sample size needed to estimate the mean IQ of psy-\nchologists, given that we want 98% confidence that the sample mean is within 3 IQ points of \nthe population mean. Does the sample size appear to be practical?\n29. Mean Grade-Point Average Assume that all grade-point averages are to be standard-\nized on a scale between 0 and 4. How many grade-point averages must be obtained so that the \nsample mean is within 0.01 of the population mean? Assume that a 95% confidence level is de-\nsired. If we use the range rule of thumb, we can estimate s to be range>4 = 14 - 02>4 = 1.\nDoes the sample size seem practical?\n30. Mean Weight of Male Medical Students Data Set 1 “Body Data” in Appendix B in-\ncludes weights of 153 randomly selected adult males, and those weights have a standard de-\nviation of 17.65 kg. Because it is reasonable to assume that weights of male medical students \ncontinued","page_start":331,"page_end":331,"token_count":291,"section_type":"other","chapter_number":7,"chapter_title":"ESTIMATING PARAMETERS AND DETERMINING SAMPLE SIZES","chunk_index":447}
{"chunk_id":"325edff936434a20","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"314 \nCHAPTER 7 Estimating Parameters and Determining Sample Sizes\nhave less variation than weights of the population of adult males, we can be conservative by \nletting s = 17.65 kg. How many male medical students must be weighed in order to estimate \nthe mean weight of all male medical students? Assume that we want 90% confidence that the \nsample mean is within 1.5 kg of the population mean. Does it seem reasonable to assume that \nweights of male medical students have less variation than weights of the population of adult \nmales?\n31. Mean Age of Female Medical Students Data Set 1 “Body Data” in Appendix B in-\ncludes ages of 147 randomly selected adult females, and those ages have a standard deviation \nof 17.7 years. Assume that ages of female medical students have less variation than ages of \nfemales in the general population, so let s = 17.7 years for the sample size calculation. How \nmany female medical student ages must be obtained in order to estimate the mean age of all \nfemale medical students? Assume that we want 95% confidence that the sample mean is within \none-half year of the population mean. Does it seem reasonable to assume that ages of female \nmedical students have less variation than ages of females in the general population?\n32. Mean Pulse Rate of Females Data Set 1 “Body Data” in Appendix B includes pulse \nrates of 147 randomly selected adult females, and those pulse rates vary from a low of 36 bpm \nto a high of 104 bpm. Find the minimum sample size required to estimate the mean pulse rate \nof adult females. Assume that we want 99% confidence that the sample mean is within 2 bpm \nof the population mean.\na. Find the sample size using the range rule of thumb to estimate s.\nb. Assume that s = 12.5 bpm, based on the value of s = 12.5 bpm for the sample of 147 \nfemale pulse rates.\nc. Compare the results from parts (a) and (b). Which result is likely to be better?\n33. Mean Pulse Rate of Males Data Set 1 “Body Data” in Appendix B includes pulse rates \nof 153 randomly selected adult males, and those pulse rates vary from a low of 40 bpm to a \nhigh of 104 bpm. Find the minimum sample size required to estimate the mean pulse rate of \nadult males. Assume that we want 99% confidence that the sample mean is within 2 bpm of the \npopulation mean.\na. Use the range rule of thumb to estimate s.\nb. Assume that s = 11.3 bpm, based on the value of s = 11.3 bpm for the sample of 153 male \npulse rates.\nc. Compare the results from parts (a) and (b). Which result is likely to be better?\n34. Mean Body Temperature Data Set 2 “Body Temperatures” in Appendix B includes 106 \nbody temperatures of adults for day 2 at 12 AM, and they vary from a low of 96.5°F to a high ","page_start":332,"page_end":332,"token_count":646,"section_type":"other","chapter_number":7,"chapter_title":"ESTIMATING PARAMETERS AND DETERMINING SAMPLE SIZES","chunk_index":448}
{"chunk_id":"8e8d8aed9c761de3","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"pulse rates.\nc. Compare the results from parts (a) and (b). Which result is likely to be better?\n34. Mean Body Temperature Data Set 2 “Body Temperatures” in Appendix B includes 106 \nbody temperatures of adults for day 2 at 12 AM, and they vary from a low of 96.5°F to a high \nof 99.6°F. Find the minimum sample size required to estimate the mean body temperature of \nall adults. Assume that we want 98% confidence that the sample mean is within 0.1°F of the \npopulation mean.\na. Find the sample size using the range rule of thumb to estimate s.\nb. Assume that s = 0.62°F, based on the value of s = 0.62°F for the sample of 106 body \ntemperatures.\nc. Compare the results from parts (a) and (b). Which result is likely to be better?\n35. Finite Population Correction Factor If a simple random sample of size n is selected \nwithout replacement from a finite population of size N, and the sample size is more than 5% of \nthe population size 1n 7 0.05N2, better results can be obtained by using the finite population \ncorrection factor, which involves multiplying the margin of error E by 11N - n2>1N - 12. \n7-2 Beyond the Basics\ncontinued","page_start":332,"page_end":332,"token_count":298,"section_type":"other","chapter_number":7,"chapter_title":"ESTIMATING PARAMETERS AND DETERMINING SAMPLE SIZES","chunk_index":449}
{"chunk_id":"63204b176327f3f7","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"7-3 Estimating a Population Standard Deviation or Variance \n315\nFor a sample of 40 platelet counts of females from Data Set 1 “Body Data” in Appendix B, we \nget x = 255.1 and s = 65.4. All platelet counts are in 1000 cells>mL.\na. Construct a 95% confidence interval estimate of m assuming that the population is large.\nb. Construct a 95% confidence interval estimate of m assuming that the sample is selected \nwithout replacement from a population of 500 females.\nc. Compare the results.\nKey Concept This section presents methods for using a sample standard deviation s \n(or a sample variance s2) to estimate the value of the corresponding population stan-\ndard deviation s (or population variance s2). Here are the main concepts included in \nthis section:\n \n■Point Estimate: The sample variance s2 is the best point estimate (or single \nvalue estimate) of the population variance s2. The sample standard deviation s is \ncommonly used as a point estimate of s, even though it is a biased estimator, as \ndescribed in Section 6-3.\n \n■Confidence Interval: When constructing a confidence interval estimate of a \npopulation standard deviation (or population variance), we construct the con-\nfidence interval using the x2 distribution. (The Greek letter x is pronounced \n“kigh.”)\nChi-Square Distribution\nHere are key points about the x2(chi-square or chi-squared) distribution:\n \n■In a normally distributed population with variance s2, if we randomly select in-\ndependent samples of size n and, for each sample, compute the sample variance \ns2, the sample statistic x2 = 1n - 12s2>s2 has a sampling distribution called \nthe chi-square distribution, as shown in Formula 7-5.\n7-3 \nEstimating a Population Standard Deviation or Variance\nFORMULA 7-5\nx2 = 1n - 12s2\ns2\n \n■Critical Values of X2 We denote a right-tailed critical value by x2\nR and we de-\nnote a left-tailed critical value by x2\nL. Those critical values can be found by using \ntechnology or Table A-4, and they require that we first determine a value for the \nnumber of degrees of freedom.\n \n■Degrees of Freedom For the methods of this section, the number of degrees of \nfreedom is the sample size minus 1.\nDegrees of freedom: df = n −1\ncontinued\n","page_start":333,"page_end":333,"token_count":535,"section_type":"other","chapter_number":7,"chapter_title":"ESTIMATING PARAMETERS AND DETERMINING SAMPLE SIZES","chunk_index":450}
{"chunk_id":"974741473d94b3d8","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"316 \nCHAPTER 7 Estimating Parameters and Determining Sample Sizes\n \n■The chi-square distribution is skewed to the right, unlike the normal and Student \nt distributions (see Figure 7-7).\n \n■The values of chi-square can be zero or positive, but they cannot be negative, as \nshown in Figure 7-7.\n \n■The chi-square distribution is different for each number of degrees of freedom, \nas illustrated in Figure 7-8. As the number of degrees of freedom increases, the \nchi-square distribution approaches a normal distribution.\nNot symmetric\nAll values are nonnegative\n0\nx2\nFIGURE 7-7 Chi-Square Distribution\n0\n5\n10\n15\n20\n25\n30\n35\n40\n45\nx2\ndf 5 10\ndf 5 20\nFIGURE 7-8  Chi-Square Distribution for \ndf = 10 and df = 20\nBecause the chi-square distribution is not symmetric, a confidence interval esti-\nmate of s2 does not fit a format of s2 - E 6 s2 6 s2 + E, so we must do separate \ncalculations for the upper and lower confidence interval limits. If using Table A-4 for \nfinding critical values, note the following design feature of that table:\nIn Table A-4, each critical value of X2 in the body of the table corresponds \nto an area given in the top row of the table, and each area in that top row \nis a cumulative area to the right of the critical value.\nCAUTION Table A-2 for the standard normal distribution provides cumulative areas \nfrom the left, but Table A-4  for the chi-square distribution uses cumulative areas \nfrom the right.\nEXAMPLE 1  Finding Critical Values of X2\nA simple random sample of 22 IQ scores is obtained (as in Example 2, which fol-\nlows). Construction of a confidence interval for the population standard deviation s \nrequires the left and right critical values of x2 corresponding to a confidence level \nof 95% and a sample size of n = 22. Find x2\nL (the critical value of x2 separating an \narea of 0.025 in the left tail), and find x2\nR (the critical value of x2 separating an area \nof 0.025 in the right tail).\nSOLUTION\nWith a sample size of n = 22, the number of degrees of freedom is df = n - 1 = 21.\nSee Figure 7-9.\n","page_start":334,"page_end":334,"token_count":533,"section_type":"other","chapter_number":7,"chapter_title":"ESTIMATING PARAMETERS AND DETERMINING SAMPLE SIZES","chunk_index":451}
{"chunk_id":"5d3fc6f1c8847f4f","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"7-3 Estimating a Population Standard Deviation or Variance \n317\nWhen obtaining critical values of x2 from Table A-4, if a number of degrees of \nfreedom is not found in the table, you can be conservative by using the next lower \nnumber of degrees of freedom, or you can use the closest critical value in the table, \nor you can get an approximate result with interpolation. For numbers of degrees of \nfreedom greater than 100, use the equation given in Exercise 23 on page 324, or use a \nmore extensive table, or use technology.\nAlthough s2 is the best point estimate of s2, there is no indication of how good \nit is, so we use a confidence interval that gives us a range of values associated with a \nconfidence level.\n0\nx2\nL 5 10.283\nx2\nR 5 35.479\nx2\n(df 5 21)\n 0.025\n 0.025\nTable A-4:\nUse df 5 21 and\na cumulative right\narea of 0.975.\nTable A-4:\nUse df 5 21 and\na cumulative right\narea of 0.025.\nFIGURE 7-9 Finding Critical Values of X2\nThe critical value to the right 1x2\nR = 35.4792 is obtained from Table A-4  in \na straightforward manner by locating 21 in the degrees-of-freedom column at the \nleft and 0.025 across the top row. The leftmost critical value of x2\nL = 10.283 also \ncorresponds to 21 in the degrees-of-freedom column, but we must locate 0.975 (or \n1 - 0.025) across the top row because the values in the top row are always areas \nto the right of the critical value. Refer to Figure 7-9 and see that the total area to the \nright of x2\nL = 10.283 is 0.975.\nConfidence Interval for Estimating a Population Standard Deviation or Variance\nObjective\nConstruct a confidence interval estimate of a population standard deviation or variance.\nNotation\ns = population standard deviation \ns2 = population variance\ns = sample standard deviation \ns2 = sample variance\nn = number of sample values \nE = margin of error\nx2\nL = left-tailed critical value of x2 \nx2\nR = right-tailed critical value of x2\nKEY ELEMENTS\ncontinued\n","page_start":335,"page_end":335,"token_count":536,"section_type":"other","chapter_number":7,"chapter_title":"ESTIMATING PARAMETERS AND DETERMINING SAMPLE SIZES","chunk_index":452}
{"chunk_id":"2169c718dfbb7336","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"318 \nCHAPTER 7 Estimating Parameters and Determining Sample Sizes\nProcedure for Constructing a Confidence Interval for S or S2\nConfidence intervals can be easily constructed with technology or they can be con-\nstructed by using Table A-4 with the following procedure.\n1. Verify that the two requirements are satisfied: The sample is a random sample \nfrom a normally distributed population.\n2. Using n - 1 degrees of freedom, find the critical values x2\nR and x2\nL that corre-\nspond to the desired confidence level (as in Example 1).\n3. Construct a confidence interval estimate of s2 by using the following:\n1n - 12s2\nx2\nR\n6 s2 6 1n - 12s2\nx2\nL\n4. To get a confidence interval estimate of s, take the square root of each compo-\nnent of the above confidence interval.\n5. Round the confidence interval limits using the round-off rule given in the \npreceding Key Elements box.\nUsing Confidence Intervals for Comparisons or Hypothesis Tests\nComparisons Confidence intervals can be used informally to compare the varia-\ntion in different data sets, but the overlapping of confidence intervals should not be \nRequirements\n1. The sample is a simple random sample.\n2. The population must have normally distributed values (even if the sample is large). The requirement of a normal \ndistribution is much stricter here than in earlier sections, so large departures from normal distributions can result in \nlarge errors. (If the normality requirement is not satisfied, use the bootstrap method described in Section 7-4.)\nConfidence Interval for the Population Variance S2\n1n - 12s2\nx2\nR\n6 s2 6 1n - 12s2\nx2\nL\nConfidence Interval for the Population Standard Deviation S\nB\n1n - 12s2\nx2\nR\n6 s 6 B\n1n - 12s2\nx2\nL\nRound-Off Rule\n1. Original Data: When using the original set of data values, round the confidence interval limits to one more decimal \nplace than is used for the original data.\n2. Summary Statistics: When using the summary statistics (n, s), round the confidence interval limits to the same num-\nber of decimal places used for the sample standard deviation.\nCAUTION A confidence interval can be expressed in a format such as  \n11.0 6 s 6 20.4 or a format of (11.0, 20.4), but it cannot be expressed in a format \nof s { E.\n","page_start":336,"page_end":336,"token_count":557,"section_type":"other","chapter_number":8,"chapter_title":"HYPOTHESIS TESTING","chunk_index":453}
{"chunk_id":"c180a1a01dbd1d83","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"7-3 Estimating a Population Standard Deviation or Variance \n319\nused for making formal and final conclusions about equality of variances or standard \ndeviations.\nEXAMPLE 2  Confidence Interval for Estimating S of IQ Scores\nData Set 8 “IQ and Lead” in Appendix B lists IQ scores for subjects in three differ-\nent lead exposure groups. The 22 full IQ scores for the group with medium expo-\nsure to lead (Group 2) have a standard deviation of 14.29263. Consider the sample \nto be a simple random sample and construct a 95% confidence interval estimate of \ns, the standard deviation of the population from which the sample was obtained.\nSOLUTION\nREQUIREMENT CHECK\nStep 1: Check requirements. (1) The sample can be treated as a simple random \nsample. (2) The accompanying histogram has a shape very close to the bell shape of \na normal distribution, so the requirement of normality is satisfied. \nMinitab\nStep 2: Using Technology The confidence interval can be found using technology. \nThe StatCrunch display shows the lower and upper confidence interval limits for \nthe 95% confidence interval estimate of s2, so we get 120.9 6 s2 6 417.2. Tak-\ning square roots, we get 11.0 6 s 6 20.4\nStatCrunch\nUsing Table A-4  If using Table A-4, we first use the sample size of n = 22 to \nfind degrees of freedom: df = n - 1 = 21. In Table A-4, refer to the row cor-\nresponding to 21 degrees of freedom, and refer to the columns with areas of 0.975 \nand 0.025. (For a 95% confidence level, we divide a = 0.05 equally between the \ntwo tails of the chi-square distribution, and we refer to the values of 0.975 and \n0.025 across the top row of Table A-4.) The critical values are x2\nL = 10.283 and \nx2\nR = 35.479 (as shown in Example 1).\ncontinued\n","page_start":337,"page_end":337,"token_count":463,"section_type":"other","chapter_number":8,"chapter_title":"HYPOTHESIS TESTING","chunk_index":454}
{"chunk_id":"6460aa59f455c25e","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"320 \nCHAPTER 7 Estimating Parameters and Determining Sample Sizes\nRationale for the Confidence Interval See Figure 7-9 on page 317 to make sense \nof this statement: If we select random samples of size n from a normally distrib-\nuted population with variance s2, there is a probability of 1 - a that the statistic \n1n - 12s2>s2 will fall between the critical values of x2\nL and x2\nR. It follows that there \nis a 1 - a probability that both of the following are true:\n1n - 12s2\ns2\n6 x2\nR and 1n - 12s2\ns2\n7 x2\nL\nMultiply both of the preceding inequalities by s2, then divide each inequality by the \nappropriate critical value of x2, so the two preceding inequalities can be expressed in \nthese equivalent forms:\n1n - 12s2\nx2\nR\n6 s2 and 1n - 12s2\nx2\nL\n7 s2\nThe two preceding inequalities can be combined into one inequality to get the format \nof the confidence interval used in this section:\n1n - 12s2\nx2\nR\n6 s2 6 1n - 12s2\nx2\nL\nDetermining Sample Size\nThe procedures for finding the sample size necessary to estimate s are much more \ncomplex than the procedures given earlier for means and proportions. For normally \ndistributed populations, Table 7-2 or the formula given in Exercise 24 “Finding Sam-\nple Size” on page 324 can be used.\nStep 3: Using the critical values of 10.283 and 35.479, the sample standard devia-\ntion of s = 14.29263, and the sample size of n = 22, we construct the 95% confi-\ndence interval by evaluating the following:\n 1n - 12s2\nx2\nR\n6 s2 6 1n - 12s2\nx2\nL\n 122 - 12114.292632 2\n35.479\n6 s2 6 122 - 12114.292632 2\n10.283\nStep 4: Evaluating the expression above results in 120.9 6 s2 6 417.2. Finding \nthe square root of each part (before rounding), then rounding to one decimal place, \nyields this 95% confidence interval estimate of the population standard deviation: \n11.0 6 s 6 20.4.\nINTERPRETATION\nBased on this result, we have 95% confidence that the limits of 11.0 and 20.4 contain \nthe true value of s. The confidence interval can also be expressed as (11.0, 20.4), but \nit cannot be expressed in a format of s { E.\nTABLE 7-2 Finding Sample Size\ns\nTo be 95%  \nconfident that \ns is within . . .\nof the value  \nof s, the sample \nsize n should be \nat least","page_start":338,"page_end":338,"token_count":666,"section_type":"other","chapter_number":8,"chapter_title":"HYPOTHESIS TESTING","chunk_index":455}
{"chunk_id":"6f407c566014ddc5","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"the true value of s. The confidence interval can also be expressed as (11.0, 20.4), but \nit cannot be expressed in a format of s { E.\nTABLE 7-2 Finding Sample Size\ns\nTo be 95%  \nconfident that \ns is within . . .\nof the value  \nof s, the sample \nsize n should be \nat least\n1%\n19,205\n5%\n768\n10%\n192\n20%\n48\n30%\n21\n40%\n12\n50%\n8\nTo be 99%  \nconfident that \ns is within . . .\nof the value  \nof s, the sample \nsize n should be \nat least\n1%\n33,218\n5%\n1,336\n10%\n336\n20%\n85\n30%\n38\n40%\n22\n50%\n14","page_start":338,"page_end":338,"token_count":178,"section_type":"other","chapter_number":8,"chapter_title":"HYPOTHESIS TESTING","chunk_index":456}
{"chunk_id":"2db0ae8511f0dbd8","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"7-3 Estimating a Population Standard Deviation or Variance \n321\nEXAMPLE 3  Finding Sample Size for Estimating S\nWe want to estimate the standard deviation s of all IQ scores of people with exposure to \nlead. We want to be 99% confident that our estimate is within 5% of the true value of s. \nHow large should the sample be? Assume that the population is normally distributed.\nSOLUTION\nFrom Table 7-2, we can see that 99% confidence and an error of 5% for s corre-\nspond to a sample of size 1336. We should obtain a simple random sample of 1336 \nIQ scores from the population of subjects exposed to lead.\nConfidence Interval Estimate for Standard Deviation or Variance\nAccess tech instructions, videos, and data sets at www.TriolaStats.com\nTECH CENTER \nStatistical Literacy and Critical Thinking\n1. Brain Volume Using all of the brain volumes listed in Data Set 9 “IQ and Brain Size,” we get \nthis 95% confidence interval estimate: 9027.8 6 s2 6 33,299.8, and the units of measurement \nare (cm3)2. Identify the corresponding confidence interval estimate of s and include the appropri-\nate units. Given that the original values are whole numbers, round the limits using the round-off rule \ngiven in this section. Write a statement that correctly interprets the confidence interval estimate of s.\n2. Expressing Confidence Intervals Example 2 showed how the statistics of n = 22 and \ns = 14.3 result in this 95% confidence interval estimate of s: 11.0 6 s 6 20.4. That confi-\ndence interval can also be expressed as (11.0, 20.4), but it cannot be expressed as 15.7 { 4.7.\nGiven that 15.7 { 4.7 results in values of 11.0 and 20.4, why is it wrong to express the confi-\ndence interval as 15.7 { 4.7?\n3. Last Digit Analysis The accompanying dotplot depicts the last digits of the weights of \n153 males in Data Set 1 “Body Data.” Do those digits appear to be from a normally distributed \npopulation? If not, does the large sample size of n = 153 justify treating the values as if they \nwere from a normal distribution? Can the sample be used to construct a 95% confidence inter-\nval estimate of s for the population of all such digits?\n7-3  Basic Skills and Concepts\n4. Normality Requirement What is different about the normality requirement for a confidence \ninterval estimate of s and the normality requirement for a confidence interval estimate of m?\nFinding Critical Values and Confidence Intervals. In Exercises 5–8, use the given infor-\nmation to find the number of degrees of freedom, the critical values X2\nL and X2\nR, and the confi-\ndence interval estimate of S. The samples are from Appendix B and it is reasonable to assume ","page_start":339,"page_end":339,"token_count":656,"section_type":"other","chapter_number":8,"chapter_title":"HYPOTHESIS TESTING","chunk_index":457}
{"chunk_id":"43eaa62674b572d4","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"interval estimate of s and the normality requirement for a confidence interval estimate of m?\nFinding Critical Values and Confidence Intervals. In Exercises 5–8, use the given infor-\nmation to find the number of degrees of freedom, the critical values X2\nL and X2\nR, and the confi-\ndence interval estimate of S. The samples are from Appendix B and it is reasonable to assume \nthat a simple random sample has been selected from a population with a normal distribution.\n5. Nicotine in Menthol Cigarettes 95% confidence; n = 25, s = 0.24 mg.\n6. White Blood Cell Counts of Men 95% confidence; n = 153, s = 1.86.","page_start":339,"page_end":339,"token_count":156,"section_type":"other","chapter_number":8,"chapter_title":"HYPOTHESIS TESTING","chunk_index":458}
{"chunk_id":"db39831bdc04c957","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"322 \nCHAPTER 7 Estimating Parameters and Determining Sample Sizes\n7. Platelet Counts of Women 99% confidence; n = 147, s = 65.4.\n8. Heights of Men 99% confidence; n = 153, s = 7.10 cm.\nFinding Confidence Intervals. In Exercises 9–16, assume that each sample is a simple \nrandom sample obtained from a population with a normal distribution.\n9. Body Temperature Data Set 2 “Body Temperatures” in Appendix B includes a sample of \n106 body temperatures having a mean of 98.20°F and a standard deviation of 0.62°F (for day 2 \nat 12 AM). Construct a 95% confidence interval estimate of the standard deviation of the body \ntemperatures for the entire population.\n10. Atkins Weight Loss Program In a test of weight loss programs, 40 adults used the Atkins \nweight loss program. After 12 months, their mean weight loss was found to be 2.1 lb, with \na standard deviation of 4.8 lb. Construct a 90% confidence interval estimate of the standard \ndeviation of the weight loss for all such subjects. Does the confidence interval give us informa-\ntion about the effectiveness of the diet?\n11. Insomnia Treatment A clinical trial was conducted to test the effectiveness of the drug zop-\niclone for treating insomnia in older subjects. After treatment with zopiclone, 16 subjects had a \nmean wake time of 98.9 min and a standard deviation of 42.3 min (based on data from “Cognitive \nBehavioral Therapy vs Zopiclone for Treatment of Chronic Primary Insomnia in Older Adults,” \nby Sivertsen et al., Journal of the American Medical Association, Vol. 295, No. 24). Assume that \nthe 16 sample values appear to be from a normally distributed population and construct a 98% \nconfidence interval estimate of the standard deviation of the wake times for a population with \nzopiclone treatments. Does the result indicate whether the treatment is effective?\n12. Garlic for Reducing Cholesterol In a test of the effectiveness of garlic for lowering cho-\nlesterol, 49 subjects were treated with raw garlic. Cholesterol levels were measured before and \nafter the treatment. The changes (before minus after) in their levels of LDL cholesterol (in mg>dL) \nhad a mean of 0.4 and a standard deviation of 21.0 (based on data from “Effect of Raw Garlic \nvs Commercial Garlic Supplements on Plasma Lipid Concentrations in Adults with Moderate \nHypercholesterolemia,” by Gardner et al., Archives of Internal Medicine, Vol. 167). Construct \na 98% confidence interval estimate of the standard deviation of the changes in LDL cholesterol \nafter the garlic treatment. Does the result indicate whether the treatment is effective?\n 13. World’s Smallest Mammal The world’s smallest mammal is the bumblebee bat, also \nknown as the Kitti’s hog-nosed bat (or Craseonycteris thonglongyai as it is affectionately ","page_start":340,"page_end":340,"token_count":655,"section_type":"other","chapter_number":8,"chapter_title":"HYPOTHESIS TESTING","chunk_index":459}
{"chunk_id":"3e9134a05031104c","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"a 98% confidence interval estimate of the standard deviation of the changes in LDL cholesterol \nafter the garlic treatment. Does the result indicate whether the treatment is effective?\n 13. World’s Smallest Mammal The world’s smallest mammal is the bumblebee bat, also \nknown as the Kitti’s hog-nosed bat (or Craseonycteris thonglongyai as it is affectionately \ncalled). Such bats are roughly the size of a large bumblebee. Listed below are weights (in \ngrams) from a sample of these bats. Construct a 95% confidence interval estimate of the stan-\ndard deviation of weights for all such bats.\n1.7 1.6 1.5 2.0 2.3 1.6 1.6 1.8 1.5 1.7 2.2 1.4 1.6 1.6 1.6\n 14. Queues A Providence Hospital experiment involves two different waiting line configura-\ntions for patients arriving for admission. The waiting times (in seconds) are recorded with a \nsingle-line configuration that feeds four stations and another configuration with individual lines \nat the four stations. Determine whether there is a difference in variation between the two data \nsets. Which configuration appears to be better?\n  Single Line\n  390  396  402  408  426  438  444  462  462  462 \n Individual Lines  252  324  348  372  402  462  462  510  558  600\n 15. Shoveling Heart Rates Because cardiac deaths appear to increase after heavy snowfalls, \nan experiment was designed to compare cardiac demands of snow shoveling to those of using an \nelectric snow thrower. Ten subjects cleared tracts of snow using both methods, and their maxi-\nmum heart rates (beats per minute, or BPM) were recorded during both activities. The results \nshown below were obtained (based on data from “Cardiac Demands of Heavy Snow Shoveling,” \nby Franklin et al., Journal of the American Medical Association, Vol. 273, No. 11).\n  Manual Snow Shoveling:  n = 10, x = 175 BPM, s = 15 BPM\n Electric Snow Thrower:  n = 10, x = 124 BPM, x = 124, s = 18 BPM\ncontinued","page_start":340,"page_end":340,"token_count":524,"section_type":"other","chapter_number":8,"chapter_title":"HYPOTHESIS TESTING","chunk_index":460}
{"chunk_id":"9437109b132d76f9","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"7-3 Estimating a Population Standard Deviation or Variance \n323\na. Construct a 95% confidence interval estimate of the population standard deviation s for \nthose who did manual snow shoveling.\nb. Construct a 95% confidence interval estimate of the population standard deviation s for \nthose who used the automated electric snow thrower.\nc. Compare the results. Does the variation appear to be different for the two groups?\n16. Acupuncture for Migraines In a study designed to test the effectiveness of acupuncture \nfor treating migraine headaches, 142 subjects were treated with acupuncture and 80 subjects \nwere given a sham treatment. The numbers of migraine attacks for the acupuncture treatment \ngroup had a mean of 1.8 and a standard deviation of 1.4. The numbers of migraine attacks for \nthe sham treatment group had a mean of 1.6 and a standard deviation of 1.2. Construct a 95% \nconfidence interval estimate of s for each of the two groups, and then compare the results.\nLarge Data Sets from Appendix B. In Exercises 17 and 18, use the data set in \n Appendix B. Assume that each sample is a simple random sample obtained from a popula-\ntion with a normal distribution.\n17. Birth Length of Stay Refer to Data Set 3 “Births” in Appendix B.\na. Use the lengths of stay (days) for the 205 girls to construct a 95% confidence interval esti-\nmate of the standard deviation of the population from which the sample was obtained. For criti-\ncal values, use x2\nL = 166.337 and x2\nR = 245.449. Does the distribution of those data appear to \nbe approximately normal? How does that affect the results?\nb. Repeat part (a) using the 195 boys and, for critical values, use x2\nL = 157.321 and \nx2\nR = 234.465.\nc. Compare the results from part (a) and part (b).\n18. Birth Weights Refer to Data Set 3 “Births” in Appendix B\na. Use the 205 birth weights of girls to construct a 95% confidence interval estimate of the \nstandard deviation of the population from which the sample was obtained. For critical values, \nuse x2\nL = 166.337 and x2\nR = 245.449.\nb. Repeat part (a) using the 195 birth weights of boys and, for critical values, use x2\nL = 157.321 \nand x2\nR = 234.465.\nc. Compare the results from part (a) and part (b).\nDetermining Sample Size. In Exercises 19–22, assume that each sample is a simple ran-\ndom sample obtained from a normally distributed population. Use Table 7-2 on page 320 to \nfind the indicated sample size.\n 19. IQ of Biostatistics Professors You want to estimate s for the population of IQ scores \nof biostatistics professors. Find the minimum sample size needed to be 95% confident that the ","page_start":341,"page_end":341,"token_count":653,"section_type":"other","chapter_number":8,"chapter_title":"HYPOTHESIS TESTING","chunk_index":461}
{"chunk_id":"9f5a0c5db1762bc0","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"Determining Sample Size. In Exercises 19–22, assume that each sample is a simple ran-\ndom sample obtained from a normally distributed population. Use Table 7-2 on page 320 to \nfind the indicated sample size.\n 19. IQ of Biostatistics Professors You want to estimate s for the population of IQ scores \nof biostatistics professors. Find the minimum sample size needed to be 95% confident that the \nsample standard deviation s is within 1% of s. Is this sample size practical?\n20. ER Waiting Times You want to estimate s for the population of waiting times for hos-\npital emergency rooms. You want to be 99% confident that the sample standard deviation is \nwithin 1% of s. Find the minimum sample size. Is this sample size practical?\n21. Statistics Student Incomes You want to estimate the standard deviation of the annual \nincomes of all current statistics students. Find the minimum sample size needed to be 95% con-\nfident that the sample standard deviation is within 20% of the population standard deviation. \nAre those incomes likely to satisfy the requirement of a normal distribution?\n22. Aspirin Quality When attempting to verify the aspirin contents in manufactured tablets, \nyou must estimate the standard deviation of the population of aspirins in use. Find the mini-\nmum sample size needed to be 99% confident that the sample standard deviation is within 10% \nof the population standard deviation.","page_start":341,"page_end":341,"token_count":306,"section_type":"other","chapter_number":8,"chapter_title":"HYPOTHESIS TESTING","chunk_index":462}
{"chunk_id":"7111f7b33a5e9887","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"324 \nCHAPTER 7 Estimating Parameters and Determining Sample Sizes\n23. Finding Critical Values In constructing confidence intervals for s or s2, Table A-4  can \nbe used to find the critical values x2\nL and x2\nR only for select values of n up to 101, so the number \nof degrees of freedom is 100 or smaller. For larger numbers of degrees of freedom, we can ap-\nproximate x2\nL and x2\nR by using\nx2 = 1\n23 {za>2 + 22k - 142\nwhere k is the number of degrees of freedom and za>2 is the critical z score described in Sec-\ntion 7-1. Use this approximation to find the 95% critical values x2\nL and x2\nR for the acupuncture \ntreatment group in Exercise 16 “Acupuncture for Migraines” where n = 142. How do the \nresults compare to the actual critical values of x2\nL = 110.020 and x2\nR = 175.765?\n24. Finding Sample Size Instead of using Table 7-2 for determining the sample size required \nto estimate a population standard deviation s, the following formula can be used:\nn = 1\n2\n a\nza>2\nd b\n2\nwhere za>2 corresponds to the confidence level and d is the decimal form of the percentage \n error. For example, to be 95% confident that s is within 15% of the value of s, use za>2 = 1.96\nand d = 0.15 to get a sample size of n = 86. Find the sample size required to estimate s, \n assuming that we want 98% confidence that s is within 15% of s.\n7-3 Beyond the Basics\nKey Concept The preceding sections presented methods for estimating population pro-\nportions, means, and standard deviations (or variances). All of those methods have certain \nrequirements that limit the situations in which they can be used. When some of the require-\nments are not satisfied, we can often use the bootstrap method to estimate a parameter with \na confidence interval. The bootstrap method typically requires the use of software.\nSampling Requirement The preceding methods of this chapter all have a require-\nment that the sample must be a simple random sample. If the sample is not collected \nin an appropriate way, there’s a good chance that nothing can be done to get a us-\nable confidence interval estimate of a parameter. Bootstrap methods do not correct for \npoor sampling methods.\nRequirements Listed below are important requirements from the preceding sections \nof this chapter:\n■CI for Proportion (Section 7-1): There are at least 5 successes and at least 5 \nfailures, or np Ú 5 and nq Ú 5.\n■CI for Mean (Section 7-2): The population is normally distributed or n 7 30.\n■CI for S or S2 (Section 7-3): The population must have normally distributed \nvalues, even if the sample is large.\nWhen the above requirements are not satisfied, we should not use the methods pre-","page_start":342,"page_end":342,"token_count":665,"section_type":"other","chapter_number":8,"chapter_title":"HYPOTHESIS TESTING","chunk_index":463}
{"chunk_id":"d82a9047ea8f5d58","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"failures, or np Ú 5 and nq Ú 5.\n■CI for Mean (Section 7-2): The population is normally distributed or n 7 30.\n■CI for S or S2 (Section 7-3): The population must have normally distributed \nvalues, even if the sample is large.\nWhen the above requirements are not satisfied, we should not use the methods pre-\nsented in the preceding sections of this chapter, but we can use the bootstrap method \ninstead. The bootstrap method does not require large samples. This method does not \nrequire the sample to be collected from a normal or any other particular distribution, \nand so it is called a nonparametric or distribution-free method; other nonparamet-\nric methods are included in Chapter 13.\n7-4 \nBootstrapping: Using Technology for Estimates","page_start":342,"page_end":342,"token_count":176,"section_type":"other","chapter_number":8,"chapter_title":"HYPOTHESIS TESTING","chunk_index":464}
{"chunk_id":"e5e2c3ee69885ce8","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"7-4 Bootstrapping: Using Technology for Estimates \n325\nWhy Is It Called “Bootstrap”? The term “bootstrap” is used because the data “pull \nthemselves up by their own bootstraps” to generate new data sets. In days of yore, \n“pulling oneself up by one’s bootstraps” meant that an impossible task was somehow \naccomplished, and the bootstrap method described in this section might seem impos-\nsible, but it works!\nHow Many? In the interest of providing manageable examples that don’t occupy mul-\ntiple pages each, the examples in this section involve very small data sets and no more \nthan 20 bootstrap samples, but we should use at least 1000 bootstrap samples when \nwe use bootstrap methods in serious applications. Professional statisticians commonly \nuse 10,000 or more bootstrap samples.\nBootstrap Procedure for a Confidence Interval Estimate of a Parameter\n1. Given a simple random sample of size n, obtain many (such as 1000 or more) \nbootstrap samples of the same size n.\n2. For the parameter to be estimated, find the corresponding statistic for each \nof the bootstrap samples. (Example: For a confidence estimate of m, find the \n sample mean x from each bootstrap sample.)\n3. Sort the list of sample statistics from low to high.\nDEFINITION\nGiven a simple random sample of size n, a bootstrap sample is another random \nsample of n values obtained with replacement from the original sample.\nCAUTION Note that a bootstrap sample involves sampling with replacement, so \nthat when a sample value is selected, it is replaced before the next selection is \nmade.\nWithout replacement, every sample would be the same as the original sample, so the \nproportions or means or standard deviations or variances would all be the same, and \nthere would be no confidence “interval.”\nEXAMPLE 1  Bootstrap Sample of Incomes\nWhen one of the authors collected annual incomes of current statistics students, he \nobtained these results (in thousands of dollars): 0, 2, 3, 7.\nOriginal Sample\nBootstrap Sample\n0\n7\n2\n2\n3\n2\n7\n3\nThe sample of {7, 2, 2, 3} is one bootstrap sample obtained from the original sam-\nple. Other bootstrap samples may be different.\nIncomes tend to have distributions that are skewed instead of being normal, so \nwe should not use the methods of Section 7-2 with a small sample of incomes. This \nis a situation in which the bootstrap method comes to the rescue.\nhe\nHow Many People  \nDo You Know?\nIt’s difficult for \nanyone to count \nthe number \nof people he \nor she knows, \nbut statistical \nmethods can \nbe used to estimate the mean \nnumber of people that we all \nknow. The simple approach of \njust asking someone how many \npeople are known has worked \npoorly in the past. A much \nbetter approach is to select a \nrepresentative sample of people \nand ask each person how many \npeople he or she knows who ","page_start":343,"page_end":343,"token_count":647,"section_type":"other","chapter_number":8,"chapter_title":"HYPOTHESIS TESTING","chunk_index":465}
{"chunk_id":"295c1985e906ccb7","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"It’s difficult for \nanyone to count \nthe number \nof people he \nor she knows, \nbut statistical \nmethods can \nbe used to estimate the mean \nnumber of people that we all \nknow. The simple approach of \njust asking someone how many \npeople are known has worked \npoorly in the past. A much \nbetter approach is to select a \nrepresentative sample of people \nand ask each person how many \npeople he or she knows who \nare named Marc, Mario, Jason, \nGinny, Rachel, or Todd. (Uncom-\nmon names are more effective \nbecause people with more com-\nmon names are more difficult to \naccurately recall.) Responses \nare then used to project the total \nnumber of people that are known. \n(If sample subjects know a mean \nof 1.76 people with those names, \nand we know that 0.288% of the \npopulation has those names, \nthen the mean number of people \nknown is 1.76>0.00288 = 611.) \nAccording to one estimate, the \nmean number of people known \nis 611, and the median is 472. \n(See “How Many People Do \nYou Know? Efficiently Estimat-\ning Personal Network Size,” by \n McCormick, Salganik, and Zheng, \nJournal of the American Statisti-\ncal Association, Vol. 105, No. 4.)\ncontinued","page_start":343,"page_end":343,"token_count":301,"section_type":"other","chapter_number":8,"chapter_title":"HYPOTHESIS TESTING","chunk_index":466}
{"chunk_id":"802dc63338d2a837","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"326 \nCHAPTER 7 Estimating Parameters and Determining Sample Sizes\n4. Using the sorted list of the statistics, create the confidence interval by find-\ning corresponding percentile values. Procedures for finding percentiles are \ngiven in Section 3-3. (Example: Using a list of sorted sample means, the \n90% confidence interval limits are P5 and P95. The 90% confidence interval \nestimate of m is P5 6 m 6 P95.)\nUsefulness of Results For the purpose of illustrating the bootstrap procedure, \n Examples 2, 3, and 4 all involve very small samples with only 20 bootstrap samples. \nConsequently, the resulting confidence intervals include almost the entire range of \nsample values, and those confidence intervals are not very useful. Larger samples \nwith 1000 or more bootstrap samples will provide much better results than those \nfrom Examples 2, 3, and 4.\nProportions\nWhen working with proportions, it is very helpful to represent the data from the two \ncategories by using 0’s and 1’s, as in the following example.\nTABLE 7-3 Bootstrap Samples for p\nBootstrap Sample\npn\nSorted pn\n1\n0\n0\n1\n0.50\n0.00\nP5 = 0.00\n1\n0\n1\n0\n0.50\n0.00\n0\n1\n1\n1\n0.75\n0.00\n0\n0\n0\n0\n0.00\n0.00\n0\n1\n0\n0\n0.25\n0.25\n1\n0\n0\n0\n0.25\n0.25\n0\n1\n0\n1\n0.50\n0.25\n1\n0\n0\n0\n0.25\n0.25\n0\n0\n0\n0\n0.00\n0.25\n0\n0\n1\n1\n0.50\n0.25\n90% Confidence Interval:\n0\n0\n0\n1\n0.25\n0.25\n0.00 6 p 6 0.75\n0\n0\n1\n0\n0.25\n0.25\n1\n1\n1\n0\n0.75\n0.50\n0\n0\n0\n0\n0.00\n0.50\n0\n0\n0\n0\n0.00\n0.50\n0\n1\n1\n0\n0.50\n0.50\n0\n0\n1\n0\n0.25\n0.50\n1\n0\n0\n0\n0.25\n0.75\n1\n1\n1\n0\n0.75\n0.75\nP95 = 0.75\n0\n0\n0\n1\n0.25\n0.75\nEXAMPLE 2  Eye Color Survey: Bootstrap CI for Proportion\nIn a survey, four randomly selected subjects were asked if they have brown eyes, and here are the results: 0, \n0, 1, 0 (where 0 = no and 1 = yes). Use the bootstrap resampling procedure to construct a 90% confidence ","page_start":344,"page_end":344,"token_count":674,"section_type":"other","chapter_number":8,"chapter_title":"HYPOTHESIS TESTING","chunk_index":467}
{"chunk_id":"702899d4316b9857","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"1\n1\n1\n0\n0.75\n0.75\nP95 = 0.75\n0\n0\n0\n1\n0.25\n0.75\nEXAMPLE 2  Eye Color Survey: Bootstrap CI for Proportion\nIn a survey, four randomly selected subjects were asked if they have brown eyes, and here are the results: 0, \n0, 1, 0 (where 0 = no and 1 = yes). Use the bootstrap resampling procedure to construct a 90% confidence \ninterval estimate of the population proportion p, the proportion of people with brown eyes in the population.\nSOLUTION\nREQUIREMENT CHECK The sample is a simple random sample. \n(There is no requirement of at least 5 successes and at least 5 \nfailures, or np Ú 5 and nq Ú 5. There is no requirement that \nthe sample must be from a normally distributed population.) \nStep 1: In Table 7-3, we created 20 bootstrap samples from \nthe original sample of 0, 0, 1, 0.\nStep 2: Because we want a confidence interval estimate of the \npopulation proportion p, we want the sample proportion pn for \neach of the 20 bootstrap samples, and those sample propor-\ntions are shown in the column to the right of the bootstrap \nsamples.\nStep 3: The column of data shown farthest to the right is a list \nof the 20 sample proportions arranged in order (“sorted”) from \nlowest to highest.\nStep 4: Because we want a confidence level of 90%, we want \nto find the percentiles P5 and P95. Recall that P5 separates the \nlowest 5% of values, and P95 separates the top 5% of values. \nUsing the methods from Section 3-3 for finding percentiles, \nwe use the sorted list of bootstrap sample proportions to find \nthat P5 = 0.00 and P95 = 0.75. The 90% confidence interval \nestimate of the population proportion is 0.00 6 p 6 0.75.\nINTERPRETATION\nThe confidence interval of 0.00 6 p 6 0.75 is quite wide. After all, every confidence interval for every pro-\nportion must fall between 0 and 1, so the 90% confidence interval of 0.00 6 p 6 0.75 doesn’t seem to be \nhelpful, but it is based on only four sample values.","page_start":344,"page_end":344,"token_count":537,"section_type":"other","chapter_number":8,"chapter_title":"HYPOTHESIS TESTING","chunk_index":468}
{"chunk_id":"7ebcff95d2a9241c","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"7-4 Bootstrapping: Using Technology for Estimates \n327\nMeans\nIn Section 7-2 we noted that when constructing a confidence interval estimate of a \npopulation mean, there is a requirement that the sample is from a normally distributed \npopulation or the sample size is greater than 30. The bootstrap method can be used \nwhen this requirement is not satisfied.\nHINT Example 2 uses only 20 bootstrap samples, but effective use of the bootstrap \nmethod typically requires the use of software to generate 1000 or more bootstrap \nsamples.\nTABLE 7-4 Bootstrap Samples for m\nBootstrap Sample\nx\nSorted x\n3\n3\n0\n2\n2.00\n1.75\nP5 = 1.75\n0\n3\n2\n2\n1.75\n1.75\n7\n0\n2\n7\n4.00\n1.75\n3\n2\n7\n3\n3.75\n2.00\n0\n0\n7\n2\n2.25\n2.00\n7\n0\n0\n3\n2.50\n2.25\n3\n0\n3\n2\n2.00\n2.50\n3\n7\n3\n7\n5.00\n2.50\n0\n3\n2\n2\n1.75\n2.50\n0\n3\n7\n0\n2.50\n2.75\n90% Confidence Interval:\n0\n7\n2\n2\n2.75\n3.00\n1.75 6 m 6 4.875\n7\n2\n2\n3\n3.50\n3.25\n7\n2\n3\n7\n4.75\n3.25\n2\n7\n2\n7\n4.50\n3.50\n0\n7\n2\n3\n3.00\n3.75\n7\n3\n7\n2\n4.75\n4.00\n3\n7\n0\n3\n3.25\n4.50\n0\n0\n3\n7\n2.50\n4.75\n3\n3\n7\n0\n3.25\n4.75\nP95 = 4.875\n2\n0\n2\n3\n1.75\n5.00\nEXAMPLE 3  Incomes: Bootstrap CI for Mean\nWhen one of the authors collected a simple random sample of annual incomes of his statistics students, he obtained \nthese results (in thousands of dollars): 0, 2, 3, 7. Use the bootstrap resampling procedure to construct a 90% confi-\ndence interval estimate of the mean annual income of the population of all of the author’s statistics students.\nSOLUTION\nREQUIREMENT CHECK The sample is a simple random sample and there is no requirement that the sample must be from \na normally distributed population. Because distributions of incomes are typically skewed instead of normal, we should \nnot use the methods of Section 7-2 for finding the confidence interval, but the bootstrap method can be used. \nStep 1: In Table 7-4, we created 20 bootstrap samples \n(with replacement!) from the original sample of 0, 2, 3, ","page_start":345,"page_end":345,"token_count":679,"section_type":"other","chapter_number":8,"chapter_title":"HYPOTHESIS TESTING","chunk_index":469}
{"chunk_id":"3b1ce99206c62851","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"a normally distributed population. Because distributions of incomes are typically skewed instead of normal, we should \nnot use the methods of Section 7-2 for finding the confidence interval, but the bootstrap method can be used. \nStep 1: In Table 7-4, we created 20 bootstrap samples \n(with replacement!) from the original sample of 0, 2, 3, \n7. (Here we use only 20 bootstrap samples, so we have a \nmanageable example that doesn’t occupy many pages of \ntext, but we usually want at least 1000 bootstrap samples.)\nStep 2: Because we want a confidence interval estimate \nof the population mean m, we want the sample mean x for \neach of the 20 bootstrap samples, and those sample means \nare shown in the column to the right of the bootstrap \nsamples.\nStep 3: The column of data shown farthest to the right is \na list of the 20 sample means arranged in order (“sorted”) \nfrom lowest to highest.\nStep 4: Because we want a confidence level of 90%, we \nwant to find the percentiles P5 and P95. Again, P5 separates \nthe lowest 5% of values, and P95 separates the top 5% of \nvalues. Using the methods from Section 3-3 for finding \npercentiles, we use the sorted list of bootstrap sample \nmeans to find that P5 = 1.75 and P95 = 4.875. The 90% \nconfidence interval estimate of the population mean is \n1.75 6 m 6 4.875, where the values are in thousands of \ndollars.\nStandard Deviations\nIn Section 7-3 we noted that when constructing confidence interval estimates of popu-\nlation standard deviations or variances, there is a requirement that the sample must \nbe from a population with normally distributed values. Even if the sample is large, ","page_start":345,"page_end":345,"token_count":403,"section_type":"other","chapter_number":8,"chapter_title":"HYPOTHESIS TESTING","chunk_index":470}
{"chunk_id":"dbfbce024cc98ab0","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"328 \nCHAPTER 7 Estimating Parameters and Determining Sample Sizes\nthis normality requirement is much stricter than the normality requirement used for \nestimating population means. Consequently, the bootstrap method becomes more im-\nportant for confidence interval estimates of s or s2.\nEXAMPLE 4  Incomes: Bootstrap CI for Standard Deviation\nUse these same incomes (thousands of dollars) from Example 3: 0, 2, 3, 7. Use the \nbootstrap resampling procedure to construct a 90% confidence interval estimate of \nthe population standard deviation s, the standard deviation of the annual incomes of \nthe population of the author’s statistics students.\nSOLUTION\nREQUIREMENT CHECK The same requirement check used in Example 3 applies  \nhere. \nThe same basic procedure used in Example 3 is used here. Example 3 already \nincludes 20 bootstrap samples, so here we find the standard deviation of each \nbootstrap sample, and then we sort them to get this sorted list of sample standard \ndeviations:\n1.26 1.26 1.26 1.41 1.41 2.22 2.31 2.38 2.63 2.63\n2.87 2.87 2.89 2.94 2.99 3.30 3.32 3.32 3.32 3.56\nThe 90% confidence interval limits are found from this sorted list of standard devia-\ntions by finding P5 and P95. Using the methods from Section 3-3, we get P5 = 1.26 \nand P95 = 3.44. The 90% confidence interval estimate of the population standard \ndeviation s is 1.26 6 s 6 3.44, where the values are in thousands of dollars.\nAgain, know that for practical reasons, the examples of this section involved very \nsmall data sets and no more than 20 bootstrap samples, but use at least 1000 bootstrap \nsamples. The use of 10,000 or more bootstrap samples is common.\nBootstrap Resampling\nAccess tech instructions, videos, and data sets at www.TriolaStats.com\nTECH CENTER \nStatistical Literacy and Critical Thinking \n1. Replacement Why does the bootstrap method require sampling with replacement? What \nwould happen if we used the methods of this section but sampled without replacement?\n2. Bootstrap Sample Here is a random sample of numbers of patients in a day who required \nmedication at a clinic: 12, 19, 13, 43, 15. For this sample, what is a bootstrap sample?\n3. Bootstrap Sample Given the sample data from Exercise 2, which of the following are not \npossible bootstrap samples?\na. 12, 19, 13, 43, 15 \nb. 12, 19, 15 \nc. 12, 12, 12, 43, 43\nd. 14, 20, 12, 19, 15 \ne. 12, 13, 13, 12, 43, 15, 19\n7-4 Basic Skills and Concepts\n","page_start":346,"page_end":346,"token_count":672,"section_type":"other","chapter_number":8,"chapter_title":"HYPOTHESIS TESTING","chunk_index":471}
{"chunk_id":"1b0e4a67f503359a","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"7-4 Bootstrapping: Using Technology for Estimates \n329\n4. How Many? The examples in this section all involved no more than 20 bootstrap samples. \nHow many should be used in real applications?\nIn Exercises 5–8, use the relatively small number of given bootstrap samples to construct \nthe confidence interval.\n5. Survey Responses In a physician’s office, four patients are asked if they would be willing \nto complete a survey before leaving. Responses included these: no, yes, no, no. Letting “yes”\n= 1 and letting “no” = 0, here are ten bootstrap samples for those responses: {0, 0, 0, 0}, \n{1, 0, 1, 0}, {1, 0, 1, 0}, {0, 0, 0, 0}, {0, 0, 0, 0}, {0, 1, 0, 0}, {0, 0, 0, 0}, {0, 0, 0, 0}, \n{0, 1, 0, 0}, {1, 1, 0, 0}. Using only the ten given bootstrap samples, construct a 90% confi-\ndence interval estimate of the proportion of patients who said that they would be willing to \ncomplete the survey.\n6. ER Admissions An emergency room official records whether patients are admitted to the \nhospital, and the results include these: admitted, admitted, not admitted, not admitted. Letting \n“admitted” = 1 and letting “not admitted” = 0, here are ten bootstrap samples for these pa-\ntients: {0, 0, 0, 0}, {0, 1, 0, 0}, {0, 1, 0, 1}, {0, 0, 1, 0}, {1, 1, 1, 0}, {0, 1, 1, 0}, {1, 0, 0, 1}, \n{0, 1, 1, 1}, {1, 0, 1, 0}, {1, 0, 0, 1}. Using only the ten given bootstrap samples, construct an \n80% confidence interval estimate of the proportion of patients who are admitted.\n7. Freshman 15 Here is a sample of amounts of weight change (kg) of college students in their \nfreshman year (from Data Set 10 “Freshman 15” in Appendix B): 11, 3, 0, -2, where -2 repre-\nsents a loss of 2 kg and positive values represent weight gained. Here are ten bootstrap samples: \n{11, 11, 11, 0}, {11, -2, 0, 11}, {11, -2, 3, 0}, {3, -2, 0, 11}, {0, 0, 0, 3}, {3, -2, 3, -2}, ","page_start":347,"page_end":347,"token_count":661,"section_type":"other","chapter_number":8,"chapter_title":"HYPOTHESIS TESTING","chunk_index":472}
{"chunk_id":"8fb415cd0263a0c9","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"sents a loss of 2 kg and positive values represent weight gained. Here are ten bootstrap samples: \n{11, 11, 11, 0}, {11, -2, 0, 11}, {11, -2, 3, 0}, {3, -2, 0, 11}, {0, 0, 0, 3}, {3, -2, 3, -2}, \n{11, 3, -2, 0}, {-2, 3, -2, 3}, {-2, 0, -2, 3}, {3, 11, 11, 11}.\na. Using only the ten given bootstrap samples, construct an 80% confidence interval estimate \nof the mean weight change for the population.\nb. Using only the ten given bootstrap samples, construct an 80% confidence interval estimate \nof the standard deviation of the weight changes for the population.\n8. Cell Phone Radiation Here is a sample of measured radiation emissions (cW>kg) for cell \nphones (based on data from the Environmental Working Group): 38, 55, 86, 145. Here are \nten bootstrap samples: {38, 145, 55, 86}, {86, 38, 145, 145}, {145, 86, 55, 55}, {55, 55, 55, \n145}, {86, 86, 55, 55}, {38, 38, 86, 86}, {145, 38, 86, 55}, {55, 86, 86, 86}, {145, 86, 55, 86}, \n{38, 145, 86, 55}.\na. Using only the ten given bootstrap samples, construct an 80% confidence interval estimate \nof the population mean.\nb. Using only the ten given bootstrap samples, construct an 80% confidence interval estimate \nof the population standard deviation.\nIn Exercises 9–22, use technology to create the large number of bootstrap samples.\n9. Freshman 15 Repeat Exercise 7 “Freshman 15” using a confidence level of 90% for parts \n(a) and (b) and using 1000 bootstrap samples instead of the 10 that were given in Exercise 7.\n10. Cell Phone Radiation Repeat Exercise 8 “Cell Phone Radiation” using a confidence \nlevel of 90% for parts (a) and (b), using 1000 bootstrap samples instead of the 10 that were \ngiven in Exercise 8.\n11. ER Wait Times The District of Columbia has some of the longest emergency room wait-\ning times in the United States. Here are times (minutes) patients waited in District of Columbia \nemergency rooms before seeing a physician: 40, 68, 72, 67, 54, 59, 68, 47, 55, 74, 63, 73. Use \nthe bootstrap method with 1000 bootstrap samples.\na. Construct a 99% confidence interval estimate of the population mean. Is the result dramati-","page_start":347,"page_end":347,"token_count":661,"section_type":"other","chapter_number":8,"chapter_title":"HYPOTHESIS TESTING","chunk_index":473}
{"chunk_id":"2ccf79314802f566","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"ing times in the United States. Here are times (minutes) patients waited in District of Columbia \nemergency rooms before seeing a physician: 40, 68, 72, 67, 54, 59, 68, 47, 55, 74, 63, 73. Use \nthe bootstrap method with 1000 bootstrap samples.\na. Construct a 99% confidence interval estimate of the population mean. Is the result dramati-\ncally different from the 99% confidence interval that would be found using the confidence \ninterval constructed by using the t distribution, as in Section 7-2?\ncontinued","page_start":347,"page_end":347,"token_count":131,"section_type":"other","chapter_number":8,"chapter_title":"HYPOTHESIS TESTING","chunk_index":474}
{"chunk_id":"49235f9ccfe9ee6f","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"330 \nCHAPTER 7 Estimating Parameters and Determining Sample Sizes\nb. Construct a 95% confidence interval estimate of the population standard deviation. Is the \nresult dramatically different from the 95% confidence interval that would be found using the x2\ndistribution, as in Section 7-3?\n12. ER Wait Times Repeat Exercise 11 “ER Wait Times” using these emergency room wait-\ning times (minutes) from Florida: 29, 49, 31, 24, 14, 37, 43, 40, 35, 34, 10, 38, 2, 54.\n13. Lipitor In clinical trials of the drug Lipitor (atorvastatin), 863 subjects were treated with \n10 mg of the drug, and 8 of them experienced allergic reactions. Use the bootstrap method to \nconstruct a 95% confidence interval estimate of the percentage of treated subjects who experi-\nence allergic reactions. Use 1000 bootstrap samples. How does the result compare to the confi-\ndence interval found in Exercise 22 from Section 7-1 on page 296?\n14. Eliquis The drug Eliquis (apixaban) is used to help prevent blood clots in certain patients. \nIn clinical trials, among 5924 patients treated with Eliquis, 153 developed the adverse reaction \nof nausea (based on data from Bristol-Myers Squibb Co.). Use the bootstrap method to con-\nstruct a 99% confidence interval estimate of the proportion of patients who experience nausea. \nUse 1000 bootstrap samples. How does the result compare to the confidence interval found in \nExercise 14 “Eliquis” from Section 7-1 on page 295?\n15. Survey Return Rate In a study of cell phone use and brain hemispheric dominance, an In-\nternet survey was e-mailed to 5000 subjects randomly selected from an online otological group \n(focused on ears), and 717 surveys were returned. Use the bootstrap method to construct a 90% \nconfidence interval estimate of the proportion of returned surveys. Use 1000 bootstrap samples. \nHow does the result compare to the confidence interval found in Exercise 15 “Survey Return \nRate” from Section 7-1 on page 295?\n16. Medical Malpractice In a study of 1228 randomly selected medical malpractice lawsuits, \nit was found that 856 of them were dropped or dismissed (based on data from the Physicians \nInsurers Association of America). Use the bootstrap method to construct a 95% confidence in-\nterval estimate of the proportion of lawsuits that are dropped or dismissed. Use 1000 bootstrap \nsamples. How does the result compare to the confidence interval found in Exercise 16 “Medi-\ncal Malpractice” from Section 7-1 on page 295?\n17. Student Evaluations Listed below are student evaluation ratings of courses, where a \nrating of 5 is for “excellent.” The ratings were obtained at the University of Texas at Austin. \nUsing the bootstrap method with 1000 bootstrap samples, construct a 90% confidence interval ","page_start":348,"page_end":348,"token_count":649,"section_type":"other","chapter_number":8,"chapter_title":"HYPOTHESIS TESTING","chunk_index":475}
{"chunk_id":"3df81241e7cb3c1f","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"samples. How does the result compare to the confidence interval found in Exercise 16 “Medi-\ncal Malpractice” from Section 7-1 on page 295?\n17. Student Evaluations Listed below are student evaluation ratings of courses, where a \nrating of 5 is for “excellent.” The ratings were obtained at the University of Texas at Austin. \nUsing the bootstrap method with 1000 bootstrap samples, construct a 90% confidence interval \nestimate of m. How does the result compare to the result that would be obtained by using the \nmethods from Section 7-2?\n3.8 3.0 4.0 4.8 3.0 4.2 3.5 4.7 4.4 4.2 4.3 3.8 3.3 4.0 3.8\n18. Caffeine in Soft Drinks Listed below are measured amounts of caffeine (mg per 12 oz of \ndrink) obtained in one can from each of 20 brands. Using the bootstrap method with 1000 bootstrap \nsamples, construct a 99% confidence interval estimate of m. How does the result compare to the \nconfidence interval found in Exercise 21 “Caffeine in Soft Drinks” in Section 7-2 on page 312?\n0 0 34 34 34 45 41 51 55 36 47 41 0 0 53 54 38 0 41 47\n 19. Cell Phone Radiation Here are the measured radiation emissions (in W>kg) from differ-\nent cell phones: 0.38, 0.55, 1.54, 1.55, 0.50, 0.60, 0.92, 0.96, 1.00, 0.86, 1.46. Use the bootstrap \nmethod with 1000 bootstrap samples to find a 90% confidence interval estimate of m. How does \nthe result compare to the confidence interval found for Exercise 17 in Section 7-2 on page 311?\n 20. Cell Phone Radiation Repeat Exercise 19 using the standard deviation instead of the mean. \nCompare the confidence interval to the one that would be found using the methods of Section 7-3.\n21. Analysis of Last Digits Weights of respondents were recorded as part of the California \nHealth Interview Survey. The last digits of weights from 50 randomly selected respondents are \nlisted below.\n5 0 1 0 2 0 5 0 5 0 3 8 5 0 5 0 5 6 0 0 0 0 0 0 8\n5 5 0 4 5 0 0 4 0 0 0 0 0 8 0 9 5 3 0 5 0 0 0 5 8\ncontinued","page_start":348,"page_end":348,"token_count":625,"section_type":"other","chapter_number":8,"chapter_title":"HYPOTHESIS TESTING","chunk_index":476}
{"chunk_id":"83bc1cdf196dae3e","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"a. Use the bootstrap method with 1000 bootstrap samples to find a 95% confidence interval \nestimate of s.\nb. Find the 95% confidence interval estimate of s found by using the methods of Section 7-3.\nc. Compare the results. If the two confidence intervals are different, which one is better? Why?\n22. Analysis of Last Digits Repeat Exercise 21 “Analysis of Last Digits” using the mean in-\nstead of the standard deviation. Compare the confidence interval to the one that would be found \nusing the methods of Section 7-2.\n23. Effect of the Number of Bootstrap Samples Repeat Exercise 21 “Analysis of Last \nDigits” using 10,000 bootstrap samples instead of 1000. What happens?\n24. Distribution Shapes Use the sample data given in Exercise 21 “Analysis of Last Digits.” \na. Do the original sample values appear to be from a normally distributed population? Explain.\nb. Do the 1000 bootstrap samples appear to have means that are from a normally distributed \npopulation? Explain.\nc. Do the 1000 bootstrap samples appear to have standard deviations that are from a normally \ndistributed population? Explain.\n7-4 Beyond the Basics\n1. Vision Correction Here is a 95% confidence interval estimate of the proportion of adults \nwho correct their vision by wearing contact lenses: 0.110 6 p 6 0.150 (based on data from a \nVision Council survey). What is the best point estimate of the proportion of adults in the popu-\nlation who correct their vision by wearing contact lenses?\n2.  Interpreting CI Write a brief statement that correctly interprets the confidence interval \ngiven in Exercise 1.\n3. Critical Value For the survey described in Exercise 1, find the critical value that would be \nused for constructing a 99% confidence interval estimate of the population proportion.\n4. Vision Correction From the same survey results cited in Exercise 1 “Vision Correction,” it \nwas reported that 3% of adults correct their vision with surgery, and the margin of error is {1.0\npercentage points. Identify the confidence interval.\n5. Sample Size for Proportion Find the sample size required to estimate the percentage of \ncollege students who take a statistics course. Assume that we want 95% confidence that the \nproportion from the sample is within four percentage points of the true population percentage.\n6. Sample Size for Mean Find the sample size required to estimate the mean IQ of surgeons. \nAssume that we want 98% confidence that the mean from the sample is within three IQ points \nof the true population mean. Also assume that s = 15.\n7. Requirements A quality control analyst has collected a random sample of 12 batteries used \nin heart pacemakers and she plans to test their voltage level and construct a 95% confidence \ninterval estimate of the mean voltage level for the population of batteries. What requirements \nmust be satisfied in order to construct the confidence interval using the method with the t dis-\ntribution?\n8. Degrees of Freedom In general, what does “degrees of freedom” refer to? For the sample ","page_start":349,"page_end":349,"token_count":656,"section_type":"other","chapter_number":8,"chapter_title":"HYPOTHESIS TESTING","chunk_index":477}
{"chunk_id":"4b6236421ba4a93c","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"7. Requirements A quality control analyst has collected a random sample of 12 batteries used \nin heart pacemakers and she plans to test their voltage level and construct a 95% confidence \ninterval estimate of the mean voltage level for the population of batteries. What requirements \nmust be satisfied in order to construct the confidence interval using the method with the t dis-\ntribution?\n8. Degrees of Freedom In general, what does “degrees of freedom” refer to? For the sample \ndata described in Exercise 7, find the number of degrees of freedom, assuming that you want to \nconstruct a confidence interval estimate of m using the t distribution.\nChapter Quick Quiz\nCHAPTER 7 Chapter Quick Quiz \n331","page_start":349,"page_end":349,"token_count":144,"section_type":"other","chapter_number":8,"chapter_title":"HYPOTHESIS TESTING","chunk_index":478}
{"chunk_id":"201514195a3e0e03","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"332 \nCHAPTER 7 Estimating Parameters and Determining Sample Sizes\n9. Critical Value Refer to Exercise 7 and assume that the requirements are satisfied. Find the \ncritical value that would be used for constructing a 95% confidence interval estimate of m using \nthe t distribution.\n10. Which Method? Refer to Exercise 7 and assume that a sample of 12 voltage levels ap-\npears to be from a population with a distribution that is substantially far from being normal. \nShould a 95% confidence interval estimate of s be constructed using the x2 distribution? If \nnot, what other method could be used to find a 95% confidence interval estimate of s?\nReview Exercises\n1. Brain Cancer Cluster In a study designed to determine whether there was a cluster of brain \ncancer cases at a Pratt & Whitney plant, records from 223,000 employees were studied and \n723 employees with brain tumors were found. Treat those employees as a random sample and \nconstruct a 95% confidence interval estimate of the proportion of all adults who develop such \ntumors. Write a brief statement interpreting that confidence interval.\n2. Medicare A hospital wants to estimate the percentage of admitted patients who receive \nMedicare benefits. If we want to estimate that percentage based on examination of randomly \nselected patient payment records, how many patient records must be examined in order to be \n90% confident that we are within four percentage points of the population percentage?\n3. Cuckoo Egg Lengths Listed below are lengths (mm) of cuckoo eggs.\na. Identify the best point estimate of the population mean m.\nb. Construct a 95% confidence interval estimate of the mean length of all cuckoo eggs.\nc. Write a statement that interprets the confidence interval.\n22.05 22.05 22.05 22.05 22.05 22.05 22.05 22.05 22.05 22.05 22.25 22.25\n4. Lefties There have been several studies conducted in an attempt to identify ways in which \nleft-handed people are different from those who are right handed. Assume that you want to \nestimate the mean IQ of all left-handed adults. How many random left-handed adults must \nbe tested in order to be 99% confident that the mean IQ of the sample group is within four IQ \npoints of the mean IQ of all left-handed adults? Assume that s is known to be 15.\n5. Distributions Identify the distribution (normal, Student t, chi-square) that should be used \nin each of the following situations. If none of the three distributions can be used, what other \nmethod could be used?\na. In constructing a confidence interval of m, you have 75 sample values and they appear to be \nfrom a population with a skewed distribution. The population standard deviation is not known.\nb. In constructing a confidence interval estimate of m, you have 75 sample values and they ap-\npear to be from a population with a skewed distribution. The population standard deviation is \nknown to be 18.2 cm.\nc. In constructing a confidence interval estimate of s, you have 75 sample values and they ","page_start":350,"page_end":350,"token_count":660,"section_type":"other","chapter_number":8,"chapter_title":"HYPOTHESIS TESTING","chunk_index":479}
{"chunk_id":"52d8914424eecd1a","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"from a population with a skewed distribution. The population standard deviation is not known.\nb. In constructing a confidence interval estimate of m, you have 75 sample values and they ap-\npear to be from a population with a skewed distribution. The population standard deviation is \nknown to be 18.2 cm.\nc. In constructing a confidence interval estimate of s, you have 75 sample values and they \n appear to be from a population with a skewed distribution.\nd. In constructing a confidence interval estimate of s, you have 75 sample values and they \n appear to be from a population with a normal distribution.\ne. In constructing a confidence interval estimate of p, you have 1200 survey respondents and \n5% of them answered “yes” to the first question.\n6. Sample Size You have been assigned the task of conducting a survey to study prescription \nmedication purchases of adults.\na. If you want to estimate the percentage of adults who have purchased prescription medication \nduring the past 30 days, how many adults must you survey if you want 95% confidence that \nyour percentage has a margin of error of three percentage points?\ncontinued","page_start":350,"page_end":350,"token_count":235,"section_type":"other","chapter_number":8,"chapter_title":"HYPOTHESIS TESTING","chunk_index":480}
{"chunk_id":"1b6a44fb80dd28a2","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"b. If you want to estimate the mean amount that adults have spent on prescription medications \nduring the past 30 days, how many adults must you survey if you want 95% confidence that your \nsample mean is in error by no more than $5? (Based on results from a pilot study, assume that \nthe standard deviation of amounts spent on prescription medications in the past 30 days is $39.)\nc. If you plan to obtain the estimates described in parts (a) and (b) with a single survey having \nseveral questions, how many adults must be surveyed?\n7. Aspirin Generic aspirin tablets are supposed to contain 325 mg of aspirin. Listed below are \nthe measured amounts of aspirin (mg) found in randomly selected tablets. Construct a 95% \nconfidence interval estimate of the mean amount of aspirin in tablets. Do these tablets appear \nto be acceptable?\n330 358 318 338 317 329 339 324 409 248 357 315\n8. Aspirin\na. Use the sample data from Exercise 7 and construct a 95% confidence interval estimate of s.\nb. Assume that we want almost all of the tablets to contain between 315 mg and 335 mg of aspi-\nrin. Find the range, then use the range rule of thumb to estimate the desired standard deviation.\nc. Based on the results from parts (a) and (b), what do you conclude?\n9. Bootstrap for Aspirin Repeat Exercise 7 using 1000 bootstrap samples. How does the re-\nsult compare to the confidence interval found in Exercise 7?\n10. CI for Proportion In a TE Connectivity survey of 1000 randomly selected adults, 2% said \nthat they “did not know” when asked if they felt comfortable being in a self-driving vehicle. \nThere is a need to construct a 95% confidence interval estimate of the proportion of all adults in \nthe population who don’t know.\na. Find the confidence interval using the normal distribution as an approximation to the \n binomial distribution.\nb. Find the confidence interval using 1000 bootstrap samples.\nc. Compare the results.\nCHAPTER 7 Cumulative Review Exercises \n333\nFeet. Listed below are lengths (cm) of feet of adult males. Use these values for Exercises 1–5.\n26.7 25.9 26.4 29.2 26.8 28.1 25.4 27.9 27.5 28.8\n1. Statistics Find the mean, median, standard deviation, and range. Are the results statistics or \nparameters?\n2. Range Rule of Thumb Use the results from Exercise 1 with the range rule of thumb to find \nthe limits separating those that are significantly low and those that are significantly high. Is a \nfoot length of 30 cm significantly high (or long)?\n3. Level of Measurement What is the level of measurement of the foot lengths (nominal, or-\ndinal, interval, ratio)? Are the original unrounded foot lengths continuous data or discrete data?","page_start":351,"page_end":351,"token_count":651,"section_type":"other","chapter_number":8,"chapter_title":"HYPOTHESIS TESTING","chunk_index":481}
{"chunk_id":"ab990e7d15ff0992","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"parameters?\n2. Range Rule of Thumb Use the results from Exercise 1 with the range rule of thumb to find \nthe limits separating those that are significantly low and those that are significantly high. Is a \nfoot length of 30 cm significantly high (or long)?\n3. Level of Measurement What is the level of measurement of the foot lengths (nominal, or-\ndinal, interval, ratio)? Are the original unrounded foot lengths continuous data or discrete data?\n4. Distribution Do the given data appear to be from a normally distributed population? Explain.\n5. Confidence Interval Construct a 95% confidence interval estimate of the mean foot length \nfor the population of all adult males.\n6. Sample Size Find the sample size necessary to estimate the mean foot length for the popu-\nlation of adult females. Assume that we want 95% confidence that the sample mean is in error \nby no more than 0.1 cm. Based on a prior study, assume that adult females have foot lengths \nwith a standard deviation of 1.12 cm.\nCumulative Review Exercises","page_start":351,"page_end":351,"token_count":225,"section_type":"other","chapter_number":8,"chapter_title":"HYPOTHESIS TESTING","chunk_index":482}
{"chunk_id":"7b1b149a7ae61e36","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"334 \nCHAPTER 7 Estimating Parameters and Determining Sample Sizes\n7. Foot Lengths Based on Data Set 7 “Foot and Height,” assume that women have foot lengths \nthat are normally distributed with a mean of 24.20 cm and a standard deviation of 1.12 cm.\na. Find the probability that a randomly selected woman has a foot length greater than 25.00 cm.\nb. Find the probability that 25 randomly selected women have foot lengths with a mean greater \nthan 25.00 cm.\nc. For the population of foot lengths of women, find the 95th percentile.\n8. Piercing, Tattoos, Infections Survey subjects were asked if they knew that body pierc-\nings and tattoos can transmit infectious disease. There were 1440 responses of “yes” and 48 \nresponses of “no” (based on data from “Body Piercing and Tattoos: A Survey on Young Adults’ \nKnowledge of the Risks and Practices in Body Art,” by Quaranta et al., BioMed Central Public \nHealth, published online). Find the 99% confidence interval estimate of the percentage of those \nwho know that body piercings and tattoos can transmit infectious disease. Does the population \nappear to be well informed about the risk of infectious disease?\nBody Temperatures Data Set 2 “Body Temperatures” in Appendix B includes body tempera-\ntures (°F) of a sample of healthy adults. Use technology for the following.\na. Find the mean and standard deviation of the body temperatures at 8 AM on day 2.\nb. Generate a histogram and normal quantile plot of the body temperatures at 8 AM on day \n2. Does it appear that the temperatures are from a population having a normal distribution? \nExplain.\nc. In obtaining a 95% confidence interval estimate of the body temperatures of all adults, are \nthe requirements for using a t distribution satisfied? Explain.\nd. Find a 95% confidence interval estimate of the mean body temperature of all adults.\ne. Find a 95% confidence interval estimate of the mean body temperature of all adults, using \n1000 bootstrap samples.\nf. What do you conclude about the common belief that the mean body temperature is 98.6°F?\nTechnology Project\nFROM DATA TO DECISION\nCritical Thinking: What does the survey tell us?\nSurveys have become an integral part of our lives. Because \nit is so important that every citizen has the ability to interpret \nsurvey results, surveys are the focus of this project.\nFour researchers conducted a survey of 717 subjects. Here \nare some findings (based on data from “Hemispheric Domi-\nnance and Cell Phone Use,” by Seidman et al., JAMA  \nOtolaryngology - Head Neck Surgery, Vol. 139, No. 5):\n•  The respondents include 642 right-handed subjects, 69 left-\nhanded subjects, and 6 ambidextrous subjects.\n•  Among the 642 right-handed subjects, 436 prefer to use \ntheir right ear for cell phone use, 166 prefer their left ear, \nand 40 have no preference.","page_start":352,"page_end":352,"token_count":657,"section_type":"other","chapter_number":8,"chapter_title":"HYPOTHESIS TESTING","chunk_index":483}
{"chunk_id":"7f8e22ead1fd5c37","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"Otolaryngology - Head Neck Surgery, Vol. 139, No. 5):\n•  The respondents include 642 right-handed subjects, 69 left-\nhanded subjects, and 6 ambidextrous subjects.\n•  Among the 642 right-handed subjects, 436 prefer to use \ntheir right ear for cell phone use, 166 prefer their left ear, \nand 40 have no preference.\n•  Among the 69 left-handed subjects, 16 prefer to use their \nright ear for cell phone use, 50 prefer their left ear, and 3 \nhave no preference.\nAnalyzing the Data\n1. Use the survey results to construct a 95% confidence inter-\nval estimate of the proportion of all right-handed people who \nprefer their right ear for cell phone use.\n2. Use the result from part (a) and identify the margin of error.\n3. A common criticism of surveys is that they poll only a very \nsmall percentage of the population and therefore cannot be \naccurate. Is a sample of only 717 people taken from a large \npopulation a sample size that is too small? Write a brief ex-\nplanation of why the sample size of 717 is or is not too small.\n4. Does it appear that most right-handed people prefer their \nright ear for cell phone use? Does it appear that most left-\nhanded people prefer their left ear for cell phone use?\n5. The survey was e-mailed to 5000 people and 717 surveys \nwere returned. What does the response rate suggest about the re-\nsults? What does the sampling method suggest about the results?","page_start":352,"page_end":352,"token_count":339,"section_type":"other","chapter_number":8,"chapter_title":"HYPOTHESIS TESTING","chunk_index":484}
{"chunk_id":"877b42095abb00a7","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"1. Out-of-class activity Collect sample data, and use the methods of this chapter to construct \nconfidence interval estimates of population parameters. Here are some suggestions for parameters:\n• Proportion of students at your college who can raise one eyebrow without raising the other \neyebrow.\n• Mean pulse rate of male college students, or mean pulse rate of female college students.\n• Mean length of words in New York Times editorials and mean length of words in a profes-\nsional journal, such as Journal of the American Medical Association.\n• Proportion of students at your college who have consumed an alcoholic beverage within the \nlast seven days.\n• Mean number of hours that students at your college study each week.\n2. In-class activity Without using any measuring device, each student should draw a line \nbelieved to be 3 in. long and another line believed to be 3 cm long. Then use rulers to measure \nand record the lengths of the lines drawn. Find the means and standard deviations of the two \nsets of lengths. Use the sample data to construct a confidence interval for the length of the line \nestimated to be 3 in., and then do the same for the length of the line estimated to be 3 cm. Do \nthe confidence interval limits actually contain the correct length? Compare the results. Do the \nestimates of the 3-in. line appear to be more accurate than those for the 3-cm line?\n3. In-class activity Assume that a method of gender selection can affect the probability of a baby \nbeing a girl, so that the probability becomes 1>4. Each student should simulate 20 births by drawing \n20 cards from a shuffled deck. Replace each card after it has been drawn, then reshuffle. Consider \nthe hearts to be girls and consider all other cards to be boys. After making 20 selections and record-\ning the “genders” of the babies, construct a confidence interval estimate of the proportion of girls. \nDoes the result appear to be effective in identifying the true value of the population proportion? (If \ndecks of cards are not available, use some other way to simulate the births, such as using the random \nnumber generator on a calculator or using digits from phone numbers or Social Security numbers.)\n4. Out-of-class activity Groups of three or four students should go to the library and collect \na sample consisting of the ages of books (based on copyright dates). Plan and describe the \nsampling procedure, execute the sampling procedure, and then use the results to construct a \nconfidence interval estimate of the mean age of all books in the library.\n5. In-class activity Each student should estimate the length of the classroom. The values \nshould be based on visual estimates, with no actual measurements being taken. After the es-\ntimates have been collected, construct a confidence interval, then measure the length of the \nroom. Does the confidence interval contain the actual length of the classroom? Is there a “col-\nlective wisdom,” whereby the class mean is approximately equal to the actual room length?\n6. In-class activity Divide into groups of three or four. Examine a sample of different issues \nof a current magazine and find the proportion of pages that include advertising. Based on the ","page_start":353,"page_end":353,"token_count":664,"section_type":"other","chapter_number":8,"chapter_title":"HYPOTHESIS TESTING","chunk_index":485}
{"chunk_id":"ed6dc98ddac20c8e","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"timates have been collected, construct a confidence interval, then measure the length of the \nroom. Does the confidence interval contain the actual length of the classroom? Is there a “col-\nlective wisdom,” whereby the class mean is approximately equal to the actual room length?\n6. In-class activity Divide into groups of three or four. Examine a sample of different issues \nof a current magazine and find the proportion of pages that include advertising. Based on the \nresults, construct a 95% confidence interval estimate of the percentage of all such pages that \nhave advertising. Compare results with other groups.\n7. Out-of-class activity Identify a topic of general interest and coordinate with all members \nof the class to conduct a survey. Instead of conducting a “scientific” survey using sound prin-\nciples of random selection, use a convenience sample consisting of respondents who are read-\nily available, such as friends, relatives, and other students. Analyze and interpret the results. \nIdentify the population. Identify the shortcomings of using a convenience sample, and try to \nidentify how a sample of subjects randomly selected from the population might be different.\n8. Out-of-class activity Each student should find an article in a professional journal that in-\ncludes a confidence interval of the type discussed in this chapter. Write a brief report describing \nthe confidence interval and its role in the context of the article.\nCooperative Group Activities\nCHAPTER 7 Cooperative Group Activities \n335","page_start":353,"page_end":353,"token_count":296,"section_type":"other","chapter_number":8,"chapter_title":"HYPOTHESIS TESTING","chunk_index":486}
{"chunk_id":"81c399f59b86551c","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"336\nBasics of Hypothesis \nTesting\nTesting a Claim About a \nProportion\nTesting a Claim About a \nMean\nTesting a Claim About \na Standard Deviation or \nVariance\n8-1\n8-2\n8-3\n8-4\nDoes the MicroSort Method of Gender Selection \nIncrease the Likelihood That a Baby Will Be a Girl?\nCHAPTER \nPROBLEM\nHypothesis Testing\nGender selection methods are somewhat controversial. Some \npeople believe that use of such methods should be prohib-\nited, regardless of the reason. Others believe that limited use \nshould be allowed for medical reasons, such as to prevent \ngender-specific hereditary disorders. For example, some cou-\nples carry X-linked recessive genes, so that a male child has a \n50% chance of inheriting a serious disorder and a female child \nhas no chance of inheriting the disorder. These couples may \nwant to use a gender selection method to increase the likeli-\nhood of having a baby girl so that none of their children inherit \nthe disorder.\nMethods of gender selection have been around for many \nyears. In the 1980s, ProCare Industries sold a product called \nGender Choice. It cost only $49.95, but the Food and Drug \n8 \n","page_start":354,"page_end":354,"token_count":266,"section_type":"other","chapter_number":8,"chapter_title":"HYPOTHESIS TESTING","chunk_index":487}
{"chunk_id":"4b9c6ec2434430f6","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"Administration told the company to stop distributing Gender \nChoice because there was no evidence to support the claim \nthat it was 80% reliable.\nThe Genetics & IVF Institute developed a newer gen-\nder selection method called MicroSort. Clinical trials for \nthis method were never completed and MicroSort was not \nbrought to market. The MicroSort XSORT method was de-\nsigned to increase the likelihood of a baby girl, and the \nYSORT method was designed to increase the likelihood of \na boy. The MicroSort website included this statement: “The \nGenetics & IVF Institute is offering couples the ability to in-\ncrease the chance of having a child of the desired gender \nto reduce the probability of X-linked diseases or for family \nbalancing.” For a cost exceeding $3000, the Genetics & IVF \nInstitute claimed that it could increase the probability of hav-\ning a baby of the gender that a couple prefers. In clinical tri-\nals, among 945 babies born to parents who used the XSORT \nmethod in trying to have a baby girl, 879 couples did have \nbaby girls, for a success rate of 93%. Under normal circum-\nstances with no special treatment, girls occur in about 50% \nof births. (Actually, the current birth rate of girls is 48.8%, but \nwe will use 50% to keep things simple.) These results provide \nus with an interesting question: Given that 879 out of 945 \ncouples had girls, can we actually support the claim that the \nXSORT technique is effective in increasing the probability of \na girl? When the Genetics & IVF Institute chose to discontinue \nthe clinical trials, does it appear that a major reason was inef-\nfectiveness of their methods?\nHere are the chapter objectives:\nBasics of Hypothesis Testing\n• Develop the ability to identify the null and alternative hypotheses when given some \nclaim about a population parameter (such as a proportion, mean, standard deviation, \nor variance).\n• Develop the ability to calculate a test statistic, find critical values, calculate P-values, \nand state a final conclusion that addresses the original claim. Here are the compo-\nnents that should be included in the hypothesis test:\n• Statements of the null and alternative hypotheses expressed in symbolic form\n• Value of the test statistic\n• Selection of the sampling distribution to be used for the hypothesis test\n• Identification of a P-value and>or critical value(s)\n• Statement of a conclusion rejecting the null hypothesis or failing to reject the \nnull hypothesis\n• Statement of a final conclusion that uses simple and nontechnical terms to \naddress the original claim\nTesting a Claim About a Proportion\n• Develop the ability to conduct a formal hypothesis test of a claim about a popula-\ntion proportion. The procedure should include the components listed above with the \n objectives for Section 8-1.\nTesting a Claim About a Mean\n• Develop the ability to use sample data to conduct a formal hypothesis test of a claim \nmade about a population mean. The procedure should include the same compo-\nnents listed above with the objectives for Section 8-1.\n8-1\n8-2\n8-3\nChapter Objectives \n337\nCHAPTER OBJECTIVES\n>>>\n","page_start":355,"page_end":355,"token_count":674,"section_type":"other","chapter_number":8,"chapter_title":"HYPOTHESIS TESTING","chunk_index":488}
{"chunk_id":"530554c32af6b576","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"338 \nCHAPTER 8 Hypothesis Testing\nKey Concept In this section we present key components of a formal hypothesis test. \nThe concepts in this section are general and apply to hypothesis tests involving pro-\nportions, means, or standard deviations or variances. In Part 1, we begin with the “big \npicture” to understand the basic underlying approach to hypothesis tests. Then we de-\nscribe null and alternative hypotheses, significance level, types of tests (two-tailed, \nleft-tailed, right-tailed), test statistic, P-value, critical values, and statements of conclu-\nsions. In Part 2 we describe types of errors (type I and type II). In Part 3 we describe \nthe power of a hypothesis test.\nPART 1\n Basic Concepts of Hypothesis Testing\nWe begin with two very basic definitions.\n8-1 \nBasics of Hypothesis Testing\nTesting a Claim About a Standard Deviation or Variance\n• Develop the ability to use sample data to conduct a formal hypothesis test of a claim \nmade about a population standard deviation or variance. The procedure should in-\nclude the same components listed with the objectives for Section 8-1.\n8-4\nTesting a Claim About a Standard Deviation or Variance\n• Develop the ability to use sample data to conduct a formal hypothesis test of a claim\nmade about a population standard deviation or variance. The procedure should in-\nclude the same components listed with the objectives for Section 8-1.\nDEFINITIONS\nIn statistics, a hypothesis is a claim or statement about a property of a population.\nA hypothesis test (or test of significance) is a procedure for testing a claim about \na property of a population.\nThe “property of a population” referred to in the preceding definitions is often the \nvalue of a population parameter, so here are some examples of typical hypotheses (or \nclaims):\n \n■m 6 98.6°F “The mean body temperature of humans is less than 98.6°F.”\n \n■p 7 0.5 “The proportion of girls born to parents using the XSORT method of \ngender selection is greater than 0.5.”\n \n■s = 15 “The population of nurses has IQ scores with a standard deviation equal \nto 15.”\nEXAMPLE 1  XSORT Method of Gender Selection\nConsider the claim from the Chapter Problem that “the XSORT technique is effec-\ntive in increasing the probability of a girl.” Using p to denote the proportion of girls \nborn to parents using the XSORT method of gender selection, the “effective” claim \nis equivalent to the claim that the proportion is significantly greater than half, or \np 7 0.5. The expression p 7 0.5 is the symbolic form of the original claim.\n","page_start":356,"page_end":356,"token_count":581,"section_type":"other","chapter_number":8,"chapter_title":"HYPOTHESIS TESTING","chunk_index":489}
{"chunk_id":"b98e4cfb6eb1dc06","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"8-1 Basics of Hypothesis Testing \n339\nThe Big Picture In Example 1, we have the claim that the proportion p is such that \np 7 0.5. Among 945 babies, how many do we need to get a significantly high number \nof girls?\n \n■A result of 473 girls (or 50.1%) could easily occur by chance under normal cir-\ncumstances with no treatment, so 473 is not significantly high.\n \n■The actual result of 879 girls (or 93.0%) appears to be significantly high.\nThe method of hypothesis testing gives us a standard and widely accepted procedure \nfor deciding whether such results are significant.\nUsing Technology It is easy to obtain hypothesis-testing results using technology. The \naccompanying screen displays show results from different technologies, so we can use \ncomputers or calculators to do all of the computational heavy lifting. Examining the \nscreen displays, we see some common elements. They all display a “test statistic” of \nz = 26.45 (rounded), and they all include a “P-value” of 0.0000 (rounded). These two \nresults are important, but understanding the hypothesis-testing procedure is critically \nimportant. Focus on understanding how the hypothesis-testing procedure works and \nlearn the associated terminology. Only then will results from technology make sense.\nStatdisk\nMinitab\nTI-83 , 84 Plus\nXLSTAT\nStatCrunch\nSignificance Hypothesis tests are also called tests of significance. In Section 4-1 we \nused probabilities to determine when sample results are significantly low or signifi-\ncantly high. This chapter formalizes those concepts in a unified procedure that is used \noften throughout many different fields of application. Figure 8-1 on the next page \nsummarizes the procedures used in two slightly different methods for conducting a \nformal hypothesis test. We will proceed to conduct a formal test of the claim from \nExample 1 that p 7 0.5. In testing that claim, we will use the sample data from the \nresults cited in the Chapter Problem, with x = 879 girls among n = 945 births.\nat \ner \nAspirin Not Helpful for \nGeminis and Libras\nPhysician \nRichard Peto \nsubmitted an ar-\nticle to Lancet, a \nBritish medical \njournal. The \narticle showed \nthat patients \nhad a better chance of surviving \na heart attack if they were treated \nwith aspirin within a few hours of \ntheir heart attacks. Lancet editors \nasked Peto to break down his \nresults into subgroups to see if \nrecovery worked better or worse \nfor different groups, such as \nmales or females. Peto believed \nthat he was being asked to use \ntoo many subgroups, but the edi-\ntors insisted. Peto then agreed, \nbut he supported his objections \nby showing that when his pa-\ntients were categorized by signs \nof the zodiac, aspirin was useless \nfor Gemini and Libra heart attack \npatients, but aspirin is a lifesaver \nfor those born under any other \nsign. This shows that when con-\nducting multiple hypothesis tests \nwith many different subgroups, \nthere is a very large chance of \ngetting some wrong results.\n","page_start":357,"page_end":357,"token_count":689,"section_type":"other","chapter_number":8,"chapter_title":"HYPOTHESIS TESTING","chunk_index":490}
{"chunk_id":"f0dfd6facdb3d833","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"340 \nCHAPTER 8 Hypothesis Testing\n8. Restate Decision in Nontechnical Terms\nConstruct a conﬁdence interval with a conﬁdence \nlevel selected as in Table 8-1.\nBecause a conﬁdence interval estimate of a population\nparameter contains the likely values of that parameter,\nreject a claim that the population parameter has a value\nthat is not included in the conﬁdence interval.\nTable 8-1\nSigniﬁcance \n0.01\nLevel for \n0.05\nHypothesis \n0.10\nTest\nTwo-Tailed Test\nOne-Tailed Test\n99%\n95%\n90%\n98%\n90%\n80%\nConﬁdence Level for Conﬁdence Interval\nConﬁdence Interval Method\nRestate this previous decision in simple nontechnical terms, and \naddress the original claim.\n5. Identify the Test Statistic\nIdentify the test statistic that is relevant to the test and determine its \nsampling distribution (such as normal, t, chi-square).\n4. Select Signiﬁcance Level\nSelect the signiﬁcance level A based on the seriousness of a type type I error. \nMake A small if the consequences of rejecting a true H0 are severe.\n \n• The values of 0.05 and 0.01 are very common.\n2. Give Symbolic Form\nGive the symbolic form that must be true when the original claim is false.\n1. Identify the Claim\nIdentify the claim to be tested and express it in symbolic form.\n3. Identify Null and Alternative Hypothesis\nConsider the two symbolic expressions obtained so far:\n \n• Alternative hypothesis H1 is the one NOT containing equality, so H1 uses \n \n the symbol . or , or Þ.\n \n• Null hypothesis H0 is the symbolic expression that the parameter equals\n \n the ﬁxed value being considered.\n7. Make a Decision\n• Reject H0 if P-value # a.\n• Fail to reject H0 if P-value . a.\n6. Find Values\nFind the value of the test statistic and the \nP-value (see Figure 8-3). Draw a graph and \nshow the test statistic and P-value.\n7. Make a Decision\n• Reject H0 if the test statistic is in the\ncritical region.\n• Fail to reject H0 if the test statistic is not in \nthe critical region.\n6. Find Values\nP-Value Method\nCritical Value Method\nFind the value of the test statistic and the \ncritical values. Draw a graph showing the test \nstatistic, critical value(s) and critical region.\nFIGURE 8-1  \nProcedure for \nHypothesis Tests\n","page_start":358,"page_end":358,"token_count":569,"section_type":"other","chapter_number":8,"chapter_title":"HYPOTHESIS TESTING","chunk_index":491}
{"chunk_id":"f4ed10383fb24c82","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"8-1 Basics of Hypothesis Testing \n341\nSteps 1, 2, 3: Use the Original Claim to Create a Null \nHypothesis H0 and an Alternative Hypothesis H1\nThe objective of Steps 1, 2, 3 is to identify the null hypothesis and alternative \nhypothesis so that the formal hypothesis test includes these standard components that \nare often used in many different disciplines. The null hypothesis includes the working \nassumption for the purposes of conducting the test.\nDEFINITIONS\nThe null hypothesis (denoted by H0) is a statement that the value of a popula-\ntion parameter (such as proportion, mean, or standard deviation) is equal to some \nclaimed value.\nThe alternative hypothesis (denoted by H1 or Ha or HA) is a statement that the pa-\nrameter has a value that somehow differs from the null hypothesis. For the methods \nof this chapter, the symbolic form of the alternative hypothesis must use one of \nthese symbols: 6, 7, ≠.\nThe term null is used to indicate no change or no effect or no difference. We conduct \nthe hypothesis test by assuming that the parameter is equal to some specified value so \nthat we can work with a single distribution having a specific value.\nExample: Here is an example of a null hypothesis involving a proportion:\nH0: p = 0.5\nExample: Here are different examples of alternative hypotheses involving proportions:\nH1: p 7 0.5  H1: p 6 0.5  H1: p ≠0.5\nGiven the claim from Example 1 that the gender selection method is effective in \nincreasing the probability that a baby will be a girl, we can apply Steps 1, 2, and 3 in \nFigure 8-1 as follows.\nStep 1:  Identify the claim to be tested and express it in symbolic form. Using p to \ndenote the probability of selecting a girl, the claim that the gender selection is effec-\ntive can be expressed in symbolic form as p 7 0.5.\nStep 2:  Give the symbolic form that must be true when the original claim is false. If \nthe original claim of p 7 0.5 is false, then p … 0.5 must be true.\nStep 3:  This step is in two parts: Identify the alternative hypothesis H1 and identify \nthe null hypothesis H0.\n• Identify H1: Using the two symbolic expressions p 7 0.5 and p … 0.5, the alter-\nnative hypothesis H1 is the one that does not contain equality. Of those two ex-\npressions, p 7 0.5 does not contain equality, so we get\nH1: p 7 0.5\n• Identify H0: The null hypothesis H0 is the symbolic expression that the parameter \nequals the fixed value being considered, so we get\nH0: p = 0.5\nThe result of the first three steps is the identification of the null and alternative \nhypotheses:\nH0: p = 0.5 1null hypothesis2\nH1: p 7 0.5 1alternative hypothesis2\n","page_start":359,"page_end":359,"token_count":680,"section_type":"other","chapter_number":8,"chapter_title":"HYPOTHESIS TESTING","chunk_index":492}
{"chunk_id":"b4486445e4265ab9","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"342 \nCHAPTER 8 Hypothesis Testing\nNote About Forming Your Own Claims (Hypotheses): If you are conducting a study \nand want to use a hypothesis test to support your claim, your claim must be worded so \nthat it becomes the alternative hypothesis (and can be expressed using only the symbols \n6, 7, or ≠). You can never support a claim that a parameter is equal to a specified value.\nStep 4: Select the Significance Level A\nTABLE 8-2\nParameter\nSampling Distribution\nRequirements\nTest Statistic\nProportion p\nNormal (z)\nnp Ú 5 and nq Ú 5\nz = pn - p\nA\npq\nn\nMean m\nt\ns not known and normally \ndistributed population\nor\ns not known and n 7 30\nt =\nx - m\ns\n2n\nMean m\nNormal (z)\ns known and normally dis-\ntributed population\nor\ns known and n 7 30\nz =\nx - m\ns\n2n\nSt. dev. s or  \nvariance s2\nx2\nStrict requirement: normally \ndistributed population\nx2 =\n1n - 12s2\ns2\nStep 6: Find the Value of the Test Statistic, Then Find \nEither the P-Value or the Critical Value(s)\nDEFINITION\nThe test statistic is a value used in making a decision about the null hypothesis. It \nis found by converting the sample statistic (such as pn, x, or s) to a score (such as \nz, t, or x2) with the assumption that the null hypothesis is true.\nDEFINITION\nThe significance level A for a hypothesis test is the probability value used as the \ncutoff for determining when the sample evidence constitutes significant evidence \nagainst the null hypothesis. By its nature, the significance level a is the probability \nof mistakenly rejecting the null hypothesis when it is true:\nSignificance level A = P1rejecting H0 when H0 is true2\nThe significance level a is the same a introduced in Section 7-1, where we defined \n“critical value.” Common choices for a are 0.05, 0.01, and 0.10; 0.05 is the most com-\nmon choice.\nStep 5: Identify the Statistic Relevant to the Test and \nDetermine Its Sampling Distribution (such as normal, t,  \nor X2 )\nTable 8-2 lists parameters along with the corresponding sampling distributions.\nExample: The claim p 7 0.5 is a claim about the population proportion p, so use \nthe normal distribution provided that the requirements are satisfied. (With n = 945, \np = 0.5, and q = 0.5 from Example 1, np Ú 5 and nq Ú 5 are both true.)\n","page_start":360,"page_end":360,"token_count":610,"section_type":"other","chapter_number":8,"chapter_title":"HYPOTHESIS TESTING","chunk_index":493}
{"chunk_id":"a78bdc122fa200ce","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"8-1 Basics of Hypothesis Testing \n343\nIn this chapter we use the test statistics listed in the last column of Table 8-2.\nExample: Preliminary results from the XSORT method of gender selection in-\nvolved 14 babies, with 13 of them being girls. Here we have n = 14 and x = 13, so \npn = x>n = 13>14 = 0.929. With the null hypothesis of H0: p = 0.5, we are working \nwith the assumption that p = 0.5, and it follows that q = 1 - p = 0.5. We can evalu-\nate the test statistic as shown below (or technology can find the test statistic for us).\nz = pn - p\nA\npq\nn\n=\n13\n14 - 0.5\nB\n10.5210.52\n14\n= 3.21\nFinding the P-value and>or critical value(s) requires that we first consider whether the \nhypothesis test is two-tailed, left-tailed, or right-tailed, which are described as follows.\nTwo-Tailed, Left-Tailed, Right-Tailed\nDEFINITION\nThe critical region (or rejection region) is the area corresponding to all values of \nthe test statistic that cause us to reject the null hypothesis.\nDepending on the claim being tested, the critical region could be in the two extreme \ntails, it could be in the left tail, or it could be in the right tail.\n■Two-tailed test: The critical region is in the two extreme regions (tails) under \nthe curve (as in the top graph in Figure 8-2).\n■Left-tailed test: The critical region is in the extreme left region (tail) under the \ncurve (as in the middle graph in Figure 8-2).\n■Right-tailed test: The critical region is in the extreme right region (tail) under \nthe curve (as in the bottom graph in Figure 8-2).\nSign used in H1: Þ\nTwo-tailed test\nSign used in H1: ,\nLeft-tailed test\nSign used in H1: .\nRight-tailed test\nFIGURE 8-2 Critical \nRegion in Two-Tailed, \nLeft-Tailed, and Right-\nTailed Tests\nHINT Look at the symbol used in the alternative hypothesis H1.\n• The symbol 7 points to the right and the test is right-tailed.\n• The symbol 6 points to the left and the test is left-tailed.\n• The symbol ≠is used for a two-tailed test.\nExample: With H0: p = 0.5 and H1: p 7 0.5, we reject the null hypothesis and \n support the alternative hypothesis only if the sample proportion is greater than 0.5 \nby a signiﬁcant amount, so the hypothesis test in this case is right-tailed.\nP-Value Method\nWith the P-value method of testing hypotheses, we make a decision by comparing \nthe P-value to the significance level.\nDEFINITION","page_start":361,"page_end":361,"token_count":653,"section_type":"other","chapter_number":8,"chapter_title":"HYPOTHESIS TESTING","chunk_index":494}
{"chunk_id":"7b8f885dbb41947a","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"Example: With H0: p = 0.5 and H1: p 7 0.5, we reject the null hypothesis and \n support the alternative hypothesis only if the sample proportion is greater than 0.5 \nby a signiﬁcant amount, so the hypothesis test in this case is right-tailed.\nP-Value Method\nWith the P-value method of testing hypotheses, we make a decision by comparing \nthe P-value to the significance level.\nDEFINITION\nIn a hypothesis test, the P-value is the probability of getting a value of the test sta-\ntistic that is at least as extreme as the test statistic obtained from the sample data, \nassuming that the null hypothesis is true.","page_start":361,"page_end":361,"token_count":149,"section_type":"other","chapter_number":8,"chapter_title":"HYPOTHESIS TESTING","chunk_index":495}
{"chunk_id":"11781070ffd1f15e","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"344 \nCHAPTER 8 Hypothesis Testing\nTo find the P-value, first find the area beyond the test statistic, then use the procedure \ngiven in Figure 8-3. That procedure can be summarized as follows:\n \n■Critical region in left tail:  P-value = area to the left of the test statistic\n \n■Critical region in right tail: P-value = area to the right of the test statistic\n \n■Critical region in two tails: P-value = twice the area in the tail beyond the test \nstatistic\nP-value\nP-value is\ntwice this area.\nTest statistic\nTest statistic\nTest statistic\nTest statistic\nP-value is\ntwice this area.\nP-value\nIs the test\nstatistic to the\nright or left of\ncenter?\nLeft\nRight\nLeft-tailed\nRight-tailed\nP-value 5 twice the\narea to the left of\nthe test statistic\nP-value 5 area to\nthe left of the\ntest statistic\nP-value 5 twice the\narea to the right of\nthe test statistic\nP-value 5 area to\nthe right of the\ntest statistic\nWhat type\nof test?\nStart\nFIGURE 8-3 Finding P-Values\nExample: Using only the preliminary results of the XSORT method of gender selec-\ntion, we have 13 girls in 14 births and the test statistic is z = 3.21 and it has a normal \ndistribution area of 0.0007 to its right, so a right-tailed test with test statistic z = 3.21\nhas a P-value of 0.0007.\nCAUTION Don’t confuse a P-value with the parameter p or the statistic pn. Know the \nfollowing notation:\nP-value = probability of a test statistic at least as extreme as the one obtained\np = population proportion\npn = sample proportion\nP-Value and Hypothesis Testing Controversy\nThe standard method of testing hypotheses and the use of P-values have very wide-\nspread acceptance and use, but not everyone is convinced that these methods are \nT\ng\nJournal Bans P-Values!\nThe P-value \nmethod \nof testing \nhypotheses \nhas received \nwidespread \nacceptance in \nthe research community, but the \neditors of the journal Basic and \nApplied Social Psychology took a \ndramatic stance when they said \nthat they would no longer publish \narticles that included P-values. In \nan editorial, David Trafimow and \nMichael Marks stated their belief \nthat “the P-value bar is too easy \nto pass and sometimes serves \nas an excuse for lower quality \nresearch.” David Trafimow stated \nthat he did not know which \nstatistical method should replace \nthe use of P-values.\nMany reactions to the P-value \nban acknowledged that although \nP-values can be misused and \nmisinterpreted, their use as a \nvaluable research tool remains.\n","page_start":362,"page_end":362,"token_count":612,"section_type":"other","chapter_number":8,"chapter_title":"HYPOTHESIS TESTING","chunk_index":496}
{"chunk_id":"ccd2edb331ef2826","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"8-1 Basics of Hypothesis Testing \n345\nsound. Editors of the Journal of Basic and Applied Social Psychology took a strong \nstand when they said that they would no longer publish articles that included P-values. \nThey said that P-values are an excuse for lower-quality research and the P-value cri-\nterion is too easy to pass. In the past, P-values have been misinterpreted and misused, \nso a serious and important statistical analysis should not rely solely on P-value results. \nInstead, it would be wise to consider other aspects, such as the following.\n \n■Sample Size: Very large samples could result in small P-values suggesting that \nresults are significant when the results don’t really make much of a practical dif-\nference.\n \n■Power: Part 3 of this section discusses the concept of power, and it is often help-\nful to analyze power as part of an analysis.\n \n■Other Factors: Instead of relying on just one outcome such as the P-value, it \nis generally better to also consider other results, such as a confidence interval, \nresults from simulations, practical significance, design of the study, quality of \nthe sample, consequences of type I and type II errors (discussed in Part 2 of this \n section), and replication of results.\nThis chapter presents the same methods of hypothesis testing and the same use of \nP-values that are currently being used, but again, it should be stressed that important \napplications should also consider other factors, such as those listed above.\nCritical Value Method\nWith the critical value method (or traditional method) of testing hypotheses, we \nmake a decision by comparing the test statistic to the critical value(s).\nDEFINITION\nIn a hypothesis test, the critical value(s) separates the critical region (where we \nreject the null hypothesis) from the values of the test statistic that do not lead to re-\njection of the null hypothesis.\nCritical values depend on the null hypothesis, the sampling distribution, and the sig-\nnificance level a.\nExample: The critical region in Figure 8-4 is shaded in green. Figure 8-4 shows that \nwith a significance level of a = 0.05, the critical value is z = 1.645.\np 5 0.5\nor\nz 5 0\nCritical Region:\nArea of a 5 0.05\nused to identify\nsigniﬁcantly high\nsample proportions\nCritical Value:\nz 5 1.645\nFIGURE 8-4 Critical Value and Critical Region\n","page_start":363,"page_end":363,"token_count":527,"section_type":"other","chapter_number":8,"chapter_title":"HYPOTHESIS TESTING","chunk_index":497}
{"chunk_id":"e62c012be333fbbc","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"346 \nCHAPTER 8 Hypothesis Testing\nStep 7: Make a Decision to Either Reject H0 or Fail  \nto Reject H0.\nDecision Criteria for the P-Value Method:\n■If P-value … a, reject H0. (“If the P is low, the null must go.”)\n■If P-value 7 a, fail to reject H0.\nExample: With significance level a = 0.05 and P-value = 0.0007, we have \nP-value … a, so reject H0. Remember, the P-value is the probability of getting a sample \nresult at least as extreme as the one obtained, so if the P-value is low (less than or \nequal to a), the sample statistic is significantly low or significantly high.\nDecision Criteria for the Critical Value Method:\n■If the test statistic is in the critical region, reject H0.\n■If the test statistic is not in the critical region, fail to reject H0.\nExample: With test statistic z = 3.21 and the critical region from z = 1.645 to infin-\nity, the test statistic falls within the critical region, so reject H0.\nStep 8: Restate the Decision Using Simple and  \nNontechnical Terms\nWithout using technical terms not understood by most people, state a final conclusion \nthat addresses the original claim with wording that can be understood by those with-\nout knowledge of statistical procedures.\nExample: There is sufficient evidence to support the claim that with the XSORT \nmethod of gender selection, the probability of getting a baby girl is greater than 0.5.\nWording the Final Conclusion For help in wording the final conclusion, refer to \nTable 8-3, which lists the four possible circumstances and their corresponding conclu-\nsions. Note that only the first case leads to wording indicating support for the original \nconclusion. If you want to support some claim, state it in such a way that it becomes \nthe alternative hypothesis, and then hope that the null hypothesis gets rejected.\nTABLE 8-3 Wording of the Final Conclusion\nCondition\nConclusion\nOriginal claim does not include equality,  \nand you reject H0.\n“There is sufficient evidence to support the claim \nthat . . . (original claim).”\nOriginal claim does not include equality,  \nand you fail to reject H0.\n“There is not sufficient evidence to support the \nclaim that . . . (original claim).”\nOriginal claim includes equality, and you  \nreject H0.\n“There is sufficient evidence to warrant rejection \nof the claim that . . . (original claim).”\nOriginal claim includes equality, and you fail  \nto reject H0.\n“There is not sufficient evidence to warrant rejec-\ntion of the claim that . . . (original claim).”\nAccept or Fail to Reject? We should say that we “fail to reject the null hypothesis” \ninstead of saying that we “accept the null hypothesis.” The term accept is misleading, \nbecause it implies incorrectly that the null hypothesis has been proved, but we can \nnever prove a null hypothesis. The phrase fail to reject says more correctly that the ","page_start":364,"page_end":364,"token_count":643,"section_type":"other","chapter_number":8,"chapter_title":"HYPOTHESIS TESTING","chunk_index":498}
{"chunk_id":"c332b818f0037fdd","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"to reject H0.\n“There is not sufficient evidence to warrant rejec-\ntion of the claim that . . . (original claim).”\nAccept or Fail to Reject? We should say that we “fail to reject the null hypothesis” \ninstead of saying that we “accept the null hypothesis.” The term accept is misleading, \nbecause it implies incorrectly that the null hypothesis has been proved, but we can \nnever prove a null hypothesis. The phrase fail to reject says more correctly that the \navailable evidence isn’t strong enough to warrant rejection of the null hypothesis.\nMultiple Negatives Final conclusions can include as many as three negative terms. \n(Example: “There is not sufficient evidence to warrant rejection of the claim of no dif-\nference between 0.5 and the population proportion.”) For such confusing conclusions, \nS\nto\nLie Detectors  \nand the Law\nWhy not sim-\nply require all \ncriminal sus-\npects to take \npolygraph (lie \ndetector) tests \nand eliminate \ntrials by jury? According to the \nCouncil of Scientific Affairs of the \nAmerican Medical Association, \nwhen lie detectors are used to \ndetermine guilt, accuracy can \nrange from 75% to 97%. How-\never, a high accuracy rate of 97% \ncan still result in a high percent-\nage of false positives, so it is \npossible that 50% of innocent \nsubjects incorrectly appear to \nbe guilty. Such a high chance of \nfalse positives rules out the use \nof polygraph tests as the single \ncriterion for determining guilt.","page_start":364,"page_end":364,"token_count":321,"section_type":"other","chapter_number":8,"chapter_title":"HYPOTHESIS TESTING","chunk_index":499}
{"chunk_id":"17f718230e2eb144","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"8-1 Basics of Hypothesis Testing \n347\nit is better to restate them to be understandable. Instead of saying that “there is not \nsufficient evidence to warrant rejection of the claim of no difference between 0.5 and \nthe population proportion,” a better statement would be this: “Until stronger evidence \nis obtained, continue to assume that the population proportion is equal to 0.5.”\nCAUTION Never conclude a hypothesis test with a statement of “reject the \nnull hypothesis” or “fail to reject the null hypothesis.” Always make sense of the \nconclusion with a statement that uses simple nontechnical wording that addresses \nthe original claim.\nConfidence Intervals for Hypothesis Tests\nIn this section we have described the individual components used in a hypothesis test, \nbut the following sections will combine those components in comprehensive proce-\ndures. We can test claims about population parameters by using the P-value method \nor the critical value method summarized in Figure 8-1, or we can use confidence \nintervals.\nA confidence interval estimate of a population parameter contains the likely val-\nues of that parameter. If a confidence interval does not include a claimed value of a \npopulation parameter, reject that claim. For two-tailed hypothesis tests, construct a \nconfidence interval with a confidence level of 1 - a, but for a one-tailed hypothesis \ntest with significance level a, construct a confidence interval with a confidence level \nof 1 - 2a. (See Table 8-1 on page 340 for common cases.) For a left-tailed test or a \nright-tailed test, we could also use a one-sided confidence interval; see Exercise 38 in \nSection 7-1. After constructing the confidence interval, use this criterion:\nA conﬁdence interval estimate of a population parameter contains the \nlikely values of that parameter. We should therefore reject a claim that the \npopulation parameter has a value that is not included in the  conﬁdence \ninterval.\nEquivalent Methods\nIn some cases, a conclusion based on a confidence interval may be different from a \nconclusion based on a hypothesis test. The P-value method and critical value method \nare equivalent in the sense that they always lead to the same conclusion. The following \ntable shows that for the methods included in this chapter, a confidence interval estimate \nof a proportion might lead to a conclusion different from that of a hypothesis test.\n \n \nParameter\nIs a confidence interval equivalent to a hypothesis \ntest in the sense that they always lead to the same \nconclusion?\nProportion\nNo\nMean\nYes\nStandard Deviation or Variance\nYes\nPART 2\n Type I and Type II Errors \nWhen testing a null hypothesis, we arrive at a conclusion of rejecting it or failing \nto reject it. Our conclusions are sometimes correct and sometimes wrong (even \nif we apply all procedures correctly). Table 8-4 includes two different types of \n","page_start":365,"page_end":365,"token_count":610,"section_type":"other","chapter_number":8,"chapter_title":"HYPOTHESIS TESTING","chunk_index":500}
{"chunk_id":"554e5a572a5f5fdc","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"348 \nCHAPTER 8 Hypothesis Testing\nerrors and we distinguish between them by calling them type I and type II errors, \nas  described here:\n \n■Type I error: The mistake of rejecting the null hypothesis when it is actually \ntrue. The symbol a (alpha) is used to represent the probability of a type I error.\nA = P1type I error2 = P1rejecting H0 when H0 is true2\n \n■Type II error: The mistake of failing to reject the null hypothesis when it is actu-\nally false. The symbol b (beta) is used to represent the probability of a type II error.\nB = P1type II error2 = P1failing to reject H0 when H0 is false2\nMemory Hint for Type I and Type II Errors Remember “routine for fun,” and use \nthe consonants from those words (RouTiNe FoR FuN) to remember that a type I er-\nror is RTN: Reject True Null (hypothesis), and a type II error is FRFN: Fail to Reject a \nFalse Null (hypothesis).\nHint for Describing Type I and Type II Errors Descriptions of a type I error and \na type II error refer to the null hypothesis being true or false, but when wording a \nstatement representing a type I error or a type II error, be sure that the conclusion \naddresses the original claim (which may or may not be the null hypothesis). See \nExample 2.\nTABLE 8-4 Type I and Type II Errors\nTrue State of Nature\nNull hypothesis is true\nNull hypothesis is false\nPreliminary \nConclusion\nReject H0\nType I error:\nReject a true H0.\nP (type I error) = a\nCorrect decision\nFail to reject H0\nCorrect decision\nType II error:\nFail to reject a false H0.\nP(type II error) = b\nEXAMPLE 2  Describing Type I and Type II Errors\nConsider the claim that the XSORT gender selection method is effective in increas-\ning the likelihood of a baby girl, so that the probability of a baby girl is p 7 0.5. \nGiven the following null and alternative hypotheses, write statements describing  \n(a) a type I error, and (b) a type II error.\nH0: p = 0.5\nH1: p 7 0.5 1original claim that will be addressed in the final conclusion2\nSOLUTION\n \na. Type I Error: A type I error is the mistake of rejecting a true null hypothesis, \nso the following is a type I error: In reality p = 0.5, but sample evidence \nleads us to conclude that p 7 0.5.\n \n •  In this case, a type I error is to conclude that the XSORT gender selection \nmethod is eﬀective when in reality it has no eﬀect.\n","page_start":366,"page_end":366,"token_count":613,"section_type":"other","chapter_number":8,"chapter_title":"HYPOTHESIS TESTING","chunk_index":501}
{"chunk_id":"4d55313fe40c306d","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"8-1 Basics of Hypothesis Testing \n349\nControlling Type I and Type II Errors Step 4 in our standard procedure for test-\ning hypotheses is to select a significance level a (such as 0.05), which is the prob-\nability of a type I error. The values of a, b, and the sample size n are all related, so if \nyou choose any two of them, the third is automatically determined (although b can’t \nbe determined until an alternative value of the population parameter has been speci-\nfied along with a and n). One common practice is to select the significance level a,\nthen select a sample size that is practical, so the value of b is determined. Generally, \ntry to use the largest a that you can tolerate, but for type I errors with more serious \nconsequences, select smaller values of a. Then choose a sample size n as large as is \nreasonable, based on considerations of time, cost, and other relevant factors. Another \ncommon practice is to select a and b so the required sample size n is automatically \ndetermined. (See Example 4 in Part 3 of this section.)\nPART 3\n Power of a Hypothesis Test \nWe use b to denote the probability of failing to reject a false null hypothesis, so \nP(type II error) = b. It follows that 1 - b is the probability of rejecting a false null \nhypothesis, so 1 - b is a probability that is one measure of the effectiveness of a \n hypothesis test.\n \nb. Type II Error: A type II error is the mistake of failing to reject the null hy-\npothesis when it is false, so the following is a type II error: In reality p 7 0.5, \nbut we fail to support that conclusion.\n \n •  In this case, a type II error is to conclude that the XSORT gender selection \nmethod has no eﬀect, when it really is eﬀective in increasing the likelihood \nof a baby girl.\nDEFINITION\nThe power of a hypothesis test is the probability 1 - b of rejecting a false null \nhypothesis. The value of the power is computed by using a particular significance \nlevel a and a particular value of the population parameter that is an alternative to \nthe value assumed true in the null hypothesis.\nBecause determination of power requires a particular value that is an alternative to the \nvalue assumed in the null hypothesis, a hypothesis test can have many different values \nof power, depending on the particular values of the population parameter chosen as \nalternatives to the null hypothesis.\nEXAMPLE 3  Power of a Hypothesis Test\nConsider these preliminary results from the XSORT method of gender selection: \nThere were 13 girls among the 14 babies born to couples using the XSORT method. \nIf we want to test the claim that girls are more likely 1p 7 0.52 with the XSORT \nmethod, we have the following null and alternative hypotheses:\nH0: p = 0.5  H1: p 7 0.5\nLet’s use a significance level of a = 0.05. In addition to all given test components, \nfinding power requires that we select a particular value of p that is an alternative to \ncontinued\n","page_start":367,"page_end":367,"token_count":689,"section_type":"other","chapter_number":8,"chapter_title":"HYPOTHESIS TESTING","chunk_index":502}
{"chunk_id":"89f71c8829577f99","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"350 \nCHAPTER 8 Hypothesis Testing\nBecause the calculations of power are quite complicated, the use of technology is \nstrongly recommended. (In this section, only Exercises 33–35 involve power.)\nPower and the Design of Experiments\nJust as 0.05 is a common choice for a significance level, a power of at least 0.80 is a \ncommon requirement for determining that a hypothesis test is effective. (Some statisti-\ncians argue that the power should be higher, such as 0.85 or 0.90.) When designing an \nexperiment, we might consider how much of a difference between the claimed value of a \nparameter and its true value is an important amount of difference. If testing the effective-\nness of the XSORT gender selection method, a change in the proportion of girls from \n0.5 to 0.501 is not very important, whereas a change in the proportion of girls from 0.5 \nto 0.9 would be very important. Such magnitudes of differences affect power. When de-\nsigning an experiment, a goal of having a power value of at least 0.80 can often be used \nto determine the minimum required sample size, as in the following example.\nthe value assumed in the null hypothesis H0: p = 0.5. Find the values of power cor-\nresponding to these alternative values of p: 0.6, 0.7, 0.8, and 0.9.\nSOLUTION\nThe values of power in the following table were found by using Minitab, and exact \ncalculations are used instead of a normal approximation to the binomial distribution.\nSpecific Alternative Value of p\nb\nPower of Test = 1 −b\n0.6\n0.820\n0.180\n0.7\n0.564\n0.436\n0.8\n0.227\n0.773\n0.9\n0.012\n0.988\nINTERPRETATION\nOn the basis of the power values listed above, we see that this hypothesis test has a \npower of 0.180 (or 18.0%) of rejecting H0: p = 0.5 when the population proportion \np is actually 0.6. That is, if the true population proportion is actually equal to 0.6, \nthere is an 18.0% chance of making the correct conclusion of rejecting the false null \nhypothesis that p = 0.5. That low power of 18.0% is not so good.\nThere is a 0.436 probability of rejecting p = 0.5 when the true value of p is \nactually 0.7. It makes sense that this test is more effective in rejecting the claim \nof p = 0.5 when the population proportion is actually 0.7 than when the popula-\ntion proportion is actually 0.6. (When identifying animals assumed to be horses, \nthere’s a better chance of rejecting an elephant as a horse—because of the greater \ndifference—than rejecting a mule as a horse.) In general, increasing the difference ","page_start":368,"page_end":368,"token_count":660,"section_type":"other","chapter_number":8,"chapter_title":"HYPOTHESIS TESTING","chunk_index":503}
{"chunk_id":"8510579183b8af56","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"actually 0.7. It makes sense that this test is more effective in rejecting the claim \nof p = 0.5 when the population proportion is actually 0.7 than when the popula-\ntion proportion is actually 0.6. (When identifying animals assumed to be horses, \nthere’s a better chance of rejecting an elephant as a horse—because of the greater \ndifference—than rejecting a mule as a horse.) In general, increasing the difference \nbetween the assumed parameter value and the actual parameter value results in an \nincrease in power, as shown in the table above.\nEXAMPLE 4   Finding the Sample Size Required to  \nAchieve 80% Power\nHere is a statement similar to one in an article from the Journal of the American \nMedical Association: “The trial design assumed that with a 0.05 significance level, \n153 randomly selected subjects would be needed to achieve 80% power to detect ","page_start":368,"page_end":368,"token_count":193,"section_type":"other","chapter_number":8,"chapter_title":"HYPOTHESIS TESTING","chunk_index":504}
{"chunk_id":"3446848a62c0a141","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"8-1 Basics of Hypothesis Testing \n351\na reduction in the coronary heart disease rate from 0.5 to 0.4.” From that statement \nwe know the following:\n■Before conducting the experiment, the researchers selected a significance level \nof 0.05 and a power of at least 0.80.\n■The researchers decided that a reduction in the proportion of coronary heart \ndisease from 0.5 to 0.4 is an important and clinically significant difference that \nthey wanted to detect (by correctly rejecting the false null hypothesis).\n■Using a significance level of 0.05, power of 0.80, and the alternative proportion \nof 0.4, technology such as Minitab is used to find that the required minimum \nsample size is 153.\nThe researchers can then proceed by obtaining a sample of at least 153 randomly \nselected subjects. Because of factors such as dropout rates, the researchers are likely \nto need somewhat more than 153 subjects. (See Exercise 35.)\nStatistical Literacy and Critical Thinking \n1. Vitamin C and Aspirin A bottle contains a label stating that it contains Spring Valley pills \nwith 500 mg of vitamin C, and another bottle contains a label stating that it contains Bayer pills \nwith 325 mg of aspirin. When testing claims about the mean contents of the pills, which would \nhave more serious implications: rejection of the Spring Valley vitamin C claim or rejection of \nthe Bayer aspirin claim? Is it wise to use the same significance level for hypothesis tests about \nthe mean amount of vitamin C and the mean amount of aspirin?\n2. Estimates and Hypothesis Tests Data Set 2 “Body Temperatures” in Appendix B in-\ncludes sample body temperatures. We could use methods of Chapter 7 for making an estimate, \nor we could use those values to test the common belief that the mean body temperature is \n98.6°F. What is the difference between estimating and hypothesis testing?\n3. Mean Height of Men A formal hypothesis test is to be conducted using the claim that the \nmean height of men is equal to 174.1 cm.\na. What is the null hypothesis, and how is it denoted?\nb. What is the alternative hypothesis, and how is it denoted?\nc. What are the possible conclusions that can be made about the null hypothesis?\nd. Is it possible to conclude that “there is sufficient evidence to support the claim that the mean \nheight of men is equal to 174.1 cm”?\n4. Interpreting P-value The Ericsson method is one of several methods claimed to increase \nthe likelihood of a baby girl. In a clinical trial, results could be analyzed with a formal hypoth-\nesis test with the alternative hypothesis of p 7 0.5, which corresponds to the claim that the \nmethod increases the likelihood of having a girl, so that the proportion of girls is greater than \n0.5. If you have an interest in establishing the success of the method, which of the following ","page_start":369,"page_end":369,"token_count":629,"section_type":"other","chapter_number":8,"chapter_title":"HYPOTHESIS TESTING","chunk_index":505}
{"chunk_id":"46864ff620203646","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"the likelihood of a baby girl. In a clinical trial, results could be analyzed with a formal hypoth-\nesis test with the alternative hypothesis of p 7 0.5, which corresponds to the claim that the \nmethod increases the likelihood of having a girl, so that the proportion of girls is greater than \n0.5. If you have an interest in establishing the success of the method, which of the following \nP-values would you prefer: 0.999, 0.5, 0.95, 0.05, 0.01, 0.001? Why?\nIdentifying H0 and H1. In Exercises 5–8, do the following:\na. Express the original claim in symbolic form.\nb. Identify the null and alternative hypotheses.\n5. Hypertension Claim: Most adults do not have hypertension. When 983 randomly selected \nadults were tested, it was found that 70.9% of them do not have hypertension.\n8-1 Basic Skills and Concepts","page_start":369,"page_end":369,"token_count":209,"section_type":"other","chapter_number":8,"chapter_title":"HYPOTHESIS TESTING","chunk_index":506}
{"chunk_id":"2ac79d56a91bc46b","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"352 \nCHAPTER 8 Hypothesis Testing\n6. Cell Phones Claim: Fewer than 95% of nurses have a cell phone. In a survey of 1128 \nnurses, 87% said that they have a cell phone.\n7. Pulse Rates Claim: The mean pulse rate (in beats per minute, or bpm) of adult males is \nequal to 69 bpm. For the random sample of 153 adult males in Data Set 1 “Body Data” from \nAppendix B, the mean pulse rate is 69.6 bpm and the standard deviation is 11.3 bpm.\n8. Pulse Rates Claim: The standard deviation of pulse rates of adult males is more than 11 \nbpm. For the random sample of 153 adult males in Data Set 1 “Body Data” from Appendix B, \nthe pulse rates have a standard deviation of 11.3 bpm.\nConclusions. In Exercises 9–12, refer to the exercise identified. Make subjective esti-\nmates to decide whether results are significantly low or significantly high, then state a con-\nclusion about the original claim. For example, if the claim is that a coin favors heads and \nsample results consist of 11 heads in 20 flips, conclude that there is not sufficient evidence \nto support the claim that the coin favors heads (because it is easy to get 11 heads in 20 flips \nby chance with a fair coin).\n9. Exercise 5 “Hypertension” \n10. Exercise 6 “Cell Phone”\n11. Exercise 7 “Pulse Rates” \n12. Exercise 8 “Pulse Rates”\nTest Statistics. In Exercises 13–16, refer to the exercise identified and find the value of the \ntest statistic. (Refer to Table 8-2 on page 342 to select the correct expression for evaluating the \ntest statistic.)\n13. Exercise 5 “Hypertension” \n14. Exercise 6 “Cell Phone”\n15. Exercise 7 “Pulse Rates” \n16. Exercise 8 “Pulse Rates”\nP-Values. In Exercises 17–20, do the following:\na. Identify the hypothesis test as being two-tailed, left-tailed, or right-tailed.\nb. Find the P-value. (See Figure 8-3 on page 344.)\nc. Using a significance level of a = 0.05, should we reject H0 or should we fail to reject H0?\n17. The test statistic of z = 1.00 is obtained when testing the claim that p 7 0.3.\n18. The test statistic of z = -2.50 is obtained when testing the claim that p 6 0.75.\n19. The test statistic of z = 2.01 is obtained when testing the claim that p ≠0.345.\n20. The test statistic of z = -1.94 is obtained when testing the claim that p = 3>8.\nCritical Values. In Exercises 21–24, refer to the information in the given exercise and do \nthe following.\na. Find the critical value(s).","page_start":370,"page_end":370,"token_count":649,"section_type":"other","chapter_number":8,"chapter_title":"HYPOTHESIS TESTING","chunk_index":507}
{"chunk_id":"a5885cad7de1f4c6","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"19. The test statistic of z = 2.01 is obtained when testing the claim that p ≠0.345.\n20. The test statistic of z = -1.94 is obtained when testing the claim that p = 3>8.\nCritical Values. In Exercises 21–24, refer to the information in the given exercise and do \nthe following.\na. Find the critical value(s).\nb. Using a significance level of a = 0.05, should we reject H0 or should we fail to reject H0?\n21. Exercise 17 \n22. Exercise 18\n23. Exercise 19 \n24. Exercise 20\nFinal Conclusions. In Exercises 25–28, use a significance level of A = 0.05 and use the \ngiven information for the following:\na. State a conclusion about the null hypothesis. (Reject H0 or fail to reject H0.)\nb. Without using technical terms or symbols, state a final conclusion that addresses the original \nclaim.\n 25. Original claim: More than 70% of adults do not have hypertension. The hypothesis test \nresults in a P-value of 0.2678.","page_start":370,"page_end":370,"token_count":242,"section_type":"other","chapter_number":8,"chapter_title":"HYPOTHESIS TESTING","chunk_index":508}
{"chunk_id":"ea4a022a0800532a","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"8-1 Basics of Hypothesis Testing \n353\n 26. Original claim: Fewer than 90% of nurses have a cell phone. The hypothesis test results in \na P-value of 0.0003.\n27. Original claim: The mean pulse rate (in beats per minute) of adult males is 72 bpm. The \nhypothesis test results in a P-value of 0.0095.\n28. Original claim: The standard deviation of pulse rates of adult males is more than 11 bpm. \nThe hypothesis test results in a P-value of 0.3045.\nType I and Type II Errors. In Exercises 29–32, provide statements that identify the type I \nerror and the type II error that correspond to the given claim. (Although conclusions are \nusually expressed in verbal form, the answers here can be expressed with statements that \ninclude symbolic expressions such as p = 0.1.)\n29. The proportion of people who write with their left hand is equal to 0.1.\n30. The proportion of people with blue eyes is equal to 0.35.\n31. The proportion of adults who use the Internet is greater than 0.87.\n32. The proportion of people who require no vision correction is less than 0.25.\n33. Interpreting Power Chantix (varenicline) tablets are used as an aid to help people stop \nsmoking. In a clinical trial, 129 subjects were treated with Chantix twice a day for 12 weeks, \nand 16 subjects experienced abdominal pain (based on data from Pfizer, Inc.). If someone \nclaims that more than 8% of Chantix users experience abdominal pain, that claim is supported \nwith a hypothesis test conducted with a 0.05 significance level. Using 0.18 as an alternative \nvalue of p, the power of the test is 0.96. Interpret this value of the power of the test.\n34. Calculating Power Consider a hypothesis test of the claim that the Ericsson method of \ngender selection is effective in increasing the likelihood of having a baby girl, so that the claim \nis p 7 0.5. Assume that a significance level of a = 0.05 is used, and the sample is a simple \nrandom sample of size n = 64.\na. Assuming that the true population proportion is 0.65, find the power of the test, which is \nthe probability of rejecting the null hypothesis when it is false. (Hint: With a 0.05 significance \nlevel, the critical value is z = 1.645, so any test statistic in the right tail of the accompanying \ntop graph is in the rejection region where the claim is supported. Find the sample proportion pn\nin the top graph, and use it to find the power shown in the bottom graph.)\nb\nz 5 1.645\na 5 0.05\np 5 0.5\np 5 0.65\nPower\nb. Explain why the green-shaded region of the bottom graph represents the power of the test.","page_start":371,"page_end":371,"token_count":651,"section_type":"other","chapter_number":8,"chapter_title":"HYPOTHESIS TESTING","chunk_index":509}
{"chunk_id":"32c9ed06797baef3","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"top graph is in the rejection region where the claim is supported. Find the sample proportion pn\nin the top graph, and use it to find the power shown in the bottom graph.)\nb\nz 5 1.645\na 5 0.05\np 5 0.5\np 5 0.65\nPower\nb. Explain why the green-shaded region of the bottom graph represents the power of the test.\n35. Finding Sample Size to Achieve Power Researchers plan to conduct a test of a gender \nselection method. They plan to use the alternative hypothesis of H1: p 7 0.5 and a significance \nlevel of a = 0.05. Find the sample size required to achieve at least 80% power in detecting an \nincrease in p from 0.50 to 0.55. (This is a very difficult exercise. Hint: See Exercise 34.)\n8-1 Beyond the Basics","page_start":371,"page_end":371,"token_count":198,"section_type":"other","chapter_number":8,"chapter_title":"HYPOTHESIS TESTING","chunk_index":510}
{"chunk_id":"eca51dd8919eacd7","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"354 \nCHAPTER 8 Hypothesis Testing\nKey Concept This section describes a complete procedure for testing a claim made \nabout a population proportion p. We illustrate hypothesis testing with the P-value \nmethod, the critical value method, and the use of confidence intervals. The methods of \nthis section can be used with claims about population proportions, probabilities, or the \ndecimal equivalents of percentages.\nThere are different methods for testing a claim about a population proportion. \nPart 1 of this section is based on the use of a normal approximation to a binomial \ndistribution, and this method serves well as an introduction to basic concepts, but it \nis not a method used by professional statisticians. Part 2 discusses other methods that \nmight require the use of technology.\nPART 1\n Normal Approximation Method\nThe following box includes the key elements used for testing a claim about a population \nproportion by using a normal distribution as an approximation to a binomial distribution.\n8-2 \nTesting a Claim About a Proportion\nTesting a Claim About a Population Proportion (Normal Approximation Method)\nObjective\nConduct a formal hypothesis test of a claim about a population proportion p.\nNotation\nKEY ELEMENTS \nn = sample size or number of trials\npn = x\nn (sample proportion)\np =  population proportion (p is the value used in the \nstatement of the null hypothesis)\nq = 1 - p\nRequirements\n1. The sample observations are a simple random sample.\n2. The conditions for a binomial distribution are satisfied:\n • There is a fixed number of trials.\n • The trials are independent.\n • Each trial has two categories of “success” and “failure.”\n • The probability of a success remains the same in all \ntrials.\n3. The conditions np Ú 5 and nq Ú 5 are both satisfied, \nso the binomial distribution of sample proportions \ncan be approximated by a normal distribution with \nm = np and s = 1npq (as described in Section 6-6). \nNote that p used here is the assumed proportion used in \nthe claim, not the sample proportion pn.\nTest Statistic for Testing a Claim About a Proportion\nz = pn - p\nA\npq\nn\nP-Values: P-values are automatically provided by technol-\nogy. If technology is not available, use the standard normal \ndistribution (Table A-2) and refer to Figure 8-1 on page 340.\nCritical Values: Use the standard normal distribution \n(Table A-2).\nThe test statistic does not include a correction for continuity (as described in Section 6-6), \nbecause its effect tends to be very small with large samples.\n","page_start":372,"page_end":372,"token_count":558,"section_type":"other","chapter_number":8,"chapter_title":"HYPOTHESIS TESTING","chunk_index":511}
{"chunk_id":"6dd815eef238bfd6","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"8-2 Testing a Claim About a Proportion \n355\nEquivalent Methods\nWhen testing claims about proportions, the confidence interval method is not equiv-\nalent to the P-value and critical value methods, so the confidence interval method \ncould result in a different conclusion. (Both the P-value method and the critical value \nmethod use the same standard deviation based on the claimed proportion p, so they \nare equivalent to each other, but the confidence interval method uses an estimated \nstandard deviation based on the sample proportion.) Recommendation: Use a confi-\ndence interval to estimate a population proportion, but use the P-value method or criti-\ncal value method for testing a claim about a proportion. See Exercise 30.\nClaim: The XSORT Method of Gender Selection  \nIs Effective\nLet’s use the preliminary results from tests of the XSORT method of gender selection. \nThose preliminary results consisted of 14 babies born to couples using the XSORT \nmethod of gender selection, and 13 of the babies were girls. Use these results to test \nthe claim that most babies born to couples using the XSORT method are girls. We \ninterpret “most” to mean “more than half” or “greater than 0.5.”\nREQUIREMENT CHECK We first check the three requirements.\n1. The 14 babies are not randomly selected, but based on the design of the clinical \ntrial, they can be treated as being random.\n2. There is a fixed number (14) of independent trials with two categories (the baby \nis a girl or is not).\n3. The requirements np Ú 5 and nq Ú 5 are both satisfied with n = 14, \np = 0.5, and q = 0.5. [The value of p = 0.5 comes from the claim. We \nget np = 114210.52 = 7, which is greater than or equal to 5, and we get \nnq = 114210.52 = 7, which is also greater than or equal to 5.]\nThe three requirements are satisfied. \nSolution: P-Value Method\nTechnology Computer programs and calculators usually provide a P-value, so the \nP-value method is used. Different technologies will display the test statistic of \nz = 3.21 and the P-value of 0.0007.\nTable A-2 If technology is not available, Figure 8-1 on page 340 in the preceding sec-\ntion lists the steps for using the P-value method. Using those steps from Figure 8-1, \nwe can test the claim that “most babies born to couples using the XSORT method are \ngirls” as follows.\nStep 1: The original claim is that the XSORT method is effective in increasing the like-\nlihood of a baby girl, and that claim can be expressed in symbolic form as p 7 0.5.\nStep 2: The opposite of the original claim is p … 0.5.\nStep 3: Of the preceding two symbolic expressions, the expression p 7 0.5 does not \ncontain equality, so it becomes the alternative hypothesis. The null hypothesis is the state-","page_start":373,"page_end":373,"token_count":660,"section_type":"other","chapter_number":8,"chapter_title":"HYPOTHESIS TESTING","chunk_index":512}
{"chunk_id":"02273a62613fa68d","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"lihood of a baby girl, and that claim can be expressed in symbolic form as p 7 0.5.\nStep 2: The opposite of the original claim is p … 0.5.\nStep 3: Of the preceding two symbolic expressions, the expression p 7 0.5 does not \ncontain equality, so it becomes the alternative hypothesis. The null hypothesis is the state-\nment that p equals the fixed value of 0.5. We can therefore express H0 and H1 as follows:\nH0: p = 0.5\nH1: p 7 0.5 1original claim2\nv-\nd \nue \ny\nd \nProcess of Drug \nApproval\nGaining Food \nand Drug \nAdministration \n(FDA) approval \nfor a new drug \nis expensive \nand time- \nconsuming. \nHere are the different stages of \ngetting approval for a new drug:\n• Phase I study: The safety of \nthe drug is tested with a small \n(20–100) group of volunteers.\n• Phase II: The drug is tested for \neffectiveness in randomized tri-\nals involving a larger (100–300) \ngroup of subjects. This phase \noften has subjects randomly \nassigned to either a treatment \ngroup or a placebo group.\n• Phase III: The goal is to better \nunderstand the effective-\nness of the drug as well as its \nadverse reactions. This phase \ntypically involves 1,000–3,000 \nsubjects, and it might require \nseveral years of testing.\nLisa Gibbs wrote in Money \nmagazine that “the (drug) indus-\ntry points out that for every 5,000 \ntreatments tested, only 5 make it \nto clinical trials and only 1 ends \nup in drugstores.” Total cost \nestimates vary from a low of  \n$40 million to as much as  \n$1.5 billion.\ncontinued","page_start":373,"page_end":373,"token_count":404,"section_type":"other","chapter_number":8,"chapter_title":"HYPOTHESIS TESTING","chunk_index":513}
{"chunk_id":"c4dbecc0441ad152","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"356 \nCHAPTER 8 Hypothesis Testing\nStep 4: For the significance level, we select a = 0.05, which is a very common \nchoice.\nStep 5: Because we are testing a claim about a population proportion p, the sample sta-\ntistic pn is relevant to this test. The sampling distribution of sample proportions pn can be \napproximated by a normal distribution in this case (as described in Section 6-3).\nStep 6: The test statistic z = 3.21 can be found by using technology, or it can be \ncalculated by using pn = 13>14 (sample proportion), n = 14 (sample size), p = 0.5 \n(assumed in the null hypothesis), and q = 1 - 0.5 = 0.5.\nz = pn - p\nA\npq\nn\n=\n13\n14 - 0.5\nB\n10.5210.52\n14\n= 3.21\nThe P-value can be found from technology, or it can be found by using the fol-\nlowing procedure, which is shown in Figure 8-3 on page 344:\nLeft-tailed test: \nP-value = area to left of test statistic z\nRight-tailed test: \nP-value = area to right of test statistic z\nTwo-tailed test: \nP-value =  twice the area of the extreme region bounded by \nthe test statistic z\nBecause this hypothesis test is right-tailed with a test statistic of z = 3.21, the \nP-value is the area to the right of z = 3.21. Referring to Table A-2, we see that the \ncumulative area to the left of z = 3.21 is 0.9993, so the area to the right of that test \nstatistic is 1 - 0.9993 = 0.0007. We get P-value = 0.0007. Figure 8-5 shows the \ntest statistic and P-value for this example.\nStep 7: Because the P-value of 0.0007 is less than or equal to the significance level \nof a = 0.05, we reject the null hypothesis.\nStep 8: Because we reject H0: p = 0.5, we support the alternative hypothesis of \np 7 0.5. We conclude that there is sufficient sample evidence to support the claim \nthat the XSORT method is effective in increasing the likelihood of a baby girl. (See \nTable 8-3 on page 346 for help with wording this final conclusion.)\np 5 0.5\nor\nz 5 0\nP-value 5 0.0007\np 5     5 0.929\nor\nz 5 3.21\nˆ\n13\n14\nFIGURE 8-5 P-Value Method\np 5 0.5\nor\nz 5 0\nCritical Region:\nArea of a 5 0.05\nused to identify\nsigniﬁcantly high\nsample proportions\nCritical Value:\nz 5 1.645\nFIGURE 8-6 Critical Value Method\n","page_start":374,"page_end":374,"token_count":683,"section_type":"other","chapter_number":8,"chapter_title":"HYPOTHESIS TESTING","chunk_index":514}
{"chunk_id":"71c01028ee581050","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"8-2 Testing a Claim About a Proportion \n357\nSolution: Critical Value Method\nThe critical value method of testing hypotheses is summarized in Figure 8-1 on \npage 340 in Section 8-1. When using the critical value method with the claim that \n“most babies born to couples using the XSORT method are girls,” Steps 1 through \n5 are the same as Steps 1 through 5 for the P-value method, as shown. We continue \nwith Step 6 of the critical value method.\nStep 6: The test statistic is computed to be z = 3.21, as shown for the preceding \nP-value method. With the critical value method, we now find the critical values (in-\nstead of the P-value). This is a right-tailed test, so the area of the critical region is an \narea of a = 0.05 in the right tail. Referring to Table A-2 and applying the methods \nof Section 6-1, we find that the critical value is z = 1.645, which is at the boundary \nof the critical region, as shown in Figure 8-6.\nStep 7: Because the test statistic does fall within the critical region, we reject the null \nhypothesis.\nStep 8: Because we reject H0: p = 0.5, we conclude that there is sufficient sample \nevidence to support the claim that for couples using the XSORT gender selection \nmethod, most (more than half) of their babies are girls.\nSolution: Confidence Interval Method\nThe claim that “with the XSORT method of gender selection, most babies are girls” is \na claim that can be tested with a 0.05 significance level by constructing a 90% confi-\ndence interval. (See Table 8-1 on page 340 to see why the 0.05 significance level cor-\nresponds to a 90% confidence interval.)\nThe 90% confidence interval estimate of the population proportion p is found \nusing the sample data consisting of n = 14 and pn = 13>14. Using the methods of \n Section 7-1 we get: 0.815 6 p 6 1.042. The entire range of values in this confidence \ninterval is greater than 0.5. Because we are 90% confident that the limits of 0.815 and \n1.042 contain the true value of p, the sample data appear to support the claim that \nmost (more than 0.5) XSORT babies are girls. In this case, the conclusion is the same \nas with the P-value method and the critical value method, but that is not always the \ncase. It is possible that a conclusion based on the confidence interval can be different \nfrom the conclusion based on the P-value method or critical value method.\nFinding the Number of Successes x\nWhen using technology for hypothesis tests of proportions, we must usually enter \nthe sample size n and the number of successes x, but in real applications the sample \nproportion pn is often given instead of x. The number of successes x can be found by ","page_start":375,"page_end":375,"token_count":657,"section_type":"other","chapter_number":8,"chapter_title":"HYPOTHESIS TESTING","chunk_index":515}
{"chunk_id":"9a7788611802bd79","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"case. It is possible that a conclusion based on the confidence interval can be different \nfrom the conclusion based on the P-value method or critical value method.\nFinding the Number of Successes x\nWhen using technology for hypothesis tests of proportions, we must usually enter \nthe sample size n and the number of successes x, but in real applications the sample \nproportion pn is often given instead of x. The number of successes x can be found by \nevaluating x = npn, as illustrated in Example 1. Note that in Example 1, the result of \n5587.712 adults must be rounded to the nearest whole number of 5588.\nCAUTION: Don’t confuse the following notation.\n•  P-value = probability of getting a test statistic at least as extreme as the one repre-\nsenting the sample data, assuming that the null hypothesis H0 is true\n• p = population proportion\n• pn = sample proportion\n-\nIs 0.05 a Bad Choice?\nThe value of \n0.05 is a very \ncommon choice \nfor serving as \nthe cutoff sepa-\nrating results \nconsidered to \nbe significant from those that are \nnot. Science writer John Timmer \nwrote in Ars Technica that some \nproblems with conclusions in \nscience are attributable to the \nfact that statistics is sometimes \nweak because of the common \nuse of 0.05 for a significance \nlevel. He gives examples of \nparticle physics and genetics \nexperiments in which P-values \nmust be much lower than 0.05. \nHe cites a study by statistician \nValen Johnson, who suggested \nthat we should raise standards \nby requiring that experiments use \na P-value of 0.005 or lower. We \ndo know that the choice of 0.05 \nis largely arbitrary, and lowering \nthe significance level will result \nin fewer conclusions of signifi-\ncance, along with fewer wrong \nconclusions.","page_start":375,"page_end":375,"token_count":402,"section_type":"other","chapter_number":8,"chapter_title":"HYPOTHESIS TESTING","chunk_index":516}
{"chunk_id":"aace80563f560095","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"358 \nCHAPTER 8 Hypothesis Testing\nEXAMPLE 1  Finding the Number of Successes x\nA study of sleepwalking or “nocturnal wandering” was described in the journal \nNeurology, and it included information that 29.2% of 19,136 American adults have \nsleepwalked. What is the actual number of adults who have sleepwalked?\nSOLUTION\nThe number of adults who have sleepwalked is 29.2% of 19,136, or 0.292 * 19,136\n= 5587.712, but the result must be a whole number, so we round the product to the \nnearest whole number of 5588.\nCAUTION When conducting hypothesis tests of claims about proportions, slightly \ndifferent results can be obtained when calculating the test statistic using a given \nsample proportion instead of using a rounded value of x found by using x = npn.\nEXAMPLE 2  Fewer Than 30% of Adults Have Sleepwalked\nUsing the same sleepwalking data from Example 1 (n = 19,136 and pn = 29.2%),  \nwould a reporter be justified in stating that “fewer than 30% of adults have sleep-\nwalked”? Let’s use a 0.05 significance level to test the claim that for the adult popu-\nlation, the proportion of those who have sleepwalked is less than 0.30.\nSOLUTION\nREQUIREMENT CHECK (1) The sample is a simple random sample. (2) There is a \nfixed number (19,136) of independent trials with two categories (a subject has \nsleepwalked or has not). (3) The requirements np Ú 5 and nq Ú 5 are both satisfied \nwith n = 19,136 and p = 0.30. [We get np = 119,136210.302 = 5740.8, which \nis greater than or equal to 5, and we also get nq = 119,136210.702 = 13,395.2, \nwhich is greater than or equal to 5.] The three requirements are all satisfied. \nStep 1: The original claim is expressed in symbolic form as p 6 0.30.\nStep 2: The opposite of the original claim is p Ú 0.30.\nStep 3: Because p 6 0.30 does not contain equality, it becomes H1. We get\nH0: p = 0.30 1null hypothesis2\nH1: p 6 0.30 1alternative hypothesis and original claim2\nStep 4: The significance level is a = 0.05.\nStep 5: Because the claim involves the proportion p, the statistic relevant to this test \nis the sample proportion pn and the sampling distribution of sample proportions can \nbe approximated by the normal distribution.\nStep 6: Technology If using technology, the test statistic and the P-value will be \nprovided. See the following results from StatCrunch showing that the test statistic is \nz = -2.41 (rounded) and the P-value = 0.008.\n","page_start":376,"page_end":376,"token_count":665,"section_type":"other","chapter_number":8,"chapter_title":"HYPOTHESIS TESTING","chunk_index":517}
{"chunk_id":"7d790abb254b8f43","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"8-2 Testing a Claim About a Proportion \n359\nCritical Value Method If we were to repeat Example 2 using the critical value method of \ntesting hypotheses, we would see that in Step 6 the critical value is z = -1.645, which \ncan be found from technology or Table A-2. In Step 7 we would reject the null hypothesis \nbecause the test statistic of z = -2.41 would fall within the critical region bounded by \nz = -1.645. We would then reach the same conclusion given in Example 2.\nConfidence Interval Method If we were to repeat Example 2 using the confidence \ninterval method, we would use a 90% confidence level because we have a left-tailed \ntest. (See Table 8-1.) We get this 90% confidence interval: 0.287 6 p 6 0.297. Be-\ncause the entire range of the confidence interval falls below 0.30, there is sufficient \nevidence to support the claim that fewer than 30% of adults have sleepwalked.\nPART 2\nExact Methods for Testing Claims About a \nPopulation Proportion p\nInstead of using the normal distribution as an approximation to the binomial distribu-\ntion, we can get exact results by using the binomial probability distribution itself. Bi-\nnomial probabilities are a real nuisance to calculate manually, but technology makes \nTable A-2 If technology is not available, proceed as follows to conduct the  \nhypothesis test using the P-value method summarized in Figure 8-1 on page 340.\nThe test statistic z = -2.41 is calculated as follows:\nz = pn - p\nA\npq\nn\n=\n5588\n19,136 - 0.30\nB\n10.30210.702\n19,136\n= -2.41\nRefer to Figure 8-3 on page 344 for the procedure for finding the P-value.  \nFigure 8-3 shows that for this left-tailed test, the P-value is the area to the left of \nthe test statistic. Using Table A-2, we see that the area to the left of z = -2.41 is \n0.0080, so the P-value is 0.0080.\nStep 7: Because the P-value of 0.0080 is less than or equal to the significance level \nof 0.05, we reject the null hypothesis.\nINTERPRETATION\nBecause we reject the null hypothesis, we support the alternative hypothesis. We \ntherefore conclude that there is sufficient evidence to support the claim that fewer \nthan 30% of adults have sleepwalked.\nStatCrunch\nLefties Die Sooner?\nA study by \npsychologists \nDiane Halpern \nand Stanley \nCoren received \nconsiderable \nmedia atten-\ntion and generated considerable \ninterest when it concluded that \nleft-handed people don’t live as \nlong as right-handed people. \nBased on their study, it appeared \nthat left-handed people live an \naverage of nine years less than \nrighties. The Halpern>Coren ","page_start":377,"page_end":377,"token_count":655,"section_type":"other","chapter_number":8,"chapter_title":"HYPOTHESIS TESTING","chunk_index":518}
{"chunk_id":"d0a74e1a6c678ef2","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"StatCrunch\nLefties Die Sooner?\nA study by \npsychologists \nDiane Halpern \nand Stanley \nCoren received \nconsiderable \nmedia atten-\ntion and generated considerable \ninterest when it concluded that \nleft-handed people don’t live as \nlong as right-handed people. \nBased on their study, it appeared \nthat left-handed people live an \naverage of nine years less than \nrighties. The Halpern>Coren \nstudy has been criticized for \nusing flawed data. They used \nsecond-hand data by surveying \nrelatives about people who had \nrecently died. The myth of lefties \ndying younger became folklore \nthat has survived many years. \nHowever, more recent studies \nshow that left-handed people do \nnot have shorter lives than those \nwho are right-handed.","page_start":377,"page_end":377,"token_count":171,"section_type":"other","chapter_number":8,"chapter_title":"HYPOTHESIS TESTING","chunk_index":519}
{"chunk_id":"dea0163d318038cd","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"360 \nCHAPTER 8 Hypothesis Testing\nthis approach quite simple. Also, this exact approach does not require that np Ú 5 and \nnq Ú 5, so we have a method that applies when that requirement is not satisfied. To \ntest hypotheses using the exact method, find P-values as follows:\nExact Method Identify the sample size n, the number of successes x, and the claimed \nvalue of the population proportion p (used in the null hypothesis); then find the P-value \nby using technology for finding binomial probabilities as follows:\nLeft-tailed test:   P-value = P1x or fewer successes among n trials2\nRight-tailed test:   P-value = P1x or more successes among n trials2\nTwo-tailed test:   P-value =  twice the smaller of the preceding left-tailed and \nright-tailed values\nNote: There is no universally accepted method for the above two-tailed exact case, \nso this case can be treated with other different approaches, some of which are quite \ncomplex. For example, Minitab uses a “likelihood ratio test” that is different from the \nabove approach that is commonly used.\nEXAMPLE 3  Using the Exact Method\nIn testing a method of gender selection, 10 randomly selected couples are treated \nwith the method, they each have a baby, and 9 of the babies are girls. Use a 0.05 \nsignificance level to test the claim that with this method, the probability of a baby \nbeing a girl is greater than 0.75.\nSOLUTION\nREQUIREMENT CHECK The normal approximation method described in Part 1 of \nthis section requires that np Ú 5 and nq Ú 5, but nq = (10)(0.25) = 2.5, so the \nrequirement is violated. The exact method has only the requirements of being a \nsimple random sample and satisfying the conditions for binomial distribution, and \nthose two requirements are satisfied. \nHere are the null and alternative hypotheses:\nH0: p = 0.75 1null hypothesis2\nH1: p 7 0.75 1alternative hypothesis and original claim2\nInstead of using the normal distribution, we use technology to find probabilities in a \nbinomial distribution with p = 0.75. Because this is a right-tailed test, the P-value \nis the probability of 9 or more successes among 10 trials, assuming that p = 0.75. \nSee the following Statdisk display of exact probabilities from the binomial distri-\nbution. This Statdisk display shows that the probability of 9 or more successes is \n0.2440252 when rounded to seven decimal places, so the P-value is 0.2440252. The \nP-value is high (greater than 0.05), so we fail to reject the null hypothesis. There is \nnot sufficient evidence to support the claim that with the gender selection method, \nthe probability of a girl is greater than 0.75.\n","page_start":378,"page_end":378,"token_count":635,"section_type":"other","chapter_number":8,"chapter_title":"HYPOTHESIS TESTING","chunk_index":520}
{"chunk_id":"e8fa027bddc7a8f1","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"8-2 Testing a Claim About a Proportion \n361\nImproving the Exact Method A criticism of the exact method is that it is too conser-\nvative in the sense that the actual probability of a type I error is typically less than or \nequal to a, and it could be much lower than a.\nWith the exact method, the actual probability of a type I error is less than \nor equal to A, which is the desired probability of a type I error.\nA simple continuity correction improves the conservative behavior of the exact \nmethod with an adjustment to the P-value that is obtained by subtracting from it the \nvalue that is one-half the binomial probability at the boundary, as shown below. (See \nExercise 33.) This method is easy to apply if technology is available for finding bino-\nmial probabilities.\nSimple Continuity Correction to the Exact Method\nLeft-tailed test: \nP-value = P1x or fewer2 - 1\n2P1exactly x2\nRight-tailed test: \nP-value = P1x or more2 - 1\n2P1exactly x2\nTwo-tailed test: \n P-value =  twice the smaller of the preceding left-tailed \nand right-tailed values\nThe above “simple continuity correction” is described in “Modifying the Exact Test for a \nBinomial Proportion and Comparisons with Other Approaches,” by Alan Huston, Jour-\nnal of Applied Statistics, Vol. 33, No. 7. For another improvement that uses weighted tail \nareas based on a measure of skewness, see the preceding article by Alan Huston.\nStatdisk\nHypothesis Test: Proportion\nAccess tech instructions, videos, and data sets at www.TriolaStats.com\nTECH CENTER \n","page_start":379,"page_end":379,"token_count":372,"section_type":"other","chapter_number":8,"chapter_title":"HYPOTHESIS TESTING","chunk_index":521}
{"chunk_id":"ddf68db43926b793","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"362 \nCHAPTER 8 Hypothesis Testing\nStatistical Literacy and Critical Thinking\nIn Exercises 1–4, use these results from a USA Today survey in which 510 people chose to \nrespond to this question that was posted on the USA Today website: “Should Americans \nreplace passwords with biometric security (fingerprints, etc)?” Among the respondents, 53% \nsaid yes. We want to test the claim that more than half of the population believes that pass-\nwords should be replaced with biometric security.\n1. Number and Proportion\na. Identify the actual number of respondents who answered yes.\nb. Identify the sample proportion and the symbol used to represent it.\n2. Null and Alternative Hypotheses Identify the null hypothesis and alternative hypothesis.\n3. Equivalence of Methods If we use the same significance level to conduct the hypoth-\nesis test using the P-value method, the critical value method, and a confidence interval, which \nmethod is not equivalent to the other two?\n4. Requirements and Conclusions\na. Are any of the three requirements violated? Can the methods of this section be used to test \nthe claim?\nb. It was stated that we can easily remember how to interpret P-values with this: “If the P is \nlow, the null must go.” What does this mean?\nc. Another memory trick commonly used is this: “If the P is high, the null will fly.” Given that \na hypothesis test never results in a conclusion of proving or supporting a null hypothesis, how \nis this memory trick misleading?\nd. Common significance levels are 0.01 and 0.05. Why would it be unwise to use a significance \nlevel with a number like 0.0483?\nUsing Technology. In Exercises 5–8, identify the indicated values or interpret the given \ndisplay. Use the normal distribution as an approximation to the binomial distribution as \n described in Part 1 of this section. Use a 0.05 significance level and answer the following:\na. Is the test two-tailed, left-tailed, or right-tailed?\nb. What is the test statistic?\nc. What is the P-value?\nd. What is the null hypothesis, and what do you conclude about it?\ne. What is the final conclusion?\n5. Adverse Reactions to Drug The drug Lipitor (atorvastatin) is used to treat high choles-\nterol. In a clinical trial of Lipitor, 47 of 863 treated subjects experienced headaches (based on \ndata from Pfizer). The accompanying TI-83>84 Plus calculator display shows results from a \ntest of the claim that fewer than 10% of treated subjects experience headaches.\n8-2 Basic Skills and Concepts\nTI-83 , 84 Plus\n","page_start":380,"page_end":380,"token_count":574,"section_type":"other","chapter_number":8,"chapter_title":"HYPOTHESIS TESTING","chunk_index":522}
{"chunk_id":"f8bf1960ac85f0b6","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"8-2 Testing a Claim About a Proportion \n363\n6. Self-Driving Vehicles In a TE Connectivity survey of 1000 adults, 29% said that they \nwould feel comfortable in a self-driving vehicle. The accompanying StatCrunch display results \nfrom testing the claim that more than 1>4 of adults feel comfortable in a self-driving vehicle.\nStatCrunch\n7. Hygiene A KRC Research poll of 1020 randomly selected adults showed that 65% of them \nwash their hands after touching an animal. The following Minitab display results from a test of \nthe claim that 67% of adults wash their hands after touching an animal.\nMinitab\n8. Biometric Security In a USA Today survey of 510 people, 53% said that we should replace \npasswords with biometric security, such as fingerprints. The accompanying Statdisk display \nresults from a test of the claim that half of us say that we should replace passwords with bio-\nmetric security.\nTesting Claims About Proportions. In Exercises 9–28, test the given claim. Identify the \nnull hypothesis, alternative hypothesis, test statistic, P-value, or critical value(s), then state \nthe conclusion about the null hypothesis, as well as the final conclusion that addresses the \noriginal claim. Use the P-value method unless your instructor specifies otherwise. Use the \nnormal distribution as an approximation to the binomial distribution, as described in Part 1 \nof this section.\n9. Gender Selection The Genetics & IVF Institute conducted a clinical trial of the YSORT \nmethod designed to increase the probability of conceiving a boy. 291 babies were born to parents \nusing the YSORT method, and 239 of them were boys. Use a 0.01 significance level to test the \nclaim that the YSORT method is effective in increasing the likelihood that a baby will be a boy.\n10. Eliquis The drug Eliquis (apixaban) is used to help prevent blood clots in certain patients. \nIn clinical trials, among 5924 patients treated with Eliquis, 153 developed the adverse reaction \nof nausea (based on data from Bristol-Myers Squibb Co.). Use a 0.05 significance level to test \nthe claim that 3% of Eliquis users develop nausea. Does nausea appear to be a problematic \nadverse reaction?\n11. Stem Cell Survey Adults were randomly selected for a Newsweek poll. They were asked \nif they “favor or oppose using federal tax dollars to fund medical research using stem cells \nobtained from human embryos.” Of those polled, 481 were in favor, 401 were opposed, and \n120 were unsure. A politician claims that people don’t really understand the stem cell issue and \ntheir responses to such questions are random responses equivalent to a coin toss. Exclude the \n120 subjects who said that they were unsure, and use a 0.01 significance level to test the claim \nthat the proportion of subjects who respond in favor is equal to 0.5. What does the result sug-\ngest about the politician’s claim?\n12. Clinical Trial of Tamiflu Clinical trials involved treating flu patients with Tamiflu (osel-","page_start":381,"page_end":381,"token_count":661,"section_type":"other","chapter_number":8,"chapter_title":"HYPOTHESIS TESTING","chunk_index":523}
{"chunk_id":"a02a5a62cb24d7be","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"their responses to such questions are random responses equivalent to a coin toss. Exclude the \n120 subjects who said that they were unsure, and use a 0.01 significance level to test the claim \nthat the proportion of subjects who respond in favor is equal to 0.5. What does the result sug-\ngest about the politician’s claim?\n12. Clinical Trial of Tamiflu Clinical trials involved treating flu patients with Tamiflu (osel-\ntamivir phosphate), which is a medicine intended to attack the influenza virus and stop it from \ncausing flu symptoms. Among 724 patients treated with Tamiflu, 72 experienced nausea as an \nadverse reaction. Use a 0.05 significance level to test the claim that the rate of nausea is greater \nthan the 6% rate experienced by flu patients given a placebo. Does nausea appear to be a con-\ncern for those given the Tamiflu treatment?\nStatdisk","page_start":381,"page_end":381,"token_count":192,"section_type":"other","chapter_number":8,"chapter_title":"HYPOTHESIS TESTING","chunk_index":524}
{"chunk_id":"f54a49eb7d8a8c9c","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"364 \nCHAPTER 8 Hypothesis Testing\n13. OxyContin The drug OxyContin (oxycodone) is used to treat pain, but it is dangerous \nbecause it is addictive and can be lethal. In clinical trials, 227 subjects were treated with \n OxyContin and 52 of them developed nausea (based on data from Purdue Pharma L.P.). Use a \n0.05 significance level to test the claim that more than 20% of OxyContin users develop nau-\nsea. Does the rate of nausea appear to be too high?\n14. Medical Malpractice In a study of 1228 randomly selected medical malpractice lawsuits, \nit was found that 856 of them were dropped or dismissed (based on data from the Physicians \nInsurers Association of America). Use a 0.01 significance level to test the claim that most medi-\ncal malpractice lawsuits are dropped or dismissed. Should this be comforting to physicians?\n15. Survey Return Rate In a study of cell phone use and brain hemispheric dominance, an \nInternet survey was e-mailed to 5000 subjects randomly selected from an online group involved \nwith ears. 717 surveys were returned. Use a 0.01 significance level to test the claim that the \nreturn rate is less than 15%.\n16. Drug Screening The company Drug Test Success provides a “1-Panel-THC” test for mar-\nijuana usage. Among 300 tested subjects, results from 27 subjects were wrong (either a false \npositive or a false negative). Use a 0.05 significance level to test the claim that less than 10% of \nthe test results are wrong. Does the test appear to be good for most purposes?\n17. Births A random sample of 860 births in New York State included 426 boys. Use a 0.05 \nsignificance level to test the claim that 51.2% of newborn babies are boys. Do the results sup-\nport the belief that 51.2% of newborn babies are boys?\n18. Mendelian Genetics When Mendel conducted his famous genetics experiments with \npeas, one sample of offspring consisted of 428 green peas and 152 yellow peas. Use a 0.01 \nsignificance level to test Mendel’s claim that under the same circumstances, 25% of offspring \npeas will be yellow. What can we conclude about Mendel’s claim?\n19. Predicting Gender of Baby A study addressed the issue of whether pregnant women can \ncorrectly guess the gender of their baby. Among 104 recruited subjects, 55% correctly guessed \nthe gender of the baby (based on data from “Are Women Carrying ‘Basketballs’ Really Having \nBoys? Testing Pregnancy Folklore,” by Perry, DiPietro, and Constigan, Birth, Vol. 26, No. 3). \nUse these sample data to test the claim that the success rate of such guesses is no different from \nthe 50% success rate expected with random chance guesses. Use a 0.05 significance level.\n20. Predicting Gender of Baby In the same study cited in the preceding exercise, 45 of the ","page_start":382,"page_end":382,"token_count":656,"section_type":"other","chapter_number":8,"chapter_title":"HYPOTHESIS TESTING","chunk_index":525}
{"chunk_id":"bc305d0b290265d7","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"Boys? Testing Pregnancy Folklore,” by Perry, DiPietro, and Constigan, Birth, Vol. 26, No. 3). \nUse these sample data to test the claim that the success rate of such guesses is no different from \nthe 50% success rate expected with random chance guesses. Use a 0.05 significance level.\n20. Predicting Gender of Baby In the same study cited in the preceding exercise, 45 of the \npregnant women had more than 12 years of education, and 32 of them made correct predic-\ntions. Use these results to test the claim that women with more than 12 years of education have \na proportion of correct predictions that is greater than the 0.5 proportion expected with random \nguesses. Use a 0.01 significance level. Do these women appear to have an ability to correctly \npredict the gender of their babies?\n21. Touch Therapy When she was 9 years of age, Emily Rosa did a science fair experiment \nin which she tested professional touch therapists to see if they could sense her energy field. She \nflipped a coin to select either her right hand or her left hand, and then she asked the therapists \nto identify the selected hand by placing their hand just under Emily’s hand without seeing it \nand without touching it. Among 280 trials, the touch therapists were correct 123 times (based \non data in “A Close Look at Therapeutic Touch,” Journal of the American Medical Associa-\ntion, Vol. 279, No. 13). Use a 0.10 significance level to test the claim that touch therapists use a \nmethod equivalent to random guesses. Do the results suggest that touch therapists are effective?\n22. Touch Therapy Repeat the preceding exercise using a 0.01 significance level. Does the \nconclusion change?\n23. Cell Phones and Cancer In a study of 420,095 Danish cell phone users, 135 subjects de-\nveloped cancer of the brain or nervous system (based on data from the Journal of the National \nCancer Institute as reported in USA Today). Test the claim of a somewhat common belief that \nsuch cancers are affected by cell phone use. That is, test the claim that cell phone users develop \ncancer of the brain or nervous system at a rate that is different from the rate of 0.0340% for ","page_start":382,"page_end":382,"token_count":489,"section_type":"other","chapter_number":8,"chapter_title":"HYPOTHESIS TESTING","chunk_index":526}
{"chunk_id":"40d679edc0482967","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"8-2 Testing a Claim About a Proportion \n365\npeople who do not use cell phones. Because this issue has such great importance, use a 0.005 \nsignificance level. Based on these results, should cell phone users be concerned about cancer of \nthe brain or nervous system?\n24. Lie Detectors Trials in an experiment with a polygraph yield 98 results that include 24 cases \nof wrong results and 74 cases of correct results (based on data from experiments conducted by \nresearchers Charles R. Honts of Boise State University and Gordon H. Barland of the Depart-\nment of Defense Polygraph Institute). Use a 0.05 significance level to test the claim that such \npolygraph results are correct less than 80% of the time. Based on the results, should polygraph \ntest results be prohibited as evidence in trials?\n25. Testing Effectiveness of Nicotine Patches In one study of smokers who tried to quit \nsmoking with nicotine patch therapy, 39 were smoking one year after the treatment and 32 \nwere not smoking one year after the treatment (based on data from “High-Dose Nicotine Patch \nTherapy,” by Dale et al., Journal of the American Medical Association, Vol. 274, No. 17). Use a \n0.05 significance level to test the claim that among smokers who try to quit with nicotine patch \ntherapy, the majority are smoking a year after the treatment. What do these results suggest \nabout the effectiveness of nicotine patch therapy for those trying to quit smoking?\n26. Postponing Death An interesting and popular hypothesis is that individuals can tem-\nporarily postpone death to survive a major holiday or important event such as a birthday. In \na study, it was found that there were 6062 deaths in the week before Thanksgiving, and 5938 \ndeaths the week after Thanksgiving (based on data from “Holidays, Birthdays, and Postpone-\nment of Cancer Death,” by Young and Hade, Journal of the American Medical Association, \nVol. 292, No. 24). If people can postpone death until after Thanksgiving, then the proportion \nof deaths in the week before should be less than 0.5. Use a 0.05 significance level to test the \nclaim that the proportion of deaths in the week before Thanksgiving is less than 0.5. Based on \nthe result, does there appear to be any indication that people can temporarily postpone death to \nsurvive the Thanksgiving holiday?\n27. Smoking Stopped In a program designed to help patients stop smoking, 198 patients \nwere given sustained care, and 82.8% of them were no longer smoking after one month (based \non data from “Sustained Care Intervention and Postdischarge Smoking Cessation Among \n Hospitalized Adults,” by Rigotti et al., Journal of the American Medical Association, Vol. 312, \nNo. 7). Use a 0.01 significance level to test the claim that 80% of patients stop smoking when \ngiven sustained care. Does sustained care appear to be effective?","page_start":383,"page_end":383,"token_count":642,"section_type":"other","chapter_number":8,"chapter_title":"HYPOTHESIS TESTING","chunk_index":527}
{"chunk_id":"3ac7b076ff41607c","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"on data from “Sustained Care Intervention and Postdischarge Smoking Cessation Among \n Hospitalized Adults,” by Rigotti et al., Journal of the American Medical Association, Vol. 312, \nNo. 7). Use a 0.01 significance level to test the claim that 80% of patients stop smoking when \ngiven sustained care. Does sustained care appear to be effective?\n28. Medication Usage In a survey of 3005 adults aged 57 through 85 years, it was found that \n81.7% of them used at least one prescription medication (based on data from “Use of Prescrip-\ntion and Over-the-Counter Medications and Dietary Supplements Among Older Adults in the \nUnited States,” by Qato et al., Journal of the American Medical Association, Vol. 300, No. 24). \nUse a 0.01 significance level to test the claim that more than 3>4 of adults use at least one pre-\nscription medication. Does the rate of prescription use among adults appear to be high?\n29. Exact Method For each of the three different methods of hypothesis testing (identified in \nthe column at the left), enter the P-values corresponding to the given alternative hypothesis and \nsample data. Comment on the results.\nH1: p 3 0.5  \nn = 10, x = 9\nH1: p 3 0.4 \nn = 10, x = 9\nH1: p + 0.5 \nn = 1009, x = 545\nNormal approximation\nExact\nExact with simple  \ncontinuity correction\n8-2 Beyond the Basics","page_start":383,"page_end":383,"token_count":344,"section_type":"other","chapter_number":8,"chapter_title":"HYPOTHESIS TESTING","chunk_index":528}
{"chunk_id":"ea8405dd254a98d8","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"366 \nCHAPTER 8 Hypothesis Testing\n30. Using Confidence Intervals to Test Hypotheses When analyzing the last digits of tele-\nphone numbers of hospital patients, it is found that among 1000 randomly selected digits, 119 \nare zeros. If the digits are randomly selected, the proportion of zeros should be 0.1.\na. Use the critical value method with a 0.05 significance level to test the claim that the propor-\ntion of zeros equals 0.1.\nb. Use the P-value method with a 0.05 significance level to test the claim that the proportion of \nzeros equals 0.1.\nc. Use the sample data to construct a 95% confidence interval estimate of the proportion of \nzeros. What does the confidence interval suggest about the claim that the proportion of zeros \nequals 0.1?\nd. Compare the results from the critical value method, the P-value method, and the confidence \ninterval method. Do they all lead to the same conclusion?\n31. Power For a hypothesis test with a specified significance level a, the probability of a type I \nerror is a, whereas the probability b of a type II error depends on the particular value of p that \nis used as an alternative to the null hypothesis.\na. Using an alternative hypothesis of p 6 0.4, using a sample size of n = 50, and assuming \nthat the true value of p is 0.25, find the power of the test. See Exercise 34 “Calculating Power” \nin Section 8-1. [Hint: Use the values p = 0.25 and pq>n = 10.25210.752>50.4\nb. Find the value of b, the probability of making a type II error.\nc. Given the conditions cited in part (a), find the power of the test. What does the power tell us \nabout the effectiveness of the test?\nKey Concept Testing a claim about a population mean is one of the most important \nmethods presented in this book. This section deals with the very realistic and com-\nmonly used case in which the population standard deviation s is not known.\nIn reality, it is very rare that we test a claim about an unknown value of a popula-\ntion mean m but we somehow know the value of the population standard deviation s. \nThe realistic situation is that we test a claim about a population mean and the value of \nthe population standard deviation s is not known. When s is not known, we estimate \nit with the sample standard deviation s. From the central limit theorem (Section 6-4), \nwe know that the distribution of sample means x is approximately a normal distribu-\ntion with mean mx = m and standard deviation sx = s> 1n, but if s is unknown, we \nestimate s> 1n with s> 1n, which is used in the test statistic for a “t test.” This test \nstatistic has a distribution called the Student t distribution. The requirements, test \nstatistic, P-value, and critical values are summarized in the Key Elements box that \nfollows.\nEquivalent Methods","page_start":384,"page_end":384,"token_count":654,"section_type":"other","chapter_number":8,"chapter_title":"HYPOTHESIS TESTING","chunk_index":529}
{"chunk_id":"cdcf84f974b01046","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"tion with mean mx = m and standard deviation sx = s> 1n, but if s is unknown, we \nestimate s> 1n with s> 1n, which is used in the test statistic for a “t test.” This test \nstatistic has a distribution called the Student t distribution. The requirements, test \nstatistic, P-value, and critical values are summarized in the Key Elements box that \nfollows.\nEquivalent Methods\nFor the t test described in this section, the P-value method, the critical value method, \nand the confidence interval method are all equivalent in the sense that they all lead to \nthe same conclusions.\n8-3 \nTesting a Claim About a Mean","page_start":384,"page_end":384,"token_count":145,"section_type":"other","chapter_number":8,"chapter_title":"HYPOTHESIS TESTING","chunk_index":530}
{"chunk_id":"96518078bb18517e","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"8-3 Testing a Claim About a Mean \n367\nRequirement of Normality or n + 30 This t test is robust against a departure \nfrom normality, meaning that the test works reasonably well if the departure from \nnormality is not too extreme. Verify that there are no outliers and that the histogram or \ndotplot has a shape that is not very far from a normal distribution.\nIf the original population is not itself normally distributed, we use the condition \nn 7 30 for justifying use of the normal distribution, but there is no exact specific \nminimum sample size that works for all cases. Sample sizes of 15 to 30 are sufficient \nif the population has a distribution that is not far from normal, but some populations \nhave distributions that are extremely far from normal, and sample sizes greater than \n30 might be necessary. In this text we use the simplified criterion of n 7 30 as justi-\nfication for treating the distribution of sample means as a normal distribution, regard-\nless of how far the distribution departs from a normal distribution.\nImportant Properties of the Student t Distribution\nHere is a brief review of important properties of the Student t distribution first pre-\nsented in Section 7-2:\n1. The Student t distribution is different for different sample sizes (see Figure 7-4 \nin Section 7-2).\n2. The Student t distribution has the same general bell shape as the standard nor-\nmal distribution; its wider shape reflects the greater variability that is expected \nwhen s is used to estimate s.\nTesting Claims About a Population Mean with s Not Known\nObjective\nUse a formal hypothesis test to test a claim about a population mean m.\nNotation\nKEY ELEMENTS \nn = sample size \nx = sample mean\ns = sample standard deviation \nmx =  population mean (this value is taken from the claim and is used in the \nstatement of the null hypothesis H0)\nRequirements\n1. The sample is a simple random sample.\n2. Either or both of these conditions are satisfied: The \npopulation is normally distributed or n 7 30.\nTest Statistic for Testing a Claim About a Mean\nt = x - mx\ns\n2n\n \n1Round t to three decimal places, as in Table A@3.2\nP-Values: Use technology or use the Student t distri-\nbution (Table A-3) with degrees of freedom given by \ndf = n - 1. (Figure 8-3 in Section 8-1 on page 344 sum-\nmarizes the procedure for finding P-values.)\nCritical Values: Use the Student t distribution (Table A-3) \nwith degrees of freedom given by df = n - 1. (When \n Table A-3 doesn’t include the number of degrees of free-\ndom, you could be conservative by using the next lower \nnumber of degrees of freedom found in the table, you \ncould use the closest number of degrees of freedom in the \ntable, or you could interpolate.)\ncontinued\n","page_start":385,"page_end":385,"token_count":625,"section_type":"other","chapter_number":8,"chapter_title":"HYPOTHESIS TESTING","chunk_index":531}
{"chunk_id":"909183d49b7ef0cf","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"368 \nCHAPTER 8 Hypothesis Testing\n3. The Student t distribution has a mean of t = 0 (just as the standard normal dis-\ntribution has a mean of z = 0).\n4. The standard deviation of the Student t distribution varies with the sample size \nand is greater than 1 (unlike the standard normal distribution, which has s = 1).\n5. As the sample size n gets larger, the Student t distribution gets closer to the \nstandard normal distribution.\nP-Value Method with Technology\nIf suitable technology is available, the P-value method of testing hypotheses is the \nway to go.\nEXAMPLE 1  Adult Sleep: P-Value Method with Technology\nThe authors obtained times of sleep for randomly selected adult subjects in-\ncluded in the National Health and Nutrition Examination Study, and those times \n(hours) are listed below. Here are the unrounded statistics for this sample: n = 12, \nx = 6.83333333 hours, s = 1.99240984 hours. A common recommendation is \nthat adults should sleep between 7 hours and 9 hours each night. Use the P-value \nmethod with a 0.05 significance level to test the claim that the mean amount of \nsleep for adults is less than 7 hours.\n4 8 4 4 8 6 9 7 7 10 7 8\nSOLUTION\nREQUIREMENT CHECK (1) The sample is a simple random sample. (2) The second \nrequirement is that “the population is normally distributed or n 7 30.” The sample \nsize is n = 12, which does not exceed 30, so we must determine whether the sample \ndata appear to be from a normally distributed population. The accompanying histo-\ngram and normal quantile plot, along with the apparent absence of outliers, indicate \nthat the sample appears to be from a population with a distribution that is approxi-\nmately normal. Both requirements are satisfied. \nStatdisk\nHere are the steps that follow the procedure summarized in Figure 8-1 on page 340.\nStep 1: The claim that “the mean amount of adult sleep is less than 7 hours” be-\ncomes m 6 7 hours when expressed in symbolic form.\nStep 2: The alternative (in symbolic form) to the original claim is m Ú 7 hours.\nStep 3: Because the statement m 6 7 hours does not contain the condition of equal-\nity, it becomes the alternative hypothesis H1. The null hypothesis H0 is the state-\nment that m = 7 hours.\n“How Statistics Can Help \nSave Failing Hearts”\nA New York \nTimes ar-\nticle by David \nLeonhardt \nfeatured the \nheadline \nof “How \nStatistics Can Help Save Failing \nHearts.” Leonhardt writes that \npatients have the best chance of \nrecovery if their clogged arteries \nare opened within two hours \nof a heart attack. In 2005, the \nU.S. Department of Health and \nHuman Services began posting \nhospital data on its website  ","page_start":386,"page_end":386,"token_count":645,"section_type":"other","chapter_number":8,"chapter_title":"HYPOTHESIS TESTING","chunk_index":532}
{"chunk_id":"0a20bc86bdd52552","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"Save Failing Hearts”\nA New York \nTimes ar-\nticle by David \nLeonhardt \nfeatured the \nheadline \nof “How \nStatistics Can Help Save Failing \nHearts.” Leonhardt writes that \npatients have the best chance of \nrecovery if their clogged arteries \nare opened within two hours \nof a heart attack. In 2005, the \nU.S. Department of Health and \nHuman Services began posting \nhospital data on its website  \nwww.hospitalcompare.hhs.gov, \nand it included the percentage \nof heart attack patients who re-\nceived treatment for blocked ar-\nteries within two hours of arrival \nat the hospital. Not wanting to be \nembarrassed by poor data, doc-\ntors and hospitals are reducing \nthe time it takes to unblock those \nclogged arteries. Leonhardt \nwrites about the University of \nCalifornia, San Francisco Medical \nCenter, which cut its time in half \nfrom almost three hours to about \n90 minutes. Effective use of \nsimple statistics can save lives.","page_start":386,"page_end":386,"token_count":213,"section_type":"other","chapter_number":8,"chapter_title":"HYPOTHESIS TESTING","chunk_index":533}
{"chunk_id":"76dce7bec15d2a31","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"8-3 Testing a Claim About a Mean \n369\nH0: m = 7 hours 1null hypothesis2\nH1: m 6 7 hours 1alternative hypothesis and original claim2\nStep 4: As specified in the statement of the problem, the significance level is \na = 0.05.\nStep 5: Because the claim is made about the population mean m, the sample statistic \nmost relevant to this test is the sample mean x, and we use the t distribution.\nStep 6: The sample statistics of n = 12, x = 6.83333333 hours, s = 1.99240984 \nhours are used to calculate the test statistic as follows, but technologies provide the \ntest statistic of t = -0.290. In calculations such as the following, it is good to carry \nextra decimal places and not round.\nt = x - mx\ns\n2n\n= 6.83333333 - 7\n1.99240984\n212\n= -0.290\nP-Value with Technology We could use technology to obtain the P-value. Shown \nhere are results from several technologies, and we can see that the P-value is 0.3887 \n(rounded). (SPSS shows a two-tailed P-value of 0.777, so it must be halved for this \none-tailed test.)\nStep 7: Because the P-value of 0.3887 is greater than the significance level of \na = 0.05, we fail to reject the null hypothesis.\nINTERPRETATION\nStep 8: Because we fail to reject the null hypothesis, we conclude that there is not \nsufficient evidence to support the claim that the mean amount of adult sleep is less \nthan 7 hours.\nMinitab\nStatCrunch\nTI-83 , 84 Plus\nExcel (XLSTAT)\nStatdisk\nJMP\nSPSS\nc \nMeta-Analysis\nThe term meta-\nanalysis refers \nto a technique \nof conduct-\ning a study \nthat essen-\ntially combines \nresults of other studies. It has the \nadvantage that separate smaller \nsamples can be combined into \none big sample, making the \ncollective results more meaning-\nful. It also has the advantage \nof using work that has already \nbeen done. Meta-analysis has \nthe disadvantage of being only \nas good as the studies that are \nused. If the previous studies are \nflawed, the “garbage in, garbage \nout” phenomenon can occur. The \nuse of meta-analysis is currently \npopular in medical research and \npsychological research. As an \nexample, a study of migraine \nheadache treatments was based \non data from 46 other studies. \n(See “Meta-Analysis of Migraine \nHeadache Treatments: Combin-\ning Information from Heteroge-\nneous Designs,” by Dominici \net al., Journal of the American \nStatistical Association, Vol. 94, \nNo. 445.)\n","page_start":387,"page_end":387,"token_count":635,"section_type":"other","chapter_number":8,"chapter_title":"HYPOTHESIS TESTING","chunk_index":534}
{"chunk_id":"674139d0dde7a211","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"370 \nCHAPTER 8 Hypothesis Testing\nExamine the technology displays to see that only two of them include critical values, \nbut they all include P-values. This is a major reason why the P-value method of test-\ning hypotheses has become so widely used in recent years.\nP-Value Method Without Technology\nIf suitable technology is not available, we can use Table A-3 to identify a range of \nvalues containing the P-value. In using Table A-3, keep in mind that it is designed for \npositive values of t and right-tail areas only, but left-tail areas correspond to the same \nt values with negative signs.\nEXAMPLE 2  Adult Sleep: P-Value Method Without Technology\nExample 1 is a left-tailed test with a test statistic of t = -0.290 (rounded) and a sam-\nple size of n = 12, so the number of degrees of freedom is df = n - 1 = 11. Using \nthe test statistic of t = -0.290 with Table A-3, examine the values of t in the row for  \ndf = 11 to see that 0.290 is less than all of the listed t values in the row, which indi-\ncates that the area in the left tail below the test statistic of t = -0.290 is greater than \n0.10. In this case, Table A-3 allows us to conclude that the P-value 7 0.10, but tech-\nnology provided the P-value of 0.3887. With a P-value 7 0.10, the conclusions are \nthe same as in Example 1.\nHINT: Because using Table A-3 to find a range of values containing the P-value \ncan be a bit tricky, the critical value method (see Example 3) might be easier than \nthe P-value method if suitable technology is not available.\nCritical Value Method\nEXAMPLE 3  Adult Sleep: Critical Value Method\nExample 1 is a left-tailed test with test statistic t = -0.290 (rounded). The \nsample size is n = 12, so the number of degrees of freedom is df = n - 1 = 11. \nGiven the significance level of a = 0.05, refer to the row of Table A-3 corre-\nsponding to 11 degrees of freedom, and refer to the column identifying an “area \nin one tail” of 0.05 (the significance level). The intersection of the row and col-\numn yields the critical value of t = 1.796, but this test is left-tailed, so the actual \ncritical value is t = -1.796. Figure 8-7 shows that the test statistic of t = -0.290 \ndoes not fall within the critical region bounded by the critical value t = -1.796, \nso we fail to reject the null hypothesis. The conclusions are the same as those \ngiven in  Example 1.\n","page_start":388,"page_end":388,"token_count":626,"section_type":"other","chapter_number":8,"chapter_title":"HYPOTHESIS TESTING","chunk_index":535}
{"chunk_id":"c605ca17f09e39c4","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"8-3 Testing a Claim About a Mean \n371\nConfidence Interval Method\nEXAMPLE 4  Adult Sleep: Confidence Interval Method\nExample 1 is a left-tailed test with significance level a = 0.05, so we should use \n90% as the confidence level (as indicated by Table 8-1 on page 340). For the sample \ndata given in Example 1, here is the 90% confidence interval estimate of m:  \n5.80 hours 6 m 6 7.87 hours. In testing the claim that m 6 7 hours, we use  \nH0: m = 7 hours, but the assumed value of m = 7 hours is contained within the con-\nfidence interval limits, so the confidence interval is telling us that 7 hours could be \nthe value of m. We don’t have sufficient evidence to reject H0: m = 7 hours, so we \nfail to reject this null hypothesis and we get the same conclusions given in Example 1.\nEXAMPLE 5  Is the Mean Body Temperature Really 98.6°F?\nData Set 2 “Body Temperatures” in Appendix B includes measured body tempera-\ntures with these statistics for 12 AM on day 2: n = 106, x = 98.20°F, s = 0.62°F. \nUse a 0.05 significance level to test the common belief that the population mean  \nis 98.6°F.\nSOLUTION\nREQUIREMENT CHECK (1) With the study design used, we can treat the sample as a \nsimple random sample. (2) The second requirement is that “the population is nor-\nmally distributed or n 7 30.” The sample size is n = 106, so the second require-\nment is satisfied and there is no need to investigate the normality of the data. Both \nrequirements are satisfied. \nHere are the steps that follow the procedure summarized in Figure 8-1.\nStep 1: The claim that “the population mean is 98.6°F” becomes m = 98.6°F when \nexpressed in symbolic form.\nStep 2: The alternative (in symbolic form) to the original claim is m ≠98.6°F.\ncontinued\nHuman Lie Detectors\nResearchers \ntested 13,000 \npeople for \ntheir ability to \ndetermine when \nsomeone is ly-\ning. They found \n31 people with exceptional skills \nat identifying lies. These human \nlie detectors had accuracy rates \naround 90%. They also found \nthat federal officers and sheriffs \nwere quite good at detecting lies, \nwith accuracy rates around 80%. \nPsychology Professor Maureen \nO’Sullivan questioned those who \nwere adept at identifying lies, \nand she said that “all of them pay \nattention to nonverbal cues and \nthe nuances of word usages and \napply them differently to differ-\nent people. They could tell you \neight things about someone after \nwatching a two-second tape. It’s \nscary, the things these people \nnotice.” Methods of statistics can ","page_start":389,"page_end":389,"token_count":646,"section_type":"other","chapter_number":8,"chapter_title":"HYPOTHESIS TESTING","chunk_index":536}
{"chunk_id":"ac5b35ca913323ed","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"with accuracy rates around 80%. \nPsychology Professor Maureen \nO’Sullivan questioned those who \nwere adept at identifying lies, \nand she said that “all of them pay \nattention to nonverbal cues and \nthe nuances of word usages and \napply them differently to differ-\nent people. They could tell you \neight things about someone after \nwatching a two-second tape. It’s \nscary, the things these people \nnotice.” Methods of statistics can \nbe used to distinguish between \npeople unable to detect lying and \nthose with that ability.\ni\nl kill\nm 5 7\nor\nt 5 0\nCritical Value:\nt 5 21.796\na 5 0.05\nSample Mean:\nx 5 6.833 hours\nor t 5 20.290\n2\nFIGURE 8-7 t Test: Critical Value Method","page_start":389,"page_end":389,"token_count":190,"section_type":"other","chapter_number":8,"chapter_title":"HYPOTHESIS TESTING","chunk_index":537}
{"chunk_id":"0543cefb0a200ae7","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"372 \nCHAPTER 8 Hypothesis Testing\nStep 3: Because the statement m ≠98.6°F does not contain the condition of equality, \nit becomes the alternative hypothesis H1. The null hypothesis H0 is the statement \nthat m = 98.6°F.\nH0: m = 98.6°F 1null hypothesis and original claim2\nH1: m ≠98.6°F 1alternative hypothesis2\nStep 4: As specified in the statement of the problem, the significance level is \na = 0.05.\nStep 5: Because the claim is made about the population mean m, the sample statistic \nmost relevant to this test is the sample mean x. We use the t distribution because \nthe relevant sample statistic is x and the requirements for using the t distribution are \nsatisfied.\nStep 6: The sample statistics are used to calculate the test statistic as follows, but \ntechnologies use unrounded values to provide the test statistic of t = -6.61.\nt = x - mx\ns\n2n\n= 98.20 - 98.6\n0.62\n2106\n= -6.64\nP-Value: The P-value is 0.0000 or 0+ (or “less than 0.01” if using Table A-3).\nCritical Values: The critical values are {1.983 (or {1.984 if using Table A-3).\nConfidence Interval: The 95% confidence interval is 98.08°F 6 m 6 98.32°F.\nStep 7: All three approaches lead to the same conclusion: Reject H0.\n■ P-Value: The P-value of 0.0000 is less than the significance level of a = 0.05.\n■Critical Values: The test statistic t = -6.64 falls in the critical region bounded \nby {1.983.\n■Confidence Interval: The claimed mean of 98.6°F does not fall within the con-\nfidence interval of 98.08°F 6 m 6 98.32°F.\nINTERPRETATION\nStep 8: There is sufficient evidence to warrant rejection of the common belief that \nthe population mean body temperature is 98.6°F.\nAlternative Methods Used When Population Is Not Normal and n \" 30\nThe methods of this section include two requirements: (1) The sample is a simple \nrandom sample; (2) either the population is normally distributed or n 7 30. If we \nhave sample data that are not collected in an appropriate way, such as a voluntary \n response sample, it is likely that there is nothing that can be done to salvage the \ndata, and the methods of this section should not be used. If the data are a simple \nrandom sample but the second condition is violated, there are alternative methods that \ncould be used, including these three alternative methods:\n■Bootstrap Resampling Use the confidence interval method of testing hypoth-\neses, but obtain the confidence interval using bootstrap resampling, as described \nin Section 7-4. Be careful to use the appropriate confidence level, as indicated by ","page_start":390,"page_end":390,"token_count":659,"section_type":"other","chapter_number":8,"chapter_title":"HYPOTHESIS TESTING","chunk_index":538}
{"chunk_id":"afb5f8495f58fc8c","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"data, and the methods of this section should not be used. If the data are a simple \nrandom sample but the second condition is violated, there are alternative methods that \ncould be used, including these three alternative methods:\n■Bootstrap Resampling Use the confidence interval method of testing hypoth-\neses, but obtain the confidence interval using bootstrap resampling, as described \nin Section 7-4. Be careful to use the appropriate confidence level, as indicated by \nTable 8-1 on page 340. Reject the null hypothesis if the confidence interval limits do \nnot contain the value of the mean claimed in the null hypothesis. See Example 6.","page_start":390,"page_end":390,"token_count":132,"section_type":"other","chapter_number":8,"chapter_title":"HYPOTHESIS TESTING","chunk_index":539}
{"chunk_id":"2dc4b404dc49ecfa","file_id":"803570a2-592f-4cda-9aab-60e05f861faa","filename":"Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf","text":"8-3 Testing a Claim About a Mean \n373\n \n■Sign Test See Section 13-2.\n \n■Wilcoxon Signed-Ranks Test See Section 13-3.\nEXAMPLE 6  Bootstrap Resampling\nListed below is a random sample of times (seconds) of tobacco use in animated \nchildren’s movies (from Data Set 13 “Alcohol and Tobacco in Movies”). Use a 0.05 \nsignificance level to test the claim that the sample is from a population with a mean \ngreater than 1 minute (or 60 seconds).\n0 223 0 176 0 548 0 37 158 51 0 0 299 37 0 11 0 0 0 0\nSOLUTION\nREQUIREMENT CHECK The t test described in this section requires that the popula-\ntion is normally distributed or n 7 30, but we have n = 20 and the accompanying \nnormal quantile plot shows that the sample does not appear to be from a normally \ndistributed population. The t test should not be used. \nSOLUTION\nInstead of incorrectly using the t test, we use the bootstrap resampling method de-\nscribed in Section 7-4. After obtaining 1000 bootstrap samples and finding the mean \nof each sample, we sort the means. Because the test is right-tailed with a 0.05 sig-\nnificance level, we use the 1000 sorted sample means to find the 90% confidence \ninterval limits of P5 = 29.9 seconds and P95 = 132.9 seconds. The 90% confidence \ninterval is 29.9 seconds 6 m 6 132.9 seconds. (These values can vary somewhat.) \nBecause the assumed mean of 60 seconds is contained within those confidence inter-\nval limits, we fail to reject H0: m = 60 seconds. There is not sufficient evidence to \nsupport H1: m 7 60 seconds.\nINTERPRETATION\nThere is not sufficient evidence to support the claim that the given sample is from a \npopulation with a mean greater than 60 seconds.\nHypothesis Test: Mean\nAccess tech instructions, videos, and data sets at www.TriolaStats.com\nTECH CENTER \n","page_start":391,"page_end":391,"token_count":475,"section_type":"other","chapter_number":8,"chapter_title":"HYPOTHESIS TESTING","chunk_index":540}
