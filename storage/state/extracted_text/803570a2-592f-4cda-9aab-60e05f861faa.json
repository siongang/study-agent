{
  "file_id": "803570a2-592f-4cda-9aab-60e05f861faa",
  "path": "Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf",
  "num_pages": 729,
  "pages": [
    "",
    "Conceptual Understanding \nStudents need to be equipped with both the methods and conceptual  \nunderstanding of statistics. MyStatLab offers a full question library of over \n1,000 conceptual-based questions to help tighten the comprehension of  \nstatistical concepts.\nReal-World Statistics\nMyStatLab video resources help foster conceptual understanding. StatTalk  \nVideos, hosted by fun-loving statistician, Andrew Vickers, demonstrate  \nimportant statistical concepts through interesting stories and real-life events. \nThis series of 24 videos includes assignable questions built in MyStatLab and  \nan instructor’s guide.\nVisit www.mystatlab.com and click Get Trained to make sure  \nyou’re getting the most out of MyStatLab.\n",
    "BIOSTATISTICS\nFOR THE BIOLOGICAL  \nAND HEALTH SCIENCES\nMARC M. TRIOLA, MD, FACP\nNew York University School of Medicine\nMARIO F. TRIOLA\nDutchess Community College \nJASON ROY, PHD\nUniversity of Pennsylvania \nPerelman School of Medicine\nSECOND EDITION\n",
    "To Ginny\nDushana and Marisa\nTrevor and Mitchell\nDirector, Portfolio Management Deirdre Lynch\nSenior Portfolio Manager Suzy Bainbridge\nPortfolio Management Assistant Justin Billing\nContent Producer Peggy McMahon\nManaging Producer Karen Wernholm\nCourseware QA Manager Mary Durnwald\nSenior Producer Vicki Dreyfus\nProduct Marketing Manager Yvonne Vannatta\nField Marketing Manager Evan St. Cyr\nProduct Marketing Assistant Jennifer Myers\nField Marketing Assistant Erin Rush\nSenior Author Support/Technology Specialist Joe Vetere \nManager, Rights and Permissions Gina M. Cheselka\nText and Cover Design, Illustrations, Production  Coordination, \nComposition Cenveo Publisher Services\nCover Image Robert Essel NYC/Getty Images\nCopyright © 2018, 2006 by Pearson Education, Inc. All Rights Reserved. Printed in the United States of America. This publica-\ntion is protected by copyright, and permission should be obtained from the publisher prior to any prohibited reproduction, storage \nin a retrieval system, or transmission in any form or by any means, electronic, mechanical, photocopying, recording, or otherwise. \nFor information regarding permissions, request forms and the appropriate contacts within the Pearson Education Global Rights & \nPermissions department, please visit www.pearsoned.com/permissions/.\nAttributions of third party content appear on page 683–684, which constitutes an extension of this copyright page.\nPEARSON, ALWAYS LEARNING, and MYSTATLAB are exclusive trademarks owned by Pearson Education, Inc. or its affiliates \nin the U.S. and/or other countries.\nUnless otherwise indicated herein, any third-party trademarks that may appear in this work are the property of their respective own-\ners and any references to third-party trademarks, logos or other trade dress are for demonstrative or descriptive purposes only. Such \nreferences are not intended to imply any sponsorship, endorsement, authorization, or promotion of Pearson’s products by the owners \nof such marks, or any relationship between the owner and Pearson Education, Inc. or its affiliates, authors, licensees or distributors.\nMICROSOFT AND>OR ITS RESPECTIVE SUPPLIERS MAKE NO REPRESENTATIONS ABOUT THE SUITABILITY OF THE INFORMATION CONTAINED IN THE \nDOCUMENTS AND RELATED GRAPHICS PUBLISHED AS PART OF THE SERVICES FOR ANY PURPOSE. ALL SUCH DOCUMENTS AND RELATED GRAPHICS \nARE PROVIDED “AS IS” WITHOUT WARRANTY OF ANY KIND. MICROSOFT AND>OR ITS RESPECTIVE SUPPLIERS HEREBY DISCLAIM ALL WARRANTIES \nAND CONDITIONS WITH REGARD TO THIS INFORMATION, INCLUDING ALL WARRANTIES AND CONDITIONS OF MERCHANTABILITY, WHETHER EXPRESS, \nIMPLIED OR STATUTORY, FITNESS FOR A PARTICULAR PURPOSE, TITLE AND NON-INFRINGEMENT. IN NO EVENT SHALL MICROSOFTAND>OR ITS RESPEC-\nTIVE SUPPLIERS BE LIABLE FOR ANY SPECIAL, INDIRECT OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES WHATSOEVER RESULTING FROM LOSS OF \nUSE, DATA OR PROFITS, WHETHER IN AN ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT OF OR IN CONNECTION WITH \nTHE USE OR PERFORMANCE OF INFORMATION AVAILABLE FROM THE SERVICES.\nTHE DOCUMENTS AND RELATED GRAPHICS CONTAINED HEREIN COULD INCLUDE TECHNICAL INACCURACIES OR TYPOGRAPHICAL ERRORS. CHANGES \nARE PERIODICALLY ADDED TO THE INFORMATION HEREIN. MICROSOFT AND>OR ITS RESPECTIVE SUPPLIERS MAY MAKE IMPROVEMENTS AND>OR \nCHANGES IN THE PRODUCT(S) AND>OR THE PROGRAM(S) DESCRIBED HEREIN AT ANY TIME. PARTIAL SCREEN SHOTS MAY BE VIEWED IN FULL WITHIN \nTHE SOFTWARE VERSION SPECIFIED.\nLibrary of Congress Cataloging-in-Publication Data\nNames: Triola, Marc M. | Triola, Mario F. | Roy, Jason (Jason Allen)\nTitle: Biostatistics for the biological and health sciences.\nDescription: Second edition / Marc M. Triola, New York University, \nMario F. Triola, Dutchess Community College, Jason Roy, University of \nPennsylvania. | Boston : Pearson, [2018] | Includes bibliographical \nreferences and index.\nIdentifiers: LCCN 2016016759| ISBN 9780134039015 (hardcover) | ISBN\n0134039017 (hardcover)\nSubjects: LCSH: Biometry. | Medical statistics.\nClassification: LCC QH323.5 .T75 2018 | DDC 570.1/5195–dc23\nLC record available at https://lccn.loc.gov/2016016759\n1 16\nISBN 13: 978-0-13-403901-5\nISBN 10: 0-13-403901-7\n",
    "iii\nMarc Triola, MD, FACP is the \nAssociate Dean for Educational \nInformatics at NYU School of \nMedicine, the founding director \nof the NYU Langone  Medical \nCenter Institute for Innovations \nin Medical Education (IIME), \nand an  Associate Professor of \nMedicine. Dr. Triola’s research \nexperience and expertise focus \non the disruptive effects of the \npresent revolution in educa-\ntion, driven by technological \nadvances, big data, and learn-\ning analytics. Dr. Triola has \nworked to create a “learning \necosystem” that includes interconnected computer-based e-learning tools and new \nways to effectively integrate growing amounts of electronic data in educational re-\nsearch. Dr. Triola and IIME have been funded by the National Institutes of Health, \nthe Integrated Advanced Information Management Systems program, the National \nScience Foundation Advanced Learning Technologies program, the Josiah Macy, \nJr. Foundation, the U.S. Department of Education, and the American Medical As-\nsociation Accelerating Change in Medical Education program. He chairs numer-\nous committees at the state and national levels focused on the future of health \nprofessions educational technology development and research.\nMario F. Triola is a Professor \nEmeritus of Mathematics at \nDutchess Community College, \nwhere he has taught statistics \nfor over 30 years. Marty is the \nauthor of Elementary Statistics, \n13th edition, Essentials of Sta-\ntistics, 5th edition, Elementary \nStatistics Using Excel, 6th edi-\ntion, and Elementary Statis-\ntics Using the TI-83>84 Plus \nCalculator, 4th edition, and \nhe is a co-author of Statistical \nReasoning for Everyday Life, \n5th edition. Elementary Statis-\ntics is currently available as an \nInternational Edition, and it has been translated into several foreign languages. \nMarty designed the original Statdisk statistical software, and he has  written \n several  manuals and workbooks for technology supporting statistics education. \nABOUT THE AUTHORS\n",
    "iv \nAbout the Authors\nHe has been a speaker at many conferences and colleges. Marty’s consulting work \nincludes the design of casino slot machines and the design of fishing rods. He has \nworked with attorneys in determining probabilities in paternity lawsuits, analyz-\ning data in medical malpractice lawsuits, identifying salary inequities based on \ngender, and analyzing disputed election results. He has also used statistical meth-\nods in analyzing medical school surveys and in analyzing survey results for the \nNew York City Transit Authority. Marty has testified as an expert witness in the \nNew York State Supreme Court.\nJason Roy, PhD, is Associate \nProfessor of Biostatistics in \nthe Department of Biostatistics \nand Epidemiology, Perelman \nSchool of Medicine, Univer-\nsity of Pennsylvania. He re-\nceived his PhD in Biostatistics \nin 2000 from the University \nof Michigan. He was recipi-\nent of the 2002 David P. Byar \nYoung Investigator Award from \nthe American Statistical Asso-\nciation Biometrics Section. His \nstatistical research interests are \nin the areas of causal inference, \nmissing data, and prediction \nmodeling. He is especially interested in the statistical challenges with analyzing \ndata from large health care databases. He collaborates in many different disease \nareas, including chronic kidney disease, cardiovascular disease, and liver diseases. \nDr Roy is Associate Editor of Biometrics, Journal of the American Statistical \nAssociation, and Pharmacoepidemiology & Drug Safety, and has over 90 peer- \nreviewed publications.\n",
    "v\nCONTENTS\n1 \nINTRODUCTION TO STATISTICS \n1\n1-1  \nStatistical and Critical Thinking  4\n1-2  \nTypes of Data  13\n1-3  \nCollecting Sample Data  24\n2 \nEXPLORING DATA WITH TABLES AND GRAPHS \n40\n2-1  \nFrequency Distributions for Organizing and Summarizing Data  42\n2-2  Histograms  51\n2-3  Graphs That Enlighten and Graphs That Deceive  56\n2-4  Scatterplots, Correlation, and Regression  65\n3 \nDESCRIBING, EXPLORING, AND COMPARING DATA \n75\n3-1  \nMeasures of Center  77\n3-2  Measures of Variation  89\n3-3  Measures of Relative Standing and Boxplots  102\n4 \nPROBABILITY \n118\n4-1  \nBasic Concepts of Probability  120\n4-2  Addition Rule and Multiplication Rule  131\n4-3  Complements, Conditional Probability, and Bayes’ Theorem  144\n4-4  Risks and Odds  153\n4-5  Rates of Mortality, Fertility, and Morbidity  162\n4-6  Counting  167\n5 \nDISCRETE PROBABILITY DISTRIBUTIONS \n180\n5-1  \nProbability Distributions  182\n5-2  Binomial Probability Distributions  193\n5-3  Poisson Probability Distributions  206\n6 \nNORMAL PROBABILITY DISTRIBUTIONS \n216\n6-1  \nThe Standard Normal Distribution  218\n6-2  Real Applications of Normal Distributions  231\n6-3  Sampling Distributions and Estimators  241\n6-4  The Central Limit Theorem  252\n6-5  Assessing Normality  261\n6-6  Normal as Approximation to Binomial  269\n7 \nESTIMATING PARAMETERS AND DETERMINING SAMPLE SIZES \n282\n7-1 \nEstimating a Population Proportion  284\n7-2  Estimating a Population Mean  299\n7-3  Estimating a Population Standard Deviation or Variance  315\n7-4  Bootstrapping: Using Technology for Estimates  324\n8 \nHYPOTHESIS TESTING  \n336\n8-1  \nBasics of Hypothesis Testing  338\n8-2  Testing a Claim About a Proportion  354\n8-3  Testing a Claim About a Mean  366\n8-4  Testing a Claim About a Standard Deviation or Variance  377\n9 \nINFERENCES FROM TWO SAMPLES  \n392\n9-1  \nTwo Proportions  394\n9-2  Two Means: Independent Samples  406\n9-3  Two Dependent Samples (Matched Pairs)  418\n9-4  Two Variances or Standard Deviations  428\n",
    "vi \nContents\n10 \nCORRELATION AND REGRESSION  \n442\n10-1  Correlation  444\n10-2  Regression  462\n10-3  Prediction Intervals and Variation  474\n10-4  Multiple Regression  481\n10-5  Dummy Variables and Logistic Regression  489\n11 \nGOODNESS-OF-FIT AND CONTINGENCY TABLES  \n502\n11-1  Goodness-of-Fit  503\n11-2  Contingency Tables  514\n12 \nANALYSIS OF VARIANCE  \n531\n12-1  One-Way ANOVA  533\n12-2  Two-Way ANOVA  547\n13 \nNONPARAMETRIC TESTS  \n560\n13-1  Basics of Nonparametric Tests  562\n13-2  Sign Test  564\n13-3  Wilcoxon Signed-Ranks Test for Matched Pairs  575\n13-4  Wilcoxon Rank-Sum Test for Two Independent Samples  581\n13-5  Kruskal-Wallis Test for Three or More Samples  586\n13-6  Rank Correlation  592\n14 \nSURVIVAL ANALYSIS  \n603\n14-1  Life Tables  604\n14-2  Kaplan-Meier Survival Analysis  614\nAPPENDIX A TABLES  \n625\nAPPENDIX B DATA SETS  \n638\nAPPENDIX C WEBSITES AND BIBLIOGRAPHY OF BOOKS   \n645\nAPPENDIX D ANSWERS TO ODD-NUMBERED SECTION EXERCISES  \n646\n(and all Quick Quizzes, all Review Exercises, and all Cumulative Review Exercises)\nCredits  683\nIndex  685\n",
    "PREFACE\nStatistics permeates nearly every aspect of our lives, and its role has become partic-\nularly important in the biological, life, medical, and health sciences. From opinion \npolls to clinical trials in medicine and analysis of big data from health applications, \nstatistics influences and shapes the world around us. Biostatistics for the Health and \nBiological Sciences forges the relationship between statistics and our world through \nextensive use of a wide variety of real applications that bring life to theory and \nmethods.\nGoals of This Second Edition\n \n■Incorporate the latest and best methods used by professional statisticians.\n \n■Include features that address all of the recommendations included in the Guide-\nlines for Assessment and Instruction in Statistics Education (GAISE) as recom-\nmended by the American Statistical Association.\n \n■Provide an abundance of new and interesting data sets, examples, and exercises.\n \n■Foster personal growth of students through critical thinking, use of technology, \ncollaborative work, and development of communication skills.\n \n■Enhance teaching and learning with the most extensive and best set of supple-\nments and digital resources.\nAudience, Prerequisites\nBiostatistics for the Health and Biological Sciences is written for students major-\ning in the biological and health sciences, and it is designed for a wide variety of \nstudents taking their first statistics course. Algebra is used minimally, and calculus \nis not required. It is recommended that students have completed at least an elemen-\ntary algebra course or that students should learn the relevant algebra components \nthrough an integrated or co-requisite course. In many cases, underlying theory is \nincluded, but this book does not require the mathematical rigor more appropriate for \nmathematics majors.\nHallmark Features\nGreat care has been taken to ensure that each chapter of Biostatistics for the Health \nand Biological Sciences will help students understand the concepts presented. The \nfollowing features are designed to help meet that objective.\nReal Data\nHundreds of hours have been devoted to finding data that are real, meaningful, and \ninteresting to students. Fully 87% of the examples are based on real data, and 89% of \nthe exercises are based on real data. Some exercises refer to the 18 data sets listed in \nAppendix B, and 12 of those data sets are new to this edition. Exercises requiring use \nof the Appendix B data sets are located toward the end of each exercise set and are \nmarked with a special data set icon \n.\nReal data sets are included throughout the book to provide relevant and interesting \nreal-world statistical applications, including biometric security, body measurements, \nbrain sizes and IQ scores, and data from births. Appendix B includes descriptions of \nvii\n",
    "viii \nPreface\nthe 18 data sets that can be downloaded from the companion website www.pearson-\nhighered.com/triola, the author maintained www.TriolaStats.com and MyStatLab.\nTriolaStats.com includes downloadable data sets in formats for technologies \nincluding Excel, Minitab, JMP, SPSS, and TI@83>84 Plus calculators. The data \nsets are also included in the free Statdisk software, which is also available on the \nwebsite.\nReadability\nGreat care, enthusiasm, and passion have been devoted to creating a book that is readable, \nunderstandable, interesting, and relevant. Students pursuing any major in the biological, \nlife, medical, or health fields are sure to find applications related to their future work.\nWebsite\nThis textbook is supported by www.TriolaStats.com, and www.pearsonhighered.com/\ntriola which are continually updated to provide the latest digital resources, including:\n \n■Statdisk: A free, robust statistical software package designed for this book.\n \n■Downloadable Appendix B data sets in a variety of technology formats.\n \n■Downloadable textbook supplements including Glossary of Statistical Terms and \nFormulas and Tables.\n \n■Online instructional videos created specifically for this book that provide step-\nby-step technology instructions.\n \n■Triola Blog, which highlights current applications of statistics, statistics in the \nnews, and online resources.\nChapter Features\nChapter Opening Features\n \n■Chapters begin with a Chapter Problem that uses real data and motivates the \nchapter material.\n \n■Chapter Objectives provide a summary of key learning goals for each section in \nthe chapter.\nExercises\nMany exercises require the interpretation of results. Great care has been taken to \nensure their usefulness, relevance, and accuracy. Exercises are arranged in order of \nincreasing difficulty, and they begin with Basic Skills and Concepts. Most sections \ninclude additional Beyond the Basics exercises that address more difficult concepts or \nrequire a stronger mathematical background. In a few cases, these exercises introduce \na new concept.\nEnd-of-Chapter Features\n \n■Chapter Quick Quiz provides review questions that require brief answers.\n \n■Review Exercises offer practice on the chapter concepts and procedures.\n \n■Cumulative Review Exercises reinforce earlier material.\n \n■Technology Project provides an activity that can be used with a variety of \n technologies.\n \n■From Data to Decision is a capstone problem that requires critical thinking and \nwriting.\n \n■Cooperative Group Activities encourage active learning in groups.\n",
    "Preface \nix\nOther Features\nMargin Essays There are 57 margin essays designed to highlight real-world topics \nand foster student interest.\nFlowcharts The text includes flowcharts that simplify and clarify more complex con-\ncepts and procedures. Animated versions of the text’s flowcharts are available within \nMyStatLab and MathXL.\nQuick-Reference Endpapers Tables A-2 and A-3 (the normal and t distributions) are \nreproduced on the rear inside cover pages.\nDetachable Formula and Table Card This insert, organized by chapter, gives students \na quick reference for studying, or for use when taking tests (if allowed by the instruc-\ntor). It also includes the most commonly used tables. This is also available for download \nat www.TriolaStats.com, www.pearsonhighered.com/triola and in MyStatLab.\nTechnology Integration\nAs in the preceding edition, there are many displays of screens from technology through-\nout the book, and some exercises are based on displayed results from technology. Where \nappropriate, sections include a reference to an online Tech Center subsection that in-\ncludes detailed instructions for Statdisk, Minitab®, Excel®, StatCrunch, or a TI@83>84\nPlus® calculator. (Throughout this text, “TI-83>84 Plus” is used to identify a TI-83 Plus \nor TI-84 Plus calculator). The end-of-chapter features include a Technology Project.\nThe Statdisk statistical software package is designed specifically for this textbook \nand contains all Appendix B data sets. Statdisk is free to users of this book, and it can \nbe downloaded at www.statdisk.org.\nChanges in This Edition\nNew Features\nChapter Objectives provide a summary of key learning goals for each section in the \nchapter.\nLarger Data Sets: Some of the data sets in Appendix B are much larger than in the \nprevious edition. It is no longer practical to print all of the Appendix B data sets in this \nbook, so the data sets are described in Appendix B, and they can be downloaded at \nwww.TriolaStats.com, www.pearsonhighered.com/triola, and MyStatLab.\nNew Content: New examples, new exercises, and Chapter Problems provide relevant \nand interesting real-world statistical applications, including biometric security, drug \ntesting, gender selection, and analyzing ultrasound images.\nNumber\nNew to This Edition\nUse Real Data\nExercises\n1600\n85%\n89%\nExamples\n 200\n84%\n87%\nMajor Organization Changes\nAll Chapters\n \n■New Chapter Objectives: All chapters now begin with a list of key learning goals \nfor that chapter. Chapter Objectives replaces the former Overview numbered sec-\ntions. The first numbered section of each chapter now covers a major topic.\nChapter 1\n \n■New Section 1-1: Statistical and Critical Thinking\n \n■New Subsection 1-3, Part 2: Big Data and Missing Data: Too Much and Not Enough\n",
    "x \nPreface\nChapters 2 and 3\n \n■Chapter Partitioned: Chapter 2 (Describing, Exploring, and Comparing Data) \nfrom the first edition has been partitioned into Chapter 2 (Summarizing and Graph-\ning) and Chapter 3 (Statistics for Describing, Exploring, and Comparing Data).\n \n■New Section 2-4: Scatterplots, Correlation, and Regression This new section \nincludes scatterplots in Part 1, the linear correlation coefficient r in Part 2, and \nlinear regression in Part 3. These additions are intended to greatly facilitate cover-\nage for those professors who prefer some early coverage of correlation and regres-\nsion concepts. Chapter 10 includes these topics discussed with much greater detail.\nChapter 4\n \n■Combined Sections: Section 3-3 (Addition Rule) and Section 3-4 (Multiplication \nRule) from the first edition are now combined into one section: 4-2 (Addition \nRule and Multiplication Rule).\n \n■New Subsection 4-3, Part 3: Bayes’ Theorem\nChapter 5\n \n■Combined Sections: Section 4-3 (Binomial Probability Distributions) and \nSection 4-4 (Mean, Variance, and Standard Deviation for the Binomial Distribu-\ntion) from the first edition are now combined into one section: 5-2 (Binomial \nProbability Distributions).\nChapter 6\n \n■Switched Sections: Section 6-5 (Assessing Normality) now precedes Section 6-6 \n(Normal as Approximation to Binomial).\nChapter 7\n \n■Combined Sections: Sections 6-4 (Estimating a Population Mean: s Known) \nand 6-5 (Estimating a Population Mean: s Not Known) from the first edition \nhave been combined into one section: 7-2 (Estimating a Population Mean). The \ncoverage of the s known case has been substantially reduced and it is now lim-\nited to Part 2 of Section 7-2.\n \n■New Section 7-4: Bootstrapping: Using Technology for Estimates\nChapter 8\n \n■Combined Sections: Sections 7-4 (Testing a Claim About a Population Mean: s \nKnown) and 7-5 (Testing a Claim About a Population Mean: s Not Known) from \nthe first edition have been combined into one section: 8-3 (Testing a Claim About \na Mean). Coverage of the s known case has been substantially reduced and it is \nnow limited to Part 2 of Section 8-3.\nChapter 10\n \n■New Section: 10-5 Dummy Variables and Logistic Regression\nChapter 11\n \n■New Subsection: Section 11-2, Part 2 Test of Homogeneity, Fisher’s Exact Test, \nand McNemar’s Test for Matched Pairs\nChapter 14\n \n■Combined Sections: Section 13-2 (Elements of a Life Table) and Section 13-3 \n(Applications of Life Tables) from the first edition have been combined into \nSection 14-1 (Life Tables).\n \n■New Section: 14-2 Kaplan-Meier Survival Analysis\n",
    "Preface \nxi\nFlexible Syllabus\nThis book’s organization reflects the preferences of most statistics instructors, but \nthere are two common variations:\n \n■Early Coverage of Correlation and Regression: Some instructors prefer to \ncover the basics of correlation and regression early in the course. Section 2-4 \nnow includes basic concepts of scatterplots, correlation, and regression without \nthe use of formulas and greater depth found in Sections 10-1 (Correlation) and \n10-2 (Regression).\n \n■Minimum Probability: Some instructors prefer extensive coverage of probability, \nwhile others prefer to include only basic concepts. Instructors preferring mini-\nmum coverage can include Section 4-1 while skipping the remaining sections of \nChapter 4, as they are not essential for the chapters that follow. Many instructors \nprefer to cover the fundamentals of probability along with the basics of the addi-\ntion rule and multiplication rule (Section 4-2).\nGAISE\nThis book reflects recommendations from the American Statistical Association and \nits Guidelines for Assessment and Instruction in Statistics Education (GAISE). Those \nguidelines suggest the following objectives and strategies.\n1. Emphasize statistical literacy and develop statistical thinking: Each section \nexercise set begins with Statistical Literacy and Critical Thinking exercises. \nMany of the book’s exercises are designed to encourage statistical thinking \nrather than the blind use of mechanical procedures.\n2. Use real data: 87% of the examples and 89% of the exercises use real data.\n3. Stress conceptual understanding rather than mere knowledge of procedures: \nInstead of seeking simple numerical answers, most exercises and examples \ninvolve conceptual understanding through questions that encourage practical \ninterpretations of results. Also, each chapter includes a From Data to Decision \nproject.\n4. Foster active learning in the classroom: Each chapter ends with several \nCooperative Group Activities.\n5. Use technology for developing conceptual understanding and analyzing data: \nComputer software displays are included throughout the book. Special Tech \nCenter subsections are available online, and they include instruction for using \nthe software. Each chapter includes a Technology Project. When there are dis-\ncrepancies between answers based on tables and answers based on technology, \nAppendix D provides both answers. The websites www.TriolaStats.com and \nwww.pearsonhighered.com/triola as well as MyStatLab include free text-specific \nsoftware (Statdisk), data sets formatted for several different technologies, and \ninstructional videos for technologies.\n6. Use assessments to improve and evaluate student learning: Assessment tools \ninclude an abundance of section exercises, Chapter Quick Quizzes, Review \nExercises, Cumulative Review Exercises, Technology Projects, From Data to \nDecision projects, and Cooperative Group Activities.\n",
    "xii \nPreface\nAcknowledgments\nWe would like to thank the many statistics professors and students who have contrib-\nuted to the success of this book. We thank the reviewers for their suggestions for this \nsecond edition:\nJames Baldone, Virginia College\nNaomi Brownstein, Florida State University\nChristina Caruso, University of Guelph\nErica A. Corbett, Southeastern Oklahoma State University\nXiangming Fang, East Carolina University\nPhil Gona, UMASS Boston\nSharon Homan, University of North Texas\nJackie Milton, Boston University\nJoe Pick, Palm Beach State College\nSteve Rigdon, St. Louis University\nBrian Smith, Black Hills State University\nMahbobeh Vezvaei, Kent State University\nDavid Zeitler, Grand Valley State University\nWe also thank Paul Lorczak, Joseph Pick and Erica Corbett for their help in \nchecking the accuracy of the text and answers.\nMarc Triola\nMario Triola\nJason Roy\nSeptember 2016\n",
    "MyStatLab\n® Online Course for Biostatistics: For  \nthe Biological and Health Sciences, 2e by Marc M. Triola, \nMario F. Triola and Jason Roy (access code required)\nMyStatLab is available to accompany Pearson’s market leading text offerings. To give \nstudents a consistent tone, voice, and teaching method each text’s flavor and ap-\nproach is tightly integrated throughout the accompanying MyStatLab course, making \nlearning the material as seamless as possible.\nReal-World Data Examples - Help \nunderstand how statistics applies to \neveryday life through the extensive \ncurrent, real-world data examples and \nexercises provided throughout the text.\nMathXL coverage - MathXL is a market-leading \ntext-speciﬁc autograded homework system built \nto improve student learning outcomes.\nEnhanced video program to meet Introductory \nStatistics needs:\n•  New! Tech-Specific Video Tutorials - These \nshort, topical videos address how to use varying \ntechnologies to complete exercises.\n•  Updated! Section Lecture Videos - Watch author, \nMarty Triola, work through examples and elaborate \non key objectives of the chapter.\nResources for Success\nwww.mystatlab.com\nxiii\n",
    "xiv \nPreface\nSupplements\nFor the Student\nStudent’s Solutions Manual, by James Lapp (Colorado \nMesa University) provides detailed, worked-out solutions \nto all odd-numbered text exercises.\n(ISBN-13: 978-0-13-403909-1; ISBN-10: 0-13-403909-2)\nStudent Workbook for the Triola Statistics Series, by \nLaura lossi (Broward College) offers additional exam-\nples, concept exercises, and vocabulary exercises for each \nchapter.\n(ISBN-13: 978-0-13-446423-7; ISBN 10: 0-13-446423-0)\nThe following technology manuals, available in  MyStatLab, \ninclude instructions, examples from the main text, and \ninterpretations to complement those given in the text.\nExcel Student Laboratory Manual and Workbook \n(Download Only), by Laurel Chiappetta (University of \nPittsburgh).\n(ISBN-13: 978-0-13-446427-5; ISBN-10: 0-13-446427-3)\nMINITAB Student Laboratory Manual and Work-\nbook (Download Only), by Mario F. Triola.\n(ISBN-13: 978-0-13-446418-3; ISBN-10: 0-13-446418-4)\nGraphing Calculator Manual for the TI-83 Plus, \nTI-84 Plus, TI-84 Plus C and TI-84 Plus CE (Down-\nload Only), by Kathleen McLaughlin (University of \nConnecticut) & Dorothy Wakefield (University of Con-\nnecticut Health Center).\n(ISBN-13: 978-0-13-446414-5; ISBN 10: 0-13-446414-1)\nStatdisk Student Laboratory Manual and Workbook \n(Download Only), by Mario F. Triola. These files are \navailable to instructors and students through the Triola Sta-\ntistics Series website, www.pearsonhighered.com/triola, \nand MyStatLab.\nSPSS Student Laboratory Manual and Workbook \n(Download Only), by James J. Ball (Indiana State Uni-\nversity). These files are available to instructors and stu-\ndents through the Triola Statistics Series website, www.\npearsonhighered.com/triola, and MyStatLab.\nFor the Instructor\nInstructor’s Solutions Manual (Download Only), by \nJames Lapp (Colorado Mesa University) contains so-\nlutions to all the exercises. These files are available to \nqualified instructors through Pearson Education’s on-\nline catalog at www.pearsonhighered.com/irc or within \nMyStatLab.\nInsider’s Guide to Teaching with the Triola Statistics \nSeries, by Mario F. Triola, contains sample syllabi and \ntips for incorporating projects, as well as lesson overviews, \nextra examples, minimum outcome objectives, and recom-\nmended assignments for each chapter.\n(ISBN-13: 978-0-13-446425-1; ISBN-10: 0-13-446425-7)\nTestGen® Computerized Test Bank (www.pearsoned.\ncom/testgen) enables instructors to build, edit, print, and \nadminister tests using a computerized bank of questions \ndeveloped to cover all the objectives of the text. TestGen is \nalgorithmically based, allowing instructors to create mul-\ntiple but equivalent versions of the same question or test \nwith the click of a button. Instructors can also modify test \nbank questions or add new questions. The software and tes-\ntbank are available for download from Pearson Education’s \nonline catalog at www.pearsonhighered.com. A test bank \n(Download Only) is also available from the  online catalog.\nLearning Catalytics: Learning Catalytics is a web-based \nengagement and assessment tool. As a “bring-your-own-\ndevice” direct response system, Learning Catalytics offers \na diverse library of dynamic question types that allow stu-\ndents to interact with and think critically about statistical \nconcepts. As a real-time resource, instructors can take ad-\nvantage of critical teaching moments both in the classroom \nor through assignable and gradeable homework.\nTechnology Resources\nThe following resources can be found on the Triola Statistics \nSeries website (http://www.pearsonhighered.com/triola), the \nauthor maintained www.triolastats.com, and MyStatLab\n \n■Appendix B data sets formatted for Minitab, SPSS, \nSAS, Excel, JMP, and as text files. Additionally, these \ndata sets are available as an APP for the TI-83>84 \nPlus calculators, and supplemental programs for the \nTI-83>84 Plus calculator are also available.\n \n■Statdisk statistical software instructions for down-\nload. New features include the ability to directly use \nlists of data instead of requiring the use of their sum-\nmary statistics.\n \n■Extra data sets, an index of applications, and a sym-\nbols table.\nVideo resources have been expanded, updated and now \nsupplement most sections of the book, with many topics \npresented by the author.  The videos aim to support both \ninstructors and students through lecture, reinforcing sta-\ntistical basics through technology, and applying concepts:\n \n■Section Lecture Videos\n",
    "Preface \nxv\n \n■New! Technology Video Tutorials - These short, \ntopical videos address how to use Excel, Statdisk, \nand the TI graphing calculator to complete exercises.\n \n■StatTalk Videos: 24 Conceptual Videos to Help \nYou Actually Understand Statistics. Fun-loving \nstatistician Andrew Vickers takes to the streets of \nBrooklyn, NY, to demonstrate important statistical \nconcepts through interesting stories and real-life \nevents. These fun and engaging videos will help \nstudents actually understand statistical concepts. \nAvailable with an instructors user guide and assess-\nment questions.\nMyStatLab™ Online Course (access code required)\nMyStatLab is a course management system that delivers \nproven results in helping individual students succeed.\n \n■MyStatLab can be successfully implemented in \nany environment—lab-based, hybrid, fully online, \ntraditional—and demonstrates the quantifiable differ-\nence that integrated usage has on student retention, \nsubsequent success, and overall achievement.\n \n■MyStatLab’s comprehensive online gradebook au-\ntomatically tracks students’ results on tests, quizzes, \nhomework, and in the study plan. Instructors can use \nthe gradebook to provide positive feedback or inter-\nvene if students have trouble. Gradebook data can be \neasily exported to a variety of spreadsheet programs, \nsuch as Microsoft Excel. You can determine which \npoints of data you want to export, and then analyze \nthe results to determine success.\nMyStatLab provides engaging experiences that personal-\nize, stimulate, and measure learning for each student. In \naddition to the resources below, each course includes a full \ninteractive online version of the accompanying textbook.\n \n■Tutorial Exercises with Multimedia Learning Aids: \nThe homework and practice exercises in MyStatLab \nalign with the exercises in the textbook, and they \nregenerate algorithmically to give students unlim-\nited opportunity for practice and mastery. Exercises \noffer immediate helpful feedback, guided solutions, \nsample problems, animations, videos, and eText clips \nfor extra help at point-of-use.\n \n■Getting Ready for Statistics: A library of questions \nnow appears within each MyStatLab course to offer \nthe developmental math topics students need for the \ncourse. These can be assigned as a prerequisite to \nother assignments, if desired.\n \n■Conceptual Question Library: In addition to algo-\nrithmically regenerated questions that are aligned with \nyour textbook, there is a library of 1000 Conceptual \nQuestions available in the assessment manager that re-\nquire students to apply their statistical understanding.\n \n■StatCrunch™: MyStatLab integrates the web-based \nstatistical software, StatCrunch, within the online as-\nsessment platform so that students can easily analyze \ndata sets from exercises and the text. In addition, \nMyStatLab includes access to www.StatCrunch.com, \na website where users can access more than 15,000 \nshared data sets, conduct online surveys, perform \ncomplex analyses using the powerful statistical \nsoftware, and generate compelling reports.\n \n■Statistical Software Support: Knowing that  students \noften use external statistical software, we make it \neasy to copy our data sets, both from the ebook and \nthe MyStatLab questions, into software such as \nStatCrunch, Minitab, Excel, and more. Students have \naccess to a variety of support tools—Technology  \nTutorial Videos, Technology Study Cards, and Tech-\nnology Manuals for select titles—to learn how to \neffectively use statistical software.\nMathXL® for Statistics Online Course (access code \nrequired)\nMathXL® is the homework and assessment engine that \nruns MyStatLab. (MyStatLab is MathXL plus a learning \nmanagement system.)\nWith MathXL for Statistics, instructors can:\n \n■Create, edit, and assign online homework and tests \nusing algorithmically generated exercises correlated \nat the objective level to the textbook.\n \n■Create and assign their own online exercises and \nimport TestGen tests for added flexibility.\n \n■Maintain records of all student work, tracked in \nMathXL’s online gradebook.\nWith MathXL for Statistics, students can:\n \n■Take chapter tests in MathXL and receive personal-\nized study plans and>or personalized homework \nassignments based on their test results.\n \n■Use the study plan and>or the homework to link \ndirectly to tutorial exercises for the objectives they \nneed to study.\n \n■Students can also access supplemental animations \nand video clips directly from selected exercises.\n \n■Knowing that students often use external statistical \nsoftware, we make it easy to copy our data sets, both \nfrom the ebook and the MyStatLab questions, into \nsoftware like StatCrunch™, Minitab, Excel, and more.\n",
    "xvi\t\nPreface\nMathXL for Statistics is available to qualified adopters. \nFor more information, visit our website at www.mathxl \n.com, or contact your Pearson representative.\nStatCrunch™\nStatCrunch is powerful, web-based statistical software \nthat allows users to perform complex analyses, share data \nsets, and generate compelling reports. A vibrant online \ncommunity offers more than 15,000 data sets for students \nto analyze.\n■\n■Collect. Users can upload their own data to ­StatCrunch \nor search a large library of publicly shared data sets, \nspanning almost any topic of interest. Also, an online \nsurvey tool allows users to quickly collect data via \nweb-based surveys.\n■\n■Crunch. A full range of numerical and graphical \nmethods allow users to analyze and gain insights \nfrom any data set. Interactive graphics help users \nunderstand statistical concepts and are available for \nexport to enrich reports with visual representations \nof data.\n■\n■Communicate. Reporting options help users create a \nwide variety of visually appealing representations of \ntheir data.\nFull access to StatCrunch is available with ­MyStatLab \nand StatCrunch is available by itself to qualified adopt-\ners. StatCrunch Mobile is now available to access from \nyour mobile device. For more information, visit our web-\nsite at www.StatCrunch.com, or contact your Pearson \n­representative.\nMinitab® 17 and Minitab Express™ make learning sta-\ntistics easy and provide students with a skill-set that’s \nin demand in today’s data driven workforce. Bundling \nMinitab® software with educational materials ensures stu-\ndents have access to the software they need in the class-\nroom, around campus, and at home. And having 12 month \nversions of Minitab 17 and Minitab Express available \nensures students can use the software for the duration of \ntheir course.\nISBN 13: 978-0-13-445640-9\nISBN 10: 0-13-445640-8 (Access Card only; not sold as \nstand alone.)\nJMP Student Edition, Version 12 is an easy-to-use, stream-\nlined version of JMP desktop statistical discovery software \nfrom SAS Institute, Inc., and is available for bundling with \nthe text.\n(ISBN-13: 978-0-13-467979-2 ISBN-10: 0-13-467979-2)\n",
    "Statistical and Critical \nThinking\nTypes of Data\nCollecting Sample Data\n1-1\n1-2\n1-3\nSurvey Question: Do You Need Caffeine to Start Up Your Brain for the Day?\nCHAPTER \nPROBLEM\nIntroduction  \nto Statistics\n1\nSurveys provide data that enable us to improve products or \nservices. Surveys guide political candidates, shape business \npractices, identify effective medical treatments, and affect \nmany aspects of our lives. Surveys give us insight into the \nopinions and behaviors of others. As an example, the National \nHealth and Nutrition Examination Survey (NHANES) is part \n1\nof a research program that studies the health and nutrition of \nthousands of adults and children in the United States.\nLet’s consider one USA Today survey in which respondents \nwere asked if they need caffeine to start up their brain for the \nday. Among 2,006 respondents, 74% said that they did need the \ncaffeine. Figure 1-1 includes graphs that depict these results.\n",
    "The survey results suggest that people overwhelmingly need caffeine to start up their brains \nfor the day. The graphs in Figure 1-1 visually depict the survey results. One of the most impor-\ntant objectives of this book is to encourage the use of critical thinking so that such results are \nnot blindly accepted. We might question whether the survey results are valid. Who conducted \nthe survey? How were respondents selected? Do the graphs in Figure 1-1 depict the results \nwell, or are those graphs somehow misleading?\nThe survey results presented here have major flaws that are among the most common, so \nthey are especially important to recognize. Here are brief descriptions of each of the major flaws:\nFlaw 1: Misleading Graphs The bar chart in Figure 1-1(a) is very deceptive. By using a \nvertical scale that does not start at zero, the difference between the two percentages is grossly \nexaggerated. Figure 1-1(a) makes it appear that approximately eight times as many people \nneed the caffeine. However, with 74% needing caffeine and 26% not needing caffeine, the \nratio is actually about 3:1, rather than the 8:1 ratio that is suggested by the graph.\nThe illustration in Figure 1-1(b) is also deceptive. Again, the difference between the actual \nresponse rates of 74% (needing caffeine) and 26% (not needing caffeine) is a difference that \nis grossly distorted. The picture graph (or “pictograph”) in Figure 1-1(b) makes it appear that \n2 \nCHAPTER 1 Introduction to Statistics\nFIGURE 1-1(a) Survey Results\nFIGURE 1-1(b) Survey Results\nPeople Needing Caﬀeine to Start\nUp Brain for the Day\nPeople Not Needing Caﬀeine to Start\nUp Brain for the Day\n",
    "the ratio of people needing caffeine to people not needing caffeine is roughly 9:1 instead of \nthe correct ratio of about 3:1. (Objects with area or volume can distort perceptions because \nthey can be drawn to be disproportionately larger or smaller than the data indicate.) Decep-\ntive graphs are discussed in more detail in Section 2-3, but we see here that the illustrations in \nFigure 1-1 grossly exaggerate the number of people needing caffeine.\nFlaw 2: Bad Sampling Method The aforementioned survey responses are from a USA \nToday survey of Internet users. The survey question was posted on a website and Internet \nusers decided whether to respond. This is an example of a voluntary response sample—a \nsample in which respondents themselves decide whether to participate. With a voluntary \nresponse sample, it often happens that those with a strong interest in the topic are more likely \nto participate, so the results are very questionable. For example, people who strongly feel that \nthey cannot function without their morning cup(s) of coffee might be more likely to respond to \nthe caffeine survey than people who are more ambivalent about caffeine or coffee. When using \nsample data to learn something about a population, it is extremely important to obtain sample \ndata that are representative of the population from which the data are drawn. As we proceed \nthrough this chapter and discuss types of data and sampling methods, we should focus on \nthese key concepts:\n• Sample data must be collected in an appropriate way, such as through a process of \nrandom selection.\n• If sample data are not collected in an appropriate way, the data may be so completely \nuseless that no amount of statistical torturing can salvage them.\nIt would be easy to accept the preceding survey results and blindly proceed with calcula-\ntions and statistical analyses, but we would miss the critical two flaws described above. We \ncould then develop conclusions that are fundamentally wrong and misleading. Instead, we \nshould develop skills in statistical thinking and critical thinking so that we are better prepared \nto analyze such data.\nChapter Objectives \n3\nThe single most important concept presented in this chapter is this: When using meth-\nods of statistics with sample data to form conclusions about a population, it is absolutely \nessential to collect sample data in a way that is appropriate. Here are the main chapter \nobjectives:\nStatistical and Critical Thinking\n• Analyze sample data relative to context, source, and sampling method.\n• Understand the difference between statistical significance and practical significance.\n• Define and identify a voluntary response sample and know that statistical conclu-\nsions based on data from such a sample are generally not valid.\n1-1\nCHAPTER OBJECTIVES\n>>>\n",
    "4 \nCHAPTER 1 Introduction to Statistics\nBecause populations are often very large, a common objective of the use of statis-\ntics is to obtain data from a sample and then use those data to form a conclusion about \nthe population.\nTypes of Data\n• Distinguish between a parameter and a statistic.\n• Distinguish between quantitative data and categorical (or qualitative or attribute) data.\n• Distinguish between discrete data and continuous data.\n• Determine whether basic statistical calculations are appropriate for a particular data set.\nCollecting Sample Data\n• Define and identify a simple random sample.\n• Understand the importance of sound sampling methods and the importance of \ngood design of experiments.\n1-2\n1-3\nTypes of Data\n• Distinguish between a parameter and a\nr r\nstatistic.\n• Distinguish between quantitative data and categorical (or \nl l\nqualitative or attribute) data.\n• Distinguish between discrete data and continuous data.\n• Determine whether basic statistical calculations are appropriate for a particular data set.\nCollecting Sample Data\n• Define and identify a simple random sample.\n• Understand the importance of sound sampling methods and the importance of \ngood design of experiments.\nKey Concept In this section we begin with a few very basic definitions, and then we \nconsider an overview of the process involved in conducting a statistical study. This \nprocess consists of “prepare, analyze, and conclude.” “Preparation” involves consid-\neration of the context, the source of data, and sampling method. In future chapters we \nconstruct suitable graphs, explore the data, and execute computations required for the \nstatistical method being used. In future chapters we also form conclusions by deter-\nmining whether results have statistical significance and practical significance.\nStatistical thinking involves critical thinking and the ability to make sense of results. \nStatistical thinking demands so much more than the ability to execute complicated cal-\nculations. Through numerous examples, exercises, and discussions, this text will help \nyou develop the statistical thinking skills that are so important in today’s world.\nWe begin with some very basic definitions.\n1-1 \nStatistical and Critical Thinking\nDEFINITIONS\nData are collections of observations, such as measurements, or survey responses. \n(A single data value is called a datum, a term rarely used. The term “data” is plural, \nso it is correct to say “data are…” not “data is…”)\nStatistics is the science of planning studies and experiments; obtaining data; and \norganizing, summarizing, presenting, analyzing, and interpreting those data and \nthen drawing conclusions based on them.\nA population is the complete collection of all measurements or data that are be-\ning considered. Typically, the population is the complete collection of data that we \nwould like to make inferences about.\nA census is the collection of data from every member of the population.\nA sample is a subcollection of members selected from a population.\n",
    "1-1 Statistical and Critical Thinking \n5\nWe now proceed to consider the process involved in a statistical study. See Figure 1-2 \nfor a summary of this process and note that the focus is on critical thinking, not mathe-\nmatical calculations. Thanks to wonderful developments in technology, we have power-\nful tools that effectively do the number crunching so that we can focus on understanding \nand interpreting results.\nEXAMPLE 1  Residential Carbon Monoxide Detectors\nIn the journal article “Residential Carbon Monoxide Detector Failure Rates in the \nUnited States” (by Ryan and Arnold, American Journal of Public Health, Vol. 101, \nNo. 10), it was stated that there are 38 million carbon monoxide detectors installed \nin the United States. When 30 of them were randomly selected and tested, it was \nfound that 12 of them failed to provide an alarm in hazardous carbon monoxide \nconditions. In this case, the population and sample are as follows:\nPopulation: All 38 million carbon monoxide detectors in the United States \nSample: The 30 carbon monoxide detectors that were selected and tested \nThe objective is to use the sample data as a basis for drawing a conclusion about the \npopulation of all carbon monoxide detectors, and methods of statistics are helpful in \ndrawing such conclusions.\nConclude\n1. Signiﬁcance\n• Do the results have statistical signiﬁcance?\n• Do the results have practical signiﬁcance?\nAnalyze\n1. Graph the Data\n2. Explore the Data\n• Are there any outliers (numbers very far away from almost all of the other data)?\n• What important statistics summarize the data (such as the mean and standard deviation\n described in Chapter 3)?\n• How are the data distributed?\n• Are there missing data?\n• Did many selected subjects refuse to respond?\n3. Apply Statistical Methods\n• Use technology to obtain results.\nPrepare\n1. Context\n• What do the data represent?\n• What is the goal of study? \n2. Source of the Data\n• Are the data from a source with a special interest so that there is pressure to obtain \n results that are favorable to the source?\n3. Sampling Method\n \n• Were the data collected in a way that is unbiased, or were the data collected in a \n way that is biased (such as a procedure in which respondents volunteer to participate)?\nFIGURE 1-2 Statistical Thinking\nSurvivorship Bias\nIn World War \nII, statisti-\ncian Abraham \nWald saved \nmany lives \nwith his work \non the Applied \nMathematics Panel. Military \nleaders asked the panel how they \ncould improve the chances of \naircraft bombers returning after \nmissions. They wanted to add \nsome armor for protection, and \nthey recorded locations on the \nbombers where damaging holes \nwere found. They reasoned that \narmor should be placed in loca-\ntions with the most holes, but \nWald said that strategy would be \na big mistake. He said that armor \nshould be placed where returning \nbombers were not damaged. His \nreasoning was this: The bombers \nthat made it back with damage \nwere survivors, so the damage \nthey suffered could be survived. \nLocations on the aircraft that \nwere not damaged were the most \nvulnerable, and aircraft suffer-\ning damage in those vulnerable \nareas were the ones that did \nnot make it back. The military \nleaders would have made a big \nmistake with survivorship bias by \nstudying the planes that survived \ninstead of thinking about the \nplanes that did not survive.\n",
    "6 \nCHAPTER 1 Introduction to Statistics\nPrepare\nContext Figure 1-2 suggests that we begin our preparation by considering the context \nof the data, so let’s start with context by considering the data in Table 1-1. (The data \nare from Data Set 9 “IQ and Brain Size” in Appendix B.) The data in Table 1-1 consist \nof measured IQ scores and measured brain volumes from 10 different subjects. The \ndata are matched in the sense that each individual “IQ>brain volume” pair of values \nis from the same person. The first subject had a measured IQ score of 96 and a brain \nvolume of 1005 cm3. The format of Table 1-1 suggests the following goal: Determine \nwhether there is a relationship between IQ score and brain volume. This goal suggests \na possible hypothesis: People with larger brains tend to have higher IQ scores.\nSource of the Data The data in Table 1-1 were provided by M. J. Tramo, W. C. \nLoftus, T. A. Stukel, J. B. Weaver, and M. S. Gazziniga, who discuss the data in the \narticle “Brain Size, Head Size, and IQ in Monozygotic Twins,” Neurology, Vol. 50. \nThe researchers are from reputable medical schools and hospitals, and they would not \ngain by presenting the results in way that is misleading. In contrast, Kiwi Brands, a \nmaker of shoe polish, commissioned a study that resulted in this statement, which was \nprinted in some newspapers: “According to a nationwide survey of 250 hiring profes-\nsionals, scuffed shoes was the most common reason for a male job seeker’s failure to \nmake a good first impression.”\nWhen physicians who conduct clinical experiments on the efficacy of drugs re-\nceive funding from drug companies, they have an incentive to obtain favorable results. \nSome professional journals, such as the Journal of the American Medical Association, \nnow require that physicians report sources of funding in journal articles. We should be \nskeptical of studies from sources that may be biased.\nSampling Method Figure 1-2 suggests that we conclude our preparation by consid-\nering the sampling method. The data in Table 1-1 were obtained from subjects whose \nmedical histories were reviewed in an effort to ensure that no subjects had neurologic \nor psychiatric disease. In this case, the sampling method appears to be sound, but we \ncannot be sure of that without knowing how the subjects were recruited and whether \nany payments may have affected participation in the study.\nSampling methods and the use of randomization will be discussed in Section 1-3, \nbut for now, we stress that a sound sampling method is absolutely essential for good \nresults in a statistical study. It is generally a bad practice to use voluntary response (or \nself-selected) samples, even though their use is common.\nTABLE 1-1 IQ Scores and Brain Volumes (cm3)\nIQ\n96\n87\n101\n103\n127\n96\n88\n85\n97\n124\nBrain Volume (cm3)\n1005\n1035\n1281\n1051\n1034\n1079\n1104\n1439\n1029\n1160\nDEFINITION\nA voluntary response sample (or self-selected sample) is one in which the \nrespondents themselves decide whether to be included.\nThe following types of polls are common examples of voluntary response samples. \nBy their very nature, all are seriously flawed because we should not make conclusions \nabout a population on the basis of samples with a strong possibility of bias:\n \n■Internet polls, in which people online can decide whether to respond\n \n■Mail-in polls, in which people decide whether to reply\nOrigin of “Statistics”\nThe word \nstatistics is \nderived from \nthe Latin word \nstatus (mean-\ning “state”). \nEarly uses of \nstatistics involved compilations \nof data and graphs describing \nvarious aspects of a state or \ncountry. In 1662, John Graunt \npublished statistical information \nabout births and deaths. Graunt’s \nwork was followed by studies \nof mortality and disease rates, \npopulation sizes, incomes, and \nunemployment rates. House-\nholds, governments, and busi-\nnesses rely heavily on statistical \ndata for guidance. For example, \nunemployment rates, inflation \nrates, consumer indexes, and \nbirth and death rates are carefully \ncompiled on a regular basis, \nand the resulting data are used \nby business leaders to make \ndecisions affecting future hiring, \nproduction levels, and expansion \ninto new markets.\n",
    "1-1 Statistical and Critical Thinking \n7\n \n■Telephone call-in polls, in which newspaper, radio, or television announcements \nask that you voluntarily call a special number to register your opinion\nThe Chapter Problem involves a USA Today survey with a voluntary response sample. \nSee also the following Example 2.\nEXAMPLE 2  Voluntary Response Sample\nUSA Today posted this question on the electronic edition of their newspaper: “Have \nyou ever been bitten by an animal?” Internet users who saw that question then de-\ncided themselves whether to respond. Among the 2361 responses, 65% said “yes” \nand 35% said “no.” Because the 2361 subjects themselves chose to respond, they \nare a voluntary response sample and the results of the survey are highly question-\nable. It would be much better to get results through a poll in which the pollster ran-\ndomly selects the subjects, instead of allowing the subjects to volunteer themselves.\nAnalyze\nFigure 1-2 indicates that after completing our preparation by considering the context, \nsource, and sampling method, we begin to analyze the data.\nGraph and Explore An analysis should begin with appropriate graphs and explora-\ntions of the data. Graphs are discussed in Chapter 2, and important statistics are dis-\ncussed in Chapter 3.\nApply Statistical Methods Later chapters describe important statistical methods, \nbut application of these methods is often made easy with technology (calculators \nand>or statistical software packages). A good statistical analysis does not require \nstrong computational skills. A good statistical analysis does require using common \nsense and paying careful attention to sound statistical methods.\nConclude\nFigure 1-2 shows that the final step in our statistical process involves conclusions, and \nwe should develop an ability to distinguish between statistical significance and practi-\ncal significance.\nStatistical Significance Statistical significance is achieved in a study when we get \na result that is very unlikely to occur by chance. A common criterion is that we have \nstatistical significance if the likelihood of an event occurring by chance is 5% or less.\n \n■Getting 98 girls in 100 random births is statistically significant because such an \nextreme outcome is not likely to result from random chance.\n \n■Getting 52 girls in 100 births is not statistically significant because that event \ncould easily occur with random chance.\nPractical Significance It is possible that some treatment or finding is effective, but \ncommon sense might suggest that the treatment or finding does not make enough of a \ndifference to justify its use or to be practical, as illustrated in Example 3 which follows.\n",
    "8 \nCHAPTER 1 Introduction to Statistics\nAnalyzing Data: Potential Pitfalls\nHere are a few more items that could cause problems when analyzing data.\nMisleading Conclusions When forming a conclusion based on a statistical analy-\nsis, we should make statements that are clear even to those who have no understand-\ning of statistics and its terminology. We should carefully avoid making statements \nnot justified by the statistical analysis. For example, later in this book we introduce \nthe concept of a correlation, or association between two variables, such as smoking \nand pulse rate. A statistical analysis might justify the statement that there is a cor-\nrelation between the number of cigarettes smoked and pulse rate, but it would not \njustify a statement that the number of cigarettes smoked causes a person’s pulse rate \nto change. Such a statement about causality can be justified by physical evidence, not \nby statistical analysis.\nCorrelation does not imply causation.\nSample Data Reported Instead of Measured When collecting data from people, \nit is better to take measurements yourself instead of asking subjects to report results. \nAsk people what they weigh and you are likely to get their desired weights, not their \nactual weights. People tend to round, usually down, sometimes way down. When \nasked, someone with a weight of 187 lb might respond that he or she weighs 160 lb. \nAccurate weights are collected by using a scale to measure weights, not by asking \npeople what they weigh.\nLoaded Questions If survey questions are not worded carefully, the results of a \nstudy can be misleading. Survey questions can be “loaded” or intentionally worded to \nelicit a desired response. Here are the actual rates of “yes” responses for the two dif-\nferent wordings of a question:\n97% yes: “Should the President have the line item veto to eliminate waste?”\n57% yes: “Should the President have the line item veto, or not?”\nOrder of Questions Sometimes survey questions are unintentionally loaded \nby such factors as the order of the items being considered. See the following two \nEXAMPLE 3   Statistical Significance Versus  \nPractical Significance\nProCare Industries once supplied a product named Gender Choice that supposedly \nincreased the chance of a couple having a baby with the gender that they desired. \nIn the absence of any evidence of its effectiveness, the product was banned by the \nFood and Drug Administration (FDA) as a “gross deception of the consumer.” But \nsuppose that the product was tested with 10,000 couples who wanted to have baby \ngirls, and the results consist of 5200 baby girls born in the 10,000 births. This re-\nsult is statistically significant because the likelihood of it happening due to chance \nis only 0.003%, so chance doesn’t seem like a feasible explanation. That 52% rate \nof girls is statistically significant, but it lacks practical significance because 52% is \nonly slightly above 50%. Couples would not want to spend the time and money to \nincrease the likelihood of a girl from 50% to 52%. (Note: In reality, the likelihood \nof a baby being a girl is about 48.8%, not 50%.)\n",
    "1-1 Statistical and Critical Thinking \n9\nquestions from a poll conducted in Germany, along with the very different response \nrates:\n“Would you say that traﬃc contributes more or less to air pollution than indus-\ntry?” (45% blamed traﬃc; 27% blamed industry.)\n“Would you say that industry contributes more or less to air pollution than traf-\nﬁc?” (24% blamed traﬃc; 57% blamed industry.)\nIn addition to the order of items within a question, as illustrated above, the order of \nseparate questions could also affect responses.\nNonresponse A nonresponse occurs when someone either refuses to respond to \na survey question or is unavailable. When people are asked survey questions, some \nfirmly refuse to answer. The refusal rate has been growing in recent years, partly be-\ncause many persistent telemarketers try to sell goods or services by beginning with a \nsales pitch that initially sounds as though it is part of an opinion poll. (This “selling \nunder the guise” of a poll is called sugging.) In Lies, Damn Lies, and Statistics, author \nMichael Wheeler makes this very important observation:\nPeople who refuse to talk to pollsters are likely to be different from those \nwho do not. Some may be fearful of strangers and others jealous of their \nprivacy, but their refusal to talk demonstrates that their view of the \nworld around them is markedly different from that of those people who \nwill let poll-takers into their homes.\nPercentages Some studies cite misleading or unclear percentages. Note that 100% \nof some quantity is all of it, but if there are references made to percentages that exceed \n100%, such references are often not justified. If a medical researcher claims that she \nhas developed a treatment for migraine headaches and the treatment results in a 150% \nreduction in those headaches, that researcher cannot be correct, because totally elimi-\nnating all migraine headaches would be a 100% reduction. It is impossible to reduce \nthe number of migraine headaches by more than 100%.\nWhen working with percentages, we should know that % or “percent” really \nmeans “divided by 100.” Here is a principle used often in this book.\nPercentage of: To ﬁnd a percentage of an amount, replace the % symbol with \ndivision by 100, and then interpret “of” to be multiplication. The following \n calculation shows that 6% of 1200 is 72:\n6% of 1200 responses =\n6\n100 * 1200 = 72\nStatistical Literacy and Critical Thinking\n1. Online Medical Info USA Today posted this question on its website: “How often do you seek \nmedical information online?” Of 1072 Internet users who chose to respond, 38% of them responded \nwith “frequently.” What term is used to describe this type of survey in which the people surveyed \nconsist of those who decided to respond? What is wrong with this type of sampling method?\n2. Reported Versus Measured In a survey of 1046 adults conducted by Bradley Corpora-\ntion, subjects were asked how often they wash their hands when using a public restroom, and \n70% of the respondents said “always.”\na. Identify the sample and the population.\nb. Why would better results be obtained by observing the hand washing instead of asking about it?\n1-1 Basic Skills and Concepts\ne \nPublication Bias\nThere is a “pub-\nlication bias” \nin professional \njournals. It is \nthe tendency to \npublish positive \nresults (such \nas showing that some treatment \nis effective) much more often \nthan negative results (such as \nshowing that some treatment has \nno effect). In the article “Regis-\ntering Clinical Trials” (Journal of \nthe American Medical Asso-\nciation, Vol. 290, No. 4), authors \nKay Dickersin and Drummond \n Rennie state that “the result of \nnot knowing who has performed \nwhat (clinical trial) is loss and \ndistortion of the evidence, waste \nand duplication of trials, inability \nof funding agencies to plan, and \na chaotic system from which \nonly certain sponsors might \nbenefit, and is invariably against \nthe interest of those who offered \nto participate in trials and of \npatients in general.” They sup-\nport a process in which all clinical \ntrials are registered in one central \nsystem, so that future research-\ners have access to all previous \nstudies, not just the studies that \nwere published.\n",
    "10 \nCHAPTER 1 Introduction to Statistics\n3. Statistical Significance Versus Practical Significance When testing a new treatment, \nwhat is the difference between statistical significance and practical significance? Can a treat-\nment have statistical significance, but not practical significance?\n4. Correlation One study showed that for a recent period of 11 years, there was a strong cor-\nrelation (or association) between the numbers of people who drowned in swimming pools and \nthe amounts of power generated by nuclear power plants (based on data from the Centers for \nDisease Control and Prevention and the Department of Energy). Does this imply that increas-\ning power from nuclear power plants is the cause of more deaths in swimming pools? Why or \nwhy not?\nConsider the Source. In Exercises 5–8, determine whether the given source has the \n potential to create a bias in a statistical study.\n5. Physicians Committee for Responsible Medicine The Physicians Committee for Re-\nsponsible Medicine tends to oppose the use of meat and dairy products in our diets, and that \norganization has received hundreds of thousands of dollars in funding from the Foundation to \nSupport Animal Protection.\n6. Arsenic in Rice Amounts of arsenic in samples of rice grown in Texas were measured by \nthe Food and Drug Administration (FDA).\n7. Brain Size A data set in Appendix B includes brain volumes from 10 pairs of monozygotic \n(identical) twins. The data were collected by researchers at Harvard University, Massachusetts \nGeneral Hospital, Dartmouth College, and the University of California at Davis.\n8. Chocolate An article in Journal of Nutrition (Vol. 130, No. 8) noted that chocolate is rich \nin flavonoids. The article notes “regular consumption of foods rich in flavonoids may reduce \nthe risk of coronary heart disease.” The study received funding from Mars, Inc., the candy com-\npany, and the Chocolate Manufacturers Association.\nSampling Method. In Exercises 9–12, determine whether the sampling method appears \nto be sound or is flawed.\n9. Nuclear Power Plants In a survey of 1368 subjects, the following question was posted \non the USA Today website: “In your view, are nuclear plants safe?” The survey subjects \nwere Internet users who chose to respond to the question posted on the electronic edition of \nUSA Today.\n10. Clinical Trials Researchers at Yale University conduct a wide variety of clinical trials by \nusing subjects who volunteer after reading advertisements soliciting paid volunteers.\n11. NHANES Examinations In a recent year, the National Health and Nutrition Examina-\ntion Survey (NHANES), sponsored by the National Center for Health Statistics, selected \nmore than 9000 subjects who were given physical exams. Subjects were selected through \na somewhat complicated procedure designed to obtain results that are representative of the \npopulation.\n12. Health In a survey of 3014 randomly selected U.S. adults, 45% reported that they have \nat least one chronic health condition, such as diabetes or high blood pressure. The survey was \nconducted by Princeton Survey Research Associates International.\nStatistical Significance and Practical Significance. In Exercises 13–16, determine \nwhether the results appear to have statistical significance, and also determine whether the \nresults appear to have practical significance.\n13. Diet and Exercise Program In a study of the Kingman diet and exercise program, \n40  subjects lost an average of 22 pounds. There is about a 1% chance of getting such results \nwith a program that has no effect.\n",
    "1-1 Statistical and Critical Thinking \n11\n14. MCAT The Medical College Admissions Test (MCAT) is commonly used as part of the \n decision-making process for determining which students to accept into medical schools. To test \nthe effectiveness of the Siena MCAT preparation course, 16 students take the MCAT test, then \nthey complete the preparatory course, and then they retake the MCAT test, with the result that the \naverage (mean) score for this group rises from 25 to 30. There is a 0.3% chance of getting those \nresults by chance. Does the course appear to be effective?\n15. Gender Selection In a study of the Gender Aide method of gender selection used to \n increase the likelihood of a baby being born a girl, 2000 users of the method gave birth to \n980 boys and 1020 girls. There is about a 19% chance of getting that many girls if the method \nhad no effect.\n16. Systolic Blood Pressure High systolic blood pressure is 140 mm Hg or higher.  (Normal \nvalues are less than 120 mm Hg, and prehypertension levels are between 120 mm Hg and \n139 mm Hg.) Subjects with high blood pressure are encouraged to take action to lower it. A \npharmaceutical company develops a new medication designed to lower blood pressure, and \ntests on 25 subjects result in an average (mean) decrease of 2 mm Hg. Analysis of the results \nshows that there is a 15% chance of getting such results if the medication has no effect.\nIn Exercises 17–20, refer to the sample of body temperatures (degrees Fahrenheit) in the \ntable below. (The body temperatures are recorded on the same day from a sample of five \nrandomly selected males listed in a data set in Appendix B.)\nSubject\n1\n2\n3\n4\n5\n8 AM\n97.0\n98.5\n97.6\n97.7\n98.7\n12 AM\n97.6\n97.8\n98.0\n98.4\n98.4\n17. Context of the Data Refer to the table of body temperatures. Is there some meaning-\nful way in which each body temperature recorded at 8 AM is matched with the 12 AM \n temperature?\n18. Source The listed body temperatures were obtained from Dr. Steven Wasserman, Dr. \nPhilip Mackowiak, and Dr. Myron Levine, who were researchers at the University of Maryland. \nIs the source of the data likely to be biased?\n19. Conclusion Given the body temperatures in the table, what issue can be addressed by con-\nducting a statistical analysis of the data?\n20. Conclusion If we analyze the listed body temperatures with suitable methods of statistics, \nwe conclude that when the differences are found between the 8 AM body temperatures and \nthe 12 AM body temperatures, there is a 64% chance that the differences can be explained by \nrandom results obtained from populations that have the same 8 AM and 12 AM body tempera-\ntures. What should we conclude about the statistical significance of those differences?\nIn Exercises 21–24, refer to the data in the table below. The entries are white blood cell \ncounts (1000 cells,ML) and red blood cell counts (million cells,ML) from male subjects \n examined as part of a large health study conducted by the National Center for Health Statis-\ntics. The data are matched, so that the first subject has a white blood cell count of 8.7 and a \nred blood cell count of 4.91, and so on.\nSubject\n1\n2\n3\n4\n5\nWhite\n8.7\n5.9\n7.3\n6.2\n5.9\nRed\n4.91\n5.59\n4.44\n4.80\n5.17\ncontinued\n",
    "12 \nCHAPTER 1 Introduction to Statistics\n21. Context Given that the data (on the bottom of the preceding page) are matched and consid-\nering the units of the data, does it make sense to use the difference between each white blood \ncell count and the corresponding red blood cell count? Why or why not?\n22. Analysis Given the context of the data in the table (on the bottom of the preceding page), \nwhat issue can be addressed by conducting a statistical analysis of the measurements?\n23. Source of the Data Considering the source of the data (on the bottom of the preceding \npage), does that source appear to be biased in some way?\n24. Conclusion If we analyze the sample data (on the bottom of the preceding page) and \nconclude that there is a correlation between white and red blood cell counts, does it follow that \nhigher white are the cause of higher red blood cell counts?\nWhat’s Wrong? In Exercises 25–28, identify what is wrong.\n25. Potatoes In a poll sponsored by the Idaho Potato Commission, 1000 adults were asked to \nselect their favorite vegetables, and the favorite choice was potatoes, which were selected by \n26% of the respondents.\n26. Healthy Water In a USA Today online poll, 951 Internet users chose to respond, and 57% \nof them said that they prefer drinking bottled water instead of tap water.\n27. Cheese and Bedsheet Deaths In recent years, there has been a strong correlation be-\ntween per capita consumption of cheese in the United States and the numbers of people who \ndied from being tangled in their bedsheets. Really. Therefore, consumption of cheese causes \nbedsheet entanglement fatalities.\n28. Smokers The electronic cigarette maker V2 Cigs sponsored a poll showing that 55% of \nsmokers surveyed say that they feel ostracized “sometimes,” “often,” or “always.”\nPercentages. In Exercises 29 and 30, answer the given questions, which are related to \npercentages.\n29. Health It was noted in Exercise 12 “Health” that in a survey of 3014 randomly selected \nU.S. adults, 45% reported that they have at least one chronic health condition, such as diabetes \nor high blood pressure.\na. What is 45% of 3014 adults?\nb. Could the result from part (a) be the actual number of survey subjects who have at least one \nchronic condition?\nc. What is the actual number of survey subjects who have at least one chronic condition?\nd. Among those surveyed, 1808 were called by landline and 1206 were called by cell phone. \nWhat percentage of the survey subjects were called by cell phone?\n30. Chillax USA Today reported results from a Research Now for Keurig survey in which \n1458 men and 1543 women were asked this: “In a typical week, how often can you kick back \nand relax?”\na. Among the women, 19% responded with “rarely, if ever.” What is the exact value that is 19% \nof the number of women surveyed?\nb. Could the result from part (a) be the actual number of women who responded with “rarely, if \never”? Why or why not?\nc. What is the actual number of women who responded with “rarely, if ever”?\nd. Among the men who responded, 219 responded with “rarely, if ever.” What is the percentage \nof men who responded with “rarely, if ever”?\ne. Consider the question that the subjects were asked. Is that question clear and unambiguous so \nthat all respondents will interpret the question the same way? How might the survey be improved?\n",
    "1-2 Types of Data \n13\nIf we have more than one statistic, we have “statistics.” Another meaning of “statis-\ntics” was given in Section 1-1, where we defined statistics to be the science of plan-\nning studies and experiments; obtaining data; organizing, summarizing, presenting, \nanalyzing, and interpreting those data; and then drawing conclusions based on them. \nWe now have two different definitions of statistics, but we can determine which of \nthese two definitions applies by considering the context in which the term statistics is \nused, as in the following example.\n31. What’s Wrong with This Picture? The Newport Chronicle ran a survey by asking read-\ners to call in their response to this question: “Do you support a ban on electronic cigarettes, \nwhich foster smoking among our children?” It was reported that 20 readers responded and that \n87% said “no,” while 13% said “yes.” Identify four major flaws in this survey.\n32. Falsifying Data A researcher at the Sloan-Kettering Cancer Research Center was once \ncriticized for falsifying data. Among his data were figures obtained from 6 groups of mice, \nwith 20 individual mice in each group. The following values were given for the percentage of \nsuccesses in each group: 53%, 58%, 63%, 46%, 48%, 67%. What’s wrong with those values?\n1-1 Beyond the Basics\nDEFINITIONS\nA parameter is a numerical measurement describing some characteristic of a \npopulation.\nA statistic is a numerical measurement describing some characteristic of a sample.\nHINT The alliteration in “population parameter” and “sample statistic” helps us \nremember the meanings of these terms.\nEXAMPLE 1  Parameter, Statistic\nThere are 17,246,372 high school students in the United States. In a study of 8505 \nU.S. high school students 16 years of age or older, 44.5% of them said that they \ntexted while driving at least once during the previous 30 days (based on data in \nKey Concept A major use of statistics is to collect and use sample data to make con-\nclusions about populations. We should know and understand the meanings of the terms \nstatistic and parameter, as defined below. In this section we describe a few different \ntypes of data. The type of data is one of the key factors that determine the statistical \nmethods we use in our analysis.\nIn Part 1 of this section we describe the basics of different types of data, and then \nin Part 2 we consider “big data” and missing data.\nPART 1\n Basic Types of Data\nParameter, Statistic\n \n1-2 \nTypes of Data\ncontinued\n",
    "14 \nCHAPTER 1 Introduction to Statistics\nQuantitative, Categorical\nSome data are numbers representing counts or measurements (such as a systolic blood \npressure of 118 mm Hg), whereas others are attributes (such as eye color of green or \nbrown) that are not counts or measurements. The terms quantitative data and cat-\negorical data distinguish between these types.\n“Texting While Driving and Other Risky Motor Vehicle Behaviors Among U.S. \nHigh School Students,” by Olsen, Shults, Eaton, Pediatrics, Vol. 131, No. 6).\n \n1. Parameter: The population size of all 17,246,372 high school students is a \nparameter, because it is the size of the entire population of all high school \nstudents in the United States. If we somehow knew the percentage of all \n17,246,372 high school students who reported they had texted while driving, \nthat percentage would also be a parameter.\n \n2. Statistic: The value of 44.5% is a statistic, because it is based on the sample, \nnot on the entire population.\nDEFINITIONS\nQuantitative (or numerical) data consist of numbers representing counts or mea-\nsurements.\nCategorical (or qualitative or attribute) data consist of names or labels (not num-\nbers that represent counts or measurements).\nCAUTION Categorical data are sometimes coded with numbers, with those num-\nbers replacing names. Although such numbers might appear to be quantitative, \nthey are actually categorical data. See the third part of Example 2.\nInclude Units of Measurement With quantitative data, it is important to use the \nappropriate units of measurement, such as dollars, hours, feet, or meters. We should \ncarefully observe information given about the units of measurement, such as “all \namounts are in thousands of dollars,” or “all units are in kilograms.” Ignoring such \nunits of measurement can be very costly. The National Aeronautics and Space Admin-\nistration (NASA) lost its $125 million Mars Climate Orbiter when the orbiter crashed \nbecause the controlling software had acceleration data in English units, but they were \nincorrectly assumed to be in metric units.\nEXAMPLE 2  Quantitative, Categorical\n \n1. Quantitative Data: The ages (in years) of subjects enrolled in a clinical trial\n \n2. Categorical Data as Labels: The genders (male>female) of subjects enrolled \nin a clinical trial\n \n3. Categorical Data as Numbers: The identiﬁcation numbers 1, 2, 3, . . . , 25 \nare assigned randomly to the 25 subjects in a clinical trial. Those numbers \nare substitutes for names. They don’t measure or count anything, so they are \ncategorical data, not quantitative data.\n",
    "1-2 Types of Data \n15\nDiscrete, Continuous\nQuantitative data can be further described by distinguishing between discrete and con-\ntinuous types.\nDEFINITIONS\nDiscrete data result when the data values are quantitative and the number of \nvalues is finite or “countable.” (If there are infinitely many values, the collection of \nvalues is countable if it is possible to count them individually, such as the number \nof tosses of a coin before getting tails or the number of births in Houston before \ngetting a male.)\nContinuous (numerical) data result from infinitely many possible quantitative \nvalues, where the collection of values is not countable. (That is, it is impossible \nto count the individual items because at least some of them are on a continuous \nscale, such as the lengths of distances from 0 cm to 12 cm.)\nCAUTION The concept of countable data plays a key role in the preceding defini-\ntions, but it is not a particularly easy concept to understand. Continuous data can \nbe measured, but not counted. If you select a particular data value from continuous \ndata, there is no “next” data value. See Example 3.\n \n Continuous Data\n \n Discrete Data\nEXAMPLE 3  Discrete, Continuous\n \n1. Discrete Data of the Finite Type: Each of several physicians plans to count \nthe number of physical examinations given during the next full week. The \ndata are discrete data because they are ﬁnite numbers, such as 27 and 46 that \nresult from a counting process.\n \n2. Discrete Data of the Inﬁnite Type: Researchers plan to test the accuracy of a \nblood typing test by repeating the process of submitting a sample of the same \nblood (Type O+) until the test yields an error. It is possible that each research-\ner could repeat this test forever without ever getting an error, but they can \nstill count the number of tests as they proceed. The collection of the numbers \nof tests is countable, because you can count them, even though the counting \ncould go on forever.\n \n3. Continuous Data: When the typical patient has blood drawn as part of a \nroutine examination, the volume of blood drawn is between 0 mL and 50 mL. \nThere are inﬁnitely many values between 0 mL and 50 mL. Because it is im-\npossible to count the number of diﬀerent possible values on such a continuous \nscale, these amounts are continuous data.\n",
    "16 \nCHAPTER 1 Introduction to Statistics\nLevels of Measurement\nAnother common way of classifying data is to use four levels of measurement: nomi-\nnal, ordinal, interval, and ratio, all defined below. (Also see Table 1-2 for brief de-\nscriptions of the four levels of measurements.) When we are applying statistics to \nreal problems, the level of measurement of the data helps us decide which procedure \nto use. There will be references to these levels of measurement in this book, but the \nimportant point here is based on common sense: Don’t do computations and don’t use \nstatistical methods that are not appropriate for the data. For example, it would not \nmake sense to compute an average (mean) of Social Security numbers, because those \nnumbers are data used for identification, and they don’t represent measurements or \ncounts of anything.\nGRAMMAR: FEWER VERSUS LESS When describing smaller amounts, it is \ncorrect grammar to use “fewer” for discrete amounts and “less” for continuous \namounts. It is correct to say that we drank fewer cans of cola and that, in the pro-\ncess, we drank less cola. The numbers of cans of cola are discrete data, whereas \nthe volume amounts of cola are continuous data.\nDEFINITION\nThe nominal level of measurement is characterized by data that consist of \nnames, labels, or categories only. It is not possible to arrange the data in some \norder (such as low to high).\nEXAMPLE 4  Nominal Level\nHere are examples of sample data at the nominal level of measurement.\n1. Yes, No, Undecided: Survey responses of yes, no, and undecided\n \n2. Coded Survey Responses: For an item on a survey, respondents are given a \nchoice of possible answers, and they are coded as follows: “I agree” is coded \nas 1; “I disagree” is coded as 2; “I don’t care” is coded as 3; “I refuse to \nanswer” is coded as 4; “Go away and stop bothering me” is coded as 5. The \nnumbers 1, 2, 3, 4, 5 don’t measure or count anything.\nBecause nominal data lack any ordering or numerical significance, they should \nnot be used for calculations. Numbers such as 1, 2, 3, and 4 are sometimes assigned \nto the different categories (especially when data are coded for computers), but these \nnumbers have no real computational significance and any average (mean) calculated \nfrom them is meaningless and possibly misleading.\nDEFINITION\nData are at the ordinal level of measurement if they can be arranged in some \norder, but differences (obtained by subtraction) between data values either cannot \nbe determined or are meaningless.\n",
    "1-2 Types of Data \n17\nOrdinal data provide information about relative comparisons, but not the magni-\ntudes of the differences. Usually, ordinal data should not be used for calculations such \nas an average (mean), but this guideline is sometimes disregarded (such as when we \nuse letter grades to calculate a grade-point average).\nEXAMPLE 5  Ordinal Level\nHere is an example of sample data at the ordinal level of measurement.\nCourse Grades: A biostatistics professor assigns grades of A, B, C, D, or F. These \ngrades can be arranged in order, but we can’t determine differences between the \ngrades. For example, we know that A is higher than B (so there is an ordering), but \nwe cannot subtract B from A (so the difference cannot be found).\nDEFINITION\nData are at the interval level of measurement if they can be arranged in order, and \ndifferences between data values can be found and are meaningful; but data at this \nlevel do not have a natural zero starting point at which none of the quantity is present.\nEXAMPLE 6  Interval Level\nThese examples illustrate the interval level of measurement.\n \n1. Temperatures: Body temperatures of 98.2°F and 98.8°F are examples of data \nat this interval level of measurement. Those values are ordered, and we can \ndetermine their diﬀerence of 0.6°F. However, there is no natural starting point. \nThe value of 0°F might seem like a starting point, but it is arbitrary and does \nnot represent the total absence of heat.\n \n2. Years: The years 1492 and 1776 can be arranged in order, and the diﬀerence \nof 284 years can be found and is meaningful. However, time did not begin in \nthe year 0, so the year 0 is arbitrary instead of being a natural zero starting \npoint representing “no time.”\nDEFINITION\nData are at the ratio level of measurement if they can be arranged in order, differ-\nences can be found and are meaningful, and there is a natural zero starting point \n(where zero indicates that none of the quantity is present). For data at this level, dif-\nferences and ratios are both meaningful.\nEXAMPLE 7  Ratio Level\nThe following are examples of data at the ratio level of measurement. Note the pres-\nence of the natural zero value, and also note the use of meaningful ratios of “twice” \nand “three times.”\n \n1. Heights of Students: Heights of 180 cm and 90 cm for a high school student and a \npreschool student (0 cm represents no height, and 180 cm is twice as tall as 90 cm.)\n \n2. Class Times: The times of 50 min and 100 min for a statistics class (0 min \nrepresents no class time, and 100 min is twice as long as 50 min.)\n",
    "18 \nCHAPTER 1 Introduction to Statistics\nSee Table 1-2 for brief descriptions of the four levels of measurements.\nTABLE 1-2 Levels of Measurement\nLevel of \nMeasurement\n \nBrief Description\n \nExample\nRatio\nThere is a natural zero starting point and \nratios make sense.\nHeights, lengths, distances, \nvolumes\nInterval\nDifferences are meaningful, but there is \nno natural zero starting point and ratios \nare meaningless.\nBody temperatures in degrees \nFahrenheit or Celsius\nOrdinal\nData can be arranged in order, but dif-\nferences either can’t be found or are \nmeaningless.\nRanks of colleges in U.S. News & \nWorld Report\nNominal\nCategories only. Data cannot be arranged \nin order.\nEye colors\nHINT The distinction between the interval and ratio levels of measurement can \nbe a bit tricky. Here are two tools for help with that distinction:\n \n1.  Ratio Test Focus on the term “ratio” and know that the term “twice” describes the \nratio of one value to be double the other value. To distinguish between the interval \nand ratio levels of measurement, use a “ratio test” by asking this question: Does \nuse of the term “twice” make sense? “Twice” makes sense for data at the ratio level \nof measurement, but it does not make sense for data at the interval level of mea-\nsurement.\n \n2.  True Zero For ratios to make sense, there must be a value of “true zero,” where \nthe value of zero indicates that none of the quantity is present, and zero is not \nsimply an arbitrary value on a scale. The temperature of 0°F is arbitrary and \ndoes not indicate that there is no heat, so temperatures on the Fahrenheit scale \nare at the interval level of measurement, not the ratio level.\nEXAMPLE 8   Distinguishing Between the Ratio Level and  \nInterval Level\nFor each of the following, determine whether the data are at the ratio level of mea-\nsurement or the interval level of measurement:\n \na. Times (minutes) it takes to complete a statistics test.\n \nb. Body temperatures (Celsius) of statistics students.\nSOLUTION\n \na. Apply the “ratio test” described in the preceding hint. If one student completes \nthe test in 40 minutes and another student completes the test in 20 min, does it \nmake sense to say that the ﬁrst student used twice as much time? Yes! So the \ntimes are at the ratio level of measurement. Also, a time of 0 minutes does repre-\nsent “no time,” so the value of 0 is a true zero indicating that no time was used.\n \nb. Apply the “ratio test” described in the preceding hint. If one student has a \nbody temperature of 40°C and another student has a body temperature of \n20°C, does it make sense to say that the ﬁrst student is twice as hot as the \nT\nSurvey Pitfalls\nSurveys con-\nstitute a huge \nand growing \nbusiness in the \nUnited States, \nbut survey \nresults can be \ncompromised by many factors. \nA growing number of people \nrefuse to respond; the average \nresponse rate is now about 22%, \ncompared to 36% around the \nyear 2000. A growing number of \npeople are more difficult to reach \nbecause they use cell phones \n(no directories); about 15% of \nadults now have cell phones and \nno landlines, and they tend to \nbe younger than average. There \nare obvious problems associated \nwith surveys that ask respon-\ndents about drug use, theft, or \nsexual behavior, and a social \ndesirability bias occurs when sur-\nvey respondents are not honest \nbecause they don’t want to be \nviewed negatively by the person \nconducting the interview.\n",
    "1-2 Types of Data \n19\nPART 2\n  Big Data and Missing Data:  \nToo Much and Not Enough\nWhen working with data, we might encounter some data sets that are excessively \nlarge, and we might also encounter some data sets with individual elements missing. \nHere in Part 2 we briefly discuss both cases.\nBig Data\nEdward Snowden used his employment at the NSA (National Security Agency) to re-\nveal substantial top secret documents that led to the realization that the NSA was con-\nducting telephone and Internet surveillance of U.S. citizens as well as world leaders. \nThe NSA was collecting massive amounts of data that were analyzed in an attempt to \nprevent terrorism. Monitoring telephone calls and Internet communications is made \npossible with modern technology. The NSA can compile big data, and such ginormous \ndata sets have led to the birth of data science. There is not universal agreement on the \nfollowing definitions, and various other definitions can be easily found elsewhere.\n second student? (Ignore subjective amounts of attractiveness and consider \nonly science.) No! So the body temperatures are not at the ratio level of \nmeasurement. Because the diﬀerence between 40°C and 20°C is the same as \nthe diﬀerence between 90°C and 70°C, the diﬀerences are meaningful, but be-\ncause ratios do not make sense, the body temperatures are at the interval level \nof measurement. Also, the temperature of 0°C does not represent “no heat” so \nthe value of 0 is not a true zero indicating that no heat is present.\nDEFINITIONS\nBig data refers to data sets so large and so complex that their analysis is beyond \nthe capabilities of traditional software tools. Analysis of big data may require soft-\nware simultaneously running in parallel on many different computers.\nData science involves applications of statistics, computer science, and software en-\ngineering, along with some other relevant fields (such as biology and epidemiology).\nExamples of Data Set Magnitudes We can see from the above definition of big \ndata that there isn’t a fixed number that serves as an exact boundary for determining \nwhether a data set qualifies as being big data, but big data typically involves amounts \nof data such as the following.\n \n■Terabytes (1012 or 1,000,000,000,000 bytes) of data\n \n■Petabytes (1015 bytes) of data\n \n■Exabytes (1018 bytes) of data\n \n■Zettabytes (1021 bytes) of data\n \n■Yottabytes (1024 bytes) of data\nExamples of Applications of Big Data The following are a few examples involv-\ning big data:\n \n■Attempt to forecast flu epidemics by analyzing Internet searches of flu symptoms.\n \n■The Spatio Temporal Epidemiological Modeler developed by IBM is providing a \nmeans for using a variety of data that are correlated with disease data.\ne-\nl \no\nBig Data Instead  \nof a Clinical Trial\nNicholas \nTatonetti of \nColumbia \nUniversity \nsearched Food \nand Drug \nAdministration \ndatabases for \nadverse reactions in patients that \nresulted from different pairings \nof drugs. He discovered that \nthe paroxetine drug for depres-\nsion and the pravastatin drug \nfor high cholesterol interacted \nto create increases in glucose \n(blood sugar) levels. When taken \nseparately by patients, neither \ndrug raised glucose levels, but \nthe increase in glucose levels \noccurred when the two drugs \nwere taken together. This finding \nresulted from a general database \nsearch of interactions from many \npairings of drugs, not from a \nclinical trial involving patients \nusing Paxil and pravastatin.\ncontinued\n",
    "20 \nCHAPTER 1 Introduction to Statistics\n \n■A National Electronic Disease Surveillance System is used to monitor disease \ntrends and identify outbreaks of infectious disease.\n \n■Google provides live traffic maps by recording and analyzing GPS (global posi-\ntioning system) data collected from the smartphones of people traveling in their \nvehicles.\n \n■Amazon monitors and tracks 1.4 billion items in its store that are distributed \nacross hundreds of fulfillment centers around the world.\nExamples of Jobs According to Analytic Talent, there are 6000 companies hiring \ndata scientists, and here are some job posting examples:\n \n■Facebook: Data Scientist\n \n■IBM: Data Scientist\n \n■PayPal: Data Scientist\n \n■The College Board: SAS Programmer>Data Scientist\n \n■Netflix: Senior Data Engineer>Scientist\nStatistics in Data Science The modern data scientist has a solid background in \nstatistics and computer systems as well as expertise in fields that extend beyond sta-\ntistics. The modern data scientist might be skilled with Hadoop software, which uses \nparallel processing on many computers for the analysis of big data. The modern data \nscientist might also have a strong background in some other field, such as psychology, \nbiology, medicine, chemistry, or economics. Because of the wide range of disciplines \nrequired, a data science project might typically involve a team of collaborating indi-\nviduals with expertise in different fields. An introductory statistics course is a great \nfirst step in becoming a data scientist.\nMissing Data\nWhen collecting sample data, it is quite common to find that some values are miss-\ning. Ignoring missing data can sometimes create misleading results. If you make the \nmistake of skipping over a few different sample values when you are manually typ-\ning them into a statistics software program, the missing values are not likely to have \na serious effect on the results. However, if a survey includes many missing salary en-\ntries because those with very low incomes are reluctant to reveal their salaries, those \nmissing low values will have the serious effect of making salaries appear higher than \nthey really are.\nFor an example of missing data, see the following table. The body temperature for \nSubject 2 at 12 AM on day 2 is missing. (The table below includes the first three rows \nof data from Data Set 2 “Body Temperatures” in Appendix B.)\n Body Temperatures (in degrees Fahrenheit) of Healthy Adults\nTemperature  \nDay 1\nTemperature  \nDay 2\nSubject\nAge\nSex\nSmoke\n8 AM\n12 AM\n8 AM\n12 AM\n1\n22\nM\nY\n98.0\n98.0\n98.0\n98.6\n2\n23\nM\nY\n97.0\n97.6\n97.4\n----\n3\n22\nM\nY\n98.6\n98.8\n97.8\n98.6\n",
    "1-2 Types of Data \n21\nThere are different categories of missing data. See the following definitions.\nDEFINITION\nA data value is missing completely at random if the likelihood of its being miss-\ning is independent of its value or any of the other values in the data set. That is, any \ndata value is just as likely to be missing as any other data value.\n(Note: More complete discussions of missing data will distinguish between missing \ncompletely at random and missing at random, which means that the likelihood of a \nvalue being missing is independent of its value after controlling for another variable. \nThere is no need to know this distinction in this book.)\nExample of Missing Data—Random When using a keyboard to manually enter \nages of survey respondents, the operator is distracted by a colleague singing “Day-\ndream Believer” and makes the mistake of failing to enter the age of 37 years. This \ndata value is missing completely at random.\nDEFINITION\nA data value is missing not at random if the missing value is related to the reason \nthat it is missing.\nExample of Missing Data—Not at Random A survey question asks each respon-\ndent to enter his or her annual income, but respondents with very low incomes skip \nthis question because they find it embarrassing.\nBiased Results? Based on the above two definitions and examples, it makes sense \nto conclude that if we ignore data missing completely at random, the remaining values \nare not likely to be biased and good results should be obtained. However, if we ignore \ndata that are missing not at random, it is very possible that the remaining values are \nbiased and results will be misleading.\nCorrecting for Missing Data There are different methods for dealing with missing \ndata.\n1. Delete Cases: One very common method for dealing with missing data is to \ndelete all subjects having any missing values.\n \n■If the data are missing completely at random, the remaining values are not \nlikely to be biased and good results can be obtained, but with a smaller sam-\nple size.\n \n■If the data are missing not at random, deleting subjects having any missing \nvalues can easily result in a bias among the remaining values, so results can \nbe misleading.\n2. Impute Missing Values: We impute missing data values when we substitute \nvalues for them. There are different methods of determining the replacement \nvalues, such as using the mean of the other values, or using a randomly selected \nvalue from other similar cases, or using a method based on regression analysis \n(which will make more sense after studying Chapter 10).\nMeasuring  \nDisobedience\nHow are data \ncollected about \nsomething that \ndoesn’t seem \nto be measur-\nable, such as \npeople’s level of \ndisobedience? \nPsychologist Stanley Milgram \ndevised the following experi-\nment: A researcher instructed a \nvolunteer subject to operate a \ncontrol board that gave increas-\ningly painful “electrical shocks” \nto a third person. Actually, no real \nshocks were given, and the third \nperson was an actor. The volun-\nteer began with 15 volts and was \ninstructed to increase the shocks \nby increments of 15 volts. The \ndisobedience level was the point \nat which the subject refused to \nincrease the voltage. Surpris-\ningly, two-thirds of the subjects \nobeyed orders even when the \nactor screamed and faked a \nheart attack.\n",
    "22 \nCHAPTER 1 Introduction to Statistics\nIn this book we do not work much with missing data, but it is important to under-\nstand this:\nWhen analyzing sample data with missing values, try to determine why \nthey are missing, and then decide whether it makes sense to treat the \nremaining values as being representative of the population. If it appears \nthat there are missing values that are missing not at random (that is, \ntheir values are related to the reasons why they are missing), know that \nthe remaining data may well be biased and any conclusions based on \nthose remaining values may well be misleading.\nStatistical Literacy and Critical Thinking\n1. Health Survey In a survey of 1020 adults in the United States, 44% said that they wash \ntheir hands after riding public transportation (based on data from KRC Research).\na. Identify the sample and the population.\nb. Is the value of 44% a statistic or a parameter?\n2. Health Survey For the same survey from Exercise 1, answer the following.\na. What is the level of measurement of the value of 44%? (nominal, ordinal, interval, ratio)\nb. Are the numbers of subjects in such surveys discrete or continuous?\nc. The responses are “yes,” “no,” “not sure,” or “refused to answer.” Are these responses quan-\ntitative data or categorical data?\n3. Quantitative, Categorical Data Identify each of the following as quantitative data or cat-\negorical data.\na. The platelet counts of exam subjects in Data Set 1 “Body Data” in Appendix B\nb. The names of the pharmaceutical companies that manufacture aspirin tablets\nc. The colors of pills\nd. The weights of aspirin tablets\n4. Discrete, Continuous Data Which of the following describe discrete data?\na. The numbers of people surveyed in each of the next several National Health and Nutrition \n Examination Surveys\nb. The exact foot lengths (cm) of a random sample of statistics students\nc. The exact times that randomly selected drivers spend texting while driving during the past 7 days\nIn Exercises 5–12, identify whether the given value is a statistic or a parameter.\n5. Brain Volume The average (mean) volume of the brains included in Data Set 9 “IQ and \nBrain Size” in Appendix B is 1126.0 cm3.\n6. CHIS A recent California Health Interview Survey (CHIS) included 2799 adolescent resi-\ndents of California.\n7. Cigarettes A data set in Appendix B includes measurements from 25 king-size cigarettes, \nand the average (mean) amount of nicotine in those 25 cigarettes is 1.26 mg.\n8. Triangle Fire Fatalities A deadly disaster in the United States was the Triangle Shirtwaist \nFactory Fire in New York City. A population of 146 garment workers died in that fire.\n1-2 Basic Skills and Concepts\n",
    "1-2 Types of Data \n23\n9. Birth Weight In a study of 400 babies born at four different hospitals in New York State, it \nwas found that the average (mean) weight at birth was 3152.0 grams.\n10. Birth Genders In the same study cited in the preceding exercise, 51% of the babies were girls.\n11. Titanic A study was conducted of all 2223 passengers aboard the Titanic when it sank.\n12. Periodic Table The average (mean) atomic weight of all elements in the periodic table is \n134.355 unified atomic mass units.\nIn Exercises 13–20, determine whether the data are from a discrete or continuous  \ndata set.\n13. Freshman 15 In a study of weight gains by college students in their freshman year, re-\nsearchers record the amounts of weight gained by randomly selected students (as in Data Set \n10 “Freshman 15” in Appendix B).\n14. Births Data Set 3 “Births” in Appendix B includes the length of stay (in days) for each \nbaby in a sample of babies born in New York State. The first few values are 2, 2, 36, 5, and 2.\n15. CHIS Among the subjects surveyed as part of the California Health Interview Survey \n(CHIS), several subjects are randomly selected and their heights are recorded.\n16. Arm Circumference From Data Set 1 “Body Data” in Appendix B we see that a female \nhad an arm circumference of 32.49 cm.\n17. Families A sample of married couples is randomly selected and the number of children in \neach family is recorded.\n18. Criminal Forensics When studying the relationship between lengths of feet and heights \nso that footprint evidence at a crime scene can be used to estimate the height of the suspect, a \nresearcher records the exact lengths of feet from a large sample of random subjects.\n19. Stitch In Time The Emergency Room of the Albany Medical Center records the numbers \nof stitches used for patients in a week.\n20. Texting Fatalities The Insurance Institute for Highway Safety collects data consisting of \nthe numbers of motor vehicle fatalities caused by driving while texting.\nIn Exercises 21–28, determine which of the four levels of measurement (nominal, ordinal, \ninterval, ratio) is most appropriate.\n21. Brain Volumes Volumes (cm3) of brains listed in Data Set 9 “IQ and Brain Size” in \n Appendix B\n22. Blood Lead Level Blood lead levels of low, medium, and high used to describe the sub-\njects in Data Set 8 “IQ and Lead” in Appendix B\n23. Body Temperatures Body temperatures (in degrees Fahrenheit) listed in Data Set 2 \n“Body Temperatures” in Appendix B.\n24. Privacy Codes Instead of using actual names, subjects included in the National Health \nand Nutrition Examination Survey are coded with consecutive numbers.\n25. Hospitals A research project on the effectiveness of heart transplants begins with a compi-\nlation of the U.S. hospitals that provide heart transplants.\n26. Hospital Charges A research project on the effectiveness of heart transplants begins \nwith a compilation of the charges (dollars) for heart transplant procedures that were conducted \nwithin the past year.\n27. Physician Ranks A research project on the effectiveness of heart transplants includes \nrankings (scale of 1, 2, 3, 4, 5) of physicians who perform those procedures.\n28. Pharmaceuticals Pfizer records the years in which new products were launched, \n beginning with 1849.\n",
    "24 \nCHAPTER 1 Introduction to Statistics\nIn Exercises 29–32, identify the level of measurement of the data as nominal, ordinal, inter-\nval, or ratio. Also, explain what is wrong with the given calculation.\n29. Hospital ID The four hospitals included in Data Set 3 “Births” in Appendix B are coded as \nfollows: Albany Medical Center (1); Bellevue Hospital Center (1438); Olean General Hospital \n(66); Strong Memorial Hospital (413). The average (mean) of those numbers is 479.5.\n30. Social Security Numbers As part of a clinical study, the Social Security number of each \nsubject is recorded and the average (mean) of the individual digits is computed to be 4.7.\n31. Temperatures A person has a body temperature of 98.0°F during the time when the out-\nside air temperature is 49.0°F, so the person is twice as warm as the outside air.\n32. Medical School Ranks As of this writing, U.S. News & World Report ranked medical \nschools, including these results: Harvard (1), Stanford (2), Johns Hopkins (3), University of \nCalifornia at San Francisco (4), and University of Pennsylvania (5). The difference between \nHarvard and Stanford is the same as the difference between Johns Hopkins and University of \nCalifornia at San Francisco.\n33. Countable For each of the following, categorize the nature of the data using one of these \nthree descriptions: (1) discrete because the number of possible values is finite; (2) discrete \nbecause the number of possible values is infinite but countable; (3) continuous because the \nnumber of possible values is infinite and not countable.\na. Exact lengths of the feet of members of the band the Monkees\nb. Shoe sizes of members of the band the Monkees (such as 9, 9½, and so on)\nc. The number of albums sold by the Monkees band\nd. The numbers of monkeys sitting at keyboards before one of them randomly types the lyrics \nfor the song “Daydream Believer”\n1-2 Beyond the Basics\nKey Concept When using statistics in a study, planning is very important, and it is \nessential to use an appropriate method for collecting the sample data. This section \nincludes comments about various methods and sampling procedures. Of particular im-\nportance is the method of using a simple random sample. We will make frequent use \nof this sampling method throughout the remainder of this book.\nAs you read this section, remember this:\nIf sample data are not collected in an appropriate way, the data may be \nso utterly useless that no amount of statistical torturing can salvage them.\nPART 1\n  Basics of Design of Experiments and \nCollecting Sample Data\nThe Gold Standard Randomization with placebo>treatment groups is sometimes \ncalled the “gold standard” because it is so effective. (A placebo such as a sugar pill \nhas no medicinal effect.) The following example describes how the gold standard was \nused in the largest health experiment ever conducted.\n \n1-3 \nCollecting Sample Data\n",
    "1-3 Collecting Sample Data \n25\nExample 1 describes an experiment because subjects were given a treatment, but ethi-\ncal, cost, time, and other considerations sometimes prohibit the use of an experiment. \nWe would never want to conduct a driving/texting experiment in which we ask sub-\njects to text while driving—some of them could die. It would be far better to observe \npast crash results to understand the effects of driving while texting. See the following \ndefinitions.\nEXAMPLE 1  The Salk Vaccine Experiment\nIn 1954, an experiment was designed to test the effectiveness of the Salk vaccine in \npreventing polio, which had killed or paralyzed thousands of children. By random \nselection, 401,974 children were randomly assigned to two groups: (1) 200,745 \nchildren were given a treatment consisting of Salk vaccine injections; (2) 201,229 \nchildren were injected with a placebo that contained no drug. Children were as-\nsigned to the treatment or placebo group through a process of random selection, \nequivalent to flipping a coin. Among the children given the Salk vaccine, 33 later \ndeveloped paralytic polio, and among the children given a placebo, 115 later devel-\noped paralytic polio.\nDEFINITIONS\nIn an experiment, we apply some treatment and then proceed to observe its \n effects on the individuals. (The individuals in experiments are called experimental \nunits, and they are often called subjects when they are people.)\nIn an observational study, we observe and measure specific characteristics, but \nwe don’t attempt to modify the individuals being studied.\nExperiments are often better than observational studies because well-planned experi-\nments typically reduce the chance of having the results affected by some variable that \nis not part of a study. A lurking variable is one that affects the variables included in \nthe study, but it is not included in the study.\nEXAMPLE 2  Ice Cream and Drownings\nObservational Study: Observe past data to conclude that ice cream causes drown-\nings (based on data showing that increases in ice cream sales are associated with \nincreases in drownings). The mistake is to miss the lurking variable of temperature \nand the failure to see that as the temperature increases, ice cream sales increase and \ndrownings increase because more people swim.\nExperiment: Conduct an experiment with one group treated with ice cream while \nanother group gets no ice cream. We would see that the rate of drowning victims \nis about the same in both groups, so ice cream consumption has no effect on \ndrownings.\nHere, the experiment is clearly better than the observational study.\nDesign of Experiments\nGood design of experiments includes replication, blinding, and randomization.\n \n■Replication is the repetition of an experiment on more than one individual. Good \nuse of replication requires sample sizes that are large enough so that we can see \nn \nClinical Trials vs. \nObservational Studies\nIn a New York \nTimes article \nabout hormone \ntherapy for \nwomen, reporter \nDenise Grady \nwrote about \nrandomized \nclinical trials that involve subjects \nwho were randomly assigned to \na treatment group and another \ngroup not given the treatment. \nSuch randomized clinical trials \nare often referred to as the “gold \nstandard” for medical research. \nIn contrast, observational studies \ncan involve patients who decide \nthemselves to undergo some \ntreatment. Subjects who decide \nthemselves to undergo treat-\nments are often healthier than \nother subjects, so the treatment \ngroup might appear to be more \nsuccessful simply because it \ninvolves healthier subjects, not \nnecessarily because the treat-\nment is effective. Researchers \ncriticized observational studies of \nhormone therapy for women by \nsaying that results might appear \nto make the treatment more ef-\nfective than it really is.\n",
    "26 \nCHAPTER 1 Introduction to Statistics\neffects of treatments. In the Salk experiment in Example 1, the experiment used \nsufficiently large sample sizes, so the researchers could see that the Salk vaccine \nwas effective.\n \n■Blinding is used when the subject doesn’t know whether he or she is receiving a \ntreatment or a placebo. Blinding is a way to get around the placebo effect, which \noccurs when an untreated subject reports an improvement in symptoms. (The \nreported improvement in the placebo group may be real or imagined.) The Salk \nexperiment in Example 1 was double-blind, which means that blinding occurred \nat two levels: (1) The children being injected didn’t know whether they were \ngetting the Salk vaccine or a placebo, and (2) the doctors who gave the injec-\ntions and evaluated the results did not know either. Codes were used so that the \nresearchers could objectively evaluate the effectiveness of the Salk vaccine.\n \n■Randomization is used when individuals are assigned to different groups \nthrough a process of random selection, as in the Salk vaccine experiment in \nExample 1. The logic behind randomization is to use chance as a way to create \ntwo groups that are similar. The following definition refers to one common and \neffective way to collect sample data in a way that uses randomization.\nDEFINITION\nA simple random sample of n subjects is selected in such a way that every pos-\nsible sample of  the same size n has the same chance of being chosen. (A simple \nrandom sample is often called a random sample, but strictly speaking, a random \nsample has the weaker requirement that all members of the population have the \nsame chance of being selected. That distinction is not so important in this text. \n(See Exercise 38 “Simple Random Sample vs. Random Sample.”)\nThroughout, we will use various statistical procedures, and we often have \na requirement that we have collected a simple random sample, as defined \nabove.\nUnlike careless or haphazard sampling, random sampling usually requires very \ncareful planning and execution.\nOther Sampling Methods In addition to simple random sampling, here are some \nother sampling methods commonly used for surveys. Figure 1-3 illustrates these dif-\nferent sampling methods.\nDEFINITIONS\nIn systematic sampling, we select some starting point and then select every kth \n(such as every 50th) element in the population.\nWith convenience sampling, we simply use data that are very easy to get.\nIn stratified sampling, we subdivide the population into at least two different \nsubgroups (or strata) so that subjects within the same subgroup share the same \ncharacteristics (such as gender). Then we draw a sample from each subgroup (or \nstratum).\nIn cluster sampling, we first divide the population area into sections (or clusters). \nThen we randomly select some of those clusters and choose all the members from \nthose selected clusters.\nHawthorne and \nExperimenter Effects\nThe well-\nknown \nplacebo effect \noccurs when \nan untreated \nsubject incor-\nrectly believes \nthat he or she is receiving a \nreal treatment and reports an \nimprovement in symptoms. The \nHawthorne effect occurs when \ntreated subjects somehow re-\nspond differently, simply because \nthey are part of an experiment. \n(This phenomenon was called \nthe “Hawthorne effect” because \nit was first observed in a study \nof factory workers at Western \nElectric’s Hawthorne plant.) An \nexperimenter effect (sometimes \ncalled a Rosenthal effect) occurs \nwhen the researcher or experi-\nmenter unintentionally influences \nsubjects through such factors as \nfacial expression, tone of voice, \nor attitude.\n",
    "1-3 Collecting Sample Data \n27\nMultistage Sampling Professional pollsters and government researchers often  collect \ndata by using some combination of the preceding sampling methods. In a  multistage \nsample design, pollsters select a sample in different stages, and each stage might use \ndifferent methods of sampling, as in the following example.\nMAIN\nCENTER\nHeritage\nSchool\nPark St.\nNorth St.\n1st St.\n2nd St.\n3rd St.\n82nd St.\n52nd St.\n36th St.\n43rd St.\nA St.\nB St.\nC St.\nD St.\nE St.\nF St.\nWay St.\n4th St.\n5th St.\nMLK PKWY\n555-867-5309\n555-606-0842\n555-777-9311\nSimple Random Sample\nA sample of n subjects is selected \nso that every sample of the same \nsize n has the same chance of \nbeing selected.\nStratiﬁed Sample\nSubdivide population into strata \n(groups) with the same \ncharacteristics, then randomly \nsample within those strata.\nCluster Sample\nPartition the population in clusters \n(groups), then randomly select \nsome clusters, then select all \nmembers of the selected clusters.\nSystematic Sample\nSelect every kth subject.\nConvenience Sample\nUse data that are very easy to get.\nMen\nWomen\n3rd\n6th\nFIGURE 1-3 Common Sampling Methods\nEXAMPLE 3  Multistage Sample Design\nThe U.S. government’s unemployment statistics are based on surveys of house-\nholds. It is impractical to personally survey each household in a simple random \nsample, because they would be scattered all over the country. Instead, the U.S. \n Census Bureau and the Bureau of Labor Statistics collaborate to conduct a survey \ncalled the Current Population Survey. A recent survey incorporates a multistage \nsample design, roughly following these steps:\n \n1. The entire United States is partitioned into 2,007 diﬀerent regions called \nprimary sampling units (PSUs). The primary sampling units are metropolitan \nareas, large counties, or combinations of smaller counties. The 2,007 primary \nsampling units are then grouped into 824 diﬀerent strata.\nValue of a  \nStatistical Life\nThe value of a \nstatistical life \n(VSL) is a mea-\nsure routinely \ncalculated and \nused for making \ndecisions in \nfields such as \nmedicine, insurance, environ-\nmental health, and transportation \nsafety. As of this writing, the \nvalue of a statistical life is  \n$6.9 million.\nMany people oppose the con-\ncept of putting a value on a hu-\nman life, but the word statistical \nin the “value of a statistical life” \nis used to ensure that we don’t \nequate it with the true worth \nof a human life. Some people \nlegitimately argue that every life \nis priceless, but others argue that \nthere are conditions in which it \nis impossible or impractical to \nsave every life, so a value must \nbe somehow assigned to a hu-\nman life in order that sound and \nrational decisions can be made. \nNot far from the author’s home, a \nparkway was modified at a cost \nof about $3 million to improve \nsafety at a location where car \noccupants had previously died \nin traffic crashes. In the cost-\nbenefit analysis that led to this \nimprovement in safety, the value \nof a statistical life was surely \nconsidered.\ncontinued\n",
    "28 \nCHAPTER 1 Introduction to Statistics\nPART 2\n  Beyond the Basics of Design of \nExperiments and Collecting Sample Data\nObservational Studies In Part 2 of this section, we discuss different types of ob-\nservational studies and different ways of designing experiments. The following defi-\nnitions identify the standard terminology used in professional journals for different \ntypes of observational studies. These definitions are illustrated in Figure 1-4.\n \n2. In each of the 824 diﬀerent strata, one of the primary sampling units is \nselected so that the probability of selection is proportional to the size of the \npopulation in each primary sampling unit.\n \n3. In each of the 824 selected primary sampling units, census data are used to \nidentify a census enumeration district, with each containing about 300 house-\nholds. Enumeration districts are then randomly selected.\n \n4. In each of the selected enumeration districts, clusters of about four addresses \n(contiguous whenever possible) are randomly selected.\n \n5. A responsible person in each of the 60,000 selected households is interviewed \nabout the employment status of each household member of age 16 or older.\nThis multistage sample design includes a combination of random, stratified, and \ncluster sampling at different stages. The end result is a very complicated sampling \ndesign, but it is much more practical, less expensive, and faster than using a simpler \ndesign, such as a simple random sample.\nWhen\nare the\nobservations\nmade?\nObservational Study:\nObserve and measure,\nbut do not modify.\nOne point in time\nRetrospective\n(or case-control) study:\nGo back in time to \ncollect data over some \npast period.\nCross-sectional \nstudy:\nData are\nmeasured at one \npoint in time.\nProspective\n(or longitudinal or cohort) study:\nGo forward in time and observe\ngroups sharing common factors,\nsuch as smokers and nonsmokers.\nForward in time\nPast period of time\nFIGURE 1-4 Types of Observational Studies\nDEFINITIONS\nIn a cross-sectional study, data are observed, measured, and collected at one \npoint in time, not over a period of time.\nIn a retrospective (or case-control) study, data are collected from a past time pe-\nriod by going back in time (through examination of records, interviews, and so on).\nIn a prospective (or longitudinal or cohort) study, data are collected in the future \nfrom groups that share common factors (such groups are called cohorts).\n",
    "1-3 Collecting Sample Data \n29\nExperiments In a study, confounding occurs when we can see some effect, but \nwe can’t identify the specific factor that caused it, as in the ice cream and drowning \nobservational study in Example 2. See also the bad experimental design illustrated \nin  Figure 1-5(a), where confounding can occur when the treatment group of women \nshows strong positive results. Because the treatment group consists of women and the \nplacebo group consists of men, confounding has occurred because we cannot deter-\nmine whether the treatment or the gender of the subjects caused the positive results. \nThe Salk vaccine experiment in Example 1 illustrates one method for controlling the \neffect of the treatment variable: Use a completely randomized experimental design, \nwhereby randomness is used to assign subjects to the treatment group and the placebo \ngroup. A completely randomized experimental design is one of the following methods \nthat are used to control effects of variables.\nCompletely Randomized Experimental Design: Assign subjects to different treat-\nment groups through a process of random selection, as illustrated in Figure 1-5(b).\nTreatment Group: Women\nBad experimental design:\nTreat all women subjects\nand give the men a placebo.\n(Problem: We don’t know if\neﬀects are due to sex or\nto treatment.)\nCompletely randomized\nexperimental design:\nUse randomness to\ndetermine who gets the\ntreatment and who gets\nthe placebo.\n  \nTreat all women subjects.\nPlacebo Group: Men\n  \nGive all men a placebo\nTreat these  randomly\nselected subjects and give\nthe others a placebo.\n(a)\n(b)\nBefore\nAfter\nAlex\nBob\nChris\nBlock of Women\nRandomized block design:\n1. Form a block of women\n \nand a block of men.\n2. Within each block,\n \nrandomly select subjects\n \nto be treated.\nMatched pairs design:\nGet measurements from the\nsame subjects before and after\nsome treatment.\n  \nTreat randomly selected\nwomen.\nBlock of Men\n  \nTreat randomly selected men.\n(c)\n(d)\nFIGURE 1-5 Designs of Experiments\n",
    "30 \nCHAPTER 1 Introduction to Statistics\nExperimental design requires much more thought and care than we can describe \nin this relatively brief section. Taking a complete course in the design of experiments \nis a good start in learning so much more about this important topic.\nRandomized Block Design: See Figure 1-5c. A block is a group of subjects that are \nsimilar, but blocks differ in ways that might affect the outcome of the experiment. Use \nthe following procedure, as illustrated in Figure 1-5(c):\n1. Form blocks (or groups) of subjects with similar characteristics.\n2. Randomly assign treatments to the subjects within each block.\nFor example, in designing an experiment to test the effectiveness of aspirin treatments \non heart disease, we might form a block of men and a block of women, because it is \nknown that the hearts of men and women can behave differently. By controlling for \ngender, this randomized block design eliminates gender as a possible source of con-\nfounding.\nA randomized block design uses the same basic idea as stratified sampling, but \nrandomized block designs are used when designing experiments, whereas stratified \nsampling is used for surveys.\nMatched Pairs Design: Compare two treatment groups (such as treatment and pla-\ncebo) by using subjects matched in pairs that are somehow related or have similar \ncharacteristics, as in the following cases.\n \n■Before/After: Matched pairs might consist of measurements from subjects before \nand after some treatment, as illustrated in Figure 1-5(d) on the preceding page. \nEach subject yields a “before” measurement and an “after” measurement, and \neach before/after pair of measurements is a matched pair.\n \n■Twins: A test of Crest toothpaste used matched pairs of twins, where one twin \nused Crest and the other used another toothpaste.\nRigorously Controlled Design: Carefully assign subjects to different treatment \ngroups, so that those given each treatment are similar in the ways that are important to \nthe experiment. This can be extremely difficult to implement, and often we can never \nbe sure that we have accounted for all of the relevant factors.\nSampling Errors\nIn statistics, you could use a good sampling method and do everything correctly, and \nyet it is possible to get wrong results. No matter how well you plan and execute the \nsample collection process, there is likely to be some error in the results. The different \ntypes of sampling errors are described here.\nDEFINITIONS\nA sampling error (or random sampling error) occurs when the sample has been \nselected with a random method, but there is a discrepancy between a sample \nresult and the true population result; such an error results from chance sample \nfluctuations.\nA nonsampling error is the result of human error, including such factors as wrong \ndata entries, computing errors, questions with biased wording, false data provided \nby respondents, forming biased conclusions, or applying statistical methods that \nare not appropriate for the circumstances.\nA nonrandom sampling error is the result of using a sampling method that is not \nrandom, such as using a convenience sample or a voluntary response sample.\n",
    "1-3 Collecting Sample Data \n31\nStatistical Literacy and Critical Thinking\n1. Back Pain Treatment In a study designed to test the effectiveness of paracetamol (also \nknown as acetaminophen) as a treatment for lower back pain, 1643 patients were randomly \nassigned to one of three groups: (1) the 547 subjects in the placebo group were given pills \ncontaining no medication; (2) 550 subjects were in a group given pills with paracetamol taken \nat regular intervals; (3) 546 subjects were in a group given pills with paracetamol to be taken \nwhen needed for pain relief. (See “Efficacy of Paracetamol for Acute Low-Back Pain,” by \n Williams et al., Lancet.) Is this study an experiment or an observational study? Explain.\n2. Blinding What does it mean when we say that the study cited in Exercise 1 was “double-blind”?\n3. Replication In what specific way was replication applied in the study cited in Exercise 1?\n4. Sampling Method The patients included in the study cited in Exercise 1 were those “who \nsought care for low-back pain directly or in response to a community advertisement.” What \ntype of sampling best describes the way in which the 1634 subjects were chosen: simple ran-\ndom sample, systematic sample, convenience sample, stratified sample, cluster sample? Does \nthe method of sampling appear to adversely affect the quality of the results?\nExercises 5–8 refer to the study of an association between which ear is used for cell phone \ncalls and whether the subject is left-handed or right-handed. The study is reported in “Hemi-\nspheric Dominance and Cell Phone Use,” by Seidman et al., JAMA Otolaryngology—Head \n& Neck Surgery, Vol. 139, No. 5. The study began with a survey e-mailed to 5000 people \nbelonging to an otology online group, and 717 surveys were returned. (Otology relates to the \near and hearing.)\n5. Sampling Method What type of sampling best describes the way in which the 717 subjects \nwere chosen: simple random sample, systematic sample, convenience sample, stratified sample, \ncluster sample? Does the method of sampling appear to adversely affect the quality of the results?\n6. Experiment or Observational Study Is the study an experiment or an observational \nstudy? Explain.\n7. Response Rate What percent of the 5000 surveys were returned? Does that response rate \nappear to be low? In general, what is a problem with a very low response rate?\n8. Sampling Method Assume that the population consists of all students currently in your \nstatistics class. Describe how to obtain a sample of six students so that the result is a sample of \nthe given type.\na. Simple random sample\nb. Systematic sample\nc. Stratified sample\nd. Cluster sample\nIn Exercises 9–20, identify which of these types of sampling is used: random, systematic, \nconvenience, stratified, or cluster.\n9. Cormorant Density Cormorant bird population densities were studied by using the “line \ntransect method” with aircraft observers flying along the shoreline of Lake Huron and collecting \nsample data at intervals of every 20 km (based on data from Journal of Great Lakes Research).\n1-3 Basic Skills and Concepts\n",
    "32 \nCHAPTER 1 Introduction to Statistics\n10. Sexuality of Women The sexuality of women was discussed in Shere Hite’s book Women \nand Love: A Cultural Revolution. Her conclusions were based on sample data that consisted of \n4500 mailed responses from 100,000 questionnaires that were sent to women.\n11. Acupuncture Study In a study of treatments for back pain, 641 subjects were randomly \nassigned to the four different treatment groups of individualized acupuncture, standardized \nacupuncture, simulated acupuncture, and usual care (based on data from “A Randomized Trial \nComparing Acupuncture, Simulated Acupuncture, and Usual Care for Chronic Low Back \nPain,” by Cherkin et al., Archives of Internal Medicine, Vol. 169, No. 9).\n12. Class Survey A professor surveys her statistics class by identifying groups of males and \nfemales, then randomly selecting five students from each of those two groups.\n13. Class Survey A professor conducts a survey by randomly selecting three different classes \nand surveying all of the students as they left those classes.\n14. Exercise Program In a study designed to test the effectiveness of exercise in lowering \nblood pressure, 532 subjects were randomly assigned to these two different groups: (1) group \ngiven regular exercise programs; (2) group given no exercise programs.\n15. Hospital Survey A researcher collects sample data by randomly selecting 20 hospital \n employees from each of the categories of physician, nurse, and administrator.\n16. Deforestation Rates Satellites are used to collect sample data for estimating deforesta-\ntion rates. The Forest Resources Assessment of the United Nations (UN) Food and Agriculture \nOrganization uses a method of selecting a sample of a 10-km-wide square at every 1° intersec-\ntion of latitude and longitude.\n17. Testing Lipitor In a clinical trial of the cholesterol drug Lipitor (atorvastatin), subjects \nwere partitioned into groups given a placebo or Lipitor doses of 10 mg, 20 mg, 40 mg, or \n80 mg. The subjects were randomly assigned to the different treatment groups (based on data \nfrom Pfizer, Inc.).\n18. Blood Drives A researcher for the American Red Cross randomly selected five different \nblood donor sites and then interviewed all blood donors as they left the sites.\n19. Smoking Prevalence A medical student collects sample data on the prevalence of smok-\ning among adults by surveying all of the patients she encounters in the clinic where she is doing \nher residency.\n20. Health Survey The Texas Health and Human Services Commission obtains an alphabeti-\ncal listing of all 20,126,759 adults and constructs a sample by selecting every 10,000th name \non that list.\nCritical Thinking: What’s Wrong? In Exercises 21–28, determine whether the study is \nan experiment or an observational study, and then identify a major problem with the study.\n21. Online Medical Information In a survey conducted by USA Today, 1072 Internet users \nchose to respond to this question posted on the USA Today electronic edition: “How often do \nyou seek medical information online?” 38% of the respondents said “frequently.”\n22. Physicians’ Health Study The Physicians’ Health Study involved 22,071 male physi-\ncians. Based on random selections, 11,037 of them were treated with aspirin and the other \n11,034 were given placebos. The study was stopped early because it became clear that aspirin \nreduced the risk of myocardial infarctions by a substantial amount.\n23. Drinking and Driving A researcher for a consortium of insurance companies plans to \ntest for the effects of drinking on driving ability by randomly selecting 1000 drivers and then \nrandomly assigning them to two groups: One group of 500 will drive in New York City after no \nalcohol consumption, and the second group will drive in New York City after consuming three \nshots of Jim Beam bourbon whiskey.\n",
    "1-3 Collecting Sample Data \n33\n24. Blood Pressure A medical researcher tested for a difference in systolic blood pressure \nlevels between male and female students who are 20 years of age. She randomly selected four \nmales and four females for her study.\n25. Salt Deprivation In a program designed to investigate the effects of salt deprivation in \ndiets, the original plan was to use a sample of 500 adults randomly selected throughout the \ncountry. The program managers know that they would get a biased sample if they limit their \nstudy to adults in New York City, so they planned to compensate for that bias by using a larger \nsample of 2000 adults in New York City.\n26. Atkins Weight Loss Program An independent researcher tested the effectiveness of the \nAtkins weight loss program by randomly selecting 1000 subjects using that program. Each of \nthe subjects was called to report his or her weight before the diet and after the diet.\n27. Crime Research A researcher has created a brief survey to be given to 2000 adults ran-\ndomly selected from the U.S. population. Here are her first two questions: (1) Have you ever \nbeen the victim of a felony crime? (2) Have you ever been convicted of a felony?\n28. Medications The Pharmaceutical Research and Manufacturers of America wants infor-\nmation about the consumption of various medications. An independent researcher conducts a \nsurvey by mailing 10,000 questionnaires to randomly selected adults in the United States, and \nshe receives 152 responses.\nIn Exercises 29–32, indicate whether the observational study used is cross-sectional, \n retrospective, or prospective.\n29. Nurses’ Health Study II Phase II of the Nurses’ Health Study was started in 1989 with \n116,000 female registered nurses. The study is ongoing.\n30. Heart Health Study Samples of subjects with and without heart disease were selected, \nthen researchers looked back in time to determine whether they took aspirin on a regular basis.\n31. Marijuana Study Researchers from the National Institutes of Health want to determine the \ncurrent rates of marijuana consumption among adults living in states that have legalized the use \nof marijuana. They conduct a survey of 500 adults in those states.\n32. Framingham Heart Study The Framingham Heart Study was started in 1948 and is ongo-\ning. Its focus is on heart disease.\nIn Exercises 33–36, identify which of these designs is most appropriate for the given \nexperiment: completely randomized design, randomized block design, or matched pairs \ndesign.\n33. Lunesta Lunesta (eszopiclone) is a drug designed to treat insomnia. In a clinical trial of \nLunesta, amounts of sleep each night are measured before and after subjects have been treated \nwith the drug.\n34. Lipitor A clinical trial of Lipitor treatments is being planned to determine whether its \neffects on diastolic blood pressure are different for men and women.\n35. West Nile Vaccine Currently, there is no approved vaccine for the prevention of West Nile \nvirus infection. A clinical trial of a possible vaccine is being planned to include subjects treated \nwith the vaccine while other subjects are given a placebo.\n36. HIV Vaccine The HIV Trials Network is conducting a study to test the effectiveness of two \ndifferent experimental HIV vaccines. Subjects will consist of 80 pairs of twins. For each pair \nof twins, one of the subjects will be treated with the DNA vaccine and the other twin will be \ntreated with the adenoviral vector vaccine.\n1-3 Beyond the Basics\n",
    "34 \nCHAPTER 1 Introduction to Statistics\n37. Sample Design Literacy In “Cardiovascular Effects of Intravenous Triiodothyronine in \nPatients Undergoing Coronary Artery Bypass Graft Surgery” (Journal of the American Medi-\ncal Association, Vol. 275, No. 9), the authors explain that patients were assigned to one of \nthree groups: (1) a group treated with triiodothyronine, (2) a group treated with normal saline \nbolus and dopamine, and (3) a placebo group given normal saline. The authors summarize the \nsample design as a “prospective, randomized, double-blind, placebo-controlled trial.” Describe \nthe meaning of each of those terms in the context of this study.\n38. Simple Random Sample vs. Random Sample Refer to the definition of simple random \nsample in this section and the accompanying definition of random sample enclosed within pa-\nrentheses. Determine whether each of the following is a simple random sample and a random \nsample.\na. A statistics class with 36 students is arranged so that there are 6 rows with 6 students in each \nrow, and the rows are numbered from 1 through 6. A die is rolled and a sample consists of all \nstudents in the row corresponding to the outcome of the die.\nb. For the same class described in part (a), the 36 student names are written on 36 individual \nindex cards. The cards are shuffled and six names are drawn from the top.\nc. For the same class described in part (a), the six youngest students are selected.\n1. Clinical Study When conducting a clinical study, it is common to maintain the privacy of \nsubjects by assigning them number codes that will be used instead of their actual names. Sev-\neral subjects are assigned these codes: 1, 2, 3, 5, 6, 9, 11, 13, 16, 20, 22, 26, 32, and 40. Does it \nmake sense to calculate the average (mean) of these numbers?\n2. Clinical Study Which of the following best describes the level of measurement of the data \nlisted in Exercise 1: nominal, ordinal, interval, ratio?\n3. Waist Data Set 1 “Body Data” includes measurements of waist circumferences. Are waist \ncircumferences values that are discrete or continuous?\n4. Waist Are the waist circumferences described in Exercise 3 quantitative data or categorical \ndata?\n5. Waist Which of the following best describes the level of measurement of the waist \n circumferences described in Exercise 3: nominal, ordinal, interval, ratio?\n6. Waist If you construct a sample by selecting every sixth waist circumference from those \nlisted in Data Set 1 “Body Data,” is the result a simple random sample of the listed waist \n circumferences?\n7. Gallup Poll In a recent Gallup poll, pollsters randomly selected adults and asked them \nwhether they smoke. Because the subjects agreed to respond, is the sample a voluntary re-\nsponse sample?\n8. Parameter and Statistic In a recent Gallup poll, pollsters randomly selected adults and \nasked them whether they smoke. Among the adults who responded to the survey question, 21% \nsaid that they did smoke. Is that value of 21% an example of a statistic or a parameter?\n9. Observational Study or Experiment Are the data described in Exercise 8 the result of an \nobservational study or an experiment?\n10. Statistical Significance and Practical Significance True or false: If data lead to a con-\nclusion with statistical significance, then the results also have practical significance.\nChapter Quick Quiz\n",
    "1. Hospitals Currently, there are 5723 registered hospitals in the United States.\na. Are the numbers of hospitals in different states discrete or continuous?\nb. What is the level of measurement for the numbers of hospitals in different years? (nominal, \nordinal, interval, ratio)\nc. If a survey is conducted by randomly selecting 10 patients in every hospital, what type of \nsampling is used? (random, systematic, convenience, stratified, cluster)\nd. If a survey is conducted by randomly selecting 20 hospitals and interviewing all of the mem-\nbers of each board of directors, what type of sampling is used? (random, systematic, conve-\nnience, stratified, cluster)\ne. What is wrong with surveying patient satisfaction by mailing questionnaires to 10,000 ran-\ndomly selected patients?\n2. What’s Wrong? A survey sponsored by the American Laser Centers included responses \nfrom 575 adults, and 24% of the respondents said that the face is their favorite body part (based \non data from USA Today). What is wrong with this survey?\n3. What’s Wrong? A survey included 2028 responses from Internet users who decided to \nrespond to a question posted by AOL. Here is the question: “How often do you drink soda?” \nAmong the respondents, 33% said that they drink soda almost every day. What is wrong with \nthis survey?\n4. Sampling Seventy-two percent of Americans squeeze their toothpaste tube from the top. \nThis and other not-so-serious findings are included in The First Really Important Survey of \nAmerican Habits. Those results are based on 7000 responses from the 25,000 questionnaires \nthat were mailed.\na. What is wrong with this survey?\nb. As stated, the value of 72% refers to all Americans, so is that 72% a statistic or a parameter? \nExplain.\nc. Does the survey constitute an observational study or an experiment?\n5. Percentages\na. The labels on U-Turn protein energy bars include the statement that these bars contain \n“125% less fat than the leading chocolate candy brands” (based on data from Consumer \nReports magazine). What is wrong with that claim?\nb. In a Pew Research Center poll on driving, 58% of the 1182 respondents said that they like to \ndrive. What is the actual number of respondents who said that they like to drive?\nc. In a Pew Research Center poll on driving, 331 of the 1182 respondents said that driving is a \nchore. What percentage of respondents said that driving is a chore?\n6. Simple Random Sample Which of the following is>are simple random samples?\na. As Lipitor pills are being manufactured, a quality control plan is to select every 500th pill \nand test it to confirm that it contains 80 mg of atorvastatin.\nb. To test for a gender difference in the way that men and women make online purchases, \n Gallup surveys 500 randomly selected men and 500 randomly selected women.\nc. A list of all 10,877 adults in Trinity County, California, is obtained; the list is numbered from \n1 to 10,877; and then a computer is used to randomly generate 250 different numbers between \n1 and 10,877. The sample consists of the adults corresponding to the selected numbers.\nReview Exercises\nCHAPTER 1 Review Exercises \n35\n",
    "36 \nCHAPTER 1 Introduction to Statistics\n7. Statistical Significance and Practical Significance The Gengene Research Group has \ndeveloped a procedure designed to increase the likelihood that a baby will be born a girl. In a \nclinical trial of their procedure, 112 girls were born to 200 different couples. If the method has \nno effect, there is about a 4% chance that such extreme results would occur. Does the procedure \nappear to have statistical significance? Does the procedure appear to have practical signifi-\ncance?\n8. Marijuana Survey In a recent Pew poll of 1500 adults, 52% of the respondents said that the \nuse of marijuana should not be made legal. In the same poll, 23% of the respondents said that \nthe use of marijuana for medical purposes should not be legal.\na. The sample of 1500 adults was selected from the population of all adults in the United \nStates. The method used to select the sample was equivalent to placing the names of all adults \nin a giant bowl, mixing the names, and then drawing 1500 names. What type of sampling is \nthis? (random, systematic, convenience, stratified, cluster)\nb. If the sampling method consisted of a random selection of 30 adults from each of the 50 states, \nwhat type of sampling would this be? (random, systematic, convenience, stratified, cluster)\nc. What is the level of measurement of the responses of yes, no, don’t know, and refused to \nrespond?\nd. Is the given value of 52% a statistic or a parameter? Why?\ne. What would be wrong with conducting the survey by mailing a questionnaire that respon-\ndents could complete and mail back?\n9. Marijuana Survey Identify the type of sampling (random, systematic, convenience, strati-\nfied, cluster) used when a sample of the 1500 survey responses is obtained as described. Then \ndetermine whether the sampling scheme is likely to result in a sample that is representative of \nthe population of all adults.\na. A complete list of all 241,472,385 adults in the United States is compiled, and every \n150,000th name is selected until the sample size of 1500 is reached.\nb. A complete list of all 241,472,385 adults in the United States is compiled, and 1500 adults \nare randomly selected from that list.\nc. The United States is partitioned into regions with 100 adults in each region. Then 15 of those \nregions are randomly selected, and all 100 people in each of those regions are surveyed.\nd. The United States is partitioned into 150 regions with approximately the same number of \nadults in each region; then 10 people are randomly selected from each of the 150 regions.\ne. A survey is mailed to 10,000 randomly selected adults, and the 1500 responses are used.\n10. Marijuana Survey Exercise 8 referred to a Pew poll of 1500 adults, and 52% of the \n respondents said that the use of marijuana should not be made legal.\na. Among the 1500 adults who responded, what is the number of respondents who said that the \nuse of marijuana should not be made legal?\nb. In the same poll of 1500 adults, 345 of the respondents said that the use of marijuana for \nmedical purposes should not be legal. What is the percentage of respondents who said that the \nuse of marijuana for medical purposes should not be legal?\nc. In this survey of 1500 adults, 727 are men and 773 are women. Find the percentage of \n respondents who are men, and then find the percentage of respondents who are women.\nd. Does the difference between the two percentages from part (c) appear to have statistical \nsignificance?\ne. Does the difference between the two percentages from part (c) appear to have practical \n significance?\n",
    "For Chapter 2 through Chapter 14, the Cumulative Review Exercises include topics from \npreceding chapters. For this chapter, we present a few calculator warm-up exercises, with \nexpressions similar to those found throughout this book. Use your calculator to find the \nindicated values.\n1. Birth Weights Listed below are the weights (grams) of newborn babies from Albany Medi-\ncal Center Hospital. What value is obtained when those weights are added and the total is di-\nvided by the number of weights? (This result, called the mean, is discussed in Chapter 3.) What \nis notable about these values, and what does it tell us about how the weights were measured?\n3600 1700 4000 3900 3100 3800\n2200 3000\n2. Six Children Jule Cole is a founder of Mabel’s Labels, and she is the mother of six chil-\ndren. The probability that six randomly selected children are all girls is found by evaluating \n0.56. Find that value.\n3. Tallest Person Robert Wadlow (1918–1940) is the tallest known person to have lived. The \nexpression below converts his height of 272 cm to a standardized score. Find this value and \nround the result to two decimal places. Such standardized scores are considered to be signifi-\ncantly high if they are greater than 2 or 3. Is the result significantly high?\n272 - 176\n6\n4. Body Temperature The given expression is used for determining the likelihood that the av-\nerage (mean) human body temperature is different from the value of 98.6°F that is commonly \nused. Find the given value and round the result to two decimal places.\n98.2 - 98.6\n0.62\n2106\n5. Determining Sample Size The given expression is used to determine the size of the sam-\nple necessary to estimate the proportion of college students who have the profound wisdom to \ntake a statistics course. Find the value and round the result to the nearest whole number.\n1.962 # 0.25\n0.032\n6. Standard Deviation One way to get a very rough approximation of the value of a standard \ndeviation of sample data is to find the range, then divide it by 4. The range is the difference be-\ntween the highest sample value and the lowest sample value. In using this approach, what value \nis obtained from the sample data listed in Exercise 1 “Birth Weights”?\n7. Standard Deviation The standard deviation is an extremely important concept introduced \nin Chapter 3. Using the sample data from Exercise 1 “Birth Weights,” part of the calculation of \nthe standard deviation is shown in the expression below. Evaluate this expression. (Fortunately, \ncalculators and software are designed to automatically execute such expressions, so our future \nwork with standard deviations will not be burdened with cumbersome calculations.)\n13600 - 3162.52 2\n7\n8. Standard Deviation The given expression is used to compute the standard deviation of \nthree randomly selected body temperatures. Perform the calculation and round the result to two \ndecimal places.\nB\n198.4 - 98.62 2 + 198.6 - 98.62 2 + 198.8 - 98.62 2\n3 - 1\nCumulative Review Exercises\nCHAPTER 1 Cumulative Review Exercises \n37\n",
    "38 \nCHAPTER 1 Introduction to Statistics\nScientific Notation. In Exercises 9–12, the given expressions are designed to yield re-\nsults expressed in a form of scientific notation. For example, the calculator-displayed re-\nsult of 1.23E5 can be expressed as 123,000, and the result of 1.23E-4 can be expressed as \n0.000123. Perform the indicated operation and express the result as an ordinary number \nthat is not in scientific notation.\n9. 0.48  10. 911  11. 614  12. 0.312\nTechnology Project\nMissing Data The focus of this project is to download a data set and manipulate it to work \naround missing data.\na. First, download Data Set 2 “Body Temperatures” in Appendix B from www.TriolaStats.com. \nChoose the download format that matches your technology. (If you have no preferred technol-\nogy, you can download a free copy of Statdisk (from www.statdisk.org), which is designed for \nthis book and contains all Appendix B data sets.)\nb. Some statistical procedures, such as those involved with correlation and regression (dis-\ncussed in later chapters) require data that consist of matched pairs of values, and those proce-\ndures ignore pairs in which at least one of the data values in a matched pair is missing. Assume \nthat we want to conduct analyses for correlation and regression on the last two columns of \ndata in Data Set 2: body temperatures measured at 8 AM on day 2 and again at 12 AM on day \n2. For those last two columns, identify the rows with at least one missing value. Note that in \nsome technologies, such as TI-83>84 Plus calculators, missing data must be represented by a \nconstant such as -9 or 999.\nc. Here are two different strategies for reconfiguring the data set to work around the missing \ndata in the last two columns (assuming that we need matched pairs of data with no missing \nvalues):\ni. Manual Deletion Highlight rows with at least one missing value in the last two columns, \nthen delete those rows. This can be tedious if there are many rows with missing data and those \nrows are interspersed throughout instead of being adjacent rows.\nii. Sort Most technologies have a Sort feature that allows you to rearrange all rows using one \nparticular column as the basis for sorting (TI-83>84 Plus calculators do not have this type of sort \nfeature). The result is that all rows remain the same but they are in a different order. First use \nthe technology’s Sort feature to rearrange all rows using the “8 AM day 2” column as the basis \nfor sorting (so that all missing values in the “8 AM day 2” column are at the beginning); then \nhighlight and delete all of those rows with missing values in the “8 AM day 2” column. Next, \nuse the technology’s Sort feature to rearrange all rows using the “12 AM day 2” column as the \nbasis for sorting (so that all missing values in the “12 AM day 2” column are at the beginning); \nthen highlight and delete all of those rows with missing values in the “12 AM day 2” column. \nThe remaining rows will include matched pairs of body temperatures, and those rows will be \nsuitable for analyses such as correlation and regression. Print the resulting reconfigured data set.\n",
    "Cooperative Group Activities\n1. In-class activity Working in groups of three or four, design an experiment to determine \nwhether pulse rates of college students are the same while the students are standing and sitting. \nConduct the experiment and collect the data. Save the data so that they can be analyzed with \nmethods presented in the following chapters.\n2. In-class activity Working in groups of three or four, construct a brief survey that includes \nonly a few questions that can be quickly asked. Include some objective questions along with \nsome that are biased, such as the first question below.\n•  Should your college force all students to pay a $100 activity fee?\n•  Should your college fund activities by collecting a $100 fee?\n Conduct the survey and try to detect the effect that the biased wording has on the  responses.\n3. In-class activity Identify problems with a mailing from Consumer Reports magazine that \nincluded an annual questionnaire about cars and other consumer products. Also included were \na request for a voluntary contribution of money and a voting ballot for the board of directors. \nResponses were to be mailed back in envelopes that required postage stamps.\n4. Out-of-class activity Find a report of a survey that used a voluntary response sample. De-\nscribe how it is quite possible that the results do not accurately reflect the population.\n5. Out-of-class activity Find a professional journal with an article that includes a statistical \nanalysis of an experiment. Describe and comment on the design of the experiment. Identify \none particular issue addressed by the study, and determine whether the results were found to \nbe statistically significant. Determine whether those same results have practical significance.\nFROM DATA TO DECISION\nCritical Thinking:  \nDo Male Symphony Conductors Really Live Longer?\nSeveral media reports made the interesting observation that \nmale symphony conductors live longer than other males. \nJohn Amaral wrote in Awaken that orchestra conductors \n“live longer than almost any other group of people by three \nto seven years.” Robert Levine wrote in Polyphonic.org that \nthey live longer “because they stand up while working.” \nSome provided other explanations for this phenomenon, \noften referring to cardiovascular activity. But do male sym-\nphony conductors really live longer than other groups of \nmales? The Internet can be researched for possible answers. \nLet’s also consider the following.\nAnalysis\n1. Consider the statement that “male symphony conductors \nlive longer.” Identify the specific group that they supposedly \nlive longer than. Does that other group consist of males ran-\ndomly selected from the general population?\n2. It is reasonable to assume that males do not become sym-\nphony conductors until they have reached at least the age \nof 40 years. When comparing life spans of male conduc-\ntors, should we compare them to other males in the general \n population, or should we compare them to other males who \nlived until at least 40 years of age? Explain.\n3. Without any disabilities, males qualify for Medicare if \nthey are 65 or older and meet a few other requirements. If \nwe compare life spans of males on Medicare to life spans \nof males randomly selected from the general population, \nwhy would we find that males on Medicare have longer life \nspans?\n4. Explain in detail how to design a study for collecting data \nto determine whether it is misleading to state that male sym-\nphony conductors live longer. Should the study be an experi-\nment or an observational study?\nCHAPTER 1 Cooperative Group Activities \n39\n",
    "40\nFrequency Distributions \nfor Organizing and \nSummarizing Data\nHistograms\nGraphs That Enlighten \nand Graphs That \nDeceive\nScatterplots, \nCorrelation, and \nRegression\n2-1\n2-2\n2-3\n2-4\nDoes Exposure to Lead Affect IQ Scores?\nCHAPTER \nPROBLEM\nExploring Data with \nTables and Graphs\nData Set 8 “IQ and Lead” in Appendix B includes full IQ scores \nfrom three groups of children who lived near a lead smelter. \nThe children in Group 1 had low levels of measured lead in \ntheir blood (with blood levels less than 40 micrograms>100 mL \nin each of two years). Group 2 had medium levels of measured \nlead in their blood (with blood levels of at least  \n40 micrograms/100 mL in exactly one of two years). Group 3 \nhad high levels of measured lead in their blood (with blood lev-\nels of at least 40 micrograms>100 mL in each of two years).\nLet’s consider the measured full IQ scores from Group 1  \n(low lead level) and Group 3 (high lead level), as listed in \nTable 2-1. It is an exceptionally rare person who can look \nat both lists of IQ scores and form meaningful conclusions. \nAlmost all of us must work at describing, exploring, and \n2\n",
    "comparing the two sets of data. In this chapter we pres-\nent methods that focus on summarizing the data and using \ngraphs that enable us to understand important characteris-\ntics of the data, especially the distribution of the data. These \nmethods will help us compare the two sets of data so that we \ncan determine whether the IQ scores of the low lead group \nare somehow different from the IQ scores of the high lead \ngroup. Such comparisons will be helpful as we try to address \nthis important and key issue: Does exposure to lead have an \neffect on IQ score?\nThis chapter and the following chapter focus on important characteristics of data, \nincluding the following:\nCharacteristics of Data\n1. Center: A representative value that shows us where the middle of the data set is \nlocated.\n2. Variation: A measure of the amount that the data values vary.\n3. Distribution: The nature or shape of the spread of the data over the range of values \n(such as bell-shaped).\n4. Outliers: Sample values that lie very far away from the vast majority of the other \nsample values. (Later, a more objective definition of “outlier” will be given.)\n5. Time: Any change in the characteristics of the data over time.\nThis chapter provides tools that enable us to gain insight into data by organizing, sum-\nmarizing, and representing them in ways that enable us to see important characteristics \nof the data. Here are the chapter objectives:\nFrequency Distributions for Organizing and Summarizing Data\n• Develop an ability to summarize data in the format of a frequency distribution and a \nrelative frequency distribution.\n• For a frequency distribution, identify values of class width, class midpoint, class lim-\nits, and class boundaries.\n2-1\nChapter Objectives \n41\nCHAPTER OBJECTIVES\n>>>\nTABLE 2-1 Full IQ Scores of the Low Lead Group and the High Lead Group\nLow Lead Level (Group 1)\n70\n85\n86\n76\n84\n96\n94\n56\n115\n97\n77\n128\n99\n80\n118\n86\n141\n88\n96\n96\n107\n86\n80\n107\n101\n91\n125\n96\n99\n99\n115\n106\n105\n96\n50\n99\n85\n88\n120\n93\n87\n98\n78\n100\n105\n87\n94\n89\n80\n111\n104\n85\n94\n75\n73\n76\n107\n88\n89\n96\n72\n97\n76\n107\n104\n85\n76\n95\n86\n89\n76\n96\n101\n108\n102\n77\n74\n92\nHigh Lead Level (Group 3)\n82\n93\n85\n75\n85\n80\n101\n89\n80\n94\n88\n104\n88\n88\n83\n104\n96\n76\n80\n79\n75\n",
    "42 \nCHAPTER 2 Exploring Data with Tables and Graphs\nHistograms\n• Develop the ability to picture the distribution of data in the format of a histogram or \nrelative frequency histogram.\n• Examine a histogram and identify common distributions, including a uniform distribu-\ntion and a normal distribution.\nGraphs That Enlighten and Graphs That Deceive\n• Develop an ability to graph data using a dotplot, stemplot, time-series graph, Pareto \nchart, pie chart, and frequency polygon.\n• Determine when a graph is deceptive through the use of a nonzero axis or a \n pictograph that uses an object of area or volume for one-dimensional data.\nScatterplots, Correlation, and Regression\n• Develop an ability to construct a scatterplot of paired data.\n• Analyze a scatterplot to determine whether there appears to be a correlation \n between two variables.\n2-2\n2-3\n2-4\nHistograms\n• Develop the ability to picture the distribution of data in the format of a histogram or \nrelative frequency histogram.\n• Examine a histogram and identify common distributions, including a uniform distribu-\ntion and a normal distribution.\nGraphs That Enlighten and Graphs That Deceive\n• Develop an ability to graph data using a dotplot, stemplot, time-series graph, Pareto\nchart, pie chart, and frequency polygon.\n• Determine when a graph is deceptive through the use of a nonzero axis or a\npictograph that uses an object of area or volume for one-dimensional data.\nScatterplots, Correlation, and Regression\n• Develop an ability to construct a scatterplot of paired data.\n• Analyze a scatterplot to determine whether there appears to be a correlation \nbetween two variables.\nKey Concept When working with large data sets, a frequency distribution (or frequency \ntable) is often helpful in organizing and summarizing data. A frequency distribution \nhelps us to understand the nature of the distribution of a data set.\n \n2-1\n \n Frequency Distributions for Organizing  \nand Summarizing Data\nDEFINITION\nA frequency distribution (or frequency table) shows how data are partitioned \namong several categories (or classes) by listing the categories along with the num-\nber (frequency) of data values in each of them.\nConsider the IQ scores of the low lead group listed in Table 2-1. Table 2-2 is a fre-\nquency distribution summarizing those IQ scores. The frequency for a particular class \nis the number of original values that fall into that class. For example, the first class in \nTable 2-2 has a frequency of 2, so 2 of the IQ scores are between 50 and 69 inclusive.\nThe following standard terms are often used in constructing frequency distributions \nand graphs.\nTABLE 2-2 IQ Scores of the \nLow Lead Group\nIQ Score\nFrequency\n50–69\n 2\n70–89\n33\n 90–109\n35\n110–129\n 7\n130–149\n 1\nDEFINITIONS\nLower class limits are the smallest numbers that can belong to each of the differ-\nent classes. (Table 2-2 has lower class limits of 50, 70, 90, 110, and 130.)\nUpper class limits are the largest numbers that can belong to each of the different \nclasses. (Table 2-2 has upper class limits of 69, 89, 109, 129, and 149.)\nClass boundaries are the numbers used to separate the classes, but without the \ngaps created by class limits. In Figure 2-1 we see that the values of 69.5, 89.5, \n109.5, and 129.5 are in the centers of those gaps, and following the pattern of \nthose class boundaries, we see that the lowest class boundary is 49.5 and the \n",
    "2-1 Frequency Distributions for Organizing and Summarizing Data  \n43\nProcedure for Constructing a Frequency Distribution\nWe construct frequency distributions to (1) summarize large data sets, (2) see the dis-\ntribution and identify outliers, and (3) have a basis for constructing graphs (such as \nhistograms, introduced in Section 2-2). Technology can generate frequency distribu-\ntions, but here are the steps for manually constructing them:\n1. Select the number of classes, usually between 5 and 20. The number of classes \nmight be affected by the convenience of using round numbers.\n2. Calculate the class width.\nClass width ≈1maximum data value2 - 1minimum data value2\nnumber of classes\nRound this result to get a convenient number. (It’s usually best to round up.) \nUsing a specific number of classes is not too important, and it’s usually wise to \nchange the number of classes so that they use convenient values for the class \nlimits.\n3. Choose the value for the first lower class limit by using either the minimum \nvalue or a convenient value below the minimum.\nhighest class boundary is 149.5. Thus the complete list of class boundaries is 49.5, \n69.5, 89.5, 109.5, 129.5, and 149.5.\nClass midpoints are the values in the middle of the classes. Table 2-2 has class \nmidpoints of 59.5, 79.5, 99.5, 119.5, and 139.5. Each class midpoint is computed \nby adding the lower class limit to the upper class limit and dividing the sum by 2.\nClass width is the difference between two consecutive lower class limits (or two \nconsecutive lower class boundaries) in a frequency distribution. Table 2-2 uses a \nclass width of 20. (The first two lower class boundaries are 50 and 70, and their dif-\nference is 20.)\nCAUTION Finding the correct class width can be tricky. For class width, don’t \nmake the most common mistake of using the difference between a lower class limit \nand an upper class limit. See Table 2-2 and note that the class width is 20, not 19.\n69.5\n49.5\n50\n69\n149.5\nSTEP 1:\nList the class limits\nfrom Table 2-2.\nSTEP 2:\nSplit the diﬀerence\nas shown.\nSTEP 3:\nFind the ﬁrst and\nlast values of 49.5\nand 149.5 by\nprojecting the\nsame pattern.\n70\n89\n89.5\n90\n109\n109.5\n110\n129\n129.5\n130\n149\nFIGURE 2-1 Finding Class Boundaries from Class Limits in Table 2-2\nGrowth Charts Updated\nPediatricians \ntypically use \nstandardized \ngrowth charts to \ncompare their \npatient’s weight \nand height \nto a sample of other children. \nChildren are considered to be in \nthe normal range if their weight \nand height fall between the 5th \nand 95th percentiles. If they fall \noutside that range, they are often \ngiven tests to ensure that there \nare no serious medical problems. \nPediatricians became increas-\ningly aware of a major problem \nwith the charts: Because they \nwere based on children living be-\ntween 1929 and 1975, the growth \ncharts had become inaccurate. \nTo rectify this problem, the charts \nwere updated in 2000 to reflect \nthe current measurements of \nmillions of children. The weights \nand heights of children are good \nexamples of populations that \nchange over time. This is the \nreason for including changing \ncharacteristics of data over time \nas an important consideration for \na population.\nh\nhild\nCAUTION For class boundaries, remember that they split the difference between \nthe end of one class and the beginning of the next class, as shown in Figure 2-1.\ncontinued\n",
    "44 \nCHAPTER 2 Exploring Data with Tables and Graphs\n4. Using the first lower class limit and the class width, list the other lower class \nlimits. (Do this by adding the class width to the first lower class limit to get the \nsecond lower class limit. Add the class width to the second lower class limit to \nget the third lower class limit, and so on.)\n5. List the lower class limits in a vertical column and then determine and enter the \nupper class limits.\n6. Take each individual data value and put a tally mark in the appropriate \nclass. Add the tally marks to find the total frequency for each class.\nWhen constructing a frequency distribution, be sure the classes do not overlap. \nEach of the original values must belong to exactly one class. Include all classes, even \nthose with a frequency of zero. Try to use the same width for all classes, although it is \nsometimes impossible to avoid open-ended intervals, such as “65 years or older.”\nEXAMPLE 1  IQ Scores of Low Lead Group\nUsing the IQ scores of the low lead group in Table 2-1, follow the above procedure \nto construct the frequency distribution shown in Table 2-2. Use five classes.\nSOLUTION\nStep 1: Select 5 as the number of desired classes.\nStep 2: Calculate the class width as shown below. Note that we round 18.2 up to 20, \nwhich is a much more convenient number.\n Class width ≈1maximum data value2 - 1minimum data value2\nnumber of classes\n = 141 - 50\n5\n= 18.2 ≈20 1rounded up to a convenient number2\nStep 3: The minimum data value is 50 and it is a convenient starting point, so use \n50 as the first lower class limit. (If the minimum value had been 52 or 53, we would \nhave rounded down to the more convenient starting point of 50.)\nStep 4: Add the class width of 20 to 50 to get the second lower class limit of 70. \nContinue to add the class width of 20 until we have five lower class limits. The \nlower class limits are therefore 50, 70, 90, 110, and 130.\nStep 5: List the lower class limits vertically, as shown in the margin. From this list, \nwe identify the corresponding upper class limits as 69, 89, 109, 129, and 149.\nStep 6: Enter a tally mark for each data value in the appropriate class. Then add the \ntally marks to find the frequencies shown in Table 2-2.\n 50–\n 70–\n 90–\n110–\n130–\nCategorical Data So far we have discussed frequency distributions using only quan-\ntitative data sets, but frequency distributions can also be used to summarize categori-\ncal (or qualitative or attribute) data, as illustrated in Example 2.\nEXAMPLE 2   Emergency Room Visits for Injuries from Sports \nand Recreation \nTable 2-3 lists data for the highest seven sources of injuries resulting in a visit to \na hospital emergency room (ER) in a recent year (based on data from the Centers \nfor Disease Control and Prevention). The activity names are categorical data at \n",
    "2-1 Frequency Distributions for Organizing and Summarizing Data  \n45\nRelative Frequency Distribution\nA variation of the basic frequency distribution is a relative frequency distribution or \npercentage frequency distribution, in which each class frequency is replaced by a \nrelative frequency (or proportion) or a percentage. In this text we use the term “rela-\ntive frequency distribution” whether we use relative frequencies or percentages. Rela-\ntive frequencies and percentages are calculated as follows.\n Relative frequency for a class = frequency for a class\nsum of all frequencies\n Percentage for a class = frequency for a class\nsum of all frequencies * 100%\nTable 2-4 is an example of a relative frequency distribution. It is a variation of \nTable 2-2 in which each class frequency is replaced by the corresponding percent-\nage value. Because there are 78 data values, divide each class frequency by 78, and \nthen multiply by 100%. The first class of Table 2-2 has a frequency of 2, so divide \n2 by 78 to get 0.0256, and then multiply by 100% to get 2.56%, which we rounded \nto 2.6%. The sum of the percentages should be 100%, with a small discrepancy al-\nlowed for rounding errors, so a sum such as 99% or 101% is acceptable. The sum \nof the percentages in Table 2-4 is 100.1%.\nThe sum of the percentages in a relative frequency distribution must be \nvery close to 100%.\nCumulative Frequency Distribution\nAnother variation of a frequency distribution is a cumulative frequency distribu-\ntion in which the frequency for each class is the sum of the frequencies for that class \nand all previous classes. Table 2-5 is a cumulative frequency distribution based on \nTable 2-2. Using the original frequencies of 2, 33, 35, 7, and 1, we add 2 + 33 to get \nthe second cumulative frequency of 35; then we add 2 + 33 + 35 to get the third; \nand so on. See Table 2-5, and note that in addition to the use of cumulative frequen-\ncies, the class limits are replaced by “less than” expressions that describe the new \nranges of values.\nTABLE 2-3 Annual ER Visits for Injuries from Sports and Recreation\nActivity\nFrequency\nBicycling\n26,212\nFootball\n25,376\nPlayground\n16,706\nBasketball\n13,987\nSoccer\n10,436\nBaseball\n 9,634\nAll-terrain vehicle\n 6,337\nthe nominal level of measurement, but we can create the frequency distribution as \nshown. It might be surprising to see that bicycling is at the top of this list, but this \ndoesn’t mean that bicycling is the most dangerous of these activities; many more \npeople bicycle than play football or ride an all-terrain vehicle or do any of the other \nlisted activities.\nTABLE 2-4 Relative  \nFrequency Distribution of IQ \nScores of Low Lead Group\nIQ Score\nFrequency\n50–69\n2.6%\n70–89\n42.3%\n 90–109\n44.9%\n110–129\n 9.0%\n130–149\n 1.3%\nTABLE 2-5 Cumulative  \nFrequency Distribution of IQ \nScores of Low Lead Group\n \nIQ Score\nCumulative \nFrequency\nLess than 70\n 2\nLess than 90\n35\nLess than 110\n70\nLess than 130\n77\nLess than 150\n78\n",
    "46 \nCHAPTER 2 Exploring Data with Tables and Graphs\nCritical Thinking: Using Frequency Distributions  \nto Understand Data\nAt the beginning of this section we noted that a frequency distribution can help us un-\nderstand the distribution of a data set, which is the nature or shape of the spread of the \ndata over the range of values (such as bell-shaped). In statistics we are often interested \nin determining whether the data have a normal distribution. (Normal distributions are \ndiscussed extensively in Chapter 6.) Data that have an approximately normal distribu-\ntion are characterized by a frequency distribution with the following features:\nNormal Distribution\n1. The frequencies start low, then increase to one or two high frequencies, and \nthen decrease to a low frequency.\n2. The distribution is approximately symmetric: Frequencies preceding the \nmaximum frequency should be roughly a mirror image of those that follow \nthe maximum frequency.\nTable 2-6 satisfies these two conditions. The frequencies start low, increase to the max-\nimum of 56, and then decrease to a low frequency. Also, the frequencies of 1 and 10 \nthat precede the maximum are a mirror image of the frequencies 10 and 1 that follow \nthe maximum. Real data sets are usually not so perfect as Table 2-6, and judgment \nmust be used to determine whether the distribution comes “close enough” to satisfying \nthe above two conditions. (There are more objective procedures included later.)\nTABLE 2-6 Frequency Distribution Showing a Normal Distribution\nScore\nFrequency\nNormal Distribution\n50–69\n 1\nd Frequencies start low, . . .\n70–89\n10\n 90–109\n56\nd  Increase to a maximum, . . .\n110–129\n10\n130–149\n 1\nd  Decrease to become low again.\nAnalysis of Last Digits Example 3 illustrates this principle:\nFrequencies of last digits sometimes reveal how the data were collected \nor measured.\nEXAMPLE 3   Exploring Data: How Were the Weights Obtained in \nCalifornia? \nWhen collecting weights of people, it’s better to actually weigh people than to \nask them what they weigh. People often tend to round way down, so that a weight \nof 196 lb might be reported as 170 lb. Table 2-7 summarizes the last digits of the \nweights of 100 people used in the California Health Interview Survey. If people are \nactually weighed on a scale, the last digits of weights tend to have frequencies that \nare approximately the same, but Table 2-6 shows that the vast majority of weights \nhave last digits of 0 or 5, and this is strong evidence that people reported their \nweights and were not physically weighed. (Also, the word “interview” in the title \nof the California Health Interview Survey reveals that people were interviewed and \nwere not physically measured.)\n",
    "2-1 Frequency Distributions for Organizing and Summarizing Data  \n47\nGaps Example 4 illustrates this principle:\nThe presence of gaps can suggest that the data are from two or more \ndiﬀerent populations.\nThe converse of this principle is not true, because data from different populations do \nnot necessarily result in gaps.\nTABLE 2-7  Last Digits of Weights from the \nCalifornia Health Interview Survey\nLast Digit of Weight\nFrequency\n0\n46\n1\n 1\n2\n 2\n3\n 3\n4\n 3\n5\n30\n6\n 4\n7\n 0\n8\n 8\n9\n 3\nEXAMPLE 4  Exploring Data: What Does a Gap Tell Us?\nTable 2-8 is a frequency distribution of the heights (in.) of males. Examination of \nthe frequencies reveals a large gap between the shortest males and the tallest males. \nThis can be explained by the fact that half of the males are 7 years old and the other \nhalf are adults, so we really have samples from two different populations.\nTABLE 2-8 Heights of Males\nHeight (in.)\nFrequency\n40–44\n 3\n45–49\n17\n50–54\n29\n55–59\n 1\n60–64\n 0\n65–69\n24\n70–74\n23\n75–79\n 3\n",
    "48 \nCHAPTER 2 Exploring Data with Tables and Graphs\nTABLE 2-9 IQ Scores from the Low Lead Group and the High Lead Group\nIQ Score\nLow Lead Group\nHigh Lead Group\n50–69\n 2.6%\n70–89\n42.3%\n71.4%\n 90–109\n44.9%\n28.6%\n110–129\n 9.0%\n130–149\n 1.3%\nEXAMPLE 5   Comparing IQ Scores of the Low Lead Group and \nthe High Lead Group \nTable 2-1, which is given with the Chapter Problem at the beginning of this chapter, \nlists IQ scores from the low lead group and the high lead group. Because the sample \nsizes of 78 and 21 are so different, a comparison of frequency distributions is not \neasy, but Table 2-9 shows the relative frequency distributions for those two groups. \nBy comparing those relative frequencies, we see that the majority of children in the \nlow lead group had IQ scores of 90 or higher, but the majority of children in the \nhigh lead group had IQ scores below 90. This suggests that perhaps high lead expo-\nsure has a detrimental effect on IQ scores.\nFrequency Distributions\nAccess tech instructions, videos, and data sets at www.TriolaStats.com\nTECH CENTER \nStatistical Literacy and Critical Thinking\n1. Cotinine in Smokers Refer to the accompanying table summarizing measured amounts \nof serum cotinine (ng/mL) from a sample of smokers (from Data Set 14 “Passive and Active \nSmoke” in Appendix B). When nicotine is absorbed by the body, cotinine is produced. How \nmany subjects are included in the summary? Is it possible to identify the exact values of all of \nthe original cotinine measurements?\n2-1 Basic Skills and Concepts \nCotinine (ng, mL)\nFrequency\n 0–99\n11\n100–199\n12\n200–299\n14\n300–399\n 1\n400-499\n 2\n2. Cotinine in Smokers Refer to the accompanying frequency distribution. What problem is \ncreated by using classes of 0–100, 100–200, . . . ?\n3. Relative Frequency Distribution Use percentages to construct the relative frequency dis-\ntribution corresponding to the accompanying frequency distribution for cotinine amounts.\n4. What’s Wrong? Heights of adult males are known to have a normal distribution, as de-\nscribed in this section. A researcher claims to have randomly selected adult males and mea-\nsured their heights with the resulting relative frequency distribution as shown here. Identify two \nmajor flaws with theses results.\nHeight \n(cm)\nRelative  \nFrequency\n130–144\n23%\n145–159\n25%\n160–174\n22%\n175–189\n27%\n190–204\n28%\nComparisons Example 5 illustrates this principle:\nCombining two or more relative frequency distributions in one table \nmakes comparisons of data much easier.\n",
    "2-1 Frequency Distributions for Organizing and Summarizing Data  \n49\nIn Exercises 5–8, identify the class width, class midpoints, and class boundaries for the \ngiven frequency distribution. The frequency distributions are based on real data from \nAppendix B.\n5. \nCotinine (NonSmokers  \nExposed to Smoke  \nin ng, mL)\n \n \nFrequency\n0–99\n34\n100–199\n 2\n200–299\n 1\n300–399\n 1\n400–499\n 0\n500–599\n 2\n6. \nBrain Volume (cm3)\nFrequency\n960–1049\n6\n1050–1139\n7\n1140–1229\n3\n1230–1319\n2\n1320–1409\n1\n1410–1499\n1\n7. \nBlood Platelet \nCount of Males\n \nFrequency\n 0–99\n 1\n100–199\n51\n200–299\n90\n300–399\n10\n400–499\n 0\n500–599\n 0\n600–699\n 1\n8. \nBlood Platelet \nCount of Females\n \nFrequency\n100–199\n25\n200–299\n92\n300–399\n28\n400–499\n 0\n500–599\n 2\nNormal Distributions. In Exercises 9–12, answer the given questions, which are related \nto normal distributions.\n9. Cotinine Determine whether the frequency distribution given in Exercise 5 is approximately \na normal distribution. Explain.\n10. Brain Volume Refer to the frequency distribution given in Exercise 6 and ignore the given fre-\nquencies. Assume that the first three frequencies are 1, 3, and 6, respectively. Assuming that the dis-\ntribution of the 20 sample values is a normal distribution, identify the remaining three frequencies.\n11. Normal Distribution Refer to the frequency distribution given in Exercise 7 and ignore \nthe given frequencies. Assume that the first three frequencies are 2, 12, and 18, respectively. \nAssuming that the distribution of the 153 sample values is a normal distribution, identify the \nremaining four frequencies.\n12. Normal Distribution Refer to the frequency distribution given in Exercise 8 and deter-\nmine whether it appears to be a normal distribution. Explain.\nConstructing Frequency Distributions. In Exercises 13–22, use the indicated data and \nconstruct the frequency distribution. (The data for Exercises 13–22 can be downloaded at \nTriolaStats.com.)\n13. Pulse Rates of Males Refer to Data Set 1 “Body Data” in Appendix B and use the pulse \nrates (beats per minute) of males. Begin with a lower class limit of 40 and use a class width of \n10. Do the pulse rates of males appear to have a normal distribution?\n14. Pulse Rates of Females Refer to Data Set 1 “Body Data” in Appendix B and use the \npulse rates (beats per minute) of females. Begin with a lower class limit of 30 and use a class \nwidth of 10. Do the pulse rates of females appear to have a normal distribution?\n15. Lead and IQ Refer to Data Set 8 “IQ and Lead” in Appendix B and use the verbal IQ \nscores of the low lead group. Begin with a lower class limit of 50 and use a class width of 10. \nDo these IQ scores appear to be normally distributed?\n",
    "50 \nCHAPTER 2 Exploring Data with Tables and Graphs\n16. Lead and IQ Refer to Data Set 8 “IQ and Lead” in Appendix B and use the verbal IQ \nscores of the high lead group. Begin with a lower class limit of 60 and use a class width of 10. \nDo these IQ scores appear to be normally distributed?\n17. Male Red Blood Cell Counts Refer to Data Set 1 “Body Data” in Appendix B and use \nthe red blood cell counts (million cells>mL) for males. Begin with a lower class limit of 3.00 \nand use a class width of 0.50. Using a very loose interpretation of the requirements for a nor-\nmal distribution, do the red blood cell counts appear to be normally distributed?\n18. Female Red Blood Cell Counts Repeat the preceding exercise using the red blood cell \ncounts for females.\n19. Freshman 15 Refer to Data Set 10 “Freshman 15” in Appendix B and use the weights (kg) \nof males in September of their freshman year. Begin with a lower class limit of 50 kg and use a \nclass width of 10 kg.\n20.  Freshman 15 Repeat the preceding exercise using the weights (kg) of males in April. \nCompare the result to the frequency distribution from the preceding exercise. Does it appear \nthat males gain 15 lb (or 6.8 kg) during their freshman year?\n21. Analysis of Last Digits Heights of statistics students were obtained by one of the authors \nas part of an experiment conducted for class. The last digits of those heights are listed below. \nConstruct a frequency distribution with 10 classes. Based on the distribution, do the heights ap-\npear to be reported or actually measured? What do you know about the accuracy of the results?\n0 0 0 0 0 0 0 0 0 1 1 2 3 3 3 4 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 6 6 8 8 8 9\n22. Analysis of Last Digits Listed below are the last digits of weights of subjects. After con-\nstructing the frequency distribution, does it appear that the weights were reported or physically \nmeasured? Explain.\n2 7 7 3 2 8 5 9 7 2 8 6 9 2 7 5 6 4 0 7 6 8 4 0 4\n7 5 5 4 8 6 3 8 9 3 9 2 6 0 1 1 1 7 2 0 3 5 6 6 8\nRelative Frequencies for Comparisons. In Exercises 23 and 24, find the relative fre-\nquencies and answer the given questions.\n23. Cotinine Construct one table (similar to Table 2-9 on page 48) that includes relative fre-\nquencies based on the frequency distributions from Exercise 1 (smokers) and Exercise 5 (non-\nsmokers exposed to smoke), and then compare them. Are there notable differences?\n24. Blood Platelet Counts Construct one table (similar to Table 2-9 on page 48) that includes \nrelative frequencies based on the frequency distributions from Exercises 7 and 8, and then com-\npare them. Are there notable differences?\nCumulative Frequency Distributions. In Exercises 25 and 26, construct the cumulative \nfrequency distribution that corresponds to the frequency distribution in the exercise indicated.\n25. Exercise 5\n26. Exercise 6\n27. Interpreting Effects of Outliers Exercise 5 in this section involved cotinine levels of \nnonsmokers who were exposed to tobacco smoke. (See the middle column in Data Set 14 \n “Passive and Active Smoke” in Appendix B.)\na. Identify any outliers.\nb. After adding another value of 999 to the cotinine levels of nonsmokers exposed to smoke, construct \nthe frequency distribution as in Exercise 5. How is the frequency distribution affected by the addition \nof the outlier 999? State a generalization about the effect of an outlier on a frequency distribution.\n2-1 Beyond the Basics \n",
    "2-2 Histograms \n51\nImportant Uses of a Histogram\n \n■Visually displays the shape of the distribution of the data\n \n■Shows the location of the center of the data\n \n■Shows the spread of the data\n \n■Identifies outliers\nA histogram is basically a graph of a frequency distribution. For example, \n Figure 2-2 shows the histogram corresponding to the frequency distribution given in \nTable 2-2 on page 42.\nClass frequencies should be used for the vertical scale and that scale should be la-\nbeled as in Figure 2-2. There is no universal agreement on the procedure for selecting \nwhich values are used for the bar locations along the horizontal scale, but it is com-\nmon to use class boundaries (as shown in Figure 2-2) or class midpoints or class limits \nor something else. It is often easier for us mere mortals to use class midpoints for the \nhorizontal scale. Histograms can usually be generated using technology.\nRelative Frequency Histogram\nA relative frequency histogram has the same shape and horizontal scale as a histo-\ngram, but the vertical scale uses relative frequencies (as percentages or proportions) \ninstead of actual frequencies. Figure 2-3 is the relative frequency histogram corre-\nsponding to Figure 2-2.\nPART 1\nBasic Concepts of Histograms\nKey Concept While a frequency distribution is a useful tool for summarizing data \nand investigating the distribution of data, an even better tool is a histogram, which is a \ngraph that is easier to interpret than a table of numbers.\n2-2 \nHistograms\nDEFINITION\nA histogram is a graph consisting of bars of equal width drawn adjacent to each \nother (unless there are gaps in the data). The horizontal scale represents classes of \nquantitative data values, and the vertical scale represents frequencies. The heights \nof the bars correspond to frequency values.\nFIGURE 2-2 Histogram\nFIGURE 2-3 Relative Frequency Histogram\n",
    "52 \nCHAPTER 2 Exploring Data with Tables and Graphs\nCritical Thinking: Interpreting Histograms\nThe ultimate objective of a histogram is to understand characteristics of the data. Ex-\nplore the data by analyzing the histogram to see what can be learned about “CVDOT”: \nthe center of the data, the variation (which will be discussed at length in Section 3-2), \nthe shape of the distribution, whether there are any outliers (values far away from the \nother values), and time (whether there is any change in the characteristics of the data \nover time). Examining Figure 2-2, we see that the histogram is centered close to 90, \nthe values vary from around 50 to 150, and the distribution is roughly bell-shaped. \nThere aren’t any outliers and any changes in time are irrelevant for these data.\nCommon Distribution Shapes\nThe histograms shown in Figure 2-4 depict four common distribution shapes.\nNormal Distribution\nWhen graphed as a histogram, data with a normal distribution have a “bell” shape \nsimilar to the one superimposed in Figure 2-5. Many collections of data have a dis-\ntribution that is approximately normal. Many statistical methods require that sample \ndata come from a population having a distribution that is approximately a normal dis-\ntribution, and we can often use a histogram to judge whether this requirement is satis-\nfied. There are more advanced and less subjective methods for determining whether \nthe distribution is a normal distribution. Normal quantile plots are very helpful for \nassessing normality: see Part 2 of this section.\n   \n   \nFIGURE 2-4 Common Distributions\n(a)\n(b)\n(c)\n(d)\n",
    "2-2 Histograms \n53\nUniform Distribution\nThe different possible values occur with approximately the same frequency, so the \nheights of the bars in the histogram are approximately uniform, as in Figure 2-4(b). \nFigure 2-4(b) depicts outcomes of last digits of weights from a large sample of ran-\ndomly selected subjects, and such a graph is helpful in determining whether the sub-\njects were actually weighed or whether they reported their weights.\nPopulation sizes of an organism are often uniformly distributed when they are \nfound in equally sized areas of a region where they must compete for a limited re-\nsource. For example, redwood trees must compete for light, and numbers of redwood \ntrees in equally sized areas of a region tend to be uniformly distributed.\nSkewness\nA distribution of data is skewed if it is not symmetric and extends more to one side \nthan to the other. Data skewed to the right (also called positively skewed) have a \nlonger right tail, as in Figure 2-4(c). Annual incomes of adult Americans are skewed \nto the right; death rates of nations are skewed to the right. Data skewed to the left \n(also called negatively skewed) have a longer left tail, as in Figure 2-4(d). Life span \ndata in humans are skewed to the left. (Here’s a mnemonic for remembering skew-\nness: A distribution skewed to the right resembles the toes on your right foot, and \none skewed to the left resembles the toes on your left foot.) Distributions skewed to \nthe right are more common than those skewed to the left because it’s often easier to \nget exceptionally large values than values that are exceptionally small. With annual \nincomes, for example, it’s impossible to get values below zero, but there are a few \npeople who earn millions or billions of dollars in a year. Annual incomes therefore \ntend to be skewed to the right.\nPART 2\n  Assessing Normality with  \nNormal Quantile Plots\nSome methods presented in later chapters have a requirement that sample data must \nbe from a population having a normal distribution. Histograms can be helpful in de-\ntermining whether the normality requirement is satisfied, but they are not very help-\nful with small data sets. Section 6-5 discusses methods for assessing normality—that \nis, determining whether the sample data are from a normally distributed population. \nSection 6-5 includes a procedure for constructing normal quantile plots, which are \nFIGURE 2-5  Bell-Shaped Distribution\nBecause this histogram is roughly bell-shaped, we say that the \ndata have a normal distribution. (A more rigorous deﬁnition will be \ngiven in Chapter 6.)\nRemembering Skewness:\nSkewed Left:   Resembles \ntoes on left \nfoot\nSkewed Right:  Resembles \ntoes on right \nfoot\n",
    "54 \nCHAPTER 2 Exploring Data with Tables and Graphs\neasy to generate using technology such as Statdisk, SPSS, JMP, Minitab, XLSTAT, \nStatCrunch, or a TI-83>84 Plus calculator. Interpretation of a normal quantile plot is \nbased on the following criteria:\nCriteria for Assessing Normality with a Normal Quantile Plot\nNormal Distribution: The population distribution is normal if the pattern of the \npoints in the normal quantile plot is reasonably close to a straight line, and the \npoints do not show some systematic pattern that is not a straight-line pattern.\nNot a Normal Distribution: The population distribution is not normal if the \nnormal quantile plot has either or both of these two conditions:\n•  The points do not lie reasonably close to a straight-line pattern.\n•  The points show some systematic pattern that is not a straight-line pattern.\nThe following are examples of normal quantile plots. Procedures for creating such \nplots are described in Section 6-5.\nNormal Distribution: The points are  \nreasonably close to a straight-line pattern, \nand there is no other systematic pattern \nthat is not a straight-line pattern.\nNot a Normal Distribution: The \npoints do not lie reasonably close to a \nstraight line.\nNot a Normal Distribution: The \npoints show a systematic pattern that \nis not a straight-line pattern.\nHistograms\nAccess tech instructions, videos, and data sets at www.TriolaStats.com\nTECH CENTER \nStatistical Literacy and Critical Thinking\n1. Histogram Table 2-2 is a frequency distribution summarizing the IQ scores of the low lead \ngroup listed in Table 2-1 on page 41, and Figure 2-2 on page 51 is a histogram depicting that \nsame data set. When trying to better understand the IQ data, what is the advantage of examin-\ning the histogram instead of the frequency distribution?\n2. Voluntary Response Sample The histogram in Figure 2-2 on page 51 is constructed from \na simple random sample of children. If you construct a histogram with data collected from a \nvoluntary response sample, will the distribution depicted in the histogram reflect the true dis-\ntribution of the population? Why or why not?\n3. Blood Platelet Counts Listed below are blood platelet counts (1000 cells>mL) randomly \nselected from adults in the United States. Why does it not make sense to construct a histogram \nfor this data set?\n191 286 263 193 193 215 162 646 250 386\n2-2 Basic Skills and Concepts\n",
    "2-2 Histograms \n55\n4. Normal Distribution When it refers to a normal distribution, does the term “normal” have \nthe same meaning as in ordinary language? What criterion can be used to determine whether \nthe data depicted in a histogram have a distribution that is approximately a normal distribution? \nIs this criterion totally objective, or does it involve subjective judgment?\nInterpreting a Histogram. In Exercises 5–8, answer the questions by referring to the fol-\nlowing histogram, which represents the sepal widths (mm) of a sample of irises. (See Data \nSet 16 “Iris Measurements” in Appendix B.)\n5. Sample Size Based on the histogram, what is the approximate number of irises in \nthe sample?\n6. Class Width and Class Limits What is the class width? What are the approximate lower \nand upper class limits of the first class?\n7. Outlier? What is the largest possible value? Would that value be an outlier?\n8. Normal Distribution Does it appear that the sample is from a population having a normal \ndistribution?\nConstructing Histograms. In Exercises 9–18, construct the histograms and answer the \ngiven questions. Use class midpoint values for the horizontal scale.\n9. Pulse Rates of Males Use the frequency distribution from Exercise 13 in Section 2-1 on \npage 49 to construct a histogram. Do the pulse rates of males appear to have a normal distribution?\n10. Pulse Rates of Females Use the frequency distribution from Exercise 14 in Section 2-1  \non page 49 to construct a histogram. Do the pulse rates of females appear to have a normal \ndistribution?\n11. Lead and IQ Use the frequency distribution from Exercise 15 in Section 2-1 on page 49 to \nconstruct a histogram. Do the IQ scores appear to have a normal distribution?\n12. Lead and IQ Use the frequency distribution from Exercise 16 in Section 2-1 on page 50 to \nconstruct a histogram. Do the IQ scores appear to have a normal distribution?\n13.  Male Red Blood Cell Counts Use the frequency distribution from Exercise 17 in \nSection 2-1 on page 50 to construct a histogram. Do the red blood cell counts appear to have a \nnormal distribution?\n14. Female Red Blood Cell Counts Use the frequency distribution from Exercise 18 in \nSection 2-1 on page 50 to construct a histogram. Do the red blood cell counts appear to have \na normal distribution?\n15. Freshman 15 Use the frequency distribution from Exercise 19 in Section 2-1 on page 50 \nto construct a histogram.\n16. Freshman 15 Use the frequency distribution from Exercise 20 in Section 2-1 on page 50 \nto construct a histogram.\n",
    "56 \nCHAPTER 2 Exploring Data with Tables and Graphs\n17. Last Digit Analysis Use the frequency distribution from Exercise 21 in Section 2-1 on \npage 50 to construct a histogram. What does the histogram suggest about the method used to \ncollect the heights?\n18. Last Digit Analysis Use the frequency distribution from Exercise 22 in Section 2-1 on \npage 50 to construct a histogram. What does the histogram suggest about the method used to \ncollect the weights?\n2-2 Beyond the Basics\nKey Concept Section 2-2 introduced the histogram, and this section introduces other \ncommon graphs that foster understanding of data. We also discuss some graphs that \nare deceptive because they create impressions about data that are somehow mislead-\ning or wrong.\nThe era of charming and primitive hand-drawn graphs has passed, and technol-\nogy now provides us with powerful tools for generating a wide variety of graphs. \nHere we go.\nGraphs That Enlighten\nDotplots\nA dotplot consists of a graph of quantitative data in which each data value is plotted \nas a point (or dot) above a horizontal scale of values. Dots representing equal values \nare stacked.\nFeatures of a Dotplot\n \n■Displays the shape of the distribution of data.\n \n■It is usually possible to recreate the original list of data values.\n2-3 \nGraphs That Enlighten and Graphs That Deceive\n19. Interpreting Normal Quantile Plots Which of the following normal quantile plots  appear \nto represent data from a population having a normal distribution? Explain.\n(a)\n(b)\n(c)\n(d)\n",
    "2-3 Graphs That Enlighten and Graphs That Deceive \n57\nStemplots\nA stemplot (or stem-and-leaf plot) represents quantitative data by separating each \nvalue into two parts: the stem (such as the leftmost digit) and the leaf (such as the \nrightmost digit). Better stemplots are often obtained by first rounding the original data \nvalues. Also, stemplots can be expanded to include more rows and can be condensed \nto include fewer rows.\nFeatures of a Stemplot\n \n■Shows the shape of the distribution of the data.\n \n■Retains the original data values.\n \n■The sample data are sorted (arranged in order).\nFIGURE 2-6 Dotplot of Pulse Rates of Males\nEXAMPLE 1  Dotplot of Pulse Rates of Males\nFigure 2-6 shows a dotplot of the pulse rates (beats per minute) of males from Data \nSet 1 “Body Data” in Appendix B. The two stacked dots above the position at 50 in-\ndicate that two of the pulse rates are 50. (In this dotplot, the horizontal scale allows \neven numbers only, but the original pulse rates are all even numbers.)\nEXAMPLE 2  Stemplot of Male Pulse Rates\nThe following stemplot displays the pulse rates of the males in Data Set 1 “Body \nData” in Appendix B. The lowest pulse rate of 40 is separated into the stem of 4 and \nthe leaf of 0. The stems and leaves are arranged in increasing order, not the order in \nwhich they occur in the original list. If you turn the stemplot on its side, you can see \nthe distribution of the IQ scores in the same way you would see it in a histogram or \ndotplot.\nPulse rates are 40 and 42\nPulse rates are 90, 92, 94, 96, 96\nTime-Series Graph\nA time-series graph is a graph of time-series data, which are quantitative data that \nhave been collected at different points in time, such as monthly or yearly. An advan-\ntage of a time-series graph is that it reveals information about trends over time.\nFeatures of a Time-series Graph\n \n■Reveals information about trends over time\n",
    "58 \nCHAPTER 2 Exploring Data with Tables and Graphs\nBar Graphs\nA bar graph uses bars of equal width to show frequencies of categories of categori-\ncal (or qualitative) data. The bars may or may not be separated by small gaps.\nFeature of a Bar Graph\n \n■Shows the relative distribution of categorical data so that it is easier to compare \nthe different categories\nPareto Charts\nA Pareto chart is a bar graph for categorical data, with the added stipulation that the \nbars are arranged in descending order according to frequencies, so the bars decrease \nin height from left to right.\nFeatures of a Pareto Chart\n \n■Shows the relative distribution of categorical data so that it is easier to compare \nthe different categories\n \n■Draws attention to the more important categories\nFIGURE 2-7  Time-Series Graph of Law  \nEnforcement Fatalities\nEXAMPLE 3   Time-Series Graph of Fatalities of Law  \nEnforcement Officers\nThe time-series graph shown in Figure 2-7 depicts the yearly number of fatalities \nof law enforcement officers in the United States. See that a spike occurred in 2001, \nthe year of the September 11, 2001 terrorist attacks. Except for the data from 2001, \nthere appears to be a slight downward trend.\nEXAMPLE 4  Pareto Chart of Causes of Accidental Deaths\nFor the accidental deaths in a recent year, Figure 2-8 shows the most common \ncauses. We can see that deaths from poison represent the most serious problem. \n(Deaths from poison include deaths from drug overdoses.)\nThe Power of a Graph\nWith annual \nsales around \n$13 billion and \nwith roughly \n50 million \npeople using \nit, Pfizer’s \nprescription drug Lipitor (ator-\nvastatin) has become the most \nprofitable and most widely used \nprescription drug ever marketed. \nIn the early stages of its develop-\nment, Lipitor was compared to \nother drugs (Zocor [simvastatin], \nMevacor [lovastatin], Lescol \n[fluvastatin], and Pravachol \npravastatin) in a process that \ninvolved controlled trials. The \nsummary report included a graph \nshowing a Lipitor curve that had \na steeper rise than the curves for \nthe other drugs, visually showing \nthat Lipitor was more effective \nin reducing cholesterol than the \nother drugs. Pat Kelly, who was \nthen a senior marketing execu-\ntive for Pfizer, said, “I will never \nforget seeing that chart…. It was \nlike ‘Aha!’ Now I know what this \nis about. We can communicate \nthis!” The Food and Drug Admin-\nistration approved Lipitor and al-\nlowed Pfizer to include the graph \nwith each prescription. Pfizer \nsales personnel also distributed \nthe graph to physicians.\n",
    "2-3 Graphs That Enlighten and Graphs That Deceive \n59\nPie Charts\nA pie chart is a very common graph that depicts categorical data as slices of a circle, \nin which the size of each slice is proportional to the frequency count for the category. \nAlthough pie charts are very common, they are not as effective as Pareto charts.\nFeature of a Pie Chart\n \n■Shows the distribution of categorical data in a commonly used format\nFIGURE 2-8  Pareto Chart of Causes of \n Accidental Deaths\nEXAMPLE 5  Pie Chart of Causes of Accidental Deaths\nFigure 2-9 is a pie chart of the same cause of death data from Example 4. Construc-\ntion of a pie chart involves slicing up the circle into the proper proportions that rep-\nresent relative frequencies. For example, the category poison accounts for 34% of \nthe total, so the slice representing poison should be 34% of the total (with a central \nangle of 0.34 * 360° = 122°).\nFIGURE 2-9  Pie Chart of Causes of \nAccidental Deaths\nThe Pareto chart in Figure 2-8 and the pie chart in Figure 2-9 depict the same data in \ndifferent ways, but the Pareto chart does a better job of showing the relative sizes of the \ndifferent components. Graphics expert Edwin Tufte makes the following suggestion:\nNever use pie charts because they waste ink on components that are not \ndata, and they lack an appropriate scale.\n",
    "60 \nCHAPTER 2 Exploring Data with Tables and Graphs\nFrequency Polygon\nA frequency polygon uses line segments connected to points located directly above \nclass midpoint values. A frequency polygon is very similar to a histogram, but a fre-\nquency polygon uses line segments instead of bars.\nA variation of the basic frequency polygon is the relative frequency polygon, \nwhich uses relative frequencies (proportions or percentages) for the vertical scale. An \nadvantage of relative frequency polygons is that two or more of them can be combined \non a single graph for easy comparison, as in Figure 2-11.\nFIGURE 2-10  Frequency Polygon of Full IQ \nScores of Low Lead Group\nEXAMPLE 6   Frequency Polygon of Full IQ Scores of  \nLow Lead Group\nSee Figure 2-10 for the frequency polygon corresponding to the full IQ scores of the \nlow lead group summarized in the frequency distribution of Table 2-2 on page 42 \n(from Data Set 8 in Appendix B). The heights of the points correspond to the class \nfrequencies, and the line segments are extended to the right and left so that the graph \nbegins and ends on the horizontal axis. The points are plotted directly above class \nmidpoint values.\nEXAMPLE 7   Relative Frequency Polygon: IQ Scores  \nof Lead Groups\nFigure 2-11 shows the relative frequency polygons for the full IQ scores of two \ngroups: (1) group with low blood lead levels; (2) group with high blood lead levels. \nHere, relative frequency polygons are much better than frequency polygons because \nthe different sample sizes of 21 and 78 would have made a comparison difficult, but \nthat difficulty is removed by using relative percentages.\nFigure 2-11 shows that the group with high blood lead levels has full IQ scores \nthat are somewhat lower than those in the low blood level group. This suggests that \nexposure to lead has an effect on IQ scores. Later chapters will provide us with \nmore tools that allow us to examine this issue beyond the subjective interpretation \nof a graph.\nF\nA\nc\nq\nFlorence Nightingale\nFlorence \nNightingale \n(1820–1910) \nis known to \nmany as the \nfounder of \nthe nursing \nprofession, but she also saved \nthousands of lives by using \nstatistics. When she encountered \nan unsanitary and undersup-\nplied hospital, she improved \nthose conditions and then used \nstatistics to convince others of \nthe need for more widespread \nmedical reform. She developed \noriginal graphs to illustrate that \nduring the Crimean War, more \nsoldiers died as a result of \nunsanitary conditions than were \nkilled in combat. Florence Night-\ningale pioneered the use of social \nstatistics as well as graphics \ntechniques.\n",
    "2-3 Graphs That Enlighten and Graphs That Deceive \n61\nGraphs That Deceive\nDeceptive graphs are commonly used to mislead people, and we really don’t want \nstatistics students to be among those susceptible to such deceptions. Graphs should be \nconstructed in a way that is fair and objective. The readers should be allowed to make \ntheir own judgments, instead of being manipulated by misleading graphs. We present \ntwo of the ways in which graphs are commonly used to misrepresent data.\nNonzero Vertical Axis\nA common deceptive graph involves using a vertical scale that starts at some value \ngreater than zero to exaggerate differences between groups.\nFIGURE 2-11  Relative Frequency Polygons for Full IQ \nScores of High and Low Lead Groups\nNONZERO AXIS: Always examine a graph carefully to see whether a vertical axis \nbegins at some point other than zero so that differences are exaggerated.\nEXAMPLE 8  Nonzero Axis\nFigure 2-12(a) and Figure 2-12(b) are based on the same data from a clinical trial of \nOxyContin (oxycodone), a drug used to treat moderate to severe pain. The results of \nthat clinical trial included the percentage of subjects who experienced nausea in an \nOxyContin treatment group and the percentage in a group given a placebo.\n \nFIGURE 2-12 Nausea in a Clinical Trial\n(a)\n(b)\ncontinued\n",
    "62 \nCHAPTER 2 Exploring Data with Tables and Graphs\nPictographs\nDrawings of objects, called pictographs, are often misleading. Data that are one-\ndimensional in nature (such as budget amounts) are often depicted with two-dimensional \nobjects (such as dollar bills) or three-dimensional objects (such as stacks of coins, \nhomes, or barrels). With pictographs, artists can create false impressions that grossly \ndistort differences by using these simple principles of basic geometry: (1) When you \ndouble each side of a square, its area doesn’t merely double; it increases by a factor \nof four. (2) When you double each side of a cube, its volume doesn’t merely double; \nit increases by a factor of eight.\nBy using a vertical scale that starts at 10% instead of 0%, Figure 2-12(a) \ngrossly exaggerates the difference between the two groups. Figure 2-12(a) makes it \nappear that those using OxyContin experience nausea at a rate that is about 12 times \nhigher than the rate for those using a placebo, but Figure 2-12(b) shows that the true \nratio is about 2:1, not 12:1. Perhaps someone wants to discourage recreational use \nof OxyContin by misleading people into thinking that the problem with nausea is \nmuch greater than it really is. The objective might be sincere, but the use of a mis-\nleading graph is not the way to achieve that objective.\nPICTOGRAPHS: When examining data depicted with a pictograph, determine \nwhether the graph is misleading because objects of area or volume are used to \ndepict amounts that are actually one-dimensional. (Histograms and bar charts \nrepresent one-dimensional data with two-dimensional bars, but they use bars with \nthe same width so that the graph is not misleading.)\nEXAMPLE 9  Pictograph of Cigarette Smokers\nRefer to Figure 2-13 and see that the larger cigarette is about twice as long, twice as \ntall, and twice as deep as the smaller cigarette, so the volume of the larger cigarette \nis about eight times the volume of the smaller cigarette. (The data are from the Cen-\nters for Disease Control and Prevention.) The larger cigarette appears to be eight \ntimes as large as the smaller cigarette, but the actual percentages show that the 37% \nsmoking rate in 1970 is about twice that of the 18% rate in 2013.\n \nFIGURE 2-13 Smoking by U.S. Adults\n1970: 37% of U.S. adults smoked.       2013: 18% of U.S. adults smoked.\n",
    "2-3 Graphs That Enlighten and Graphs That Deceive \n63\nConcluding Thoughts\nIn addition to the graphs we have discussed in this section, there are many other useful \ngraphs—some of which have not yet been created. The world desperately needs more \npeople who can create original graphs that enlighten us about the nature of data. In \nThe Visual Display of Quantitative Information, Edward Tufte offers these principles:\n \n■For small data sets of 20 values or fewer, use a table instead of a graph.\n \n■A graph of data should make us focus on the true nature of the data, not on other \nelements, such as eye-catching but distracting design features.\n \n■Do not distort data; construct a graph to reveal the true nature of the data.\n \n■Almost all of the ink in a graph should be used for the data, not for other design \nelements.\nGraphing Capabilities\nAccess tech instructions, videos, and data sets at www.TriolaStats.com\nTECH CENTER \nStatistical Literacy and Critical Thinking\n1. Body Temperatures Listed below are body temperatures (°F) of healthy adults. Why is it \nthat a graph of these data would not be very effective in helping us understand the data?\n98.6 98.6 98.0 98.0 99.0 98.4 98.4 98.4 98.4 98.6\n2. Voluntary Response Data If we have a large voluntary response sample consisting of \nweights of subjects who chose to respond to a survey posted on the Internet, can a graph help to \novercome the deficiency of having a voluntary response sample?\n3. Ethics There are data showing that smoking is detrimental to good health. Given that people \ncould be helped and lives could be saved by reducing smoking, is it ethical to graph the data in \na way that is misleading by exaggerating the health risks of smoking?\n4. CVDOT Section 2-1 introduced important characteristics of data summarized by the acro-\nnym CVDOT. What characteristics do those letters represent, and which graph does the best \njob of giving us insight into the last of those characteristics?\nDotplots. In Exercises 5 and 6, construct the dotplot.\n5. Pulse Rates Listed below are pulse rates (beats per minute) of females selected from Data \nSet 1 “Body Data” in Appendix B. All of those pulse rates are even numbers. Is there a pulse \nrate that appears to be an outlier? What is its value?\n80  94  58  66  56  82  78  86  88  56  36  66  84  76  78  64  66  78  60  64\n6. Diastolic Blood Pressure Listed below are diastolic blood pressure measurements \n(mm Hg) of females selected from Data Set 1 “Body Data” in Appendix B. All of the values are \neven numbers. Are there any outliers? If so, identify their values.\n62 70 72 88 70 66 68 70 82 74 90 62 70 76 90 86 60 78 82 78 84 76 60 64\nStemplots. In Exercises 7 and 8, construct the stemplot.\n7. Pulse Rates Refer to the data listed in Exercise 5. How are the data sorted in the stemplot?\n8. Diastolic Blood Pressure Refer to the data listed in Exercise 6. Identify the two values \nthat are closest to the middle when the data are sorted in order from lowest to highest. (These \nvalues are often used to find the median, which is defined in Section 3-1.)\n2-3 Basic Skills and Concepts\n",
    "64 \nCHAPTER 2 Exploring Data with Tables and Graphs\nTime-Series Graphs. In Exercises 9 and 10, construct the time-series graph.\n9. Triplets Listed below are the numbers of triplets born in the United States each year beginning \nwith 1995. Is there a trend?\n4551 5298 6148 6919 6742 6742 6885 6898 7110\n6750 6208 6118 5967 5877 5905 5153 5137 4598\n10. Drunk Driving Fatalities Listed below are annual fatality rates (per 100,000 population) \nfrom drunk driving. The first entry represents the year 1991. Is there a trend? Any explanation?\n6.3 5.5 5.3 5.1 5.1 5.1 4.8 4.6 4.6 4.7 4.7\n4.7 4.5 4.5 4.6 4.5 4.3 3.9 3.5 3.3 3.2 3.3\nPareto Charts. In Exercises 11 and 12 construct the Pareto chart.\n11. Journal Retractions In a study of retractions in biomedical journals, 436 were due to \nerror, 201 were due to plagiarism, 888 were due to fraud, 291 were duplications of publica-\ntions, and 287 had other causes (based on data from “Misconduct Accounts for the Majority \nof Retracted Scientific Publications,” by Fang, Steen, Casadevall, Proceedings of the National \nAcademy of Sciences of the United States of America, Vol. 110, No. 3). Among such retrac-\ntions, does misconduct (fraud, duplication, plagiarism) appear to be a major factor?\n12. Getting a Job In a survey, subjects seeking a job were asked to whom they send a thank-\nyou note after having a job interview. Results were as follows: 40 said only the person they \nspent the most time with, 40 said only the most senior-level person, 396 said everyone that they \nmet, 15 said the person that they had the best conversation with, and 10 said that they don’t \nsend thank-you notes (based on data from TheLadders.com). Comment on the results.\nPie Charts. In Exercises 13 and 14, construct the pie chart.\n13. Journal Retractions Use the data from Exercise 11 “Journal Retractions.”\n14. Getting a Job Use the data from Exercise 12 “Getting a Job.”\nFrequency Polygon. In Exercises 15 and 16, construct the frequency polygons.\n15. Pulse Rates of Males Use the frequency distribution for the pulse rates of males from \nExercise 13 in Section 2-1 on page 49 to construct a frequency polygon. Comment on the \nshape of the distribution.\n16. Pulse Rates of Females Use the frequency distribution for the pulse rates of females \nfrom Exercise 14 in Section 2-1 on page 49 to construct a frequency polygon. Comment on the \nshape of the distribution.\nDeceptive Graphs. In Exercises 17–18, identify how the graph is deceptive.\n17. Self-Driving Vehicles In a survey of adults, subjects were asked if they felt comfortable \nbeing in a self-driving vehicle. The accompanying graph depicts the results (based on data from \nTE Connectivity).\n",
    "2-4 Scatterplots, Correlation, and Regression \n65\n18. Cost of Giving Birth According to the Agency for Healthcare Research and Quality \nHealthcare Cost and Utilization Project, the typical cost of a C-section baby delivery is $4500, \nand the typical cost of a vaginal delivery is $2600. See the accompanying illustration.\nCost of C-Section Delivery: $4500\nCost of Vaginal Delivery: $2600\nKey Concept This section introduces the analysis of paired (or “bivariate”) sample \ndata, which are data from two different variables that are paired in some way, such \nas the variables of heights and weights from subjects. In Part 1 of this section we dis-\ncuss correlation and the role of a graph called a scatterplot. In Part 2 we provide an \nintroduction to the use of the linear correlation coefficient. In Part 3 we provide a very \nbrief discussion of linear regression, which involves the equation and graph of the \nstraight line that best fits the sample paired data.\nAll of the principles discussed in this section are discussed more fully in Chapter 10, \nbut this section serves as a quick introduction to some important concepts of correlation \nand regression. This section does not include details for executing manual calculations, \nand those calculations are rarely done. Instructions for using technology to obtain results \ncan be found at www.TriolaStats.com; refer to the instructions for Chapter 10.\nPART 1\n Scatterplot and Correlation \nOur objective in this section is to explore whether there is a correlation, or associa-\ntion, between two variables. We begin with basic definitions.\n2-4 \nScatterplots, Correlation, and Regression\nDEFINITIONS\nA correlation exists between two variables when the values of one variable are \nsomehow associated with the values of the other variable.\nA linear correlation exists between two variables when there is a correlation and \nthe plotted points of paired data result in a pattern that can be approximated by a \nstraight line.\nA scatterplot or scatter diagram is a plot of paired (x, y) quantitative data with a \nhorizontal x-axis and a vertical y-axis. The horizontal axis is used for the first vari-\nable (x), and the vertical axis is used for the second variable (y).\n",
    "66 \nCHAPTER 2 Exploring Data with Tables and Graphs\nA scatterplot can be used as a visual aid in determining whether there is a correlation \n(or relationship) between the two variables. (This issue is discussed at length when the \ntopic of correlation is considered in Section 10-1.)\nCAUTION: The presence of a correlation between two variables is not evidence \nthat one of the variables causes the other. We might find a correlation between beer \nconsumption and weight, but we cannot conclude from the statistical evidence that \ndrinking beer has a direct effect on weight.\nCorrelation does not imply causality!\nEXAMPLE 1  Correlation: Waist and Arm Circumference\nData Set 1 “Body Data” in Appendix B includes waist circumferences (cm) and arm \ncircumferences (cm) of randomly selected adult subjects. Figure 2-14 is a scatter-\nplot of the paired waist>arm measurements. The points show a pattern of increasing \nvalues from left to right. This pattern suggests that there is a correlation or relation-\nship between waist circumferences and arm circumferences.\nEXAMPLE 2  No Correlation: Weight and Pulse Rate\nData Set 1 “Body Data” in Appendix B includes weights (kg) and pulse rates (beats \nper minute) of randomly selected adult subjects. Figure 2-15 is a scatterplot of the \npaired weight>pulse rate measurements. The points in Figure 2-15 do not show any \nobvious pattern, and this lack of a pattern suggests that there is no correlation or re-\nlationship between weights and pulse rates.\nFIGURE 2-14  Waist and Arm Circumferences\nCorrelation: The distinct straight-line pattern of the plotted \npoints suggests that there is a correlation between waist \ncircumferences and arm circumference.\nFIGURE 2-15 Weights and Pulse Rates\nNo Correlation: The plotted points do not show a distinct \npattern, so it appears that there is no correlation between \nweights and pulse rates.\nThe preceding two examples involve making decisions about a correlation \nbased on subjective judgments of scatterplots, but Part 2 introduces the linear corre-\nlation coefficient as a numerical measure that can help us make such decisions more \nobjectively. Using paired data, we can calculate the value of the linear correlation \ncoefficient r.\n",
    "2-4 Scatterplots, Correlation, and Regression \n67\nPART 2\nLinear Correlation Coefficient r\nUsing paired data, we can calculate the value of the linear correlation coefficient r.\nDEFINITION\nThe linear correlation coefficient is denoted by r, and it measures the strength of \nthe linear association between two variables.\nThe value of a linear correlation coefficient r can be manually computed by applying \nFormula 10-1 or Formula 10-2 found in Section 10-1 on page 447, but in practice, r is \nalmost always found by using technology.\nUsing r for Determining Correlation\nThe computed value of the linear correlation coefficient is always between -1 and \n1. A value of exactly -1 or 1 implies that all of the data fall exactly on a line, which \nreflects a perfect correlation. If r is close to -1 or close to 1, there appears to be a \nstrong correlation, but if r is close to 0, there appears to be a weak or no linear cor-\nrelation. For the data depicted in the scatterplot of Figure 2-14, r = 0.802 (somewhat \nclose to 1), and the data in the scatterplot of Figure 2-15 result in r = 0.082 (pretty \nclose to 0). These descriptions of “close to” -1 or 1 or 0 are vague, but there are other \nobjective criteria discussed in Chapter 10. See the following example illustrating the \ninterpretation of the linear correlation coefficient r.\nTABLE 2-10 Shoe Print Lengths and Heights of Males\nShoe Print Length (cm)\n29.7\n29.7\n31.4\n31.8\n27.6\nHeight (cm)\n175.3\n177.8\n185.4\n175.3\n172.7\nEXAMPLE 3   Correlation Between Shoe Print  \nLengths and Heights?\nConsider the data in Table 2-10 (using data from Data Set 7 “Foot and Height” in \nAppendix B). From the accompanying scatterplot of the paired data in Table 2-10, it \nisn’t very clear whether there is a linear correlation. The Statdisk display of the results \nshows that the linear correlation coefficient has the value of r = 0.591 (rounded).\nPolice Deaths in Car \nChases\nUSA Today \ninvestigated \nthe annual \nreporting of \nthe numbers of \npolice who were \nkilled during \ncar chases. It was found that the \nFederal Bureau of Investigation \n(FBI) counted 24 deaths in the \npast 35 years, but other records \nshow that there were 371 deaths \nduring that time period. USA \nToday reporter Thomas Frank \nwrote that “the undercount is one \nof the most extreme examples of \nthe federal government’s inability \nto accurately track violent deaths \nand has led the FBI to minimize \nthe danger of police chasing \nmotorists.” Apparently, the FBI \nwas categorizing these deaths \nas automobile accidents instead \nof designating them as police \ndeaths that occurred during a car \nchase.\nStatdisk\n",
    "68 \nCHAPTER 2 Exploring Data with Tables and Graphs\nIn Example 3, we know from the Statdisk display that using the five pairs of data from \nTable 2-10, the linear correlation coefficient is computed to be r = 0.591. The value \nof r = 0.591 is not very close to 0 or 1, so based on that value and the displayed scat-\nterplot, it does not appear that there is a strong correlation between shoeprint lengths \nand heights of males.\nEXAMPLE 4   Correlation Between Shoe Print Lengths  \nand Heights?\nExample 3 used only five pairs of data from Data Set 7 “Foot and Height” in Appendix B. \nIf we use the shoe print lengths and heights from all of the 40 subjects listed in Data Set 7 \nin Appendix B, we get the scatterplot shown in Figure 2-16 and we get the Minitab results \nshown in the accompanying display. The scatterplot does show a distinct pattern instead of \nhaving points scattered about willy-nilly. Also, we see that the value of the linear correla-\ntion coefficient is r = 0.813. Because r = 0.813 is reasonably close to 1 and because of \nthe pattern of points in the scatterplot, it appears that there is a linear  correlation between \nshoe print lengths and heights.\nIn Example 3 with only five pairs of data, we did not have enough evidence to \nconclude that there is a linear correlation, but in this example with 40 pairs of data, it \ndoes appear that there is a linear correlation between shoe print lengths and heights.\nPART 3\n Regression \nWhen we do conclude that there appears to be a linear correlation between two vari-\nables (as in Example 4), we can find the equation of the straight line that best fits the \nsample data, and that equation can be used to predict the value of one variable when \ngiven a specific value of the other variable. Based on the results from Example 4, we \ncan predict someone’s height given the length of their shoe print (which may have \nbeen found at a crime scene).\nInstead of using the straight-line equation format of y = mx + b that we have all \nlearned in prior math courses, we use the format that follows.\nFIGURE 2-16 Scatterplot of 40 Pairs of Data\nMinitab\n",
    "2-4 Scatterplots, Correlation, and Regression \n69\nThe regression equation\nyn = b0 + b1x\nalgebraically describes the regression line.\nSection 10-2 gives a good reason for using the format of yn = b0 + b1x instead of \nthe format of y = mx + b. Section 10-2 also provides formulas that could be used to \nidentify the values of the y-intercept b0 and the slope b1, but those values are usually \nfound by using technology.\nDEFINITION\nGiven a collection of paired sample data, the regression line (or line of  best fit or \nleast-squares line) is the straight line that “best” fits the scatterplot of the data. (The \nspecific criterion for the “best”-fitting straight line is the “least squares” property \ndescribed in Section 10-2.)\nFIGURE 2-17 Regression Line\nEXAMPLE 5  Regression Line\nExample 4 included a scatterplot of the 40 pairs of shoe print lengths and heights \nfrom Data Set 7 “Foot and Height” in Appendix B. Figure 2-17 shown here is that \nsame scatterplot with the graph of the regression line included. Also shown is the \nStatdisk display from the 40 pairs of data.\nFrom the Statdisk display, we see that the general form of the regression equa-\ntion has a y-intercept of b0 = 80.9 (rounded) and slope b1 = 3.22 (rounded), so the \nequation of the regression line shown in Figure 2-17 is yn = 80.9 + 3.22x. It might \nbe helpful to express that equation more clearly by using the names of the variables:\nHeight = 80.9 + 3.22 1Shoe Print Length2\nNote that the equation shows the y-intercept of 80.9 that does not appear on the ver-\ntical scale in the graph. The leftmost vertical scale in Figure 2-19 is not the actual \ny-axis that passes through 0 on the x-axis. If the graph were extended to the left, the \nregression line would intercept the actual y-axis at the height of y = 80.9 cm.\nStatdisk\n",
    "70 \nCHAPTER 2 Exploring Data with Tables and Graphs\nStatistical Literacy and Critical Thinking\n1. Linear Correlation In this section we use r to denote the value of the linear correlation co-\nefficient. Why do we refer to this correlation coefficient as being linear?\n2. Causation A study has shown that there is a correlation between body weight and blood \npressure. Higher body weights are associated with higher blood pressure levels. Can we con-\nclude that gaining weight is a cause of increased blood pressure?\n3. Scatterplot What is a scatterplot and how does it help us?\n4. Estimating r For each of the following, estimate the value of the linear correlation coeffi-\ncient r for the given paired data obtained from 50 randomly selected adults.\na. Their heights are measured in inches (x) and those same heights are recorded in centimeters (y).\nb. Their IQ scores (x) are measured and their heights (y) are measured in centimeters.\nc. Their pulse rates (x) are measured and their IQ scores are measured (y).\nd. Their heights (x) are measured in centimeters and those same heights are listed again, but \nwith negative signs (y) preceding each of these second listings.\nScatterplot. In Exercises 5–8, use the sample data to construct a scatterplot. Use the first vari-\nable for the x-axis. Based on the scatterplot, what do you conclude about a linear correlation?\n5. Brain Volume and IQ The table lists brain volumes (cm3) and IQ scores of five males (from \nData Set 9 “IQ and Brain Size” in Appendix B).\nBrain volume (cm3)\n1173\n1067\n1347\n1029\n1204\nIQ\n 101\n  93\n  94\n  97\n 113\n6. Bear Measurements The table lists chest sizes (distance around chest in inches) and \nweights (pounds) of anesthetized bears that were measured (from Data Set 11 in Appendix B).\nChest (in.)\n26\n 45\n 54\n 49\n 35\n 41\n 41\nWeight (lb)\n80\n344\n416\n348\n166\n220\n262\n7. Body Temperatures The table lists body temperatures (°F) of seven healthy adults at 8 AM on \none day and at 8 AM  on the following day (from Data Set 2 “Body Temperatures” in Appendix B).\nDay 1  98.6  97.4  98.2  98.2  98.2  96.6  97.4\nDay 2  97.8  97.0  97.0  96.6  97.0  96.8  96.6\n8. Heights of Fathers and Sons The table lists heights (in.) of fathers and the heights (in.) of \ntheir first sons (from Francis Galton).\nHeight of father (in.)\n73.0\n75.5\n75.0\n75.0\n75.0\n74.0\n74.0\n73.0\n73.0\n78.5\nHeight of first son (in.)\n74.0\n73.5\n71.0\n70.5\n72.0\n76.5\n74.0\n71.0\n72.0\n73.2\nLinear Correlation Coefficient. In Exercises 9–12, the linear correlation coefficient r is \nprovided. What do you conclude about a linear correlation?\n9. Using the data from Exercise 5 “Brain Volume and IQ,” the linear correlation coefficient is \nr = 0.127.\n10. Using the data from Exercise 6 “Bear Measurements,” the linear correlation coefficient is \nr = 0.980.\n2-4 Basic Skills and Concepts\n",
    "11. Using the data from Exercise 7 “Body Temperatures,” the linear correlation coefficient is \nr = 0.520.\n12. Using the data from Exercise 8 “Heights of Fathers and Sons,” the linear correlation coef-\nficient is r = -0.017.\nChapter Quick Quiz\n1. BAC When constructing a table representing the frequency distribution of blood alcohol \ncontent (g>dL) of drunk drivers involved in fatal car crashes, the first two classes of a fre-\nquency distribution are 0.08 – 0.11 and 0.12 – 0.15. What is the class width?\n2. BAC Using the same first two classes from Exercise 1, identify the class boundaries of the \nfirst class.\n3. BAC The first class described in Exercise 1 has a frequency of 36. If you know only the class \nlimits given in Exercise 1 and the frequency of 36, can you identify the original 36 data values?\n4. BAC A stemplot is created from the ages of drunk drivers involved in fatal car crashes and \nthe first row is 1 | 67889. Identify the values represented by that row.\n5. Reaction Times A large sample is randomly selected from a normally distributed popula-\ntion of reaction times, and a histogram is constructed from a frequency distribution. What is the \nshape of the histogram?\n6. Tylenol In testing samples of regular Tylenol pills to verify that they have close to the de-\nsired amount of 325 mg of acetaminophen, which important characteristic of data is missing \nfrom this list: center, distribution, outliers, changes over time?\n7. Tylenol A quality control manager wants to monitor the production of regular Tylenol pills \nto be sure that the mean amount of acetaminophen does not change over time. Which of the fol-\nlowing graphs is most helpful for that purpose: histogram, Pareto chart, pie chart, scatterplot, \ntime-series graph, dotplot?\n8. Blood Pressure In an investigation of the relationship between systolic blood pressure and \ndiastolic blood pressure, which of the following graphs is most helpful: histogram; pie chart; \nscatterplot; stemplot; dotplot?\n9. Blood Pressure Thing The W. A. Baum Company manufactures sphygmomanometers \nused to measure blood pressure. Quality control managers at such companies monitor defects \nand identify various causes, including worn machinery, human error, bad supplies, and packag-\ning mistreatment. Which of the following graphs would be best for describing the causes of \ndefects: histogram, scatterplot, Pareto chart, dotplot, stemplot?\n10. Frequency Distribution and Histogram What is the basic difference between a fre-\nquency distribution and a histogram?\n1. Frequency Distribution of Body Temperatures Construct a frequency distribution of the \n20 body temperatures 1°F2 listed below. (These data are from Data Set 2 “Body Temperatures” \nin Appendix B.) Use a class width of 0.5°F and a starting value of 97.0°F.\n97.1 97.2 97.5 97.6 97.6 97.8 98.0 98.0 98.2 98.2\n98.2 98.3 98.4 98.6 98.6 98.7 98.7 98.9 99.1 99.4\nReview Exercises\nCHAPTER 2 Review Exercises \n71\n",
    "72 \nCHAPTER 2 Exploring Data with Tables and Graphs\n2. Histogram of Body Temperatures Construct the histogram that corresponds to the fre-\nquency distribution from Exercise 1. Use class midpoint values for the horizontal scale. Does \nthe histogram suggest that the data are from a population having a normal distribution? Why or \nwhy not?\n3. Dotplot of Body Temperatures Construct a dotplot of the body temperatures listed in \n Exercise 1. Which does a better job of illustrating the distribution of the data: the histogram \nfrom Exercise 2 or the dotplot?\n4. Stemplot of Body Temperatures Construct a stemplot of the body temperatures listed in \nExercise 1. Are there any outliers?\n5. Bears Listed below are the neck sizes (in.) and weights (lb) of bears (from Data Set 11 \n“Bear Measurements” in Appendix B). Construct a scatterplot. Based on the graph, does there \nappear to be a relationship between neck sizes and weights of bears?\nNeck Size (in.)   16   28   31   31.5   22   21   26.5    27   20   18\nWeight (lb)     80  344  416  348.0  166  220  262.0  360  204  144\n6. Monitoring Weight\na. After collecting the average (mean) weight of adult males in the United States for each of the \nmost recent 100 years, we want to construct the graph that is most appropriate for these data. \nWhich graph is best?\nb. After collecting the average (mean) weight and height of males for the most recent 100 years, \nwe want to construct a graph to investigate the association between those two variables. Which \ngraph is best?\nc. An investigation of health problems associated with overweight males includes heart dis-\nease, stroke, high blood pressure, diabetes, and breathing problems. If we want to construct a \ngraph that illustrates the relative importance of these adverse effects, which graph is best?\n7. Medical School Enrollees The accompanying graph illustrates male and female enrollees \nin U.S. medical schools in a recent year. What is wrong with the graph?\nCumulative Review Exercises\n1. Hygiene Listed below are times (minutes) spent on hygiene and grooming in the morning \nby randomly selected subjects (based on data from a Svenska Cellulosa Aktiebolaget survey). \nConstruct a table representing the frequency distribution. Use the classes 0–9, 10–19, and so on.\n0  5  12  15  15  20  22  24  25  25  25  27  27  28  30  30  35  35  40  45\n2. Hygiene Histogram Use the frequency distribution from Exercise 1 to construct a histo-\ngram. Use class midpoint values for the horizontal scale. Based on the result, do the data ap-\npear to be from a population with a normal distribution? Explain.\n3. Hygiene Stemplot Use the data from Exercise 1 to construct a stemplot.\n4. Analysis of Last Digits Use the data from Exercise 1 and construct a frequency distribution \nof the last digits of the grooming times. What does the result suggest about the grooming times?\n5. Hygiene Refer to the grooming times given in Exercise 1.\na. What is the level of measurement of those times? (nominal, ordinal, interval, ratio)\nb. Are the exact unrounded grooming times discrete data or continuous data?\nc. Are the grooming times categorical data?\nd. The average (mean) of the grooming times is 24.3 minutes. Is that value a statistic or a \n parameter?\n",
    "6. Mother, Daughter Heights Refer to the following list of heights of mothers and the heights \nof their first daughters (from Data Set 6 “Family Heights” in Appendix B). What issue would \nbe investigated with these data? Construct the best graph for investigating that issue. What does \nthat graph suggest?\nMother’s Height (in.)    67.0  66.5  64  64  58.5  68.0  62  66.5  65.0  64.5\nDaughter’s Height (in.)  69.2  65.5  68  67  66.5  70.5  68  66.7  68.7  66.5\nTechnology Project\nIt was stated in this chapter that the days of charming and primitive hand-drawn graphs are well \nbehind us, and technology now provides us with powerful tools for generating a wide variety of \ndifferent graphs. This project therefore serves as a good preparation for professional presenta-\ntions that will be inevitably made in the future.\nThe complete data sets in Appendix B can be downloaded from www.TriolaStats.com. \nThey can be opened by statistical software packages, such as Minitab, Excel, SPSS, and JMP. \nStatdisk already includes the data sets. Use a statistical software package to open Data Set 1 \n“Body Data.” Use this statistical software with the methods of this chapter to describe, explore, \nand compare the ages of males and females. Does there appear to be a difference? Reports \nof randomized clinical trials typically include “baseline characteristics” of the subjects in the \ndifferent groups so that we can see whether the groups are similar in ways that are important. \nBased on ages, do the males and females in Data Set 1 appear to be similar? (Later chapters \nwill present more formal methods for making such comparisons.)\nFROM DATA TO DECISION\nCar crash fatalities are tragic losses of lives and they are \ndevastating to the families involved. Listed below are the \nages of 100 randomly selected drivers who were killed in car \ncrashes. Also given is a frequency distribution of licensed \ndrivers by age (based on recent data from the Insurance Insti-\ntute for Highway Safety).\nAges (in years) of Drivers Killed in Car Crashes\n \nAge\nLicensed Drivers  \n(millions)\n41 43 38 31 57 29 65 18 42 47\n16–19\n 9.7\n69 50 22 60 30 30 34 18 18 42\n20–29\n33.6\n18 16 74 25 41 43 50 34 54 45\n30–39\n40.2\n32 20 50 36 27 59 19 23 57 74\n40–49\n40.3\n27 38 29 24 56 72 21 22 74 20\n50–59\n29.6\n43 34 38 62 39 45 56 70 68 75\n60–69\n18.3\n37 49 25 24 21 25 31 21 76 69\n70–79\n13.4\n28 62 69 26 22 62 64 24 56 70\n80–89\n 5.4\n21 52 32 30 38 73 35 52 38 29\n23 17 44 25 24 70 16 49 45 34\nAnalysis\nConvert the given frequency distribution to a relative fre-\nquency distribution, then create a relative frequency distri-\nbution using the 100 ages of drivers killed in car crashes. \nCompare the two relative frequency distributions. Which age \ncategories appear to have substantially greater proportions \nof fatalities than the proportions of licensed drivers? If you \nwere responsible for establishing the rates for auto insurance, \nwhich age categories would you select for higher rates? Con-\nstruct a graph that is effective in identifying age categories \nthat are more prone to fatal car crashes.\nCHAPTER 2 Technology Project \n73\n",
    "74 \nCHAPTER 2 Exploring Data with Tables and Graphs\nCooperative Group Activities\n1. In-class activity In class, each student should record two pulse rates by counting the \nnumber of heartbeats in 1 minute. The first pulse rate should be measured while the student \nis seated, and the second pulse rate should be measured while the student is standing. Us-\ning the pulse rates measured while seated, construct a frequency distribution and histogram \nfor the pulse rates of males, and then construct another frequency distribution and histo-\ngram for the pulse rates of females. Using the pulse rates measured while standing, construct \na frequency distribution and histogram for the pulse rates of males, and then construct another \nfrequency distribution and histogram for the pulse rates of females. Compare the results. Do \nmales and females appear to have different pulse rates? Do pulse rates measured while seated \nappear to be different from pulse rates measured while standing? Use an appropriate graph to \ndetermine whether there is a relationship between sitting pulse rate and standing pulse rate.\n2. In-class activity Given below are the ages of motorcyclists at the time they were fatally \ninjured in traffic accidents (based on data from the U.S. Department of Transportation). If your \nobjective is to dramatize the dangers of motorcycles for young people, which graph would be \nmost effective: histogram, Pareto chart, pie chart, dotplot, stemplot, frequency polygon, time-\nseries graph? Construct the graph that best meets that objective. Is it okay to deliberately distort \ndata if the objective is one such as saving lives of motorcyclists?\n17 38 27 14 18 34 16 42 28 24 40 20 23 31\n37 21 30 25 17 28 33 25 23 19 51 18 29\n3. Out-of-class activity In each group of three or four students, select one of the following \nitems and construct a graph that is effective in addressing the question:\na. Is there a difference between the body mass index (BMI) values for men and for women? \n(See Data Set 1 “Body Data” in Appendix B.)\nb. Is there a relationship between the heights of sons (or daughters) and the heights of their \nfathers (or mothers)? (See Data Set 6 “Family Heights” in Appendix B.)\n4. Out-of-class activity Search the Internet to find an example of a graph that is misleading. \nDescribe how the graph is misleading. Redraw the graph so that it depicts the information cor-\nrectly. If possible, please submit your graph to www.TriolaStats.com.\n5. Out-of-class activity Find Charles Joseph Minard’s graph describing Napoleon’s march to \nMoscow and back, and explain why Edward Tufte says that “it may well be the best graphic \never drawn.” (See The Visual Display of Quantitative Information by Edward Tufte, Graphics \nPress). Minard’s graph can be seen at www.TriolaStats.com under “Textbook Supplements.”\n6. Out-of-class activity In The Visual Display of Quantitative Information by Edward Tufte \n(Graphics Press), find the graph that appeared in American Education, and explain why Tufte \nsays that “this may well be the worst graphic ever to find its way into print.” The graph can be \nseen at www.TriolaStats.com under “Textbook Supplements.” Construct a graph that is effec-\ntive in depicting the same data.\n",
    "75\nCHAPTER \nPROBLEM\nData Set 1 “Body Data” in Appendix B includes pulse rates \nof men and women. The full data set contains measurements \nfrom 300 adults, and the first 5 cases are printed in Appendix B. \nFigure 3-1 shows dotplots of the pulse rates categorized ac-\ncording to gender. Close examination of Figure 3-1 reveals \nthat the pulse rates consist of even numbers only. This sug-\ngests that the pulse rates were measured for 30 seconds, \nand the result was doubled to provide a pulse rate in beats \nper minute. Examine Figure 3-1 closely to see that the pulse \nrates of males tend to be generally a little lower (farther to \nthe left) than the pulse rates of females. This observation \nsuggests a hypothesis: Males have lower pulse rates than \nfemales. A conclusion about such a hypothesis should not \nbe made on the basis of a graph alone. We should consider \nDo men and women have the same pulse rates?\nMeasures of Center\nMeasures of Variation\nMeasures of Relative \nStanding and Boxplots\n3-1\n3-2\n3-3\nDescribing, Exploring, \nand Comparing Data\n3 \n",
    ">>>\nwhether the sample data were collected with an appropriate \nmethod. We should also consider whether the apparent dif-\nference between male pulse rates and female pulse rates is \nactually a significant difference and not just a random chance \nanomaly.\nInstead of relying solely on subjective interpretations of a \ngraph like Figure 3-1, this chapter introduces measures that \nare essential to any study of statistics. This chapter introduces \nthe mean, median, standard deviation, and variance, which \nare among the most important statistics presented in this book, \nand they are among the most important statistics in the study \nof statistics. We will use these statistics for describing, explor-\ning, and comparing the measured pulse rates for males and \nfemales in Data Set 1 “Body Data.”\nCHAPTER OBJECTIVES\nCritical Thinking and Interpretation: Going Beyond Formulas and Arithmetic\nIn this modern biostatistics course, it isn’t so important to memorize formulas or manu-\nally do messy arithmetic. We can get results with a calculator or software so that we \ncan focus on making practical sense of results through critical thinking. Although this \nchapter includes detailed steps for important procedures, it isn’t always necessary to \nmaster those steps. It is, however, generally helpful to perform a few manual calcula-\ntions before using technology, so that understanding is enhanced.\nThe methods and tools presented in this chapter are often called methods of \ndescriptive statistics, because they summarize or describe relevant characteristics of \ndata. In later chapters we use inferential statistics to make inferences, or generaliza-\ntions, about populations. Here are the chapter objectives:\nMeasures of Center\n• Develop the ability to measure the center of data by finding the mean, median, \nmode, and midrange.\n• Determine whether an outlier has a substantial effect on the mean and median.\nMeasures of Variation\n• Develop the ability to measure variation in a set of sample data by finding values of \nthe range, variance, and standard deviation.\n3-1\n3-2\nFIGURE 3-1 Dotplot of Pulse Rates of Males and Females\n76 \nCHAPTER 3 Describing, Exploring, and Comparing Data\n",
    "3-1 Measures of Center \n77\nThere are different approaches for measuring the center, so we have different defi-\nnitions for those different approaches. We begin with the mean.\nMean\nThe mean (or arithmetic mean) is generally the most important of all numerical mea-\nsurements used to describe data, and it is what many people call an average.\nKey Concept The focus of this section is to obtain a value that measures the center of \na data set. We present measures of center, including mean and median. Our objective \nhere is not only to find the value of each measure of center, but also to interpret and \nmake sense of those values. Part 1 of this section includes core concepts that should \nbe understood before considering Part 2.\nPART 1\n Basic Concepts of Measures of Center \nIn Part 1 of this section, we introduce the mean, median, mode, and midrange as dif-\nferent measures of center. Measures of center are widely used to provide representa-\ntive values that “summarize” data sets.\n3-1 \nMeasures of Center\nDEFINITION\nA measure of center is a value at the center or middle of a data set.\nDEFINITION\nThe mean (or arithmetic mean) of a set of data is the measure of center found by \nadding all of the data values and dividing the total by the number of data values.\nImportant Properties of the Mean\n \n■Sample means drawn from the same population tend to vary less than other mea-\nsures of center.\n \n■The mean of a data set uses every data value.\n• Develop the ability to interpret values of the standard deviation by applying the \nrange rule of  thumb to determine whether a particular value is significantly low or \nsignificantly high.\nMeasures of Relative Standing and Boxplots\n• Develop the ability to compute a z score and use the result to determine whether a \ngiven value x is significantly low or significantly high.\n• Identify percentile values and quartile values from a set of data.\n• Develop the ability to construct a boxplot from a set of data.\n3-3\n• Develop the ability to interpret values of the standard deviation by applying the\nrange rule of  thumb to determine whether a particular value is significantly low or \nw\nsignificantly high.\nMeasures of Relative Standing and Boxplots\n• Develop the ability to compute a z score and use the result to determine whether a\nz z\ngiven value x is \nx\nsignificantly low or \nw\nsignificantly high.\n• Identify percentile\nrc\nr\nvalues and quartile values from a set of data.\n• Develop the ability to construct a boxplot from a set of data.\ncontinued\n",
    "78 \nCHAPTER 3 Describing, Exploring, and Comparing Data\nCalculation and Notation of the Mean\nThe definition of the mean can be expressed as Formula 3-1, in which the Greek letter \nΣ (uppercase sigma) indicates that the data values should be added, so Σ  x represents \nthe sum of all data values. The symbol n denotes the sample size, which is the number \nof data values.\nFORMULA 3-1\nMean = Σ  x\nn  d sum of all data values\nd number of data values\nIf the data are a sample from a population, the mean is denoted by x (pronounced \n“x-bar”); if the data are the entire population, the mean is denoted by m (lowercase \nGreek mu).\nDEFINITION\nA statistic is resistant if the presence of extreme values (outliers) does not cause it \nto change very much.\n \n■A disadvantage of the mean is that just one extreme value (outlier) can change \nthe value of the mean substantially. (Using the following definition, we say that \nthe mean is not resistant.)\nNOTATION Hint: Sample statistics are usually represented by English letters, \nsuch as x, and population parameters are usually represented by Greek letters, \nsuch as m.\nΣ \ndenotes the sum of a set of data values.\nx \nis the variable usually used to represent the individual data values.\nn \nrepresents the number of data values in a sample.\nN \nrepresents the number of data values in a population.\nx = Σ  x\nn  \nis the mean of a set of sample values.\nm = Σ  x\nN  \nis the mean of all values in a population.\nEXAMPLE 1  Mean\nData Set 1 “Body Data” in Appendix B includes measures of pulse rates. Find the \nmean of the first five pulse rates for males: 84, 74, 50, 60, 52 (all in beats per minute, \nor BPM).\nSOLUTION\nThe mean is computed by using Formula 3-1. First add the data values, then divide \nby the number of data values:\n x = Σx\nn\n= 84 + 74 + 50 + 60 + 52\n5\n= 320\n5\n = 64.0 BPM\nThe mean of the first five male pulse rates is 64.0 BPM.\n",
    "3-1 Measures of Center \n79\nMedian\nThe median can be thought of loosely as a “middle value” in the sense that about half \nof the values in a data set are less than the median and half are greater than the me-\ndian. The following definition is more precise.\nCAUTION Never use the term average when referring to a measure of center. \nThe word average is often used for the mean, but it is sometimes used for other \nmeasures of center. The term average is not used by statisticians, it is not used in \nprofessional journals, and it will not be used throughout the remainder of this book \nwhen referring to a specific measure of center.\nDEFINITION\nThe median of a data set is the measure of center that is the middle value when the \noriginal data values are arranged in order of increasing (or decreasing) magnitude.\nImportant Properties of the Median\n \n■The median does not change by large amounts when we include just a few ex-\ntreme values, so the median is a resistant measure of center.\n \n■The median does not directly use every data value. (For example, if the largest \nvalue is changed to a much larger value, the median does not change.)\nCalculation and Notation of the Median\nThe median of a sample is sometimes denoted by x∼ (pronounced “x-tilde”) or M or \nMed; there isn’t a commonly accepted notation and there isn’t a special symbol for \nthe median of a population. To find the median, first sort the values (arrange them in \norder), and then follow one of these two procedures:\n1. If the number of data values is odd, the median is the number located in the ex-\nact middle of the sorted list.\n2. If the number of data values is even, the median is found by computing the \nmean of the two middle numbers in the sorted list.\nEXAMPLE 2  Median with an Odd Number of Data Values\nFind the median of the first five pulse rates for males: 84, 74, 50, 60, 52 (all in \nBPM).\nSOLUTION\nFirst sort the data values by arranging them in ascending order, as shown below:\n50 52 60 74 84\nBecause there are 5 data values, the number of data values is an odd number (5), \nso the median is the number located in the exact middle of the sorted list, which is \n60.0 BPM. The median is therefore 60.0 BPM. Note that the median of 60.0 BPM \nis different from the mean of 64.0 BPM found in Example 1.\nWhat the Median Is Not\nHarvard  \nbiologist Ste-\nphen Jay Gould \nwrote, “The \nMedian Isn’t the \nMessage.” In \nit, he describes \nhow he learned that he had ab-\ndominal mesothelioma, a form of \ncancer. He went to the library to \nlearn more, and he was shocked \nto find that mesothelioma was \nincurable, with a median survival \ntime of only eight months after \nit was discovered. Gould wrote \nthis: “I suspect that most people, \nwithout training in statistics, \nwould read such a statement as \n‘I will probably be dead in eight \nmonths’ the very conclusion that \nmust be avoided, since it isn’t \nso, and since attitude (in fighting \nthe cancer) matters so much.” \nGould went on to carefully \ninterpret the value of the median. \nHe knew that his chance of liv-\ning longer than the median was \ngood because he was young, his \ncancer was diagnosed early, and \nhe would get the best medical \ntreatment. He also reasoned that \nsome could live much longer \nthan eight months, and he saw \nno reason why he could not be \nin that group. Armed with this \nthoughtful interpretation of the \nmedian and a strong positive \nattitude, Gould lived for 20 years \nafter his diagnosis. He died of \nanother cancer not related to the \nmesothelioma.\n",
    "80 \nCHAPTER 3 Describing, Exploring, and Comparing Data\nMode\nThe mode isn’t used much with quantitative data, but it’s the only measure of center \nthat can be used with qualitative data (consisting of names, labels, or categories only).\nEXAMPLE 3  Median with an Even Number of Data Values\nRepeat Example 2 after including the sixth pulse rate of 62 BPM. That is, find the \nmedian of these pulse rates: 84, 74, 50, 60, 52, 62 (all in BPM).\nSOLUTION\nFirst arrange the values in ascending order: 50, 52, 60, 62, 74, 84.\nBecause the number of data values is an even number (6), the median is found by \ncomputing the mean of the two middle numbers, which are 60 and 62.\nMedian = 60 + 62\n2\n= 122\n2\n= 61.0 BPM\nThe median is 61.0 BPM.\nDEFINITION\nThe mode of a data set is the value(s) that occurs with the greatest frequency.\nImportant Properties of the Mode\n \n■The mode can be found with qualitative data.\n \n■A data set can have no mode or one mode or multiple modes.\nFinding the Mode: A data set can have one mode, more than one mode, or no mode.\n \n■When two data values occur with the same greatest frequency, each one is a \nmode and the data set is said to be bimodal.\n \n■When more than two data values occur with the same greatest frequency, each is \na mode and the data set is said to be multimodal.\n \n■When no data value is repeated, we say that there is no mode.\nEXAMPLE 4  Mode\nFind the mode of these pulse rates (in BPM):\n58 58 58 58 60 60 62 64\nSOLUTION\nThe mode is 58 BPM, because it is the pulse rate occurring most often (four times).\nIn Example 4, the mode is a single value. Here are other possible circumstances:\nTwo modes:  The pulse rates (BPM) of 58, 58, 58, 60, 60, 60, 62, 64 have two \nmodes: 58 BPM and 60 BPM.\nNo mode: \n The pulse rates of 58, 60, 64, 68, 72 have no mode because no \nvalue is repeated.\n",
    "3-1 Measures of Center \n81\nMidrange\nAnother measure of center is the midrange.\nDEFINITION\nThe midrange of a data set is the measure of center that is the value midway be-\ntween the maximum and minimum values in the original data set. It is found by add-\ning the maximum data value to the minimum data value and then dividing the sum \nby 2, as in the following formula:\nMidrange = maximum data value + minimum data value\n2\nImportant Properties of the Midrange\n \n■Because the midrange uses only the maximum and minimum values, it is very \nsensitive to those extremes so the midrange is not resistant.\n \n■In practice, the midrange is rarely used, but it has three redeeming features:\n1. The midrange is very easy to compute.\n2. The midrange helps reinforce the very important point that there are several \ndifferent ways to define the center of a data set.\n3. The value of the midrange is sometimes used incorrectly for the median, so con-\nfusion can be reduced by clearly defining the midrange along with the median.\nEXAMPLE 5  Midrange\nFind the midrange of these five pulse rates for males used in Example 1: 84, 74, 50, \n60, 52 (BPM).\nSOLUTION\nThe midrange is found as follows:\n Midrange = maximum data value + minimum data value\n2\n = 84 + 50\n2\n= 67.0 BPM\nThe midrange is 67.0 BPM.\nRounding Measures of Center\nWhen calculating measures of center, we often need to round the result. We use the \nfollowing rule.\nROUND-OFF RULES FOR MEASURES OF CENTER:\n \n■For the mean, median, and midrange, carry one more decimal place than is \npresent in the original set of values.\n \n■For the mode, leave the value as is without rounding (because values of the \nmode are the same as some of the original data values).\n",
    "82 \nCHAPTER 3 Describing, Exploring, and Comparing Data\nWhen applying any rounding rules, round only the final answer, not intermedi-\nate values that occur during calculations. For example, the mean of 2, 3, and 5 is \n3.333333. . . , which is rounded to 3.3, which has one more decimal place than the origi-\nnal values of 2, 3, and 5. As another example, the mean of 80.4 and 80.6 is 80.50 (one \nmore decimal place than was used for the original values). Because the mode is one or \nmore of the original data values, we do not round values of the mode; we simply use \nthe same original values that are modes.\nCritical Thinking\nWe can always calculate measures of center from a sample of numbers, but we should \nalways think about whether it makes sense to do that. In Section 1-2 we noted that it \nmakes no sense to do numerical calculations with data at the nominal level of mea-\nsurement, because those data consist of names, labels, or categories only, so statistics \nsuch as the mean and median are meaningless for such data. We should also think \nabout the sampling method used to collect the data. If the sampling method is not \nsound, the statistics we obtain may be very misleading.\nEXAMPLE 6  Critical Thinking and Measures of Center\nEach of the following illustrates data for which the mean and median are not mean-\ningful statistics.\na. Zip codes of the hospitals in the United States. (The zip codes don’t measure \nor count anything. The numbers are just labels for geographic locations.)\n \nb. Ranks of selected medical schools: 2, 3, 7, 10, 14. (The ranks reﬂect an order-\ning, but they don’t measure or count anything.)\n \nc. Numbers on the jerseys of the starting defense for the Seattle Seahawks when \nthey won Super Bowl XLVIII: 31, 28, 41, 56, 25, 54, 69, 50, 91, 72, 29. (The \nnumbers on the football jerseys don’t measure or count anything; they are just \nsubstitutes for names.)\n \nd. Top 5 incomes of hospital chief executive oﬃcers. (Such “top 5” or “top 10” \nlists include data that are not at all representative of the larger population.)\n \ne. The 50 mean ages computed from the means in each of the 50 states. (If you \ncalculate the mean of those 50 values, the result is not the mean age of people \nin the entire United States. The population sizes of the 50 diﬀerent states must \nbe taken into account, as described in the weighted mean introduced in Part 2 \nof this section.)\nIn the spirit of describing, exploring, and comparing data, we provide Table 3-1, \nwhich summarizes the different measures of center for the 300 pulse rates referenced \nin the Chapter Problem. Figure 3-1 on page 76 suggests that males have lower pulse \nrates, and comparison of the means and medians in Table 3-1 also suggests that males \nhave lower pulse rates. The following chapters will describe other tools that can be \nused for an effective comparison.\n",
    "3-1 Measures of Center \n83\nPART 2\n Beyond the Basics of Measures of Center\nCalculating the Mean from a Frequency Distribution\nFormula 3-2 is the same calculation for the mean that was presented in Part 1, but it \nincorporates this approach: When working with data summarized in a frequency dis-\ntribution, we make calculations possible by pretending that all sample values in each \nclass are equal to the class midpoint. Formula 3-2 is not really a new concept; it is \nsimply a variation of Formula 3-1 for the mean.\nFORMULA 3-2 MEAN FROM A FREQUENCY DISTRIBUTION\nFirst multiply each frequency and\nclass midpoint; then add the products. \n T \nx = Σ 1f ·x2\nΣ f   1Result is an approximation2\n c \nSum of frequencies\n(equal to n)\nExample 7 illustrates the procedure for finding the mean from a frequency distribution.\nTABLE 3-1 Male and Female Pulse Rates\nMale\nFemale\nMean\n69.6\n  74.0\nMedian\n68.0\n  74.0\nMode\n    66\n72, 74, 82\nMidrange\n72.0\n  70.0\nEXAMPLE 7  Computing the Mean from a Frequency Distribution\nThe first two columns of Table 3-2 on the next page constitute a frequency distribution \nsummarizing the pulse rates from males in Data Set 1 “Body Data” from Appendix B. \nUse the frequency distribution in the first two columns to find the mean.\nSOLUTION\nRemember, when working with data summarized in a frequency distribution, we \nmake calculations possible by pretending that all sample values in each class are \nequal to the class midpoint. For example, see Table 3-2 and consider the first class \ninterval of 40–54 with a frequency of 15. We pretend that each of the 15 pulse rates \nis 47 (the class midpoint). With the pulse rate of 47 repeated 15 times, we have a \ntotal of 47 # 15 = 705, as shown in the last column of Table 3-2. We can then add \nthose results to find the sum of all sample values.\nThe bottom row of Table 3-2 shows the two components we need for the cal-\nculation of the mean (as in Formula 3-2): Σf = 153 and Σ1f # x2 =  10,611. We \ncalculate the mean using Formula 3-2 as follows:\nx = Σ1 f # x2\nΣf\n= 10,611\n153\n= 69.4 BPM\ncontinued\n",
    "84 \nCHAPTER 3 Describing, Exploring, and Comparing Data\nCalculating a Weighted Mean\nWhen different x data values are assigned different weights w, we can compute a \nweighted mean. Formula 3-3 can be used to compute the weighted mean.\nFORMULA 3-3\nWeighted mean: x = Σ(w # x)\nΣw\nFormula 3-3 tells us to first multiply each weight w by the corresponding value \nx, then to add the products, and then finally to divide that total by the sum of the \nweights, Σw.\nThe result of x = 69.4 BPM is an approximation because it is based on the use  \nof class midpoint values instead of the original list of pulse rates. The mean of \n69.6 BPM found by using all of the original pulse rates for males is a more accu-\nrate result.\nTABLE 3-2 Pulse Rates (BPM) of Males\nPulse Rate\nFrequency f\nClass Midpoint x\nf ~ x\n40–54\n15\n 47\n 705\n55–69\n63\n 62\n3906\n70–84\n62\n 77\n4774\n85–99\n11\n 92\n1012\n100–114\n 2\n107\n 214\nTotals:\n횺f =  153\n횺1f ~ x2 = 10,611\nEXAMPLE 8  Computing Grade-Point Average\nIn her first semester of college, a student of one of the authors took five courses. \nHer final grades along with the number of credits for each course were A (3 cred-\nits), A (4 credits), B (3 credits), C (3 credits), and F (1 credit). The grading system \nassigns quality points to letter grades as follows: A = 4; B = 3; C = 2; D = 1; \nF = 0. Compute her grade-point average.\nSOLUTION\nUse the numbers of credits as weights: w = 3, 4, 3, 3, 1. Replace the letter grades \nof A, A, B, C, and F with the corresponding quality points: x = 4, 4, 3, 2, and 0. \nWe now use Formula 3-3 as shown below. The result is a first-semester grade-point \naverage of 3.07. (In using the preceding round-off rule, the result should be rounded \nto 3.1, but it is common to round grade-point averages to two decimal places.)\n x = Σ1w # x2\nΣw\n = 13 * 42 + 14 * 42 + 13 * 32 + 13 * 22 + 11 * 02\n3 + 4 + 3 + 3 + 1\n = 43\n14 = 3.07\n",
    "3-1 Measures of Center \n85\nDescriptive Statistics\nAccess tech instructions, videos, and data sets at www.TriolaStats.com\nTECH CENTER \nStatistical Literacy and Critical Thinking \n1. Average A report includes a statement that the “average” Medical College Admission Test \n(MCAT) score of applicants to medical schools is 28.4. What is the role of the term average in \nstatistics? Should another term be used in place of average?\n2. What’s Wrong? The Centers for Disease Control and Prevention (CDC) publishes a list of \nsmoking rates in each state. If we add the 50 percentages and then divide by 50, we get 19.67%. \nIs the value of 19.67% the mean smoking rate for all of the United States? Why or why not?\n3. Measures of Center In what sense are the mean, median, mode, and midrange measures \nof “center”?\n4. Resistant Measures Here are five pulse rates (BPM) of females: 80, 94, 58, 66, 56. Find \nthe mean and median of these five values. Then find the mean and median after including a \nsixth value of 740, which is an outlier. (One of the female pulse rates is 74, but 740 is used here \nas an error resulting from an incorrect data entry.) Compare the two sets of results. How much \nwas the mean affected by the inclusion of the outlier? How much is the median affected by the \ninclusion of the outlier?\nCritical Thinking. Each of Exercises 5–16 involves some feature that is somewhat tricky. \nFind the (a) mean, (b) median, (c) mode, and (d) midrange, and then answer the given \nquestion.\n5. Charges for Births Data Set 3 “Births” in Appendix B includes total charges for births at \nfour hospitals in New York State, and the top 10 highest amounts (in dollars) are listed below. \nWhat do the results tell us about the population of all such charges?\n471,062 359,091 290,837 271,863 255,788\n247,477 232,782 197,912 183,271 155,857\n6. MCAT Score Listed below are mean MCAT scores listed in order by year, starting with the \nyear 2002. What important feature of the data is not revealed by any of the measures of center?\n27.0 26.8 27.1 27.3 27.4 27.7 28.1 27.9 28.3 28.2 28.3 28.4\n7. Football Player Numbers Listed below are the jersey numbers of 11 players randomly \nselected from the roster of the Seattle Seahawks when they won Super Bowl XLVIII. What do \nthe results tell us?\n89 91 55 7 20 99 25 81 19 82 60\n8. Football Player Weights Listed below are the weights in pounds of 11 players randomly \nselected from the roster of the Seattle Seahawks when they won Super Bowl XLVIII (the same \nplayers from the preceding exercise). Are the results likely to be representative of all National \nFootball League (NFL) players?\n189 254 235 225 190 305 195 202 190 252 305\n9.  Peas in a Pod Biologists conducted experiments to determine whether a deficiency \nof carbon dioxide in the soil affects the phenotypes of peas. Listed below are the pheno-\ntype codes, where 1 = smooth@yellow, 2 = smooth@green, 3 = wrinkled@yellow, and \n3-1 Basic Skills and Concepts\ncontinued\n",
    "86 \nCHAPTER 3 Describing, Exploring, and Comparing Data\n4 = wrinkled@green. Can the measures of center be obtained for these values? Do the results \nmake sense?\n2 1 1 1 1 1 1 4 1 2 2 1 2 3 3 2 3 1 3 1 3 1 3 2 2\n10. TV Prices A physician plans to buy a television for her large waiting room. Listed below \nare selling prices in dollars of TVs that are 60 inches or larger and rated as a “best buy” by \nConsumer Reports magazine. Are the resulting statistics representative of the population of all \nTVs that are 60 inches and larger? If you decide to buy one of these TVs, what statistic is most \nrelevant, other than the measures of central tendency?\n1800 1500 1200 1500 1400 1600 1500 950 1600 1150 1500 1750\n11. Cell Phone Radiation Listed below are the measured radiation absorption rates (in W>kg) \ncorresponding to these cell phones: iPhone 5S, BlackBerry Z30, Sanyo Vero, Optimus V, Droid \nRazr, Nokia N97, Samsung Vibrant, Sony Z750a, Kyocera Kona, LG G2, and Virgin Mobile \nSupreme. The data are from the Federal Communications Commission (FCC). The media often \nreport about the dangers of cell phone radiation as a cause of cancer. The FCC has a standard \nthat a cell phone absorption rate must be 1.6 W>kg or less. If you are planning to purchase a cell \nphone, are any of the measures of center the most important statistic? Is there another statistic \nthat is most relevant? If so, which one?\n1.18 1.41 1.49 1.04 1.45 0.74 0.89 1.42 1.45 0.51 1.38\n12. Caffeine in Soft Drinks Listed below are measured amounts of caffeine (mg per 12 oz \nof drink) obtained in one can from each of 20 brands (7-UP, A&W Root Beer, Cherry Coke, \n. . . , Tab). Are the statistics representative of the population of all cans of the same 20 brands \nconsumed by Americans?\n0 0 34 34 34 45 41 51 55 36 47 41 0 0 53 54 38 0 41 47\n13. Firefighter Fatalities Listed below are the numbers of heroic firefighters who lost their \nlives in the United States each year while fighting forest fires. The numbers are listed in order \nby year, starting with the year 2000. What important feature of the data is not revealed by any \nof the measures of center?\n20 18 23 30 20 12 24 9 25 15 8 11 15 34\n14. Foot Lengths Listed below are foot lengths in inches of randomly selected Army women \nmeasured in the 1988 Anthropometric Survey (ANSUR). Are the statistics representative of the \ncurrent population of all Army women?\n10.4 9.3 9.1 9.3 10.0 9.4 8.6 9.8 9.9 9.1 9.1\n15. Medical School Tuition Listed below in dollars are the annual costs of tuition at the 10 \nmost expensive private medical schools in the United States for a recent year (based on data \nfrom U.S. News & World Report). What does this “top 10” list tell us about those costs for the \npopulation of all U.S. private medical school tuitions?\n57,261 56,784 55,196 54,976 54,653 54,528 54,268 54,050 53,581 53,323\n16. California Smokers In the California Health Interview Survey, randomly selected adults \nare interviewed. One of the questions asks how many cigarettes are smoked per day, and results \nare listed below for 50 randomly selected respondents. How well do the results reflect the \nsmoking behavior of California adults?\n9\n10\n10\n20\n40\n50\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n",
    "3-1 Measures of Center \n87\nIn Exercises 17–20, find the mean and median for each of the two samples, then compare \nthe two sets of results.\n17.  Blood Pressure A sample of blood pressure measurements is taken from Data Set \n1 “Body Data” in Appendix B, and those values (mm Hg) are listed below. The values are \nmatched so that 10 subjects each have systolic and diastolic measurements. (Systolic is a mea-\nsure of the force of blood being pushed through arteries, but diastolic is a measure of blood \npressure when the heart is at rest between beats.) Are the measures of center the best statistics \nto use with these data? What else might be better?\nSystolic:\n118\n128\n158\n96\n156\n122\n116\n136\n126\n120\nDiastolic:\n 80\n 76\n 74\n52\n 90\n 88\n 58\n 64\n 72\n 82\n18. White>Red Blood Counts Listed below are white blood cell counts (1000 cells>mL) \nand red blood cell counts (million cells>mL) from different subjects (from Data Set 1 “Body \nData” in Appendix B). The values are matched so that each of the 12 subjects has a white blood \ncell count and a red blood cell count. Are the measures of center the best statistics to use with \nthese data? What else might be better?\nWhite:\n8.7\n4.9\n6.9\n7.5\n6.1\n5.7\n4.1\n8.1\n8.0\n5.6\n8.3\n6.9\nRed:\n4.8\n4.7\n4.5\n4.3\n5.0\n4.0\n4.7\n4.6\n4.1\n5.5\n4.4\n4.2\n19. White Blood Counts Listed below are white blood cell counts (1000 cells>mL) from \nmales and females (from Data Set 1 “Body Data” in Appendix B). Do they appear to be  different?\nFemale:\n8.7\n6.9\n8.1\n8.0\n6.9\n8.1\n6.4\n6.3\n10.9\n4.8\n5.9\n7.2\nMale:\n4.9\n7.5\n6.1\n5.7\n4.1\n5.6\n8.3\n5.1\n 9.5\n6.1\n5.7\n5.4\n20. Queues A Providence Hospital experiment involves two different waiting line configura-\ntions for patients arriving for admission. The waiting times (in seconds) are recorded with a \nsingle line configuration that feeds four stations and another configuration with individual lines \nat the four stations. Determine whether there is a difference between the two data sets that is \nnot apparent from a comparison of the measures of center. If so, what is it?\nSingle Line\n390\n396\n402\n408\n426\n438\n444\n462\n462\n462\nIndividual Lines\n252\n324\n348\n372\n402\n462\n462\n510\n558\n600\nLarge Data Sets from Appendix B. In Exercises 21–24, refer to the indicated data set in \nAppendix B. Use software or a calculator to find the means and medians.\n21. HDL Use the high-density lipoprotein (HDL) cholesterol measurements (mg>dL) from the \n300 subjects included in Data Set 1 “Body Data” in Appendix B. Identify the highest value. \nDoes it appear to be an outlier? Do the mean and median change much when that highest value \nis deleted?\n22. LDL Repeat the preceding exercise using the low-density lipoprotein (LDL) measurements \n(mg>dL).\n23. Body Temperatures Refer to Data Set 2 “Body Temperatures” in Appendix B and use \nthe body temperatures for 12:00 AM on day 2. Do the results support or contradict the common \nbelief that the mean body temperature is 98.6oF?\n24. Births Use the birth weights (grams) of the 400 babies listed in Data Set 3 “Births” in \n Appendix B. Examine the list of birth weights to make an observation about those numbers. \nHow does that observation affect the way that the results should be rounded?\n",
    "88 \nCHAPTER 3 Describing, Exploring, and Comparing Data\nIn Exercises 25 and 26, find the mean of the data summarized in the frequency distribution. \nAlso, compare the computed means to the actual means obtained by using the original list \nof data values, which are as follows: (Exercise 25) 224.3; (Exercise 26) 255.1.\n25. \nBlood Platelet \nCount of Males\n \nFrequency\n 0–99\n 1\n100–199\n51\n200–299\n90\n300–399\n10\n400–499\n 0\n500–599\n 0\n600–699\n 1\n26. \nBlood Platelet Count \nof Females\n \nFrequency\n100–199\n25\n200–299\n92\n300–399\n28\n400–499\n 0\n500–599\n 2\n27. Weighted Mean A student of one of the authors earned grades of A, C, B, A, and D. \nThose courses had these corresponding numbers of credit hours: 3, 3, 3, 4, and 1. The grad-\ning system assigns quality points to letter grades as follows: A = 4; B = 3; C = 2; D = 1;\nF = 0. Compute the grade-point average (GPA) and round the result with two decimal places. \nIf the dean’s list requires a GPA of 3.00 or greater, did this student make the dean’s list?\n28. Weighted Mean A student of one of the authors earned grades of 63, 91, 88, 84, and 79 \non her five regular statistics tests. She earned a grade of 86 on the final exam and 90 on her \nclass projects. Her combined homework grade was 70. The five regular tests count for 60% \nof the final grade, the final exam counts for 10%, the project counts for 15%, and homework \ncounts for 15%. What is her weighted mean grade? What letter grade did she earn (A, B, C, D, \nor F)? Assume that a mean of 90 or above is an A, a mean of 80 to 89 is a B, and so on.\n29. Degrees of Freedom Five pulse rates randomly selected from Data Set 1 “Body Data” in \nAppendix B have a mean of 78.0 beats per minute. Four of the pulse rates are 82, 78, 56, and 84.\na. Find the missing value.\nb. We need to create a list of n values that have a specific known mean. We are free to select \nany values we desire for some of the n values. How many of the n values can be freely assigned \nbefore the remaining values are determined? (The result is referred to as the number of degrees \nof freedom.)\n30. Censored Data Recently, five U.S. presidents were still alive and after their first inaugura-\ntion, they have lived 37 years, 25 years, 21 years, 13 years, and 5 years so far. We might use the \nvalues of 37+, 25+, 21+, 13+, and 5+, where the positive signs indicate that the actual value \nis equal to or greater than the current value. (These values are said to be censored at the current \ntime that this list was compiled.) If we ignore the presidents who took office because of an as-\nsassination or resignation and if we ignore the five presidents who are still alive, the mean of \nthe 33 remaining presidents is 15.0 years. What do we know about the mean if we include the \ncensored values of 37+, 25+, 21+, 13+, and 5+? Do the two results differ by much?\n31. Trimmed Mean Because the mean is very sensitive to extreme values, we say that it is \nnot a resistant measure of center. By deleting some low values and high values, the trimmed \nmean (or truncated mean) is more resistant. To find the 10% trimmed mean for a data set, first \narrange the data in order, next delete the bottom 10% of the values and delete the top 10% of \nthe values, and then calculate the mean of the remaining values. Use the LDL measurements \nof the 300 subjects from Data Set 1 “Body Data” in Appendix B. Compare the mean, the 10% \ntrimmed mean, and the 20% trimmed mean.\n3-1 Beyond the Basics\n",
    "3-2 Measures of Variation \n89\nPART 1\nBasic Concepts of Variation \nTo visualize the property of variation, see Figure 3-2, which illustrates pulse rates \n(beats per minute or BPM) for subjects given a treatment and subjects given a pla-\ncebo. (A high priority is placed on using real data, but these pulse rates are fabricated \nfor the purposes of making an important point here.) Verify this important observa-\ntion: The pulse rates in the treatment group (top dotplot) have more variation than \nthose in the placebo group (bottom dotplot). Both sets of pulse rates have the same \nmean of 70.2 BPM, they have the same median of 70.0 BPM, and they have the same \nmode of 70 BPM. Those measures of center do not “see” the difference in variation.\nTo keep our round-off rules as consistent and as simple as possible, we will round \nthe measures of variation using this rule:\nKey Concept Variation is the single most important topic in statistics, so this is the \nsingle most important section in this book. This section presents three important \nmeasures of variation: range, standard deviation, and variance. These statistics are \nnumbers, but our focus is not just computing those numbers but developing the abil-\nity to interpret and understand them. This section is not a study of arithmetic; it is \nabout understanding and interpreting measures of variation, especially the standard \ndeviation.\n3-2 \nMeasures of Variation\nSTUDY HINT: Part 1 of this section presents basic concepts of variation, and \nPart 2 presents additional concepts related to the standard deviation. Part 1 \nand Part 2 both include formulas for computation, but do not spend too much \ntime memorizing formulas or doing arithmetic calculations. Instead, focus on \nunderstanding and interpreting values of standard deviation.\nROUND-OFF RULE FOR MEASURES OF VARIATION When rounding the value \nof a measure of variation, carry one more decimal place than is present in the \noriginal set of data.\nFIGURE 3-2 Dotplots of Pulse Rates\n",
    "90 \nCHAPTER 3 Describing, Exploring, and Comparing Data\nRange\nLet’s begin with the range because it is quick and easy to compute, but it is not as im-\nportant as other measures of variation.\nDEFINITION\nThe range of a set of data values is the difference between the maximum data \nvalue and the minimum data value.\nRange =  1maximum data value2 − 1minimum data value2\nImportant Properties of the Range\n \n■The range uses only the maximum and the minimum data values, so it is very \nsensitive to extreme values. The range is not resistant.\n \n■Because the range uses only the maximum and minimum values, it does not take \nevery value into account and therefore does not truly reflect the variation among \nall of the data values.\nEXAMPLE 1  Range\nFind the range of the first five pulse rates for males from Data Set 1 “Body Data” in \nAppendix B: 84, 74, 50, 60, 52 (all in BPM).\nSOLUTION\nThe range is found by subtracting the lowest value from the largest value, so we get\nRange = 1maximum value2 - 1minimum value2 = 84 - 50 = 34.0 BPM\nThe range of 34.0 BPM is shown with one more decimal place than is present in the \noriginal data values.\nStandard Deviation of a Sample\nThe standard deviation is the measure of variation most commonly used in statistics.\nDEFINITION\nThe standard deviation of a set of sample values, denoted by s, is a measure  \nof how much data values deviate away from the mean. It is calculated by using  \nFormula 3-4 or 3-5. Formula 3-5 is just a different version of Formula 3-4; both for-\nmulas are algebraically the same.\nThe standard deviation found from sample data is a statistic denoted by s, but the stan-\ndard deviation found from population data is a parameter denoted by s. The formula \nfor s is slightly different with division by the population size N used instead of divi-\nsion by n - 1. The population standard deviation s will be discussed later.\nNotation\ns = sample standard deviation\ns = population standard deviation\nR\nL\np\nGot a Second?\nThe time unit \nof 1 second \nis defined \nto be “the \nduration of \n9,192,631,770 \nperiods of the \nradiation corresponding to the \ntransition between the two hy-\nperfine levels of the ground state \nof the cesium-133 atom.” That \ndefinition redefines time to be \nbased on the behavior of atoms \ninstead of the earth’s motion. It \nresults in accuracy of ±1 second \nin 10,000,000 years, which is the \nmost accurate measurement we \nuse. Because it is so accurate, the \nsecond is being used to define \nother quantities, such as the me-\nter. The meter was once defined \nas 1>10,000,000 of the distance \nalong the surface of the earth \nbetween the North Pole and the \nequator (passing through Paris). \nThe meter is now defined as the \nlength of the distance traveled by \nlight in a vacuum during a time \ninterval of 1>299,792,458 sec.\nWhen dealing with time mea-\nsurement devices, the traditional \nstandard deviation has been \nfound to be poor because of a \ntrend in which the mean changes \nover time. Instead, other special \nmeasures of variation are used, \nsuch as Allan variance, total vari-\nance, and TheoH.\nUnrelated to statistics but \nnonetheless interesting is the \nfact that ads for watches usually \nshow a watch with a time close \nto 10:10. That time allows the \nbrand name to be visible, and it \ncreates a subliminal image of a \nhappy face. The time of 10:10 \nhas been the industry standard \nsince the 1940s.\n",
    "3-2 Measures of Variation \n91\nFORMULA 3-4\ns = B\nΣ1x - x2 2\nn - 1\n sample standard deviation\nFORMULA 3-5\ns = B\nn1Σ  x22 - 1Σ  x2 2\nn1n - 12\n shortcut formula for sample standard\n  deviation (used by calculators and software)\nLater we give the reasoning behind these formulas, but for now we recommend \nthat you use Formula 3-4 for an example or two, and then learn how to find standard \ndeviation values using a calculator or software.\nImportant Properties of Standard Deviation\n \n■The standard deviation is a measure of how much data values deviate away from \nthe mean.\n \n■The value of the standard deviation s is never negative. It is zero only when all of \nthe data values are exactly the same.\n \n■Larger values of s indicate greater amounts of variation.\n \n■The standard deviation s can increase dramatically with one or more outliers.\n \n■The units of the standard deviation s (such as minutes, feet, pounds) are the same \nas the units of the original data values.\n \n■The sample standard deviation s is a biased estimator of the population standard \ndeviation s, which means that values of the sample standard deviation s do not \ncenter around the value of s. (This is explained in Part 2.)\nExample 2 illustrates a calculation using Formula 3-4 because that formula better \nillustrates that the standard deviation is based on deviations of sample values away \nfrom the mean.\nEXAMPLE 2  Calculating Standard Deviation with Formula 3-4\nUse Formula 3-4 to find the standard deviation of the first five pulse rates for males \nfrom Data Set 1 “Body Data” in Appendix B: 84, 74, 50, 60, 52 (all in BPM).\nSOLUTION\nThe left column of Table 3-3 on the next page summarizes the general procedure \nfor finding the standard deviation using Formula 3-4, and the right column illus-\ntrates that procedure using the sample values 84, 74, 50, 60, 52. The result shown \nin Table 3-3 is 14.6 BPM, which is rounded to one more decimal place than is \npresent in the original list of sample values. Also, the units for the standard devia-\ntion are the same as the units of the original data. Because the original data values \nare all in units of BPM, the standard deviation is 14.6 BPM.\nVariation in Faces\nResearchers \ncommented \nthat “if everyone \nlooked more or \nless the same, \nthere would be \ntotal chaos.” \nThey studied \nhuman body measurements and \nfound that facial traits varied \nmore than other body traits, \nand the greatest variation oc-\ncurred within the triangle formed \nby the eyes and mouth. They \nlearned that facial traits vary \nindependently of each other. For \nexample, there is no relationship \nbetween the distance between \nyour eyes and how big your \nmouth is. The researchers stated \nthat our facial variation played an \nimportant role in human evolu-\ntion. (See “Morphological and \nPopulation Genomic Evidence \nThat Human Faces Have Evolved \nto Signal Individual Identity,” by \nSheehan and Nachman, Nature \nCommunications, Vol. 5,  \nNo. 4800.)\n",
    "92 \nCHAPTER 3 Describing, Exploring, and Comparing Data\nTABLE 3-3\nGeneral Procedure for Finding Standard  \nDeviation with Formula 3-4\nSpecific Example Using These Sample  \nValues: 84, 74, 50, 60, 52\nStep 1: Compute the mean x.\nThe sum of 84, 74, 50, 60, 52 is 320; therefore:\n x = Σ  x\nn\n= 84 + 74 + 50 + 60 + 52\n5\n = 320\n5\n= 64.0\nStep 2: Subtract the mean from each individual \nsample value. [The result is a list of deviations \nof the form 1x - x2.]\nSubtract the mean of 64.0 from each sample \nvalue to get these deviations away from the \nmean: 20, 10, −14, −4, −12.\nStep 3: Square each of the deviations obtained \nfrom Step 2. [This produces numbers of the \nform 1x - x2 2.]\nThe squares of the deviations from Step 2 are: \n400, 100, 196, 16, 144.\nStep 4: Add all of the squares obtained from \nStep 3. The result is Σ1x - x2 2.\nThe sum of the squares from Step 3 is 856.\nStep 5: Divide the total from Step 4 by the num-\nber n - 1, which is 1 less than the total number \nof sample values present.\nWith n = 5 data values, n - 1 = 4, so we \ndivide 856 by 4 to get this result:\n856\n4\n= 214\nStep 6: Find the square root of the result of \nStep 5. The result is the standard deviation, \ndenoted by s.\nThe standard deviation is 2214 = 14.6287. \nRounding the result, we get s = 14.6 BPM.\nEXAMPLE 3  Calculating Standard Deviation with Formula 3-5\nUse Formula 3-5 to find the standard deviation of the first five pulse rates of males \nfrom Data Set 1 “Body Data”: 84, 74, 50, 60, 52.\nSOLUTION\nHere are the components needed in Formula 3-5.\nn = 5 (because there are 5 values in the sample)\nΣ  x = 320 (found by adding the original sample values)\nΣ  x2 = 21,336 (found by adding the squares of the sample values, as in\n842 + 742 + 502 + 602 + 522 = 21,336)\nUsing Formula 3-5, we get\ns = B\nn1Σ  x22 - 1Σ  x2 2\nn1n - 12\n= B\n5121,3362 - 13202 2\n515 - 12\n= B\n4280\n20\n= 14.6 BPM\nThe result of s = 14.6 BPM is the same as the result in Example 2.\nRange Rule of Thumb for Understanding Standard Deviation\nThe range rule of thumb is a crude but simple tool for understanding and interpreting \nstandard deviation. It is based on the principle that for many data sets, the vast major-\nity (such as 95%) of sample values lie within 2 standard deviations of the mean. We \ncould improve the accuracy of this rule by taking into account such factors as the size \nof the sample and the distribution, but here we sacrifice accuracy for the sake of sim-\nplicity. The concept of significance as given below will be enhanced in later chapters, \nespecially those that include the topic of hypothesis tests, which are also called tests \n",
    "3-2 Measures of Variation \n93\nof significance. The following range rule of thumb is based on the population mean m\nand the population standard deviation s, but for large and representative samples, we \ncould use x and s instead.\nRange Rule of Thumb for Identifying Significant Values\nSigniﬁcantly low values are m - 2s or lower.\nSignificantly high values are m + 2s or higher.\nValues not signiﬁcant: Between 1m - 2s2 and 1m + 2s2\nSee Figure 3-3, which illustrates the above criteria.\nValues not signiﬁcant\nSigniﬁcantly\nlow values\nSigniﬁcantly\nhigh values\nm\nm − 2s\nm + 2s\nFIGURE 3-3  Range Rule of Thumb for Identifying \nSignificant Values\nRange Rule of Thumb for Estimating a Value of the Standard Deviation s\nTo roughly estimate the standard deviation from a collection of known sample \ndata, use\ns ≈range\n4\nEXAMPLE 4  Range Rule of Thumb for Interpreting s\nUsing the 153 pulse rates of males listed in Data Set 1 “Body Data” in Appendix B, \nthe mean is x = 69.6 BPM and the standard deviation is s = 11.3 BPM. Use x and \ns as estimates of m and s, and use the range rule of thumb to find the limits separat-\ning values that are significantly low or significantly high. Then determine whether a \nmale pulse rate of 100 BPM is significantly high.\nSOLUTION\nWith a mean of 69.6 and a standard deviation of 11.3, we use the range rule of \nthumb to find values that are significantly low or significantly high as follows:\nSignificantly low values are 169.6 - 2 * 11.32 or lower, \nso significantly low values are 47.0 BPM or lower.\nSignificantly high values are 169.6 + 2 * 11.32 or higher, \nso significantly high values are 92.2 BPM or higher.\nValues not significant: Between 47.0 and 92.2 BPM\nINTERPRETATION\nBased on these results, we expect that typical pulse rates of males are between \n47.0 BPM and 92.2 BPM. Because the given value of 100 BPM falls above \n92.2 BPM, we consider it to be a significantly high pulse rate for a male.\n",
    "94 \nCHAPTER 3 Describing, Exploring, and Comparing Data\nStandard Deviation of a Population\nThe definition of standard deviation and Formulas 3-4 and 3-5 apply to the standard \ndeviation of sample data. A slightly different formula is used to calculate the standard \ndeviation s (lowercase sigma) of a population: Instead of dividing by n - 1, we di-\nvide by the population size N, as shown here:\nPopulation standard deviation s = B\nΣ1x - m2 2\nN\nBecause we generally deal with sample data, we will usually use Formula 3-4, in \nwhich we divide by n - 1. Many calculators give both the sample standard deviation \nand the population standard deviation, but they use a variety of different notations.\nEXAMPLE 5  Range Rule of Thumb for Estimating s\nUse the range rule of thumb to estimate the standard deviation of the sample of \n153 pulse rates of males listed in Data Set 1 “Body Data” in Appendix B. Those \n153 values have a minimum of 40 BPM and a maximum of 104 BPM.\nSOLUTION\nThe range rule of thumb indicates that we can estimate the standard deviation by \nfinding the range and dividing it by 4. With a minimum of 40 BPM and a maximum \nof 104 BPM, the range rule of thumb can be used to estimate the standard deviation \ns as follows:\ns ≈range\n4\n= 104 - 40\n4\n= 16.0 BPM\nINTERPRETATION\nThe actual value of the standard deviation is s = 11.3 BPM, so the estimate of \n16.0 BPM is very roughly in the general neighborhood of the exact result. Because \nthis estimate is based on only the minimum and maximum values, it might be off by \na considerable amount.\nCAUTION When using a calculator to find standard deviation, identify the notation \nused by your particular calculator so that you get the sample standard deviation, \nnot the population standard deviation.\nVariance of a Sample and a Population\nSo far, we have used the term variation as a general description of the amount that val-\nues vary among themselves. (The terms dispersion and spread are sometimes used in-\nstead of variation.) Unlike the term variation, the term variance has a specific meaning.\nDEFINITION\nThe variance of a set of values is a measure of variation equal to the square of the \nstandard deviation.\n•  Sample variance: s2 =  square of the standard deviation s.\n•  Population variance: s2 =  square of the population standard deviation s.\n",
    "3-2 Measures of Variation \n95\nNotation Here is a summary of notation for the standard deviation and variance:\ns = sample standard deviation\ns2 = sample variance\ns = population standard deviation\ns2 = population variance\nNote: Articles in professional journals and reports often use SD for standard deviation \nand VAR for variance.\nImportant Properties of Variance\n \n■The units of the variance are the squares of the units of the original data values. \n(If the original data values are in feet, the variance will have units of ft2; if the \noriginal data values are in seconds, the variance will have units of  sec2.)\n \n■The value of the variance can increase dramatically with the inclusion of outliers. \n(The variance is not resistant.)\n \n■The value of the variance is never negative. It is zero only when all of the data \nvalues are the same number.\n \n■The sample variance s2 is an unbiased estimator of the population variance s2, \nas described in Part 2 of this section. (The sample standard deviation s is a biased \nestimator of the population standard deviation s.)\nThe variance is a statistic used in some statistical methods, but for our present pur-\nposes, the variance has the serious disadvantage of using units that are different than \nthe units of the original data set. This makes it difficult to understand variance as it \nrelates to the original data set. Because of this property, it is better to first focus on the \nstandard deviation when trying to develop an understanding of variation.\nPART 2\nBeyond the Basics of Variation\nIn Part 2, we focus on making sense of the standard deviation so that it is not some \nmysterious number devoid of any practical significance. We begin by addressing com-\nmon questions that relate to the standard deviation.\nWhy Is Standard Deviation Defined as in Formula 3-4?\nIn measuring variation in a set of sample data, it makes sense to begin with the indi-\nvidual amounts by which values deviate from the mean. For a particular data value x, \nthe amount of deviation is x - x. It makes sense to somehow combine those devia-\ntions into one number that can serve as a measure of the variation. Adding the devia-\ntions isn’t good, because the sum will always be zero. To get a statistic that measures \nvariation, it’s necessary to avoid the canceling out of negative and positive numbers. \nOne approach is to add absolute values, as in Σ\u001ax - x \u001a. If we find the mean of that \nsum, we get the mean absolute deviation (or MAD), which is the mean distance of \nthe data from the mean:\nMean absolute deviation = Σ\u001ax - x \u001a\nn\nWhy Not Use the Mean Absolute Deviation Instead of the Standard \nDeviation? Computation of the mean absolute deviation uses absolute values, \nso it uses an operation that is not “algebraic.” (The algebraic operations include \n",
    "96 \nCHAPTER 3 Describing, Exploring, and Comparing Data\naddition, multiplication, extracting roots, and raising to powers that are integers \nor fractions.) The use of absolute values would be simple, but it would create \nalgebraic difficulties in inferential methods of statistics discussed in later chap-\nters. The standard deviation has the advantage of using only algebraic opera-\ntions. Because it is based on the square root of a sum of squares, the standard \ndeviation closely parallels distance formulas found in algebra. There are many \ninstances where a statistical procedure is based on a similar sum of squares. \nConsequently, instead of using absolute values, we square all deviations 1x - x2\nso that they are nonnegative, and those squares are used to calculate the standard \ndeviation.\nWhy Divide by n −1? After finding all of the individual values of 1x - x2 2 we \ncombine them by finding their sum. We then divide by n - 1 because there are only \nn - 1 values that can assigned without constraint. With a given mean, we can use any \nnumbers for the first n - 1 values, but the last value will then be automatically deter-\nmined. With division by n - 1, sample variances s2 tend to center around the value of \nthe population variance s2; with division by n, sample variances s2 tend to underesti-\nmate the value of the population variance s2.\nComparing Variation in Different Samples or Populations\nIt’s a good practice to compare two sample standard deviations only when the sample \nmeans are approximately the same. When comparing variation in samples or popula-\ntions with very different means, it is better to use the coefficient of variation. Also use \nthe coefficient of variation to compare variation from two samples or populations with \ndifferent scales or units of values, such as the comparison of variation of pulse rates of \nmen and heights of men. (See Example 6.)\nDEFINITION\nThe coefficient of variation (or CV) for a set of nonnegative sample or popula-\ntion data, expressed as a percent, describes the standard deviation relative to the \nmean, and is given by the following:\n \nSample \nPopulation\n \nCV = s\nx # 100% \nCV = s\nm # 100%\nROUND-OFF RULE FOR THE COEFFICIENT OF VARIATION Round the \ncoefficient of variation to one decimal place (such as 25.3%).\nEXAMPLE 6  Pulse Rates and Heights\nCompare the variation of the 153 male pulse rates listed in Data Set 1 “Body \nData” in Appendix B and the heights of the same males. For the male pulse \nrates, x = 69.6 BPM and s = 11.3 BPM; for their heights, x = 174.12 cm and \ns = 7.10 cm. Note that we want to compare variation among pulse rates to varia-\ntion among heights.\n",
    "3-2 Measures of Variation \n97\nBiased and Unbiased Estimators\nThe sample standard deviation s is a biased estimator of the population standard de-\nviation s, which means that values of the sample standard deviation s do not tend \nto center around the value of the population standard deviation s. While individual \nvalues of s could equal or exceed s, values of s generally tend to underestimate the \nvalue of s. For example, consider an IQ test designed so that the population standard \ndeviation is 15. If you repeat the process of randomly selecting 100 subjects, giving \nthem IQ tests, and calculating the sample standard deviation s in each case, the sample \nstandard deviations that you get will tend to be less than 15, which is the population \nstandard deviation. There is no correction that allows us to fix the bias for all distribu-\ntions of data. There is a correction that allows us to fix the bias for normally distrib-\nuted populations, but it is rarely used because it is too complex and makes relatively \nminor corrections.\nThe sample variance s2 is an unbiased estimator of the population variance s2,\nwhich means that values of s2 tend to center around the value of s2 instead of system-\natically tending to overestimate or underestimate s2. Consider an IQ test designed so \nthat the population variance is 225. If you repeat the process of randomly selecting \n100 subjects, giving them IQ tests, and calculating the sample variance s2 in each \ncase, the sample variances that you obtain will tend to center around 225, which is the \npopulation variance.\nBiased estimators and unbiased estimators will be discussed more in Section 6-3.\nSOLUTION\nWe can compare the standard deviations if the same scales and units are used and \nthe two means are approximately equal, but here we have different scales and differ-\nent units of measurement, so we use the coefficients of variation:\n Male Pulse Rates:   CV = s\nx # 100% = 11.3 BPM\n69.6 BPM # 100% = 16.2%\n Male Heights:  \n CV = s\nx # 100% =\n7.10 cm\n174.12 cm # 100% = 4.1%\nWe can now see that the male pulse rates (with CV = 16.2%) vary more than male \nheights (with CV = 4.1%).\nMeasures of Variation\nAccess tech instructions, videos, and data sets at www.TriolaStats.com\nTECH CENTER \nStatistical Literacy and Critical Thinking \n1. Range Rule of Thumb for Estimating s The 20 brain volumes (cm3) from Data Set 9 \n“IQ and Brain Size” in Appendix B vary from a low of 963 cm3 to a high of 1439 cm3. Use \nthe range rule of thumb to estimate the standard deviation s and compare the result to the exact \nstandard deviation of 124.9 cm3.\n3-2 Basic Skills and Concepts\n",
    "98 \nCHAPTER 3 Describing, Exploring, and Comparing Data\n2. Range Rule of Thumb for Interpreting s The 20 brain volumes (cm3) from Data Set 9 \n“IQ and Brain Size” in Appendix B have a mean of 1126.0 cm3 and a standard deviation of \n124.9 cm3. Use the range rule of thumb to identify the limits separating values that are signifi-\ncantly low or significantly high. For such data, would a brain volume of 1440 cm3 be signifi-\ncantly high?\n3.  Variance The 20 subjects used in Data Set 9 “IQ and Brain Size” in Appendix B have \nweights with a standard deviation of 20.0414 kg. What is the variance of their weights? Include \nthe appropriate units with the result.\n4. Symbols Identify the symbols used for each of the following: (a) sample standard devia-\ntion; (b) population standard deviation; (c) sample variance; (d) population variance.\nIn Exercises 5–20, find the range, variance, and standard deviation for the given sample \ndata. Include appropriate units (such as “minutes”) in your results. (The same data were \nused in Section 3-1 where we found measures of center. Here we find measures of varia-\ntion.) Then answer the given questions.\n5. Charges for Births Data Set 3 “Births” in Appendix B includes total charges for births at \nfour hospitals in New York State, and the top 10 highest amounts (in dollars) are listed below. \nWhat do the results tell us about the population of all such charges?\n471,062 359,091 290,837 271,863 255,788\n247,477 232,782 197,912 183,271 155,857\n6. MCAT Score Listed below are mean MCAT scores listed in order by year, starting with the \nyear 2002. What important feature of the data is not revealed by any of the measures of center?\n27.0 26.8 27.1 27.3 27.4 27.7 28.1 27.9 28.3 28.2 28.3 28.4\n7. Football Player Numbers Listed below are the jersey numbers of 11 players randomly \nselected from the roster of the Seattle Seahawks when they won Super Bowl XLVIII. What do \nthe results tell us?\n89 91 55 7 20 99 25 81 19 82 60\n8. Football Player Weights Listed below are the weights (lb) of 11 players randomly selected \nfrom the roster of the Seattle Seahawks when they won Super Bowl XLVIII (the same players \nfrom the preceding exercise). Are the results likely to be representative of all NFL players?\n189 254 235 225 190 305 195 202 190 252 305\n9.  Peas in a Pod Biologists conducted experiments to determine whether a deficiency \nof carbon dioxide in the soil affects the phenotypes of peas. Listed below are the pheno-\ntype codes, where 1 = smooth @ yellow, 2 = smooth @ green, 3 = wrinkled @yellow, and \n4 = wrinkled @ green. Do the results make sense?\n2  1  1  1  1  1  1  4  1  2  2  1  2  3  3  2  3  1  3  1  3  1  3  2  2\n10. TV Prices A physician plans to buy a television for her large waiting room. Listed below \nare selling prices (in dollars) of TVs that are 60 inches or larger and rated as a “best buy” by \nConsumer Reports magazine. Are the resulting statistics representative of the population of all \nTVs that are 60 inches and larger?\n1800 1500 1200 1500 1400 1600 1500 950 1600 1150 1500 1750\n11. Cell Phone Radiation Listed below are the measured radiation absorption rates (in W>kg) \ncorresponding to these cell phones: iPhone 5S, BlackBerry Z30, Sanyo Vero, Optimus V, Droid \nRazr, Nokia N97, Samsung Vibrant, Sony Z750a, Kyocera Kona, LG G2, and Virgin Mobile \nSupreme. The data are from the Federal Communications Commission. If one of each model of \ncell phone is measured for radiation and the results are used to find the measures of variation, \nare the results typical of the population of cell phones that are in use?\n1.18 1.41 1.49 1.04 1.45 0.74 0.89 1.42 1.45 0.51 1.38\n",
    "3-2 Measures of Variation \n99\n12. Caffeine in Soft Drinks Listed below are measured amounts of caffeine (mg per 12 oz of \ndrink) obtained in one can from each of 20 brands (7-UP, A&W Root Beer, Cherry Coke, . . . , \nTab). Are the statistics representative of the population of all cans of the same 20 brands consumed \nby Americans?\n0  0  34  34  34  45  41  51  55  36  47  41 0  0  53  54  38  0  41  47\n13. Firefighter Fatalities Listed below are the numbers of heroic firefighters who lost their \nlives in the United States each year while fighting forest fires. The numbers are listed in order \nby year, starting with the year 2000. What important feature of the data is not revealed by any \nof the measures of variation?\n20 18 23 30 20 12 24 9 25 15 8 11 15 34\n14. Foot Lengths Listed below are foot lengths in inches of randomly selected Army women \nmeasured in the 1988 Anthropometric Survey (ANSUR). Are the statistics representative of the \ncurrent population of all Army women?\n10.4 9.3 9.1 9.3 10.0 9.4 8.6 9.8 9.9 9.1 9.1\n15. Medical School Tuition Listed below in dollars are the annual costs of tuition at the 10 \nmost expensive private medical schools in the United States for a recent year (based on data \nfrom U.S. News & World Report). What does this “top 10” list tell us about those costs for the \npopulation of all U.S. private medical school tuitions?\n57,261 56,784 55,196 54,976 54,653 54,528 54,268 54,050 53,581 53,323\n16. California Smokers In the California Health Interview Survey, randomly selected adults \nare interviewed. One of the questions asks how many cigarettes are smoked per day, and results \nare listed below for 50 randomly selected respondents. How well do the results reflect the \nsmoking behavior of California adults?\n9 10 10 20 40 50 1Plus 44 other values that are all 02\nIn Exercises 17–20, find the coefficient of variation for each of the two samples; then com-\npare the variation. (The same data were used in Section 3-1.)\n17.  Blood Pressure A sample of blood pressure measurements is taken from Data Set \n1 “Body Data” in Appendix B, and those values (mm Hg) are listed below. The values are \nmatched so that 10 subjects each have systolic and diastolic measurements.\nSubject:\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\nSystolic:\n118\n128\n158\n96\n156\n122\n116\n136\n126\n120\nDiastolic:\n 80\n 76\n 74\n52\n 90\n 88\n 58\n 64\n 72\n 82\n18. White , Red Blood Counts Listed below are white blood cell counts (1000 cells>mL) \nand red blood cell counts (million cells>mL) from different subjects (from Data Set 1 “Body \nData” in Appendix B). The values are matched so that each of the 12 subjects has a white blood \ncell count and a red blood cell count.\nWhite:\n8.7\n4.9\n6.9\n7.5\n6.1\n5.7\n4.1\n8.1\n8.0\n5.6\n8.3\n6.9\nRed:\n4.8\n4.7\n4.5\n4.3\n5.0\n4.0\n4.7\n4.6\n4.1\n5.5\n4.4\n4.2\n19.  White Blood Counts Listed below are white blood cell counts (1000 cells>mL) from \nmales and females (from Data Set 1 “Body Data” in Appendix B). Do they appear to be different?\nFemale:\n8.7\n6.9\n8.1\n8.0\n6.9\n8.1\n6.4\n6.3\n10.9\n4.8\n5.9\n7.2\nMale:\n4.9\n7.5\n6.1\n5.7\n4.1\n5.6\n8.3\n5.1\n 9.5\n6.1\n5.7\n5.4\n",
    "100 \nCHAPTER 3 Describing, Exploring, and Comparing Data\n20. Queues A Providence Hospital experiment involves two different waiting line configura-\ntions for patients arriving for admission. The waiting times (in seconds) are recorded with a \nsingle line configuration that feeds four stations and another configuration with individual lines \nat the four stations.\nSingle Line\n390\n396\n402\n408\n426\n438\n444\n462\n462\n462\nIndividual Lines\n252\n324\n348\n372\n402\n462\n462\n510\n558\n600\nLarge Data Sets from Appendix B. In Exercises 21–24, refer to the indicated data set in \nAppendix B. Use software or a calculator to find the range, variance, and standard devia-\ntion. Express answers using appropriate units, such as “minutes.”\n21. HDL Use the HDL cholesterol measurements (mg>dL) from the 300 subjects included in \nData Set 1 “Body Data” in Appendix B. Identify the highest value. Does it appear to be an out-\nlier? Do the measures of variation change much when that highest value is deleted?\n22. LDL Repeat the preceding exercise using the LDL measurements (mg>dL).\n23. Body Temperatures Refer to Data Set 2 “Body Temperatures” in Appendix B and use \nthe body temperatures for 12:00 AM on day 2.\n24. Births Use the birth weights (grams) of the 400 babies listed in Data Set 3 “Births” in \n Appendix B. Examine the list of birth weights to make an observation about those numbers. \nHow does that observation affect the way that the results should be rounded?\nEstimating Standard Deviation with the Range Rule of Thumb. In Exercises 25–28, \nrefer to the data in the indicated exercise. After finding the range of the data, use the range \nrule of thumb to estimate the value of the standard deviation. Compare the result to the \nstandard deviation computed with all of the data.\n25. HDL Exercise 21\n26. LDL Exercise 22\n27. Body Temperatures Exercise 23\n28. Births Exercise 24\nIdentifying Significant Values with the Range Rule of Thumb. In Exercises 29–32, \nuse the range rule of thumb to identify the limits separating values that are significantly low \nor significantly high.\n29. Pulse Rates of Females Based on Data Set 1 “Body Data” in Appendix B, females \nhave pulse rates with a mean of 74.0 beats per minute and a standard deviation of 12.5 beats \nper minute. Is a female pulse rate of 44 beats per minute significantly low or significantly high? \n(All of these pulse rates are measured at rest.)\n30. Pulse Rates of Males Based on Data Set 1 “Body Data” in Appendix B, males have \npulse rates with a mean of 69.6 beats per minute and a standard deviation of 11.3 beats per \nminute. Is a male pulse rate of 50 beats per minute significantly low or significantly high? (All \nof these pulse rates are measured at rest.) Explain.\n31. Foot Lengths Based on Data Set 7 “Foot and Height” in Appendix B, adult males have \nfoot lengths with a mean of 27.32 cm and a standard deviation of 1.29 cm. Is the adult male \nfoot length of 30 cm significantly low or significantly high? Explain.\n32. Body Temperatures Based on Data Set 2 “Body Temperatures” in Appendix B, body \ntemperatures of adults have a mean of 98.20oF and a standard deviation of 0.62oF. Is an adult \nbody temperature of 100oF significantly low or significantly high?\n",
    "3-2 Measures of Variation \n101\nFinding Standard Deviation from a Frequency Distribution. In Exercises 33 and 34, \nrefer to the frequency distribution in the given exercise and find the standard deviation by \nusing the formula below, where x represents the class midpoint, f represents the class fre-\nquency, and n represents the total number of sample values. Also, compare the computed \nstandard deviations to these standard deviations obtained by using Formula 3-4 with the \noriginal list of data values: (Exercise 33) 59.5; (Exercise 34) 65.4.\ns = B\nn3Σ1f # x22 4 - 3Σ1f # x2 42\nn1n - 12\n33. \nBlood Platelet \nCount of Males\n \nFrequency\n 0–99\n 1\n100–199\n51\n200–299\n90\n300–399\n10\n400–499\n 0\n500–599\n 0\n600–699\n 1\n34. \nBlood Platelet \nCount of Females\n \nFrequency\n100–199\n25\n200–299\n92\n300–399\n28\n400–499\n 0\n500–599\n 2\n35. Why Divide by n −1? Let a population consist of these values: 9 cigarettes, 10 \ncigarettes, and 20 cigarettes smoked in a day (based on data from the California Health \nInterview Survey). Assume that samples of two values are randomly selected with replace-\nment from this population. (That is, a selected value is replaced before the second selection \nis made.)\na. Find the variance s2 of the population {9 cigarettes, 10 cigarettes, 20 cigarettes}.\nb. After listing the nine different possible samples of two values selected with replacement, \nfind the sample variance s2 (which includes division by n - 1) for each of them; then find the \nmean of the nine sample variances s2.\nc. For each of the nine different possible samples of two values selected with replacement, find \nthe variance by treating each sample as if it is a population (using the formula for population \nvariance, which includes division by n); then find the mean of those nine population variances.\nd. Which approach results in values that are better estimates of s2: part (b) or part (c)? Why? \nWhen computing variances of samples, should you use division by n or n - 1?\ne. The preceding parts show that s2 is an unbiased estimator of s2. Is s an unbiased estimator \nof s? Explain.\n36. Mean Absolute Deviation Use the same population of {9 cigarettes, 10 cigarettes, \n20 cigarettes} from Exercise 35. Show that when samples of size 2 are randomly selected \nwith replacement, the samples have mean absolute deviations that do not center about the \nvalue of the mean absolute deviation of the population. What does this indicate about a \nsample mean absolute deviation being used as an estimator of the mean absolute deviation \nof a population?\n3-2  Beyond the Basics\n",
    "102 \nCHAPTER 3 Describing, Exploring, and Comparing Data\nKey Concept This section introduces measures of relative standing, which are num-\nbers showing the location of data values relative to the other values within the same \ndata set. The most important concept in this section is the z score, which will be used \noften in following chapters. We also discuss percentiles and quartiles, which are com-\nmon statistics, as well as another statistical graph called a boxplot.\nPART 1\n  Basics of z Scores, Percentiles, Quartiles, \nand Boxplots \nz Scores\nA z score is found by converting a value to a standardized scale, as given in the fol-\nlowing definition. This definition shows that a z score is the number of standard devia-\ntions that a data value is away from the mean. The z score is used often in Chapter 6 \nand later chapters.\n3-3 \nMeasures of Relative Standing and Boxplots\nDEFINITION\nA z score (or standard score or standardized value) is the number of standard \ndeviations that a given value x is above or below the mean. The z score is calcu-\nlated by using one of the following:\nSample\nPopulation\nz = x - x\ns\nor\nz = x - m\ns\nROUND-OFF RULE FOR z SCORES Round z scores to two decimal places  \n(such as 2.31).\nThis round-off rule is motivated by the format of standard tables in which z scores \nare expressed with two decimal places, as in Table A-2 in Appendix A. Example 1 il-\nlustrates how z scores can be used to compare values, even if they come from different \npopulations.\nImportant Properties of z Scores\n1. A z score is the number of standard deviations that a given value x is above or \nbelow the mean.\n2. z Scores are expressed as numbers with no units of measurement.\n3. A data value is significantly low if its z score is less than or equal to -2 or the \nvalue is significantly high if its z score is greater than or equal to +2.\n4. If an individual data value is less than the mean, its corresponding z score \nis a negative number.\n",
    "3-3 Measures of Relative Standing and Boxplots \n103\nUsing z Scores to Identify Significant Values In Section 3-2 we used the range \nrule of thumb to conclude that a value is significantly low or significantly high if it is \nat least 2 standard deviations away from the mean. It follows that significantly low \nvalues have z scores less than or equal to -2 and significantly high values have z \nscores greater than or equal to +2, as illustrated in Figure 3-4. Using this criterion \nwith the two individual values used in Example 1 above, we see that neither value is \nsignificant because both z scores are between -2 and +2.\nEXAMPLE 1   Comparing a Baby’s Weight and  \nAdult Body Temperature\nWhich of the following two data values is more extreme relative to the data set from \nwhich it came?\n \n■The 4000 g weight of a newborn baby (among 400 weights with sample mean \nx = 3152.0 g and sample standard deviation s = 693.4 g)\n \n■The 99°F temperature of an adult (among 106 adults with sample mean \nx = 98.20°F and sample standard deviation s = 0.62°F)\nSOLUTION\nThe 4000 g weight and the 99°F body temperature can be standardized by convert-\ning each of them to z scores as shown below.\n4000 g birth weight:\nz = x - x\ns\n= 4000 g - 3152.0 g\n693.4 g\n= 1.22\n99°F body temperature:\nz = x - x\ns\n= 99°F - 98.20°F\n0.62°F\n= 1.29\nINTERPRETATION\nThe z scores show that the 4000 g birth weight is 1.22 standard deviations above the \nmean, and the 99°F body temperature is 1.29 standard deviations above the mean. \nBecause the body temperature is farther above the mean, it is the more extreme \nvalue, but not by much. A 99°F body temperature is slightly more extreme than a \nbirth weight of 4000 g.\nValues not signiﬁcant\nSigniﬁcantly\nlow values\nSigniﬁcantly\nhigh values\nz\n−2\n−1\n2\n−3\n3\n0\n1\nFIGURE 3-4  Interpreting z Scores \nSignificant values are those with z scores …  -2.00 or Ú 2.00.\n",
    "104 \nCHAPTER 3 Describing, Exploring, and Comparing Data\nA z score is a measure of position, in the sense that it describes the location of a \nvalue (in terms of standard deviations) relative to the mean. Percentiles and quartiles \nare other measures of position useful for comparing values within the same data set or \nbetween different sets of data.\nPercentiles\nPercentiles are one type of quantiles—or fractiles—which partition data into groups \nwith roughly the same number of values in each group.\nEXAMPLE 2  Is a Platelet Count of 75 Significantly Low?\nThe lowest platelet count in Data Set 1 “Body Data” in Appendix B is 75. (The \nplatelet counts are measured in 1000 cells>mL). Is that value significantly low? \nBased on the platelet counts from Data Set 1 in Appendix B, assume that platelet \ncounts have a mean of x = 239.4 and a standard deviation of s = 64.2.\nSOLUTION\nThe platelet count of 75 is converted to a z score as shown below:\nz = x - x\ns\n= 75 - 239.4\n64.2\n= -2.56\nINTERPRETATION\nThe platelet count of 75 converts to the z score of -2.56. Refer to Figure 3-4 to \nsee that z = -2.56 is less than -2, so the platelet count of 75 is significantly low. \n(Low platelet counts are called thrombocytopenia. What a wonderful name.)\nDEFINITION\nPercentiles are measures of location, denoted P1, P2, . . . , P99, which divide a set of \ndata into 100 groups with about 1% of the values in each group.\nThe 50th percentile, denoted P50, has about 50% of the data values below it and about \n50% of the data values above it, so the 50th percentile is the same as the median. \nThere is not universal agreement on a single procedure for calculating percentiles, but \nwe will describe relatively simple procedures for (1) finding the percentile of a data \nvalue and (2) converting a percentile to its corresponding data value. We begin with \nthe first procedure.\nFinding the Percentile of a Data Value\nThe process of finding the percentile that corresponds to a particular data value x \nis given by the following (round the result to the nearest whole number):\nPercentile of value x = number of values less than x\ntotal number of values\n# 100\nDetecting Phony Data\nA class is \ngiven the \nhomework \nassignment of \nrecording the \nresults when a \ncoin is tossed \n500 times. One dishonest stu-\ndent decides to save time by just \nmaking up the results instead of \nactually flipping a coin. Because \npeople generally cannot make \nup results that are really random, \nwe can often identify such phony \ndata. With 500 tosses of an ac-\ntual coin, it is extremely likely that \nyou will get a run of six heads or \nsix tails, but people almost never \ninclude such a run when they \nmake up results.\nAnother way to detect fab-\nricated data is to establish that \nthe results violate Benford’s law: \nFor many collections of data, the \nleading digits are not uniformly \ndistributed. Instead, the leading \ndigits of 1, 2,…, 9 occur with \nrates of 30%, 18%, 12%, 10%, \n8%, 7%, 6%, 5%, and 5%, re-\nspectively. (See “The Difficulty of \nFaking Data,” by Theodore Hill, \nChance, Vol. 12, No. 3.)\n",
    "3-3 Measures of Relative Standing and Boxplots \n105\nExample 3 shows how to convert from a given sample value to the corresponding \npercentile. There are several different methods for the reverse procedure of converting \na given percentile to the corresponding value in the data set. The procedure we will \nuse is summarized in Figure 3-5 on the next page, which uses the following notation.\nNotation\nn \ntotal number of values in the data set\nk \npercentile being used (Example: For the 25th percentile, k = 25.)\nL \n locator that gives the position of a value (Example: For the 12th value in \nthe sorted list, L = 12.)\nPk \nkth percentile (Example: P25 is the 25th percentile.)\nTABLE 3-4 Sorted Cotinine Measures of Smokers\n  0\n  1\n  1\n  3\n 17\n 32\n 35\n 44\n 48\n 86\n 87\n103\n112\n121\n123\n130\n131\n149\n164\n167\n173\n173\n198\n208\n210\n222\n227\n234\n245\n250\n253\n265\n266\n277\n284\n289\n290\n313\n477\n491\nEXAMPLE 3  Finding a Percentile\nTable 3-4 lists the 40 cotinine measures (ng>mL) of smokers from Data Set 14 \n“Passive and Active Smoke” in Appendix B, and they are listed in order. Find the \npercentile for the cotinine level of 198 ng>mL.\nSOLUTION\nFrom the sorted list of cotinine levels in Table 3-4, we see that there are 22 values \nless than 198 ng>mL, so\nPercentile of 198 ng>mL = 22\n40 # 100 = 55\nINTERPRETATION\nA cotinine level of 198 ng>mL is in the 55th percentile. This can be interpreted \nloosely as this: A cotinine level of 198 ng>mL separates the lowest 55% of values \nfrom the highest 45% of values. We have P55 = 198 ng>mL.\nEXAMPLE 4  Converting a Percentile to a Data Value\nRefer to the sorted cotinine levels of smokers in Table 3-4 and use the procedure in \nFigure 3-5 to find the value of the 33rd percentile, P33.\ncontinued\n",
    "106 \nCHAPTER 3 Describing, Exploring, and Comparing Data\nThe value of Pk is the Lth\nvalue, counting from\nthe lowest.\nIs L a whole\nnumber?\nYes\nNo\nChange L by rounding it\nup to the next larger\nwhole number.\nCompute\nn 5 number of values\nk 5 percentile in question\nSort the data.\n(Arrange the data in order\nof lowest to highest.)\nStart\nL 5\nn   where\nk\n100\nThe value of the kth percentile is \nmidway between the Lth value \nand the next value in the sorted \nset of data. Find Pk by adding \nthe Lth value and the next value \nand dividing the total by 2. \nFIGURE 3-5  Converting from the kth percentile to the \ncorresponding data value\nSOLUTION\nFrom Figure 3-5, we see that the sample data are already sorted, so we can proceed \nto find the value of the locator L. In this computation we use k = 33 because we are \ntrying to find the value of the 33rd percentile. We use n = 40 because there are 40 \ndata values.\nL =\nk\n100 # n = 33\n100 # 40 = 13.2\nSince L = 13.2 is not a whole number, we proceed to the next lower box in Figure 3-5 \nwhere we change L by rounding it up from 13.2 to the next larger whole number: 14. \n(In this book we typically round off the usual way, but this is one of two cases where \nwe round up instead of rounding off.) From the bottom box we see that the value of P33 \nis the 14th value, counting from the lowest. In Table 3-4, the 14th value is 121. That is, \nP33 = 121 ng>mL. Roughly speaking, about 33% of the cotinine levels in Table 3-4 \nare less than 121 ng>mL and 67% of them are more than 121 ng>mL.\n",
    "3-3 Measures of Relative Standing and Boxplots \n107\nQuartiles\nJust as there are 99 percentiles that divide the data into 100 groups, there are three \nquartiles that divide the data into four groups.\nEXAMPLE 5  Converting a Percentile to a Data Value\nRefer to the sorted pulse rates in Table 3-4. Use Figure 3-5 to find the 25th percen-\ntile, denoted by P25.\nSOLUTION\nReferring to Figure 3-5, we see that the sample data are already sorted, so we can \nproceed to compute the value of the locator L. In this case, we use k = 25 because \nwe are attempting to find the value of the 25th percentile, and we use n = 40 be-\ncause there are 40 data values.\nL =\nk\n100 # n = 25\n100 # 40 = 10\nSince L = 10 is a whole number, we proceed to the box in Figure 3-5 located at the \nright. We now see that the value of the 25th percentile is midway between the Lth \n(10th) value and the next higher value in the original set of data. That is, the value \nof the 25th percentile is midway between the 10th value and the 11th value. The \n10th value in Table 3-4 is 86 and the 11th value is 87, so the value midway between \nthem is 86.5 ng>mL. We conclude that the 25th percentile is P25 = 86.5 ng>mL.\nDEFINITION\nQuartiles are measures of location, denoted Q1, Q2, and Q3,which divide a set of \ndata into four groups with about 25% of the values in each group.\nHere are descriptions of quartiles that are more accurate than those given in the \npreceding definition:\nQ1 (First quartile): \n Same value as P25. It separates the bottom 25% of the \nsorted values from the top 75%. (To be more precise, \nat least 25% of the sorted values are less than or equal \nto Q1, and at least 75% of the values are greater than or \nequal to Q1.)\nQ2 (Second quartile):  Same as P50 and same as the median. It separates the \nbottom 50% of the sorted values from the top 50%.\nQ3 (Third quartile): \n Same as P75. It separates the bottom 75% of the sorted val-\nues from the top 25%. (To be more precise, at least 75% of \nthe sorted values are less than or equal to Q3, and at least \n25% of the values are greater than or equal to Q3.)\nFinding values of quartiles can be accomplished with the same procedure used for \nfinding percentiles. Simply use the relationships shown in the margin. In Example 4 \nwe found that P25 = 86.5 ng>mL, so it follows that Q1 = 86.5 ng>mL.\nQ1 = P25\nQ2 = P50\nQ3 = P75\n",
    "108 \nCHAPTER 3 Describing, Exploring, and Comparing Data\nIn earlier sections of this chapter we described several statistics, including the \nmean, median, mode, range, and standard deviation. Some other statistics are defined \nusing quartiles and percentiles, as in the following:\nInterquartile range (or IQR) \n= Q3 - Q1\nSemi-interquartile range \n= Q3 - Q1\n2\nMidquartile \n= Q3 + Q1\n2\n10–90 percentile range \n= P90 - P10\n5-Number Summary and Boxplot\nThe values of the minimum, maximum and three quartiles 1Q1, Q2, Q32 are used for \nthe 5-number summary and the construction of boxplot graphs.\nCAUTION Just as there is not universal agreement on a procedure for finding \npercentiles, there is not universal agreement on a single procedure for calculating \nquartiles, and different technologies often yield different results. If you use a \ncalculator or software for exercises involving quartiles, you may get results that differ \nsomewhat from the answers obtained by using the procedures described here.\nDEFINITION\nFor a set of data, the 5-number summary consists of these five values:\n1. Minimum\n2. First quartile, Q1\n3. Second quartile, Q2 (same as the median)\n4. Third quartile, Q3\n5. Maximum\nEXAMPLE 6  Finding a 5-Number Summary\nUse the cotinine measurements in Table 3-4 to find the 5-number summary.\nSOLUTION\nBecause the cotinine measurements in Table 3-4 are sorted, it is easy to see that \nthe minimum is 0 ng>mL and the maximum is 491 ng>mL. The value of the first \nquartile is Q1 = 86.5 ng>mL (from Example 5). The median is equal to Q2, and it \nis 170.0 ng>mL. Also, we can find that Q3 = 251.5 ng>mL by using the procedure \nfor finding P75 (as summarized in Figure 3-5). The 5-number summary is therefore \n0, 86.5, 170.0, 251.5, and 491 (all in units of ng>mL).\nDEFINITION\nA boxplot (or box-and-whisker diagram) is a graph of a data set that consists of a \nline extending from the minimum value to the maximum value, and a box with lines \ndrawn at the first quartile Q1, the median, and the third quartile Q3. (See Figure 3-6.)\n",
    "3-3 Measures of Relative Standing and Boxplots \n109\nProcedure for Constructing a Boxplot\n1. Find the 5-number summary (minimum value, Q1, Q2, Q3, maximum value).\n2. Construct a line segment extending from the minimum data value to the maxi-\nmum data value.\n3. Construct a box (rectangle) extending from Q1 to Q3, and draw a line in the \nbox at the value of Q2 (median).\nCAUTION Because there is not universal agreement on procedures for finding \nquartiles, and because boxplots are based on quartiles, different technologies may \nyield different boxplots.\nEXAMPLE 7  Constructing a Boxplot\nUse the cotinine measurements listed in Table 3-4 to construct a boxplot.\nSOLUTION\nThe boxplot uses the 5-number summary found in Example 6: 0, 86.5, 170.0, 251.5, \nand 491 (all in units of ng>mL). Figure 3-6 is the boxplot representing the cotinine \nmeasurements listed in Table 3-4.\nFIGURE 3-6 Boxplot of Cotinine Measurements (ng, mL)\nSkewness A boxplot can often be used to identify skewness (discussed in \n Section 2-2). The boxplot in Figure 3-6 isn’t exactly symmetric; it shows that the \ndata are slightly skewed to the right.\nBecause the shape of a boxplot is determined by the five values from the 5-number \nsummary, a boxplot is not a graph of the distribution of the data, and it doesn’t show \nas much detailed information as a histogram or stemplot. However, boxplots are often \ngreat for comparing two or more data sets. When using two or more boxplots for com-\nparing different data sets, graph the boxplots on the same scale so that comparisons \ncan be easily made. Methods discussed later in this book allow us to analyze com-\nparisons of data sets more formally than subjective conclusions based on a graph. It is \nalways wise to construct suitable graphs, such as histograms, dotplots, and boxplots, \nbut we should not rely solely on subjective judgments based on graphs.\nEXAMPLE 8  Comparing the Pulse Rates of Men and Women\nThe Chapter Problem involves pulse rates of men and women, and the data are \nfound in Data Set 1 “Body Data” in Appendix B. Construct boxplots of those two \ndifferent sets of pulse rates.\ncontinued\n",
    "110 \nCHAPTER 3 Describing, Exploring, and Comparing Data\nOutliers\nWhen analyzing data, it is important to identify and consider outliers because they \ncan strongly affect values of some important statistics (such as the mean and standard \ndeviation), and they can also strongly affect important methods discussed later in this \nbook. In Chapter 2 we described outliers as sample values that lie very far away from \nthe vast majority of the other values in a set of data, but that description is vague and \nit does not provide specific objective criteria. Part 2 of this section includes a descrip-\ntion of modified boxplots along with a more precise definition of outliers used in the \ncontext of creating modified boxplots.\nSOLUTION\nThe Statdisk-generated boxplots are shown in Figure 3-7. The three quartiles for \nmales are all lower than the corresponding three quartiles for females, which sug-\ngests that males generally have lower pulse rates than females. The minimums and \nmaximums are not very different in the two boxplots, and we shouldn’t place too \nmuch importance on those differences because they are not very reliable measures.\nFIGURE 3-7 Boxplots of Pulse Rates of Men and Women\nCAUTION When analyzing data, always identify outliers and consider their effects, \nwhich can be substantial.\nPART 2\n Outliers and Modified Boxplots \nWe noted that the description of outliers is somewhat vague, but for the purposes of \nconstructing modified boxplots, we can consider outliers to be data values meeting \nspecific criteria based on quartiles and the interquartile range. (The interquartile range \nis often denoted by IQR, and IQR = Q3 - Q1.)\nIdentifying Outliers for Modified Boxplots\n1. Find the quartiles Q1, Q2, and Q3.\n2. Find the interquartile range (IQR), where IQR = Q3 - Q1.\n3. Evaluate 1.5 * IQR.\n4. In a modified boxplot, a data value is an outlier if it is\nabove Q3, by an amount greater than 1.5 : IQR\nor below Q1, by an amount greater than 1.5 : IQR\nModified Boxplots\nThe boxplots described earlier in Part 1 are called skeletal (or regular) boxplots, but \nsome statistical software packages provide modified boxplots, which represent outliers as \n",
    "3-3 Measures of Relative Standing and Boxplots \n111\nspecial points. A modified boxplot is a regular boxplot constructed with these modifi-\ncations: (1) A special symbol (such as an asterisk or point) is used to identify outliers \nas defined above, and (2) the solid horizontal line extends only as far as the minimum \ndata value that is not an outlier and the maximum data value that is not an outlier. \n(Note: Exercises involving modified boxplots are found in the “Beyond the Basics” \nexercises only.)\nEXAMPLE 9  Constructing Modified Boxplots\nUse the pulse rates of males in Data Set 1 “Body Data” from Appendix B to con-\nstruct a modified boxplot. The five-number summary is 40, 62.0, 68.0, 76.0, 104 (all \nin BPM).\nSOLUTION\nLet’s begin with the four steps for identifying outliers in a modified boxplot.\n1. Using the pulse rates of males, the three quartiles are Q1 = 62.0, the median \nis Q2 = 68.0, and Q3 = 76.0.\n2. The interquartile range is IQR = Q3 - Q1 = 76.0 - 62.0 = 14.0.\n3. 1.5 * IQR = 1.5 * 14.0 = 21.0.\n \n4. Any outliers are\n \n■Greater than Q3 = 76.0 by more than 21.0 or\n \n■Less than Q1 = 62.0 by more than 21.0.\nThis means that any outliers are greater than 97.0 or less than 41.0. We can now \nexamine the original pulse rates of males to identify any that are greater than 97.0 or \nless than 41.0. We find that the pulse rates of 102 and 104 are greater than 97.0, and \nthe pulse rate of 40 is less than 41.0. The outliers are 102, 104, and 40.\nWe can now construct the modified boxplot shown in Figure 3-8. In Figure 3-8, \nthe three outliers (40, 102, 104) are identified as special points, the three quartiles \n(62.0, 68.0, 76.0) are shown as in a regular boxplot, and the horizontal line extends \nfrom the lowest data value that is not an outlier (42) to the highest data value that is \nnot an outlier (96).\nFIGURE 3-8 Modified Boxplot of Male Pulse Rates (BPM)\nCAUTION Because there is not universal agreement on procedures for finding \nquartiles, and because modified boxplots are based on quartiles, different \ntechnologies may yield different modified boxplots.\n",
    "112 \nCHAPTER 3 Describing, Exploring, and Comparing Data\nBoxplots, 5-Number Summary, Outliers\nAccess tech instructions, videos, and data sets at www.TriolaStats.com\nTECH CENTER \nStatistical Literacy and Critical Thinking \n1.  z Scores LeBron James, one of the most successful basketball players of all time, has \na height of 6 feet 8 inches, or 203 cm. Based on statistics from Data Set 1 “Body Data” in \n Appendix B, his height converts to the z score of 4.07. How many standard deviations is his \nheight above the mean?\n2. Heights The boxplot shown below results from the heights (cm) of males listed in Data Set \n1 “Body Data” in Appendix B. What do the numbers in that boxplot tell us?\n3. Boxplot Comparison Refer to the boxplots shown below that are drawn on the same scale. \nOne boxplot represents weights of men and the other boxplot represents weights of women. \nWhich boxplot represents weights of women? Explain.\n4. z Scores If your score on your next statistics test is converted to a z score, which of these z \nscores would you prefer: -2.00,-1.00, 0, 1.00, 2.00? Why?\nz Scores. In Exercises 5–8, express all z scores with two decimal places.\n5. Female Pulse Rates For the pulse rates of females listed in Data Set 1 “Body Data” in \nAppendix B, the mean is 74.0 BPM, the standard deviation is 12.5 BPM, and the maximum is \n104 BPM.\na. What is the difference between the maximum and the mean?\nb. How many standard deviations is that [the difference found in part (a)]?\nc. Convert the maximum pulse rate to a z score.\nd. If we consider pulse rates that convert to z scores between -2 and 2 to be neither signifi-\ncantly low nor significantly high, is the maximum pulse rate significant?\n6. Female Pulse Rates For the pulse rates of females listed in Data Set 1 “Body Data” in \nAppendix B, the mean is 74.0 BPM, the standard deviation is 12.5 BPM, and the minimum is \n36 BPM.\na. What is the difference between the minimum and the mean?\nb. How many standard deviations is that [the difference found in part (a)]?\n3-3 Basic Skills and Concepts\n",
    "3-3 Measures of Relative Standing and Boxplots \n113\nc. Convert the minimum pulse rate to a z score.\nd. If we consider pulse rates that convert to z scores between -2 and 2 to be neither significantly \nlow nor significantly high, is the minimum pulse rate significantly low or significantly high?\n7. Body Temperatures For the body temperatures at 12 AM on day 2 (listed in Data Set 2 \n“Body Temperatures” in Appendix B), the mean is 98.20oF, the standard deviation is 0.62oF, \nand the minimum is 96.5oF.\na. What is the difference between the minimum and the mean?\nb. How many standard deviations is that [the difference found in part (a)]?\nc. Convert the minimum temperature to a z score.\nd. If we consider body temperatures that convert to z scores between -2 and 2 to be neither \nsignificantly low nor significantly high, is the minimum body temperature significant?\n8. Body Temperatures For the body temperatures at 12 AM on day 2 (listed in Data Set 2 \n“Body Temperatures” in Appendix B), the mean is 98.20°F, the standard deviation is 0.62°F,\nand Q3 = 98.60°F.\na. What is the difference between Q3 and the mean?\nb. How many standard deviations is that [the difference found in part (a)]?\nc. Convert Q3 to a z score.\nd. If we consider temperatures that convert to z scores between -2 and 2 to be neither signifi-\ncantly low nor significantly high, is Q3 significant?\nSignificant Values. In Exercises 9–12, consider a value to be significantly low if its z \nscore is less than or equal to −2 or consider the value to be significantly high if its z score \nis greater than or equal to 2.\n9. ACT The ACT test is used to assess readiness for college. In a recent year, the mean ACT \nscore was 21.1 and the standard deviation was 5.1. Identify the ACT scores that are signifi-\ncantly low or significantly high.\n10. MCAT In a recent year, scores on the MCAT had a mean of 25.2 and a standard deviation \nof 6.4. Identify the MCAT scores that are significantly low or significantly high.\n11. Birth Weights Data Set 3 “Births” lists birth weights (g) of 400 babies. Those weights \nhave a mean of 3152.0 g and a standard deviation of 693.4 g. Identify birth weights that are \nsignificantly low or significantly high.\n12. Ergonomics in Aircraft Seats In the process of designing aircraft seats, it was found \nthat men have hip breadths with a mean of 36.6 cm and a standard deviation of 2.5 cm (based \non anthropometric survey data from Gordon, Clauser, et al.). Identify the hip breadths of men \nthat are significantly low or significantly high.\nComparing Values. In Exercises 13–16, use z scores to compare the given values.\n13. Tallest and Shortest Men The tallest living man at the time of this writing is Sultan \nKosen, who has a height of 251 cm. The shortest living man is Chandra Bahadur Dangi, who \nhas a height of 54.6 cm. Heights of men have a mean of 174.12 cm and a standard deviation of \n7.10 cm. Which of these two men has the height that is more extreme?\n14. Red Blood Cell Counts Based on Data Set 1 “Body Data” in Appendix B, males have \nred blood cell counts with a mean of 4.719 and a standard deviation of 0.490, while females \nhave red blood cell counts with a mean of 4.349 and a standard deviation of 0.402. Who has the \nhigher count relative to the sample from which it came: a male with a count of 5.58 or a female \nwith a count of 5.23? Explain.\n15. Birth Weights Based on Data Set 3 “Births” in Appendix B, newborn males have weights \nwith a mean of 3272.8 g and a standard deviation of 660.2 g. Newborn females have weights \nwith a mean of 3037.1 g and a standard deviation of 706.3 g. Who has the weight that is more \ncontinued\n",
    "114 \nCHAPTER 3 Describing, Exploring, and Comparing Data\nextreme relative to the group from which they came: a male who weighs 1500 g or a female \nwho weighs 1500 g? Who has the larger weight relative to the group from which they came?\n16. Oscars In the 87th Academy Awards, Eddie Redmayne won for best actor at the age of \n33 and Julianne Moore won for best actress at the age of 54. For all best actors, the mean age \nis 44.1 years and the standard deviation is 8.9 years. For all best actresses, the mean age is \n36.2 years and the standard deviation is 11.5 years. (All ages are determined at the time of the \nawards ceremony.) Relative to their genders, who had the more extreme age when winning the \nOscar: Eddie Redmayne or Julianne Moore? Explain.\nPercentiles. In Exercises 17–20, use the following lengths (inches) of bears (from Data \nSet 11 “Bear Measurements” in Appendix B). Find the percentile corresponding to the \ngiven length.\n36.0 37.0 40.0 40.0 41.0 43.0 43.5 46.0 46.0 47.0 48.0 48.0\n49.0 50.0 52.0 52.5 53.0 53.0 54.0 57.3 57.5 58.0 59.0 59.0\n59.0 60.0 60.5 61.0 61.0 61.5 62.0 63.0 63.0 63.0 63.5 64.0\n64.0 64.0 65.0 65.0 66.5 67.0 67.5 68.5 70.0 70.5 72.0 72.0\n72.0 72.0 73.0 73.5 75.0 76.5\n17. 61.0 in.  18. 47.0 in.  19. 70.0 in.  20. 58.0 in.\nIn Exercises 21–28, use the same list of bear lengths (in.) given for Exercises 17–20. Find \nthe indicated percentile or quartile.\n21. P60   22. Q1\n23. Q3   24. P40\n25. P50   26. P75\n27. P25   28. P85\nBoxplots. In Exercises 29–32, use the given data to construct a boxplot and identify the \n5-number summary.\n29. Foot Lengths The following are the foot lengths (cm) of 19 males (from Data Set 7 “Foot \nand Height” in Appendix B).\n 25.1 25.4 25.7 25.9 26.4 26.7 26.7 26.7 26.8 27.5\n 27.8 27.9 27.9 28.1 28.6 28.7 28.8 29.2 29.2\n30.  Cell Phone Radiation Listed below are the measured radiation absorption rates (in \nW>kg) corresponding to these cell phones: iPhone 5S, BlackBerry Z30, Sanyo Vero, Optimus \nV, Droid Razr, Nokia N97, Samsung Vibrant, Sony Z750a, Kyocera Kona, LG G2, and Virgin \nMobile Supreme. The data are from the Federal Communications Commission.\n1.18 1.41 1.49 1.04 1.45 0.74 0.89 1.42 1.45 0.51 1.38\n31. Radiation in Baby Teeth Listed below are amounts of strontium-90 (in millibecquerels, \nor mBq) in a simple random sample of baby teeth obtained from Pennsylvania residents born \nafter 1979 (based on data from “An Unexpected Rise in Strontium-90 in U.S. Deciduous Teeth \nin the 1990s,” by Mangano et. al., Science of the Total Environment).\n 128 130 133 137 138 142 142 144 147 149 151 151 151 155\n 156 161 163 163 166 172\n32. Blood Pressure Measurements Fourteen different second-year medical students \nat  Bellevue Hospital measured the blood pressure of the same person. The systolic readings \n(mm Hg) are listed below.\n138 130 135 140 120 125 120 130 130 144 143 140 130 150\n",
    "Boxplots from Large Data Sets in Appendix B. In Exercises 33 and 34, use the given \ndata sets from Appendix B. Use the boxplots to compare the two data sets.\n33. BMI Use the body mass indexes (BMI) for males and use the BMI measures for females \nlisted in Data Set 1 “Body Data.”\n34. Lead and IQ Use the same scale to construct boxplots for the full IQ scores (IQF) for the \nlow lead level group and the high lead level group in Data Set 8 “IQ and Lead” in Appendix B.\n35. Outliers and Modified Boxplots Repeat Exercise 33 “BMI” using modified boxplots. \nIdentify any outliers as defined in Part 2 of this section.\n3-3 Beyond the Basics\nChapter Quick Quiz\n1. Sleep Mean As part of the National Health and Nutrition Examination Survey, subjects \nwere asked how long they slept the preceding night and the following times (hours) were re-\nported: 8, 7, 5, 7, 4, 7, 6, 7, 8, 8, 8, 6. Find the mean.\n2. Sleep Median What is the median of the sample values listed in Exercise 1?\n3. Sleep Mode What is the mode of the sample values listed in Exercise 1?\n4. Sleep Variance The standard deviation of the sample values in Exercise 1 is 1.3 hours. \nWhat is the variance (including units)?\n5. Sleep Outlier If the sleep time of 0 hours is included with the sample data given in Exercise 1, \nis it an outlier? Why or why not?\n6. Sleep z Score A larger sample of 50 sleep times (hours) has a mean of 6.3 hours and a stan-\ndard deviation of 1.4 hours. What is the z score for a sleep time of 5 hours?\n7. Sleep Q3 For a sample of 80 sleep times, approximately how many of those times are less \nthan Q3?\n8. Sleep 5-Number Summary For a sample of 100 sleep times, give the names of the val-\nues that constitute the 5-number summary. (The actual values can’t be identified; just give the \nnames of those values.)\n9. Estimating s A large sample of sleep times includes values ranging from a low of 4 hours \nto a high of 10 hours. Use the range rule of thumb to estimate the standard deviation.\n10. Sleep Notation Consider a sample of sleep times taken from the population of all adults \nliving in Alaska. Identify the symbols used for the sample mean, population mean, sample stan-\ndard deviation, population standard deviation, sample variance, and the population variance.\nReview Exercises\n1. Ergonomics When designing an eye-recognition security device, engineers must consider \nthe eye heights of standing women. (It’s easy for men to bend lower, but it’s more difficult for \nwomen to rise higher.) Listed below are the eye heights (in millimeters) obtained from a simple \nrandom sample of standing adult women (based on anthropometric survey data from Gordon, \nChurchill, et al.). Use the given eye heights to find the (a) mean; (b) median; (c) mode; (d) mid-\nrange; (e) range; (f) standard deviation; (g) variance.\n1550 1642 1538 1497 1571\nCHAPTER 3 Review Exercises \n115\n",
    "116 \nCHAPTER 3 Describing, Exploring, and Comparing Data\n2. z Score Using the sample data from Exercise 1, find the z score corresponding to the eye \nheight of 1642 mm. Is that eye height significantly low or significantly high? Why or why not?\n3. ER Codes In an analysis of activities that resulted in brain injuries presenting at hospital \nemergency rooms (ERs), the following activities were identified by the code shown in paren-\ntheses: bicycling (12); football (14); playground (22); basketball (27); swimming (40). Find the \nmean of 12, 14, 22, 27, and 40. What is wrong with this result?\n4. Comparing Birth Weights The birth weights of a sample of males have a mean of 3273 g and \na standard deviation of 660 g. The birth weights of a sample of females have a mean of 3037 g \nand a standard deviation of 706 g (based on Data Set 3 “Births” in Appendix B). When consid-\nered among members of the same gender, which baby has the relatively larger birth weight: a \nboy with a birth weight of 3400 g or a girl with a birth weight of 3200 g? Why?\n5. Effects of an Outlier Listed below are platelet counts (1000 cells>mL) from subjects in-\ncluded in Data Set 1 “Body Data.” Identify the outlier and then comment on the effect it has \non the mean and standard deviation by finding the values of those statistics with the outlier \nincluded and then with the outlier excluded.\n263 206 185 246 188 191 308 262 198 253 646\n6. Interpreting a Boxplot Shown below is a boxplot of a sample of 30 maximal skull breadths \n(mm) measured from Egyptian skulls from around 4000 B.C. What do the numbers in the box-\nplot represent?\n7. Interpreting Standard Deviation A physician routinely makes physical examinations of \nchildren. She is concerned that a three-year-old girl has a height of only 87.8 cm. Heights of \nthree-year-old girls have a mean of 97.5 cm and a standard deviation of 6.9 cm (based on data \nfrom the National Health and Nutrition Examination Survey). Use the range rule of thumb to \nfind the limits separating heights of three-year-old girls that are significantly low or signifi-\ncantly high. Based on the result, is the height of 87.8 cm significant? Should the physician be \nconcerned?\n8. Mean or Median? A biostatistics class consists of 30 students with no income, 10 students \nwith small incomes from part-time jobs, plus a professor with a very large income that is well \ndeserved. Which is better for describing the income of a typical person in this class: mean or \nmedian? Explain.\nCumulative Review Exercises\n1. Arsenic in Rice Listed below are measured amounts (mg per serving) of arsenic in a sample \nof servings of brown rice [data from the Food and Drug Administration (FDA)]. Construct a \nfrequency distribution. Use a class width of 2 mg, and use 0 mg as the lower class limit of the \nfirst class.\n6.1 5.4 6.9 4.9 6.6 6.3 6.7 8.2 7.8 1.5 5.4 7.3\n2. Histogram Use the frequency distribution from Exercise 1 to construct a histogram. Use \nclass midpoint values for the horizontal scale.\n3. Stemplot Use the amounts of arsenic from Exercise 1 to construct a stemplot.\n4. Descriptive Statistics Use amounts of arsenic in Exercise 1 and find the following: (a) \nmean; (b) median; (c) standard deviation; (d) variance; (e) range. Include the appropriate units \nof measurement.\n",
    "CHAPTER 3 Cooperative Group Activities \n117\n5. a. A medical researcher has a collection of data at the nominal level of measurement and she \nwants to obtain a representative data value. Which of the following is most appropriate: mean, \nmedian, mode, or midrange? Why?\nb. A botanist wants to obtain data about the plants being grown in homes. If a sample is ob-\ntained by telephoning the first 250 people listed in the local telephone directory, what type of \nsampling is being used? (random, stratified, systematic, cluster, convenience)\nc. A botanist is experimenting with fertilizer sticks used for growing plants. She finds that the \namounts of fertilizer placed in the sticks are not very consistent, so that some fertilization lasts \nlonger than claimed, but others don’t last long enough. She wants to improve quality by making \nthe amounts of fertilizer in the sticks more consistent. When analyzing the amounts of fertil-\nizer for that purpose, which of the following statistics is most relevant: mean, median, mode, \nmidrange, standard deviation, first quartile, third quartile? Should the value of that statistic be \nraised, lowered, or left unchanged?\nTechnology Project\nFreshman 15 Refer to Data Set 10 “Freshman 15” in Appendix B, which includes results from \na study of the legend that college freshmen tend to gain around 15 pounds (or 6.8 kilograms) \nduring their freshman year. That data set includes 5 columns of data from 67 subjects. Use the \nmethods of this chapter to make relevant comparisons, then form a subjective conclusion about \nthe 15-pound (or 6.8-kilogram) weight gain. Write a brief report including your conclusions \nwith supporting graphs and statistics.\nFROM DATA TO DECISION\nSecond-Hand Smoke\nData Set 14 “Passive and Active Smoke” in Appendix B \nlists measures of cotinine from three groups of subjects: \n(1) smokers; (2) nonsmokers exposed to environmental to-\nbacco smoke; and (3) nonsmokers not exposed to environ-\nmental tobacco smoke. Cotinine is an indicator of nicotine \nabsorption.\nCritical Thinking\nUse the methods from this chapter to explore and compare \nthe cotinine measures in the three groups. Are there any \nnotable differences? Are there any outliers? What do you \nconclude about the effects that smokers have on nonsmok-\ners? Write a brief report of your conclusions, and provide \nsupporting statistical evidence.\nCooperative Group Activities\n1. In-class activity In class, each student should record two pulse rates by counting the num-\nber of heartbeats in 1 minute. The first pulse rate should be measured while the student is \nseated, and the second pulse rate should be measured while the student is standing. Use the \nmethods of this chapter to compare results. Do males and females appear to have different \npulse rates? Do pulse rates measured while seated appear to be different from pulse rates mea-\nsured while standing?\n2. Out-of-class activity Appendix B includes many real and interesting data sets. In each \ngroup of three or four students, select a data set from Appendix B and analyze it using the \nmethods discussed so far in this book. Write a brief report summarizing key conclusions.\n3. Out-of-class activity In each group of three or four students, collect an original data set of \nvalues at the interval or ratio level of measurement. Provide the following: (1) a list of sample \nvalues; (2) printed software results of descriptive statistics and graphs; and (3) a written de-\nscription of the nature of the data, the method of collection, and important characteristics.\n",
    "118\nBasic Concepts of \nProbability\nAddition Rule and \nMultiplication Rule\nComplements, \nConditional Probability, \nand Bayes’ Theorem\nRisks and Odds\nRates of Mortality, \nFertility, and Morbidity\nCounting\n4-1\n4-2\n4-3\n4-4\n4-5\n4-6\nDrug Testing of Job Applicants\nCHAPTER \nPROBLEM\nProbability\nApproximately 85% of U. S. companies test employees  \nand>or job applicants for drug use. A common and inexpen-\nsive (around $50) urine test is the EMIT (enzyme multiplied \nimmunoassay technique) test, which tests for the presence of \nany of five drugs: marijuana, cocaine, amphetamines, opiates, \nor phencyclidine. Most companies require that positive test \nresults be confirmed by a more reliable GC-MS (gas chroma-\ntography mass spectrometry) test.\nLike nearly all medical tests, drug tests are sometimes \nwrong. Wrong results are of two different types: (1) false posi-\ntive results and (2) false negative results. In today’s society, \nthese terms should be clearly understood. A job applicant or \n4 \n",
    "employee who gets a false positive result is someone who \nincorrectly appears to be using drugs when he or she is not \nactually using drugs. This type of mistake can unfairly result in \njob denial or termination of employment.\nAnalyzing the Results\nTable 4-1 includes results from 555 adults in the United States. \nIf one of the subjects from Table 4-1 is randomly selected \nfrom those who do not use drugs, what is the probability of a \nfalse positive result? If one of the subjects from Table 4-1 is \nrandomly selected from those who do not use drugs, what is \nthe probability of a true negative result? We will address such \nquestions in this chapter.\n• Prevalence: Proportion of the population having the condi-\ntion (such as drug use or disease) being considered.\n• False positive: Wrong test result that incorrectly indicates \nthat the subject has a condition when the subject does not \nhave that condition.\n• False negative: Wrong test result that incorrectly indicates \nthat the subject does not have a condition when the subject \ndoes have that condition.\n• True positive: Correct test result that indicates that a \n subject has a condition when the subject does have the \ncondition.\n• True negative: Correct test result that indicates that a sub-\nject does not have a condition when the subject does not \nhave the condition.\n• Test sensitivity: The probability of a true positive test \n result, given that the subject actually has the condition \n being tested.\n• Test specificity: The probability of a true negative test \n result, given that the subject does not have the condition \nbeing tested.\n• Positive predictive value: Probability that a subject actu-\nally has the condition, given that the test yields a positive \nresult (indicating that the condition is present).\n• Negative predictive value: Probability that the subject \ndoes not actually have the condition, given that the test \nyields a negative result (indicating that the condition is not \npresent).\nChapter Objectives \n119\nTABLE 4-1 Results from Drug Tests of Job Applicants\nPositive Test Result \n(Test shows drug use.)\nNegative Test Result \n(Test shows no drug use.)\nSubject Uses Drugs\n45\n(True Positive)\n5\n(False Negative)\nSubject Does Not Use Drugs\n25\n(False Positive)\n480\n(True Negative)\nThe main objective of this chapter is to develop a sound understanding of probability \nvalues, because those values constitute the underlying foundation on which methods \nof inferential statistics are built. The important methods of hypothesis testing com-\nmonly use P-values, which are probability values expressed as numbers between 0 \nand 1, inclusive. Smaller probability values, such as 0.01, correspond to events that \nare very unlikely. Larger probability values, such as 0.99, correspond to events that are \nvery likely. Here are the chapter objectives:\nBasic Concepts of Probability\n• Identify probabilities as values between 0 and 1, and interpret those values as \n expressions of likelihood of events.\n• Develop the ability to calculate probabilities of events.\n• Define the complement of an event and calculate the probability of that \n complement.\n4-1\nCHAPTER OBJECTIVES\n>>>\n",
    "120 \nCHAPTER 4 Probability\nKey Concept The single most important objective of this section is to learn how to \ninterpret probability values, which are expressed as values between 0 and 1. A small \nprobability, such as 0.001, corresponds to an event that rarely occurs.\nRole of Probability in Statistics\nProbability plays a central role in the important statistical method of hypothesis \ntesting introduced later in Chapter 8. Statisticians make decisions using data by \nrejecting explanations (such as chance) based on very low probabilities. See the \nfollowing example illustrating the role of probability and a fundamental way that \nstatisticians think.\n4-1 \nBasic Concepts of Probability\nAddition Rule and Multiplication Rule\n• Develop the ability to calculate the probability that in a single trial, some event A oc-\ncurs or some event B occurs or they both occur. Apply the addition rule by correctly \nadjusting for events that are not disjoint (or are overlapping).\n• Develop the ability to calculate the probability of an event A occurring in a first trial \nand an event B occurring in a second trial. Apply the multiplication rule by adjusting \nfor events that are not independent.\n• Distinguish between independent events and dependent events.\nComplements, Conditional Probability, and Bayes’ Theorem\n• Compute the probability of “at least one” occurrence of an event A.\n• Apply the multiplication rule by computing the probability of some event, given that \nsome other event has already occurred.\nRisks and Odds\n• Compare two probabilities using measures of absolute risk reduction and  \nrelative risk.\n• Obtain a measure of risk by calculating the odds ratio.\n• Measure the practical effectiveness of a treatment by determining the “number \nneeded to treat,” which is the number of subjects that must be treated in order to \nprevent one occurrence of some event.\nRates of Mortality, Fertility, and Morbidity\n• Use rates to describe the likelihood of an event.\n• Determine mortality rates, fertility rates, and morbidity rates.\nCounting\n• Develop the ability to apply the fundamental counting rule, factorial rule, permuta-\ntions rule, and combinations rule.\n• Distinguish between circumstances requiring the permutations rule and those \n requiring the combinations rule.\n4-2\n4-3\n4-4\n4-5\n4-6\nAddition Rule and Multiplication Rule\n• Develop the ability to calculate the probability that in a single trial, some event A oc-\ncurs or some event B occurs or they both occur. Apply the addition rule by correctly\nadjusting for events that are not disjoint (or are overlapping).\n• Develop the ability to calculate the probability of an event A occurring in a first trial\nand an event B occurring in a second trial. Apply the multiplication rule by adjusting\nfor events that are not independent.\n• Distinguish between independent events and dependent events.\nComplements, Conditional Probability, and Bayes’ Theorem\n• Compute the probability of “at least one” occurrence of an event A.\n• Apply the multiplication rule by computing the probability of some event, given that\nsome other event has already occurred.\nRisks and Odds\n• Compare two probabilities using measures of absolute risk reduction and  \nrelative risk.\n• Obtain a measure of risk by calculating the odds ratio.\n• Measure the practical effectiveness of a treatment by determining the “number \nneeded to treat,” which is the number of subjects that must be treated in order to\nprevent one occurrence of some event.\nRates of Mortality, Fertility, and Morbidity\n• Use rates to describe the likelihood of an event.\n• Determine mortality rates, fertility rates, and morbidity rates.\nCounting\n• Develop the ability to apply the fundamental counting rule, factorial rule, permuta-\ntions rule, and combinations rule.\n• Distinguish between circumstances requiring the permutations rule and those\nrequiring the combinations rule.\n",
    "4-1 Basic Concepts of Probability \n121\nINTERPRETATION\nAmong the 100 babies, 75 girls and 55 girls are both greater than the 50 girls that \nwe typically expect, but only the event of 75 girls leads us to believe that the gender \nselection method is effective. Even though there is a chance of getting 75 girls (or \nmore) in 100 births with no special treatment, the probability of that happening is so \nsmall (0.0000003) that we should reject chance as a reasonable explanation. Instead, \nit would be generally recognized that the results provide strong support for the claim \nthat the gender selection method is effective. This is exactly how statisticians think: \nThey reject explanations (such as chance) based on very low probabilities.\nEXAMPLE 1  Analyzing a Claim\nResearchers have made this claim (really, they have):\nClaim: “We have developed a gender selection method that greatly increases \nthe likelihood of a baby being a girl.”\nHypothesis Used When Testing the Preceding Claim: The method of gender \nselection has no eﬀect, so that for couples using this method, about 50% of the \nbirths result in girls.\n(The probability of a girl in the United States is actually 0.488, but here we assume \nthat boys and girls are equally likely.)\nFigure 4-1 shows the sample data from two tests of 100 couples using the \n gender selection method and the conclusion reached for each test.\n75\nGirls\nStatisticians reject explanations based on\nvery low probabilities\nTest A Result\nProbability of 75 (or more) Girls by\nchance 5 3 in 10,000,000\n5 0.0000003\nChance rejected as\nreasonable explanation\nGender selection method\nappears to be eﬀective\n25\nBoys\n55\nGirls\nTest B Result\nProbability of 55 (or more) Girls by\nchance 5 184 in 1,000\n5 0.184\nChance not rejected as\nreasonable explanation\nCannot conclude gender\nselection method is eﬀective\n45\nBoys\nDiﬀerent Gender Selection Methods\nTested with 100 Births\nFIGURE 4-1 Gender Selection Method Test Data and Conclusions\nBasics of Probability\nIn probability, we deal with procedures (such as generating male>female births or \nmanufacturing defective>nondefective pregnancy test kits) that produce outcomes.\nProbabilities That \nChallenge Intuition\nIn certain cases, \nour subjective \nestimates of \nprobability val-\nues are dramati-\ncally different \nfrom the actual \nprobabilities. \nHere is a classical example: If \nyou take a deep breath, there is \nbetter than a 99% chance that \nyou will inhale a molecule that \nwas exhaled in dying Caesar’s \nlast breath. In that same morbid \nand unintuitive spirit, if Socrates’ \nfatal cup of hemlock was mostly \nwater, then the next glass of \nwater you drink will likely contain \none of those same molecules. \nHere’s another, less morbid \nexample that can be verified: In \nclasses of 25 students, there is \nbetter than a 50% chance that \nat least 2 students will share the \nsame birthday (day and month).\n",
    "122 \nCHAPTER 4 Probability\nExample 2 illustrates the concepts defined above.\nDEFINITIONS\nAn event is any collection of results or outcomes of a procedure.\nA simple event is an outcome or an event that cannot be further broken down into \nsimpler components.\nThe sample space for a procedure consists of all possible simple events. That is, \nthe sample space consists of all outcomes that cannot be broken down any further.\nEXAMPLE 2  Simple Event and Sample Spaces\nIn the following display, we use “b” to denote a baby boy and “g” to denote a \nbaby girl.\n \nProcedure\n \nExample of Event\nSample Space: Complete \nList of Simple Events\nSingle birth\n1 girl (simple event)\n{b, g}\n3 births\n2 boys and 1 girl (bbg, \nbgb, and gbb are all \nsimple events resulting in \n2 boys and 1 girl)\n{bbb, bbg, bgb, bgg, gbb, \ngbg, ggb, ggg}\nSimple Events:\n \n■With one birth, the result of 1 girl is a simple event and the result of 1 boy is \nanother simple event. They are individual simple events because they cannot be \nbroken down any further.\n \n■With three births, the result of 2 girls followed by a boy (ggb) is a simple event.\n \n■When rolling a single die, the outcome of 5 is a simple event, but the outcome \nof an even number is not a simple event.\nNot a Simple Event: With three births, the event of “2 girls and 1 boy” is not  \na simple event because it can occur with these diﬀerent simple events: ggb,  \ngbg, bgg.\nSample Space: With three births, the sample space consists of the eight  diﬀerent \nsimple events listed in the above table.\nThree Common Approaches to Finding the Probability of an Event\nWe first list some basic notation, and then we present three common approaches to \nfinding the probability of an event.\nNotation for Probabilities\nP denotes a probability.\nA, B, and C denote specific events.\nP(A) denotes the “probability of event A occurring.”\nThe following three approaches for finding probabilities result in values between 0 \nand 1: 0 … P1A2 … 1. Figure 4-2 shows the possible values of probabilities and the \nmore familiar and common expressions of likelihood.\nCertain\nLikely\n50–50 Chance\nUnlikely\nImpossible\n0\n0.5\n1\nFIGURE 4-2 Possible \nValues for Probabilities\n",
    "4-1 Basic Concepts of Probability \n123\n1. Relative Frequency Approximation of Probability Conduct (or observe) a \nprocedure and count the number of times that event A occurs. P(A) is then ap-\nproximated as follows:\nP1A2 =\nnumber of times A occurred\nnumber of times the procedure was repeated\nWhen referring to relative frequency approximations of probabilities, this text \nwill not distinguish between results that are exact probabilities and those that \nare approximations, so an instruction to “find the probability” could actually \nmean “estimate the probability.”\n2. Classical Approach to Probability (Requires Equally Likely Outcomes) \nIf a procedure has n different simple events that are equally likely, and if \nevent A can occur in s different ways, then\nP1A2 =\nnumber of ways A occurs\nnumber of different simple events = s\nn\nCAUTION When using the classical approach, always confirm that the outcomes \nare equally likely.\n3. Subjective Probabilities P(A), the probability of event A, is estimated by \nusing knowledge of the relevant circumstances.\nFigure 4-3 illustrates the approaches of the preceding three definitions.\n1. Relative Frequency Approach: When trying to de-\ntermine the probability that an individual car crashes in a \nyear, we must examine past results to determine the num-\nber of cars in use in a year and the number of them that \ncrashed; then we ﬁnd the ratio of the number of cars that \ncrashed to the total number of cars. For a recent year, the \nresult is a probability of 0.0480. (See Example 3.)\n2. Classical Approach: When trying to determine the \nprobability of randomly selecting three children who are \nof the same gender, there are two ways to get the same \ngenders (boy/boy/boy and girl/girl/girl) among the eight \nequally likely outcomes, so the probability is 2/8 or 1/4. \n(See Example 4.)\n3. Subjective Probability: When trying to estimate the \nprobability of someone with an appendix getting acute \nappendicitis in the next year, we know from personal ex-\nperience that the probability is quite small. Let’s estimate \nit to be, say, 0.001 (equivalent to 1 chance in 1000). (See \nExample 5.)\nFIGURE 4-3 Three Approaches to Finding a Probability\n",
    "124 \nCHAPTER 4 Probability\nSimulations Sometimes none of the preceding three approaches can be used. A simu-\nlation of a procedure is a process that behaves in the same ways as the procedure itself \nso that similar results are produced. Probabilities can sometimes be found by using a \nsimulation. See the Technology Project near the end of this chapter.\nRounding Probabilities Although it is difficult to develop a universal rule for round-\ning off probabilities, the following guide will apply to most problems in this text.\nROUNDING PROBABILITIES\nWhen expressing the value of a probability, either give the exact fraction or deci-\nmal or round off final decimal results to three significant digits. (Suggestion: When \na probability is not a simple fraction such as 2>3 or 5>9, express it as a decimal so \nthat the number can be better understood.) All digits in a number are significant ex-\ncept for the zeros that are included for proper placement of the decimal point. See \nthe following examples.\n \n■The probability of 0.4450323339 (from Example 6) has ten significant digits \n(4450323339), and it can be rounded to three significant digits as 0.445.\n \n■The probability of 1>3 can be left as a fraction or rounded to 0.333. (Do not \nround to 0.3.)\n \n■The probability of 2>8 can be expressed as 1>4 or 0.25. (Because 0.25 is exact, \nthere’s no need to express it with three significant digits as 0.250.)\nProbabilities Expressed as Percentages? Mathematically, a probability of 0.25 is \nequivalent to 25%, but there are good reasons for sticking with fractions and decimals \nand not using percentages. Professional journals almost universally express probabili-\nties as decimals, not as percentages. Later in this book, we will use probability values \ngenerated from statistical software, and they will always be in the form of decimals.\nWhen finding probabilities with the relative frequency approach, we obtain an ap-\nproximation instead of an exact value. As the total number of observations increases, \nthe corresponding approximations tend to get closer to the actual probability. This \nproperty is commonly referred to as the law of large numbers.\nLAW OF LARGE NUMBERS\nAs a procedure is repeated again and again, the relative frequency probability of \nan event tends to approach the actual probability.\nThe law of large numbers tells us that relative frequency approximations tend to get \nbetter with more observations. This law reflects a simple notion supported by common \nsense: A probability estimate based on only a few trials can be off by a substantial amount, \nbut with a very large number of trials, the estimate tends to be much more accurate.\nCAUTIONS\n1.  The law of large numbers applies to behavior over a large number of trials, and it \ndoes not apply to any one individual outcome. Gamblers sometimes foolishly lose \nlarge sums of money by incorrectly thinking that a string of losses increases the \nchances of a win on the next bet, or that a string of wins is likely to continue.\n2.  If we know nothing about the likelihood of different possible outcomes, we \nshould not assume that they are equally likely. For example, we should not think \nthat the probability of passing the next statistics test is 1>2, or 0.5 (because we \neither pass the test or do not). The actual probability depends on factors such \nas the amount of preparation and the difficulty of the test.\n",
    "4-1 Basic Concepts of Probability \n125\nEXAMPLE 3  Relative Frequency Probability: Skydiving\nFind the probability of dying when making a skydiving jump.\nSOLUTION\nIn a recent year, there were about 3,000,000 skydiving jumps and 21 of them \n resulted in deaths. We use the relative frequency approach as follows:\nP1skydiving death2 =\nnumber of skydiving deaths\ntotal number of skydiving jumps =\n21\n3,000,0000 = 0.000007\nHere the classical approach cannot be used because the two outcomes (dying, \n surviving) are not equally likely. A subjective probability can be estimated in the \nabsence of historical data.\nEXAMPLE 4   Classical Probability: Three Children of the  \nSame Gender\nWhen three children are born, the sample space of genders is as shown in Example 1: \n{bbb, bbg, bgb, bgg, gbb, gbg, ggb, ggg}. If boys and girls are equally likely, then \nthose eight simple events are equally likely. Assuming that boys and girls are equally \nlikely, find the probability of getting three children all of the same gender when three \nchildren are born. (In reality, the probability of a boy is 0.512 instead of 0.5.)\nSOLUTION\nThe sample space {bbb, bbg, bgb, bgg, gbb, gbg, ggb, ggg} includes eight equally \nlikely outcomes, and there are exactly two outcomes in which the three children are \nof the same gender: bbb and ggg. We can use the classical approach to get\nP1three children of the same gender2 = 2\n8 = 1\n4  or  0.25\nEXAMPLE 5  Subjective Probability: Acute Appendicitis\nWhat is the probability that you will get acute appendicitis next year?\nSOLUTION\nWe could probably find past results and use the relative frequency approach, but for \nnow, in the absence of historical data on acute appendicitis, we make a subjective \nestimate. Experience suggests that the probability is quite small. Let’s estimate it to \nbe, say, 0.001 (equivalent to 1 chance in 1000). Depending on our knowledge of the \nrelevant circumstances, that subjective estimate might be reasonably accurate or it \nmight be grossly wrong.\nCAUTION Don’t make the common mistake of finding a probability value by \nmindlessly dividing a smaller number by a larger number. Instead, think carefully \nabout the numbers involved and what they represent. Carefully identify the total \nnumber of items being considered, as illustrated in Example 6.\n",
    "126 \nCHAPTER 4 Probability\nInstead of trying to determine an answer directly from the given statement, first sum-\nmarize the information in a format that allows clear understanding, such as this format:\n 3785 texted while driving\n 4720 did not text while driving\n 8505 total number of drivers in the sample\nWe can now use the relative frequency approach as follows:\n P1texting while driving2 = number of drivers who texted while driving\ntotal number of drivers in the sample\n= 3785\n8505\n = 0.445\nINTERPRETATION\nThere is a 0.445 probability that if a high school driver is randomly selected, he or \nshe texted while driving during the previous 30 days.\nEXAMPLE 6  Texting and Driving\nIn a study of U.S. high school drivers, it was found that 3785 texted while driving \nduring the previous 30 days, and 4720 did not text while driving during that same \ntime period (based on data from “Texting While Driving . . . . ,” by Olsen, Shults, \nEaton, Pediatrics, Vol. 131, No. 6). Based on these results, if a high school driver is \nrandomly selected, find the probability that he or she texted while driving during the \nprevious 30 days.\nSOLUTION\nCAUTION A common mistake is to blindly plug in numbers to get the wrong \nprobability of 3785>4720 = 0.802. We should think about what we are doing, as \nfollows.\nEXAMPLE 7  Thanksgiving Day\nIf a year is selected at random, find the probability that Thanksgiving Day in the \nUnited States will be (a) on a Wednesday or (b) on a Thursday.\nSOLUTION\na. In the United States, Thanksgiving Day always falls on the fourth Thursday  \nin November. It is therefore impossible for Thanksgiving to be on \na  Wednesday. When an event is impossible, its probability is 0. \nP(Thanksgiving on Wednesday) = 0.\nb. It is certain that a Thanksgiving Day in the United States will be on \na  Thursday. When an event is certain to occur, its probability is 1. \nP(Thanksgiving on Thursday) = 1.\nBecause any event imaginable is impossible, certain, or somewhere in between, \nit follows that the mathematical probability of any event A is 0, 1, or a number \nbetween 0 and 1 (as shown in Figure 4-2). That is, 0 … P1A2 … 1.\n",
    "4-1 Basic Concepts of Probability \n127\nComplementary Events\nSometimes we need to find the probability that an event A does not occur.\nDEFINITION\nThe complement of event A, denoted by A, consists of all outcomes in which event \nA does not occur.\nEXAMPLE 8  Complement of Death from Skydiving\nExample 3 shows that in a recent year, there were 3,000,000 skydiving jumps and \n21 of them resulted in death. Find the probability of not dying when making a \nskydiving jump.\nSOLUTION\nAmong 3,000,000 jumps there were 21 deaths, so it follows that the other 2,999,979 \njumps were survived. We get\nP1not dying when making a skydiving jump2 = 2,999,979\n3,000,000 = 0.999993\nINTERPRETATION\nThe probability of not dying when making a skydiving jump is 0.999993.\nRelationship Between P1A2 and P1A2 If we denote the event of dying in a \n skydiving jump by D, Example 3 showed that P1D2 = 0.000007 and Example 8 \nshowed that P1D2 = 0.999993. The probability of P1D2 could be found by just sub-\ntracting P(D) from 1.\nIdentifying Significant Results with Probabilities:  \nThe Rare Event Rule for Inferential Statistics\nIf, under a given assumption, the probability of a particular observed event is \nvery small and the observed event occurs signiﬁcantly less than or signiﬁcantly \ngreater than what we typically expect with that assumption, we conclude that \nthe assumption is probably not correct.\nWe can use probabilities to identify values that are significantly low or significantly \nhigh as follows.\nUsing Probabilities to Determine When Results Are Significantly High or \nSignificantly Low\n \n■Significantly high number of successes: x successes among n trials is a signifi-\ncantly high number of successes if the probability of x or more successes is un-\nlikely with a probability of 0.05 or less. That is, x is a significantly high number \nof successes if P(x or more) … 0.05.*\n \n■Significantly low number of successes: x successes among n trials is a sig-\nnificantly low number of successes if the probability of x or fewer successes is \nunlikely with a probability of 0.05 or less. That is, x is a significantly low number \nof successes if P(x or fewer) … 0.05.*\n*The value 0.05 is not absolutely rigid. Other values, such as 0.01, could be used to distinguish between results \nthat can easily occur by chance and events that are significant.\n",
    "128 \nCHAPTER 4 Probability\nSee Example 1 on page 121, which illustrates the following:\n \n■Among 100 births, 75 girls is significantly high because the probability of 75 \nor more girls is 0.0000003, which is less than or equal to 0.05 (so the gender \nselection method appears to be effective).\n \n■Among 100 births, 55 girls is not significantly high because the probability of 55 \nor more girls is 0.184, which is greater than 0.05 (so the gender selection does \nnot appear to be effective).\nProbability Review\nImportant Principles and Notation for Probability\n \n■The probability of an event is a fraction or decimal number between 0 and 1 \ninclusive.\n \n■The probability of an impossible event is 0.\n \n■The probability of an event that is certain to occur is 1.\n \n■Notation: P1A2 = the probability of event A.\n \n■Notation: P1A2 = the probability that event A does not occur.\nStatistical Literacy and Critical Thinking \n1. Probability Rewrite the following statement with the probability expressed as a number \nwith a decimal format: “The probability of selecting someone with blue eyes is 35%.”\n2. Probability Given that the following statement is incorrect, rewrite it correctly: “The prob-\nability of a baby being born a boy is 50-50.”\n3. Births In Example 4 “Three Children of the Same Gender” it was noted that in reality, the \nprobability of a boy is 0.512 instead of 0.5. Let A denote the event of getting a boy when a baby \nis born. What is the value of P1A2?\n4. Subjective Probability Estimate the probability that the next time a physician walks into \na patient’s room and turns on a light switch, she discovers that the light bulb does work.\n5. Identifying Probability Values Which of the following are probabilities?\n0 3>5 5>3 -0.25 250% 7:3 1 50@50 5:1 0.135 2.017\n6. Penicillin “Who discovered penicillin: Sean Penn, William Penn, Penn Jillette, Alexander \nFleming, or Louis Pasteur?” If you make a random guess for the answer to that question, what \nis the probability that your answer is the correct answer of Alexander Fleming?\n7. Avogadro Constant If you are asked on a quiz to give the first (leftmost) nonzero digit \nof the Avogadro constant and, not knowing the answer, you make a random guess, what is the \nprobability that your answer is the correct answer of 6?\n8. Births Example 2 in this section includes the sample space for genders from three births. \nIdentify the sample space for the genders from two births.\nIn Exercises 9–12, assume that 50 births are randomly selected. Use subjective judgment to \ndescribe the given number of girls as (a) significantly low, (b) significantly high, or (c) nei-\nther significantly low nor significantly high.\n9. 47 girls.   10. 26 girls.   11. 23 girls.   12. 5 girls.\n4-1 Basic Skills and Concepts\n",
    "4-1 Basic Concepts of Probability \n129\nIn Exercises 13–20, express the indicated degree of likelihood as a probability value \nbetween 0 and 1.\n13. Testing If you make a random guess for the answer to a true>false test question, there is a \n50-50 chance of being correct.\n14. MCAT Test When making a random guess for an answer to a multiple-choice question on \nan MCAT test, the possible answers are a, b, c, d, e, so there is 1 chance in 5 of being correct.\n15. Genes One of the four DNA bases of A, G, C, and T is randomly selected, and the result is \nG. Assume that the four DNA bases are equally likely.\n16. Sleepwalking Based on a report in Neurology magazine, 29.2% of survey respondents \nhave sleepwalked.\n17. Randomness When using a computer to randomly generate the last digit of a phone \nnumber to be called for a survey, there is 1 chance in 10 that the last digit is zero.\n18.  Job Applicant Mistakes Based on an Adecco survey of hiring managers who were \nasked to identify the biggest mistakes that job candidates make during an interview, there is a \n50-50 chance that they will identify “inappropriate attire.”\n19. Square Peg Sydney Smith wrote in “On the Conduct of the Understanding” that it is im-\npossible to fit a square peg in a round hole.\n20. Death and Taxes Benjamin Franklin said that death is a certainty of life.\nIn Exercises 21–24, refer to the sample data in Table 4-1, which is included with the \n Chapter Problem. Assume that 1 of the 555 subjects included in Table 4-1 is randomly selected.\nTABLE 4-1 Results from Drug Tests of Job Applicants\nPositive Test Result \n(Test shows drug use.)\nNegative Test Result\n(Test shows no drug use.)\nSubject Uses Drugs\n45\n(True Positive)\n5\n(False Negative)\nSubject Does Not Use Drugs\n25\n(False Positive)\n480\n(True Negative)\n21. Drug Testing Job Applicants Find the probability of selecting someone who got a re-\nsult that is a false negative. Who would suffer from a false negative result? Why?\n22. Drug Testing Job Applicants Find the probability of selecting someone who got a re-\nsult that is a false positive. Who would suffer from a false positive result? Why?\n23.  Drug Testing Job Applicants Find the probability of selecting someone who uses \ndrugs. Does the result appear to be reasonable as an estimate of the “prevalence rate” described \nin the Chapter Problem?\n24. Drug Testing Job Applicants Find the probability of selecting someone who does not \nuse drugs. Does the result appear to be reasonable as an estimate of the proportion of the adult \npopulation that does not use drugs?\nIn Exercises 25–32, find the probability and answer the questions.\n25. XSORT Gender Selection MicroSort’s XSORT gender selection technique was designed \nto increase the likelihood that a baby will be a girl. At one point before clinical trials of the \nXSORT gender selection technique were discontinued, 945 births consisted of 879 baby girls \nand 66 baby boys (based on data from the Genetics & IVF Institute). Based on these results, \nwhat is the probability of a girl born to a couple using MicroSort’s XSORT method? Does it ap-\npear that the technique is effective in increasing the likelihood that a baby will be a girl?\n",
    "130 \nCHAPTER 4 Probability\n26.  YSORT Gender Selection MicroSort’s YSORT gender-selection technique is de-\nsigned to increase the likelihood that a baby will be a boy. At one point before clinical trials \nof the YSORT gender-selection technique were discontinued, 291 births consisted of 239 \nbaby boys and 52 baby girls (based on data from the Genetics & IVF Institute). Based on \nthese results, what is the probability of a boy born to a couple using MicroSort’s YSORT \nmethod? Does it appear that the technique is effective in increasing the likelihood that a baby \nwill be a boy?\n27. Mendelian Genetics When Mendel conducted his famous genetics experiments with \npeas, one sample of offspring consisted of 428 green peas and 152 yellow peas. Based on those \nresults, estimate the probability of getting an offspring pea that is green. Is the result reasonably \nclose to the expected value of 3>4, as Mendel claimed?\n28. Guessing Birthdays On their first date, Kelly asks Mike to guess the date of her birth, \nnot including the year.\na. What is the probability that Mike will guess correctly? (Ignore leap years.)\nb. Would it be unlikely for him to guess correctly on his first try?\nc. If you were Kelly, and Mike did guess correctly on his first try, would you believe his claim \nthat he made a lucky guess, or would you be convinced that he already knew when you were \nborn?\nd. If Kelly asks Mike to guess her age, and Mike’s guess is too high by 15 years, what is the \nprobability that Mike and Kelly will have a second date?\n29. Online Medicine In a survey, 933 respondents say that they seek medical information \nonline and 139 other respondents say that they never seek medical information online. What is \nthe probability that a randomly selected person never seeks medical information online? Is it \nunlikely for someone to never seek medical information online? How are these results affected \nby the fact that the responses are from subjects who decided to respond to the survey posted on \nthe Internet by AOL?\n30. Car Rollovers In a recent year in the United States, 83,600 passenger cars rolled over \nwhen they crashed, and 5,127,400 passenger cars did not roll over when they crashed. Find the \nprobability that a randomly selected passenger car crash results in a rollover. Is it unlikely for a \ncar to roll over in a crash?\n31. Genetics: Eye Color Each of two parents has the genotype brown>blue, which con-\nsists of the pair of alleles that determine eye color, and each parent contributes one of those \nalleles to a child. Assume that if the child has at least one brown allele, that color will domi-\nnate and the eyes will be brown. (The actual determination of eye color is more complicated \nthan that.)\na. List the different possible outcomes. Assume that these outcomes are equally likely.\nb. What is the probability that a child of these parents will have the blue>blue genotype?\nc. What is the probability that the child will have brown eyes?\n32. X-Linked Genetic Disease Men have XY (or YX) chromosomes and women have XX \nchromosomes. X-linked recessive genetic diseases (such as juvenile retinoschisis) occur when \nthere is a defective X chromosome that occurs without a paired X chromosome that is not defec-\ntive. In the following, represent a defective X chromosome with lowercase x, so a child with the \nxY or Yx pair of chromosomes will have the disease and a child with XX or XY or YX or xX or \nXx will not have the disease. Each parent contributes one of the chromosomes to the child.\na. If a father has the defective x chromosome and the mother has good XX chromosomes, \nwhat is the probability that a son will inherit the disease?\nb. If a father has the defective x chromosome and the mother has good XX chromosomes, \nwhat is the probability that a daughter will inherit the disease?\ncontinued\n",
    "4-2 Addition Rule and Multiplication Rule \n131\nc. If a mother has one defective x chromosome and one good X chromosome and the father \nhas good XY chromosomes, what is the probability that a son will inherit the disease?\nd. If a mother has one defective x chromosome and one good X chromosome and the father \nhas good XY chromosomes, what is the probability that a daughter will inherit the disease?\nProbability from a Sample Space. In Exercises 33–36, use the given sample space or \nconstruct the required sample space to find the indicated probability.\n33. Three Children Use this sample space listing the eight simple events that are possible when \na couple has three children (as in Example 2 on page 122): {bbb, bbg, bgb, bgg, gbb, gbg, ggb, \nggg}. Assume that boys and girls are equally likely, so that the eight simple events are equally \nlikely. Find the probability that when a couple has three children, there is exactly one girl.\n34. Three Children Using the same sample space and assumption from Exercise 33, find the \nprobability that when a couple has three children, there are exactly two girls.\n35. Four Children Exercise 33 lists the sample space for a couple having three children. After \nidentifying the sample space for a couple having four children, find the probability of getting \nthree girls and one boy (in any order).\n36. Four Children Using the same sample space and assumption from Exercise 35, find the \nprobability that when a couple has four children, all four are of the same gender.\nUsing Probability to Form Conclusions. In Exercises 37–40, use the given probability value \nto determine whether the sample results could easily occur by chance, then form a conclusion.\n37. Predicting Gender A study addressed the issue of whether pregnant women can cor-\nrectly predict the gender of their baby. Among 104 pregnant women, 57 correctly predicted the \ngender of their baby (based on data from “Are Women Carrying ‘Basketballs’…,” by Perry, \nDiPietro, Constigan, Birth, Vol. 26, No. 3). If pregnant women have no such ability, there is a \n0.327 probability of getting such sample results by chance. What do you conclude?\n38. Clinical Trial of Tamiflu Clinical trials involved the use of Tamiflu (oseltamivir phos-\nphate) for treating flu patients. Among 724 patients treated with Tamiflu, 72 (or about 10%) \nexperienced nausea. (An untreated group experienced a 6% rate of nausea.) If Tamiflu really \nhas no effect on nausea, there is a 0.00000246 probability of getting these sample results by \nchance. What do you conclude about the effect of Tamiflu on nausea?\n39. Sleepiness In a clinical trial of OxyContin (oxycodone) used for pain relief, 227 sub-\njects were treated with OxyContin and 52 of them experienced sleepiness (based on data from \nPurdue Pharma L.P.). If OxyContin has no effect on sleepiness, the probability of getting these \nsample results by chance is less than 0.001 (when comparing this sample group with another \ngroup not treated with OxyContin). What do you conclude?\n40. Cell Phones and Cancer A study of 420,095 Danish cell phone users resulted in 135 \nwho developed cancer of the brain or nervous system (based on data from the Journal of the \nNational Cancer Institute). When comparing this sample group to another group of people who \ndid not use cell phones, it was found that there is a probability of 0.512 of getting such sample \nresults by chance. What do you conclude?\nKey Concepts In this section we present the addition rule as a tool for finding \nP(A or B), which is the probability that either event A occurs or event B occurs (or they \nboth occur) as the single outcome of a procedure. To find P(A or B), we begin by add-\ning the number of ways that A can occur and the number of ways that B can occur, but \nadd without double counting. The word “or” in the addition rule is associated with the \naddition of probabilities.\n4-2 \nAddition Rule and Multiplication Rule\n",
    "132 \nCHAPTER 4 Probability\nThis section also presents the basic multiplication rule used for finding P(A and B), \nwhich is the probability that event A occurs and event B occurs. If the outcome of \nevent A somehow affects the probability of event B, it is important to adjust the prob-\nability of B to reflect the occurrence of event A. The rule for finding P(A and B) is \ncalled the multiplication rule because it involves the multiplication of the probability \nof event A and the probability of event B (where, if necessary, the probability of event \nB is adjusted because of the outcome of event A). The word “and” in the multiplica-\ntion rule is associated with the multiplication of probabilities.\nIn Section 4-1 we considered only simple events, but in this section we consider \ncompound events.\nDEFINITION\nA compound event is any event combining two or more simple events.\nAddition Rule\nNotation for Addition Rule\nP1A or B2 = P1in a single trial, event A occurs or event B occurs or they \nboth occur2\nThe word “or” used in the preceding notation is the inclusive or, which means ei-\nther one or the other or both. The formal addition rule is often presented as a formula, \nbut blind use of formulas is not recommended. Instead, understand the spirit of the \nrule and use that understanding, as in the intuitive addition rule that follows.\nINTUITIVE ADDITION RULE\nTo find P(A or B), add the number of ways event A can occur and the number of \nways event B can occur, but add in such a way that every outcome is counted only \nonce. P(A or B) is equal to that sum, divided by the total number of outcomes in the \nsample space.\nFORMAL ADDITION RULE\nP1A or B2 = P1A2 + P1B2 - P1A and B2\nwhere P(A and B) denotes the probability that A and B both occur at the same time \nas an outcome in a trial of a procedure.\nOne way to apply the addition rule is to add the probability of event A and the \nprobability of event B and, if there is any overlap that causes double-counting, com-\npensate for it by subtracting the probability of outcomes that are included twice. This \napproach is reflected in the above formal addition rule.\nEXAMPLE 1  Drug Testing of Job Applicants\nRefer to Table 4-1, reproduced here for your convenience and viewing pleasure. \nIf 1 subject is randomly selected from the 555 subjects given a drug test, find the \nprobability of selecting a subject who had a positive test result or uses drugs.\nw\nev\nab\nProportions of  \nMales, Females\nIt is well \nknown that \nwhen a baby is \nborn, boys and \ngirls are not \nequally likely. It \nis currently be-\nlieved that 105 boys are born for \nevery 100 girls, so the probability \nof a boy is 0.512. Kristen Navara \nof the University of Georgia \nconducted a study showing that \naround the world, more boys are \nborn than girls, but the difference \nbecomes smaller as people are \nlocated closer to the equator. \nShe used latitudes, tempera-\ntures, unemployment rates, and \ngross national products from \n200 countries and conducted a \nstatistical analysis showing that \nthe proportions of boys appear \nto be affected only by latitude \nand its related weather. So far, no \none has identified a reasonable \nexplanation for this phenomenon.\n",
    "4-2 Addition Rule and Multiplication Rule \n133\nDisjoint Events and the Addition Rule\nThe addition rule is simplified when the events are disjoint.\nTABLE 4-1 Results from Drug Tests of Job Applicants\nPositive Test Result\n(Test shows drug use.)\nNegative Test Result\n(Test shows no drug use.)\nSubject Uses Drugs\n45\n(True Positive)\n5\n(False Negative)\nSubject Does Not Use Drugs\n25\n(False Positive)\n480\n(True Negative)\n*Numbers in red correspond to positive test results or subjects who use drugs, and the total of  \nthose numbers is 75.\nSOLUTION\nRefer to Table 4-1 and carefully count the number of subjects who tested positive \n(first column) or use drugs (first row), but be careful to count subjects exactly once, \nnot twice. When adding the frequencies from the first column and the first row, \ninclude the frequency of 45 only once. In Table 4-1, there are 45 + 25 + 5 = 75 \nsubjects who had positive test results or use drugs. We get this result:\nP1positive test result or subject uses drugs2 = 75>555 = 0.135\nDEFINITION\nEvents A and B are disjoint (or mutually exclusive) if they cannot occur at the \nsame time. (That is, disjoint events do not overlap.)\nEXAMPLE 2  Disjoint Events\nDisjoint events:\nEvent A—Randomly selecting someone \nfor a clinical trial who is a male\nEvent B—Randomly selecting someone \nfor a clinical trial who is a female\n(The selected person cannot be both.)\nEvents that are not disjoint:\nEvent A—Randomly selecting someone \ntaking a statistics course\nEvent B—Randomly selecting someone \nwho is a female\n(The selected person can be both.)\nWhenever A and B are disjoint, P(A and B) becomes zero in the formal addition \nrule, so for disjoint events A and B we have P1A or B2 = P1A2 + P1B2. But again, \ninstead of blind use of a formula, it is better to understand and use the intuitive addi-\ntion rule.\nHere is a summary of the key points of the addition rule:\n1. To find P(A or B), first associate the word or with addition.\n2. To find the value of P(A or B), add the number of ways A can occur and the \nnumber of ways B can occur, but be careful to add without double counting.\n",
    "134 \nCHAPTER 4 Probability\nComplementary Events and the Addition Rule\nIn Section 4-1 we used A to indicate that event A does not occur. Common sense dic-\ntates this principle: We are certain (with probability 1) that either an event A occurs or \nit does not occur, so it follows that P1A or A2 = 1. Because events A and A must be \ndisjoint, we can use the addition rule to express this principle as follows:\nP1A or A2 = P1A2 + P1A2 = 1\nThis result of the addition rule leads to the following three expressions that are “equiv-\nalent” in the sense that they are just different forms of the same principle.\nRULE OF COMPLEMENTARY EVENTS\nP1A2 + P1A2 = 1   P1A2 = 1 - P1A2  P1A2 = 1 - P1A2\nEXAMPLE 3  Sleepwalking\nBased on a journal article, the probability of randomly selecting someone who has \nsleepwalked is 0.292, so P(sleepwalked) = 0.292 (based on data from “Prevalence \nand Comorbidity of Nocturnal Wandering in the U.S. General Population,” by \nOhayon et al., Neurology, Vol. 78, No. 20). If a person is randomly selected, find the \nprobability of getting someone who has not sleepwalked.\nSOLUTION\nUsing the rule of complementary events, we get\nP1has not sleepwalked2 = 1 - P1sleepwalked2 = 1 - 0.292 = 0.708\nThe probability of randomly selecting someone who has not sleepwalked is 0.708.\nMultiplication Rule\nNotation for Multiplication Rule\nWe begin with basic notation followed by the multiplication rule. We strongly suggest \nusing the intuitive multiplication rule, because it is based on understanding instead of \nblind use of a formula.\nNotation\nP1A and B2 = P1event A occurs in one trial and event B occurs in a  \n      different trial2\nP1B\u001eA2 represents the probability of event B occurring after it is assumed that \nevent A has already occurred. (Interpret B\u001eA as “event B occurs after event A has \nalready occurred.”)\nCAUTION The notation P(A and B) has two meanings, depending on its context. \nFor the multiplication rule, P(A and B) denotes that event A occurs in one trial and \nevent B occurs in another trial; for the addition rule we use P(A and B) to denote \nthat events A and B both occur in the same trial.\n",
    "4-2 Addition Rule and Multiplication Rule \n135\nINTUITIVE MULTIPLICATION RULE\nTo find the probability that event A occurs in one trial and event B occurs in an-\nother trial, multiply the probability of event A by the probability of event B, but be \nsure that the probability of event B is found by assuming that event A has already \noccurred.\nFORMAL MULTIPLICATION RULE\nP1A and B2 = P1A2 # P1B\u001e A2\nIndependence and the Multiplication Rule\nWhen applying the multiplication rule and considering whether the probability of \nevent B must be adjusted to account for the previous occurrence of event A, we are \nfocusing on whether events A and B are independent.\nDEFINITIONS\nTwo events A and B are independent if the occurrence of one does not affect the \nprobability of the occurrence of the other. (Several events are independent if the \noccurrence of any does not affect the probabilities of the occurrence of the oth-\ners.) If A and B are not independent, they are said to be dependent.\nCAUTION Don’t think that dependence of two events means that one is the direct \ncause of the other. Having a working light in your kitchen and having a working \nlight in your bedroom are dependent events because they share the same power \nsource. One of the lights may stop working for many reasons, but if one light is out, \nthere is a higher probability that the other light will be out (because of the common \npower source).\nExample 4 illustrates the basic multiplication rule, with independent events in part (a) \nand dependent events in part (b).\nEXAMPLE 4  Drug Screening and the Basic Multiplication Rule\nLet’s use only the 50 test results from the subjects who use drugs (from Table 4-1), \nas shown below:\nPositive Test Results: \n45\nNegative Test Results: \n5\nTotal: \n50\na. If 2 of these 50 subjects are randomly selected with replacement, ﬁnd the \n probability that the ﬁrst selected person had a positive test result and the sec-\nond selected person had a negative test result.\n \nb. Repeat part (a) by assuming that the two subjects are selected without \n replacement.\ncontinued\n",
    "136 \nCHAPTER 4 Probability\nThe key point of part (b) in Example 4 is this: We must adjust the probability of the \nsecond event to reflect the outcome of the first event. Because selection of the second \nsubject is made without replacement of the first subject, the second probability must \ntake into account the fact that the first selection removed a subject who tested positive, \nso only 49 subjects are available for the second selection, and 5 of them had a negative \ntest result. Part (a) of Example 4 involved sampling with replacement, so the events \nare independent; part (b) of Example 4 involved sampling without replacement, so the \nevents are dependent. See the following.\nSampling In the wonderful world of statistics, sampling methods are critically impor-\ntant, and the following relationships hold:\n \n■Sampling with replacement: Selections are independent events.\n \n■Sampling without replacement: Selections are dependent events.\nException: Treating Dependent Events as Independent\nSome cumbersome calculations can be greatly simplified by using the common prac-\ntice of treating events as independent when small samples are drawn without replace-\nment from large populations. (In such cases, it is rare to select the same item twice.) \nHere is a common guideline routinely used with applications such as analyses of sur-\nvey results:\nTREATING DEPENDENT EVENTS AS INDEPENDENT:  \n5% GUIDELINE FOR CUMBERSOME CALCULATIONS\nWhen sampling without replacement and the sample size is no more than 5% of the \nsize of the population, treat the selections as being independent (even though they \nare actually dependent).\nSOLUTION\na. With Replacement: First selection (with 45 positive results among 50 total \nresults):\nP1positive test result2 = 45\n50\nSecond selection (with 5 negative test results among the same 50 total results):\nP1negative test result2 = 5\n50\nWe now apply the multiplication rule as follows:\nP11st selection is positive and 2nd is negative2 = 45\n50 # 5\n50 = 0.0900\nb. Without Replacement: Without replacement of the ﬁrst subject, the calcula-\ntions are the same as in part (a), except that the second probability must be \nadjusted to reﬂect the fact that the ﬁrst selection was positive and is not avail-\nable for the second selection. After the ﬁrst positive result is selected, we have \n49 test results remaining, and 5 of them are negative. The second probability \nis therefore 5>49, as shown below:\nP11st selection is positive and 2nd is negative2 = 45\n50 # 5\n49 = 0.0918\n",
    "4-2 Addition Rule and Multiplication Rule \n137\nExample 5 illustrates use of the 5% guideline for cumbersome calculations and it also \nillustrates that the basic multiplication rule extends easily to three or more events.\nEXAMPLE 5   Drug Screening and the 5% Guideline for  \nCumbersome Calculations\nAssume that three adults are randomly selected without replacement from the \n247,436,830 adults in the United States. Also assume that 10% of adults in the United \nStates use drugs. Find the probability that the three selected adults all use drugs.\nSOLUTION\nBecause the three adults are randomly selected without replacement, the three \nevents are dependent, but here we can treat them as being independent by applying \nthe 5% guideline for cumbersome calculations. The sample size of 3 is clearly no \nmore than 5% of the population size of 247,436,830. We get\n P1all 3 adults use drugs2 = P1first uses drugs and second uses drugs and\n third uses drugs2\n = P1first uses drugs2 #  P1second uses drugs2 #  \nP1third uses drugs2\n = 10.10210.10210.102 = 0.00100\nThere is a 0.00100 probability that all three selected adults use drugs.\nCAUTION In any probability calculation, it is extremely important to carefully \nidentify the event being considered. See Example 6, where parts (a) and (b) might \nseem quite similar but their solutions are very different.\nEXAMPLE 6  Birthdays\nWhen two different people are randomly selected from those in your class, find the \nindicated probability by assuming that birthdays occur on the days of the week with \nequal frequencies.\n \na. Find the probability that the two people are born on the same day of the week.\n \nb. Find the probability that the two people are both born on Monday.\nIn Example 5, if we treat the events as dependent without using the 5% guideline, \nwe get the following cumbersome calculation that begins with 247,436,830 adults, \nwith 10% of them (or 24,743,683) using drugs:\n a 24,743,683\n247,436,830ba 24,743,682\n247,436,829ba 24,743,681\n247,436,828b = 0.0009999998909\n = 0.00100 1rounded2\nJust imagine randomly selecting 1000 adults instead of just 3, as is commonly done \nin typical polls. Extending the above calculation to include 1000 factors instead of 3 \nfactors would be what statisticians refer to as “painful.”\ncontinued\n",
    "138 \nCHAPTER 4 Probability\nRedundancy: Important Application of Multiplication Rule\nThe principle of redundancy is used to increase the reliability of many systems. Our \neyes have passive redundancy in the sense that if one of them fails, we continue to see. \nAn important finding of modern biology is that genes in an organism can often work \nin place of each other. Engineers often design redundant components so that the whole \nsystem will not fail because of the failure of a single component, as in the following \nexample.\nSOLUTION\na. Because no particular day of the week is speciﬁed, the ﬁrst person can be \nborn on any one of the seven weekdays. The probability that the second \n person is born on the same day as the ﬁrst person is 1>7. The probability that \ntwo people are born on the same day of the week is therefore 1>7.\n \nb. The probability that the ﬁrst person is born on Monday is 1>7 and the prob-\nability that the second person is also born on Monday is 1>7. Because the two \nevents are independent, the probability that both people are born on Monday is\n1\n7 # 1\n7 = 1\n49\nWATCH YOUR LANGUAGE! Example 6 illustrates that finding correct or relevant \nprobability values often requires greater language skills than computational skills. \nIn Example 6, what exactly do we mean by “same day of the week”? See how parts \n(a) and (b) in Example 6 are very different.\nEXAMPLE 7  Airbus 310: Redundancy for Better Safety\nModern aircraft are now highly reliable, and one design feature contributing to that \nreliability is the use of redundancy, whereby critical components are duplicated so \nthat if one fails, the other will work. For example, the Airbus 310 twin-engine air-\nliner has three independent hydraulic systems, so if any one system fails, full flight \ncontrol is maintained with another functioning system. For this example, we will as-\nsume that for a typical flight, the probability of a hydraulic system failure is 0.002.\n \na. If the Airbus 310 were to have one hydraulic system, what is the probability \nthat the aircraft’s ﬂight control would work for a ﬂight?\n \nb. Given that the Airbus 310 actually has three independent hydraulic systems, \nwhat is the probability that on a typical ﬂight, control can be maintained with \na working hydraulic system?\nSOLUTION\n \na. The probability of a hydraulic system failure is 0.002, so the probability that \nit does not fail is 0.998. That is, the probability that ﬂight control can be main-\ntained is as follows:\nP11 hydraulic system does not fail2\n     \n= 1 - P1failure2 = 1 - 0.002 = 0.998\n",
    "4-2 Addition Rule and Multiplication Rule \n139\nRationale for the Multiplication Rule\nTo see the reasoning that underlies the multiplication rule, consider a pop quiz consist-\ning of these two questions:\n1. True or false: A pound of feathers is heavier than a pound of gold.\n2. Who said, “By a small sample, we may judge of the whole piece”?  \n(a) Judge Judy; (b) Judge Dredd; (c) Miguel de Cervantes; (d) George \nGallup; (e) Gandhi\nThe answers are T (true) and c. (The first answer is true, because weights of feath-\ners are in avoirdupois units where a pound is 453.59 g, but weights of gold and other \nprecious metals are in troy units where a pound is 373.24 g. The second answer is \nfrom Don Quixote by Cervantes.)\nHere is the sample space for the different possible answers:\nTa Tb Tc Td Te Fa Fb Fc Fd Fe\nIf both answers are random guesses, then the above 10 possible outcomes are equally \nlikely, so\nP1both correct2 = P1T and c2 = 1\n10 = 0.1\nWith P1T and c2 = 1>10, P1T2 = 1>2, and P1c2 = 1>5, we see that\n1\n10 = 1\n2 # 1\n5\nA tree diagram is a graph of the possible outcomes of a procedure, as in Figure 4-4. \nFigure 4-4 shows that if both answers are random guesses, all 10 branches are equally \nlikely and the probability of getting the correct pair (T, c) is 1>10. For each response to \nthe first question, there are 5 responses to the second. The total number of outcomes is 5 \ntaken 2 times, or 10. The tree diagram in Figure 4-4 therefore provides a visual illustra-\ntion for using multiplication.\n \nb. With three independent hydraulic systems, ﬂight control will be maintained if \nthe three systems do not all fail. The probability of all three hydraulic systems \nfailing is 0.002 #  0.002 #  0.002 = 0.000000008. It follows that the probabil-\nity of maintaining ﬂight control is as follows:\nP1it does not happen that all three hydraulic systems fail2\n= 1 - 0.000000008 = 0.999999992\nINTERPRETATION\nWith only one hydraulic system we have a 0.002 probability of failure, but with \nthree independent hydraulic systems, there is only a 0.000000008 probability that \nflight control cannot be maintained because all three systems failed. By using three \nhydraulic systems instead of only one, risk of failure is decreased not by a factor of \n1>3, but by a factor of 1>250,000. By using three independent hydraulic systems, \nrisk is dramatically decreased and safety is dramatically increased.\nTa\nTb\nTc\nTd\nTe\nFa\nFb\nFc\nFd\nFe\na\nb\nc\nd\ne\na\nb\nc\nd\ne\nT\nF\n10\n5\n5\n2\n3\nFIGURE 4-4 Tree Diagram \nof Test Answers\n",
    "140 \nCHAPTER 4 Probability\nSummary of Addition Rule and Multiplication Rule\nAddition Rule for P(A or B): The word or suggests addition, and when adding \nP(A) and P(B), we must add in such a way that every outcome is counted only \nonce.\nMultiplication Rule for P(A and B): The word and for two trials suggests \nmultiplication, and when multiplying P(A) and P(B), we must be sure that the \nprobability of event B takes into account the previous occurrence of event A.\nStatistical Literacy and Critical Thinking\n1. Notation When randomly selecting an adult, A denotes the event of selecting someone with \nblue eyes. What do P(A) and P1A2 represent?\n2. Notation When randomly selecting adults, let M denote the event of randomly selecting \na male and let B denote the event of randomly selecting someone with blue eyes. What does \nP1M0 B2 represent? Is P1M0 B2 the same as P1B0 M2?\n3. Sample for a Poll There are 15,524,971 adults in Florida. If The Gallup organization ran-\ndomly selects 1068 adults without replacement, are the selections independent or dependent? \nIf the selections are dependent, can they be treated as being independent for the purposes of \ncalculations?\n4. Rule of Complements When randomly selecting an adult, let B represent the event of \nrandomly selecting someone with Group B blood. Write a sentence describing what the rule of \ncomplements is telling us: P1B or B2 = 1.\nFinding Complements. In Exercises 5–8, find the indicated complements.\n5. LOL A U.S. Cellular survey of smartphone users showed that 26% of respondents answered \n“yes” when asked if abbreviations (such as LOL) are annoying when texting. What is the prob-\nability of randomly selecting a smartphone user and getting a response other than “yes”?\n6. Color Blindness Women have a 0.25% rate of red>green color blindness. If a woman is \nrandomly selected, what is the probability that she does not have red>green color blindness?\n7. Clinical Test When the drug Viagra (sildenafil citrate) was clinically tested, 117 patients \nreported headaches and 617 did not. If one of these patients is randomly selected, find the prob-\nability of getting one who did not report a headache.\n8.  Sobriety Checkpoint When one of the authors observed a sobriety checkpoint con-\nducted by the Dutchess County Sheriff Department, he saw that 676 drivers were screened \nand 6 were arrested for driving while intoxicated. Based on those results, we can estimate that \nP1I2 = 0.000888, where I denotes the event of screening a driver and getting someone who is \nintoxicated. What does P1I2 denote, and what is its value?\nIn Exercises 9–20, use the data in the following table, which summarizes blood groups and \nRh types for randomly selected subjects. Assume that subjects are randomly selected from \nthose included in the table.\nO\nA\nB\nAB\nType\nRh+\n59\n53\n12\n6\nRh−\n 9\n 8\n 3\n2\n4-2 Basic Skills and Concepts\n",
    "4-2 Addition Rule and Multiplication Rule \n141\n9. Blood Groups and Types If one person is selected, find the probability of getting some-\none who is not Group A.\n10.  Blood Groups and Types If one person is selected, find the probability of getting \nsomeone who is not type Rh+.\n11.  Blood Groups and Types If one person is selected, find the probability of getting \nsomeone who is Group A or type Rh+. Are the events of selecting someone who is Group A and \nthe event of someone who is type Rh+ disjoint events?\n12.  Blood Groups and Types If one person is selected, find the probability of getting \nsomeone who is type Rh− or Group AB. Are the events of selecting someone who is type Rh−\nand the event of someone who is Group AB disjoint events?\n13. Blood Groups and Types If two people are selected, find the probability that they are \nboth Group B.\na. Assume that the selections are made with replacement. Are the events independent?\nb. Assume that the selections are made without replacement. Are the events independent?\n14. Blood Groups and Types If two people are selected, find the probability that they are \nboth type Rh−.\na. Assume that the selections are made with replacement. Are the events independent?\nb. Assume that the selections are made without replacement. Are the events independent?\n15. Blood Groups and Types If two people are selected, find the probability that they are \nboth type Rh+.\na. Assume that the selections are made with replacement. Are the events independent?\nb. Assume that the selections are made without replacement. Are the events independent?\n16. Blood Groups and Types If two people are selected, find the probability that they are \nboth Group AB.\na. Assume that the selections are made with replacement. Are the events independent?\nb. Assume that the selections are made without replacement. Are the events independent?\n17.  Blood Groups and Types If one person is selected, find the probability of getting \nsomeone who is Group A or Group B or type Rh-.\n18.  Blood Groups and Types If one person is selected, find the probability of getting \nsomeone who is Group O or Group AB or type Rh+.\n19. Blood Groups and Types If three different people are selected, find the probability that \nthey are all Group A.\n20. Blood Groups and Types If three different people are selected, find the probability that \nthey are all type Rh-.\nIn Exercises 21–24, use these results from the “1-Panel-THC” test for marijuana use, \nwhich is provided by the company Drug Test Success: Among 143 subjects with positive \ntest results, there are 24 false positive results; among 157 negative results, there are 3 false \nnegative results. (Hint: Construct a table similar to Table 4-1, which is included with the \nChapter Problem.)\n21. Testing for Marijuana Use\na. How many subjects are included in the study?\nb. How many of the subjects had a true negative result?\nc. What is the probability that a randomly selected test subject had a true negative result?\n",
    "142 \nCHAPTER 4 Probability\n22. Testing for Marijuana Use If one of the test subjects is randomly selected, find the \nprobability that the subject tested negative or used marijuana.\n23. Testing for Marijuana Use If one of the test subjects is randomly selected, find the \nprobability that the subject tested positive or did not use marijuana.\n24. Testing for Marijuana Use If one of the test subjects is randomly selected, find the \nprobability that the subject used marijuana. Do you think that the result reflects the general \npopulation rate of subjects who use marijuana?\nRedundancy. Exercises 25 and 26 involve redundancy.\n25. Redundancy in Computer Hard Drives It is generally recognized that it is wise to \nback up computer data. Assume that there is a 3% rate of disk drive failure in a year (based on \ndata from various sources including lifehacker.com).\na. If you store all of your computer data on a single hard disk drive, what is the probability that \nthe drive will fail during a year?\nb. If all of your computer data are stored on a hard disk drive with a copy stored on a second \nhard disk drive, what is the probability that both drives will fail during a year?\nc. If copies of all of your computer data are stored on three independent hard disk drives, what \nis the probability that all three will fail during a year?\nd. Describe the improved reliability that is gained with backup drives.\n26. Redundancy in Hospital Generators Hospitals typically require backup generators to \nprovide electricity in the event of a power outage. Assume that emergency backup generators \nfail 22% of the times when they are needed (based on data from Arshad Mansoor, senior vice \npresident with the Electric Power Research Institute). A hospital has two backup generators so \nthat power is available if one of them fails during a power outage.\na. Find the probability that both generators fail during a power outage.\nb. Find the probability of having a working generator in the event of a power outage. Is that \nprobability high enough for the hospital?\nAcceptance Sampling. With one method of a procedure called acceptance sampling, a \nsample of items is randomly selected without replacement and the entire batch is accepted \nif every item in the sample is found to be okay (or conforming). Exercises 27 and 28 involve \nacceptance sampling.\n27. Defective Pacemakers Among 8834 cases of heart pacemaker malfunctions, 504 were \nfound to be caused by firmware, which is software programmed into the device (based on data \nfrom “Pacemaker and ICD Generator Malfunctions,” by Maisel et al., Journal of the American \nMedical Association, Vol. 295, No. 16). If the firmware is tested in three different pacemak-\ners randomly selected from this batch of 8834 and the entire batch is accepted if there are no \nfailures, what is the probability that the firmware in the entire batch will be accepted? Is this \nprocedure likely to result in the entire batch being accepted?\n28. Defective Ultrasound Transducers Among 676 ultrasound transducers tested, 269 \nwere defective with transducer errors (based on data from “High Incidence of Defective Ultra-\nsound Transducers in Use in Routine Clinical Practice,” by Martensson et al., European Jour-\nnal of Cardiology, Vol. 10). If four different units are randomly selected and tested, what is the \nprobability that the entire batch will be accepted? Does that probability seem adequate?\nIn Exercises 29 and 30, find the probabilities and indicate when the “5% guideline for cum-\nbersome calculations” is used.\n29. Medical Helicopters In a study of helicopter usage and patient survival, results were \nobtained from 47,637 patients transported by helicopter and 111,874 patients transported by \nground (based on data from “Association Between Helicopter vs Ground Emergency Medical \n",
    "4-2 Addition Rule and Multiplication Rule \n143\nServices and Survival for Adults with Major Trauma,” by Galvagno et al., Journal of the Ameri-\ncan Medical Association, Vol. 307, No. 15).\na. If 1 of the 159,511 patients in the study is randomly selected, what is the probability that the \nsubject was transported by helicopter?\nb. If 5 of the subjects in the study are randomly selected without replacement, what is the prob-\nability that all of them were transported by helicopter?\n30. Medical Helicopters In the same study cited in the preceding exercise, among the 47,637 \npatients transported by helicopter, 188 of them left the treatment center against medical advice, \nand the other 47,449 did not leave against medical advice. If 40 of the subjects transported by \nhelicopter are randomly selected without replacement, what is the probability that none of them \nleft the treatment center against medical advice?\n31. MRI Reliability Refer to the accompanying figure showing surge protectors p and q used \nto protect an expensive magnetic resonance imaging (MRI) scanner used in a hospital. If there \nis a surge in the voltage, the surge protector reduces it to a safe level. Assume that each surge \nprotector has a 0.985 probability of working correctly when a voltage surge occurs.\na. If the two surge protectors are arranged in series, what is the probability that a voltage surge \nwill not damage the MRI? (Do not round the answer.)\nb. If the two surge protectors are arranged in parallel, what is the probability that a voltage \nsurge will not damage the MRI? (Do not round the answer.)\nc. Which arrangement should be used for better protection?\nSeries conﬁguration\np\nq\nMRI\nParallel conﬁguration\np\nq\nMRI\n32. Same Birthdays If 25 people are randomly selected, find the probability that no 2 of them \nhave the same birthday. Ignore leap years.\n33. Exclusive Or The exclusive or means either one or the other events occurs, but not both.\na. For the formal addition rule, rewrite the formula for P(A or B) assuming that the addition \nrule uses the exclusive or instead of the inclusive or.\nb. Repeat Exercise 11 “Blood Groups and Types” using the exclusive or instead of the inclu-\nsive or.\n34. Complements and the Addition Rule Refer to the table of blood groups and types used \nfor Exercises 9–20. Assume that one subject is randomly selected. Let A represent the event \nof getting someone with Group A blood and let B represent the event of getting someone with \nGroup B blood. Find P1A or B2, find P1A or B2, and then compare the results. In general, does \nP1A or B2 = P1A or B2?\n4-2 Beyond the Basics\n",
    "144 \nCHAPTER 4 Probability\nKey Concept In Part 1 of this section we extend the use of the multiplication rule to \ninclude the probability that among several trials, we get at least one of some specified \nevent. In Part 2 we consider conditional probability: the probability of an event occur-\nring when we have additional information that some other event has already occurred. \nIn Part 3 we provide a brief introduction to the use of Bayes’ theorem.\nPART 1\n  Complements: The Probability  \nof “At Least One” \nWhen finding the probability of some event occurring “at least once,” we should un-\nderstand the following:\n \n■“At least one” has the same meaning as “one or more.”\n \n■The complement of getting “at least one” particular event is that you get no \noccurrences of that event.\nFor example, not getting at least 1 girl in 10 births is the same as getting no girls, \nwhich is also the same as getting 10 boys.\nNot getting at least 1 girl in 10 births = Getting no girls = Getting 10 boys\nThe following steps describe the details of this backward method of finding the \nprobability of getting at least one of some event:\nFinding the probability of getting at least one of some event:\n1. Let A = getting at least one of some event.\n2. Then A = getting none of the event being considered.\n3. Find P1A2 = probability that event A does not occur. (This is relatively \neasy using the multiplication rule.)\n4. Subtract the result from 1. That is, evaluate this expression:\nP1at least one occurrence of event A2\n  = 1 −P1no occurrences of event A2\n4-3\n \nComplements, Conditional Probability,  \nand Bayes’ Theorem\nEXAMPLE 1  At Least One Subject with Group AB Blood\nThe probability of randomly selecting someone with Group AB blood is 0.0526 \n(based on the table given with Exercises 9–20 in the preceding section). A re-\nsearcher needs at least one subject having Group AB blood. If 20 subjects are ran-\ndomly selected, find the probability of getting at least one with Group AB blood. Is \nthe probability high enough so that the researcher can be reasonably sure of getting \nsomeone with Group AB blood?\nSOLUTION\nStep 1: Let A = at least 1 of the 20 subjects has Group AB blood.\nStep 2: Identify the event that is the complement of A.\n A = not getting at least 1 subject with Group AB blood among 20\n = all 20 subjects have blood that is not Group AB\n",
    "4-3 Complements, Conditional Probability, and Bayes’ Theorem  \n145\nPART 2\n Conditional Probability \nWe now consider the principle that the probability of an event is often affected by \nknowledge that some other event has occurred. For example, the probability of a \ngolfer making a hole in one is 1>12,000 (based on past results), but if you have the \nadditional knowledge that the selected person is a professional golfer, the probability \nchanges to 1>2375 (based on data from USA Today).\nStep 3: Find the probability of the complement by evaluating P1A2 If there is \na 0.0526 probability of a person having Group AB blood, it follows that there \nis a 0.9474 probability of a person not having Group AB blood, and we get the \n following:\n P1A2 = P1all 20 subjects have blood that is not Group AB2\n = 0.9474 # 0.9474 #  g # 0.9474\n = 0.947420 = 0.339365436\nStep 4: Find P(A) by evaluating 1 - P1A2.\nP1A2 = 1 - P1A2 = 1 - 0.339365436 = 0.661 1rounded2\nINTERPRETATION\nFor a group of 20 subjects, there is a 0.661 probability of getting at least 1 person \nwith Group AB blood. This probability is not very high, so if the researcher needs a \nperson with Group AB blood, more than 20 subjects should be used.\nDEFINITION\nA conditional probability of an event is a probability obtained with the additional \ninformation that some other event has already occurred.\nNotation\nP1B\u001eA2 denotes the conditional probability of event B occurring, given that event A \nhas already occurred.\nINTUITIVE APPROACH FOR FINDING P1B∣A2\nThe conditional probability of B occurring given that A has occurred can be found \nby assuming that event A has occurred and then calculating the probability that \nevent B will occur, as illustrated in Example 2.\nFORMAL APPROACH FOR FINDING P1B∣A2\nThe probability P1B\u001e A2 can be found by dividing the probability of events A and B \nboth occurring by the probability of event A:\nP1B\u001e A2 = P1A and B2\nP1A2\nProsecutor’s Fallacy\nThe prosecu-\ntor’s fallacy is \nmisunderstand-\ning or confusion \nof two different \nconditional \nprobabilities:  \n(1) the probability \nthat a defendant is innocent, giv-\nen that forensic evidence shows \na match; (2) the probability that \nforensics shows a match, given \nthat a person is innocent. The \nprosecutor’s fallacy has led to \nwrong convictions and imprison-\nment of some innocent people.\nLucia de Berk was a nurse \nwho was convicted of murder \nand sentenced to prison in the \nNetherlands. Hospital administra-\ntors observed suspicious deaths \nthat occurred in hospital wards \nwhere de Berk had been present. \nAn expert testified that there was \nonly 1 chance in 342 million that \nher presence was a coincidence. \nHowever, mathematician Richard \nGill calculated the probability to \nbe closer to 1>150, or possibly as \nlow as 1>5. The court used the \nprobability that the suspicious \ndeaths could have occurred with \nde Berk present, given that she \nwas innocent. The court should \nhave considered the probability \nthat de Berk is innocent, given \nthat the suspicious deaths oc-\ncurred when she was present. \nThis error of the prosecutor’s \nfallacy is subtle and can be \nvery difficult to understand and \nrecognize, yet it can lead to the \nimprisonment of innocent people.\n",
    "146 \nCHAPTER 4 Probability\nThe preceding formula is a formal expression of conditional probability, but blind use \nof formulas is not recommended. Instead, we recommend the intuitive approach, as \nillustrated in Example 2.\nTABLE 4-1 Results from Drug Tests of Job Applicants\nPositive Test Result\n(Test shows drug use.)\nNegative Test Result \n(Test shows no drug use.)\nSubject Uses Drugs\n45\n(True Positive)\n5\n(False Negative)\nSubject Does Not Use Drugs\n25\n(False Positive)\n480\n(True Negative)\nEXAMPLE 2  Pre-Employment Drug Screening\nRefer to Table 4-1 to find the following:\n \na. If 1 of the 555 test subjects is randomly selected, ﬁnd the probability that the \nsubject had a positive test result, given that the subject actually uses drugs. \nThat is, ﬁnd P(positive test result \u001e subject uses drugs).\n \nb. If 1 of the 555 test subjects is randomly selected, ﬁnd the probability that the \nsubject actually uses drugs, given that he or she had a positive test result. That \nis, ﬁnd P(subject uses drugs \u001e positive test result).\nSOLUTION\na. Intuitive Approach: We want P(positive test result \u001e subject uses drugs), the \nprobability of getting someone with a positive test result, given that the se-\nlected subject uses drugs. Here is the key point: If we assume that the selected \nsubject actually uses drugs, we are dealing only with the 50 subjects in the \nﬁrst row of Table 4-1. Among those 50 subjects, 45 had positive test results, \nso we get this result:\nP1positive test result \u001esubject uses drugs2 = 45\n50 = 0.900\n \n Formal Approach: The same result can be found by using the formula for \nP1B\u001eA2given with the formal approach. We use the following notation.\nP1B\u001eA2 = P1positive test result \u001esubject uses drugs2\nwhere B = positive test result and A = subject uses drugs.\n \n  \nIn the following calculation, we use P(subject uses drugs and had a posi-\ntive test result) = 45>555 and P(subject uses drugs) = 50>555 to get the \nfollowing results:\nP1B\u001eA2 = P1A and B2\nP1A2\nbecomes\nP1positive test result \u001esubject uses drugs2\n = P1subject uses drugs and had a positive test result2\nP1subject uses drugs2\n = 45>555\n50>555 = 0.900\n",
    "4-3 Complements, Conditional Probability, and Bayes’ Theorem  \n147\nConfusion of the Inverse\nNote that in Example 2, P(positive test result \u001e subject uses drugs) ≠P(subject uses \ndrugs \u001e positive test result). This example proves that in general, P1B\u001eA2 ≠P1A\u001eB2.\n(There could be individual cases where P1A\u001eB2 and P1B\u001eA2 are equal, but they are \ngenerally not equal.) To incorrectly think that P1B\u001eA2 and P1A\u001eB2 are equal or to \nincorrectly use one value in place of the other is called confusion of the inverse.\n \n By comparing the intuitive approach to the formal approach, it should be clear \nthat the intuitive approach is much easier to use, and it is also less likely to \nresult in errors. The intuitive approach is based on an understanding of condi-\ntional probability, instead of manipulation of a formula, and understanding is \nso much better.\n \nb. Here we want P(subject uses drugs \u001e positive test result). If we assume that the \nsubject had a positive test result, we are dealing with the 70 subjects in the \nﬁrst column of Table 4-1. Among those 70 subjects, 45 use drugs, so\nP1subject uses drugs \u001epositive test result2 = 45\n70 = 0.643\nAgain, the same result can be found by applying the formula for conditional \nprobability, but we will leave that for those with a special fondness for ma-\nnipulations with formulas.\nINTERPRETATION\nThe first result of P(positive test result \u001e subject uses drugs) = 0.900 indicates that \na subject who uses drugs has a 0.900 probability of getting a positive test result. \nThe second result of P(subject uses drugs \u001e positive test result) = 0.643 indicates \nthat for a subject who gets a positive test result, there is a 0.643 probability that this \nsubject actually uses drugs. Note that P1positive test result \u001esubject uses drugs2\nP1subject uses drugs \u001epositive test result2. See “Confusion of the Inverse” that \nfollows.\nEXAMPLE 3  Confusion of the Inverse\nConsider these events:\nD: It is dark outdoors.\nM: It is midnight.\nIn the following, we conveniently ignore the Alaskan winter and other such \nanomalies.\nP1D\u001eM2 = 1 1It is certain to be dark given that it is midnight.2\nP1M \u001eD2 = 0 1The probability that it is exactly midnight given\nthat it is dark is almost zero.2\nHere, P1D\u001eM2 ≠P1M \u001eD2. Confusion of the inverse occurs when we incorrectly \nswitch those probability values or think that they are equal.\n",
    "148 \nCHAPTER 4 Probability\nPART 3\nBayes’ Theorem\nIn this section we extend the discussion of conditional probability to include applica-\ntions of Bayes’ theorem (or Bayes’ rule), which we use for revising a probability value \nbased on additional information that is later obtained.\nLet’s consider a study showing that physicians often give very misleading in-\nformation when they experience confusion of the inverse. They tended to confuse \nP(cancer \u001f positive test result) with P(positive test result \u001f cancer). About 95% of physi-\ncians estimated P(cancer \u001f positive test result) to be about 10 times too high, with the \nresult that patients were given diagnoses that were very misleading, and patients were \nunnecessarily distressed by the incorrect information. Let’s take a closer look at this \nclassic example, and let’s hope that we can give physicians information in a better \nformat that is easy to understand.\nEXAMPLE 4  Interpreting Medical Test Results\nAssume cancer has a 1% prevalence rate, meaning that 1% of the population has \ncancer. Denoting the event of having a cancer by C, we have P1C2 = 0.01 for a \nsubject randomly selected from the population. This result is included with the fol-\nlowing performance characteristics of the test for cancer (based on Probabilistic \nReasoning in Clinical Medicine, by David Eddy, Cambridge University Press).\n \n■There is a 1% prevalence rate of the cancer. That is, P1C2 = 0.01.\n \n■The false positive rate is 10%. That is, P(positive test result given that cancer is \nnot present) = 0.10.\n \n■The true positive rate is 80%. That is, P(positive test result given that cancer is \npresent) = 0.80.\nFind P1C\u001fpositive test result2. That is, find the probability that a subject actually \nhas cancer given that he or she has a positive test result.\nSOLUTION\nUsing the given information, we can construct a hypothetical population with the above \ncharacteristics. We can find the entries in Table 4-2 on the next page, as follows.\n \n■Assume that we have 1000 subjects. With a 1% prevalence rate, 10 of the sub-\njects are expected to have cancer. The sum of the entries in the first row of val-\nues is therefore 10.\n \n■The other 990 subjects do not have cancer. The sum of the entries in the second \nrow of values is therefore 990.\n \n■Among the 990 subjects without cancer, 10% get positive test results, so 10% \nof the 990 cancer-free subjects in the second row get positive test results. See \nthe entry of 99 in the second row.\n \n■For the 990 subjects in the second row, 99 test positive, so the other 891 must \ntest negative. See the entry of 891 in the second row.\n \n■Among the 10 subjects with cancer in the first row, 80% of the test results are \npositive, so 80% of the 10 subjects in the first row test positive. See the entry of \n8 in the first row.\n \n■The other 2 subjects in the first row test negative. See the entry of 2 in the \nfirst row.\nIn\nti\nGroup Testing\nDuring World \nWar II, the U.S. \nArmy tested \nfor syphilis \nby giving \neach soldier \nan individual \nblood test that was analyzed \nseparately. One researcher sug-\ngested mixing pairs of blood \nsamples. After the mixed pairs \nwere tested, those with syphilis \ncould be identified by retest-\ning the few blood samples that \nwere in the pairs that tested \npositive. Since the total number \nof analyses was reduced by pair-\ning blood specimens, why not \ncombine them in groups of three \nor four or more? This technique \nof combining samples in groups \nand retesting only those groups \nthat test positive is known as \ngroup testing or pooled testing, or \ncomposite testing. University of \nNebraska statistician Christopher \nBilder wrote an article about this \ntopic in Chance magazine, and \nhe cited some real applications. \nHe noted that the American \nRed Cross uses group testing \nto screen for specific diseases, \nsuch as hepatitis, and group \n testing is used by veterinarians \nwhen cattle are tested for the \nbovine viral diarrhea virus.\n",
    "4-3 Complements, Conditional Probability, and Bayes’ Theorem  \n149\nThe solution in Example 4 is not very difficult. Another approach is to compute the \nprobability using this formula commonly given with Bayes’ theorem:\nP1A\u001eB2 =\nP1A2 # P1B\u001eA2\n3P1A2 # P1B\u001eA2 4 + 3P1A2 # P1B\u001eA2 4\nIf we replace A with C and replace B with “positive,” we get this solution for Example 4:\n P1C\u001epositive2 =\nP1C2 # P1positive \u001eC2\nP1C2 # P1positive \u001eC2 + P1C2 # P1Positive \u001eC2\n =\n0.01 # 0.80\n10.01 # 0.802 + 10.99 # 0.102 = 0.0748\nStudy Results Here is a truly fascinating fact: When 100 physicians were given \nthe information in Example 4, 95 of them estimated P(C \u001e positive) to be around \n0.70 to 0.80, so they were wrong by a factor of 10. Physicians are extremely intel-\nligent, but here they likely suffered from confusion of the inverse. The given rate \nof 80% for positive test results among those who are true positives implies that \nP1positive \u001eC2 = 0.80, but this is very different from P1C\u001epositive2. The physi-\ncians would have done much better if they had seen the given information in the form \nof a table like Table 4-2.\nThe importance and usefulness of Bayes’ theorem is that it can be used with se-\nquential events, whereby new additional information is obtained for a subsequent \nevent, and that new information is used to revise the probability of the initial event. In \nthis context, the terms prior probability and posterior probability are commonly used.\nTo find P1C\u001epositive test result2, see that the first column of values includes the \npositive test results. In that first column, the probability of randomly selecting a \nsubject with cancer is 8>107 or 0.0748, so P1C\u001epositive test result2 = 0.0748.\nINTERPRETATION\nFor the data given in this example, a randomly selected subject has a 1% chance \nof cancer, but for a randomly selected subject given a test with a positive result, \nthe chance of cancer increases to 7.48%. Based on the data given in this example, \na positive test result should not be devastating news, because there is still a good \nchance that the test is wrong.\nTABLE 4-2 Test Results\nPositive Test Result\n(Test shows cancer.)\nNegative Test Result \n(Test shows no cancer.)\n \nTotal\nCancer\n8\n(True Positive)\n2\n(False Negative)\n10\nNo Cancer\n99\n(False Positive)\n891\n(True Negative)\n990\nDEFINITIONS\nA prior probability is an initial probability value originally obtained before any ad-\nditional information is obtained.\nA posterior probability is a probability value that has been revised by using addi-\ntional information that is later obtained.\n",
    "150 \nCHAPTER 4 Probability\nRelative to Example 4, P1C2 = 0.01, which is the probability that a randomly se-\nlected subject has cancer. P(C) is an example of a prior probability. Using the ad-\nditional information that the subject has received a positive test result, we found that \nP1C\u001epositive test result2 = 0.0748, and this is a posterior probability because it uses \nthat additional information of the positive test result.\nStatistical Literacy and Critical Thinking\n1. Language: Complement of “At Least One” Let A = the event of getting at least one \ndefective pacemaker battery when 3 batteries are randomly selected with replacement from a \nbatch. Write a statement describing event A.\n2. Probability of At Least One Let A = the event of getting at least 1 defective pacemaker \nbattery when 3 batteries are randomly selected with replacement from a batch. If 5% of the \nbatteries in a batch are defective and the other 95% are all good, which of the following are \ncorrect?\na. P1A2 = 10.95210.95210.952 = 0.857\nb. P1A2 = 1 - 10.95210.95210.952 = 0.143\nc. P1A2 = 10.05210.05210.052 = 0.000125\n3. Notation Let event G = subject has glaucoma (disorder of the eye) and let event Y = test \nindicates that “yes,” the subject has glaucoma. Use your own words to translate the notation \nP1Y \u001e G2 into a verbal statement.\n4. Confusion of the Inverse Using the same events G and Y described in Exercise 3, de-\nscribe confusion of the inverse.\nAt Least One. In Exercises 5–12, find the probability.\n5. Three Girls Find the probability that when a couple has three children, at least one of them \nis a girl. (Assume that boys and girls are equally likely.)\n6. Probability of a Girl Assuming that boys and girls are equally likely, find the probability \nof a couple having a boy when their third child is born, given that the first two children were \nboth girls.\n7. Births in the United States In the United States, the true probability of a baby being a \nboy is 0.512 (based on the data available at this writing). Among the next six randomly selected \nbirths in the United States, what is the probability that at least one of them is a girl?\n8. Births in China In China, where many couples were allowed to have only one child, the \nprobability of a baby being a boy was 0.545. Among six randomly selected births in China, \nwhat is the probability that at least one of them is a girl? Could this system continue to work \nindefinitely? (Phasing out of this policy was begun in 2015.)\n9. Phone Survey Subjects for the California Health Interview Survey are contacted using \ntelephone numbers in which the last four digits are randomly selected (with replacement). Find \nthe probability that for one such phone number, the last four digits include at least one 0.\n10. At Least One Correct Answer If you make random guesses for 10 multiple-choice \nMCAT test questions (each with five possible answers), what is the probability of getting at \nleast 1 correct? If these questions are part of a practice test and an instructor says that you must \nget at least one correct answer before continuing, is there a good chance you will continue?\n11. At Least One Defective Ultrasound Transducer A study showed that 39.8% of ultra-\nsound transducers are defective (based on data from “High Incidence of Defective  Ultrasound \n4-3 Basic Skills and Concepts\n",
    "4-3 Complements, Conditional Probability, and Bayes’ Theorem  \n151\nTransducers in Use in Routine Clinical Practice,” by Martensson et al., European Journal of \nEchocardiography, Vol. 10, No. 1093.) An engineer needs at least one defective ultrasound \ntransducer so she can try to identify the problem. If she randomly selects 10 ultrasound trans-\nducers from a very large batch, what is the probability that she will get at least one that is de-\nfective? Is that probability high enough so that she can be reasonably sure of getting a defective \ntransducer for her work?\n12. Fruit Flies An experiment with fruit flies involves one parent with normal wings and one \nparent with vestigial wings. When these parents have an offspring, there is a 3>4 probability \nthat the offspring has normal wings and a 1>4 probability of vestigial wings. If the parents give \nbirth to five offspring, what is the probability that at least one of the offspring has vestigial \nwings? If researchers need at least one offspring with vestigial wings, can they be quite confi-\ndent of getting one?\nIdentical and Fraternal Twins. In Exercises 13–16, use the data in the following table. \nInstead of summarizing observed results, the entries reflect the actual probabilities based \non births of twins (based on data from the Northern California Twin Registry and the ar-\nticle “Bayesians, Frequentists, and Scientists,” by Bradley Efron, Journal of the American \nStatistical Association, Vol. 100, No. 469). Identical twins come from a single egg that splits \ninto two embryos, and fraternal twins are from separate fertilized eggs. The table entries \nreflect the principle that among sets of twins, 1 , 3 are identical and 2 , 3 are fraternal. Also, \nidentical twins must be of the same gender and the genders are equally likely (approxi-\nmately), and genders of fraternal twins are equally likely.\nBoy>boy\nBoy>girl\nGirl>boy\nGirl>girl\nIdentical Twins\n5\n0\n0\n5\nFraternal Twins\n5\n5\n5\n5\n13. Identical Twins\na. After having a sonogram, a pregnant woman learns that she will have twins. What is the \nprobability that she will have identical twins?\nb. After studying the sonogram more closely, the physician tells the pregnant woman that she \nwill give birth to twin boys. What is the probability that she will have identical twins? That is, \nfind the probability of identical twins given that the twins consist of two boys.\n14. Fraternal Twins\na. After having a sonogram, a pregnant woman learns that she will have twins. What is the \nprobability that she will have fraternal twins?\nb. After studying the sonogram more closely, the physician tells the pregnant woman that she \nwill give birth to twins consisting of one boy and one girl. What is the probability that she will \nhave fraternal twins?\n15. Fraternal Twins If a pregnant woman is told that she will give birth to fraternal twins, \nwhat is the probability that she will have one child of each gender?\n16. Fraternal Twins If a pregnant woman is told that she will give birth to fraternal twins, \nwhat is the probability that she will give birth to two girls?\n",
    "152 \nCHAPTER 4 Probability\nIn Exercises 17–20, refer to the accompanying table showing results from a Chembio test \nfor hepatitis C among HIV-infected patients (based on data from a variety of sources).\nPositive Test Result\nNegative Test Result\nHepatitis C\n335\n  10\nNo Hepatitis C\n  2\n1153\n17. False Positive Find the probability of selecting a subject with a positive test result, given \nthat the subject does not have hepatitis C. Why is this case problematic for test subjects?\n18. False Negative Find the probability of selecting a subject with a negative test result, \ngiven that the subject has hepatitis C. What would be an unfavorable consequence of this error?\n19. Positive Predictive Value Find the positive predictive value for the test. That is, find the \nprobability that a subject has hepatitis C, given that the test yields a positive result. Does the \nresult make the test appear to be effective?\n20. Negative Predictive Value Find the negative predictive value for the test. That is, find \nthe probability that a subject does not have hepatitis C, given that the test yields a negative re-\nsult. Does the result make the test appear to be effective?\n21. Redundancy in Computer Hard Drives Assume that there is a 3% rate of disk drive \nfailures in a year (based on data from various sources including lifehacker.com).\na. If all of your computer data are stored on a hard disk drive with a copy stored on a second \nhard disk drive, what is the probability that during a year, you can avoid catastrophe with at \nleast one working drive? Express the result with four decimal places.\nb. If copies of all of your computer data are stored on three independent hard disk drives, what \nis the probability that during a year, you can avoid catastrophe with at least one working drive? \nExpress the result with six decimal places. What is wrong with using the usual round-off rule \nfor probabilities in this case?\n22. Redundancy in Hospital Generators Assume that emergency backup generators fail \n22% of the times when they are needed (based on data from Arshad Mansoor, senior vice presi-\ndent with the Electric Power Research Institute). A hospital has three backup generators so \nthat power is available if at least one of them works in a power failure. Find the probability of \nhaving at least one of the backup generators working, given that a power failure has occurred. \nDoes the result appear to be adequate for the hospital’s needs?\n23. Composite Drug Test Based on the data in Table 4-1 on page 146, assume that the prob-\nability of a randomly selected person testing positive for drug use is 0.126. If drug screening \nsamples are collected from 5 random subjects and combined, find the probability that the com-\nbined sample will reveal a positive result. Is that probability low enough so that further testing \nof the individual samples is rarely necessary?\n24. Composite Water Samples The Fairfield County Department of Public Health tests \nwater for the presence of E. coli (Escherichia coli) bacteria. To reduce laboratory costs, water \nsamples from 10 public swimming areas are combined for one test, and further testing is done \nonly if the combined sample tests positive. Based on past results, there is a 0.005 probability of \nfinding E. coli bacteria in a public swimming area. Find the probability that a combined sample \nfrom 10 public swimming areas will reveal the presence of E. coli bacteria. Is that probability \nlow enough so that further testing of the individual samples is rarely necessary?\n25. Shared Birthdays Find the probability that of 25 randomly selected people, at least 2 \nshare the same birthday.\n4-3 Beyond the Basics\n",
    "4-4 Risks and Odds \n153\nKey Concept This section introduces absolute risk reduction, relative risk, and odds \nratio as measures helpful for comparing probability values and measuring risk. This \nsection also introduces “number needed to treat” as a measure of the number of sub-\njects that must be treated in order to prevent the single occurrence of some event, such \nas a disease.\nOne simple way to measure risk is to use a probability value. For example, in one \nof the largest medical experiments ever conducted, it was found that among 200,745 \nchildren injected with the Salk vaccine, 33 developed paralytic polio (poliomyelitis). \nIt follows that for this treatment group, P1polio2 = 33>200,745 = 0.000164. How-\never, that single measure does not give us any information about the rate of polio for \nthose children who were injected with a placebo. The risk of polio for children treated \nwith the Salk vaccine should be somehow compared to the risk of polio for those chil-\ndren given a placebo. Let’s consider the data summarized in Table 4-3.\n4-4 \nRisks and Odds\nTABLE 4-3 Prospective Study of Polio and the Salk Vaccine\nPolio\nNo polio\nTotal\nSalk Vaccine\n 33\n200,712\n200,745\nPlacebo\n115\n201,114\n201,229\nBased on the data in Table 4-3, we can identify the following probabilities:\n Polio rate for treatment group: P1polio \u001eSalk vaccine2 =\n33\n200,745 = 0.000164\n Polio rate for placebo group: P1polio \u001eplacebo2 =\n115\n201,229 = 0.00571\nInformal comparison of the preceding two probabilities likely suggests that there is a \nsubstantial difference between the two polio rates. Later chapters will use more effec-\ntive methods for determining whether the apparent difference is actually significant, \nbut in this section we introduce some simple measures for comparing the two rates.\nThe preceding table can be generalized with the following format:\nTABLE 4-4 Generalized Table Summarizing Results of a Prospective Study\nDisease\nNo Disease\nTreatment\na\nb\nPlacebo\nc\nd\nWe noted above that this section introduces some simple measures for comparing \ntwo rates, such as the polio rate for the Salk vaccine treatment group and the polio \nrate for the placebo group, as summarized in Table 4-3. We begin with the absolute \nrisk reduction.\n",
    "154 \nCHAPTER 4 Probability\nAbsolute Risk Reduction\nDEFINITION\nWhen comparing two probabilities or rates, the absolute risk reduction is simply \nthe absolute value of the following difference.\nAbsolute risk reduction = \u001eP1event occurring in treatment group2\n- P1event occurring in control group2 \u001e\nIf the data are in the generalized format of Table 4−4, we can express the absolute \nrisk reduction as follows:\nAbsolute risk reduction = \u001eP1event occurring in treatment group2\n- P1event occurring in control group2 \u001e\n \n= `\na\na + b -\nc\nc + d `\n(In the above expression, “treatment” might be replaced by the “presence of some \ncondition” or some other equivalent description.)\nCAUTION: The above definition of absolute risk reduction always results in the \npositive difference between a probability in the treatment group and a probability \nin the control group. Consider this when interpreting the effectiveness of the \ntreatment in terms of being helpful or harmful. See Exercises 13−16, where those \nin an atorvastatin treatment group have a higher rate of infections than those in the \nplacebo group. Be careful to interpret the results correctly.\nEXAMPLE 1  Finding Absolute Risk Reduction\nUsing the data summarized in Table 4-3, find the absolute risk reduction, which can \nbe used to measure the effectiveness of the Salk vaccine.\nSOLUTION\nBased on the data in Table 4-3, we have already found that P(polio \u001e Salk vaccine) \n= 0.000164 and P(polio \u001e placebo) = 0.000571. It follows that:\n Absolute risk reduction = \u001eP1polio\u001eSalk vaccine2 - P1polio\u001eplacebo2 \u001e\n = \u001e0.000164 - 0.000571\u001e = 0.000407\nFor a subject treated with the Salk vaccine, there is an absolute risk reduction of \n0.000407 when compared to a subject given a placebo. That is, there are 0.0407% \nfewer events of polio for subjects treated with the Salk vaccine than for subjects given \na placebo. This doesn’t seem like much of a reduction, but when considered in the con-\ntext of the number of polio events in a large population, it is a significant reduction.\nRelative Risk\nSection 1-3 included definitions of retrospective and prospective studies:\n \n■Retrospective Study: Data are collected from a past time period by going back in \ntime (through examinations of records, interviews, etc.).\n \n■Prospective Study: Data are collected in the future from groups or “cohorts” that \nshare common factors.\nA\nMonkey Typists\nA classical \nclaim is that \na monkey \nrandomly \nhitting a key-\nboard would \neventually \nproduce the complete works of \nShakespeare, assuming that it \ncontinues to type century after \ncentury. The multiplication rule \nfor probability has been used to \nfind such estimates. One  \nresult of 1,000,000,000,000,000, \n000,000,000,000,000,000,000 \nyears is considered by some to \nbe too short. In the same spirit, \nSir Arthur Eddington wrote this \npoem: “There once was a brainy \nbaboon, who always breathed \ndown a bassoon. For he said, ‘It \nappears that in billions of years, I \nshall certainly hit on a tune.’”\n",
    "4-4 Risks and Odds \n155\nIn a prospective study, a commonly used measure for comparing risk is relative risk. \nWe first introduce the following notation, and then we define relative risk.\nNotation\npt = proportion (or incidence rate) of some characteristic in a treatment group\npc = proportion (or incidence rate) of some characteristic in a control group\nDEFINITION\nIn a prospective study, the relative risk (or risk ratio or RR) of a characteristic \nis the ratio pt>pc, where pt is the proportion of the characteristic in the treatment \n(or exposed) group and pc is the proportion in the control group (or group not ex-\nposed). If the data are in the same format as the generalized Table 4-4, then the \nrelative risk is found by evaluating\npt\npc\n=\na\na + b\nc\nc + d\nInterpreting Relative Risk A relative risk value of 1 shows that the risk is the same \nfor the treatment group and the control (or placebo) group. A relative risk value much \ngreater than 1 shows that there is a much greater risk for the treatment group. The fol-\nlowing example illustrates how the relative risk of 0.287 shows that the risk of polio in \nthe treatment group is much less than the risk of polio in the placebo group.\nEXAMPLE 2  Computing Relative Risk\nUsing the data in Table 4-3, find the relative risk.\nSOLUTION\nFor the sample data in Table 4-3, we will consider the treatment group to be the \ngroup of children given the Salk vaccine, and the control group is the group of chil-\ndren given a placebo. Using the preceding notation, we have\npt = proportion of polio in treatment group =\n33\n33 + 200,712 = 0.000164\npc = proportion of polio in control 1placebo2 group =\n115\n115 + 201,114 =  0.000571\nUsing the above values, we can now find the relative risk as follows.\nRelative risk = pt\npc\n= 0.000164\n0.000571 = 0.287\nINTERPRETATION\nWe can interpret this result as follows: The polio rate for children given the Salk \nvaccine is 0.287 of the polio rate for children given a placebo. (A relative risk less \nthan 1 indicates that the treatment results in a reduced risk.) If we were to consider \nthe reciprocal value of 0.000571>0.000164 = 3.48, we see that children in the \n placebo group are 3.48 times more likely to get polio.\n",
    "156 \nCHAPTER 4 Probability\nNumber Needed to Treat\nOne problem with relative risk is that it may be misleading by suggesting that a treat-\nment is superior or inferior, even when the absolute difference between rates is not \nvery large. For example, if 3 out of 10,000 aspirin users were to experience an imme-\ndiate cure of a cold compared to only 1 out of 10,000 placebo users, the relative risk \nof 3.00 correctly indicates that the incidence of immediate cold cures is three times as \nhigh for aspirin users, but the cure rates of 0.0003 and 0.0001 are so close that, for all \npractical purposes, aspirin should not be considered as a factor affecting the immedi-\nate cure of a cold. With cure rates of 0.0003 and 0.0001, the absolute risk reduction is \n0.0002. Because the absolute risk reduction is so small, the effectiveness of the aspirin \ntreatment would be negligible. In such a situation, the number needed to treat would \nbe a more effective measure that is not so misleading.\nCAUTION: When interpreting relative risk, consider the incidence rates. If the \nprobability of disease in an exposed group is 5>1,000,000 and the probability \nof disease in an unexposed group is 1>1,000,000, the relative risk is 5.0, which \nsounds really bad, but the very low incidence rates suggest that there isn’t much \nrisk in either group.\nDEFINITION\nThe number needed to treat (NNT) is the number of subjects that must be treated \nin order to prevent one event, such as a disease or adverse reaction. It is calcu-\nlated by dividing 1 by the absolute risk reduction.\nnumber needed to treat =\n1\nabsolute risk reduction\nRound-Off Rule If the calculated value of the number needed to treat is not a whole \nnumber, round it up to the next larger whole number.\nIf the sample data are in the format of the generalized Table 4-4, then:\nNumber needed to treat =\n1\n`\na\na + b -\nc\nc + d `\n 1rounded up to the next\nlarger whole number2\nIf 3 out of 10,000 aspirin users were to experience an immediate cure of a cold \ncompared to only 1 out of 10,000 placebo users, the absolute risk reduction is \n\u001e0.0003 - 0.0001\u001e = 0.0002, and the number needed to treat is 1>0.0002 = 5000.\nThis means that we would need to treat 5000 subjects with colds to get one person \nwho experiences an immediate cure.\nEXAMPLE 3  Computing the Number Needed to Treat\nUsing the polio data in Table 4-3, find the number needed to treat, then interpret the \nresult.\nSOLUTION\nIn Example 1 we found that the absolute risk reduction is 0.000407. It is now easy \nto find the number needed to treat.\n",
    "4-4 Risks and Odds \n157\nOdds\nSo far in this chapter, we have used probability values to express likelihood of various \nevents. Probability values are numbers between 0 and 1 inclusive. However, expres-\nsions of likelihood are often given as odds, such as 50:1 (or “50 to 1”).\n Number needed to treat =\n1\nabsolute risk reduction =\n1\n0.000407 = 2457.002457\n = 2458 1rounded up2\nINTERPRETATION\nThe result of 2458 can be interpreted as follows: We would need to vaccinate 2458 \nchildren with the Salk vaccine (instead of a placebo) to prevent one of the children \nfrom getting polio. Given the extremely serious consequences of polio, the Salk \nvaccine has been found to be very effective and important.\nDEFINITIONS\nThe actual odds against event A occurring are the ratio P1A2>P1A2, usually ex-\npressed in the form of a:b (or “a to b”), where a and b are integers. (Reduce using \nthe largest common factor; if a = 16 and b = 4, express the odds as 4:1 instead \nof 16:4.)\nThe actual odds in favor of event A occurring are the ratio P1A2>P1A2, which is \nthe reciprocal of the actual odds against that event. If the odds against an event \nare a:b, then the odds in favor are b:a.\nNote that in the two preceding definitions, the actual odds against and the actual odds \nin favor describe the actual likelihood of some event. (Gambling situations typically \nuse payoff odds, which describe the amount of profit relative to the amount of a bet. \nFor example, if you bet on the number 7 in roulette, the actual odds against winning \nare 37:1, but the payoff odds are 35:1. Racetracks and casinos are in business to make \na profit, so the payoff odds will usually differ from the actual odds.)\nTABLE 4-5 Retrospective Study of Newborn Discharge and Rehospitalization\nRehospitalized \nwithin a week\nNot rehospitalized \nwithin a week\n \nTotal\nEarly discharge  \n(*30 hours)\n457\n3199\n3656\nLate discharge  \n(30+ hours)\n260\n2860\n3120\nEXAMPLE 4  Rehospitalization and Discharge\nConsider the data in Table 4-5 (based on results from “The Safety of Newborn Early \nDischarge,” by Liu, Clemens, Shay, Davis, and Novack, Journal of the American \nMedical Association, Vol. 278, No. 4).\n \na. For those babies discharged early, ﬁnd the probability of being rehospitalized \nwithin a week.\n \nb. For those babies discharged early, ﬁnd the odds in favor of being rehospital-\nized early.\ncontinued\n",
    "158 \nCHAPTER 4 Probability\nOdds Ratio\nFor the data in Table 4-5, how does the likelihood of rehospitalization differ between the \nearly discharge group and the late discharge group? One way to address that question is \nto use the odds ratio.\nSOLUTION\na. There were 3656 babies discharged early, and 457 of them were rehospital-\nized within a week, so\nP1rehospitalized2 = 457\n3656 = 1\n8\n \nb. Because P(rehospitalized) = 1>8, it follows that P1rehospitalized2 =\n1 - 1>8= 7>8. We can now ﬁnd the odds in favor of rehospitalization as follows:\nOdds in favor of rehospitalization for the early discharge group\n= P1rehospitalized2\nP1rehospitalized2 = 1>8\n7>8 = 1\n7\nThis result is often expressed as 1:7.\nWith odds of 1:7 in favor of rehospitalization for babies discharged early, it \n follows that the odds against rehospitalization for early discharge are 7:1.\nDEFINITION\nIn a retrospective or prospective study, the odds ratio (OR or relative odds) is a \nmeasure of risk found by evaluating the ratio of the odds in favor of the treatment \ngroup (or case group exposed to the risk factor) to the odds in favor of the control \ngroup, evaluated as follows:\nOdds ratio =\nodds in favor of treatment 1or exposed2 group\nodds in favor of control group\nIf the data are in the format of the generalized Table 4-4 on page 153, then the \nodds ratio can be computed as follows:\nOdds ratio = ad\nbc\nEXAMPLE 5  Computing Odds Ratio\nUsing the data in Table 4-5, find the odds ratio for rehospitalization.\nSOLUTION\nFor this example, we consider the case group to be the babies discharged early, and \nwe consider the control group to be the babies discharged late. The preceding exam-\nple showed that for the early discharge group, the odds in favor of rehospitalization \nare 1:7. Using similar calculations for the late discharge group, we get odds in favor \nof rehospitalization of 1>11 or 1:11. We can now find the odds ratio.\n Odds ratio = odds in favor of rehospitalization in early discharge group\nodds in favor of rehospitalization in late discharge group = 1>7\n1>11\n =  11\n7  or 1.571\n",
    "4-4 Risks and Odds \n159\nWhy Not Use Relative Risk for Retrospective Studies?\nRelative risk makes sense only if the involved probabilities are good estimates of \nthe actual incidence rates, as in a prospective study. Using relative risk for a retro-\nspective study could incorrectly involve a situation in which researchers can choose \ndisease cases that are very different from actual incidence rates, with the result that \nthe relative risk can be very wrong. That is the reason that relative risk is defined for \nprospective studies only. The odds ratio is defined for prospective and retrospective \nstudies.\n Relative Risk: Prospective study\n Odds Ratio:\n Prospective study or retrospective study\nTable 4–6 includes the results from a prospective study of 1000 randomly selected sub-\njects, which is conducted to investigate the risk of lung cancer from smoking.  Table 4-6 \ncontains entries that are realistic based on current incidence rates. However, Table 4-7 \nbelow is based on a retrospective study in which the researcher went back in time to \nfind 985 subjects with lung cancer and 985 subjects without lung cancer, so Table 4-7 \ndoes not reflect actual incidence rates. See the following.\nFrom Table 4-6: P1lung cancer \u001esmoker2 = 13>180 = 0.0722\nFrom Table 4-7: P1lung cancer \u001esmoker2 = 854>1021 = 0.836\nThe above probabilities are very different, so both of them cannot be good estimates of \nthe likelihood of getting lung cancer from smoking. The above probability of 0.0722 \nis a good estimate because it is based on a prospective study with realistic incidence \nrates, but the probability of 0.836 is a poor estimate because it is based on the retro-\nspective study designed to include an equal number of subjects with lung cancer and \nsubjects without lung cancer.\nNow compare the relative risk values and the odds ratio values from Tables 4-6 \nand 4-7. See that the odds ratio values are approximately the same, but the relative risk \nvalues are dramatically different. The relative risk value of 29.6 from the prospective \nstudy is a good measure, but the relative risk of 6.1 from the retrospective study is a \npoor measure.\nIf we take advantage of the fact that Table 4-5 does correspond to the generalized \nTable 4-4 on page 153, then the odds ratio can also be calculated as follows:\nOdds ratio = ad\nbc = 14572128602\n13199212602 = 1.571\nINTERPRETATION\nThis result indicates that the odds in favor of rehospitalization are 1.571 times \nhigher for babies discharged early when compared to those discharged late. This \nsuggests that newborns discharged early are at substantially increased risk of rehos-\npitalization.\nTABLE 4-6 Prospective Study\nRR = 29.6; OR = 31.8\nLung Cancer\nNo Lung Cancer\nSmoker\n13\n167\nNonsmoker\n 2\n818\nTABLE 4-7 Retrospective Study\nRR = 6.1; OR = 31.9\nLung Cancer\nNo Lung Cancer\nSmoker\n854\n167\nNonsmoker\n131\n818\nTotal\n985\n985\n",
    "160 \nCHAPTER 4 Probability\nSUMMARY OF KEY POINTS\nDisease\nNo Disease\nTreatment\na\nb\nPlacebo\nc\nd\nStatistical Literacy and Critical Thinking \n1. Notation The relative risk of a characteristic is the ratio pt>pc. What do pt and pc represent?\n2.  Relative Risk Identify an important disadvantage of relative risk used with a relatively \nsmall difference between the rates in the treatment and control groups.\n3. Number Needed to Treat A measure of the effectiveness of an influenza vaccine is the \nnumber needed to treat, which is 37 (under certain conditions). Interpret that number. Does the \nresult apply to every particular group of 37 subjects?\n4. Retrospective , Prospective The odds ratio is a measure used in retrospective or pro-\nspective studies. Describe retrospective and prospective studies.\nHeadaches and Viagra In Exercises 5−12, use the data in the accompanying table \n(based on data from Pfizer, Inc.). That table describes results from a clinical trial of the \ndrug Viagra. Some subjects were treated with Viagra while others were given a placebo; \nthen headache events were recorded.\nHeadache\nNo Headache\nViagra Treatment\n117\n617\nPlacebo\n 29\n696\n5. Type of Study Is the study retrospective or prospective?\n4-4 Basic Skills and Concepts\n \n■Absolute risk reduction = `\na\na + b -\nc\nc + d `\n \n■Number Needed to Treat (NNT) =\n1\nAbsolute Risk Reduction\n \n■Actual odds against event A = P1A2\nP1A2\n \n■Actual odds in favor of event A = P1A2\nP1A2\nRelative risk 1RR2 = pt\npc\n=\na\na + b\nc\nc + d\nOdds ratio 1OR2 = ad\nbc\n(for prospective only)\n",
    "4-4 Risks and Odds \n161\n6. Probability For those in the Viagra treatment group, find the probability that the subject \nexperienced a headache.\n7. Comparing Probabilities Compare P(headache \u001fViagra treatment) and  \nP(headache \u001f placebo).\n8. Absolute Risk Reduction Find the value of the absolute risk reduction for headaches in \nthe treatment and placebo groups.\n9. Number Needed to Treat Find the number of Viagra users that would need to stop using \nViagra in order to prevent a single headache.\n10. Odds For those in the Viagra treatment group, find the odds in favor of a headache, then \nfind the odds against a headache.\n11. Relative Risk Find the relative risk of a headache for those in the treatment group com-\npared to those in the placebo group. Interpret the result.\n12. Odds Ratio Find the odds ratio for headaches in the treatment group compared to the \nplacebo group, then interpret the result. Should Viagra users be concerned about headaches as \nan adverse reaction?\nClinical Trial of Atorvastatin (Lipitor). In Exercises 13−16, use the data in the accom-\npanying table that summarizes results from a clinical trial of atorvastatin (based on data \nfrom Parke-Davis).\nInfection\nNo Infection\nAtorvastatin (10 mg)\n89\n774\nPlacebo\n27\n243\n13. Absolute Risk Reduction\na. What is the probability of infection in the atorvastatin treatment group?\nb. What is the probability of infection in the placebo group?\nc. Find the value of the absolute risk reduction for infection in the placebo group and the atorv-\nastatin treatment group. Write a brief statement interpreting the result.\n14. Number Needed to Treat Calculate the number needed to treat and interpret the result.\n15. Odds For those who were treated with atorvastatin, find the odds in favor of an infection. \nAlso find the odds in favor of an infection for those given a placebo. Is there much of a differ-\nence between these two results?\n16. Odds Ratio and Relative Risk Find the odds ratio and relative risk for an infection in \nthe group treated with atorvastatin compared to the placebo group. Based on this result, does \natorvastatin appear to increase the risk of an infection? Why or why not?\n17. Odds Ratio and Relative Risk In a clinical trial of 2103 subjects treated with Nasonex \n(mometasone), 26 reported headaches. In a control group of 1671 subjects given a placebo, 22 \nreported headaches. Find the relative risk and odds ratio for the headache data. What do the \nresults suggest about the risk of a headache from the Nasonex treatment?\n18. Design of Experiments You would like to conduct a study to determine the effective-\nness of seat belts in saving lives in car crashes.\na. What would be wrong with randomly selecting 2000 drivers, then randomly assigning half \nof them to a group that uses seat belts and another group that does not wear seat belts?\nb. If 2000 drivers are randomly selected and separated into two groups according to whether \nthey use seat belts, what is a practical obstacle in conducting a prospective study of the effec-\ntiveness of seat belts in car crashes?\n",
    "162 \nCHAPTER 4 Probability\nIn the biological and health sciences, rates are often used to describe the likelihood of \nan event. Rates are used by researchers and health professionals to monitor the health \nstatus of a community or population. Although any specific time interval could be \nused, we assume a time interval of one year throughout this section.\n4-5 \nRates of Mortality, Fertility, and Morbidity\nDEFINITION\nA rate describes the frequency of occurrence of some event. It is the relative fre-\nquency of an event, multiplied by some number, typically a value such as 1000 or \n100,000. A rate can be expressed as\naa\nb bk\nwhere\na = frequency count of the number of people for whom the event occurred\nb = total number of people exposed to the risk of the event occurring\nk = multiplier number, such as 1000 or 100,000\nThe above general definition is commonly applied to measures of mortality, fertility, \nand morbidity. For the following rates, mortality refers to deaths, fertility refers to \nbirths, and morbidity refers to diseases. Here are additional terms and their meanings:\n \n■Infants: Babies who were born alive\n \n■Neonates: Infants under the age of 28 days\n \n■Fetal Death: Occurs when a fetus is delivered without life after 20 weeks of gestation\n \n■Neonatal Death: Occurs when an infant dies under 28 days of age\nMortality Rates\nCrude 1or unadjusted2 mortality rate = a\ndeaths\npopulation size bk\nInfant mortality rate = adeaths of infants under 1 year of age\nnumber of live births\nbk\nNeonatal mortality rate = adeaths of infants under 28 days of age\nnumber of live births\nbk\nFetal mortality rate =\na\nfetuses delivered without life after 20 weeks of gestation \nnumber of live births +  \n fetuses delivered without life after 20 weeks of gestation bk\nPerinatal mortality rate = afetal deaths + neonatal deaths\nlive births + fetal deaths\nbk\nFertility Rates\nCrude birthrate = a\nlive births\npopulation size bk\nGeneral fertility rate = a\nlive births\nnumber of women aged 15 - 44 bk\n",
    "4-5 Rates of Mortality, Fertility, and Morbidity \n163\nMorbidity (Disease) Rates\nIncidence rate = areported new cases of disease\npopulation size\nbk\nPrevalence rate = anumber of people with disease at a given time\npopulation size at the given point in time\nbk\nEXAMPLE 1  Crude Mortality Rate\nFor a recent year in the United States, there were 2,515,458 deaths in a population \nof 312,799,495 people. Use those values with a multiplier of 1000 to find the crude \nmortality rate.\nSOLUTION\nWith 2,515,458 people who died, with 312,799,495 people in the population, and \nletting k = 1000, we compute the crude mortality rate as follows:\n Crude mortality rate = a\ndeaths\npopulation size bk = a 2,515,458\n312,799,495b1000\n = 8.0 1rounded2\nINTERPRETATION\nFor this particular year, the death rate is 8.0 people for each 1000 people in the \n population. Using the relative frequency definition of probability given in Section 4-1, \nwe might also say that for a randomly selected person, the probability of death in \nthis year is 2,515,458>312,799,495 = 0.00804. One important advantage of the \nmortality rate of 8.0 people (per 1000 people in the population) is that it results in a \nvalue that uses fewer decimal places and is generally easier to use and understand.\nEXAMPLE 2  Infant Mortality Rate\nThe infant mortality rate is a very important measure of the health of a region. \n (According to the United Nations, the worldwide infant mortality rate is 49.4 per \n1000 live births.) For a recent year, there were 3,953,590 live births in the United \nStates, and there were 23,910 deaths of infants under 1 year of age. Using a mul-\ntiplying factor of k = 1000, find the infant mortality rate of the United States and \ncompare it to the rate of 2.1 for Japan.\nSOLUTION\nThe infant mortality rate is computed as shown below.\n Infant mortality rate = adeaths of infants under 1 year of age\nnumber of live births\nbk\n = a 23,910\n3,953,590b1000\n =  6.0 1rounded2\ncontinued\n",
    "164 \nCHAPTER 4 Probability\nA crude rate, as defined, is a single value based on crude totals. When compar-\ning two different regions, such as Florida and Colorado, a comparison of rates can be \nmisleading because of differences in factors such as age that might affect the rates. In \na recent year, the crude mortality rates (per 1000 population) were 9.1 in Florida and \n6.4 in Colorado. This is not too surprising, considering that in Florida, roughly 18% of \nthe population is over the age of 65, compared to only 11% for Colorado. The higher \nmortality rate for Florida does not mean that Florida is less healthy; in this case, it \nappears that Florida has a higher death rate largely because it has a higher proportion \nof older residents. Instead of using crude rates, we might use either specific rates or \nadjusted rates.\nSpecific rates are rates specific for some particular group, such as people aged \n18–24, or rates specific for some particular cause of death, such as deaths due to myo-\ncardial infarction.\nAdjusted rates involve calculations that can be quite complicated, but they basi-\ncally make adjustments for important factors, such as age, gender, or race.\nBecause age is the characteristic that typically affects mortality the most, it is the \nmost common factor used as the basis for adjustment. Calculations of adjusted rates \ninvolve the creation of a theoretical standardized population that is used for the re-\ngions being compared. A population of 1,000,000 people with the same composition \nas the United States is often used as the standardized population. Adjusted rates are \nvaluable for comparing different regions, but they do not necessarily reflect the true \ncrude death rates. Adjusted rates should not be used as death rates and they should not \nbe compared to crude rates.\nWhen assessing the accuracy of rates, we should consider the source. Mortality \nrates found in a source such as the Statistical Abstract of the United States (compiled \nby the U.S. Bureau of the Census) are likely to be quite accurate, because each state \nnow has a mandatory death reporting system, although official government reports \nseem to take years to produce. However, morbidity rates are likely to be less accurate, \nbecause some diseases are known to be underreported or not reported at all. Some \nmorbidity rates might be the result of very questionable surveys. However, some sur-\nveys, such as the annual National Health Survey, involve large samples of people who \nare very carefully chosen, so that results are likely to be very accurate.\nStatistical Literacy and Critical Thinking \n1. Birth Rate The birth rate in China is 12.3 per 1000. What exactly does that mean?\n2. Rates Exercise 1 describes the birth rate in China as 12.3 per 1000. Another way to describe \nthe birth rate is to give the rate as a proportion or probability of 0.0123. What advantage does \nthe rate of “12.3 per 1000” have over the rate expressed as 0.0123?\n3. Expected Births Given that China has a birth rate of 12.3 per 1000 and a population of \n1,360,762,587, about how many births are expected in a year?\n4. Incidence and Prevalence What is the difference between a disease incidence rate and a \ndisease prevalence rate?\n4-5 Basic Skills and Concepts\nINTERPRETATION\nThe infant mortality rate of 6.0 deaths per 1000 infants under 1 year of age is sub-\nstantially greater than the infant mortality rate of 2.1 in Japan.\n",
    "4-5 Rates of Mortality, Fertility, and Morbidity \n165\nFinding Rates. In Exercises 5−12, use the data in the accompanying table (based on data \nfor a recent year from various sources, including the U.S. Census Bureau and the National \nInstitutes of Health) to find the indicated rates. Round results to one decimal place, and use \na multiplying factor of k = 1000 unless indicated otherwise.\nVital Statistics for the United States in One Year\nPopulation: 312,799,495\nDeaths: 2,515,458\nWomen aged 15–44: 61,488,227\nMotor vehicle deaths: 33,783\nLive births: 3,953,590\nFetuses delivered without life after 20 weeks of \ngestation: 26,148\nDeaths of infants under 1 year of age: 23,910\nDeaths of infants under 28 days of age: 15,973\nHIV-infected persons: 1,155,792\nDeaths from HIV infections: 7683\n5. Find the neonatal mortality rate.\n6. Find the fetal mortality rate.\n7. Find the perinatal mortality rate.\n8. Find the crude birth rate.\n9. Find the general fertility rate.\n10. Using a multiplier of k = 100,000, find the motor vehicle death incidence rate.\n11. Find the HIV infection prevalence rate.\n12. Find the HIV infection mortality rate for HIV-infected persons.\n13. Finding Probability An example in this section involved the crude mortality rate, which \nwas found to be 8.0 persons per 1000 population. Find the probability of randomly selecting \nsomeone and getting a person who died within the year. What advantage does the crude mortal-\nity rate have over the probability value?\n14. Finding Probability The crude death rate for China was recently 7.4, and that rate was \ncomputed using a multiplier of k = 1000.\na. Find the probability that a randomly selected Chinese person died within the year.\nb. If two Chinese people are randomly selected, find the probability that they both died within \nthe year, and express the result using three significant digits.\nc. If two Chinese people are randomly selected, find the probability that neither of them died \nwithin the year, and express the result using three significant digits.\n15. Finding Probability The crude death rate for Spain was recently 8.3, and that rate was \ncomputed using a multiplier of k = 1000.\na. Find the probability that a randomly selected Spaniard died within the year.\nb. If two Spaniards are randomly selected, find the probability that they both died within the \nyear, and express the result using three significant digits.\nc. If two Spaniards are randomly selected, find the probability that at least one of them sur-\nvived the year, and express the result using six decimal places. What would be wrong with \nexpressing the answer using three significant digits?\ncontinued\n",
    "166 \nCHAPTER 4 Probability\n16. Finding Probability In a recent year in the United States, there were 787,650 deaths due \nto cardiovascular disease, and the population was 312,799,495.\na. Find the crude mortality rate for cardiovascular disease. (This result is sometimes called the \ncause-specific death rate.)\nb. Find the probability that a randomly selected person died of cardiovascular disease and \n express the result using three significant digits.\nc. Find the probability that when three people are randomly selected, none of them died \n because of cardiovascular disease.\n17.  Cause-of-Death Ratio In a recent year in the United States, there were 2,515,458 \ndeaths, and 787,650 of them were due to cardiovascular disease. The cause-of-death ratio is \nexpressed as follows:\nadeaths due to specific disease\ntotal number of deaths\nbk where k = 100\na. Find the cause-of-death ratio for cardiovascular disease.\nb. If three of the deaths are randomly selected, find the probability that none of them are due to \ncardiovascular disease.\n18. Crude Mortality Rates The table below lists numbers of deaths and population sizes for \ndifferent age groups for Florida and the United States for a recent year.\na. Find the crude mortality rate for Florida and the crude mortality rate for the United States. Al-\nthough we should not compare crude mortality rates, what does the comparison suggest in this case?\nb. Using only the age group of 65 and older, find the mortality rates for Florida and the United \nStates. Compare the results.\nc. What percentage of the Florida population is made up of people aged 65 and older? What is \nthe percentage for the United States? What do the results suggest about the crude mortality for \nFlorida compared to the United States?\nAge\n0–24\n25–64\n65 and older\nFlorida deaths\n      3625\n     39,820\n   129,395\nFlorida population\n  5,716,861\n   9,842,031\n 3,375,303\nU.S. deaths\n     63,208\n    619,982\n 1,832,268\nU.S. population\n103,542,603\n163,960,163\n45,296,729\n19. Number of Deaths The number of deaths in the United States has been steadily increas-\ning each year. Does this mean that the health of the nation is declining? Why or why not?\n20. Comparing Rates In a recent year, the crude mortality rate of the United States was 8.0 \n(per 1000 population), and the corresponding crude mortality rate for China was 7.4. What is a \nmajor problem with comparing the crude mortality rates of the United States and China?\n21. Adjusted Mortality Rate Refer to the data listed in Exercise 18. Change the Florida popula-\ntion sizes for the three age categories so that they fit the same age distribution as the U.S. popu-\nlation. Next, adjust the corresponding numbers of deaths proportionately. (Use the same Florida \nmortality rates for the individual age categories, but apply those rates to the adjusted population \nsizes.) Finally, compute the Florida mortality rate using the adjusted values. The result is a mortal-\nity rate adjusted for the variable of age. (Better results could be obtained by using more age catego-\nries.) How does this adjusted mortality rate for Florida compare to the mortality rate for the United \nStates? (Note: There are other methods for computing adjusted rates than the one used here.)\n4-5 Beyond the Basics\n",
    "4-6 Counting \n167\nMULTIPLICATION COUNTING RULE: For a sequence of events in which the first \nevent can occur n1 ways, the second event can occur n2 ways, the third event can \noccur n3 ways, and so on, the total number of possibilities is n1 # n2 # n3 . . ..\nEXAMPLE 1  Multiplication Counting Rule: DNA\nIn a linear triplet of three DNA nucleotides, each of the nucleotides can be any one \nof these four bases (with repetition allowed): A (adenine); C (cytosine); G (guanine); \nT (thymine). Two different examples of triplets are CTA and TTG. What is the total \nnumber of different possible triplets? Given that the four nucleotides are equally \nlikely, what is the probability of getting the triplet of AAA?\nSOLUTION\nThere are 4 different possibilities for each of the three nucleotides, so the total num-\nber of different possible triplets is n1 # n2 # n3 = 4 # 4 # 4 = 64.\nIf the four nucleotides are equally likely, the probability of getting the triplet of \nAAA is 1>64 or 0.0156.\n2. Factorial Rule\nThe factorial rule is used to find the total number of ways that n different items can \nbe rearranged with different arrangements of the same items counted separately. The \nfactorial rule uses the following notation.\nNOTATION\nThe factorial symbol (!) denotes the product of decreasing positive whole num-\nbers. For example, 4! = 4 # 3 # 2 # 1 = 24. By special definition, 0! = 1.\nFACTORIAL RULE The number of different arrangements (order matters) of n \ndifferent items when all n of them are selected is n!.\nThe factorial rule is based on the principle that the first item may be selected n differ-\nent ways, the second item may be selected n - 1 ways, and so on.\nRouting problems often involve applications of the factorial rule, as in the follow-\ning example.\nKey Concept Probability problems typically require that we know the total number of \nsimple events, but finding that number often requires one of the five rules presented in \nthis section. In Section 4-2, with the addition rule, multiplication rule, and conditional \nprobability, we encouraged intuitive rules based on understanding and we discour-\naged blind use of formulas, but this section requires much greater use of formulas as \nwe consider five different methods for counting the number of possible outcomes in a \nvariety of situations. Not all counting problems can be solved with these five methods, \nbut they do provide a strong foundation for the most common real applications.\n1. Multiplication Counting Rule\nThe multiplication counting rule is used to find the total number of possibilities from \nsome sequence of events.\n4-6 \nCounting\n",
    "168 \nCHAPTER 4 Probability\nPermutations and Combinations: Does Order Count?\nWhen using different counting methods, it is essential to know whether different ar-\nrangements of the same items are counted only once or are counted separately. The \nterms permutations and combinations are standard in this context, and they are de-\nfined as follows:\nEXAMPLE 2  Factorial Rule: Travel Itinerary\nQuest Diagnostics collects blood specimens from different laboratories. A driver is \ndispatched to make collections at 5 different locations. How many different routes \nare possible?\nSOLUTION\nFor those 5 different locations, the number of different routes is 5! =\n5 # 4 # 3 # 2 # 1 = 120.\nNote that this solution could have been done by applying the multiplica-\ntion counting rule. The first stop can be any one of the 5 locations, the second \nstop can be any one of the 4 remaining locations, and so on. The result is again \n5 # 4 # 3 # 2 # 1 = 120. Use of the factorial rule has the advantage of including the \nfactorial symbol, which is sure to impress.\nDEFINITIONS\nPermutations of items are arrangements in which different sequences of the same \nitems are counted separately. (The letter arrangements of abc, acb, bac, bca, cab, \nand cba are all counted separately as six different permutations.)\nCombinations of items are arrangements in which different sequences of the \nsame items are counted as being the same. (The letter arrangements of abc, acb, \nbac, bca, cab, and cba are all considered to be the same single combination.)\nMnemonics for Permutations and Combinations\n \n■Remember “Permutations Position,” where the alliteration reminds us that with \npermutations, the positions of the items makes a difference.\n \n■Remember “Combinations Committee,” which reminds us that with members of \na committee, rearrangements of the same members result in the same committee, \nso order does not count.\n3. Permutations Rule (When All of the Items Are Different)\nThe permutations rule is used when there are n different items available for selection, \nwe must select r of them without replacement, and the sequence of the items matters. \nThe result is the total number of arrangements (or permutations) that are possible. (Re-\nmember: Rearrangements of the same items are counted as different permutations.)\nPERMUTATIONS RULE: When n different items are available and r of them are \nselected without replacement, the number of different permutations (order counts) \nis given by\nnPr =\nn!\n1n - r2!\n",
    "4-6 Counting \n169\n4. Permutations Rule (When Some Items Are Identical to Others)\nWhen n items are all selected without replacement, but some items are identical, the \nnumber of possible permutations (order matters) is found by using the following rule.\nEXAMPLE 3   Permutations Rule (with Different Items):  \nClinical Trial of New Drug\nWhen testing a new drug, Phase I requires only 5 volunteers, and the objective is \nto assess the drug’s safety. To be very cautious, we plan to treat the 5 subjects in \nsequence, so that any particularly adverse effect can allow us to stop the treatments \nbefore any other subjects are treated. If 8 volunteers are available, how many differ-\nent sequences of 5 subjects are possible?\nSOLUTION\nWe need to select r = 5 subjects from n = 8 volunteers that are available. The num-\nber of different sequences of arrangements is found as shown:\nnPr =\nn!\n1n - r2! =\n8!\n18 - 52! = 6720\nThere are 6720 different possible arrangements of 5 subjects selected from the 8 \nthat are available.\nPERMUTATIONS RULE (WHEN SOME ITEMS ARE IDENTICAL TO OTHERS)\nThe number of different permutations (order counts) when n items are available \nand all n of them are selected without replacement, but some of the items are iden-\ntical to others, is found as follows:\nn!\nn1!n2! . . . nk! where n1 are alike, n2 are alike,…, and nk are alike.\nEXAMPLE 4   Permutations Rule (with Some Identical Items):  \nDesigning Surveys\nWhen designing surveys, pollsters sometimes repeat a question to see if a subject \nis thoughtlessly providing answers just to finish quickly. For one particular survey \nwith 10 questions, 2 of the questions are identical to each other, and 3 other ques-\ntions are also identical to each other. For this survey, how many different arrange-\nments are possible? Is it practical to survey enough subjects so that every different \npossible arrangement is used?\nSOLUTION\nWe have 10 questions with 2 that are identical to each other and 3 others that are \nalso identical to each other, and we want the number of permutations. Using the rule \nfor permutations with some items identical to others, we get\nn!\nn1!n2! . . . nk! = 10!\n2!3! = 3,628,800\n2 # 6\n= 302,400\ncontinued\n",
    "170 \nCHAPTER 4 Probability\n5. Combinations Rule\nThe combinations rule is used when there are n different items available for selection, \nonly r of them are selected without replacement, and order does not matter. The result \nis the total number of combinations that are possible. (Remember: Rearrangements of \nthe same items are considered to be the same combination.)\nINTERPRETATION\nThere are 302,400 different possible arrangements of the 10 questions. It is not \npractical to accommodate every possible permutation. For typical surveys, the num-\nber of respondents is somewhere around 1000.\nCOMBINATIONS RULE:\nWhen n different items are available, but only r of them are selected without replace-\nment, the number of different combinations (order does not matter) is found as follows:\nnCr =\nn!\n1n - r2!r!\nEXAMPLE 5  Combinations Rule: Phase I of a Clinical Trial\nWhen testing a new drug on humans, a clinical test is normally done in three \nphases. Phase I is conducted with a relatively small number of healthy volunteers. \nAssume that we want to treat 20 healthy humans with a new drug, and we have  \n30 suitable volunteers available. If 20 subjects are selected from the 30 that are \navailable, and the 20 selected subjects are all treated at the same time, how many \ndifferent treatment groups are possible?\nSOLUTION\nBecause all subjects are treated at the same time, order is irrelevant, so we need to \nfind the number of different possible combinations. With n = 30 subjects available \nand with r = 20 subjects selected, the number of combinations is found as follows.\nnCr =\nn!\n1n - r2!r! =\n30!\n130 - 202!20! =\n30!\n10! # 20! = 30,045,015\nINTERPRETATION\nThere are 30,045,015 different possible combinations.\nPermutations or Combinations? Because choosing between permutations and com-\nbinations can often be tricky, we provide the following example that emphasizes the \ndifference between them.\nEXAMPLE 6   Permutations and Combinations:  \nOfficers and Committees\nThe Portland Medical Center must appoint three corporate officers: chief executive \nofficer (CEO), executive chairperson, and chief operating officer (COO). It must \nalso appoint a planning committee with three different members. There are eight \nqualified candidates, and officers can also serve on the planning committee.\n",
    "4-6 Counting \n171\n \na. How many diﬀerent ways can the oﬃcers be appointed?\n \nb. How many diﬀerent ways can the committee be appointed?\nSOLUTION\nNote that in part (a), order is important because the officers have very different \nfunctions. However, in part (b), the order of selection is irrelevant because the com-\nmittee members all serve the same function.\n \na. Because order does count, we want the number of permutations of r = 3 \npeople selected from the n = 8 available people. We get\nnPr =\nn!\n1n - r2! =\n8!\n18 - 32! = 336\n \nb. Because order does not count, we want the number of combinations of r = 3 \npeople selected from the n = 8 available people. We get\nnCr =\nn!\n1n - r2!r! =\n8!\n18 - 32!3! = 56\nWith order taken into account, there are 336 different ways that the officers can be \nappointed, but without order taken into account, there are 56 different possible com-\nmittees.\nStatistical Literacy and Critical Thinking \n1. Notation What does the symbol ! represent? Six different patients can be scheduled for \nX-ray films 6! different ways, so what is the actual number of ways that six people can be \nscheduled for X-ray films?\n2.  Permutations, Combinations What is the basic difference between permutations and \ncombinations?\n3. Notation Evaluate 9C4. What does the result represent?\n4. Notation Evaluate 9P4. What does the result represent?\nIn Exercises 5–30, express all probabilities as fractions.\n5. Pin Numbers The Kinsale Medical Supply Company issues pin numbers to its employees \nso that they can access an online database. A hacker must randomly guess the correct pin code \nfor the Information Technology supervisor, and that pin code consists of four digits (each 0 \nthrough 9) that must be entered in the correct order. Repetition of digits is allowed. What is the \nprobability of a correct guess on the first try?\n6. Social Security Numbers A Social Security number consists of nine digits in a particular \norder, and repetition of digits is allowed. After seeing the last four digits printed on a receipt, if \nyou randomly select the other digits, what is the probability of getting the correct Social Secu-\nrity number of the person who was given the receipt?\n7. Assigning Shifts The staff supervisor at the Wellington Medical Center must assign a \nteam of two physicians to work the emergency room on Saturday night. If there are 19 physi-\ncians available and two of them are randomly selected, what is the probability of getting the \ntwo youngest physicians?\n4-6 Basic Skills and Concepts\n",
    "172 \nCHAPTER 4 Probability\n8. Review Board The supervisor at the Wellington Medical Center must select three nurses \nfrom 11 who are available for a review board. How many different ways can that be done?\n9. Blood Test Quest Diagnostics has just received 8 different blood samples. If they are tested \nin random order, what is the probability that they are tested in the alphabetical order of the sub-\njects who provided the samples?\n10. Radio Station Call Letters If radio station call letters must begin with either K or W and \nmust contain a total of either three or four letters, how many different possibilities are there?\n11. Scheduling Routes A new director of the Veterans Health Administration plans to visit \none hospital in each of five different states. If the five states are randomly selected from all 50 \nstates without replacement and the order is also random, what is the probability that she visits \nIdaho, Oregon, Alaska, New Jersey, and Ohio, in that order?\n12. Survey Reliability A health survey with 12 questions is designed so that 3 of the ques-\ntions are identical and 4 other questions are identical (except for minor changes in wording). \nHow many different ways can the 12 questions be arranged?\n13. Safety with Numbers A safe “combination” consists of four numbers between 0 and 99, \nand the safe is designed so that numbers can be repeated. If someone tries to gain access to the \nsafe, what is the probability that he or she will get the correct combination on the first attempt? \nAssume that the numbers are randomly selected. Given the number of possibilities, does it \nseem feasible to try opening the safe by making random guesses for the combination?\n14. Electricity The control panel for an MRI device uses five color-coded wires. If we trou-\nbleshoot by testing two wires at a time, how many different tests are required for every possible \npairing of two wires?\n15. Clinical Trial In a clinical trial of the drug atorvastatin (Lipitor), one group of subjects \nwas given placebos, a second group was given treatments of 10 mg, a third group was given \ntreatments of 20 mg, a fourth group was given treatments of 40 mg, and a fifth group was given \ntreatments of 80 mg. If the Phase I trial involved 15 subjects randomly assigned to the five \ngroups with three in each group, how many different ways can the groups be formed?\n16. Emergency Room Instead of treating emergency room patients in the order that they \narrive, it is common to treat those with more serious problems first. If an emergency room has \nseven different patients, how many ways can they be arranged in sequence?\n17. ZIP Code If you randomly select five digits, each between 0 and 9, with repetition allowed, \nwhat is the probability you will get the ZIP code of the Secretary of Health and Human Services?\n18. FedEx Deliveries With a short time remaining in the day, a FedEx driver has time to make \ndeliveries at 6 locations among the 9 locations remaining. How many different routes are possible?\n19. Phone Numbers Current rules for telephone area codes allow the use of digits 2–9 for \nthe first digit and 0–9 for the second and third digits. How many different area codes are pos-\nsible with these rules? That same rule applies to the exchange numbers, which are the three \ndigits immediately preceding the last four digits of a phone number. Given both of those rules, \nhow many ten-digit phone numbers are possible? Given that these rules apply to the United \nStates and Canada and a few islands, are there enough possible phone numbers? (Assume that \nthe combined population is about 400,000,000.)\n20. Classic Counting Problem A classic counting problem is to determine the number of \ndifferent ways that the letters of “Mississippi” can be arranged. Find that number.\n21. Corporate Officers and Committees The Newport Medical Supply Company must \nappoint a president, chief executive officer (CEO), chief operating officer (COO), and chief \nfinancial officer (CFO). It must also appoint a strategic planning committee with four different \nmembers. There are 10 qualified candidates, and officers can also serve on the committee.\na. How many different ways can the four officers be appointed?\nb. How many different ways can a committee of four be appointed?\ncontinued\n",
    "4-6 Counting \n173\nc. What is the probability of randomly selecting the committee members and getting the four \nyoungest of the qualified candidates?\n22. Card Access You have an identification card used for access to a secure area of the Wel-\nlington Medical Center. It’s dark and you can’t see your card when you insert it. The card must \nbe inserted with the front side up and the printing configured so that the beginning of your \nname enters first.\na. What is the probability of selecting a random position and inserting the card with the result \nthat the card is inserted correctly?\nb. What is the probability of randomly selecting the card’s position and finding that it is incor-\nrectly inserted on the first attempt, but it is correctly inserted on the second attempt?\nc. How many random selections are required to be absolutely sure that the card works because \nit is inserted correctly?\n23. Amino Acids With 8 different amino acids available, 5 are to be selected to form a chain \n(called a polypeptide chain) in which order counts. How many different chains are possible?\n24. Identity Theft with Credit Cards Credit card numbers typically have 16 digits, but not \nall of them are random.\na. What is the probability of randomly generating 16 digits and getting your MasterCard number?\nb. Receipts often show the last four digits of a credit card number. If only those last four digits are \nknown, what is the probability of randomly generating the other digits of your MasterCard number?\nc. Discover cards begin with the digits 6011. If you know that the first four digits are 6011 and \nyou also know the last four digits of a Discover card, what is the probability of randomly gener-\nating the other digits and getting all of them correct? Is this something to worry about?\n25. What a Word! One of the longest words in standard statistics terminology is “homosce-\ndasticity.” How many ways can the letters in that word be arranged?\n26. Phase I of a Clinical Trial A clinical test on humans of a new drug is normally done \nin three phases. Phase I is conducted with a relatively small number of healthy volunteers. For \nexample, a Phase I test of bexarotene involved only 14 subjects. Assume that we want to treat \n14 healthy humans with this new drug and we have 16 suitable volunteers available.\na. If the subjects are selected and treated one at a time in sequence, how many different sequen-\ntial arrangements are possible if 14 people are selected from the 16 that are available?\nb. If 14 subjects are selected from the 16 that are available, and the 14 selected subjects are all \ntreated at the same time, how many different treatment groups are possible?\nc. If 14 subjects are randomly selected and treated at the same time, what is the probability of \nselecting the 14 youngest subjects?\n27. Lightning and Lottery As of this writing, the Mega Millions lottery is run in 44 states. \nWinning the jackpot requires that you select the correct five different numbers between 1 and \n75 and, in a separate drawing, you must also select the correct single number between 1 and 15. \nFind the probability of winning the jackpot if you buy one ticket. How does the result compare \nto the probability of being struck by lightning in a year, which the National Weather Service \nestimates to be 1>960,000?\n28. Designing Experiment Clinical trials of Nasonex involved a group given placebos and \nanother group given treatments of Nasonex. Assume that a preliminary Phase I trial is to be \nconducted with 12 subjects, including 6 men and 6 women. If 6 of the 12 subjects are randomly \nselected for the treatment group, find the probability of getting 6 subjects of the same gender. \nWould there be a problem with having members of the treatment group all of the same gender?\n",
    "174 \nCHAPTER 4 Probability\n29. Morse Codes The International Morse code is a way of transmitting coded text by using \nsequences of on>off tones. Each character is 1 or 2 or 3 or 4 or 5 segments long, and each seg-\nment is either a dot or a dash. For example, the letter G is transmitted as two dashes followed \nby a dot, as in — — •. How many different characters are possible with this scheme? Are there \nenough characters for the alphabet and numbers?\n30. Mendel’s Peas Mendel conducted some his famous experiments with peas that were \neither smooth yellow plants or wrinkly green plants. If four peas are randomly selected from a \nbatch consisting of four smooth yellow plants and four wrinkly green plants, find the probabil-\nity that the four selected peas are of the same type.\n31. Computer Variable Names A common computer programming rule is that names of \nvariables must be between one and eight characters long. The first character can be any of the \n26 letters, while successive characters can be any of the 26 letters or any of the 10 digits. For \nexample, allowable variable names include A, BBB, and M3477K. How many different vari-\nable names are possible? (Ignore the difference between uppercase and lowercase letters.)\n32. Handshakes\na. Five physicians gather for a meeting about a patient. If each physician shakes hands with \neach other physician exactly once, what is the total number of handshakes?\nb. If n physicians shake hands with each other exactly once, what is the total number of hand-\nshakes?\nc. How many different ways can five physicians be seated at a round table? (Assume that if \neveryone moves to the right, the seating arrangement is the same.)\nd. How many different ways can n physicians be seated at a round table?\n4-6 Beyond the Basics\n1. Standard Tests Standard tests, such as the MCAT, tend to make extensive use of multiple-\nchoice questions because they are easy to grade using software. If one such multiple-choice \nquestion has possible correct answers of a, b, c, d, e, what is the probability of a wrong answer \nif the answer is a random guess?\n2.  Likelihood of Disease After obtaining a patient’s positive test result, a physician con-\ncludes that there is a 30% chance that the subject has a disease. What is the probability that the \nsubject does not have the disease?\n3. Months If a month is randomly selected after mixing the pages from a calendar, what is the \nprobability that it is a month containing the letter y?\n4.  Sigmoidoscopy, Colonoscopy Based on data from the Centers for Disease Control, \n67.7% of males over the age of 50 have had a sigmoidoscopy or colonoscopy. If two males over \nthe age of 60 are randomly selected, what is the probability that they both have had a sigmoid-\noscopy or colonoscopy?\n5. Subjective Probability Estimate the probability that the next time you get a cut, it requires \nstitches.\nChapter Quick Quiz\n",
    "In Exercises 6–10, use the following results from tests of an experiment to test the effective-\nness of an experimental vaccine for children (based on data from USA Today). Express all \nprobabilities in decimal form.\nDeveloped Flu\nDid Not Develop Flu\nVaccine Treatment\n14\n1056\nPlacebo\n95\n 437\n6. If 1 of the 1602 subjects is randomly selected, find the probability of getting 1 that devel-\noped flu.\n7. If 1 of the 1602 subjects is randomly selected, find the probability of getting 1 who had the \nvaccine treatment or developed flu.\n8. If 1 of the 1602 subjects is randomly selected, find the probability of getting 1 who had the \nvaccine treatment and developed flu.\n9. Find the probability of randomly selecting 2 subjects without replacement and finding that \nthey both developed flu.\n10. Find the probability of randomly selecting 1 of the subjects and getting 1 who developed \nflu, given that the subject was given the vaccine treatment.\nIn Exercises 1–10, use the data in the accompanying table and express all results in decimal \nform. (The results are based on “Splinting vs Surgery in the Treatment of Carpal Tunnel Syn-\ndrome,” by Gerritsen et al., Journal of the American Medical Association, Vol. 288, No. 10.)\nTreatment for Carpal Tunnel Syndrome\nSuccessful Treatment\nUnsuccessful Treatment\nSplint Treatment\n60\n23\nSurgery Treatment\n67\n 6\n1. Success If 1 of the patients is randomly selected, find the probability of selecting someone \nwith a successful treatment.\n2. Success Find the probability of randomly selecting a patient and getting one with a suc-\ncessful treatment, given that the patient was treated with splinting.\n3. Success Find the probability of randomly selecting a patient and getting one with a suc-\ncessful treatment, given that the patient was treated with surgery.\n4. Success or Surgery If 1 of the patients is randomly selected, find the probability of get-\nting a patient who had a successful treatment or was treated with surgery.\n5. No Success or Splint If 1 of the patients is randomly selected, find the probability of get-\nting someone who had an unsuccessful treatment or was treated with a splint.\n6. Both Successful If 2 patients are randomly selected without replacement, find the prob-\nability that they both had successful treatments.\n7. Both Successful If 2 patients are randomly selected with replacement, find the probability \nthat they both had successful treatments.\n8. Complement If A represents the event of randomly selecting one patient included in the \ntable and getting someone who was treated with surgery, what does A represent? Find the value \nof P1A2.\nReview Exercises\nCHAPTER 4 Review Exercises \n175\n",
    "176 \nCHAPTER 4 Probability\n9. Complement If A represents the event of randomly selecting one patient included in the \ntable and getting someone who had a successful treatment, what does A represent? Find the \nvalue of P1A2.\n10. All Three Successful If 3 patients are randomly selected without replacement, find the \nprobability that all three had successful treatments.\n11. Vision Correction About 75% of the U.S. population uses some type of vision correction \n(such as glasses or contact lenses).\na. If someone is randomly selected, what is the probability that he or she does not use vision \ncorrection?\nb. If four different people are randomly selected, what is the probability that they all use vision \ncorrection?\nc. Would it be unlikely to randomly select four people and find that they all use vision correc-\ntion? Why or why not?\n12. National Statistics Day\na. If a person is randomly selected, find the probability that his or her birthday is October 18, \nwhich is National Statistics Day in Japan. Ignore leap years.\nb. If a person is randomly selected, find the probability that his or her birthday is in October. \nIgnore leap years.\nc. Estimate a subjective probability for the event of randomly selecting an adult American and \ngetting someone who knows that October 18 is National Statistics Day in Japan.\nd. Is it unlikely to randomly select an adult American and get someone who knows that Octo-\nber 18 is National Statistics Day in Japan?\n13. Composite Sampling for Diabetes Currently, the rate for new cases of diabetes in a year \nis 3.4 per 1000 (based on data from the Centers for Disease Control and Prevention). When \ntesting for the presence of diabetes, the Portland Diagnostics Laboratory saves money by com-\nbining blood samples for tests. The combined sample tests positive if at least one person has \ndiabetes. If the combined sample tests positive, then the individual blood tests are performed. \nIn a test for diabetes, blood samples from 10 randomly selected subjects are combined. Find \nthe probability that the combined sample tests positive with at least 1 of the 10 people having \ndiabetes. Is it likely that such combined samples test positive?\n14. Redundancy Using battery-powered alarm clocks, it is estimated that the probability of \nfailure on any given day is 1>1000.\na. What is the probability that the alarm clock works for an important event?\nb. When using two alarm clocks for an important event, what is the probability that at least one \nof them works?\nCumulative Review Exercises\n1. Fatal Drunk Driving Listed below are the blood alcohol concentrations (g>dL) of drivers \nconvicted of drunk driving in fatal car crashes (based on data from the National Highway Traf-\nfic Safety Administration).\n0.09 0.11 0.11 0.13 0.14 0.15 0.17 0.17 0.18 0.18 0.23 0.35\nFind the value of the following statistics and include appropriate units.\na. mean         b. median   c. midrange   d. range\ne. standard deviation   f. variance\n",
    "2. Fatal Drunk Driving Use the same data given in Exercise 1.\na. Identify the 5-number summary and also identify any values that appear to be outliers.\nb. Construct a boxplot.  c. Construct a stemplot.\n3. Organ Donors USA Today provided information about a survey (conducted for Donate Life \nAmerica) of 5100 adult Internet users. Of the respondents, 2346 said they are willing to donate \norgans after death. In this survey, 100 adults were surveyed in each state and the District of Co-\nlumbia, and results were weighted to account for the different state population sizes.\na. What percentage of respondents said that they are willing to donate organs after death?\nb. Based on the poll results, what is the probability of randomly selecting an adult who is will-\ning to donate organs after death?\nc. What term is used to describe the sampling method of randomly selecting 100 adults from \neach state and the District of Columbia?\n4. Sampling Eye Color Based on a study by Dr. P. Sorita Soni, eye colors in the United States \nare as follows: 40% brown, 35% blue, 12% green, 7% gray, 6% hazel.\na. A statistics instructor collects eye color data from her students. What is the name for this \ntype of sample?\nb. Identify one factor that might make the sample from part (a) biased and not representative of \nthe general population of people in the United States.\nc. What is the probability that a randomly selected person will have brown or blue eyes?\nd. If two people are randomly selected, what is the probability that at least one of them has \nbrown eyes?\n5. Blood Pressure and Platelets Given below are the systolic blood pressure measurements \n(mm Hg) and blood platelet counts (1000 cells>mL) of the first few subjects included in Data \nSet 1 “Body Data” in Appendix B. Construct a graph suitable for exploring an association be-\ntween systolic blood pressure and blood platelet count. What does the graph suggest about that \nassociation?\nSystolic\n100\n112\n134\n126\n114\n134\n118\n138\n114\n124\nPlatelet\n319\n187\n297\n170\n140\n192\n191\n286\n263\n193\nCHAPTER 4 Technology Project \n177\nSimulations Calculating probabilities are sometimes painfully difficult, but simulations pro-\nvide us with a very practical alternative to calculations based on formal rules. A simulation \nof a procedure is a process that behaves the same way as the procedure so that similar results \nare produced. Instead of calculating the probability of getting exactly 5 boys in 10 births, you \ncould repeatedly toss 10 coins and count the number of times that exactly 5 heads (or simulated \n“boys”) occur. Better yet, you could do the simulation with a random number generator on a \ncomputer or calculator to randomly generate 1s (or simulated “boys”) and 0s (or simulated \n“girls”). Let’s consider this probability exercise:\nFind the probability that among 50 randomly selected people, at least 3 have  \nthe same birthday.\nFor the above problem, a simulation begins by representing birthdays by integers from \n1 through 365, where 1 represents a birthday of January 1, and 2 represents January 2, \nand so on. We can simulate 50 birthdays by using a calculator or computer to generate 50 \nTechnology Project\ncontinued\n",
    "178 \nCHAPTER 4 Probability\nrandom numbers (with repetition allowed) between 1 and 365. Those numbers can then be \nsorted, so it becomes easy to examine the list to determine whether any 3 of the simulated \nbirth dates are the same. (After sorting, equal numbers are adjacent.) We can repeat the \nprocess as many times as we wish, until we are satisfied that we have a good estimate of the \nprobability. Use technology to simulate 20 different groups of 50 birthdays. Use the results \nto estimate the probability that among 50 randomly selected people, at least 3 have the same \nbirthday.\nSummary of Simulation Functions:\nStatdisk: \n Select Data from the top menu, select Uniform Generator from the \ndropdown menu.\nExcel: \n Click Insert Function fx, select Math & Trig, select  \nRANDBETWEEN. Copy to additional cells.\nTI-83 , 84 Plus:  Press L, select PROB from the top menu, select randInt from the menu.\nStatCrunch: \n Select Data from the top menu, select Simulate from the dropdown \nmenu, select Discrete Uniform from the submenu.\nMinitab: \n Select Calc from the top menu, select Random Data from the drop-\ndown menu, select Integer from the submenu.\nFROM DATA TO DECISION \nCritical Thinking:  \nInterpreting results from a test for smoking\nIt is estimated that roughly half of patients who smoke lie \nwhen asked if they smoke. Pulse CO-oximeters may be a \nway to get information about smoking without relying on pa-\ntients’ statements. Pulse CO-oximeters use light that shines \nthrough a fingernail, and it measures carboxyhemoglobin \n(carbon monoxide in blood). These devices are used by fire-\nmen and emergency departments to detect carbon monoxide \npoisoning, but they can also be used to identify smokers. The \naccompanying table lists results from people aged 18–44 \nwhen the pulse CO-oximeter is set to detect a 6% or higher \nlevel of carboxyhemoglobin (based on data from “Carbon \nMonoxide Test Can Be Used to Identify Smoker,” by Patrice \nWendling, Internal Medicine News, Vol. 40., No. 1, and \nCenters for Disease Control and Prevention).\nCO-Oximetry Test for Smoking\nPositive Test Result\nNegative Test Result\nSmoker\n49\n 57\nNonsmoker\n24\n370\nAnalyzing the Results\n1. False Positive Based on the results in the table, find the \nprobability that a subject is not a smoker, given that the test \nresult is positive.\n2. True Positive Based on the results in the table, find the \nprobability that a subject smokes, given that the test result is \npositive.\n3. False Negative Based on the results in the table, find the \nprobability that a subject smokes, given that the test result is \nnegative.\n4. True Negative Based on the results in the table, find the \nprobability that a subject does not smoke, given that the test \nresult is negative.\n5. Sensitivity Find the sensitivity of the test by finding the \nprobability of a true positive, given that the subject actually \nsmokes.\n6. Specificity Find the specificity of the test by finding the \nprobability of a true negative, given that the subject does not \nsmoke.\n7. Positive Predictive Value Find the positive predictive \nvalue of the test by finding the probability that the subject \nsmokes, given that the test yields a positive result.\n8. Negative Predictive Value Find the negative predictive \nvalue of the test by finding the probability that the subject \ndoes not smoke, given that the test yields a negative result.\n9. Confusion of the Inverse Find the following values, \nthen compare them. In this case, what is confusion of the \ninverse?\n• P(smoker \u001f positive test result)\n• P(positive test result \u001f smoker)\n",
    "Cooperative Group Activities\n1. In-class activity Divide into groups of three or four and use coin flipping to develop a simula-\ntion that emulates the kingdom that abides by this decree: After a mother gives birth to a son, she \nwill not have any other children. If this decree is followed, does the proportion of girls increase?\n2. In-class activity Divide into groups of three or four and use actual thumbtacks or Hershey’s \nKisses candies, or paper cups, to estimate the probability that when dropped, they will land \nwith the point (or open side) up. How many trials are necessary to get a result that appears to be \nreasonably accurate when rounded to the first decimal place?\n3. Out-of-class activity Marine biologists often use the capture-recapture method as a way \nto estimate the size of a population, such as the number of fish in a lake. This method involves \ncapturing a sample from the population, tagging each member in the sample, and then return-\ning it to the population. A second sample is later captured, and the tagged members are counted \nalong with the total size of this second sample. The results can be used to estimate the size of \nthe population.\nInstead of capturing real fish, simulate the procedure using some uniform collection of \nitems such as colored beads, M&Ms, or index cards. Start with a large collection of at least \n200 of such items. Collect a sample of 50 and use a marker to “tag” each one. Replace the \ntagged items, mix the whole population, then select a second sample and proceed to estimate \nthe population size. Compare the result to the actual population size obtained by counting all \nof the items.\n4. Out-of-class activity In Cumulative Review Exercise 4, it was noted that eye colors in \nthe United States are distributed as follows: 40% brown, 35% blue, 12% green, 7% gray, 6% \nhazel. That distribution can form the basis for probabilities. Conduct a survey by asking fellow \nstudents to identify the color of their eyes. Does the probability of 0.4 for brown eyes appear to \nbe consistent with your results? Why would a large sample be required to confirm that P(hazel \neyes) = 0.06?\nCHAPTER 4 Cooperative Group Activities \n179\n",
    "180\nProbability Distributions\nBinomial Probability \nDistributions\nPoisson Probability \nDistributions\n5-1\n5-2\n5-3\nIs the XSORT Gender Selection Method Effective?\nCHAPTER \nPROBLEM\nDiscrete Probability \nDistributions\nWe live in a time with incredible advances in technology, med-\nicine, and health care. Cloning is no longer science  fiction. We \nhave iPads, iPhones, virtual-reality headsets, and self-driving \ncars. We carry calculators that can instantly execute many \ncomplex statistical calculations. Heart  pacemakers have defi-\nbrillators capable of shocking and restarting stopped hearts. \nCouples use procedures that are claimed to greatly increase \nthe chance of having a baby with a desired gender.\nSome people argue that gender selection methods should \nbe banned, regardless of the reason, while others enthusiasti-\ncally support the use of such methods. Lisa Belkin asked in the \nNew York Times Magazine, “If we allow parents to choose the \nsex of their child today, how long will it be before they order up \neye color, hair color, personality traits, and IQ?” There are some \nconvincing arguments in favor of at least limited use of gender \nselection. One such argument involves couples carrying  \n5 \n",
    "X-linked recessive genes. For some of these couples, any male \nchildren have a 50% chance of inheriting a disorder, but none \nof the female children will inherit the disorder. These couples \nmay want to use gender selection as a way to ensure that they \nhave baby girls, thereby guaranteeing that a disorder will not \nbe inherited by any of their children.\nThe Genetics & IVF Institute in Fairfax, Virginia, devel-\noped a technique called MicroSort and claimed that it in-\ncreases the chances of a couple having a baby with a desired \ngender. (Clinical trials of MicroSort have been discontinued.) \nThe  MicroSort XSORT method is claimed to increase the \nchances of a couple having a baby girl, and the MicroSort \nYSORT method is claimed to increase the chances of a \nbaby boy. The latest results for the XSORT method consist \nof 945 couples who wanted to have baby girls. After using \nthe XSORT technique, 879 of those couples had baby girls. \n(See Figure 5-1 for a bar graph illustrating these results.) \nWe usually expect that in 945 births, the number of girls \nshould be somewhere around 472 or 473. Given that 879 out \nof 945 couples had girls, can we conclude that the XSORT \ntechnique is effective, or might we explain the outcome as \njust a chance sample result? In answering that question, we \nwill use principles of probability to determine whether the \nobserved birth  results differ significantly from results that we \nwould expect from random chance. This is a common goal \nof inferential statistics: Determine whether results can be \nreasonably  explained by random chance or whether random \nchance doesn’t appear to be a feasible explanation, so that \nother  factors are influencing results. In this chapter we pres-\nent methods that allow us to find the probabilities we need \nfor  determining whether the XSORT results are significant, \n suggesting that the method is effective.\nFigure 5-2 on the next page provides a visual illustration of what this chapter accom-\nplishes. When investigating the numbers of heads in two coin tosses, we can use the \nfollowing two different approaches:\n• Use real sample data to find actual results: The approach of Chapters 2 and 3 is \nto collect sample data from actual coin tosses, then summarize the results in a table \nrepresenting the frequency distribution, and then find statistics, such as the sample \nmean x and the sample standard deviation s.\n• Use probabilities to find expected results: Using principles of probability from \nChapter 4, we can find the probability for each possible number of heads in two \ntosses. Then we could summarize the results in a table representing a probability \ndistribution.\nIn this chapter we merge the above two approaches as we create a table de-\nscribing what we expect to happen (instead of what did happen), then we find the \npopulation mean m and population standard deviation s. The table at the extreme \nright in Figure 5-2 is a probability distribution, because it describes the distribution \nusing probabilities instead of frequency counts. The remainder of this book and  \nthe core of inferential statistics are based on some knowledge of probability  \ndistributions. In this chapter we focus on discrete probability distributions.  \n \nChapter Objectives \n181\nCHAPTER OBJECTIVES\n>>>\nFIGURE 5-1 Results from the XSORT Method of \nGender Selection\n",
    "182 \nCHAPTER 5 Discrete Probability Distributions\nKey Concept This section introduces the concept of a random variable and the con-\ncept of a probability distribution. We illustrate how a probability histogram is a graph \nthat visually depicts a probability distribution. We show how to find the important \nparameters of mean, standard deviation, and variance for a probability distribution. \nMost importantly, we describe how to determine whether outcomes are significant \n(significantly low or significantly high). We begin with the related concepts of random \nvariable and probability distribution.\n5-1 \n Probability Distributions\nCount numbers of\nheads in tosses of\ntwo coins.\nCollect sample\ndata from two coin\ntosses, then ﬁnd\nstatistics and\ncreate graphs.\nNumber\nof heads\nx\n0\n1\n2\nf\n27\n56\n17\nCreate a theoretical model\nof the expected results,\nthen ﬁnd parameters.\nFind the probability for\neach possible number of\nheads in two coin tosses.\nP(0) 5 0.25\nP(1) 5 0.50\nP(2) 5 0.25\nChapters\n2 and 3\nChapter 4\nChapters 2 and 3\nChapter 5\nChapter 4\nx 5 0.9\ns 5 0.7\nNumber of\nheads in two\ncoin tosses\nx\n0\n1\n2\nP(x)\n0.25\n0.50\n0.25\nm 5 1.0\ns 5 0.7\nFIGURE 5-2\nHere are the chapter objectives:\nProbability Distributions\n• Define random variable and probability distribution.\n• Determine when a potential probability distribution actually satisfies the necessary \nrequirements.\n• Given a probability distribution, compute the mean and standard deviation, then use \nthose results to determine whether results are significantly low or significantly high.\nBinomial Probability Distributions\n• Describe a binomial probability distribution and find probability values for a binomial \ndistribution.\n• Compute the mean and standard deviation for a binomial distribution, then use \nthose results to determine whether results are significantly low or significantly high.\nPoisson Probability Distributions\n• Describe a Poisson probability distribution and find probability values for a Poisson \ndistribution.\n5-1\n5-2\n5-3\nCollect sample\ndata from two coin\ntosses, then ﬁnd\nstatistics and\ncreate graphs.\nNumber\nof heads\nx\n0\n1\n2\nf\n27\n56\n17\nCreate a theoretical model\nof the expected results,\nthen ﬁnd parameters.\nFind the probability for\neach possible number of\nheads in two coin tosses.\nP(0) 5 0.25\nP(1) 5 0.50\nP(2) 5 0.25\nChapters 2 and 3\nChapter 5\nChapter 4\nx 5 0.9\ns 5 0.7\nNumber of\nheads in two\ncoin tosses\nx\n0\n1\n2\nP(x)x)x\n0.25\n0.50\n0.25\nm 5 1.0\ns 5 0.7\nHere are the chapter objectives:\nProbability Distributions\n• Define random variable and probability distribution.\n• Determine when a potential probability distribution actually satisfies the necessary \nrequirements.\n• Given a probability distribution, compute the mean and standard deviation, then use\nthose results to determine whether results are significantly low or significantly high.\nBinomial Probability Distributions\n• Describe a binomial probability distribution and find probability values for a binomial\ndistribution.\n• Compute the mean and standard deviation for a binomial distribution, then use \nthose results to determine whether results are significantly low or \nw \nw\nsignificantly high.\nPoisson Probability Distributions\n• Describe a Poisson probability distribution and find probability values for a Poisson \ndistribution.\n",
    "5-1 Probability Distributions \n183\nPART 1\nBasic Concepts of a Probability Distribution\nDEFINITIONS\nA random variable is a variable (typically represented by x) that has a single nu-\nmerical value, determined by chance, for each outcome of a procedure.\nA probability distribution is a description that gives the probability for each value \nof the random variable. It is often expressed in the format of a table, formula, or \ngraph.\nIn Section 1-2 we made a distinction between discrete and continuous data. \n Random variables may also be discrete or continuous, and the following two defini-\ntions are consistent with those given in Section 1-2.\nDEFINITIONS\nA discrete random variable has a collection of values that is finite or countable. \n(If there are infinitely many values, the number of values is countable if it is pos-\nsible to count them individually, such as the number of tosses of a coin before \ngetting heads.)\nA continuous random variable has infinitely many values, and the collec-\ntion of values is not countable. (That is, it is impossible to count the individual \nitems because at least some of them are on a continuous scale, such as body \ntemperatures.)\nThis chapter deals exclusively with discrete random variables, but the following \nchapters deal with continuous random variables.\nProbability Distribution: Requirements\nEvery probability distribution must satisfy each of the following three requirements.\n1. There is a numerical (not categorical) random variable x, and its number values \nare associated with corresponding probabilities.\n2. ΣP(x)  =   1 where x assumes all possible values. (The sum of all probabilities \nmust be 1, but sums such as 0.999 or 1.001 are acceptable because they result \nfrom rounding errors.)\n3. 0 … P(x) … 1 for every individual value of the random variable x. (That is, \neach probability value must be between 0 and 1 inclusive.)\nThe second requirement comes from the simple fact that the random variable x \nrepresents all possible events in the entire sample space, so we are certain (with prob-\nability 1) that one of the events will occur. The third requirement comes from the basic \nprinciple that any probability value must be 0 or 1 or a value between 0 and 1.\nEXAMPLE 1  Genetics\nAlthough the Chapter Problem involves 945 births, let’s consider a simpler example \nthat involves only two births with the following random variable:\nx = number of girls in two births\nThe above x is a random variable because its numerical values depend on chance. \nWith two births, the number of girls can be 0, 1, or 2, and Table 5-1 is a probability \ncontinued\n",
    "184 \nCHAPTER 5 Discrete Probability Distributions\nNotation for 0+\nIn tables such as Table 5-1 or the binomial probabilities listed in Table A-1 in \nAppendix A, we sometimes use 0+ to represent a probability value that is positive \nbut very small, such as 0.000000123. When rounding a probability value for inclu-\nsion in such a table, rounding to 0 would be misleading because it would incor-\nrectly suggest that the event is impossible.\nProbability Histogram: Graph of a Probability Distribution\nThere are various ways to graph a probability distribution, but for now we will con-\nsider only the probability histogram. Figure 5-3 is a probability histogram corre-\nsponding to Table 5-1. Notice that it is similar to a relative frequency histogram (de-\nscribed in Section 2-2), but the vertical scale shows probabilities instead of relative \nfrequencies based on actual sample results.\ndistribution because it gives the probability for each value of the random variable x \nand it satisfies the three requirements listed earlier:\n \n1. The variable x is a numerical random variable and its values are associated \nwith probabilities, as in Table 5-1.\n \n2. ΣP(x) = 0.25 + 0.50 + 0.25 = 1\n3. Each value of P(x) is between 0 and 1. (Speciﬁcally, 0.25 and 0.50 and 0.25 \nare each between 0 and 1 inclusive.)\nThe random variable x in Table 5-1 is a discrete random variable, because it has \nthree possible values (0, 1, 2), and 3 is a finite number, so this satisfies the require-\nment of being finite or countable.\nTABLE 5-1 Probability \n Distribution for the Number of \nGirls in Two Births\nx: Number  \nof Girls\n \nP(x)\n0\n0.25\n1\n0.50\n2\n0.25\nFIGURE 5-3  Probability Histogram for Number of \nGirls in Two Births\nIn Figure 5-3, we see that the values of 0, 1, 2 along the horizontal axis are lo-\ncated at the centers of the rectangles. This implies that the rectangles are each 1 unit \nwide, so the areas of the rectangles are 0.25, 0.50, and 0.25. The areas of these rectan-\ngles are the same as the probabilities in Table 5-1. We will see in Chapter 6 and future \nchapters that such a correspondence between areas and probabilities is very useful.\nProbability Formula Example 1 involves a table, but a probability distribution \ncould also be in the form of a formula. Consider the formula P(x) =\n1\n2(2 - x)! x!\n",
    "5-1 Probability Distributions \n185\n(where x can be 0, 1, or 2). Using that formula, we find that P102 = 0.25, P112 = 0.50,\nand P122 = 0.25. The probabilities found using this formula are the same as those in \nTable 5-1. This formula does describe a probability distribution because the three re-\nquirements are satisfied, as shown in Example 1.\nTABLE 5-2 Hospital Job Interview Mistakes\nx\nP(x)\nInappropriate attire\n0.50\nBeing late\n0.44\nLack of eye contact\n0.33\nChecking phone or texting\n0.30\nTotal\n1.57\nEXAMPLE 2  Hospital Job Interview Mistakes\nHiring managers were asked to identify the biggest mistakes that job applicants \nmake during an interview, and Table 5-2 is based on their responses (based on data \nfrom an Adecco survey). Does Table 5-2 describe a probability distribution?\nSOLUTION\nTable 5-2 violates the first requirement because x is not a numerical random vari-\nable. Instead, the “values” of x are categorical data, not numbers. Table 5-2 also \nviolates the second requirement because the sum of the probabilities is 1.57, but that \nsum should be 1. Because the three requirements are not all satisfied, we conclude \nthat Table 5-2 does not describe a probability distribution.\nParameters of a Probability Distribution\nRemember that with a probability distribution, we have a description of a population \ninstead of a sample, so the values of the mean, standard deviation, and variance are \nparameters, not statistics. The mean, variance, and standard deviation of a discrete \nprobability distribution can be found with the following formulas:\nFORMULA 5-1 Mean M for a probability distribution\nm = Σ3x # P1x24 \nFORMULA 5-2 Variance S2 for a probability distribution\ns2 = Σ3 1x - m2 2 # P1x24 (This format is easier to understand.)\nFORMULA 5-3 Variance S2 for a probability distribution\ns2 = Σ3x2 # P1x24 - m2 (This format is easier for manual calculations.)\nFORMULA 5-4 Standard deviation S for a probability distribution\ns = 2Σ3x2 # P1x24 - m2 \n",
    "186 \nCHAPTER 5 Discrete Probability Distributions\nWhen applying Formulas 5-1 through 5-4, use the following rule for rounding results.\nRound-Off Rule For m, s, And s2 From A Probability Distribution\nRound results by carrying one more decimal place than the number of decimal \nplaces used for the random variable x. If the values of x are integers, round m, s, \nand s2 to one decimal place.\nExceptions to Round-Off Rule In some special cases, the above round-off rule re-\nsults in values that are misleading or inappropriate. For example, with four-engine \njets the mean number of jet engines working successfully throughout a flight is \n3.999714286, which becomes 4.0 when rounded, but that is misleading because it \nsuggests that all jet engines always work successfully. Here we need more precision to \ncorrectly  reflect the true mean, such as the precision in 3.999714.\nExpected Value\nThe mean of a discrete random variable x is the theoretical mean outcome for infinitely \nmany trials. We can think of that mean as the expected value in the sense that it is the \naverage value that we would expect to get if the trials could continue indefinitely.\nDEFINITION\nThe expected value of a discrete random variable x is denoted by E, and it is the \nmean value of the outcomes, so E = m and E can also be found by evaluating \nΣ 3x # P1x24, as in Formula 5-1.\nCAUTION An expected value need not be a whole number, even if the different \npossible values of x might all be whole numbers. The expected number of girls in \nfive births is 2.5, even though five particular births can never result in 2.5 girls. If we \nwere to survey many couples with five children, we expect that the mean number of \ngirls will be 2.5.\nEXAMPLE 3   Finding the Mean, Variance, and  \nStandard Deviation\nTable 5-1 on page 184 describes the probability distribution for the number of girls \nin two births (assuming that boys and girls are equally likely). Find the mean, vari-\nance, and standard deviation for the probability distribution described in Table 5-1 \nfrom Example 1.\nSOLUTION\nIn Table 5-3, the two columns at the left describe the probability distribution given \nearlier in Table 5-1. We create the two columns at the right for the purposes of the \ncalculations required.\nUsing Formulas 5-1 and 5-2 and the table results, we get\nMean: m = Σ3x # P1x2 4 = 1.0\nVariance: s2 = Σ3 1x - m2 2 # P1x2 4 = 0.5\n",
    "5-1 Probability Distributions \n187\nINTERPRETATION\nAssuming that boys and girls are equally likely in two births, the mean number of \ngirls is 1.0, the variance is 0.50 girls2, and the standard deviation is 0.7 girl. Also, \nthe expected value for the number of girls in two births is 1.0 girl, which is the same \nvalue as the mean. If we were to collect data on a large number of trials with two \nbirths in each trial, we expect to get a mean of 1.0 girl.\nThe standard deviation is the square root of the variance, so\nStandard deviation: s = 20.5 = 0.707107 = 0.7 1rounded2\nRounding: In Table 5-3, we use m = 1.0. If m had been the value of 1.23456, we \nmight round m to 1.2, but we should use its unrounded value of 1.23456 in \nTable 5-3 calculations. Rounding in the middle of calculations can lead to results \nwith errors that are too large.\nTABLE 5-3 Calculating m and s for a Probability Distribution\nx\nP1x2\nx # P1x2\n1x −m 22 # P1x2\n0\n0.25\n0 # 0.25 = 0.00\n10 - 12 2 # 0.25 =  0.25\n1\n0.50\n1 # 0.50 = 0.50\n11 - 12 2 # 0.50 = 0.00\n2\n0.25\n2 # 0.25 = 0.50\n12 - 12 2 # 0.25 =  0.25\nTotal\n  1.00\n   c\nm = Σ3x # P1x24\n       0.50\n       \nc\ns2 = Σ 31x - m2 2 # P1x24\nMaking Sense of Results: Significant Values\nWe present the following two different approaches for determining whether a value of \na random variable x is significantly low or high.\nIdentifying Significant Results with the Range Rule of Thumb\nThe range rule of thumb (introduced in Section 3-2) may be helpful in interpreting the \nvalue of a standard deviation. According to the range rule of thumb, the vast major-\nity of values should lie within 2 standard deviations of the mean, so we can consider \na value to be significant if it is at least 2 standard deviations away from the mean. We \ncan therefore identify “significant” values as follows:\nRange Rule of Thumb for Identifying Significant Values\nSigniﬁcantly low values are 1m - 2s2 or lower.\nSignificantly high values are 1m + 2s2 or higher.\nValues not signiﬁcant: Between 1m -  2s2 and 1m + 2s2\nFigure 3-3 from Section 3-2 illustrates the above criteria:\nValues not signiﬁcant\nSigniﬁcantly\nlow values\nSigniﬁcantly\nhigh values\nm\nm − 2s\nm + 2s\nHINT Know that the use of the number 2 in the range rule of thumb is somewhat \narbitrary, and this is a guideline, not an absolutely rigid rule.\n",
    "188 \nCHAPTER 5 Discrete Probability Distributions\nIdentifying Significant Results with Probabilities:\n \n■Significantly high number of successes: x successes among n trials is a signifi-\ncantly high number of successes if the probability of x or more successes is 0.05 or \nless. That is, x is a significantly high number of successes if P(x or more) … 0.05.*\n \n■Significantly low number of successes: x successes among n trials is a significantly \nlow number of successes if the probability of x or fewer successes is 0.05 or less. \nThat is, x is a significantly low number of successes if P(x or fewer) … 0.05.*\nEXAMPLE 4   Identifying Significant Results with the  \nRange Rule of Thumb\nIn Example 3 we found that with two births, the mean number of girls is m = 1.0 \ngirl and the standard deviation is s = 0.7 girl. Use those results and the range rule \nof thumb to determine whether 2 girls is a significantly high number of girls.\nSOLUTION\nUsing the range rule of thumb, the value of 2 girls is significantly high if it is greater \nthan or equal to m + 2s. With m = 1.0 girl and s = 0.7 girl, we get\nm + 2s = 1 + 210.72 = 2.4 girls\nSignificantly high numbers of girls are 2.4 and above.\nINTERPRETATION\nBased on these results, we conclude that 2 girls is not a significantly high number of \ngirls (because 2 is not greater than or equal to 2.4).\n*The value 0.05 is not absolutely rigid. Other values, such as 0.01, could be used to distinguish between results \nthat are signiﬁcant and those that are not signiﬁcant.\nIdentification of significantly low or significantly high numbers of successes is some-\ntimes used for the purpose of rejecting assumptions, as stated in the following rare \nevent rule.\nThe Rare Event Rule for Inferential Statistics\nIf, under a given assumption, the probability of a particular outcome is \nvery small and the outcome occurs signiﬁcantly less than or signiﬁcantly \ngreater than what we expect with that assumption, we conclude that the \nassumption is probably not correct.\nFor example, if testing the assumption that boys and girls are equally likely, the out-\ncome of 20 girls in 100 births is significantly low and would be a basis for rejecting \nthat assumption.\nEXAMPLE 5  Identifying Significant Results with Probabilities\nIs 879 girls in 945 births a signiﬁcantly high number of girls?\nWhat does the result suggest about the Chapter Problem, which includes results \nfrom the XSORT method of gender selection? (Among 945 births from parents us-\ning the XSORT method, there were 879 girls. Is 879 girls in those 945 births  \nsigniﬁcantly high?)\n",
    "5-1 Probability Distributions \n189\nNot Exactly, but “At Least as Extreme”\nIt should be obvious that among 945 births, 879 girls is significantly high, whereas \n475 girls is not significantly high. What makes 879 girls significant while 475 girls \nis not significant? It is not probabilities of exactly 879 girls and 475 girls (they are \nboth less than 0.026). It is the fact that the probability of 879 or more girls is very low \n(0.0000), but the probability of 475 or more girls is not low (0.448).\nPART 2  Expected Value and Rationale for Formulas\nExpected Value\nIn Part 1 of this section we noted that the expected value of a random variable x is equal \nto the mean m. We can therefore find the expected value by computing Σ3x # P1x2 4, \njust as we do for finding the value of m.\nSOLUTION\nA result of 879 girls in 945 births is greater than we expect with random chance, \nbut we need to determine whether 879 girls is significantly high. Here, the relevant \nprobability is the probability of getting 879 or more girls in 945 births. Using \nmethods covered later in Section 5-2, we can find that P(879 or more girls in 945 \nbirths) = 0.0000 (rounded). Because the probability of getting 879 or more girls is \nless than or equal to 0.05, we conclude that 879 girls in 945 births is a significantly \nhigh number of girls. See Figure 5-4, which is a probability histogram showing the \nprobability for the different numbers of girls.\nFIGURE 5-4 Probability Histogram of Girls in 945 Births\nEXAMPLE 6  Births\nAssuming that boys and girls are equally likely, find the expected number of girls in \n945 births. Instead of using Formula 5-1, just think about the number of girls  \nexpected in 945 births.\nSOLUTION\nThe expected number of girls in 945 births is 472.5 girls.\ncontinued\nINTERPRETATION\nIt is unlikely that we would get 879 or more girls in 945 births by chance. It follows \nthat 879 girls in 945 births is significantly high, so the XSORT method appears to \nbe effective (but this does not prove that the XSORT method is responsible for the \nlarge number of girls).\nDo Boys or Girls Run in \nthe Family?\nOne of the \nauthors of \nthis book, his \nsiblings, and \nhis siblings’ \nchildren consist \nof 11 males and \nonly 1 female. \nIs this an example of a phenom-\nenon whereby one particular \ngender runs in a family? This \nissue was studied by examin-\ning a random sample of 8770 \nhouseholds in the United States. \nThe results were reported in the \nChance magazine article “Does \nHaving Boys or Girls Run in the \nFamily?” by  Joseph Rodgers \nand Debby Doughty. Part of \ntheir analysis involves use of the \nbinomial probability distribution \ndiscussed in this section. Their \nconclusion is that “We found no \ncompelling evidence that sex \nbias runs in the family.”\n",
    "190 \nCHAPTER 5 Discrete Probability Distributions\nRationale for Formulas 5-1 Through 5-4\nInstead of blindly accepting and using formulas, it is much better to have some un-\nderstanding of why they work. When computing the mean from a frequency distribu-\ntion, f represents class frequency and N represents population size. In the expression \nbelow, we rewrite the formula for the mean of a frequency table so that it applies to a \npopulation. In the fraction f>N, the value of f is the frequency with which the value x \noccurs and N is the population size, so f>N is the probability for the value of x. When \nwe replace f>N with P(x), we make the transition from relative frequency based on \na limited number of observations to probability based on infinitely many trials. This \nresult shows why Formula 5-1 is as given earlier in this section.\nm = Σ1f # x2\nN\n= Σc f # x\nN d = Σcx # f\nN d = Σ3x # P1x2 4\nSimilar reasoning enables us to take the variance formula from Chapter 3 and \n apply it to a random variable for a probability distribution; the result is Formula 5-2. \nFormula 5-3 is a shortcut version that will always produce the same result as Formula 5-2. \nAlthough Formula 5-3 is usually easier to work with, Formula 5-2 is easier to under-\nstand directly. Based on Formula 5-2, we can express the standard deviation as\ns = 2Σ3 1x - m2 2 # P1x2 4\nor as the equivalent form given in Formula 5-4.\nINTERPRETATION\nIn any specific sample of 945 births, we can never get 472.5 girls, but 472.5 girls \nis the expected value in the sense that it would be the mean from many samples of \n945 births.\nStatistical Literacy and Critical Thinking \n1. Random Variable The accompanying table lists probabilities for the corresponding num-\nbers of girls in four births. What is the random variable, what are its possible values, and are its \nvalues numerical?\n5-1 Basic Skills and Concepts\nNumber of Girls in Four Births\nNumber of \nGirls x\n \nP(x)\n0\n0.063\n1\n0.250\n2\n0.375\n3\n0.250\n4\n0.063\n2. Discrete or Continuous? Is the random variable given in the accompanying table discrete \nor continuous? Explain.\n3. Probability Distribution For the accompanying table, is the sum of the values of P(x) \nequal to 1, as required for a probability distribution? Does the table describe a probability \ndistribution?\n4. Significant For 100 births, P(exactly 56 girls) = 0.0390 and P(56 or more girls) = 0.136. \nIs 56 girls in 100 births a significantly high number of girls? Which probability is relevant to \nanswering that question?\nIdentifying Discrete and Continuous Random Variables. In Exercises 5 and 6, refer \nto the given values, then identify which of the following is most appropriate: discrete ran-\ndom variable, continuous random variable, or not a random variable.\n5. a. Exact weights of the next 100 babies born in the United States\nb. Responses to the survey question “Which health plan do you have?”\ncontinued\n",
    "5-1 Probability Distributions \n191\nc. Numbers of families that must be surveyed before finding one with 10 children\nd. Exact foot lengths of humans\ne. Shoe sizes (such as 8 or 8½) of humans\n6. a. Grades (A, B, C, D, F) earned in biostatistics classes\nb. Heights of students in biostatistics classes\nc. Numbers of students in biostatistics classes\nd. Eye colors of biostatistics students\ne. Numbers of times biostatistics students must toss a coin before getting heads\nIdentifying Probability Distributions. In Exercises 7–14, determine whether a prob-\nability distribution is given. If a probability distribution is given, find its mean and standard \ndeviation. If a probability distribution is not given, identify the requirements that are not \nsatisfied.\n7. Genetic Disorder Five males with an X-linked genetic disorder \nhave one child each. The random variable x is the number of children \namong the five who inherit the X-linked genetic disorder.\nx\nP(x)\n0\n0.031\n1\n0.156\n2\n0.313\n3\n0.313\n4\n0.156\n5\n0.031\n8.  Male Color Blindness When conducting research on color \nblindness in males, a researcher forms random groups with five \nmales in each group. The random variable x is the number of males \nin the group who have a form of color blindness (based on data from \nthe National Institutes of Health).\nx\nP(x)\n0\n0.659\n1\n0.287\n2\n0.050\n3\n0.004\n4\n0.001\n5\n0+\n9.  Genetics Experiment A genetics experiment involves off-\nspring peas in groups of four. A researcher reports that for one \ngroup, the number of peas with white flowers has a probability dis-\ntribution as given in the accompanying table.\nx\nP(x)\n0\n0.04\n1\n0.26\n2\n0.36\n3\n0.20\n4\n0.08\n10. Mortality Study For a group of four men, the probability dis-\ntribution for the number x who live through the next year is as given \nin the accompanying table.\nx\nP(x)\n0\n0.0000\n1\n0.0001\n2\n0.0006\n3\n0.0387\n4\n0.9606\n",
    "192 \nCHAPTER 5 Discrete Probability Distributions\n11. Genetic Disorder Three males with an X-linked genetic dis-\norder have one child each. The random variable x is the number of \nchildren among the three who inherit the X-linked genetic disorder.\nx\nP(x)\n0\n0.4219\n1\n0.4219\n2\n0.1406\n3\n0.0156\n12. Diseased Seedlings An experiment involves groups of four \nseedlings grown under controlled conditions. The random variable x \nis the number of seedlings in a group that meet specific criteria for \nbeing classified as “diseased.”\nx\nP(x)\n0\n0.805\n1\n0.113\n2\n0.057\n3\n0.009\n4\n0.002\nGenetics. In Exercises 13–18, refer to the accompanying table, \nwhich describes results from groups of 8 births from 8 different \nsets of parents. The random variable x represents the number of \ngirls among 8 children.\nNumber \nof Girls x\n \nP(x)\n0\n0.004\n1\n0.031\n2\n0.109\n3\n0.219\n4\n0.273\n5\n0.219\n6\n0.109\n7\n0.031\n8\n0.004\n13. Mean and Standard Deviation Find the mean and standard \ndeviation for the numbers of girls in 8 births.\n14. Range Rule of Thumb for Significant Events Use the \nrange rule of thumb to determine whether 1 girl in 8 births is a sig-\nnificantly low number of girls.\n15. Range Rule of Thumb for Significant Events Use the \nrange rule of thumb to determine whether 6 girls in 8 births is a sig-\nnificantly high number of girls.\n16. Using Probabilities for Significant Events\na. Find the probability of getting exactly 7 girls in 8 births.\nb. Find the probability of getting 7 or more girls in 8 births.\nc. Which probability is relevant for determining whether 7 is a significantly high number of \ngirls in 10 births: the result from part (a) or part (b)?\nd. Is 7 a significantly high number of girls in 8 births? Why or why not?\n17. Using Probabilities for Significant Events \na. Find the probability of getting exactly 6 girls in 8 births.\nb. Find the probability of getting 6 or more girls in 8 births.\nc. Which probability is relevant for determining whether 6 is a significantly high number of \ngirls in 8 births: the result from part (a) or part (b)?\nd. Is 6 a significantly high number of girls in 8 births? Why or why not?\n18. Using Probabilities for Significant Events \na. Find the probability of getting exactly 1 girl in 8 births.\nb. Find the probability of getting 1 or fewer girls in 8 births.\nc. Which probability is relevant for determining whether 1 is a significantly low number of \ngirls in 8 births: the result from part (a) or part (b)?\nd. Is 1 a significantly low number of girls in 8 births? Why or why not?\n",
    "5-2 Binomial Probability Distributions \n193\nSleepwalking. In Exercises 19–23, refer to the accompanying \ntable, which describes the numbers of adults in groups of five \nwho reported sleepwalking (based on data from “Prevalence and \nComorbidity of Nocturnal Wandering In the U.S. Adult General \nPopulation,” by Ohayon et al., Neurology, Vol. 78, No. 20).\n19. Mean and Standard Deviation Find the mean and standard \ndeviation for the numbers of sleepwalkers in groups of five.\nx\nP(x)\n0\n0.172\n1\n0.363\n2\n0.306\n3\n0.129\n4\n0.027\n5\n0.002\n20. Range Rule of Thumb for Significant Events Use the \nrange rule of thumb to determine whether 4 is a significantly high \nnumber of sleepwalkers in a group of 5 adults.\n21. Range Rule of Thumb for Significant Events Use the \nrange rule of thumb to determine whether 3 is a significantly high \nnumber of sleepwalkers in a group of 5 adults.\nKey Concept Section 5-1 introduced the important concept of a discrete proba-\nbility distribution. Among the various discrete probability distributions that exist, \nthe focus of this section is the binomial probability distribution. Part 1 of this sec-\ntion introduces the binomial probability distribution along with methods for find-\ning probabilities. Part 2 presents easy methods for finding the mean and standard \ndeviation of a binomial distribution. As in other sections, we stress the importance \nof interpreting probability values to determine whether events are significantly low \nor significantly high.\nPART 1\n Basics of Binomial Probability Distribution\nBinomial probability distributions allow us to deal with circumstances in which the \noutcomes belong to two categories, such as cured>not cured or acceptable>defective \nor survived>died.\n5-2 \nBinomial Probability Distributions\n22. Using Probabilities for Identifying Significant Events\na. Find the probability of getting exactly 4 sleepwalkers among 5 adults.\nb. Find the probability of getting 4 or more sleepwalkers among 5 adults.\nc. Which probability is relevant for determining whether 4 is a significantly high number of \nsleepwalkers among 5 adults: the result from part (a) or part (b)?\nd. Is 4 a significantly high number of sleepwalkers among 5 adults? Why or why not?\n23. Using Probabilities for Identifying Significant Events\na. Find the probability of getting exactly 1 sleepwalker among 5 adults.\nb. Find the probability of getting 1 or fewer sleepwalkers among 5 adults.\nc. Which probability is relevant for determining whether 1 is a significantly low number of \nsleepwalkers among 5 adults: the result from part (a) or part (b)?\nd. Is 1 a significantly low number of sleepwalkers among 5 adults? Why or why not?\n",
    "194 \nCHAPTER 5 Discrete Probability Distributions\nNotation For Binomial Probability Distributions\nS and F (success and failure) denote the two possible categories of all outcomes.\nP1S2 = p \n1p = probability of a success2\nP1F2 = 1 - p = q \n1q = probability of a failure2\nn\nthe fixed number of trials\nx \na specific number of successes in n trials, so x can be any \nwhole number between 0 and n, inclusive\np\nprobability of success in one of the n trials\nq\nprobability of failure in one of the n trials\nP(x) \nprobability of getting exactly x successes among the n trials\nThe word success as used here is arbitrary and does not necessarily represent \nsomething good. Either of the two possible categories may be called the success S \nas long as its probability is identified as p. (The value of q can always be found from \nq = 1 - p. If p = 0.95, then q = 1 - 0.95 = 0.05.)\nDEFINITION\nA binomial probability distribution results from a procedure that meets these four \nrequirements:\n 1.  The procedure has a ﬁxed number of  trials. (A trial is a single observation.)\n 2.  The trials must be independent, meaning that the outcome of any individual trial \ndoesn’t aﬀect the probabilities in the other trials.\n 3.  Each trial must have all outcomes classiﬁed into exactly two categories, com-\nmonly referred to as success and failure.\n 4.  The probability of a success remains the same in all trials.\nCAUTION When using a binomial probability distribution, always be sure that x \nand p are consistent in the sense that they both refer to the same category being \ncalled a success.\nEXAMPLE 1  Hybridization Experiments\nWhen Gregor Mendel conducted his famous hybridization experiments, he used \npeas with green pods and peas with yellow pods. Because green is dominant and \nyellow is recessive, when crossing two parents with the green>yellow pair of genes, \nwe expect that 3>4 of the offspring peas should have green pods. That is, P(green \npod) = 3>4. Assume that all parents have the green>yellow combination of genes, \nand we want to find the probability that exactly three of five offspring peas have \ngreen pods.\n \na. Does this procedure result in a binomial distribution?\n \nb. If this procedure does result in a binomial distribution, identify the values of \nn, x, p, and q.\n",
    "5-2 Binomial Probability Distributions \n195\nTreating Dependent Events as Independent\nWhen selecting a sample (as in a survey), we usually sample without replacement. \nSampling without replacement results in dependent events, which violates a require-\nment of a binomial distribution. However, we can often treat the events as if they were \nindependent by applying the following 5% guideline introduced in Section 4-2:\n5% Guideline for Cumbersome Calculations\nWhen sampling without replacement and the sample size is no more than \n5% of the size of the population, treat the selections as being independent \n(even though they are actually dependent).\nMethods for Finding Binomial Probabilities\nWe now proceed with three methods for finding the probabilities corresponding to the \nrandom variable x in a binomial distribution. The first method involves calculations \nusing the binomial probability formula and is the basis for the other two methods. \nThe second method involves the use of software or a calculator, and the third method \ninvolves the use of the Appendix Table A-1. (With technology so widespread, such \ntables are becoming obsolete.) If using technology that automatically produces bino-\nmial probabilities, we recommend that you solve one or two exercises using Method 1 \nto better understand the basis for the calculations.\nSOLUTION\na. This procedure does satisfy the requirements for a binomial distribution, as \nshown below.\n \n 1. The number of trials (5) is ﬁxed.\n \n 2. The 5 trials are independent because the probability of any oﬀspring \npea having a green pod is not aﬀected by the outcome of any other \n oﬀspring pea.\n \n 3. Each of the 5 trials has two categories of outcomes: The pea has a green \npod or it does not.\n \n 4. For each oﬀspring pea, the probability that it has a green pod is 3>4 or \n0.75, and that probability remains the same for each of the 5 peas.\n \nb. Having concluded that the given procedure does result in a binomial distribu-\ntion, we now proceed to identify the values of n, x, p, and q.\n \n 1. With 5 oﬀspring peas, we have n = 5.\n2. We want the probability of exactly 3 peas with green pods, so x = 3.\n3. The probability of success (getting a pea with a green pod) for one selec-\ntion is 0.75, so p = 0.75.\n4. The probability of failure (not getting a green pod) is 0.25, so q = 0.25.\nAgain, it is very important to be sure that x and p both refer to the same concept of \n“success.” In this example, we use x to count the number of peas with green pods, \nso p must be the probability that a pea has a green pod. Therefore, x and p do use \nthe same concept of success (green pod) here.\nNot at Home\nPollsters cannot \nsimply ignore \nthose who were \nnot at home \nwhen they \nwere called \nthe first time. \nOne solution \nis to make repeated callback \nattempts until the person can \nbe reached.  Alfred Politz and \nWillard Simmons describe a way \nto compensate for those missed \ncalls without making repeated \ncallbacks. They suggest weight-\ning results based on how often \npeople are not at home. For \nexample, a person at home only \ntwo days out of six will have a  \n2>6 or 1>3 probability of being at \nhome when called the first time. \nWhen such a person is reached \nthe first time, his or her results \nare weighted to count three \ntimes as much as someone who \nis always home. This weighting \nis a compensation for the other \nsimilar people who are home two \ndays out of six and were not at \nhome when called the first time. \nThis clever solution was first \npresented in 1949.\n",
    "196 \nCHAPTER 5 Discrete Probability Distributions\nFORMULA 5-5  Binomial Probability Formula\nP1x2 =\nn!\n1n - x2!x! # px # qn-x  for x = 0, 1, 2, c, n\nwhere\n n = number of trials\n x = number of successes among n trials\n p = probability of success in any one trial\n q = probability of failure in any one trial 1q = 1 - p2\nFormula 5-5 can also be expressed as P1x2 = nCx # px # qn-x. With x items identi-\ncal to themselves, and n - x other items identical to themselves, the number of \npermutations is nCx = n!3 1n - x2!x!4, so the two sides of this equation are inter-\nchangeable. The factorial symbol !, introduced in Section 4-6, denotes the product \nof decreasing factors. Two examples of factorials are 3! = 3 # 2 # 1 = 6 and 0! = 1 \n(by definition).\nEXAMPLE 2  Hybridization Experiment \nAssuming that the probability of a pea having a green pod is 0.75 (as in Example 1), \nuse the binomial probability formula to find the probability of getting exactly 3 peas \nwith green pods when 5 offspring peas are generated. That is, find P(3) given that \nn = 5, x = 3, p = 0.75, and q = 0.25.\nSOLUTION\nUsing the given values of n, x, p, and q in the binomial probability formula \n (Formula 5-5), we get\n P132 =\n5!\n15 - 32!3! # 0.753 # 0.255-3\n =\n5!\n2!3! # 0.421875 # 0.0625\n = 110210.421875210.06252 = 0.263671875\nThe probability of getting exactly 3 peas with green pods among 5 offspring peas is \n0.264 (rounded to three significant digits).\nCalculation hint: When computing a probability with the binomial probability for-\nmula, it’s helpful to get a single number for n!> 3 1n - x2!x!4 or nCx, a single num-\nber for px, and a single number for qn-x, and then simply multiply the three factors \ntogether as shown in the third line of the calculation in the preceding example. Don’t \nround when you find those three factors; round only at the end, and round to three \nsignificant digits.\nMethod 1: Using the Binomial Probability Formula In a binomial probability \ndistribution, probabilities can be calculated by using Formula 5-5.\n",
    "5-2 Binomial Probability Distributions \n197\nMethod 2: Using Technology Technology can be used to find binomial probabili-\nties. The screen displays listing binomial probabilities for n = 5 and p = 0.75, as in \nExample 2, are given. Notice that in each display, the probability distribution is given \nas a table.\nStatdisk\nMinitab\nExcel\nTI-83>84 Plus\nMethod 3: Using Table A-1 in Appendix A This method can be skipped if tech-\nnology is available. Table A-1 in Appendix A lists binomial probabilities for select \nvalues of n and p. It cannot be used if n > 8 or if the probability p is not one of the 13 \nvalues included in the table.\nTo use the table of binomial probabilities, we must first locate n and the desired \ncorresponding value of x. At this stage, one row of numbers should be isolated. Now \nalign that row with the desired probability of p by using the column across the top. \nThe isolated number represents the desired probability. A very small probability, such \nas 0.000064, is indicated by 0+.\nEXAMPLE 3  Births \nAssuming that boys and girls are equally likely, find the probability of getting ex-\nactly 5 boys in 8 randomly selected births.\ncontinued\n",
    "198 \nCHAPTER 5 Discrete Probability Distributions\nPART 2\nUsing Mean and Standard Deviation for \nCritical Thinking \nSection 5-1 included formulas for finding the mean, variance, and standard deviation \nfrom any discrete probability distribution. A binomial distribution is a particular type \nof discrete probability distribution, so we could use those same formulas, but if we \nknow the values of n and p, it is much easier to use the following:\nSOLUTION\nBecause boys and girls are assumed to be equally likely, we have p = 0.5. Because \nthere are 8 births we have n = 8. Because we want the probability of exactly 5 \nboys, we have x = 5.\nRefer to Table A-1with n = 8, x = 0.5, and p = 0.5. Locate n = 8 at the left, \nthen find the row of probabilities for x = 5. Next, look across the top row to find \nthe column of values under p = 0.50. Table A-1 shows that P(5 boys) = 0.219.\nFor Binomial Distributions\nFormula 5-6 Mean: \nm = np\nFormula 5-7 Variance: \ns2 = npq\nFormula 5-8 Standard Deviation:    s = 1npq\nAs in earlier sections, finding values for m and s can be great fun, but it is especially \nimportant to interpret and understand those values, so the range rule of thumb and the \nrare event rule for inferential statistics can be very helpful. Here is a brief summary \nof the range rule of thumb: Values are significantly low or high if they differ from the \nmean by more than 2 standard deviations, as described by the following:\nRange Rule of Thumb\nSigniﬁcantly low values … 1m - 2s2\nSigniﬁcantly high values Ú 1m + 2s2\nValues not signiﬁcant: Between 1m - 2s2 and 1m + 2s2\nEXAMPLE 4  Hybridization Experiment\nUse Formulas 5-6 and 5-8 to find the mean and standard deviation for the numbers \nof peas with green pods when groups of 5 offspring peas are generated. Assume that \nthere is a 0.75 probability that an offspring pea has a green pod.\nSOLUTION\nUsing the values n = 5, p = 0.75, and q = 0.25, Formulas 5-6 and 5-8 can be \n applied as follows:\n        m = np = 15210.752 = 3.8\ns = 1npq = 215210.75210.252 = 1.0 1rounded2\n",
    "5-2 Binomial Probability Distributions \n199\nFormula 5-6 for the mean makes sense intuitively. If 75% of peas have green pods \nand five offspring peas are generated, we expect to get around 5 # 0.75 = 3.8 peas \nwith green pods. This result can be generalized as m = np. The variance and standard \ndeviation are not so easily justified, and we omit the complicated algebraic manipula-\ntions that lead to Formulas 5-7 and 5-8. Instead, refer again to the preceding example \nand Table 5-3 on page 187 to verify that for a binomial distribution, Formulas 5-6, 5-7, \nand 5-8 will produce the same results as Formulas 5-1, 5-3, and 5-4.\nEXAMPLE 5  Genetics\nIn an actual experiment, Mendel generated 580 offspring peas. He claimed that \n75%, or 435, of them would have green pods. The actual experiment resulted in \n428 peas with green pods.\na. Assuming that groups of 580 oﬀspring peas are generated, ﬁnd the mean and \nstandard deviation for the numbers of peas with green pods.\n \nb. Use the range rule of thumb to ﬁnd the numbers of peas with green pods that \nseparate signiﬁcantly low values and signiﬁcantly high values from values that \nare not signiﬁcant. Based on those numbers, can we conclude that Mendel’s \nactual result of 428 peas with green pods is signiﬁcantly low or signiﬁcantly \nhigh? Does this suggest that Mendel’s value of 75% is wrong?\nSOLUTION\na. With n = 580 oﬀspring peas, with p = 0.75, and q = 0.25, we can ﬁnd \nthe mean and standard deviation for the numbers of peas with green pods as \n follows:\n         m = np = 1580210.752 = 435.0\ns = 1npq = 21580210.75210.252 = 10.4\nFor groups of 580 oﬀspring peas, the mean number of peas with green pods is \n435.0 and the standard deviation is 10.4.\nb. We must now interpret the results to determine whether Mendel’s actual result \nof 428 peas is a result that could easily occur by chance, or whether that result \nis so unlikely that the assumed rate of 75% is wrong. We will use the range \nrule of thumb as follows:\nSignificantly low values … 1m - 2s2 = 435.0 - 2110.42 = 414.2\nSignificantly high values Ú 1m + 2s2 = 435.0 + 2110.42 = 455.8\nINTERPRETATION\nBased on these results, significantly low values are 414.2 or lower, and significantly \nhigh values are 455.8 or higher. That is, if Mendel generated many groups of 580 \noffspring peas and if his 75% rate is correct, the numbers of peas with green pods \nshould usually fall between 414.2 and 455.8. Mendel actually got 428 peas with \ngreen pods, and that value is neither significantly low nor significantly high, so the \nexperimental results are consistent with the 75% rate. The results do not suggest \nthat Mendel’s claimed rate of 75% is wrong.\n",
    "200 \nCHAPTER 5 Discrete Probability Distributions\nVariation in Statistics Example 5 is a good illustration of the importance of variation \nin statistics. In a traditional algebra course, we might conclude that 428 is not 75% \nof 580 simply because 428 does not equal 435 (which is 75% of 580). However, in \nstatistics we recognize that sample results vary. We don’t expect to get exactly 75% of \nthe peas with green pods. We recognize that as long as the results don’t vary too far \naway from the claimed rate of 75%, they are consistent with that claimed rate of 75%.\nIn this section we presented easy procedures for finding values of the mean m and \nstandard deviation s from a binomial probability distribution. However, it is really \nimportant to be able to interpret those values by using such tools as the range rule of \nthumb for distinguishing values that are significantly low or significantly high from \nvalues that are not significant.\nInstead of the range rule of thumb, we could also use probabilities to determine \nwhen values are significantly high or significantly low.\nUsing Probabilities to Determine When Results Are Significantly High or Low\n \n■Significantly high number of successes: x successes among n trials is a \n significantly high number of successes if the probability of x or more successes \nis 0.05 or less. That is, x is a significantly high number of successes if  \nP(x or more) … 0.05.*\n \n■Significantly low number of successes: x successes among n trials is a \n significantly low number of successes if the probability of x or fewer successes  \nis 0.05 or less. That is, x is a significantly low number of successes if  \nP(x or fewer) … 0.05.*\n*The value 0.05 is not absolutely rigid. Other values, such as 0.01, could be used to distinguish between results \nthat are signiﬁcant and those that are not signiﬁcant.\nRationale for the Binomial Probability Formula\nThe binomial probability formula is the basis for all three methods presented in this \nsection. Instead of accepting and using that formula blindly, let’s see why it works.\nIn Example 2, we used the binomial probability formula to find the probability \nof getting exactly 3 peas with green pods when 5 offspring peas are generated. With \nP(green pod) = 0.75, we can use the multiplication rule from Section 4-2 to find the \nprobability that the first 3 peas have green pods while the last 2 peas do not have green \npods. We get the following result:\nP13 peas with green pods followed by 2 peas with pods that are not green2\n = 0.75 # 0.75 # 0.75 # 0.25 # 0.25\n = 0.753 # 0.252\n = 0.0264\nThis result gives a probability of generating five offspring in which three have green pods. \nHowever, it does not give the probability of getting exactly three peas with green pods be-\ncause it assumes a particular arrangement for three offspring peas with green pods. Other \narrangements for generating three offspring peas with green pods are possible.\nIn Section 4-6 we saw that with three subjects identical to each other (such as peas \nwith green pods) and two other subjects identical to each other (such as peas without \ngreen pods), the total number of arrangements, or permutations, is 5!> 3 15 - 32!3!4, \nor 10. Each of those 10 different arrangements has a probability of 0.753 # 0.252, so the \ntotal probability is as follows:\nP13 peas with green pods among 52 =\n5!\n15 - 32!3! # 0.753 # 0.252\n",
    "5-2 Binomial Probability Distributions \n201\nThis particular result can be generalized as the binomial probability formula \n(Formula 5-5). That is, the binomial probability formula is a combination of the \nmultiplication rule of probability and the counting rule for the number of arrange-\nments of n items when x of them are identical to each other and the other n - x are \nidentical to each other.\nP (x) =\nn!\n(n - x)!x! # px # qn-x\nThe number of outcomes with  \nexactly x successes among n trials\nThe probability of x successes among  \nn trials for any one particular order\n2   2\nBinomial Distributions\nAccess tech instructions, videos, and data sets at www.TriolaStats.com\nTECH CENTER \nStatistical Literacy and Critical Thinking \n1.  Hybridization Assume that 75% of offspring peas have green pods. Suppose we want \nto find the probability that when five offspring peas are randomly selected, exactly two \nof them are green. What is wrong with using the multiplication rule to find the prob-\nability of getting two peas with green pods followed by three peas with yellow pods: \n(0.75)(0.75)(0.25)(0.25)(0.25) = 0.00879?\n2. Variation and Notation Assume that we want to find the probability that among five off-\nspring peas, exactly two of them have green pods. Also assume that 75% of offspring peas have \ngreen pods (and the others have yellow pods).\na. Identify the values of n, x, p, and q.\nb. For groups of 5 randomly selected offspring peas, find the mean, standard deviation, and \nvariance for the numbers of peas among five that have green pods. Include appropriate units.\n3.  Independent Events Based on a KRC Research survey, when 1020 adults were asked \nabout hand hygiene, 44% said that they wash their hands after using public transportation. Con-\nsider the probability that among 30 different adults randomly selected from the 1020 who were \nsurveyed, there are at least 10 who wash their hands after using public transportation. Given \nthat these subjects were selected without replacement, are the 30 selections independent? Can \nthey be treated as being independent? Can the probability be found using the binomial prob-\nability formula?\n4.  Notation of 0+ Using the same survey from Exercise 3, the probability of randomly \n selecting 30 of the 1020 adults and getting exactly 24 who wash hands after using public trans-\nportation is represented as 0+. What does 0+ indicate? Does 0+ indicate that it is impossible to \nget exactly 24 adults who wash their hands after using public transportation?\n5-2 Basic Skills and Concepts\n",
    "202 \nCHAPTER 5 Discrete Probability Distributions\nIdentifying Binomial Distributions. In Exercises 5–12, determine whether the given \nprocedure results in a binomial distribution (or a distribution that can be treated as bino-\nmial). For those that are not binomial, identify at least one requirement that is not satisfied.\n5.  Clinical Trial of YSORT The YSORT method of gender selection, developed by the \n Genetics & IVF Institute, was designed to increase the likelihood that a baby will be a boy. \nWhen 291 couples used the YSORT method and gave birth to 291 babies, the weights of the \nbabies were recorded.\n6.  Clinical Trial of YSORT The YSORT method of gender selection, developed by the \n Genetics & IVF Institute, was designed to increase the likelihood that a baby will be a boy. \nWhen 291 couples use the YSORT method and give birth to 291 babies, the genders of the \nbabies are recorded.\n7. Clinical Trial of Lipitor Treating 863 subjects with Lipitor (atorvastatin) and recording \nwhether there is a “yes” response when they are each asked if they experienced a headache \n(based on data from Pfizer, Inc.).\n8. Clinical Trial of Lipitor Treating 863 subjects with Lipitor (atorvastatin) and asking each \nsubject how their head feels (based on data from Pfizer, Inc.).\n9.  Nicorette Treating 50 smokers with Nicorette and asking them how their mouth and \nthroat feel.\n10. Nicorette Treating 50 smokers with Nicorette and recording whether there is a “yes” re-\nsponse when they are asked if they experience any mouth or throat soreness.\n11. Defibrillators Determining whether each of 500 defibrillators is acceptable or defective.\n12. Defibrillators Counting the numbers of defects in each of 500 defibrillators.\nBinomial Probability Formula. In Exercises 13 and 14, answer the questions designed to \nhelp understand the rationale for the binomial probability formula.\n13. Guessing Answers Standard tests, such as the SAT, ACT, or Medical College Admis-\nsion Test (MCAT) typically use multiple choice questions, each with five possible answers \n(a, b, c, d, e), one of which is correct. Assume that you guess the answers to the first three ques-\ntions.\na. Use the multiplication rule to find the probability that the first two guesses are wrong and \nthe third is correct. That is, find P(WWC), where W denotes a wrong answer and C denotes a \ncorrect answer.\nb. Beginning with WWC, make a complete list of the different possible arrangements of two \nwrong answers and one correct answer; then find the probability for each entry in the list.\nc. Based on the preceding results, what is the probability of getting exactly one correct answer \nwhen three guesses are made?\n14. Vision Correction 53% of adults use eyeglasses for vision correction (based on data \nfrom a Vision Council survey). Four adults are randomly selected.\na. Use the multiplication rule to find the probability that the first three use eyeglasses and the \nfourth does not use eyeglasses. That is, find P(EEEN), where E denotes an adult who uses eye-\nglasses and N denotes an adult who does not use eyeglasses.\nb. Beginning with EEEN, make a complete list of the different possible arrangements of three \nadults who use eyeglasses and one who does not use eyeglasses; then find the probability for \neach entry in the list.\nc. Based on the preceding results, what is the probability of getting exactly three adults who \nuse eyeglasses and one who does not?\n",
    "5-2 Binomial Probability Distributions \n203\nMCAT Test. In Exercises 15–20, assume that random guesses are made for eight multiple \nchoice questions on an MCAT test, so that there are n = 8 trials, each with probability \nof success (correct) given by p = 0.20. Find the indicated probability for the number of \n correct answers.\n15. Find the probability that the number x of correct answers is exactly 7.\n16. Find the probability that the number x of correct answers is at least 4.\n17. Find the probability that the number x of correct answers is fewer than 3.\n18. Find the probability that the number x of correct answers is no more than 2.\n19. Find the probability of no correct answers.\n20. Find the probability that at least one answer is correct.\nIn Exercises 21–24, assume that when adults are randomly selected, 21% do not require \n vision correction (based on data from a Vision Council survey).\n21. If 8 adults are randomly selected, find the probability that exactly 2 of them do not require \nvision correction.\n22. If 20 adults are randomly selected, find the probability that exactly 5 of them do not require \nvision correction.\n23. If 10 adults are randomly selected, find the probability that at least 3 of them do not require \nvision correction.\n24. If 12 adults are randomly selected, find the probability that fewer than 3 of them do not \nrequire vision correction.\nSignificance with Range Rule of Thumb. In Exercises 25 and 26, assume that different \ngroups of couples use the XSORT method of gender selection and each couple gives birth \nto one baby. The XSORT method is designed to increase the likelihood that a baby will be a \ngirl, but assume that the method has no effect, so the probability of a girl is 0.5.\n25. Gender Selection Assume that the groups consist of 36 couples.\na. Find the mean and standard deviation for the numbers of girls in groups of 36 births.\nb. Use the range rule of thumb to find the values separating results that are significantly low or \nsignificantly high.\nc. Is the result of 26 girls a result that is significantly high? What does it suggest about the ef-\nfectiveness of the XSORT method?\n26. Gender Selection Assume that the groups consist of 16 couples.\na. Find the mean and standard deviation for the numbers of girls in groups of 16 births.\nb. Use the range rule of thumb to find the values separating results that are significantly low or \nsignificantly high.\nc. Is the result of 11 girls a result that is significantly high? What does it suggest about the ef-\nfectiveness of the XSORT method?\nSignificance with Range Rule of Thumb. In Exercises 27 and 28, assume that hybrid-\nization experiments are conducted with peas having the property that for offspring, there is \na 0.75 probability that a pea has green pods (as in one of Mendel’s famous experiments).\n27. Hybrids Assume that offspring peas are randomly selected in groups of 10.\na. Find the mean and standard deviation for the numbers of peas with green pods in the groups \nof 10.\ncontinued\n",
    "204 \nCHAPTER 5 Discrete Probability Distributions\nb. Use the range rule of thumb to find the values separating results that are significantly low or \nsignificantly high.\nc. Is the result of 9 peas with green pods a result that is significantly high? Why or why not?\n28. Hybrids Assume that offspring peas are randomly selected in groups of 16.\na. Find the mean and standard deviation for the numbers of peas with green pods in the groups \nof 16.\nb. Use the range rule of thumb to find the values separating results that are significantly low or \nsignificantly high.\nc. Is a result of 7 peas with green pods a result that is significantly low? Why or why not?\nComposite Sampling. Exercises 29 and 30 involve the method of composite sampling, \nwhereby a medical testing laboratory saves time and money by combining blood samples for \ntests so that only one test is conducted for several people. A combined sample tests positive \nif at least one person has the disease. If a combined sample tests positive, then individual \nblood tests are used to identify the individual with the disease.\n29. HIV It is estimated that worldwide, 1% of those aged 15–49 are infected with the human \nimmunodeficiency virus (HIV) (based on data from the National Institutes of Health). In tests \nfor HIV, blood samples from 36 people are combined. What is the probability that the com-\nbined sample tests positive for HIV? Is it unlikely for such a combined sample to test positive?\n30. Blood Donor Testing The American Red Cross tests every unit of donated blood for \nseveral infectious diseases, including hepatitis B, hepatitis C, HIV, syphilis, and West Nile virus \ninfection. Blood samples from 16 donors are combined and tested, and all 16 individual samples \nare approved only if the combined sample passes all tests. If there is 1.4% chance that a random \nindividual fails any of the tests, find the probability that the combined sample is not approved.\nAcceptance Sampling. Exercises 31 and 32 involve the method of acceptance sampling, \nwhereby a shipment of a large number of items is accepted based on test results from a \nsample of the items.\n31. Aspirin The MedAssist Pharmaceutical Company receives large shipments of aspirin tab-\nlets and uses this acceptance sampling plan: Randomly select and test 40 tablets, and then ac-\ncept the whole batch if there is only one or none that doesn’t meet the required specifications. \nIf one shipment of 5000 aspirin tablets actually has a 3% rate of defects, what is the probability \nthat this whole shipment will be accepted? Will almost all such shipments be accepted, or will \nmany be rejected?\n32. AAA Batteries AAA batteries are made by companies including Duracell, Energizer, \nEveready, and Panasonic, and they are used to power Prestige Medical Xenon pocket otoscopes \n(those things that physicians use to look in your ears). When purchasing bulk orders of AAA \nbatteries, a manufacturer of otoscopes uses this acceptance sampling plan: Randomly select 50 \nbatteries and determine whether each is within specifications. The entire shipment is accepted \nif at most 2 batteries do not meet specifications. A shipment contains 2000 AAA batteries, and \n2% of them do not meet specifications. What is the probability that this whole shipment will be \naccepted? Will almost all such shipments be accepted, or will many be rejected?\nUltimate Binomial Exercises! Exercises 33−36 involve finding binomial probabilities, \nfinding parameters, and determining whether values are significantly high or low by using \nthe range rule of thumb and probabilities.\n33. Gender Selection At an early stage of clinical trials of the XSORT method of gender \nselection, 14 couples using that method gave birth to 13 girls and 1 boy.\na. Assuming that the XSORT method has no effect and boys and girls are equally likely, use \nthe range rule of thumb to identify the limits separating values that are significantly low and \n",
    "5-2 Binomial Probability Distributions \n205\nthose that are significantly high (for the number of girls in 14 births). Based on the results, is \nthe result of 13 girls significantly high?\nb. Find the probability of exactly 13 girls in 14 births, assuming that the XSORT method has \nno effect.\nc. Find the probability of 13 or more girls in 14 births, assuming that the XSORT method has \nno effect.\nd. Which probability is relevant for determining whether 13 girls is significantly high: the \nprobability from part (b) or part (c)? Based on the relevant probability, is the result of 13 girls \nsignificantly high?\ne. What do the results suggest about the effectiveness of the XSORT method?\n34. Clinical Trial A treatment for hypertension has been found to be successful in 60% of the \npatient population. In a test of a new treatment, 40 subjects are treated for hypertension and 29 \nof these subjects experience success with the new treatment.\na. Assuming that the old success rate of 60% still applies, use the range rule of thumb to iden-\ntify the limits separating numbers of successes that are significantly low or significantly high. \nBased on the results, is 29 successes among the 40 subjects significantly high?\nb. Find the probability that exactly 29 of the 40 cases are successes, assuming that the general \nsuccess rate is 60%.\nc. Find the probability that 29 or more of the cases are successes, assuming that the general \nsuccess rate is 60%.\nd. Which probability is relevant for determining whether 29 successes is significantly high: the \nprobability from part (b) or part (c)? Based on the relevant probability, is the result of 29 suc-\ncesses significantly high?\ne. What do the results suggest about the effectiveness of the new treatment?\n35. Hybrids One of Mendel’s famous experiments with peas included 47 offspring, and 34 of \nthem had long stems. Mendel claimed that under the same conditions, 75% of offspring peas \nwould have long stems. Assume that Mendel’s claim of 75% is true, and assume that a sample \nconsists of 47 offspring peas.\na. Use the range rule of thumb to identify the limits separating values that are significantly low \nand those that are significantly high. Based on the results, is the result of 34 peas with long \nstems either significantly low or significantly high?\nb. Find the probability of exactly 34 peas with long stems.\nc. Find the probability of 34 or fewer peas with long stems.\nd. Which probability is relevant for determining whether 34 peas with long stems is signifi-\ncantly low: the probability from part (b) or part (c)? Based on the relevant probability, is the \nresult of 34 peas with long stems significantly low?\ne. What do the results suggest about Mendel’s claim of 75%?\n36. Vaccine For a specific group of subjects, there is a 5% chance of influenza (“flu”). When \n80 subjects were treated with a vaccine, only one of them presented with influenza.\na. Use the range rule of thumb to identify the limits separating values that are significantly low \nand those that are significantly high. Based on the results, is the result of one subject getting \ninfluenza either significantly low or significantly high?\nb. Find the probability of exactly one subject experiencing influenza, assuming that the vaccine \nhas no effect.\nc. Find the probability of one or fewer subjects experiencing influenza, assuming that the \n vaccine has no effect.\ncontinued\n",
    "206 \nCHAPTER 5 Discrete Probability Distributions\nd. Which probability is relevant for determining whether one subject experiencing influenza is \nsignificantly low: the probability from part (b) or part (c)? Based on the relevant probability, is \nthe result of one subject experiencing influenza significantly low?\ne. What do the results suggest about the effectiveness of the vaccine?\n37. Geometric Distribution If a procedure meets all the conditions of a binomial distribution \nexcept that the number of trials is not fixed, then the geometric distribution can be used. The \nprobability of getting the first success on the xth trial is given by P1x2 = p11 - p2 x-1, where \np is the probability of success on any one trial. Subjects are randomly selected for the National \nHealth and Nutrition Examination Survey conducted by the National Center for Health Statis-\ntics, Centers for Disease Control and Prevention. The probability that someone is a universal \ndonor (with group O and type Rh negative blood) is 0.06. Find the probability that the first \nsubject to be a universal blood donor is the fifth person selected.\n38. Multinomial Distribution The binomial distribution applies only to cases involving two \ntypes of outcomes, whereas the multinomial distribution involves more than two categories. \nSuppose we have three types of mutually exclusive outcomes denoted by A, B, and C. Let \nP1A2 = p1, P1B2 = p2, and P1C2 = p3. In n independent trials, the probability of x1 out-\ncomes of type A, x2 outcomes of type B, and x3 outcomes of type C is given by\nn!\n1x12!1x22!1x32! # px11 # px22 # px33\nData Set 8 “IQ and Lead” in Appendix B includes 78 subjects from a low lead exposure group, \n22 subjects from a medium lead exposure group, and 21 subjects from a high lead exposure \ngroup. Find the probability of randomly selecting 10 subjects for a follow-up study and getting \n5 from the low lead group, 2 from the medium lead group, and 3 from the high lead group. \nAssume that the selections are made with replacement. Can we use the above expression for \nfinding the probability if the sampling is done without replacement?\n39. Hypergeometric Distribution If we sample from a small finite population without re-\nplacement, the binomial distribution should not be used because the events are not indepen-\ndent. If sampling is done without replacement and the outcomes belong to one of two types, \nwe can use the hypergeometric distribution. If a population has A objects of one type, while \nthe remaining B objects are of the other type, and if n objects are sampled without replacement, \nthen the probability of getting x objects of type A and n - x objects of type B is\nP1x2 =\nA!\n1A - x2!x! #\nB!\n1B - n + x2!1n - x2! ,\n1A + B2!\n1A + B - n2!n!\nIn a medical research project, there are 20 subjects available and 4 of them are infected with \nHIV, while the other 16 are not infected. If 8 of the subjects are randomly selected without re-\nplacement, what is the probability that 3 of the subjects are infected with HIV, while the other 5 \nare not infected? What is the probability if the sampling is done with replacement?\n5-2 Beyond the Basics\nKey Concept In Section 5-1 we introduced general discrete probability distributions \nand in Section 5-2 we considered binomial probability distributions, which is one \nparticular category of discrete probability distributions. In this section we introduce \nPoisson probability distributions, which are another category of discrete probability \ndistributions.\n5-3 \nPoisson Probability Distributions\n",
    "5-3 Poisson Probability Distributions \n207\nThe following definition states that Poisson distributions are used with occur-\nrences of an event over a specified interval, and here are some applications:\n \n■Number of Internet users logging onto WebMD in one day\n \n■Number of patients arriving at an emergency room in one hour\n \n■Number of Atlantic hurricanes in one year\nDEFINITION\nA Poisson probability distribution is a discrete probability distribution that ap-\nplies to occurrences of some event over a specified interval. The random variable \nx is the number of occurrences of the event in an interval. The interval can be time, \ndistance, area, volume, or some similar unit. The probability of the event occurring \nx times over an interval is given by Formula 5-9.\nFORMULA 5-9  Poisson Probability Distribution\nP1x2 = mx # e-m\nx!\nwhere\ne ≈2.71828\nm = mean number of occurrences of the event in the intervals\nRequirements for the Poisson Probability Distribution\n1.  The random variable x is the number of occurrences of an event in some \n interval.\n2. The occurrences must be random.\n3. The occurrences must be independent of each other.\n4. The occurrences must be uniformly distributed over the interval being used.\nParameters of the Poisson Probability Distribution\n \n■The mean is m.\n \n■The standard deviation is s = 1m.\nProperties of the Poisson Probability Distribution\n1. A particular Poisson distribution is determined only by the mean μ.\n2. A Poisson distribution has possible x values of 0, 1, 2, . . . with no upper limit.\nEXAMPLE 1  Hospital Births\nIn a recent year, there were 4229 births at NYU Langone Medical Center (based on \ndata from the NYU Langone website). Assume that the number of births each day is \nabout the same, and assume that the Poisson distribution is a suitable model.\n \na. Find m, the mean number of births per day.\n \nb. Find the probability that on a randomly selected day, there are exactly 10 \nbirths. That is, ﬁnd P(10), where P(x) is the probability of x births in a day.\ncontinued\n",
    "208 \nCHAPTER 5 Discrete Probability Distributions\nPoisson Distribution as Approximation to Binomial\nThe Poisson distribution is sometimes used to approximate the binomial distribution \nwhen n is large and p is small. One rule of thumb is to use such an approximation \nwhen the following two requirements are both satisfied.\nRequirements for Using Poisson as an Approximation to Binomial\n1. n Ú 100\n2. np … 10\nIf both requirements are satisfied and we want to use the Poisson distribution as an \napproximation to the binomial distribution, we need a value for m. That value can be \ncalculated by using Formula 5-6 (from Section 5-2):\nSOLUTION\na. The Poisson distribution applies because we are dealing with the occurrences \nof an event (births) over some interval (a day). The mean number of births per \nday is\nm = Number of births\nNumber of days = 4229\n365 = 11.5863\n \nb. Using Formula 5-9, the probability of x = 10 births in a day is found as \nshown here (with x = 10, m = 11.5863, and e = 2.71828):\nP1102 = mx # e-m\nx!\n= 11.586310 # 2.71828-11.5863\n10!\n= 0.112\nThe probability of exactly 10 births in a day is 0.112.\nFORMULA 5-6 Mean for Poisson as an Approximation to Binomial\nm = np\nEXAMPLE 2  Influenza\nIn one year, the rate of influenza is 5%. If 120 people are randomly selected, find \nthe probability of getting at least one who contracts influenza.\nSOLUTION\nThe time interval is a year. With n = 120 and p = 0.05, the conditions n Ú 100 \nand np … 10 are both satisfied, so we can use the Poisson distribution as an approx-\nimation to the binomial distribution. We first need the value of m, which is found as \nfollows:\nm = np = 1120210.052 = 6\nHaving found the value of m, we can proceed to find the probability for specific \nvalues of x. Because we want the probability that x is “at least 1,” we will use the \nclever strategy of first finding P(0), the probability of no subjects getting influenza. \n",
    "5-3 Poisson Probability Distributions \n209\nThe probability of at least one subject getting influenza can then be found by sub-\ntracting that result from 1. We find P(0) by using x = 0, m = 6, and e = 2.71828, \nas shown here:\nP102 = mx # e-m\nx !\n= 60 # 2.71828-6\n0!\n= 1 # 0.00248\n1\n= 0.00248\nUsing the Poisson distribution as an approximation to the binomial distribution, we \nfind that there is a 0.00248 probability of no subjects with influenza, so the prob-\nability of at least one subject with influenza is 1 - 0.00248 = 0.998. If we use the \nbinomial distribution, we again get a probability of 0.998, so the Poisson approxi-\nmation is quite good here.\nPoisson Distributions\nAccess tech instructions, videos, and data sets at www.TriolaStats.com\nTECH CENTER \nStatistical Literacy and Critical Thinking\n1. Notation In analyzing patient admissions at NYU Langone Medical Center, we find that \n31,645 patients were admitted in a recent year (based on data from the NYU Langone website). \nAssume that we want to find the probability of exactly 85 patient admissions in a randomly \nselected day. In applying Formula 5-9, identify the values of m, x, and e. Also, briefly describe \nwhat each of those symbols represents.\n2. Patient Admissions Use the same patient admission data given in Exercise 1. Let the ran-\ndom variable x represent the number of patient admissions in one day, and assume that it has \na Poisson distribution. What is the standard deviation for the values of the random variable x? \nWhat is the variance?\n3. Poisson Probability Distribution The random variable x represents the number of pa-\ntient admissions in a day, as described in Exercise 1. Assume that the random variable x has a \nPoisson distribution. What are the possible values of x? Is a value of x = 90.3 possible? Is x a \ndiscrete random variable or a continuous random variable?\n4. Probability if 0 For Formula 5-9, what does P(0) represent? Simplify Formula 5-9 for the \ncase in which x = 0.\nBirths. In Exercises 5–8, assume that the Poisson distribution applies, assume that the \nmean number of births at the NYU Langone Medical Center is 11.5863 per day, and \n proceed to find the probability that in a randomly selected day, the number of births is the \nvalue given.\n5. Births Find the probability that in a day, there will be exactly 12 births.\n6. Births Find the probability that in a day, there will be exactly 9 births.\n7. Births Find the probability that in a day, there will be at least 1 birth.\n8. Births Find the probability that in a day, there will be at least 2 births.\n9. Murders In a recent year, there were 333 murders in New York City. Find the mean number \nof murders per day; then use that result to find the probability that in a day, there are no mur-\nders. Does it appear that there are expected to be many days with no murders?\n5-3 Basic Skills and Concepts\n",
    "210 \nCHAPTER 5 Discrete Probability Distributions\n10. Deaths from Horse Kicks A classical example of the Poisson distribution involves the \nnumber of deaths caused by horse kicks to men in the Prussian Army between 1875 and 1894. \nData for 14 corps were combined for the 20-year period, and the 280 corps-years included a to-\ntal of 196 deaths. After finding the mean number of deaths per corps-year, find the probability \nthat a randomly selected corps-year has the following numbers of deaths: (a) 0, (b) 1, (c) 2, (d) 3, \n(e) 4. The actual results consisted of these frequencies: 0 deaths (in 144 corps-years); 1 death \n(in 91 corps-years); 2 deaths (in 32 corps-years); 3 deaths (in 11 corps-years); 4 deaths (in \n2 corps-years). Compare the actual results to those expected by using the Poisson probabilities. \nDoes the Poisson distribution serve as a good tool for predicting the actual results?\n11.  World War II Bombs In analyzing hits by V-1 buzz bombs in World War II, South \n London was partitioned into 576 regions, each with an area of 0.25 km2. A total of 535 bombs \nhit the combined area of 576 regions.\na. Find the probability that a randomly selected region had exactly 2 hits.\nb. Among the 576 regions, find the expected number of regions with exactly 2 hits.\nc. How does the result from part (b) compare to this actual result: There were 93 regions that \nhad exactly 2 hits?\n12. Disease Cluster Neuroblastoma, a rare form of cancer, occurs in 11 children in a  million, \nso its probability is 0.000011. Four cases of neuroblastoma occurred in Oak Park, Illinois, \nwhich had 12,429 children.\na. Assuming that neuroblastoma occurs as usual, find the mean number of cases in groups of \n12,429 children.\nb. Using the unrounded mean from part (a), find the probability that the number of neuroblas-\ntoma cases in a group of 12,429 children is 0 or 1.\nc. What is the probability of more than one case of neuroblastoma?\nd. Does the cluster of four cases appear to be attributable to random chance? Why or why not?\n13. Car Fatalities The recent rate of car fatalities was 33,561 fatalities for 2969 billion miles \ntraveled (based on data from the National Highway Traffic Safety Administration). Find the \nprobability that for the next billion miles traveled, there will be at least one fatality. What does \nthe result indicate about the likelihood of at least one fatality?\n14. Dandelions Dandelions are studied for their effects on crop production and lawn growth. \nIn one region, the mean number of dandelions per square meter was found to be 7.0 (based on \ndata from Manitoba Agriculture and Food).\na. Find the probability of no dandelions in an area of 1 m2.\nb. Find the probability of at least one dandelion in an area of 1 m2.\nc. Find the probability of at most two dandelions in an area of 1 m2.\n15. Rubella During the last 13 years in the United States, there were 138 cases of rubella.\na. Find the mean number of cases of rubella per year. Round the result to four decimal places.\nb. Find the probability of no cases of rubella in a year.\nc. Find the probability of exactly 9 cases of rubella in a year. How does it compare to the \n2 years among 13 that had exactly 9 cases of rubella?\n16.  Diphtheria During the past 34 years, there were 56 cases of diphtheria in the United \nStates.\na. Find the mean number of cases of diphtheria per year. Express the result with five decimal places.\nb. Find the probability of no cases of diphtheria in a year.\nc. Find the probability that the number of diphtheria cases in a year is 5 or fewer. If a year has \nmore than 5 cases of diphtheria, is that a significantly high number?\n",
    "6. Drinking Does the table describe a probability distribution? Why or why not?\n7. Drinking Find the mean of the number of heavy drinkers in groups of five randomly se-\nlected adult males.\n8. Drinking Based on the table, the standard deviation is 0.5 male. What is the variance? In-\nclude appropriate units.\n9. Drinking What does the probability of 0+ indicate? Does it indicate that among five ran-\ndomly selected adult males, it is impossible for all of them to be heavy drinkers?\n10. Drinking What is the probability that fewer than three of the five adult males are heavy \ndrinkers? If we were to find that among 5 randomly selected adult males, there are 4 heavy \ndrinkers, is 4 significantly high?\n17. Probability Histogram for a Poisson Distribution Construct the probability histogram \nfor Exercise 16. Is the Poisson probability distribution a normal distribution or is it skewed?\n5-3 Beyond the Basics\nIn Exercises 1–10, use the following: Based on data from the National Center for Health \nStatistics, 20.6% of adult males smoke. A random sample of 64 male adults is obtained.\n1. Smoking Find the mean number of smokers in groups of 64 randomly selected adult males.\n2. Smoking Find the standard deviation of the number of smokers in groups of 64 randomly \nselected adult males.\n3. Smoking Are the results from Exercises 1 and 2 statistics or parameters?\n4. Smoking For a random sample of 64 males, find the numbers separating the outcomes that \nare significantly high or significantly low.\n5. Smoking Find the probability that the first 8 randomly selected males include exactly 3 \nwho smoke.\nIn Exercises 6–10, use the following: Five male adults are randomly selected, and the table \nin the margin lists the probabilities for the number that are heavy drinkers (based on data \nfrom the National Center for Health Statistics). Males are considered to be heavy drinkers if \nthey have at least 14 drinks per week “on average.”\nChapter Quick Quiz\nx\nP(x)\n0\n0.762\n1\n0.213\n2\n0.024\n3\n0.001\n4\n   0+\n5\n 0+\nIn Exercises 1–5, assume that 28% of randomly selected adults have high cholesterol (with \na level of at least 240 mg , dL or are taking medicine to reduce cholesterol), based on results \nfrom the National Center for Health Statistics. Assume that a group of five adults is ran-\ndomly selected.\n1. Cholesterol Find the probability that exactly two of the five adults have high cholesterol.\n2. Cholesterol Find the probability that at least one of the five adults has high cholesterol. \nDoes the result apply to five adults from the same family? Why or why not?\n3. Cholesterol Find the mean and standard deviation for the numbers of adults in groups of \nfive who have high cholesterol.\n4. Cholesterol If all five of the adults have high cholesterol, is five significantly high? Why \nor why not?\nReview Exercises\nCHAPTER 5 Review Exercises \n211\n",
    "212 \nCHAPTER 5 Discrete Probability Distributions\n5. Cholesterol If the group of five adults includes exactly 1 with high cholesterol, is that \nvalue of 1 significantly low?\n6. Security Survey In a USA Today poll, subjects were asked if passwords should be re-\nplaced with biometric security, such as fingerprints. The results from that poll have been used \nto create the accompanying table. Does this table describe a probability distribution? Why or \nwhy not?\nResponse\nP(x)\nYes\n0.53\nNo\n0.17\nNot sure\n0.30\n7. Condom Failure Rate According to the Department of Health and Human Services, the \nfailure rate for male condoms is 18%. The accompanying table is based on the failure rate of \n18%, where x represents the number of condoms that fail when six are tested.\na. Does the table describe a probability distribution? Why or why not?\nb. Assuming that the table does describe a probability distribution, find its mean.\nc. Assuming that the table does describe a probability distribution, find its standard deviation.\nd. If 6 condoms are tested and 5 of them fail, is 5 a significantly high number of failures? Why \nor why not?\ne. What does the symbol 0+ represent?\nx\nP(x)\n0\n0.304\n1\n0.400\n2\n0.220\n3\n0.064\n4\n0.011\n5\n0.001\n6\n0+\n8.  Poisson: Deaths Currently, an average of 143 residents of Madison, CT (population \n17,858), die each year (based on data from the U.S. National Center for Health Statistics).\na. Find the mean number of deaths per day.\nb. Find the probability that on a given day, there are no deaths.\nc. Find the probability that on a given day, there are more than two deaths.\nd. Based on the preceding results, should Madison have a contingency plan to handle more \nthan two deaths per day? Why or why not?\nCumulative Review Exercises\n1. Manatee Deaths Listed below are the annual numbers of manatee deaths from boats in \nFlorida for each of the past 10 years, listed in chronological order.\n69 79 92 73 90 97 83 88 81 72\na. Find the mean.\nb. Find the median.\nc. Find the range.\nd. Find the standard deviation.\ne. Find the variance.\nf. Describe an important characteristic of the data that is not addressed by the statistics found in \nparts (a) through (e).\ng. Use the range rule of thumb to identify the values separating significant values from those \nthat are not significant.\nh. Based on the result from part (f), do any of the years have a number of manatee deaths that is \nsignificantly low or significantly high?\ni. What is the level of measurement of the data: nominal, ordinal, interval, or ratio?\nj. Are the data discrete or continuous?\n",
    "2. Analysis of Last Digits The accompanying table lists the last or rightmost digits of weights \nof the females listed in Data Set 1 “Body Data” in Appendix B. The last digits of a data set can \nsometimes be used to determine whether the data have been measured or simply reported. The \npresence of disproportionately more 0s and 5s is often a sure sign that the data have been re-\nported instead of measured.\na. Using the table, find the mean and standard deviation of those last digits. Are the results \nstatistics or parameters?\nb. Examine the given table to determine if there is anything about the sample data (such as \ndisproportionately more 0s and 5s) suggesting that the given last digits are not random? Or do \nthey appear to be random?\nc. Does the table describe a probability distribution? Why or why not?\nx\nf\n0\n11\n1\n11\n2\n16\n3\n14\n4\n16\n5\n24\n6\n13\n7\n14\n8\n19\n9\n  9\n3. Government Health Plan Fox News broadcast a graph similar to the one shown here. The \ngraph is intended to compare the number of people actually enrolled in a government health \nplan (left bar) and the goal for the number of enrollees (right bar). Does the graph depict the \ndata correctly or is it somehow misleading? Explain.\n4. Diabetes Among adults in the United States, 11.5% have diabetes (based on data from the \nNational Center for Health Statistics).\na. Find the probability that a randomly selected adult does not have diabetes.\nb. Find the probability that two randomly selected adults both have diabetes.\nc. Find the probability that among three randomly selected adults, at least one has diabetes.\nd. For groups of 40 randomly selected adults, find the mean and standard deviation for the \nnumbers of adults having diabetes. Are these results statistics or parameters?\ne. If 40 adults are randomly selected and 10 of them have diabetes, is 10 a result that is signifi-\ncantly low or significantly high? Why?\n\t\nCHAPTER 5  Cumulative Review Exercises\t\n213\n",
    "214 \nCHAPTER 5 Discrete Probability Distributions\nFROM DATA TO DECISION\nCritical Thinking: Determining criteria for concluding \nthat a gender selection method is effective\nYou are responsible for analyzing results from a clinical trial \nof the effectiveness of a new method of gender selection. \nAssume that the sample size of n = 75 couples has already \nbeen established, and each couple will have one child. Fur-\nther assume that each of the couples will be subjected to a \ntreatment that supposedly increases the likelihood that the \nchild will be a girl. Assume that with no treatment, the prob-\nability of a baby being a girl is 0.488, which is currently the \ncorrect value in the United States.\nThere is a danger in obtaining results first, then making \nconclusions about the results. If the results are close to show-\ning the effectiveness of a treatment, it might be tempting to \n conclude that there is an effect when, in reality, there is no ef-\nfect. It is better to establish criteria before obtaining results.\na. Using the methods of this chapter, identify the criteria that \nshould be used for concluding that the treatment is effective in in-\ncreasing the likelihood of a girl. Among the 75 births, how many \ngirls would you require in order to conclude that the gender selec-\ntion procedure is effective? Explain how you arrived at this result.\nb. If 60% of the 75 babies are girls, is that result high enough \nto conclude that the gender selection method is effective? \nWhy or why not?\nc. If 64% of the 75 babies are girls, is that result high enough \nto conclude that the gender selection method is effective? \nWhy or why not?\nCooperative Group Activities\n1. In-class activity Win $1,000,000! The James Randi Educational Foundation offers a \n$1,000,000 prize to anyone who can show “under proper observing conditions, evidence of \nany paranormal, supernatural, or occult power or event.” Divide into groups of three. Select \none person who will be tested for extrasensory perception (ESP) by trying to correctly identify \na digit (0–9) randomly selected by another member of the group. Conduct at least 20 trials. \nAnother group member should record the randomly selected digit, the digit guessed by the \nsubject, and whether the guess was correct or wrong. Construct the table for the probability \ndistribution of randomly generated digits, construct the relative frequency table for the ran-\ndom digits that were actually obtained, and construct a relative frequency table for the guesses \nthat were made. After comparing the three tables, what do you conclude? What proportion of \nguesses is correct? Does it seem that the subject has the ability to select the correct digit signifi-\ncantly more often than would be expected by chance?\nMendel’s Hybrid Experiments One of Mendel’s famous experiments with peas included \n1064 offspring, and 787 of them had long stems. Mendel claimed that under the same condi-\ntions, 75% of offspring peas would have long stems. Assume that Mendel’s claim of 75% is \ntrue, and assume that a sample consists of 1064 offspring peas.\n• Use the range rule of thumb to identify the limits separating values that are significantly low \nand those that are significantly high. Based on the results, is the result of 787 peas with long \nstems either significantly low or significantly high?\n• Find the probability of exactly 787 peas with long stems.\n• Find the probability of 787 or fewer peas with long stems.\n• Which probability is relevant for determining whether 787 peas with long stems is signifi-\ncantly low: the probability from part (b) or part (c)? Based on the relevant probability, is the \nresult of 787 peas with long stems significantly low?\n• What do the results suggest about Mendel’s claim of 75%?\nTechnology Project\n",
    "2. In-class activity See the preceding activity and design an experiment that would be ef-\nfective in testing someone’s claim that he or she has the ability to identify the color of a card \nselected from a standard deck of playing cards. Describe the experiment with great detail. Be-\ncause the prize of $1,000,000 is at stake, we want to be careful to avoid the serious mistake of \nconcluding that the person has a paranormal power when that power is not actually present. \nThere will likely be some chance that the subject could make random guesses and be correct \nevery time, so identify a probability that is reasonable for the event of the subject passing the \ntest with random guesses. Be sure that the test is designed so that this probability is equal to or \nless than the probability value selected.\n3. In-class activity Suppose we want to identify the probability distribution for the number \nof children in families with at least one child. For each student in the class, find the number \nof brothers and sisters and record the total number of children (including the student) in each \nfamily. Construct the relative frequency table for the result obtained. (The values of the random \nvariable x will be 1, 2, 3, . . . .) What is wrong with using this relative frequency table as an es-\ntimate of the probability distribution for the number of children in randomly selected families?\n4. Out-of-class activity The analysis of the last digits of data can sometimes reveal whether \nthe data have been collected through actual measurements or reported by the subjects. Refer \nto an almanac or the Internet and find a collection of data (such as lengths of rivers in the \nworld), then analyze the distribution of last digits to determine whether the values were ob-\ntained through actual measurements.\n5. Out-of-class activity The photos shown below depict famous statisticians with first names \nof David and John, not necessarily in the order shown. Conduct a survey by asking this ques-\ntion: “Which man is named David and which man is named John?” Do the respondents ap-\npear to give results significantly different from what is expected with random guesses? (See \n“Who Do You Look Like? Evidence of Facial Stereotypes for Male Names” by Lea, Thomas, \nLamkin, and Bell, Psychonomic Bulletin & Review, Vol. 14, Issue 5.)\nCHAPTER 5 Cooperative Group Activities \n215\n",
    "216\nThe Standard Normal \nDistribution\nReal Applications of \nNormal Distributions\nSampling Distributions \nand Estimators\nThe Central Limit \nTheorem\nAssessing Normality\nNormal as \nApproximation to \nBinomial\n6-1\n6-2\n6-3\n6-4\n6-5\n6-6\nWhat Is a Normal Pulse Rate?\nCHAPTER \nPROBLEM\nNormal Probability \nDistributions\nExploring the pulse rates of adult males and females in Data \nSet 1 “Body Data” from Appendix B reveals the  following:\n• Adult males have pulse rates with a mean of 69.6 bpm \n(beats per minute), a standard deviation of 11.3 bpm, and a \ndistribution that is approximately normal.\n• Adult females have pulse rates with a mean of 74.0 bpm, \na standard deviation of 12.5 bpm, and a distribution that is \napproximately normal.\n• There appears to be a significant difference between pulse \nrates of males and females.\nFor the purposes of this chapter, we will use the above results as \nreasonable estimates of population parameters. See the following:\nm \ns \nDistribution\nMale Adult Pulse Rates (bpm) \n69.6 \n11.3 \nNormal\nFemale Adult Pulse Rates (bpm) \n74.0 \n12.5 \nNormal\n6 \n",
    "Physicians routinely measure pulse rates of patients, and the \nnormal range is generally considered to be between 60 bpm and \n100 bpm. Here are conditions for pulse rates outside that range:\nTachycardia: Pulse rate greater than 100 bpm.\nBradycardia: Pulse rate less than 60 bpm\nAn excessively high pulse rate (tachycardia) is generally more \nof a problem than an excessively low pulse rate (bradycar-\ndia). An excessively high pulse rate can indicate a high risk of \nstroke, heart disease, or can even cause death. An excessively \nlow pulse can occur with an athlete in peak physical condition, \nand some drugs such as beta blockers can also cause an  \nexcessively low pulse rate.\nHere are some questions that can be addressed with the \nmethods of this chapter:\n• What is the proportion of adult males who are expected to \nhave pulse rates greater than 100 bpm?\n• What is the proportion of adult males who are expected to \nhave pulse rates less than 60 bpm.\n• For males, if we introduce a criterion whereby the highest \n1% of pulse rates are considered to be significantly high, \nwhat is the cutoff?\n• For males, if we introduce a criterion whereby the lowest 1% \nof pulse rates are considered to be significantly low, what is \nthe cutoff?\nThese same questions can be posed for adult females, and we will \naddress such questions using the methods in this chapter.\nChapter 5 introduced discrete probability distributions, but in this chapter we introduce \ncontinuous probability distributions, and most of this chapter focuses on normal distri-\nbutions. Here are the chapter objectives:\nThe Standard Normal Distribution\n• Describe the characteristics of a standard normal distribution.\n• Find the probability of some range of z values in a standard normal distribution.\n• Find z scores corresponding to regions under the curve representing a standard \nnormal distribution.\nReal Applications of Normal Distributions\n• Develop the ability to describe a normal distribution (not necessarily a standard \n normal distribution).\n• Find the probability of some range of values in a normal distribution.\n• Find x scores corresponding to regions under the curve representing a normal \n distribution.\nSampling Distributions and Estimators\n• Develop the ability to describe a sampling distribution of  a statistic.\n• Determine whether a statistic serves as a good estimator of the corresponding \npopulation parameter.\nThe Central Limit Theorem\n• Describe what the central limit theorem states.\n• Apply the central limit theorem by finding the probability that a sample mean falls \nwithin some specified range of values.\n• Identify conditions for which it is appropriate to use a normal distribution for the \n distribution of sample means.\n6-1\n6-2\n6-3\n6-4\nChapter Objectives \n217\nCHAPTER OBJECTIVES\n>>>\ncontinued\n",
    "218 \nCHAPTER 6 Normal Probability Distributions\nKey Concept In this section we present the standard normal distribution, which is a \nspecific normal distribution having the following three properties:\n1. Bell-shaped: The graph of the standard normal distribution is bell-shaped (as in \nFigure 6-1).\n2. m = 0: The standard normal distribution has a mean equal to 0.\n3. s = 1: The standard normal distribution has a standard deviation equal to 1.\nIn this section we develop the skill to find areas (or probabilities or relative frequen-\ncies) corresponding to various regions under the graph of the standard normal distri-\nbution. In addition, we find z scores that correspond to areas under the graph. These \nskills become important in the next section as we study nonstandard normal distribu-\ntions and the real and important applications that they involve.\nNormal Distributions\nThere are infinitely many different normal distributions, depending on the values used \nfor the mean and standard deviation. We begin with a brief introduction to this general \nfamily of normal distributions.\n6-1 \nThe Standard Normal Distribution\nAssessing Normality\n• Develop the ability to examine histograms, outliers, and normal quantile plots to \ndetermine whether sample data appear to be from a population having a distribution \nthat is approximately normal.\nNormal as Approximation to Binomial\n• Identify conditions for which it is appropriate to use a normal distribution as an ap-\nproximation to a binomial probability distribution.\n• Use the normal distribution for approximating probabilities for a binomial distribution.\n6-5\n6-6\nAssessing Normality\n• Develop the ability to examine histograms, outliers, and normal quantile plots to \ndetermine whether sample data appear to be from a population having a distribution\nthat is approximately normal.\nNormal as Approximation to Binomial\n• Identify conditions for which it is appropriate to use a normal distribution as an ap-\nfo\nf\nproximation to a binomial probability distribution.\n• Use the normal distribution for approximating probabilities for a binomial distribution.\nDEFINITION\nIf a continuous random variable has a distribution with a graph that is symmetric \nand bell-shaped, as in Figure 6-1, and it can be described by the equation given as \nFormula 6-1, we say that it has a normal distribution.\nFORMULA 6-1\ny = e- 1\n21\nx - m\ns 22\ns22p\nIn this book, we won’t actually use Formula 6-1, but examining the right side of the \nequation reveals that any particular normal distribution is determined by two parame-\nters: the population mean, m, and population standard deviation, s. (In Formula 6-1, x is \na variable that can change, p = 3.14159, and e = 2.71828.) Once specific values are \nselected for m and s, Formula 6-1 is an equation relating x and y, and we can graph \nm\nValue\nCurve is bell-shaped\nand symmetric\nFIGURE 6-1  The Normal \nDistribution\n",
    "6-1 The Standard Normal Distribution \n219\nthat equation to get a result that will look like Figure 6-1. And that’s about all we need \nto know about Formula 6-1!\nUniform Distributions\nThe major focus of this chapter is the concept of a normal probability distribution, but \nwe begin with a uniform distribution so that we can see the following two very impor-\ntant properties:\n1. The area under the graph of a continuous probability distribution is equal to 1.\n2. There is a correspondence between area and probability, so probabilities \ncan be found by identifying the corresponding areas in the graph using this \nformula for the area of a rectangle:\nArea = height * width\nEXAMPLE 1  Waiting Times for Emergency Room Check-In\nDuring certain time periods at a hospital in New York City, patients arriving at the \nemergency room have waiting times that are uniformly distributed between 0 minutes \nand 5 minutes, as illustrated in Figure 6-2.\nRefer to Figure 6-2 to see these properties:\n \n■All of the different possible waiting times are equally likely.\n \n■Waiting times can be any value between 0 min and 5 min, so it is possible to \nhave a waiting time of 1.234567 min.\n \n■By assigning the probability of 0.2 to the height of the vertical line in Figure 6-2, \nthe enclosed area is exactly 1. (In general, we should make the height of the ver-\ntical line in a uniform distribution equal to 1>range.)\n0\n0.2\n1\n2\nArea 5 1\n3\n4\n5\nx (waiting time in minutes)\nP(x)\nFIGURE 6-2 Uniform Distribution of Waiting Time\nDEFINITION\nA continuous random variable has a uniform distribution if its values are spread \nevenly over the range of possibilities. The graph of a uniform distribution results in \na rectangular shape.\nDensity Curve The graph of any continuous probability distribution is called a \ndensity curve, and any density curve must satisfy the requirement that the total area \nunder the curve is exactly 1. This requirement that the area must equal 1 simplifies \nprobability problems, so the following statement is really important:\nBecause the total area under any density curve is equal to 1, there is a \n correspondence between area and probability.\n",
    "220 \nCHAPTER 6 Normal Probability Distributions\nStandard Normal Distribution\nThe density curve of a uniform distribution is a horizontal straight line, so we can find \nthe area of any rectangular region by applying this formula:\nArea = height * width\nBecause the density curve of a normal distribution has a more complicated bell shape \nas shown in Figure 6-1, it is more difficult to find areas. However, the basic principle \nis the same: There is a correspondence between area and probability. In Figure 6-4 \nwe show that for a standard normal distribution, the area under the density curve is \nequal to 1. In Figure 6-4, we use “z Score” as a label for the horizontal axis, and this is \ncommon for the standard normal distribution, defined as follows.\nEXAMPLE 2  Waiting Times at an Emergency Room\nGiven the uniform distribution illustrated in Figure 6-2, find the probability that a \nrandomly selected patient has a waiting time of at least 2 minutes.\nSOLUTION\nThe shaded area in Figure 6-3 represents waiting times of at least 2 minutes. Because the \ntotal area under the density curve is equal to 1, there is a correspondence between area \nand probability. We can easily find the desired probability by using areas as follows:\n P1wait time of at least 2 min2 = height *  width of shaded area in Figure 6@3\n = 0.2 * 3\n = 0.6\n0\n0.2\n1\n2\nArea 5 0.2 3 3\n \n5 0.6\n3\n4\n5\nx (waiting time in minutes)\nP(x)\nFIGURE 6-3 Using Area to Find Probability\nINTERPRETATION\nThe probability of randomly selecting a patient with a waiting time of at least  \n2 minutes is 0.6.\n1\n2\n3\n0\nz Score\nArea 5 1\n21\n22\n23\nFIGURE 6-4\nStandard Normal Distribution\n",
    "6-1 The Standard Normal Distribution \n221\nFinding Probabilities When Given z Scores\nIt is not easy to manually find areas in Figure 6-4, but we can find areas (or prob-\nabilities) for many different regions in Figure 6-4 by using technology, or we can also \nuse Table A-2 (in Appendix A and the Formulas and Tables insert card). Key features \nof the different methods are summarized in Table 6-1, which follows. (StatCrunch \nprovides options for a cumulative left region, a cumulative right region, or the region \nbetween two boundaries.) Because calculators and software generally give more ac-\ncurate results than Table A-2, we strongly recommend using technology. (When there \nare discrepancies, answers in Appendix D will generally include results based on tech-\nnology as well as answers based on Table A-2.)\nTABLE 6-1 Formats Used for Finding Normal Distribution Areas\nCumulative Area from the Left\nThe following provide the cumulative area \nfrom the left up to a vertical line above a \nspecific value of z:\n• Table A-2 \n• Statdisk \n• Minitab \n• Excel \n• StatCrunch \nz\nCumulative Left Region\nArea Between Two Boundaries\nThe following provide the area bounded on \nthe left and bounded on the right by vertical \nlines above specific values.\n• TI-83, 84 Plus calculator \n• StatCrunch \nUpper\nLower\nArea Between Two Boundaries\nDEFINITION\nThe standard normal distribution is a normal distribution with the parameters of \nm = 0 and s = 1. The total area under its density curve is equal to 1 (as in Figure 6-4).\nTable A-2: If using Table A-2, it is essential to understand these points:\n1. Table A-2 is designed only for the standard normal distribution, which is a nor-\nmal distribution with a mean of 0 and a standard deviation of 1.\n2. Table A-2 is on two pages, with the left page for negative z scores and the right \npage for positive z scores.\n3. Each value in the body of the table is a cumulative area from the left up to a \nvertical boundary above a specific z score.\ncontinued\n",
    "222 \nCHAPTER 6 Normal Probability Distributions\nThe following examples illustrate procedures that can be used with real and im-\nportant applications introduced in the following sections.\nCAUTION When working with a normal distribution, be careful to avoid confusion \nbetween z scores and areas.\nz 5 1.27\n0\nArea 5 0.8980\n(from Table A-2)\nFIGURE 6-5\nFinding Area to the Left of z = 1.27\nEXAMPLE 3  Bone Density Test\nA bone mineral density test can be helpful in identifying the presence or likelihood \nof osteoporosis, a disease causing bones to become more fragile and more likely \nto break. The result of a bone density test is commonly measured as a z score. The \npopulation of z scores is normally distributed with a mean of 0 and a standard de-\nviation of 1, so these test results meet the requirements of a standard normal distri-\nbution, and the graph of the bone density test scores is as shown in Figure 6-5.\nA randomly selected adult undergoes a bone density test. Find the probability \nthat this person has a bone density test score less than 1.27.\nSOLUTION\nNote that the following are the same (because of the aforementioned correspon-\ndence between probability and area):\n \n■Probability that the bone density test score is less than 1.27\n \n■Shaded area shown in Figure 6-5\nSo we need to find the area in Figure 6-5 below z = 1.27. If using Table A-2, \n begin with the z score of 1.27 by locating 1.2 in the left column; next find the \nvalue in the adjoining row of probabilities that is directly below 0.07, as shown in \nthe excerpt on the top of the following page. Table A-2 shows that there is an area \nof 0.8980 corresponding to z = 1.27. We want the area below 1.27, and Table A-2 \ngives the cumulative area from the left, so the desired area is 0.8980. Because of \nthe correspondence between area and probability, we know that the probability of a \nz score below 1.27 is 0.8980.\n4. When working with a graph, avoid confusion between z scores and areas.\nz score: \n Distance along the horizontal scale of the standard normal dis-\ntribution (corresponding to the number of standard deviations \nabove or below the mean); refer to the leftmost column and top \nrow of Table A-2.\nArea: \n Region under the curve; refer to the values in the body of Table A-2.\n5. The part of the z score denoting hundredths is found across the top row of \nTable A-2.\n",
    "6-1 The Standard Normal Distribution \n223\nTABLE A-2 (continued) Cumulative Area from the LEFT\nz\n.00\n.01\n.02\n.03\n.04\n.05\n.06\n.07\n.08\n.09\n0.0\n.5000\n.5040\n.5080\n.5120\n.5160\n.5199\n.5239\n.5279\n.5319\n.5359\n0.1\n.5398\n.5438\n.5478\n.5517\n.5557\n.5596\n.5636\n.5675\n.5714\n.5753\n0.2\n.5793\n.5832\n.5871\n.5910\n.5948\n.5987\n.6026\n.6064\n.6103\n.6141\n1.0\n.8413\n.8438\n.8461\n.8485\n.8508\n.8531\n.8554\n.8577\n.8599\n.8621\n1.1\n.8643\n.8665\n.8686\n.8708\n.8729\n.8749\n.8770\n.8790\n.8810\n.8830\n1.2\n.8849\n.8869\n.8888\n.8907\n.8925\n.8944\n.8962\n.8980\n.8997\n.9015\n1.3\n.9032\n.9049\n.9066\n.9082\n.9099\n.9115\n.9131\n.9147\n.9162\n.9177\n1.4\n.9192\n.9207\n.9222\n.9236\n.9251\n.9265\n.9279\n.9292\n.9306\n.9319\nINTERPRETATION\nThe probability that a randomly selected person has a bone density test result below \n1.27 is 0.8980, shown as the shaded region in Figure 6-5. Another way to interpret \nthis result is to conclude that 89.80% of people have bone density levels below 1.27.\nEXAMPLE 4   Bone Density Test: Finding the Area to the Right  \nof a Value\nUsing the same bone density test from Example 3, find the probability that a ran-\ndomly selected person has a result above -1.00. A value above -1.00 is considered \nto be in the “normal” range of bone density readings.\nSOLUTION\nWe again find the desired probability by finding a corresponding area. We are look-\ning for the area of the region to the right of z = -1.00 that is shaded in Figure 6-6. \nThe Statdisk display on the top of the following page shows that the area to the \nright of z = -1.00 is 0.841345.\nIf we use Table A-2, we should know that it is designed to apply only to cumu-\nlative areas from the left. Referring to the page with negative z scores, we find that \nthe cumulative area from the left up to z = -1.00 is 0.1587, as shown in Figure \n6-6. Because the total area under the curve is 1, we can find the shaded area by \nsubtracting 0.1587 from 1. The result is 0.8413. Even though Table A-2 is designed \nonly for cumulative areas from the left, we can use it to find cumulative areas from \nthe right, as shown in Figure 6-6.\n0.1587\nz 5 –1.00\n1. Use z 5 21.00\nin Table A-2 to\nﬁnd this area.\n2. Because\n \nthe total area\n \nis 1, this area is\n \n1 2 0.1587 5 0.8413\nFIGURE 6-6  Finding the Area to the \nRight of z = −1\ncontinued\n",
    "224 \nCHAPTER 6 Normal Probability Distributions\nExample 4 illustrates a way that Table A-2 can be used indirectly to find a cumu-\nlative area from the right. The following example illustrates another way that we can \nfind an area indirectly by using Table A-2.\nINTERPRETATION\nBecause of the correspondence between probability and area, we conclude that \nthe probability of randomly selecting someone with a bone density reading above \n-1 is 0.8413 (which is the area to the right of z = -1.00). We could also say that \n84.13% of people have bone density levels above -1.00.\nz 5 21.00\n0.1587\nThis area\n0.1587\n \nz 5 22.50\n0.0062\nminus this area\n2 0.0062\n \n22.50 21.00\n0.1525\nequals this area\n5 0.1525\nFIGURE 6-7 Finding the Area Between Two z Scores\nEXAMPLE 5   Bone Density Test: Finding the Area Between  \nTwo Values\nA bone density test reading between -1.00 and -2.50 indicates that the subject has \nosteopenia, which is some bone loss. Find the probability that a randomly selected \nsubject has a reading between -1.00 and -2.50.\nSOLUTION\nWe are again dealing with normally distributed values having a mean of 0 and a \nstandard deviation of 1. The values between -1.00 and -2.50 correspond to the \nshaded region in the third graph included in Figure 6-7. Table A-2 cannot be used to \nfind that area directly, but we can use this table to find the following:\n \n1. The area to the left of z = -1.00 is 0.1587.\n \n2. The area to the left of z = -2.50 is 0.0062.\n \n3. The area between z = -2.50 and z = -1.00 (the shaded area at the far right in \nFigure 6-7) is the diﬀerence between the areas found in the preceding two steps:\n \n Statdisk\n",
    "6-1 The Standard Normal Distribution \n225\nExample 5 can be generalized as the following rule:\nThe area corresponding to the region between two z scores can be found by \nﬁnding the diﬀerence between the two areas found in Table A-2.\nFigure 6-8 illustrates this general rule. The shaded region B can be found by calculat-\ning the difference between two areas found from Table A-2.\nINTERPRETATION\nUsing the correspondence between probability and area, we conclude that there is \na probability of 0.1525 that a randomly selected subject has a bone density read-\ning between -1.00 and -2.50. Another way to interpret this result is to state that \n15.25% of people have osteopenia, with bone density readings between -1.00\nand -2.50.\nHINT Don’t try to memorize a rule or formula for this case. Focus on understanding \nby using a graph. Draw a graph, shade the desired area, and then get creative \nto think of a way to find the desired area by working with cumulative areas from \nthe left.\n0\nz Left\nz Right\nA\nB\nShaded area B 5 (areas A and B combined) — (area A)\nFIGURE 6-8 Finding the Area Between Two z Scores\nProbabilities such as those in the preceding examples can also be expressed with \nthe following notation.\nNotation\nP1a 6 z 6 b2 \ndenotes the probability that the z score is between a and b.\nP1z 7 a2 \ndenotes the probability that the z score is greater than a.\nP1z 6 a2 \ndenotes the probability that the z score is less than a.\nWith this notation, P1-2.50 6 z 6 -1.002 = 0.1525 states in symbols that the \nprobability of a z score falling between -2.50 and -1.00 is 0.1525 (as in Example 5).\nFinding z Scores from Known Areas\nExamples 3, 4, and 5 all involved the standard normal distribution, and they were all \nexamples with this same format: Given z scores, find areas (or probabilities). In many \ncases, we need a method for reversing the format: Given a known area (or probability), \nfind the corresponding z score. In such cases, it is really important to avoid  confusion \nbetween z scores and areas. Remember, z scores are distances along the horizontal \n",
    "226 \nCHAPTER 6 Normal Probability Distributions\nscale, but areas (or probabilities) are regions under the density curve. (Table A-2 lists \nz-scores in the left column and across the top row, but areas are found in the body of \nthe table.) We should also remember that z scores positioned in the left half of the \ncurve are always negative. If we already know a probability and want to find the cor-\nresponding z score, we use the following procedure.\nProcedure for Finding a z Score from a Known Area\n1. Draw a bell-shaped curve and identify the region under the curve that corre-\nsponds to the given probability. If that region is not a cumulative region from the \nleft, work instead with a known region that is a cumulative region from the left.\n2. Use technology or Table A-2 to find the z score. With Table A-2, use the cu-\nmulative area from the left, locate the closest probability in the body of the \ntable, and identify the corresponding z score.\nSpecial Cases In the solution to Example 6 that follows, Table A-2 leads to a z score \nof 1.645, which is midway between 1.64 and 1.65. When using Table A-2, we can \nusually avoid interpolation by simply selecting the closest value. The accompanying \ntable lists special cases that are often used in a wide variety of applications. (For one \nof those special cases, the value of z = 2.576 gives an area slightly closer to the area \nof 0.9950, but z = 2.575 has the advantage of being the value exactly midway be-\ntween z = 2.57 and z = 2.58.) Except in these special cases, we can usually select \nthe closest value in the table. (If a desired value is midway between two table values, \nselect the larger value.) For z scores above 3.49, we can use 0.9999 as an approxima-\ntion of the cumulative area from the left; for z scores below -3.49, we can use 0.0001 \nas an approximation of the cumulative area from the left.\nSpecial Cases in Table A-2\n \n \nz Score\nCumulative  \nArea from  \nthe Left\n 1.645\n0.9500\n-1.645\n0.0500\n 2.575\n0.9950\n-2.575\n0.0050\nAbove 3.49\n0.9999\nBelow -3.49\n0.0001\n0\nArea 5 0.95\nz 5 ?\nFIGURE 6-9  Finding the 95th Percentile\nEXAMPLE 6  Bone Density Test: Finding a Test Score \nUse the same bone density test scores used in earlier examples. Those scores are \nnormally distributed with a mean of 0 and a standard deviation of 1, so they meet \nthe requirements of a standard normal distribution. Find the bone density score cor-\nresponding to P95, the 95th percentile. That is, find the bone density score that sepa-\nrates the bottom 95% from the top 5%. See Figure 6-9.\nSOLUTION\nFigure 6-9 shows the z score that is the 95th percentile, with 95% of the area (or \n0.95) below it.\nTechnology: We could find the z score using technology. The following Excel  \ndisplay shows that the z score with an area of 0.95 to its left is z = 1.644853627, or \n1.645 when rounded.\n",
    "6-1 The Standard Normal Distribution \n227\nExcel\nTable A-2: If using Table A-2, search for the area of 0.95 in the body of the table and \nthen find the corresponding z score. In Table A-2 we find the areas of 0.9495 and \n0.9505, but there’s an asterisk with a special note indicating that 0.9500 corresponds \nto a z score of 1.645. We can now conclude that the z score in Figure 6-9 is 1.645, so \nthe 95th percentile is z = 1.645.\nINTERPRETATION\nFor bone density test scores, 95% of the scores are less than or equal to 1.645, and \n5% of them are greater than or equal to 1.645.\nINTERPRETATION\nFor the population of bone density test scores, 2.5% of the scores are equal to or \nless than -1.96 and 2.5% of the scores are equal to or greater than 1.96. Another in-\nterpretation is that 95% of all bone density test scores are between -1.96 and 1.96.\n0\nz 5 1.96\nz 5 21.96\nArea 5 0.025\nArea 5 0.025\nTo ﬁnd this z score,\nlocate the cumulative\narea to the left in \nTable A–2. Locate 0.975 \nin the body of Table A–2.\nFIGURE 6-10 Finding z Scores\nEXAMPLE 7  Bone Density Test \nUsing the same bone density test described in Example 3, we have a standard normal \ndistribution with a mean of 0 and a standard deviation of 1. Find the bone density test \nscore that separates the bottom 2.5% and find the score that separates the top 2.5%.\nSOLUTION\nThe required z scores are shown in Figure 6-10. Those z scores can be found  using \ntechnology. If using Table A-2 to find the z score located to the left, we search \nthe body of the table for an area of 0.025. The result is z = -1.96. To find the \nz score located to the right, we search the body of Table A-2 for an area of 0.975. \n (Remember that Table A-2 always gives cumulative areas from the left.) The result \nis z = 1.96. The values of z = -1.96 and z = 1.96 separate the bottom 2.5% and \nthe top 2.5%, as shown in Figure 6-10.\n",
    "228 \nCHAPTER 6 Normal Probability Distributions\nCritical Values For a normal distribution, a critical value is a z score on the bor-\nderline separating those z scores that are significantly low or significantly high. Com-\nmon critical values are z = -1.96 and z = 1.96, and they are obtained as shown in \nExample 7. In Example 7, values of z = -1.96 or lower are significantly low because \nonly 2.5% of the population have scores at or below -1.96, and the values at or above \nz = 1.96 are significantly high because only 2.5% of the population have scores at or \nabove 1.96. Critical values will become extremely important in subsequent chapters. \nThe following notation is used for critical z values found by using the standard normal \ndistribution.\nDEFINITION \nFor the standard normal distribution, a critical value is a z score on the borderline \nseparating those z scores that are significantly low or significantly high.\nCAUTION When finding a value of za for a particular value of a, note that a is the \narea to the right of za, but Table A-2 and some technologies give cumulative areas \nto the left of a given z score. To find the value of za, resolve that conflict by using \nthe value of 1 - a. For example, to find z0.1, refer to the z score with an area of 0.9 \nto its left.\nNotation \nThe expression za denotes the z score with an area of a to its right. (a is the Greek \nletter alpha.)\nEXAMPLE 8  Finding the Critical Value zA \nFind the value of z0.025. (Let a = 0.025 in the expression za.)\nSOLUTION\nThe notation of z0.025 is used to represent the z score with an area of 0.025 to its \nright. Refer to Figure 6-10 and note that the value of z = 1.96 has an area of 0.025 \nto its right, so z0.025 = 1.96. Note that z0.025 corresponds to a cumulative left area \nof 0.975.\nExamples 3 through 7 in this section are based on the real application of the bone \ndensity test, with scores that are normally distributed with a mean of 0 and standard \ndeviation of 1, so that these scores have a standard normal distribution. Apart from \nthe bone density test scores, it is rare to find such convenient parameters, because \ntypical normal distributions have means different from 0 and standard deviations dif-\nferent from 1. In the next section we present methods for working with such normal \ndistributions.\nFinding z Scores>Areas (Standard Normal)\nAccess tech instructions, videos, and data sets at www.TriolaStats.com\nTECH CENTER \n",
    "6-1 The Standard Normal Distribution \n229\n5. Greater than 3.00 minutes. \n6. Less than 4.00 minutes.\n7. Between 2 minutes and 3 minutes. \n8. Between 2.5 minutes and 4.5 minutes.\nStandard Normal Distribution. In Exercises 9–12, find the area of the shaded region. \nThe graph depicts the standard normal distribution of bone density scores with mean 0 and \nstandard deviation 1.\n9. \nz 5 0.44\n \n10. \nz 5 21.04\n11. \nz 5 20.84\nz 5 1.28\n \n12. \nz 5 21.07\nz 5 0.67\nStatistical Literacy and Critical Thinking\n1. Normal Distribution What’s wrong with the following statement? “Because the digits 0, 1, \n2, . . . , 9 are the normal results from lottery drawings, such randomly selected numbers have a \nnormal distribution.”\n2. Normal Distribution A normal distribution is informally described as a probability dis-\ntribution that is “bell-shaped” when graphed. Draw a rough sketch of a curve having the bell \nshape that is characteristic of a normal distribution.\n3. Standard Normal Distribution Identify the two requirements necessary for a normal dis-\ntribution to be a standard normal distribution.\n4. Notation What does the notation za indicate?\nContinuous Uniform Distribution. In Exercises 5–8, refer to the continuous uniform \ndistribution depicted in Figure 6-2 and described in Example 1. Assume that a patient is \nrandomly selected, and find the probability that the waiting time is within the given range.\n6-1 Basic Skills and Concepts \n0\n0.2\n1\n2\nArea 5 1\n3\n4\n5\nx (waiting time in minutes)\nP(x)\nFIGURE 6-2  Uniform Distribution of  \nWaiting Time\n",
    "230 \nCHAPTER 6 Normal Probability Distributions\nStandard Normal Distribution. In Exercises 13–16, find the indicated z score. The \ngraph depicts the standard normal distribution of bone density scores with mean 0 and \n standard deviation 1.\n13. \n0\n0.8907\nz\n \n14. \nz 0\n0.3050\n15. \nz\n0\n0.9265\n \n16. \nz\n0\n0.2061\nStandard Normal Distribution. In Exercises 17–36, assume that a randomly selected \nsubject is given a bone density test. Those test scores are normally distributed with a mean \nof 0 and a standard deviation of 1. In each case, draw a graph, then find the probability of \nthe given bone density test scores. If using technology instead of Table A-2, round answers \nto four decimal places.\n17. Less than -1.23. \n18. Less than -1.96.\n19. Less than 1.28. \n20. Less than 2.56.\n21. Greater than 0.25. \n22. Greater than 0.18.\n23. Greater than -2.00. \n24. Greater than –3.05.\n25. Between 2.00 and 3.00. \n26. Between 1.50 and 2.50.\n27. Between and -2.55 and -2.00. \n28. Between -2.75 and –0.75.\n29. Between -2.00 and 2.00. \n30. Between -3.00 and 3.00.\n31. Between -1.00 and 5.00. \n32. Between -4.27 and 2.34.\n33. Less than 4.55. \n34. Greater than -3.75.\n35. Greater than 0. \n36. Less than 0.\nFinding Bone Density Scores. In Exercises 37–40 assume that a randomly selected sub-\nject is given a bone density test. Bone density test scores are normally distributed with a mean \nof 0 and a standard deviation of 1. In each case, draw a graph, and then find the bone den-\nsity test score corresponding to the given information. Round results to two decimal places.\n37. Find P99, the 99th percentile. This is the bone density score separating the bottom 99% \nfrom the top 1%.\n38. Find P10, the 10th percentile. This is the bone density score separating the bottom 10% \nfrom the top 90%.\n39. If bone density scores in the bottom 2% and the top 2% are used as cutoff points for levels \nthat are too low or too high, find the two readings that are cutoff values.\n40. Find the bone density scores that can be used as cutoff values separating the lowest 3% and \nhighest 3%.\n",
    "6-2 Real Applications of Normal Distributions \n231\nCritical Values. In Exercises 41–44, find the indicated critical value. Round results to two \ndecimal places.\n41. z0.10    42. z0.02    43. z0.04    44. z0.15\nBasis for the Range Rule of Thumb and the Empirical Rule. In Exercises 45–48, find \nthe indicated area under the curve of the standard normal distribution; then convert it to a \npercentage and fill in the blank. The results form the basis for the range rule of thumb and \nthe empirical rule introduced in Section 3-2.\n45. About t \n % of the area is between z = -1 and z = 1 (or within 1 standard devia-\ntion of the mean).\n46. About % of the area is between z = -2 and z = 2 (or within 2 standard deviations of the \nmean).\n47. About % \n of the area is between z = -3 and z = 3 (or within 3 standard devia-\ntions of the mean).\n48. About %  \n of the area is between z = -3.5 and z = 3.5 (or within 3.5 standard \ndeviations of the mean).\n49. Significance For bone density scores that are normally distributed with a mean of 0 and a \nstandard deviation of 1, find the percentage of scores that are\na. significantly high (or at least 2 standard deviations above the mean).\nb. significantly low (or at least 2 standard deviations below the mean).\nc. not significant (or less than 2 standard deviations away from the mean).\n50. Distributions In a continuous uniform distribution,\nm = minimum +  \n maximum\n2\n and s = range\n212\na. Find the mean and standard deviation for the distribution of the waiting times represented in \nFigure 6-2, which accompanies Exercises 5–8.\nb. For a continuous uniform distribution with m = 0 and s = 1, the minimum is - 23 and \nthe maximum is 23. For this continuous uniform distribution, find the probability of randomly \nselecting a value between -1 and 1, and compare it to the value that would be obtained by in-\ncorrectly treating the distribution as a standard normal distribution. Does the distribution affect \nthe results very much?\n6-1 Beyond the Basics \nKey Concept Now we really get real as we extend the methods of the previous section \nso that we can work with any nonstandard normal distribution (with a mean different \nfrom 0 and>or a standard deviation different from 1). The key is a simple conversion \n(Formula 6-2) that allows us to “standardize” any normal distribution so that x values \ncan be transformed to z scores; then the methods of the preceding section can be used.\n6-2 \nReal Applications of Normal Distributions\n",
    "232 \nCHAPTER 6 Normal Probability Distributions\nFORMULA 6-2\nz = x - m\ns\n  (round z scores to 2 decimal places)\nFigure 6-11 illustrates the conversion from a nonstandard to a standard normal \ndistribution. The area in any normal distribution bounded by some score x (as in \nFigure 6-11a) is the same as the area bounded by the corresponding z score in the \nstandard normal distribution (as in Figure 6-11b).\nx\nm\nm\ns\nz 5 x 2\nz\nP\nP\n0\n(b) Standard\n \nNormal Distribution\n(a) Nonstandard\n \nNormal Distribution\nFIGURE 6-11 Converting Distributions\nSome calculators and software do not require the use of Formula 6-2 to convert to \nz scores because probabilities can be found directly. However, if using Table A-2, we \nmust first convert values to standard z scores.\nWhen finding areas with a nonstandard normal distribution, use the following \nprocedure.\nProcedure for Finding Areas with a Nonstandard Normal Distribution\n1. Sketch a normal curve, label the mean and any specific x values, and then shade \nthe region representing the desired probability.\n2. For each relevant value x that is a boundary for the shaded region, use Formula 6-2 \nto convert that value to the equivalent z score. (With many technologies, this step \ncan be skipped.)\n3. Use technology (software or a calculator) or Table A-2 to find the area of \nthe shaded region. This area is the desired probability.\nThe following example illustrates the above procedure.\nEXAMPLE 1   What Is the Proportion of Adult Males with Pulse \nRates Greater Than 100 Bpm?\nIn the Chapter Problem we noted that pulse rates of adult males are normally dis-\ntributed with a mean of 69.6 bpm and a standard deviation of 11.3 bpm. Find the \nproportion of adult males with a pulse rate greater than 100 bpm. These males are \nconsidered to be at a high risk of stroke, heart disease, or cardiac death.\nSOLUTION\nStep 1: See Figure 6-12, which incorporates this information: Men have pulse rates \nthat are normally distributed with a mean of 69.6 bpm and a standard deviation of \n11.3 bpm. The shaded region represents the men with pulse rates above 100 bpm.\n",
    "6-2 Real Applications of Normal Distributions \n233\n \n0.0036\n100\nm 5 69.6\nx (pulse rate)\nz 5 0\nz 5 2.69\nz scale\nFIGURE 6-12 Pulse Rates of Men\nStep 2: We can convert a pulse rate of 100 bpm to the z score of 2.69 by using \n Formula 6-2 as follows:\nz = x - m\ns\n= 100 - 69.6\n11.3\n= 2.69 1rounded to two decimal places2\nStep 3: Technology: Technology can be used to find that the area to the right \nof 100 bpm in Figure 6-12 is 0.0036. (With many technologies, Step 2 can be \nskipped.)\nTable A-2: Use Table A-2 to find that the cumulative area to the left of z = 2.69 \nis 0.9964. (Remember, Table A-2 is designed so that all areas are cumulative areas \nfrom the left.) Because the total area under the curve is 1, it follows that the shaded \narea in Figure 6-12 is 1 - 0.9964 = 0.0036.\nINTERPRETATION\nThe proportion of men with pulse rates above 100 bpm is 0.0036, which is roughly \n4 men in a thousand. This is a very rare event, so an adult male presenting with a \npulse rate above 100 bpm is extremely rare, or there is some medical condition that \nis causing the high pulse rate.\nEXAMPLE 2  Normal Pulse Rates\nNormal pulse rates are generally considered to be between 60 bpm and 100 bpm.\nGiven that pulse rates of adult males are normally distributed with a mean of \n69.6 bpm and a standard deviation of 11.3 bpm, find the percentage of males with \nnormal pulse rates.\nSOLUTION\nFigure 6-13 shows the shaded region representing men with pulse rates between \n60 bpm and 100 bpm.\nStep 1: See Figure 6-13 on the next page, which incorporates this information:  \nMen have pulse rates that are normally distributed with a mean of 69.6 bpm and a \nstandard deviation of 11.3 bpm. The shaded region represents the men with pulse \nrates between 60 bpm and 100 bpm.\ncontinued\nHigh Cost of Low Quality\nThe Federal \nDrug Adminis-\ntration recently \nreached an \nagreement \nwhereby a \npharmaceutical \ncompany, the Schering-Plough \nCorporation, would pay a record \n$500 million for failure to cor-\nrect problems in manufactur-\ning drugs. According to a New \nYork Times article by Melody \nPetersen, “Some of the problems \nrelate to the lack of controls that \nwould identify faulty medicines, \nwhile others stem from outdated \nequipment. They involve some \n200 medicines, including Claritin, \nthe allergy medicine that is \nSchering’s top-selling product.”\nh\ni\nPl\nh\n",
    "234 \nCHAPTER 6 Normal Probability Distributions\nStep 2: With some technologies, the shaded area in Figure 6-13 can be found \n directly and it is not necessary to convert the x scores of 60 bpm and 100 bpm to  \nz scores. (See Step 3.)\nIf using Table A-2, we cannot find the shaded area directly, but we can find it \nindirectly by using the same procedures from Section 6-1, as follows: (1) Find the \ncumulative area from the left up to 100 bpm (or z = 2.69); (2) find the cumulative \narea from the left up to 60 bpm (or z = -0.85); (3) find the difference between \nthose two areas. The pulse rates of 100 bpm and 60 bpm are converted to z scores \nby using Formula 6-2 as follows:\nFor x = 100 bpm: z = x - m\ns\n= 100 - 69.6\n11.3\n= 2.69 \n1z = 2.69 yields an area of 0.9964.2\nFor x = 60 bpm: z = x - m\n11.3\n= 60 - 69.6\n11.3\n= -0.85\n1z = -0.85 yields an area of 0.1977.2\nStep 3: Technology: Technology will show that the shaded area in Figure 6-13 is \n0.7986.\nTable A-2: Refer to Table A-2 with z = 2.69 and find that the cumulative area to \nthe left of z = 2.69 is 0.9964. (Remember, Table A-2 is designed so that all areas \nare cumulative areas from the left.) Table A-2 also shows that z = -0.85 corre-\nsponds to an area of 0.1977. Because the areas of 0.9964 and 0.1977 are cumulative \nareas from the left, we find the shaded area in Figure 6-13 as follows:\nShaded area in Figure 6@13 = 0.9964 - 0.1977 = 0.7987\nThere is a small discrepancy between the area of 0.7986 found from technology \nand the area of 0.7987 found from Table A-2. The area obtained from technology \nis more accurate because it is based on unrounded z scores, whereas Table A-2 \nrequires z scores rounded to two decimal places.\nINTERPRETATION\nExpressing the result as a percentage, we conclude that about 80% of men have \npulse rates between 60 bpm and 100 bpm.\n 0.7986\n100\n60\nm 5 69.6\nx (pulse rate)\nz 5 0\nz 5 2.69\nz 5 20.85\nz scale\nFIGURE 6-13 Pulse Rates of Men\n",
    "6-2 Real Applications of Normal Distributions \n235\nFinding Values from Known Areas\nHere are helpful hints for those cases in which the area (or probability or percentage) \nis known and we must find the relevant value(s):\n1. Graphs are extremely helpful in visualizing, understanding, and successfully \nworking with normal probability distributions, so they should always be \nused.\n2. Don’t confuse z scores and areas. Remember, z scores are distances along the \nhorizontal scale, but areas are regions under the normal curve. Table A-2 lists \nz scores in the left columns and across the top row, but areas are found in the \nbody of the table.\n3. Choose the correct (right>left) side of the graph. A value separating the top \n10% from the others will be located on the right side of the graph, but a value \nseparating the bottom 10% will be located on the left side of the graph.\n4. A z score must be negative whenever it is located in the left half of the normal \ndistribution.\n5. Areas (or probabilities) are always between 0 and 1, and they are never \nnegative.\nProcedure for Finding Values from Known Areas or Probabilities\n1. Sketch a normal distribution curve, write the given probability or percent-\nage in the appropriate region of the graph, and identify the x value(s) being \nsought.\n2. Use technology. If technology is not available, use Table A-2 by referring to \nthe body of Table A-2 to find the area to the left of x; then identify the z score \ncorresponding to that area.\n3. If you know z and must convert to the equivalent x value, use Formula 6-2 by \nentering the values for m, s, and the z score found in Step 2; then solve for x. \nBased on Formula 6-2, we can solve for x as follows:\nx = m + 1z # s2  \n1another form of Formula 6@22\nc\n(If z is located to the left of the mean, be sure that it is a negative number.)\n4. Refer to the sketch of the curve to verify that the solution makes sense in \nthe context of the graph and in the context of the problem.\nThe following example uses this procedure for finding a value from a known area.\nEXAMPLE 3  Pulse Rates\nGiven that pulse rates of adult males are normally distributed with a mean of \n69.6 bpm and a standard deviation of 11.3 bpm, find the pulse rate that separates the \nhighest 1% from the lowest 99%. That is, find P99.\nSOLUTION\nStep 1: Figure 6-14 on the next page shows the normal distribution with the pulse \nrate x that we want to identify. The shaded area represents the lowest 99% of the \npulse rates.\ncontinued\n",
    "236 \nCHAPTER 6 Normal Probability Distributions\nTable A-2: If using Table A-2, search for an area of 0.9900 in the body of the table. \nThe area of 0.9900 corresponds to z = 2.33.\nStep 3: With z = 2.33, m = 69.6 bpm, and s = 11.3 bpm, we can solve for x by us-\ning Formula 6-2:\nz = x - m\ns  becomes 2.33 = x - 69.6\n11.3\nThe result of x = 95.929 bpm can be found directly or by using the following ver-\nsion of Formula 6-2:\nx = m + 1z # s2 = 69.6 + 12.33 # 11.32 = 95.929 bpm\nStep 4: The solution of x = 95.9 bpm (rounded) in Figure 6-14 is reasonable be-\ncause it is greater than the mean of 69.6 bpm.\nINTERPRETATION\nThe male pulse rate of 95.9 (rounded) separates the top 1% from the bottom 99%.\n \n0.99\nx 5 ?\nm 5 69.6\nx (pulse rate)\nz 5 0\nz 5 2.83\nz scale\nFIGURE 6-14 Finding the 99th Percentile\nStep 2: Technology: Technology will provide the value of x in Figure 6-14. For \nexample, see the accompanying Excel display showing that x = 95.88773098 bpm, \nor 95.9 bpm when rounded.\n Excel\nSignificance\nIn Chapter 4 we saw that probabilities can be used to determine whether values are \nsignificantly high or significantly low. Chapter 4 referred to x successes among n tri-\nals, but we can adapt those criteria to apply to continuous variables as follows:\nSigniﬁcantly high: The value x is signiﬁcantly high if P(x or greater) … 0.05.*\nSigniﬁcantly low: The value x is signiﬁcantly low if P(x or less) … 0.05.*\n*The value of 0.05 is not absolutely rigid, and other values such as 0.01 could be used instead.\n",
    "6-2 Real Applications of Normal Distributions \n237\nStep 2: Technology: Technology will show that the values of x in Figure 6-15 are \n53.4 beats per minute and 94.6 beats per minute when rounded.\nTable A-2: If using Table A-2, we must work with cumulative areas from the left. \nFor the leftmost value of x, the cumulative area from the left is 0.05, so search for \nan area of 0.05 in the body of the table to get z = -1.645 (identified by the aster-\nisk between 0.0505 and 0.0495). For the rightmost value of x, the cumulative area \nfrom the left is 0.95, so search for an area of 0.9500 in the body of the table to get \nz = 1.645 (identified by the asterisk between 0.9495 and 0.9505). Having found \nthe two z scores, we now proceed to convert them to pulse rates.\nStep 3: We now solve for the two values of x by using Formula 6-2 directly or by \nusing the following version of Formula 6-2:\nLeftmost value of x:  \nx = m + 1z # s2 = 74.0 + 1-1.645 # 12.52 = 53.4\nRightmost value of x: x = m + 1z # s2 = 74.0 + 11.645 # 12.52 = 94.6\nStep 4: Referring to Figure 6-15, we see that the leftmost value of x = 53.4 is rea-\nsonable because it is less than the mean of 74.0. Also, the rightmost value of 94.6 is \nreasonable because it is above the mean of 74.0.\nINTERPRETATION\nHere are the pulse rates of women that are significant:\n \n■Significantly low: 53.4 beats per minute or lower\n \n■Significantly high: 94.6 beats per minute or higher\nPhysicians could use these results to investigate health issues that could cause pulse \nrates to be significantly low or significantly high.\n0.05\nx 5 ?\nx 5 ?\nm 5 74.0\n0.05\nFIGURE 6-15 Pulse Rates of Women\nEXAMPLE 4   Significantly Low or Significantly High Female \nPulse Rates\nUse the preceding criteria to identify pulse rates of women that are significantly low \nor significantly high. Based on Data Set 1 “Body Data” in Appendix B, assume that \nwomen have normally distributed pulse rates with a mean of 74.0 beats per minute \nand a standard deviation of 12.5 beats per minute.\nSOLUTION\nStep 1: We begin with the graph shown in Figure 6-15. We have entered the mean of \n74.0, and we have identified the x values separating the lowest 5% and the highest 5%.\n",
    "238 \nCHAPTER 6 Normal Probability Distributions\nFinding x Values>Areas\nAccess tech instructions, videos, and data sets at www.TriolaStats.com\nTECH CENTER \nStatistical Literacy and Critical Thinking \n1. Birth Weights Based on Data Set 3 “Births” in Appendix B, birth weights are normally \ndistributed with a mean of 3152.0 g and a standard deviation of 693.4 g.\na. What are the values of the mean and standard deviation after converting all birth weights to \nz scores using z = 1x - m2>s?\nb. The original birth weights are in grams. What are the units of the corresponding z scores?\n2. Birth Weights Based on Data Set 3 “Births” in Appendix B, birth weights are normally \ndistributed with a mean of 3152.0 g and a standard deviation of 693.4 g.\na. For the bell-shaped graph, what is the area under the curve?\nb. What is the value of the median?\nc. What is the value of the mode?\nd. What is the value of the variance?\n3. Normal Distributions What is the difference between a standard normal distribution and a \nnonstandard normal distribution?\n4. Random Digits Computers are commonly used to randomly generate digits of telephone \nnumbers to be called when conducting the California Health Survey. Can the methods of this \nsection be used to find the probability that when one digit is randomly generated, it is less than \n3? Why or why not? What is the probability of getting a digit less than 3?\nIQ Scores. In Exercises 5–8, find the area of the shaded region. The graphs depict IQ \nscores of adults, and those scores are normally distributed with a mean of 100 and a stan-\ndard deviation of 15 (as on the Wechsler IQ test).\n5. \n118\n \n6. \n91\n7. \n79\n133\n \n8. \n124\n112\n6-2 Basic Skills and Concepts\n",
    "6-2 Real Applications of Normal Distributions \n239\nIQ Scores. In Exercises 9–12, find the indicated IQ score and round to the nearest whole \nnumber. The graphs depict IQ scores of adults, and those scores are normally distributed \nwith a mean of 100 and a standard deviation of 15 (as on the Wechsler IQ test).\n9. \nx\n0.9918\n \n10. \nx\n0.1587\n11. \nx\n0.9798\n \n12. \nx\n0.9099\nFemale Pulse Rates. In Exercises 13–20, assume that an adult female is randomly \n selected. Females have pulse rates that are normally distributed with a mean of 74.0 beats \nper minute and a standard deviation of 12.5 beats per minute (based on Data Set 1 “Body \nData” in Appendix B). (Hint: Draw a graph in each case.)\n13. Find the probability of a pulse rate less than 100 beats per minute.\n14. Find the probability of a pulse rate greater than 80 beats per minute.\n15. Find the probability of a pulse rate between 60 beats per minute and 70 beats per minute.\n16. Find the probability of a pulse rate between 70 beats per minute and 90 beats per minute.\n17. Find P90, which is the pulse rate separating the bottom 90% from the top 10%.\n18.  Find the first quartile Q1, which is the pulse rate separating the bottom 25% from the \ntop 75%.\n19. Significance Instead of using 0.05 for identifying significant values, use the criteria \nthat a value x is significantly high if P(x or greater) … 0.01 and a value is significantly low \nif P(x or less) … 0.01. Find the pulse rates separating significant values from those that are \nnot significant. Using these criteria, is a pulse rate of 102 beats per minute significantly high?\n20. Significance Instead of using 0.05 for identifying significant values, use the criteria \nthat a value x is significantly high if P(x or greater) … 0.025 and a value is significantly low \nif P(x or less) … 0.025. Find the pulse rates separating significant values from those that are \nnot significant. Using these criteria, is a pulse rate of 48 beats per minute significantly low?\n21. Eye Contact In a study of facial behavior, people in a control group are timed for eye con-\ntact in a 5-minute period. Their times are normally distributed with a mean of 184.0  seconds \nand a standard deviation of 55.0 seconds (based on data from “Ethological Study of Facial \n Behavior in Nonparanoid and Paranoid Schizophrenic Patients,” by Pittman, Olk, Orr, and \nSingh, Psychiatry, Vol. 144, No. 1). For a randomly selected person from the control group, \nfind the probability that the eye contact time is greater than 230.0 seconds, which is the mean \nfor paranoid schizophrenics. Based on personal experience, does the result appear to be the \nproportion of people who are paranoid schizophrenics?\n",
    "240 \nCHAPTER 6 Normal Probability Distributions\n22. Body Temperatures Based on sample results in Data Set 2 “Body Temperatures” in \nAppendix B, assume that human body temperatures are normally distributed with a mean of \n98.20°F and a standard deviation of 0.62°F.\na. According to emedicinehealth.com, a body temperature of 100.4oF or above is considered \nto be a fever. What percentage of normal and healthy persons would be considered to have a \nfever? Does this percentage suggest that a cutoff of 100.4oF is appropriate?\nb. Physicians want to select a minimum temperature for requiring further medical tests. What \nshould that temperature be if we want only 2.0% of healthy people to exceed it? (Such a result \nis a false positive, meaning that the test result is positive, but the subject is not really sick.)\n23.  Low Birth Weight The University of Maryland Medical Center considers “low birth \nweights” to be those less than 5.5 lb or 2495 g. Birth weights are normally distributed with a mean \nof 3152.0 g and a standard deviation of 693.4 g (based on Data Set 3 “Births” in Appendix B).\na. If a birth weight is randomly selected, what is the probability that it is a “low birth weight”?\nb. Find the weights considered to be significantly low using the criterion of a probability of \n0.05 or less. How do these results compare to the criterion of 2495 g?\nc. Compare the results from parts (a) and (b).\n24. Durations of Pregnancies The lengths of pregnancies are normally distributed with a \nmean of 268 days and a standard deviation of 15 days.\na. In a letter to “Dear Abby,” a wife claimed to have given birth 308 days after a brief visit from \nher husband, who was working in another country. Find the probability of a pregnancy lasting \n308 days or longer. What does the result suggest?\nb. If we stipulate that a baby is premature if the duration of pregnancy is in the lowest 3%, \nfind the duration that separates premature babies from those who are not premature. Premature \nbabies often require special care, and this result could be helpful to hospital administrators in \nplanning for that care.\nLarge Data Sets. In Exercises 25 and 26, refer to the data sets in Appendix B and use \nsoftware or a calculator.\n25. Diastolic Blood Pressure of Males Refer to Data Set 1 in Appendix B and use the \ndiastolic blood pressures of males.\na. Find the mean and standard deviation, and verify that the data have a distribution that is \nroughly normal. Round the results using three decimal places.\nb. Treating the unrounded values of the mean and standard deviation as parameters, and assum-\ning that male diastolic blood pressures are normally distributed, find diastolic blood pressures \nseparating the lowest 2.5% and the highest 2.5%. These values could be helpful when physi-\ncians try to determine whether diastolic blood pressures are significantly low or significantly \nhigh.\n26.  Diastolic Blood Pressure of Females Repeat the preceding exercise using females \ninstead of males.\n27. Outliers For the purposes of constructing modified boxplots as described in Section 3-3, \noutliers are defined as data values that are above Q3 by an amount greater than 1.5 *  IQR or \nbelow Q1 by an amount greater than 1.5 *  IQR, where IQR is the interquartile range. Using \nthis definition of outliers, find the probability that when a value is randomly selected from a \nnormal distribution, it is an outlier.\n6-2 Beyond the Basics\n",
    "6-3 Sampling Distributions and Estimators \n241\nA Short Story Among the population of all adults, exactly 40% have brown eyes (the \nauthors just know this). In a survey of 1000 adults, 42% of the subjects were observed \nto have brown eyes. Being so intrigued by this, 50,000 people became so enthusias-\ntic that they each conducted their own individual survey of 1000 randomly selected \nadults. Each of these 50,000 new surveyors reported the percentage that they found, \nwith results such as 38%, 39%, and 43%. The authors obtained each of the 50,000 \nKey Concept We now consider the concept of a sampling distribution of a statistic. \nInstead of working with values from the original population, we want to focus on \nthe values of statistics (such as sample proportions or sample means) obtained from \nthe population. Figure 6-16 shows the key points that we need to know, so try really, \nreally hard to understand the story that Figure 6-16 tells.\n6-3 \nSampling Distributions and Estimators\nProportions\nSample 1\nSample 2\nSample 3\n(Population Proportion is p)\nDistribution of\nSample Proportions\nSample\nProportions\nSample\nSample proportions tend to\nhave a normal distribution\npˆ pˆ pˆ pˆ pˆ\npˆ pˆ pˆ\npˆ pˆ\npˆ\npˆ\npˆ\npˆ\npˆ pˆ pˆ pˆ pˆ\npˆ\np\nˆ\n•\n•\n•\n1pˆ\n2pˆ\n3pˆ\nSampling\nProcedure:\nRandomly select n\nvalues and ﬁnd\nthe proportion p for\neach sample.\nˆ\nMeans\nSample 1\nSample 2\nSample 3\n(Population Mean is m)\nDistribution of\nSample Means\nSample Means\nSample\nSample means tend to\nhave a normal distribution\n•\n•\n•\nSampling\nProcedure:\nRandomly select n\nvalues and ﬁnd\nthe mean x for\neach sample.\nx x x x x x\nx x x x\nx x x\nx x\nx\nx\nX1\nX2\nX3\nx\nx\nx\nx\nx\nVariances\nSample 1\nSample 2\nSample 3\n(Population Variance is s2)\nDistribution of\nSample Variances\nSample\nVariances\nSample\nSample variances tend to\nhave a skewed distribution\n•\n•\n•\nSampling\nProcedure:\nRandomly select n\nvalues and ﬁnd\nthe variance s2 for\neach sample.\ns2\n1\ns2\n2\ns2\n3\ns2\ns2 s2\ns2 s2 s2\ns2s2s2s2s2s2\ns2s2s2s2s2s2\ns2 s2 s2 s2\ns2s2s2s2s2\nFIGURE 6-16 General Behavior of Sampling Distributions\ncontinued\n",
    "242 \nCHAPTER 6 Normal Probability Distributions\nsample percentages, changed them to proportions, and then they constructed the his-\ntogram shown in Figure 6-17. Notice anything about the shape of the histogram? It’s \nnormal. Notice anything about the mean of the sample proportions? They are centered \nabout the value of 0.40, which happens to be the population proportion. Moral: When \nsamples of the same size are taken from the same population, the following two prop-\nerties apply:\n1. Sample proportions tend to be normally distributed.\n2. The mean of sample proportions is the same as the population mean.The \nimplications of the preceding properties will be extensive in the chapters \nthat follow.\nFIGURE 6-17 Histogram of 50,000 Sample Proportions\nLet’s formally define sampling distribution, the main character in the preceding short \nstory.\nDEFINITION\nThe sampling distribution of a statistic (such as a sample proportion or sample \nmean) is the distribution of all values of the statistic when all possible samples of \nthe same size n are taken from the same population. (The sampling distribution of a \nstatistic is typically represented as a probability distribution in the format of a prob-\nability histogram, formula, or table.)\nSampling Distribution of Sample Proportion\nThe preceding general definition of a sampling distribution of a statistic can now be \nrestated for the specific case of a sample proportion:\nDEFINITION\nThe sampling distribution of the sample proportion is the distribution of sample \nproportions (or the distribution of the variable pn), with all samples having the same \nsample size n taken from the same population. (The sampling distribution of the \nsample proportion is typically represented as a probability distribution in the format \nof a probability histogram, formula, or table.)\nWe need to distinguish between a population proportion p and a sample proportion, \nand the following notation is common and will be used throughout the remainder of \nthis book, so it’s very important.\n",
    "6-3 Sampling Distributions and Estimators \n243\nNotation for Proportions\np = population proportion\npn = sample proportion\nHINT pn is pronounced “p-hat.” When symbols are used above a letter, as in x and \npn, they represent statistics, not parameters.\nBehavior of Sample Proportions\n1. The distribution of sample proportions tends to approximate a normal distribution.\n2. Sample proportions target the value of the population proportion in the \nsense that the mean of all of the sample proportions pn is equal to the popu-\nlation proportion p; the expected value of the sample proportion is equal to \nthe population proportion.\nEXAMPLE 1  Sampling Distribution of the Sample Proportion\nConsider repeating this process: Roll a die 5 times and find the proportion of odd \nnumbers (1 or 3 or 5). What do we know about the behavior of all sample propor-\ntions that are generated as this process continues indefinitely?\nSOLUTION\nFigure 6-18 illustrates a process of rolling a die 5 times and finding the proportion of \nodd numbers. (Figure 6-18 shows results from repeating this process 10,000 times, \nbut the true sampling distribution of the sample proportion involves repeating the \nprocess indefinitely.) Figure 6-18 shows that the sample proportions are approxi-\nmately normally distributed. (Because the values of 1, 2, 3, 4, 5, 6 are all equally \nlikely, the proportion of odd numbers in the population is 0.5, and Figure 6-18 shows \nthat the sample proportions have a mean of 0.50.)\nProportions\nSample 1\nSample 2\nSample 3\n(Population Proportion is p 5 0.5)\nDistribution of\nSample Proportions\nSample\nProportions\nSample\np 5 0.5\nSample proportions are\napproximately normal\n•\n•\n•\n0.2\n0.4\n0.8\nSampling Procedure:\nRoll a die 5 times and\nﬁnd the proportion p\nof odd numbers for\neach sample.\nˆ\nFIGURE 6-18 Sample Proportions from 10,000 Trials\n",
    "244 \nCHAPTER 6 Normal Probability Distributions\nBehavior of Sample Means\n1. The distribution of sample means tends to be a normal distribution. (This will \nbe discussed further in the following section, but the distribution tends to be-\ncome closer to a normal distribution as the sample size increases.)\n2. The sample means target the value of the population mean. (That is, the \nmean of the sample means is the population mean. The expected value of \nthe sample mean is equal to the population mean.)\nDEFINITION\nThe sampling distribution of the sample mean is the distribution of all possible \nsample means (or the distribution of the variable x), with all samples having the \nsame sample size n taken from the same population. (The sampling distribution of \nthe sample mean is typically represented as a probability distribution in the format \nof a probability histogram, formula, or table.)\nEXAMPLE 2  Sampling Distribution of the Sample Mean\nA pediatrician has three patients with measles and they are ages 4, 5, and 9.  \nConsider the population of {4, 5, 9}. If two ages are randomly selected with replace-\nment from the population {4, 5, 9}, identify the sampling distribution of the sample \nmean by creating a table representing the probability distribution of the sample mean. \nDo the values of the sample mean target the value of the population mean?\nSOLUTION\nIf two values are randomly selected with replacement from the population {4, 5, 9}, \nthe leftmost column of Table 6-2 lists the nine different possible samples. The second \ncolumn lists the corresponding sample means. The nine samples are equally likely \nwith a probability of 1>9. We saw in Section 5-1 that a probability distribution gives \nthe probability for each value of a random variable, as in the second and third col-\numns of Table 6-2. The second and third columns of Table 6-2 represent the sampling \ndistribution of the sample mean. In Table 6-2, some of the sample mean values are \nrepeated, so we combined them in Table 6-3.\nTABLE 6-2 Sampling Distribution  \nof Mean\nSample\nSample Mean x\nProbability\n4, 4\n4.0\n1>9\n4, 5\n4.5\n1>9\n4, 9\n6.5\n1>9\n5, 4\n4.5\n1>9\n5, 5\n5.0\n1>9\n5, 9\n7.0\n1>9\n9, 4\n6.5\n1>9\n9, 5\n7.0\n1>9\n9, 9\n9.0\n1>9\nTABLE 6-3 Sampling Distribution \nof Mean (Condensed)\nSample Mean x\nProbability\n4.0\n1>9\n4.5\n2>9\n5.0\n1>9\n6.5\n2>9\n7.0\n2>9\n9.0\n1>9\nSampling Distribution of the Sample Mean\nWe now consider sample means.\n",
    "6-3 Sampling Distributions and Estimators \n245\nIf we were to create a probability histogram from Table 6-2, it would not have \nthe bell shape that is characteristic of a normal distribution, but that’s because we are \nworking with such small samples. If the population of {4, 5, 9} were much larger \nand if we were selecting samples much larger than n = 2, as in this example, we \nwould get a probability histogram that is much closer to being bell-shaped, indicat-\ning a normal distribution, as in Example 3.\nINTERPRETATION\nBecause Table 6-3 lists the possible values of the sample mean along with their cor-\nresponding probabilities, Table 6-3 is an example of a sampling distribution of a \nsample mean.\nThe value of the mean of the population {4, 5, 9} is m = 6.0. Using either \nTable 6-2 or 6-3, we could calculate the mean of the sample values and we get 6.0. \nBecause the mean of the sample means (6.0) is equal to the mean of the population \n(6.0), we conclude that the values of the sample mean do target the value of the \npopulation mean. It’s unfortunate that this sounds so much like doublespeak, but \nthis illustrates that the mean of the sample means is equal to the population mean m.\nHINT Read the last sentence of the above paragraph a few times until it makes sense.\nEXAMPLE 3  Sampling Distribution of the Sample Mean\nConsider repeating this process: Roll a die 5 times to randomly select 5 values from \nthe population {1, 2, 3, 4, 5, 6}, then find the mean x of the results. What do we \nknow about the behavior of all sample means that are generated as this process con-\ntinues indefinitely?\nSOLUTION\nFigure 6-19 illustrates a process of rolling a die 5 times and finding the mean of the \nresults. Figure 6-19 shows results from repeating this process 10,000 times, but the true \nsampling distribution of the mean involves repeating the process indefinitely. Because \nthe values of 1, 2, 3, 4, 5, 6 are all equally likely, the population has a mean of m = 3.5. \nThe 10,000 sample means included in Figure 6-19 have a mean of 3.5. If the process \nis continued indefinitely, the mean of the sample means will be 3.5. Also, Figure 6-19 \nshows that the distribution of the sample means is approximately a normal distribution.\nMeans\nSample 1\nSample 2\nSample 3\n(Population Mean is m 5 3.5)\nDistribution of\nSample Means\nSample\nMeans\nSample\nm 5 3.5\nSample means are\napproximately normal\n•\n•\n•\n3.4\n4.4\n2.8\nSampling Procedure:\nRoll a die 5 times and\nﬁnd the mean x for\neach sample.\nFIGURE 6-19 Sample Means from 10,000 Trials\n",
    "246 \nCHAPTER 6 Normal Probability Distributions\nSampling Distribution of the Sample Variance\nLet’s now consider the sampling distribution of sample variances.\nDEFINITION\nThe sampling distribution of the sample variance is the distribution of sample \nvariances (the variable s2), with all samples having the same sample size n taken \nfrom the same population. (The sampling distribution of the sample variance is typi-\ncally represented as a probability distribution in the format of a table, probability \nhistogram, or formula.)\nCAUTION When working with population standard deviations or variances, be \nsure to evaluate them correctly. In Section 3-2 we saw that the computations for \npopulation standard deviations or variances involve division by the population size \nN instead of n - 1, as shown here.\n Population standard deviation:  s = B\nΣ1x - m2 2\nN\n \n Population variance: \n s2 = Σ1x - m2 2\nN\nBecause the calculations are typically performed with software or calculators, be care-\nful to correctly distinguish between the variance of a sample and the variance of a \npopulation.\nBehavior of Sample Variances\n1. The distribution of sample variances tends to be a distribution skewed to the \nright.\n2. The sample variances target the value of the population variance. (That is, \nthe mean of the sample variances is the population variance. The expected \nvalue of the sample variance is equal to the population variance.)\nEXAMPLE 4  Sampling Distribution of the Sample Variance\nConsider repeating this process: Roll a die 5 times and find the variance s2 of the \nresults. What do we know about the behavior of all sample variances that are gener-\nated as this process continues indefinitely?\nSOLUTION\nFigure 6-20 illustrates a process of rolling a die 5 times and finding the variance of \nthe results. Figure 6-20 shows results from repeating this process 10,000 times, but \nthe true sampling distribution of the sample variance involves repeating the process \nindefinitely. Because the values of 1, 2, 3, 4, 5, 6 are all equally likely, the popu-\nlation has a variance of s2 = 2.9, and the 10,000 sample variances included in \nFigure 6-20 have a mean of 2.9. If the process is continued indefinitely, the mean \nof the sample variances will be 2.9. Also, Figure 6-20 shows that the distribution \nof the sample variances is a skewed distribution, not a normal distribution with its \ncharacteristic bell shape.\n",
    "6-3 Sampling Distributions and Estimators \n247\nEstimators: Unbiased and Biased\nThe preceding examples show that sample proportions, means, and variances tend to \ntarget the corresponding population parameters. More formally, we say that sample \nproportions, means, and variances are unbiased estimators. See the following two \ndefinitions.\nDEFINITIONS\nAn estimator is a statistic used to infer (or estimate) the value of a population \nparameter.\nAn unbiased estimator is a statistic that targets the value of the corresponding \npopulation parameter in the sense that the sampling distribution of the statistic has \na mean that is equal to the corresponding population parameter.\nUnbiased Estimators These statistics are unbiased estimators. That is, they each \ntarget the value of the corresponding population parameter (with a sampling distribu-\ntion having a mean equal to the population parameter):\n \n■Proportion pn\n \n■Mean x\n \n■Variance s2\nBiased Estimators These statistics are biased estimators. That is, they do not target \nthe value of the corresponding population parameter:\n \n■Median\n \n■Range\n \n■Standard deviation s\nImportant Note: The sample standard deviations do not target the population \nstandard deviation s, but the bias is relatively small in large samples, so  \ns is often used to estimate S even though s is a biased estimator of s.\nVariances\nSample 1\nSample 2\nSample 3\n(Population Variance is s2 5 2.9)\nDistribution of\nSample Variances\nSample\nVariances\nSample\ns2 5 2.9\nSample variances tend to\nhave a skewed distribution\n•\n•\n•\n1.8\n2.3\n2.2\nSampling Procedure:\nRoll a die 5 times and\nﬁnd the variance s2\nfor each sample.\nFIGURE 6-20 Sample Variances from 10,000 Trials\n",
    "248 \nCHAPTER 6 Normal Probability Distributions\nb. The last two columns of Table 6-4 list the values of the range along with the \ncorresponding probabilities, so the last two columns constitute a table summa-\nrizing the probability distribution. Table 6-4 therefore describes the sampling \ndistribution of the sample range.\n \nc. The mean of the sample ranges in Table 6-4 is 20>9, or 2.2. The population of \n{4, 5, 9} has a range of 9 - 4 = 5. Because the mean of the sample ranges \n(2.2) is not equal to the population range (5), the sample ranges do not target \nthe value of the population range.\n \nd. Because the sample ranges do not target the population range, the sample \nrange is a biased estimator of the population range.\nINTERPRETATION\nBecause the sample range is a biased estimator of the population range, a sample \nrange should generally not be used to estimate the value of the population range.\nEXAMPLE 5  Sampling Distribution of the Sample Range\nAs in Example 2, consider samples of size n = 2 randomly selected from the \n population {4, 5, 9}.\n \na. List the diﬀerent possible samples along with the probability of each sample, \nthen ﬁnd the range for each sample.\n \nb. Describe the sampling distribution of the sample range in the format of a table \nsummarizing the probability distribution.\n \nc. Based on the results, do the sample ranges target the population range, which \nis 9 - 4 = 5?\n \nd. What do these results indicate about the sample range as an estimator of the \npopulation range?\nSOLUTION\na. In Table 6-4 we list the nine diﬀerent possible samples of size n = 2 selected \nwith replacement from the population {4, 5, 9}. The nine samples are equally \nlikely, so each has probability 1>9. Table 6-4 also shows the range for each of \nthe nine samples.\nTABLE 6-4 Sampling Distribution of Range\nSample\nSample Range\nProbability\n4, 4\n0\n1>9\n4, 5\n1\n1>9\n4, 9\n5\n1>9\n5, 4\n1\n1>9\n5, 5\n0\n1>9\n5, 9\n4\n1>9\n9, 4\n5\n1>9\n9, 5\n4\n1>9\n9, 9\n0\n1>9\n",
    "6-3 Sampling Distributions and Estimators \n249\nWhy Sample with Replacement? All of the examples in this section involved sam-\npling with replacement. Sampling without replacement would have the very practi-\ncal advantage of avoiding wasteful duplication whenever the same item is selected \nmore than once. Many of the statistical procedures discussed in the following chapters \nare based on the assumption that sampling is conducted with replacement because of \nthese two very important reasons:\n1. When selecting a relatively small sample from a large population, it makes no \nsignificant difference whether we sample with replacement or without replace-\nment.\n2. Sampling with replacement results in independent events that are unaf-\nfected by previous outcomes, and independent events are easier to analyze \nand result in simpler calculations and formulas.\nStatistical Literacy and Critical Thinking\n1. Births There are about 11,000 births each day in the United States, and the proportion of \nboys born in the United States is 0.512. Assume that each day, 100 births are randomly selected \nand the proportion of boys is recorded.\na. What do you know about the mean of the sample proportions?\nb. What do you know about the shape of the distribution of the sample proportions?\n2.  Sampling with Replacement The Orangetown Medical Research Center randomly se-\nlects 100 births in the United States each day, and the proportion of boys is recorded for each \nsample.\na. Do you think the births are randomly selected with replacement or without replacement?\nb. Give two reasons why statistical methods tend to be based on the assumption that sampling \nis conducted with replacement, instead of without replacement.\n3.  Unbiased Estimators Data Set 3 “Births” in Appendix B includes birth weights of \n400 babies. If we compute the values of sample statistics from that sample, which of the \nfollowing statistics are unbiased estimators of the corresponding population parameters: \nsample mean; sample median; sample range; sample variance; sample standard deviation; \nsample proportion?\n4. Sampling Distribution Data Set 3 “Births” in Appendix B includes a sample of birth \nweights. If we explore this sample of 400 birth weights by constructing a histogram and find-\ning the mean and standard deviation, do those results describe the sampling distribution of the \nmean? Why or why not?\n5.  Good Sample? A geneticist is investigating the proportion of boys born in the world \npopulation. Because she is based in China, she obtains sample data from that country. Is the \nresulting sample proportion a good estimator of the population proportion of boys born world-\nwide? Why or why not?\n6. Physicians There are about 900,000 active physicians in the United States, and they have \nannual incomes with a distribution that is skewed instead of being normal. Many different sam-\nples of 40 physicians are randomly selected, and the mean annual income is computed for each \nsample.\na. What is the approximate shape of the distribution of the sample means (uniform, normal, \nskewed, other)?\nb. What value do the sample means target? That is, what is the mean of all such sample means?\n6-3 Basic Skills and Concepts \n",
    "250 \nCHAPTER 6 Normal Probability Distributions\nIn Exercises 7–10, use the same population of {4, 5, 9} that was used in Examples 2 and 5. As in \nExamples 2 and 5, assume that samples of size n = 2 are randomly selected with replacement.\n7. Sampling Distribution of the Sample Variance\na. Find the value of the population variance s2.\nb. Table 6-2 describes the sampling distribution of the sample mean. Construct a similar table \nrepresenting the sampling distribution of the sample variance s2. Then combine values of s2 that \nare the same, as in Table 6-3 (Hint: See Example 2 on page 244 for Tables 6-2 and 6-3, which \ndescribe the sampling distribution of the sample mean.)\nc. Find the mean of the sampling distribution of the sample variance.\nd. Based on the preceding results, is the sample variance an unbiased estimator of the popula-\ntion variance? Why or why not?\n8. Sampling Distribution of the Sample Standard Deviation For the following, round \nresults to three decimal places.\na. Find the value of the population standard deviation s.\nb. Table 6-2 describes the sampling distribution of the sample mean. Construct a similar table \nrepresenting the sampling distribution of the sample standard deviation s. Then combine values \nof s that are the same, as in Table 6-3. (Hint: See Example 2 on page 244 for Tables 6-2 and 6-3, \nwhich describe the sampling distribution of the sample mean.)\nc. Find the mean of the sampling distribution of the sample standard deviation.\nd. Based on the preceding results, is the sample standard deviation an unbiased estimator of the \npopulation standard deviation? Why or why not?\n9. Sampling Distribution of the Sample Median\na. Find the value of the population median.\nb. Table 6-2 describes the sampling distribution of the sample mean. Construct a similar table \nrepresenting the sampling distribution of the sample median. Then combine values of the me-\ndian that are the same, as in Table 6-3. (Hint: See Example 2 on page 244 for Tables 6-2 and \n6-3, which describe the sampling distribution of the sample mean.)\nc. Find the mean of the sampling distribution of the sample median.\nd. Based on the preceding results, is the sample median an unbiased estimator of the popula-\ntion median? Why or why not?\n10. Sampling Distribution of the Sample Proportion \na. For the population, find the proportion of odd numbers.\nb. Table 6-2 describes the sampling distribution of the sample mean. Construct a similar table \nrepresenting the sampling distribution of the sample proportion of odd numbers. Then combine \nvalues of the sample proportion that are the same, as in Table 6-3. (Hint: See Example 2 on \npage 244 for Tables 6-2 and 6-3, which describe the sampling distribution of the sample mean.)\nc. Find the mean of the sampling distribution of the sample proportion of odd numbers.\nd. Based on the preceding results, is the sample proportion an unbiased estimator of the popu-\nlation proportion? Why or why not?\nIn Exercises 11–14, use the population of {34, 36, 41, 51} of the amounts of caffeine  \n(mg , 12 oz) in Coca-Cola Zero, Diet Pepsi, Dr Pepper, and Mellow Yello Zero. Assume that \nrandom samples of size n = 2 are selected with replacement.\n11. Sampling Distribution of the Sample Mean\na. After identifying the 16 different possible samples, find the mean of each sample, then \nconstruct a table representing the sampling distribution of the sample mean. In the table, \n",
    "6-3 Sampling Distributions and Estimators \n251\ncombine values of the sample mean that are the same. (Hint: See Table 6-3 in Example 2 on \npage 244.)\nb. Compare the mean of the population {34, 36, 41, 51} to the mean of the sampling distribu-\ntion of the sample mean.\nc. Do the sample means target the value of the population mean? In general, do sample means \nmake good estimators of population means? Why or why not?\n12. Sampling Distribution of the Median Repeat Exercise 11 using medians instead of means.\n13. Sampling Distribution of the Range Repeat Exercise 11 using ranges instead of means.\n14. Sampling Distribution of the Variance Repeat Exercise 11 using variances instead \nof means.\n15. Births: Sampling Distribution of Sample Proportion When two births are ran-\ndomly selected, the sample space for genders is bb, bg, gb, and gg (where b = boy and g =\ngirl). Assume that those four outcomes are equally likely. Construct a table that describes the \nsampling distribution of the sample proportion of girls from two births. Does the mean of the \nsample proportions equal the proportion of girls in two births? Does the result suggest that a \nsample proportion is an unbiased estimator of a population proportion?\n16. Births: Sampling Distribution of Sample Proportion For three births, assume that \nthe genders are equally likely. Construct a table that describes the sampling distribution of the \nsample proportion of girls from three births. Does the mean of the sample proportions equal the \nproportion of girls in three births? (Hint: See Exercise 15 for two births.)\n17. MCAT Tests Because they enable efficient procedures for evaluating answers, multiple choice \nquestions are commonly used on standardized tests, such as the MCAT or the GRE Biology test. \nSuch questions typically have five choices, one of which is correct. Assume that you must make \nrandom guesses for two such questions. Assume that both questions have correct answers of “a.”\na. After listing the 25 different possible samples, find the proportion of correct answers in each \nsample; then construct a table that describes the sampling distribution of the sample propor-\ntions of correct responses.\nb. Find the mean of the sampling distribution of the sample proportion.\nc. Is the mean of the sampling distribution [from part (b)] equal to the population proportion of \ncorrect responses? Does the mean of the sampling distribution of proportions always equal the \npopulation proportion?\n18. Hybridization A hybridization experiment begins with four peas having yellow pods and \none pea having a green pod. Two of the peas are randomly selected with replacement from this \npopulation.\na. After identifying the 25 different possible samples, find the proportion of peas with yellow \npods in each of them; then construct a table to describe the sampling distribution of the propor-\ntions of peas with yellow pods.\nb. Find the mean of the sampling distribution.\nc. Is the mean of the sampling distribution [from part (b)] equal to the population proportion of \npeas with yellow pods? Does the mean of the sampling distribution of proportions always equal \nthe population proportion?\n19. Using a Formula to Describe a Sampling Distribution Exercise 15 “Births” re-\nquires the construction of a table that describes the sampling distribution of the proportions of \ngirls from two births. Consider the formula shown here, and evaluate that formula using sample \n6-3 Beyond the Basics \ncontinued\n",
    "252 \nCHAPTER 6 Normal Probability Distributions\nproportions (represented by x) of 0, 0.5, and 1. Based on the results, does the formula describe \nthe sampling distribution? Why or why not?\nP1x2 =\n1\n212 - 2x2!12x2! where x =  0, 0.5, 1\n20. Mean Absolute Deviation Is the mean absolute deviation of a sample a good statistic for \nestimating the mean absolute deviation of the population? Why or why not? (Hint: See Example 5.)\nKey Concept In the preceding section we saw that the sampling distribution of sample \nmeans tends to be a normal distribution as the sample size increases. In this section we \nintroduce and apply the central limit theorem. The central limit theorem allows us to \nuse a normal distribution for some very meaningful and important applications.\n6-4 \nThe Central Limit Theorem\nCENTRAL LIMIT THEOREM\nFor all samples of the same size n with n 7 30, the sampling distribution of x can be \napproximated by a normal distribution with mean m and standard deviation s> 1n.\nGiven any population with any distribution (uniform, skewed, whatever), the dis-\ntribution of sample means x can be approximated by a normal distribution when the \nsamples are large enough with n 7 30. (There are some special cases of very non-\nnormal distributions for which the requirement of n 7 30 isn’t quite enough, so the \nnumber 30 should be higher in those cases, but those cases are relatively rare.)\nEXAMPLE 1  HDL Cholesterol of Females\nFigures 6-21 and 6-22 illustrate the central limit theorem.\n \n■Original data: Figure 6-21 is a histogram of the high-density lipoprotein \n(HDL) cholesterol measures (mg>dL) of the 147 females listed in Data Set \n1 “Body Data” in Appendix B, and those measures have a distribution that is \nskewed to the right instead of being normal.\n \n■Sample means: Figure 6-22 is a histogram of 100 sample means. Each sample \nincludes 100 HDL cholesterol measures of females, and this histogram shows \nthat the sample means have a distribution that is very close to being normal.\nFIGURE 6-21  Nonnormal Distribution: \nHDL Cholesterol from \n147 Women\nFIGURE 6-22  Approximately Normal \nDistribution: Means from \nSamples of Size n = 100 \nof HDL Cholesterol from \nFemales\n",
    "6-4 The Central Limit Theorem \n253\nA Universal Truth Example 1 and the central limit theorem are truly remarkable be-\ncause they describe a rule of nature that works throughout the universe. If we could \nsend a spaceship to a distant planet “in a galaxy far, far away,” and if we collect samples \nof rocks (all of the same large sample size) and weigh them, the sample means would \nhave a distribution that is approximately normal. Think about the significance of that!\nThe following key points form the foundation for estimating population param-\neters and hypothesis testing—topics discussed at length in the following chapters.\nINTERPRETATION\nThe original HDL cholesterol measurements depicted in Figure 6-21 have a skewed \ndistribution, but when we collect samples and compute their means, those sample \nmeans tend to have a distribution that is normal.\nThe Central Limit Theorem and the Sampling Distribution of x\nGiven\n1. Population (with any distribution) has mean m and standard deviation s.\n2. Simple random samples all of the same size n are selected from the population.\nPractical Rules for Real Applications Involving a Sample Mean x\nRequirements: Population has a normal distribution or n + 30:\nMean of all values of x: \n \n  mx = m\nStandard deviation of all values of x: \n \n \nsx =\ns\n1n\nz score conversion of x: \n \n \n  z = x - m\ns\n1n\nOriginal population is not normally distributed and n \" 30: The distribution of x might not be approximated well \nby a normal distribution, and the methods of this section might not apply. Use other methods, such as nonparametric \nmethods or bootstrapping methods (Section 7-4).\nConsiderations for Practical Problem Solving\n1. Check Requirements: When working with the mean from a sample, verify that the normal distribution can be used \nby confirming that the original population has a normal distribution or the sample size is n 7 30.\n2. Individual Value or Mean from a Sample? Determine whether you are using a normal distribution with a single \nvalue x or the mean x from a sample of n values. See the following.\n • Individual value: When working with an individual value from a normally distributed population, use the methods of \nSection 6-2 with z = x - m\ns\n.\n • Mean from a sample of values: When working with a mean for some sample of n values, be sure to use the value of \ns> 1n for the standard deviation of the sample means, so use z = x - m\ns\n1n\n.\nKEY ELEMENTS \n",
    "254 \nCHAPTER 6 Normal Probability Distributions\nThe following new notation is used for the mean and standard deviation of the \ndistribution of x.\nNOTATION FOR THE SAMPLING DISTRIBUTION OF x\nIf all possible simple random samples of size n are selected from a population with \nmean m and standard deviation s, the mean of all sample means is denoted by mx \nand the standard deviation of all sample means is denoted by sx.\nMean of all values of x: \nmx = m\nStandard deviation of all values of x: \nsx =\ns\n1n\nNote: sx is called the standard error of  the mean and is sometimes denoted as SEM.\nApplying the Central Limit Theorem\nMany practical problems can be solved with the central limit theorem. Example 2 \nis a good illustration of the central limit theorem because we can see the difference \nbetween working with an individual value in part (a) and working with the mean for \na sample in part (b). Study Example 2 carefully to understand the fundamental differ-\nence between the procedures used in parts (a) and (b). In particular, note that when\nworking with an individual value, we use z = x - m\ns\n, but when working with the \nmean x for a collection of sample values, we use z = x - m\ns> 1n.\nEXAMPLE 2  Pulse Rates of Women\nIn the Chapter Problem it was noted that women have normally distributed pulse \nrates with a mean of 74.0 bpm and a standard deviation of 12.5 bpm.\n \na. Find the probability that 1 randomly selected woman has a pulse rate greater \nthan 80 bpm.\n \nb. Find the probability that a sample of 16 randomly selected women have a \nmean pulse rate greater than 80 bpm.\n \nc. Given that part (b) involves a sample size that is not larger than 30, why can \nthe central limit theorem be used?\nSOLUTION\n \na. Approach Used for an Individual Value: Use the methods presented in \nSection 6-2 because we are dealing with an individual value from a nor-\nmally distributed population. We seek the area of the green-shaded region in \nFigure 6-23(a).\n \n Technology: If using technology (as described at the end of Section 6-2), we \nﬁnd that the green-shaded area in the graph at the left is 0.3156.\n \n Table A-2: If using Table A-2, we convert the pulse rate of 80 bpm to the cor-\nresponding z score, as shown here:\nz = x - m\ns\n= 80 - 74.0\n12.5\n= 0.48\n \n  \nWe refer to Table A-2 to ﬁnd that the cumulative area to the left of z = 0.48 \nis 0.6844, so the green-shaded area in Figure 6-23(a) is 1 - 0.6844 = 0.3156.\n",
    "6-4 The Central Limit Theorem \n255\n \nb. Approach Used for the Mean of Sample Values: Use the central limit theo-\nrem because we are dealing with the mean of a sample of 16 women, not an \nindividual woman.\n \n Requirement check for part b We can use the normal distribution if the \noriginal population is normally distributed or n 7 30. The sample size is not \ngreater than 30, but the original population of pulse rates of women has a \nnormal distribution, so samples of any size will yield means that are normally \ndistributed. \n \n  \nBecause we are now dealing with a distribution of sample means, we \nmust use the parameters mx and sx, which are evaluated as follows:\nmx = m = 74.0\nsx =\ns\n1n = 12.5\n116 = 3.125\n \n We want to ﬁnd the green-shaded area shown in Figure 6-23(b).\n \n Technology: If using technology, the green-shaded area in Figure 6-23(b) is \n0.0274.\n \n Table A-2: If using Table A-2, we convert the value of x = 80 bpm to the \ncorresponding z score of z = 1.92, as shown here:\nz = x - mx\nsx\n= 80 - 74.0\n12.5\n116\n=\n6\n3.125 = 1.92\n \n From Table A-2 we ﬁnd that the cumulative area to the left of z = 1.92 is \n0.9726, so the green-shaded area of Figure 6-23(b) is 1 - 0.9726 = 0.0274.\n \nc. Even though the sample size is not greater than 30, we can use the central \nlimit theorem because the population of pulse rates of women is normally \ncontinued\nThe Fuzzy Central  \nLimit Theorem\nIn The Cartoon \nGuide to Statis-\ntics, by Gonick \nand Smith, \nthe authors \ndescribe the \nFuzzy Central \nLimit Theorem as follows: “Data \nthat are influenced by many small \nand unrelated random effects \nare approximately normally \ndistributed. This explains why \nthe normal is everywhere: stock \nmarket fluctuations, student \nweights, yearly temperature \naverages, SAT scores: All are the \nresult of many different effects.” \nPeople’s heights, for example, \nare the results of hereditary \nfactors, environmental factors, \nnutrition, health care, geographic \nregion, and other influences, \nwhich, when combined, produce \nnormally distributed values.\nf ll\n“D\nx 5 80\n(s 5 12.5)\nm 5 74.0\nIndividual women\npulse rates\nMeans of\npulse rates\nfrom samples\nof women\n(16 in each\nsample)\nx 5 80\nmx 5 74.0\n(sx 5 3.125)\nFIGURE 6-23 Female Pulse Rates\n(a)\n(b)\n",
    "256 \nCHAPTER 6 Normal Probability Distributions\nExample 2 shows that we can use the same basic procedures from Section 6-2, \nbut we must remember to correctly adjust the standard deviation when working with a \nsample mean instead of an individual sample value.\nIntroduction to Hypothesis Testing\nCarefully examine the conclusions that are reached in the next example illustrating \nthe type of thinking that is the basis for the important procedure of hypothesis testing \n(formally introduced in Chapter 8). Example 3 uses the rare event rule for inferential \nstatistics, first presented in Section 4-1:\nIdentifying Significant Results with Probabilities: The Rare Event Rule for \nInferential Statistics\nIf, under a given assumption, the probability of a particular observed \nevent is very small and the observed event occurs signiﬁcantly less than or \nsigniﬁcantly greater than what we typically expect with that assumption, \nwe conclude that the assumption is probably not correct.\nThe following example illustrates the above rare event rule.\n distributed. As noted in the requirement check for part (b), samples of any \nsize will yield means that are normally distributed.\nINTERPRETATION\nThere is a 0.3156 probability that an individual woman will have a pulse rate greater \nthan 80 bpm, and there is a 0.0274 probability that 16 randomly selected women \nwill have pulse rates with a mean greater than 80 bpm.\nEXAMPLE 3  Body Temperatures\nAssume that the population of human body temperatures has a mean of 98.6°F, \nas is commonly believed. Also assume that the population standard deviation is \n0.62°F (based on data from University of Maryland researchers). If a sample of size \nn = 106 is randomly selected, find the probability of getting a mean of 98.2°F or \nlower. (The value of 98.2°F was actually obtained from researchers; see the mid-\nnight temperatures for Day 2 in Data Set 2 “Body Temperatures” in Appendix B.)\nSOLUTION\nWe work under the assumption that the population of human body temperatures has \na mean of 98.6°F. We weren’t given the distribution of the population, but because \nthe sample size n = 106 exceeds 30, we use the central limit theorem and conclude \nthat the distribution of sample means is a normal distribution with these parameters:\n \nmx = m = 98.6 1by assumption2\nsx =\ns\n1n =\n0.62\n1106 = 0.0602197\nFigure 6-24 shows the shaded area (see the tiny left tail of the graph) correspond-\ning to the probability we seek. Having already found the parameters that apply to \nthe distribution shown in Figure 6-24, we can now find the shaded area by using the \nsame procedures developed in Section 6-2.\n",
    "6-4 The Central Limit Theorem \n257\nINTERPRETATION\nThe result shows that if the mean of our body temperatures is really 98.6°F, as we as-\nsumed, then there is an extremely small probability of getting a sample mean of 98.2°F \nor lower when 106 subjects are randomly selected. University of Maryland researchers \ndid obtain such a sample mean, and after confirming that the sample is sound, there are \ntwo feasible explanations: (1) The population mean really is 98.6°F and their sample \nrepresents a chance event that is extremely rare; (2) the population mean is actually lower \nthan the assumed value of 98.6°F and so their sample is typical. Because the probability  \nis so low, it is more reasonable to conclude that the population mean is lower than \n98.6°F. In reality it appears that the true mean body temperature is closer to 98.2°F!\nThis is the type of reasoning used in hypothesis testing, to be introduced in \nChapter 8. For now, we should focus on the use of the central limit theorem for \nfinding the probability of 0.0001, but we should also observe that this theorem will \nbe used later in applying some very important concepts in statistics.\nTechnology: If we use technology to find the shaded area in Figure 6-24, we get \n0.0000000000155, which can be expressed as 0+.\nTable A-2: If we use Table A-2 to find the shaded area in Figure 6-24, we must first \nconvert the score of x = 98.20°F to the corresponding z score:\nz = x - mx\nsx\n= 98.20 - 98.6\n0.0602197\n= -6.64\nReferring to Table A-2 we find that z = -6.64 is off the chart, but for values \nof z below -3.49, we use an area of 0.0001 for the cumulative left area up to \nz = -3.49. We therefore conclude that the shaded region in Figure 6-24 is 0.0001.\n0\nz\nmx 5 98.6\n26.64\nx 5 98.2\n0.0001\nFIGURE 6-24  Means of Body Temperatures from \nSamples of Size n = 106\nCorrection for a Finite Population\nIn applying the central limit theorem, our use of sx = s> 1n assumes that the popula-\ntion has infinitely many members. When we sample with replacement, the population \nis effectively infinite. When sampling without replacement from a finite population, we \nmay need to adjust sx. Here is a common rule of thumb:\nWhen sampling without replacement and the sample size n is greater than \n5% of the ﬁnite population size N (that is, n + 0.05N), adjust the standard \ndeviation of sample means Sx by multiplying it by this ﬁnite population \n correction factor:\nA\nN - n\nN - 1\n",
    "258 \nCHAPTER 6 Normal Probability Distributions\nExcept for Exercise 21 “Correcting for a Finite Population,” the examples and exer-\ncises in this section assume that the finite population correction factor does not apply, \nbecause we are sampling with replacement, or the population is infinite, or the sample \nsize doesn’t exceed 5% of the population size.\nStatistical Literacy and Critical Thinking\n1. Requirements A researcher collects a simple random sample of grade-point averages of \nbiostatistics students and she calculates the mean of this sample. Under what conditions can \nthat sample mean be treated as a value from a population having a normal distribution?\n2. Small Sample Weights of adult human brains are normally distributed. Samples of weights \nof adult human brains, each of size n = 15, are randomly collected and the sample means are \nfound. Is it correct to conclude that the sample means cannot be treated as being from a normal \ndistribution because the sample size is too small? Explain.\n3. Notation In general, what do the symbols mx and sx represent? What are the values of mx\nand sx for samples of size 64 randomly selected from the population of IQ scores with popula-\ntion mean of 100 and standard deviation of 15?\n4.  Annual Incomes Annual incomes of physicians are known to have a distribution that is \nskewed to the right instead of being normally distributed. Assume that we collect a large 1n 7 302\nrandom sample of annual incomes of physicians. Can the distribution of those incomes in that \nsample be approximated by a normal distribution because the sample is large? Why or why not?\nUsing the Central Limit Theorem. In Exercises 5–8, assume that females have pulse \nrates that are normally distributed with a mean of 74.0 beats per minute and a standard \n deviation of 12.5 beats per minute (based on Data Set 1 “Body Data” in Appendix B).\n5. a. If 1 adult female is randomly selected, find the probability that her pulse rate is less than \n80 beats per minute.\nb. If 16 adult females are randomly selected, find the probability that they have pulse rates with \na mean less than 80 beats per minute.\nc. Why can the normal distribution be used in part (b), even though the sample size does not \nexceed 30?\n6. a. If 1 adult female is randomly selected, find the probability that her pulse rate is greater \nthan 70 beats per minute.\nb. If 25 adult females are randomly selected, find the probability that they have pulse rates with \na mean greater than 70 beats per minute.\nc. Why can the normal distribution be used in part (b), even though n 6 30?\n7. a. If 1 adult female is randomly selected, find the probability that her pulse rate is between \n72 beats per minute and 76 beats per minute.\nb. If 4 adult females are randomly selected, find the probability that they have pulse rates with \na mean between 72 beats per minute and 76 beats per minute.\nc. Why can the normal distribution be used in part (b), even though the sample size does not \nexceed 30?\n8. a. If 1 adult female is randomly selected, find the probability that her pulse rate is between \n78 beats per minute and 90 beats per minute.\nb. If 16 adult females are randomly selected, find the probability that they have pulse rates with \na mean between 78 beats per minute and 90 beats per minute.\nc. Why can the normal distribution be used in part (b), even though n 6 30?\n6-4 Basic Skills and Concepts\n",
    "6-4 The Central Limit Theorem \n259\n9. Hemoglobin in Men Hemoglobin levels in adult males are normally distributed with a \nmean of 14.7 g>dL and a standard deviation of 1.3 g>dL (based on data from the National \nHealth and Nutrition Examination Survey).\na. The normal hemoglobin range for men is 13.6 g>dL to 17.7 g>dL. What percentage of men \nhave hemoglobin levels in the normal range?\nb. If we randomly collect samples of men with 9 in each sample, what percentage of those \nsamples have a mean hemoglobin level that is within the normal range?\n10. Hemoglobin in Women Hemoglobin levels in adult females are normally distributed \nwith a mean of 13.0 g>dL and a standard deviation of 1.3 g>dL (based on data from the Na-\ntional Health and Nutrition Examination Survey).\na. The normal hemoglobin range for women is 12.1 g>dL to 15.1 g>dL. What percentage of \nwomen have hemoglobin levels in the normal range?\nb. If we randomly collect samples of women with 9 in each sample, what percentage of those \nsamples have a mean hemoglobin level that is within the normal range?\n11. Diastolic BP in Women Diastolic blood pressure is a measure of the pressure when \narteries rest between heartbeats. Diastolic blood pressure levels in women are normally distrib-\nuted with a mean of 70.2 mm Hg and a standard deviation of 11.2 mm Hg (based on Data Set 1 \n“Body Data” in Appendix B).\na. A diastolic blood pressure level above 90 mm Hg is considered to be hypertension. What \npercentage of women have hypertension?\nb. If we randomly collect samples of women with 4 in each sample, what percentage of those \nsamples have a mean above 90 mm Hg?\n12. Diastolic BP in Men Diastolic blood pressure is a measure of the pressure when arteries \nrest between heartbeats. Diastolic blood pressure levels in men are normally distributed with \na mean of 71.3 mm Hg and a standard deviation of 12.0 mm Hg (based on Data Set 1 “Body \nData” in Appendix B).\na. A diastolic blood pressure level above 90 mm Hg is considered to be hypertension. What \npercentage of men have hypertension?\nb. If we randomly collect samples of men with 4 in each sample, what percentage of those \nsamples have a mean above 90 mm Hg?\n13. Mensa Membership in Mensa requires a score in the top 2% on a standard intelligence \ntest. The Wechsler IQ test is designed for a mean of 100 and a standard deviation of 15, and \nscores are normally distributed.\na. Find the minimum Wechsler IQ test score that satisfies the Mensa requirement.\nb. If 4 randomly selected adults take the Wechsler IQ test, find the probability that their mean \nscore is at least 131.\nc. If 4 subjects take the Wechsler IQ test and they have a mean of 132, but the individual scores \nare lost, can we conclude that all 4 of them are eligible for Mensa?\n14. Sleep The amounts of times that adults sleep are normally distributed with a mean of \n6.8 hours and a standard deviation of 1.4 hours (based on data from multiple sources, includ-\ning a Gallup poll and the American Journal of Epidemiology). A common recommendation is \nthat we get between 7 and 9 hours of sleep each night.\na. For someone randomly selected, find the probability that they get between 7 and 9 hours of \nsleep in a night.\nb. If we randomly collect a sample of 5 adults, what is the probability that the sample mean is \nbetween 7 hours and 9 hours?\n",
    "260 \nCHAPTER 6 Normal Probability Distributions\nErgonomics. Exercises 15–20 involve applications of ergonomics, which is a discipline \nfocused on the design of tools and equipment so that they can be used safely, comfortably, \nand efficiently.\n15. Water Taxi Safety Passengers died when a water taxi sank in Baltimore’s Inner Harbor. \nMen are typically heavier than women and children, so when loading a water taxi, assume a \nworst-case scenario in which all passengers are men. Assume that weights of men are normally \ndistributed with a mean of 189 lb and a standard deviation of 39 lb (based on Data Set 1 “Body \nData” in Appendix B). The water taxi that sank had a stated capacity of 25 passengers, and the \nboat was rated for a load limit of 3500 lb.\na. Given that the water taxi that sank was rated for a load limit of 3500 lb, what is the maxi-\nmum mean weight of the passengers if the boat is filled to the stated capacity of 25 passengers?\nb. If the water taxi is filled with 25 randomly selected men, what is the probability that their \nmean weight exceeds the value from part (a)?\nc. After the water taxi sank, the weight assumptions were revised so that the new capacity be-\ncame 20 passengers. If the water taxi is filled with 20 randomly selected men, what is the prob-\nability that their mean weight exceeds 175 lb, which is the maximum mean weight that does \nnot cause the total load to exceed 3500 lb?\nd. Is the new capacity of 20 passengers safe?\n16. Designing Manholes According to the website www.torchmate.com, “manhole covers \nmust be a minimum of 22 in. in diameter, but can be as much as 60 in. in diameter.” Assume \nthat a manhole is constructed to have a circular opening with a diameter of 22 in. Men have \nshoulder breadths that are normally distributed with a mean of 18.2 in. and a standard deviation \nof 1.0 in. (based on data from the National Health and Nutrition Examination Survey).\na. What percentage of men will fit into the manhole?\nb. Assume that Connecticut’s Eversource company employs 36 men who work in manholes. If \n36 men are randomly selected, what is the probability that their mean shoulder breadth is less \nthan 18.5 in.? Does this result suggest that money can be saved by making smaller manholes \nwith a diameter of 18.5 in.? Why or why not?\n17. Southwest Airlines Seats Southwest Airlines currently has a seat width of 17 in. Men \nhave hip breadths that are normally distributed with a mean of 14.4 in. and a standard deviation \nof 1.0 in. (based on anthropometric survey data from Gordon, Churchill, et al.).\na. Find the probability that if an individual man is randomly selected, his hip breadth will be \ngreater than 17 in.\nb. Southwest Airlines uses a Boeing 737 for some of its flights, and that aircraft seats 122 pas-\nsengers. If the plane is full with 122 randomly selected men, find the probability that these men \nhave a mean hip breadth greater than 17 in.\nc. Which result should be considered for any changes in seat design: the result from part (a) or \npart (b)?\n18. Redesign of Ejection Seats When women were finally allowed to become pilots of \nfighter jets, engineers needed to redesign the ejection seats because they had been originally \ndesigned for men only. The ACES-II ejection seats were designed for men weighing between \n140 lb and 211 lb. Weights of women are now normally distributed with a mean of 171 lb and a \nstandard deviation of 46 lb (based on Data Set 1 “Body Data” in Appendix B).\na. If 1 woman is randomly selected, find the probability that her weight is between 140 lb and \n211 lb.\nb. If 25 different women are randomly selected, find the probability that their mean weight is \nbetween 140 lb and 211 lb.\nc. When redesigning the fighter jet ejection seats to better accommodate women, which \n probability is more relevant: the result from part (a) or the result from part (b)? Why?\n",
    "6-5 Assessing Normality \n261\n19. Doorway Height The Boeing 757-200 ER airliner carries 200 passengers and has doors \nwith a height of 72 in. Heights of men are normally distributed with a mean of 68.6 in. and a \nstandard deviation of 2.8 in. (based on Data Set 1 “Body Data” in Appendix B).\na. If a male passenger is randomly selected, find the probability that he can fit through the \ndoorway without bending.\nb. If half of the 200 passengers are men, find the probability that the mean height of the 100 men \nis less than 72 in.\nc. When considering the comfort and safety of passengers, which result is more relevant: the \nprobability from part (a) or the probability from part (b)? Why?\nd. When considering the comfort and safety of passengers, why are women ignored in this \ncase?\n20. Loading Aircraft Before every flight, the pilot must verify that the total weight of the \nload is less than the maximum allowable load for the aircraft. The Bombardier Dash 8 aircraft \ncan carry 37 passengers, and a flight has fuel and baggage that allows for a total passenger load \nof 6200 lb. The pilot sees that the plane is full and all passengers are men. The aircraft will be \noverloaded if the mean weight of the passengers is greater than 6200 lb>37 = 167.6 lb. What is \nthe probability that the aircraft is overloaded? Should the pilot take any action to correct for an \noverloaded aircraft? Assume that weights of men are normally distributed with a mean of 189 lb \nand a standard deviation of 39 lb (based on Data Set 1 “Body Data” in Appendix B).\n21. Correcting for a Finite Population In a study of babies born with very low birth weights, \n275 children were given IQ tests at age 8, and their scores approximated a normal distribution \nwith m = 95.5 and s = 16.0 (based on data from “Neurobehavioral Outcomes of School-Age \nChildren Born Extremely Low Birth Weight or Very Preterm,” by Anderson et al., Journal of \nthe American Medical Association, Vol. 289, No. 24). Fifty of those children are to be ran-\ndomly selected without replacement for a follow-up study.\na. When considering the distribution of the mean IQ scores for samples of 50 children, should \nsx be corrected by using the finite population correction factor? Why or why not? What is the \nvalue of sx?\nb. Find the probability that the mean IQ score of the follow-up sample is between 95 and 105.\n6-4 Beyond the Basics\nKey Concept The following chapters include important statistical methods requiring \nthat sample data are from a population having a normal distribution. In this section we \npresent criteria for determining whether the requirement of a normal distribution is \nsatisfied. The criteria involve (1) visual inspection of a histogram to see if it is roughly \nbell-shaped; (2) identifying any outliers; and (3) constructing a normal quantile plot.\nPART 1\nBasic Concepts of Assessing Normality\nWhen trying to determine whether a collection of data has a distribution that is \napproximately normal, we can visually inspect a histogram to see if it is approxi-\nmately bell-shaped (as discussed in Section 2-2), we can identify outliers, and we can \nalso use a normal quantile plot (discussed briefly in Section 2-2).\n6-5 \nAssessing Normality\n",
    "262 \nCHAPTER 6 Normal Probability Distributions\nProcedure for Determining Whether It Is Reasonable to Assume That Sample \nData Are from a Population Having a Normal Distribution\n1. Histogram: Construct a histogram. If the histogram departs dramatically from a \nbell shape, conclude that the data do not have a normal distribution.\n2. Outliers: Identify outliers. If there is more than one outlier present, conclude \nthat the data might not have a normal distribution. (Just one outlier could be an \nerror or the result of chance variation, but be careful, because even a single out-\nlier can have a dramatic effect on results.)\n3. Normal quantile plot: If the histogram is basically symmetric and the num-\nber of outliers is 0 or 1, use technology to generate a normal quantile plot. \nApply the following criteria to determine whether the distribution is nor-\nmal. (These criteria can be used loosely for small samples, but they should \nbe used more strictly for large samples.)\n Normal Distribution: The population distribution is normal if the pattern of \nthe points is reasonably close to a straight line and the points do not show some \nsystematic pattern that is not a straight-line pattern.\n Not a Normal Distribution: The population distribution is not normal if either \nor both of these two conditions apply:\n • The points do not lie reasonably close to a straight line.\n • The points show some systematic pattern that is not a straight-line pattern.\nHistograms and Normal Quantile Plots\nIn Part 2 of this section we describe the process of constructing a normal quantile plot, \nbut for now we focus on interpreting a normal quantile plot. The following displays \nshow histograms of data along with the corresponding normal quantile plots.\nNormal: The first case shows a histogram of IQ scores that is close to being bell-\nshaped, so the histogram suggests that the IQ scores are from a normal distribution. \nThe corresponding normal quantile plot shows points that are reasonably close to a \nstraight-line pattern, and the points do not show any other systematic pattern that is \nnot a straight line. It is safe to assume that these IQ scores are from a population that \nhas a normal distribution.\nDEFINITION\nA normal quantile plot (or normal probability plot) is a graph of points (x, y) \nwhere each x value is from the original set of sample data, and each y value is the \ncorresponding z score that is expected from the standard normal distribution.\n",
    "6-5 Assessing Normality \n263\nUniform: The second case shows a histogram of data having a uniform (flat) distribu-\ntion. The corresponding normal quantile plot suggests that the data are not normally \ndistributed. Although the pattern of points is reasonably close to a straight-line pattern, \nthere is another systematic pattern that is not a straight-line pattern. We conclude that \nthese sample values are from a population having a distribution that is not normal.\nSkewed: The third case shows a histogram of the HDL cholesterol measurements. \nThe shape of the histogram is skewed to the right. The corresponding normal quantile \nplot shows points that are not close to a straight-line pattern. These HDL cholesterol \nmeasurements are from a population having a distribution that is not normal.\nTools for Determining Normality\n \n■Histogram, Outliers: If the requirement of a normal distribution is not too \nstrict, simply look at a histogram and find the number of outliers. If the histo-\ngram is roughly bell-shaped and the number of outliers is 0 or 1, treat the popula-\ntion as if it has a normal distribution.\n \n■Normal Quantile Plot: Normal quantile plots can be difficult to construct on \nyour own, but they can be generated with suitable technology.\n \n■Advanced Methods: In addition to the procedures discussed in this section, \nthere are other more advanced procedures for assessing normality, such as the \nchi-square goodness-of-fit test, the Lilliefors test, the Anderson-Darling test, the \nJarque-Bera test, and the Ryan-Joiner test (discussed briefly in Part 2).\nPART 2\nManual Construction of Normal  \nQuantile Plots\nThe following is a relatively simple procedure for manually constructing a normal \nquantile plot, and it is the same procedure used by Statdisk and the TI-83>84 Plus cal-\nculator. Some statistical packages use various other approaches, but the interpretation \nof the graph is essentially the same.\nu-\ny\nn,\nat \nThe Placebo Effect\nIt has long been \nbelieved that \nplacebos actu-\nally help some \npatients. In fact, \nsome formal \nstudies have \nshown that when given a placebo \n(a treatment with no medicinal \nvalue), many test subjects show \nsome improvement. Estimates of \nimprovement rates have typically \nranged between one-third and \ntwo-thirds of patients. However, \na more recent study suggests \nthat placebos have no real ef-\nfect. An article in New England \nJournal of Medicine (Vol. 334, \nNo. 21) was based on research \nof 114 medical studies over \n50 years. The authors of the \narticle concluded that placebos \nappear to have some effect only \nfor relieving pain, but not for \nother physical conditions. They \nconcluded that apart from clinical \ntrials, the use of placebos “can-\nnot be recommended.”\n",
    "264 \nCHAPTER 6 Normal Probability Distributions\nManual Construction of a Normal Quantile Plot\nStep 1: First sort the data by arranging the values in order from lowest to highest.\nStep 2:  With a sample of size n, each value represents a proportion of 1>n of the \nsample. Using the known sample size n, find the values of 1\n2n, 3\n2n, 5\n2n, and so \non, until you get n values. These values are the cumulative areas to the left \nof the corresponding sample values.\nStep 3:  Use the standard normal distribution (software or a calculator or Table A-2) \nto find the z scores corresponding to the cumulative left areas found in Step 2. \n(These are the z scores that are expected from a normally distributed sample.)\nStep 4:  Match the original sorted data values with their corresponding z scores \nfound in Step 3; then plot the points (x, y), where each x is an original sam-\nple value and y is the corresponding z score.\nStep 5:  Examine the normal quantile plot and use the criteria given in Part 1. Con-\nclude that the population has a normal distribution if the pattern of the \npoints is reasonably close to a straight line and the points do not show some \nsystematic pattern that is not a straight-line pattern.\nEXAMPLE 1  Platelet Counts\nConsider this sample of five patient platelet counts (1000 cells>mL): 125, 229, 236, \n257, 234. With only five values, a histogram will not be very helpful in revealing the \ndistribution of the data. Instead, construct a normal quantile plot for these five val-\nues and determine whether they appear to come from a population that is normally \ndistributed.\nSOLUTION\nThe following steps correspond to those listed in the procedure above for construct-\ning a normal quantile plot.\nStep 1: First, sort the data by arranging them in order. We get 125, 229, 234, \n236, 257.\nStep 2: With a sample of size n = 5, each value represents a proportion of 1>5 \nof the sample, so we proceed to identify the cumulative areas to the left of the \ncorresponding sample values. The cumulative left areas, which are expressed in \ngeneral as 1\n2n, 3\n2n, 5\n2n, and so on, become these specific areas for this example with \nn = 5: 1\n10, 3\n10, 5\n10, 7\n10, 9\n10. These cumulative left areas expressed in decimal form are 0.1, \n0.3, 0.5, 0.7, and 0.9.\nStep 3: We now use technology (or Table A-2) with the cumulative left areas of \n0.1000, 0.3000, 0.5000, 0.7000, and 0.9000 to find these corresponding z scores: \n-1.28, -0.52, 0, 0.52, and 1.28. (For example, the z score of -1.28 has an area of \n0.1000 to its left.)\nStep 4: We now pair the original sorted platelet counts with their corresponding \nz scores. We get these (x, y) coordinates, which are plotted in the following  \nStatdisk display:\n1125, -1.282, 1229, -0.522, 1234, 02, 1236, 0.522, 1257, 1.282\n",
    "6-5 Assessing Normality \n265\nRyan-Joiner Test The Ryan-Joiner test is one of several formal tests of normality, \neach having its own advantages and disadvantages. Statdisk has a feature of Normal-\nity Assessment that displays a histogram, normal quantile plot, the number of poten-\ntial outliers, and results from the Ryan-Joiner test.\n Statdisk\nINTERPRETATION\nWe examine the normal quantile plot in the Statdisk display. The points do not ap-\npear to lie reasonably close to the straight line, so we conclude that the sample of \nfive platelet counts does not appear to be from a normally distributed population.\nEXAMPLE 2  Platelet Counts \nExample 1 used a sample of five platelet counts. We can use the Normality Assess-\nment feature of Statdisk with a different sample of the 300 platelet counts listed in \nData Set 1 “Body Data” in Appendix B.\nStatdisk\ncontinued\n",
    "266 \nCHAPTER 6 Normal Probability Distributions\nData Transformations Many data sets have a distribution that is not normal, but \nwe can transform the data so that the modified values have a normal distribution. One \ncommon transformation is to transform each value of x by taking its logarithm. (You \ncan use natural logarithms or logarithms with base 10. If any original values are 0, \ntake logarithms of values of x + 1). If the distribution of the logarithms of the values \nis a normal distribution, the distribution of the original values is called a lognormal \ndistribution. (See Exercises 19 “Transformations” and 20 “Lognormal Distribu-\ntion”.) In addition to transformations with logarithms, there are other transformations, \nsuch as replacing each x value with 1x, or 1>x, or x2. In addition to getting a required \nnormal distribution when the original data values are not normally distributed, such \ntransformations can be used to correct deficiencies, such as a requirement (found in \nlater chapters) that different data sets have the same variance.\nLet’s use the display with the three criteria for assessing normality.\n \n1. Histogram: We can see that the histogram is skewed to the left instead of  \nbeing bell-shaped.\n \n2. Outliers: The display shows that there are 20 possible outliers. If we examine \na sorted list of the 300 platelet counts, there are platelet counts that appear to \nbe outliers.\n \n3. Normal quantile plot: The points in the normal quantile plot do not ﬁt a \nstraight-line pattern very well. We conclude that the 300 platelet counts do not \nappear to be from a population with a normal distribution.\nNormal Quantile Plots\nAccess tech instructions, videos, and data sets at www.TriolaStats.com\nTECH CENTER \nStatistical Literacy and Critical Thinking\n1. Normal Quantile Plot Data Set 1 “Body Data” in Appendix B includes the heights of 147 \nrandomly selected women, and heights of women are normally distributed. If you were to con-\nstruct a histogram of the 147 heights of women in Data Set 1, what shape do you expect the \nhistogram to have? If you were to construct a normal quantile plot of those same heights, what \npattern would you expect to see in the graph?\n2. Normal Quantile Plot After constructing a histogram of the ages of the 147 women in-\ncluded in Data Set 1 “Body Data” in Appendix B, you see that the histogram is far from being \nbell-shaped. What do you now know about the pattern of points in the normal quantile plot?\n3. Small Sample An article includes elapsed times (hours) to lumbar puncture for 19 patients \nwho entered emergency rooms with sudden and severe “thunderclap” headaches (based on data \nfrom “Thunderclap Headache and Normal Computed Tomographic Results: Value of Cerebro-\nspinal Fluid Analysis,” by DuPont et al., Mayo Clinic Proceedings, Vol. 83, No. 12). Given \nthat the sample size is less than 30, what requirement must be met in order to treat the sample \nmean as a value from a normally distributed population? Identify three tools for verifying that \nrequirement.\n6-5 Basic Skills and Concepts \n",
    "6-5 Assessing Normality \n267\n4. Assessing Normality The accompanying histogram is constructed from the diastolic blood \npressure measurements of the 147 women included in Data Set 1 “Body Data” in  Appendix B. If \nyou plan to conduct further statistical tests and there is a loose requirement of a normally distrib-\nuted population, what do you conclude about the population distribution based on this histogram?\n Minitab\nInterpreting Normal Quantile Plots. In Exercises 5–8, examine the normal quantile \nplot and determine whether the sample data appear to be from a population with a normal \ndistribution.\n5. Head Lengths of Bears The normal quantile plot represents the head lengths (in.) of \nbears listed in Data Set 11 “Bear Measurements.”\n6. Diet Pepsi The normal quantile plot represents weights (pounds) of the contents of cans of \nDiet Pepsi.\n7. Patient Service Times The normal quantile plot represents service times (minutes) of \nrandomly selected patients.\n",
    "268 \nCHAPTER 6 Normal Probability Distributions\n8. Visual Acuity Data Set 5 “Vision” includes measures of visual acuity. Shown here is the nor-\nmal quantile plot resulting from the listed measurements from the right eye of the 300 subjects.\nDetermining Normality. In Exercises 9–12, refer to the indicated sample data and deter-\nmine whether they appear to be from a population with a normal distribution. Assume that \nthis requirement is loose in the sense that the population distribution need not be exactly \nnormal, but it must be a distribution that is roughly bell-shaped.\n9. Irises The petal lengths of irises, as listed in Data Set 16 “Iris Measurements” in Appendix B.\n10. Births The lengths of stay (days) of newborn babies, as listed in Data Set 3 “Births” in \nAppendix B.\n11. Cuckoo Egg Lengths The lengths of cuckoo eggs in wren nests, as listed in Data Set 17 \n“Cuckoo Egg Lengths” in Appendix B.\n12. Bears The neck sizes of bears, as listed in Data Set 11 “Bear Measurements” in Appendix B.\nUsing Technology to Generate Normal Quantile Plots. In Exercises 13–16, use tech-\nnology to generate a normal quantile plot. Then determine whether the data come from a \nnormally distributed population.\n13.  Birth weights from Data Set 3 “Births” in Appendix B.\n14.  Lengths of stay from Data Set 3 “Births” in Appendix B.\n15.  White blood cell counts of females from Data Set 1 “Body Data” in Appendix B.\n16.  Red blood cell counts of females from Data Set 1 “Body Data” in Appendix B.\nConstructing Normal Quantile Plots. In Exercises 17 and 18, use the given data values to \nidentify the corresponding z scores that are used for a normal quantile plot; then identify the \ncoordinates of each point in the normal quantile plot. Construct the normal quantile plot, then \ndetermine whether the sample data appear to be from a population with a normal distribution.\n17. Female Arm Circumferences A sample of arm circumferences (cm) of females from \nData Set 1 “Body Data” in Appendix B: 40.7, 44.3, 34.2, 32.5, 38.5.\n18. Brain Volumes A sample of human brain volumes (cm3) is obtained from those listed \nin Data Set 9 “IQ and Brain Size” from Appendix B: 1272, 1051, 1079, 1034, 1070, 1173, \n1079, 1067.\n19. Transformations The heights (in inches) of men listed in Data Set 1 “Body Data” in \n Appendix B have a distribution that is approximately normal, so it appears that those heights \nare from a normally distributed population.\n6-5 Beyond the Basics \ncontinued\n",
    "6-6 Normal as Approximation to Binomial \n269\na. If 2 inches is added to each height, are the new heights also normally distributed?\nb. If each height is converted from inches to centimeters, are the heights in centimeters also \nnormally distributed?\nc. Are the logarithms of normally distributed heights also normally distributed?\n20. Lognormal Distribution The following are costs (dollars) of treating patients. Test these \nvalues for normality, then take the logarithm of each value and test for normality. What do you \nconclude?\n237,592 160,680 153,500 117,120 7304 6037 4483 4367 2658 1361 311\nKey Concept Section 5-2 introduced binomial probability distributions, and this sec-\ntion presents a method for using a normal distribution as an approximation to a bi-\nnomial probability distribution, so that some problems involving proportions can be \nsolved by using a normal distribution. Here are the two main points of this section:\n \n■Given probabilities p and q (where q = 1 - p) and sample size n, if the condi-\ntions np Ú 5 and nq Ú 5 are both satisfied, then probabilities from a binomial \nprobability distribution can be approximated reasonably well by using a normal \ndistribution having these parameters:\n m = np\n s = 1npq.\n \n■The binomial probability distribution is discrete (with whole numbers for the \nrandom variable x), but the normal approximation is continuous. To compensate, \nwe use a “continuity correction” with a whole number x represented by the inter-\nval from x - 0.5 to x + 0.5.\nBrief Review of Binomial Probability Distribution In Section 5-2 we saw that \na binomial probability distribution has (1) a fixed number of trials; (2) trials that are \nindependent; (3) trials that are each classified into two categories commonly referred \nto as success and failure; and (4) trials with the property that the probability of success \nremains constant. Section 5-2 also introduced the following notation.\nNotation\nn = the ﬁxed number of trials\nx = the specific number of successes in n trials\np = probability of success in one of the n trials\nq = probability of failure in one of the n trials (so q = 1 - p)\nRationale for Using a Normal Approximation We saw in Section 6-3 that the \nsampling distribution of a sample proportion tends to approximate a normal distribu-\ntion. Also, see the probability histogram on the next page for the binomial distribution \nwith n = 580 and p = 0.25. (In one of Mendel’s famous hybridization experiments, \nhe expected 25% of his 580 peas to be yellow.) The bell shape of this graph suggests \nthat we can use a normal distribution to approximate the binomial distribution.\n6-6 \nNormal as Approximation to Binomial\n",
    "270 \nCHAPTER 6 Normal Probability Distributions\n Minitab\nNormal Distribution as an Approximation to the Binomial Distribution\nRequirements\n1. The sample is a simple random sample of size n from a population in which the proportion of successes is p, or the \nsample is the result of conducting n independent trials of a binomial experiment in which the probability of success is p.\n2. np Ú 5 and nq Ú 5.\n(The requirements of np Ú 5 and nq Ú 5 are common, but some recommend using 10 instead of 5.)\nNormal Approximation\nIf the above requirements are satisfied, then the probability distribution of the random variable x can be approximated by \na normal distribution with these parameters:\n • m = np\n • s = 1npq\nContinuity Correction\nWhen using the normal approximation, adjust the discrete whole number x by using a continuity correction so that any \nindividual value x is represented in the normal distribution by the interval from x - 0.5 to x + 0.5.\nKEY ELEMENTS \nProcedure for Using a Normal Distribution to Approximate a  \nBinomial Distribution\n1. Check the requirements that np Ú 5 and nq Ú 5.\n2. Find m = np and s = 1npq to be used for the normal distribution.\n3. Identify the discrete whole number x that is relevant to the binomial probability \nproblem being considered, and represent that value by the region bounded by \nx - 0.5 and x + 0.5.\n4. Graph the normal distribution and shade the desired area bounded by \nx - 0.5 or x + 0.5 as appropriate.\nEXAMPLE 1  Was Mendel Wrong? \nIn one of Mendel’s famous hybridization experiments, he expected that among 580 \noffspring peas, 145 of them (or 25%) would be yellow, but he actually got 152 yellow \npeas. Assuming that Mendel’s rate of 25% is correct, find the probability of  \n",
    "6-6 Normal as Approximation to Binomial \n271\n(s 5 10.4283)\n151.5\nm 5 145\nArea 5 0.2665\nProbability\nNormal\nBinomial\n151.5\n152.5\n0.00\n0.01\n0.02\n0.03\n0.04\nFIGURE 6-25 Number of Yellow Peas Among 580\ngetting 152 or more yellow peas by random chance. That is, given n = 580 and \np = 0.25, find P(at least 152 yellow peas). Is 152 yellow peas significantly high?\nSOLUTION\nStep 1: Requirement check: With n = 580 and p = 0.25, we get np =  \n(580)(0.25) = 145 and nq = (580)(0.75) = 435, so the requirements that  \nnp Ú 5 and nq Ú 5 are both satisfied.\nStep 2: We now find m and s needed for the normal distribution:\nm = np = 580 # 0.25 = 145\ns = 1npq = 2580 # 0.25 # 0.75 = 10.4283\nStep 3: We want the probability of at least 152 yellow peas, so the discrete whole \nnumber relevant to this example is x = 152. We use the continuity correction as \nwe represent the discrete value of 152 in the graph of the normal distribution by the \ninterval between 151.5 and 152.5 (as shown in the top portion of Figure 6-25).\nStep 4: See the bottom portion of Figure 6-25, which shows the normal distribution \nand the area to the right of 151.5 (representing “152 or more” yellow peas).\ncontinued\n",
    "272 \nCHAPTER 6 Normal Probability Distributions\nContinuity Correction\nWe want the area to the right of 151.5 in the bottom portion of Figure 6-25.\nTechnology: If using technology, we find that the shaded area is 0.2665.\nTable A-2: If using Table A-2, we must first find the z score using x = 151.5, \nm = 145, and s = 10.4283 as follows:\nz = x - m\ns\n= 151.5 - 145\n10.4283\n= 0.62\nUsing Table A-2, we find that z = 0.62 corresponds to a cumulative left \narea of 0.7324, so the shaded region in the bottom portion of Figure 6-25 is \n1 - 0.7324 = 0.2676. (The result of 0.2665 from technology is more accurate.)\nINTERPRETATION\nMendel’s result of 152 yellow peas is greater than the 145 yellow peas he expected \nwith his theory of hybrids, but with P(152 or more yellow peas) = 0.2665, we see \nthat 152 yellow peas is not significantly high. That is a result that could easily oc-\ncur with a true rate of 25% for yellow peas. This experiment does not contradict \n Mendel’s theory.\nDEFINITION\nWhen we use the normal distribution (which is a continuous probability distribution) \nas an approximation to the binomial distribution (which is discrete), a continuity \ncorrection is made to a discrete whole number x in the binomial distribution by \nrepresenting the discrete whole number x by the interval from x - 0.5 to x + 0.5 \n(that is, adding and subtracting 0.5).\nExample 1 used a continuity correction when the discrete value of 152 was repre-\nsented in the normal distribution by the area between 151.5 and 152.5. Because we \nwanted the probability of “152 or more” yellow peas, we used the area to the right of \n151.5. Here are other uses of the continuity correction:\nStatement About the Discrete Value\nArea of the Continuous Normal Distribution\nAt least 152 (includes 152 and above)\nTo the right of 151.5\nMore than 152 (doesn’t include 152)\nTo the right of 152.5\nAt most 152 (includes 152 and below)\nTo the left of 152.5\nFewer than 152 (doesn’t include 152)\nTo the left of 151.5\nExactly 152\nBetween 151.5 and 152.5\nEXAMPLE 2  Exactly 252 Yellow Peas\nUsing the same information from Example 1, find the probability of exactly 152 \nyellow peas among the 580 offspring peas. That is, given n = 580 and assuming \nthat p = 0.25, find P(exactly 152 yellow peas). Is this result useful for determining \nwhether 152 yellow peas is significantly high?\n",
    "6-6 Normal as Approximation to Binomial \n273\nINTERPRETATION\nIn Section 4-1 we saw that x successes among n trials is significantly high if the \nprobability of x or more successes is unlikely with a probability of 0.05 or less. In \ndetermining whether Mendel’s result of 152 yellow peas contradicts his theory that \n25% of the offspring should be yellow peas, we should consider the probability \nof 152 or more yellow peas, not the probability of exactly 152 peas. The result of \n0.0305 is not the relevant probability; the relevant probability is 0.2665 found in Ex-\nample 1. In general, the relevant result is the probability of getting a result at least \nas extreme as the one obtained.\nSOLUTION\nSee Figure 6-26, which shows the normal distribution with m = 145 and s = 10.4283.\nThe shaded area approximates the probability of exactly 152 yellow peas. That region \nis the vertical strip between 151.5 and 152.5, as shown. We can find that area by using \nthe same methods introduced in Section 6-2.\nTechnology: Using technology, the shaded area is 0.0305.\nTable A-2: Using Table A-2, we convert 151.5 and 152.5 to z = 0.62 and z = 0.72,\nwhich yield cumulative left areas of 0.7324 and 0.7642. Because they are both cu-\nmulative left areas, the shaded region in Figure 6-26 is 0.7642 - 0.7324 = 0.0318.\nThe probability of exactly 152 yellow peas is 0.0318.\n(s 5 10.4283)\n152.5\nm 5 145\nThis shaded area\napproximates the\nprobability of exactly\n152 yellow peas.\n151.5\nFIGURE 6-26 Probability of Exactly 152 Yellow Peas\nTechnology for Binomial Probabilities\nThis topic of using a normal distribution to approximate a binomial distribution was \nonce quite important, but we can now use technology to find binomial probabilities \nthat were once beyond our capabilities. For example, see the following Statdisk dis-\nplay on the next page showing that for Example 1, the probability of 152 or more \nyellow peas is 0.2650, and for Example 2, the probability of exactly 152 yellow peas \nis 0.0301, so there is no real need to use a normal approximation. However, there are \ncases where we need to use a normal approximation, and Section 8-3 uses a normal \napproximation to a binomial distribution for an important statistical method intro-\nduced in that section.\n",
    "274 \nCHAPTER 6 Normal Probability Distributions\nStatistical Literacy and Critical Thinking \n1.  Continuity Correction In testing the assumption that the probability of a baby boy is \n0.512, a geneticist obtains a random sample of 1000 births and finds that 502 of them are boys. \nUsing the continuity correction, describe the area under the graph of a normal distribution cor-\nresponding to the following. (For example, the area corresponding to “the probability of at least \n502 boys” is this: the area to the right of 501.5.)\na. The probability of 502 or fewer boys\nb. The probability of exactly 502 boys\nc. The probability of more than 502 boys\n2.  Checking Requirements Common tests such as the SAT, ACT, LSAT (Law School \n Admissions Test), and MCAT (Medical College Admissions Test) use multiple choice test \nquestions, each with possible answers of a, b, c, d, e, and each question has only one correct \nanswer. We want to find the probability of getting at least 25 correct answers for someone who \nmakes random guesses for answers to a block of 100 questions. If we plan to use the methods \nof this section with a normal distribution used to approximate a binomial distribution, are the \nnecessary requirements satisfied? Explain.\n3. Notation Common tests such as the SAT, ACT, LSAT, and MCAT tests use multiple choice \ntest questions, each with possible answers of a, b, c, d, e, and each question has only one cor-\nrect answer. For people who make random guesses for answers to a block of 100 questions, \nidentify the values of p, q, m, and s. What do m and s measure?\n4. Distribution of Proportions Each week, Nielsen Media Research conducts a survey of \n5000 households and records the proportion of households tuned to Sanjay Gupta MD. If we \nobtain a large collection of those proportions and construct a histogram of them, what is the ap-\nproximate shape of the histogram?\n6-6 Basic Skills and Concepts\n",
    "6-6 Normal as Approximation to Binomial \n275\nUsing Normal Approximation. In Exercises 5–8, do the following: If the requirements \nof np # 5 and nq # 5 are both satisfied, estimate the indicated probability by using the \nnormal distribution as an approximation to the binomial distribution; if np * 5 or nq * 5, \nthen state that the normal approximation should not be used.\n5. Births of Boys With n = 20 births and p = 0.512 for a boy, find P(fewer than 8 boys).\n6. Births of Boys With n = 8 births and p = 0.512 for a boy, find P(exactly 5 boys).\n7. Guessing on United States Medical Licensing Examinations With n = 20 guesses \nand p = 0.2 for a correct answer, find P(at least 6 correct answers).\n8. Guessing on United States Medical Licensing Examinations With n = 50 guesses \nand p = 0.2 for a correct answer, find P(exactly 12 correct answers).\nEye Colors. In Exercises 9–12, assume that eye colors are distributed as shown in the ac-\ncompanying display (based on data from a study by Dr. P. Sorita at Indiana University), and \nalso assume that 100 people are randomly selected.\n9.  Blue Eyes Find the probability that at least 40 of the 100 subjects have blue eyes. Is \n40 people with blue eyes significantly high?\n10. Blue Eyes Find the probability that at least 49 of the 100 subjects have blue eyes. Is \n49 people with blue eyes significantly high?\n11. Green Eyes Find the probability that fewer than 5 of the 100 subjects have green eyes. Is \n4 people with green eyes significantly low?\n12. Brown Eyes Find the probability that among the 100 subjects, 33 or fewer have brown \neyes. Is 33 people with brown eyes significantly low?\n13. Tamiflu Assume that 10% of subjects treated with Tamiflu (oseltamivir) experienced the \nadverse reaction of nausea (based on clinical trials).\na. Find the probability that among 250 randomly selected subjects treated with Tamiflu, ex-\nactly 17 of them experience nausea.\nb. Find the probability that among 250 randomly selected subjects treated with Tamiflu, the \nnumber who experience nausea is 17 or fewer.\nc. Does it appear that 17 cases of nausea among the 250 subjects is significantly low?\n14. Mendelian Genetics When Mendel conducted his famous genetics experiments with \npeas, one sample of offspring consisted of 929 peas, with 705 of them having red flowers. If \nwe assume, as Mendel did, that under these circumstances, there is a 3>4 probability that a pea \nwill have a red flower, we would expect that 696.75 (or about 697) of the peas would have red \nflowers, so the result of 705 peas with red flowers is more than expected.\na. If Mendel’s assumed probability is correct, find the probability of getting 705 or more peas \nwith red flowers.\ncontinued\n",
    "276 \nCHAPTER 6 Normal Probability Distributions\nb. Is 705 peas with red flowers significantly high?\nc. What do these results suggest about Mendel’s assumption that 3>4 of peas will have red \nflowers?\n15. Sleepwalking Assume that 29.2% of people have sleepwalked (based on “Prevalence \nand Comorbidity of Nocturnal Wandering in the U.S. Adult General Population,” by Ohayon \net al., Neurology, Vol. 78, No. 20). Assume that in a random sample of 1480 adults, 455 have \nsleepwalked.\na. Assuming that the rate of 29.2% is correct, find the probability that 455 or more of the 1480 \nadults have sleepwalked.\nb. Is that result significantly high?\nc. What does the result suggest about the rate of 29.2%?\n16. Cell Phones and Brain Cancer In a study of 420,095 cell phone users in Denmark, it \nwas found that 135 developed cancer of the brain or nervous system. For those not using cell \nphones, there is a 0.000340 probability of a person developing cancer of the brain or nervous \nsystem. We therefore expect about 143 cases of such cancers in a group of 420,095 randomly \nselected people.\na. Find the probability of 135 or fewer cases of such cancers in a group of 420,095 people.\nb. What do these results suggest about media reports that indicate cell phones cause cancer of \nthe brain or nervous system?\n17. Births The probability of a baby being born a boy is 0.512. Consider the problem of \nfinding the probability of exactly 7 boys in 11 births. Solve that problem using (1) normal ap-\nproximation to the binomial using Table A-2; (2) normal approximation to the binomial using \ntechnology instead of Table A-2; (3) using technology with the binomial distribution instead of \nusing a normal approximation. Compare the results. Given that the requirements for using the \nnormal approximation are just barely met, are the approximations off by very much?\n6-6 Beyond the Basics\nBone Density Test. In Exercises 1–4, assume that scores on a bone mineral density test \nare normally distributed with a mean of 0 and a standard deviation of 1.\n1. Bone Density Sketch a graph showing the shape of the distribution of bone density test \nscores.\n2. Bone Density Find the score separating the lowest 9% of scores from the highest 91%.\n3. Bone Density For a randomly selected subject, find the probability of a score greater than \n-2.93.\n4. Bone Density For a randomly selected subject, find the probability of a score between \n0.87 and 1.78.\n5. Notation \na. Identify the values of m and s for the standard normal distribution.\nb. What do the symbols mx and sx represent?\nChapter Quick Quiz\n",
    "In Exercises 6–10, assume that women have diastolic blood pressure measures that are \nnormally distributed with a mean of 70.2 mm Hg and a standard deviation of 11.2 mm Hg \n(based on Data Set 1 “Body Data” in Appendix B).\n6. Diastolic Blood Pressure Find the probability that a randomly selected woman has a \nnormal diastolic blood pressure level, which is below 80 mm Hg.\n7. Diastolic Blood Pressure Find the probability that a randomly selected woman has a \ndiastolic blood pressure level between 60 mm Hg and 80 mm Hg.\n8. Diastolic Blood Pressure Find P90, the 90th percentile for the diastolic blood pressure \nlevels of women.\n9. Diastolic Blood Pressure If 16 women are randomly selected, find the probability that \nthe mean of their diastolic blood pressure levels is less than 75 mm Hg.\n10.  Diastolic Blood Pressure The accompanying normal quantile plot was constructed \nfrom the diastolic blood pressure levels of a sample of women. What does this graph suggest \nabout diastolic blood pressure levels of women?\n1. Bone Density Test A bone mineral density test is used to identify a bone disease. The re-\nsult of a bone density test is commonly measured as a z score, and the population of z scores is \nnormally distributed with a mean of 0 and a standard deviation of 1.\na. For a randomly selected subject, find the probability of a bone density test score less than 1.54.\nb. For a randomly selected subject, find the probability of a bone density test score greater than \n-1.54.\nc. For a randomly selected subject, find the probability of a bone density test score between \n-1.33 and 2.33.\nd. Find Q1, the bone density test score separating the bottom 25% from the top 75%.\ne. If the mean bone density test score is found for 9 randomly selected subjects, find the prob-\nability that the mean is greater than 0.50.\n2. Biometric Security In designing a security system based on eye (iris) recognition, we must \nconsider the standing eye heights of women, which are normally distributed with a mean of \n59.7 in. and a standard deviation of 2.5 in. (based on anthropometric survey data from Gordon, \nChurchill, et al.).\na. If an eye recognition security system is positioned at a height that is uncomfortable for \nwomen with standing eye heights less than 54 in., what percentage of women will find that \nheight uncomfortable?\nb. In positioning the eye recognition security system, we want it to be suitable for the lowest \n95% of standing eye heights of women. What standing eye height of women separates the low-\nest 95% of standing eye heights from the highest 5%?\nReview Exercises\nCHAPTER 6 Review Exercises \n277\n",
    "278 \nCHAPTER 6 Normal Probability Distributions\n3. Biometric Security Standing eye heights of men are normally distributed with a mean of \n64.3 in. and a standard deviation of 2.6 in. (based on anthropometric survey data from Gordon, \nChurchill, et al.).\na. If an eye recognition security system is positioned at a height that is uncomfortable for men \nwith standing eye heights greater than 70 in., what percentage of men will find that height un-\ncomfortable?\nb. In positioning the eye recognition security system, we want it to be suitable for the tallest \n98% of standing eye heights of men. What standing eye height of men separates the tallest 98% \nof standing eye heights from the lowest 2%?\n4. Sampling Distributions Scores on the Gilliam Autism Rating Scale (GARS) are nor-\nmally distributed with a mean of 100 and a standard deviation of 15. A sample of 64 GARS \nscores is randomly selected and the sample mean is computed.\na. Describe the distribution of such sample means.\nb. What is the mean of all such sample means?\nc. What is the standard deviation of all such sample means?\n5. Unbiased Estimators\na. What is an unbiased estimator?\nb. For the following statistics, identify those that are unbiased estimators: mean, median, range, \nvariance, proportion.\nc. Determine whether the following statement is true or false: “The sample standard deviation is a \nbiased estimator, but the bias is relatively small in large samples, so s is often used to estimate s.”\n6. Disney Monorail The Mark VI monorail used at Disney World has doors with a height of \n72 in. Heights of men are normally distributed with a mean of 68.6 in. and a standard deviation \nof 2.8 in. (based on Data Set 1 “Body Data” in Appendix B).\na. What percentage of adult men can fit through the doors without bending? Does the door \ndesign with a height of 72 in. appear to be adequate? Explain.\nb. What doorway height would allow 99% of adult men to fit without bending?\n7. Disney Monorail Consider the same Mark VI monorail described in the preceding exer-\ncise. Again assume that heights of men are normally distributed with a mean of 68.6 in. and a \nstandard deviation of 2.8 in.\na. In determining the suitability of the monorail door height, why does it make sense to con-\nsider men while women are ignored?\nb. Mark VI monorail cars have a capacity of 60 passengers. If a car is loaded with 60 randomly \nselected men, what is the probability that their mean height is less than 72 in.?\nc. Why can’t the result from part (b) be used to determine how well the doorway height accom-\nmodates men?\n8.  Assessing Normality of BMI Data Listed below are measures of body mass index \n(BMI) for women listed in Data Set 1 “Body Data.”\na. Do these measures appear to come from a population that has a normal distribution? Why or \nwhy not?\nb. Can the mean of this sample be treated as a value from a population having a normal distri-\nbution? Why or why not?\n15.9 18.7 24.2 28.7 28.8 28.9 28.9 28.9 29.0 29.1 29.3 31.4 59.0\n9. Hybridization Experiment In one of Mendel’s experiments with plants, 1064 offspring \nconsisted of 787 plants with long stems. According to Mendel’s theory, 3>4 of the offspring \n",
    "plants should have long stems. Assuming that Mendel’s proportion of 3>4 is correct, find the \nprobability of getting 787 or fewer plants with long stems among 1064 offspring plants. Based \non the result, is 787 offspring plants with long stems significantly low? What does the result \nimply about Mendel’s claimed proportion of 3>4?\n10. Tall Clubs The social organization Tall Clubs International has a requirement that women \nmust be at least 70 in. tall. Assume that women have normally distributed heights with a mean \nof 63.7 in. and a standard deviation of 2.9 in. (based on Data Set 1 in Appendix B).\na. Find the percentage of women who satisfy the height requirement.\nb. If the height requirement is to be changed so that the tallest 2.5% of women are eligible, \nwhat is the new height requirement?\nIn Exercises 1–3, use the following left threshold audiometry measures from females (from \nData Set 4 “Audiometry” in Appendix B).\n15.9 18.7 24.2 28.7 28.8 28.9 28.9 28.9 29.0 29.1 29.3 31.4\n1. Audiometry\na. Find the mean x.\nb. Find the median.\nc. Find the standard deviation s.\nd. Convert the highest measure to a z score.\ne. What level of measurement (nominal, ordinal, interval, ratio) describes this data set?\nf. Are the measures of hearing discrete data or continuous data?\n2. Audiometry\na. Find Q1, Q2, and Q3.\nb. Construct a boxplot.\nc. Based on the accompanying normal quantile plot of the audiometry measurements, what do \nyou conclude about these sample data?\n3. Left-Handedness According to data from the American Medical Association, 10% of us \nare left-handed.\na. If three people are randomly selected, find the probability that they are all left-handed.\nb. If three people are randomly selected, find the probability that at least one of them is \n left-handed.\nCumulative Review Exercises\nCHAPTER 6 Cumulative Review Exercises \n279\ncontinued\n",
    "280 \nCHAPTER 6 Normal Probability Distributions\nc. Why can’t we solve the problem in part (b) by using the normal approximation to the bino-\nmial distribution?\nd. If groups of 50 people are randomly selected, what is the mean number of left-handed peo-\nple in such groups?\ne. If groups of 50 people are randomly selected, what is the standard deviation for the numbers \nof left-handed people in such groups?\nf. Use the range rule of thumb to determine whether 8 left-handed people is a significantly high \nnumber of left-handed people in a randomly selected group of 50 people.\n4. Blue Eyes Assume that 35% of us have blue eyes (based on a study by Dr. P. Soria at \n Indiana University).\na. Let B denote the event of selecting someone who has blue eyes. What does the event B\n denote?\nb. Find the value of P1B2.\nc. Find the probability of randomly selecting three different people and finding that all of them \nhave blue eyes.\nd. Find the probability that among 100 randomly selected people, at least 45 have blue eyes.\ne. If 35% of us really do have blue eyes, is a result of 45 people with blue eyes among 100 ran-\ndomly selected people a result that is significantly high?\n5. Foot Lengths of Women Assume that foot lengths of women are normally distributed \nwith a mean of 9.6 in. and a standard deviation of 0.5 in., based on data from the U.S. Army \nAnthropometry Survey (ANSUR).\na. Find the probability that a randomly selected woman has a foot length less than 10.0 in.\nb. Find the probability that a randomly selected woman has a foot length between 8.0 in. and \n11.0 in.\nc. Find P95.\nd. Find the probability that 25 women have foot lengths with a mean greater than 9.8 in.\nSome methods in this chapter are easy with technology but very difficult without it. The two \nprojects that follow illustrate how easy it is to use technology for assessing normality and find-\ning binomial probabilities.\n1. Assessing Normality It is often necessary to determine whether sample data appear to \nbe from a normally distributed population, and that determination is helped with the construc-\ntion of a histogram and normal quantile plot. Refer to Data Set 1 “Body Data” in Appendix B. \nFor each of the 13 columns of data (not including age or gender), determine whether the data \nappear to be from a normally distributed population. Use Statdisk or any other technology. \n(Download a free copy of Statdisk from www.statdisk.org.)\n2. Binomial Probabilities Section 6-6 described a method for using a normal distribution to \napproximate a binomial distribution. Many technologies are capable of generating probabilities \nfor a binomial distribution. Instead of using a normal approximation to a binomial distribution, \nuse technology to find the exact binomial probabilities in Exercises 9–12 of Section 6-6.\nTechnology Projects\n",
    "FROM DATA TO DECISION\nCritical Thinking: Designing a campus  \ndormitory elevator\nAn Ohio college student died when he tried to escape from \na dormitory elevator that was overloaded with 24 passen-\ngers. The elevator was rated for a maximum weight of 2500 \npounds. Let’s consider this elevator with an allowable weight \nof 2500 pounds. Let’s also consider parameters for weights \nof adults, as shown in the accompanying table (based on \nData Set 1 “Body Data” in Appendix B).\nWeights of Adults\nMales\nFemales\nm\n189 lb\n171 lb\ns\n39 lb\n46 lb\nDistribution\nNormal\nNormal\nWe could consider design features such as the type of music \nthat could be played on the elevator. We could select songs \nsuch as “Imagine” or “Daydream Believer.” Instead, we will \nfocus on the critical design feature of weight.\na. First, elevators commonly have a 25% margin of error, \nso they can safely carry a load that is 25% greater than the \nstated load. What amount is 25% greater than 2500 pounds? \nLet’s refer to this amount as “the maximum safe load,” \nwhile the 2500-pound limit is the “placard maximum load.”\nb. Now we need to determine the maximum number of pas-\nsengers that should be allowed. Should we base our calcula-\ntions on the maximum safe load or the 2500-pound placard \nmaximum load?\nc. The weights given in the accompanying table are weights \nof adults not including clothing or textbooks. Add another \n10 pounds for each student’s clothing and textbooks. What \nis the maximum number of elevator passengers that should \nbe allowed?\nd. Do you think that weights of college students are different \nfrom weights of adults from the general population? If so, \nhow? How would that affect the elevator design?\n1. In-class activity Divide into groups of three or four students and address these issues af-\nfecting the design of manhole covers.\n• Which of the following is most relevant for determining whether a manhole cover diameter of \n24 in. is large enough: weights of men, weights of women, heights of men, heights of women, \nhip breadths of men, hip breadths of women, shoulder breadths of men, shoulder breadths of \nwomen?\n• Why are manhole covers usually round? (This was once a popular interview question asked \nof applicants at IBM, and there are at least three good answers. One good answer is sufficient \nhere.)\n2. Out-of-class activity Divide into groups of three or four students. In each group, develop \nan original procedure to illustrate the central limit theorem. The main objective is to show that \nwhen you randomly select samples from a population, the means of those samples tend to be \nnormally distributed, regardless of the nature of the population distribution. For this illustra-\ntion, begin with some population of values that does not have a normal distribution.\n3. In-class activity Divide into groups of three or four students. Using a coin to simulate \nbirths, each individual group member should simulate 25 births and record the number of simu-\nlated girls. Combine all results from the group and record n = total number of births and x =\nnumber of girls. Given batches of n births, compute the mean and standard deviation for the \nnumber of girls. Is the simulated result unusual? Why or why not?\n4. In-class activity Divide into groups of three or four students. Select a set of data from \n Appendix B (excluding Data Sets that were used in examples or exercises in Section 6-5). Use \nthe methods of Section 6-5 to construct a histogram and normal quantile plot, and then deter-\nmine whether the data set appears to come from a normally distributed population.\nCooperative Group Activities\nCHAPTER 6 Cooperative Group Activities \n281\n",
    "282\nEstimating a Population \nProportion\nEstimating a Population \nMean\nEstimating a Population \nStandard Deviation or \nVariance\nBootstrapping: \nUsing Technology for \nEstimates\n7-1\n7-2\n7-3\n7-4\nDoes Touch Therapy Work?\nCHAPTER \nPROBLEM\nEstimating Parameters \nand Determining \nSample Sizes\nMany patients pay $30 to $60 for a session of touch therapy in \nwhich the touch therapist moves his or her hands within a few \ninches of the patient’s body without actually making physical \ncontact. The objective is to cure a wide variety of medical con-\nditions, including cancer, AIDS, asthma, heart disease, head-\naches, burns, and bone fractures. The intent is that a profes-\nsionally trained touch therapist can detect poor alignments in \nthe patient’s energy field, and can then reposition energy fields \nto create an energy balance that fosters the healing process.\nWhen she was in the fourth grade, nine-year old Emily \nRosa chose the topic of touch therapy for a science fair project. \nShe convinced 21 experienced touch therapists to participate \nin a simple test of their ability to detect a human energy field. \nEmily constructed a cardboard partition with two holes for \n7 \n",
    "hands. Each touch therapist would put both hands through the \ntwo holes, and Emily would place her hand just above one of \nthe therapist’s hands; then the therapist was asked to identify \nthe hand that Emily had selected. Emily used a coin toss to \nrandomly select the hand to be used. This test was repeated \n280 times. If the touch therapists really did have the ability to \nsense a human energy field, they should have identified the \ncorrect hand significantly more than 50% of the time. If they \ndid not have the ability to detect the energy field and they just \nguessed, they should have been correct about 50% of the time. \nHere are Emily’s results: Among the 280 trials, the touch thera-\npists identified the correct hand 123 times, for a success rate of \n43.9%. Emily, with the help of her mother, a statistician, and a \nphysician, submitted her findings for publication in the Journal \nof the American Medical Association. After a careful and thor-\nough review of the experimental design and results, the article \n“A Close Look at Therapeutic Touch” was published (Journal of \nthe American Medical Association, Vol. 279, No. 13). Emily be-\ncame the youngest researcher to be published in that journal. \nAnd she won a blue ribbon for her science fair project.\nLet’s consider the key results from Emily’s project. Among \nthe 280 trials, the touch therapists were correct 123 times. We \nhave a sample proportion with n = 280 and x = 123 suc-\ncesses. Arguments against the validity of the study might include \nthe claim that the number of trials is too small to be meaningful, \nor that the touch therapists just had a bad day and, because \nof chance, they were not as successful as the population of all \ntouch therapists. We will consider such issues in this chapter.\nIn this chapter we begin the study of methods of inferential statistics. Listed below are \nthe major activities of inferential statistics, and this chapter introduces methods for the \nfirst activity of using sample data to estimate population parameters. Chapter 8 will intro-\nduce the basic methods for testing claims (or hypotheses) about population  parameters.\nMajor Activities of Inferential Statistics\n1. Use sample data to estimate values of population parameters (such as a population \nproportion or population mean).\n2. Use sample data to test hypotheses (or claims) made about population parameters.\nHere are the chapter objectives.\nEstimating a Population Proportion\n• Construct a confidence interval estimate of a population proportion and interpret \nsuch confidence interval estimates.\n• Identify the requirements necessary for the procedure that is used, and determine \nwhether those requirements are satisfied.\n• Develop the ability to determine the sample size necessary to estimate a population \nproportion.\nEstimating a Population Mean\n• Construct a confidence interval estimate of a population mean, and be able to inter-\npret such confidence interval estimates.\n• Determine the sample size necessary to estimate a population mean.\nEstimating a Population Standard Deviation or Variance\n• Develop the ability to construct a confidence interval estimate of a population  standard \ndeviation or variance, and be able to interpret such confidence interval  estimates.\n7-1\n7-2\n7-3\nChapter Objectives \n283\nCHAPTER OBJECTIVES\n>>>\n",
    "284 \nCHAPTER 7 Estimating Parameters and Determining Sample Sizes\nKey Concept This section presents methods for using a sample proportion to make \nan inference about the value of the corresponding population proportion. This section \nfocuses on the population proportion p, but we can also work with probabilities or \npercentages. When working with percentages, we will perform calculations with the \nequivalent proportion value. Here are the three main concepts included in this section:\n \n■Point Estimate: The sample proportion (denoted by pn) is the best point estimate \n(or single value estimate) of the population proportion p.\n \n■Confidence Interval: We can use a sample proportion to construct a confidence \ninterval estimate of the true value of a population proportion, and we should \nknow how to construct and interpret such confidence intervals.\n \n■Sample Size: We should know how to find the sample size necessary to estimate \na population proportion.\nThe concepts presented in this section are used in the following sections and chapters, \nso it is important to understand this section quite well.\nPART 1\n  Point Estimate, Confidence Interval,  \nand Sample Size \nPoint Estimate\nIf we want to estimate a population proportion with a single value, the best estimate \nis the sample proportion pn. Because pn consists of a single value that is equivalent to a \npoint on a line, it is called a point estimate.\n7-1 \nEstimating a Population Proportion\nBootstrapping: Using Technology for Estimates\n• Develop the ability to use technology along with the bootstrapping method to con-\nstruct a confidence interval estimate of a population proportion, population mean, \nand population standard deviation and population variance.\n7-4\nBootstrapping: Using Technology for Estimates\n• Develop the ability to use technology along with the bootstrapping method to con-\nstruct a confidence interval estimate of a population proportion, population mean,\nand population standard deviation and population variance.\nDEFINITION\nA point estimate is a single value used to estimate a population parameter.\nThe sample proportion pn is the best point estimate of the population \np roportion p.\nUnbiased Estimator We use pn as the point estimate of p because it is unbiased and \nit is the most consistent of the estimators that could be used. (An unbiased estima-\ntor is a statistic that targets the value of the corresponding population parameter in \nthe sense that the sampling distribution of the statistic has a mean that is equal to the \ncorresponding population parameter. The statistic pn targets the population proportion \np.) The sample proportion pn is the most consistent estimator of p in the sense that the \nstandard deviation of sample proportions tends to be smaller than the standard devia-\ntion of other unbiased estimators of p.\n",
    "7-1 Estimating a Population Proportion \n285\nConfidence Interval\nWhy Do We Need Confidence Intervals? In Example 1 we saw that 0.439 is our best \npoint estimate of the population proportion p, but we have no indication of how good \nthat best estimate is. A confidence interval gives us a much better sense of how good \nan estimate is.\nEXAMPLE 1\nTouch Therapy\nThe Chapter Problem describes a test of touch therapy. If the touch therapists had \nthe ability to sense a human energy field, they should have identified the correct \nhand significantly more than 50% of the time. If they made random guesses, their \nsuccess rate should be around 50%. Using the result of 123 correct responses in the \n280 trials, find the best point estimate of the proportion of correct responses.\nSOLUTION\nBecause the sample proportion is the best point estimate of the population propor-\ntion, we conclude that the best point estimate of p is 123>280 or 0.439. (If using \nthe sample results to estimate the percentage of correct responses, the best point \n estimate is 43.9%.)\nDEFINITION\nA confidence interval (or interval estimate) is a range (or an interval) of values \nused to estimate the true value of a population parameter. A confidence interval is \nsometimes abbreviated as CI.\nDEFINITION\nThe confidence level is the probability 1 - a (such as 0.95, or 95%) that the con-\nfidence interval actually does contain the population parameter, assuming that the \nestimation process is repeated a large number of times. (The confidence level is \nalso called the degree of confidence, or the confidence coefficient.)\nThe following table shows the relationship between the confidence level and the cor-\nresponding value of a. The confidence level of 95% is the value used most often.\nMost Common Confidence Levels\nCorresponding Values of A\n90% (or 0.90) confidence level:\na = 0.10\n95% (or 0.95) confidence level:\na = 0.05\n99% (or 0.99) confidence level:\na = 0.01\nHere’s an example of a confidence interval found later in Example 3:\nThe 0.95 (or 95%) conﬁdence interval estimate of the population proportion \np is 0.381 * p * 0.497.\ne \nBias in Internet  \nSurveys?\nCapitalizing on \nthe widespread \nuse of technol-\nogy and social \nmedia, there is a \ngrowing trend to \nconduct surveys \nusing only the \nInternet instead of using in-\nperson interviews or phone calls \nto randomly selected subjects. \nInternet surveys are faster and \nmuch less expensive, and they \nprovide important advantages in \nsurvey design and administra-\ntion. But are Internet surveys \nbiased because they use only \nsubjects randomly selected from \nthe 90% of the U.S. population \nthat uses the Internet? The Pew \nResearch Center studied this \nissue by comparing results from \nonline polls to polls that included \nthe offline population. It was \nfound that the differences were \ngenerally quite small, but topics \nrelated to the Internet and tech-\nnology resulted in much larger \ndifferences. We should be careful \nto consider consequences of \nbias with Internet surveys.\n",
    "286 \nCHAPTER 7 Estimating Parameters and Determining Sample Sizes\nInterpreting a Confidence Interval\nWe must be careful to interpret confidence intervals correctly. There is a correct inter-\npretation and many different and creative incorrect interpretations of the confidence \ninterval 0.381 6 p 6 0.497.\nCorrect: \n “We are 95% confident that the interval from 0.381 to 0.497 actu-\nally does contain the true value of the population proportion p.”\n This is a short and acceptable way of saying that if we were to \nselect many different random samples of size 280 (as in the Chapter \nProblem) and construct the corresponding confidence intervals, 95% \nof them would contain the population proportion p. In this correct \ninterpretation, the confidence level of 95% refers to the success rate \nof the process used to estimate the population proportion.\nWrong: \n “There is a 95% chance that the true value of p will fall between \n0.381 and 0.497.”\n This is wrong because p is a population parameter with a fixed \nvalue; it is not a random variable with values that vary.\nWrong: \n “95% of sample proportions will fall between 0.381 and 0.497.”\n This is wrong because the values of 0.381 and 0.497 result from one \nsample; they are not parameters describing the behavior of all samples.\nConfidence Level: The Process Success Rate A confidence level of 95% tells us that \nthe process we are using should, in the long run, result in confidence interval limits that \ncontain the true population proportion 95% of the time. Suppose that the true proportion \nof correct responses by the touch therapists is p = 0.50. See Figure 7-1, which shows \nthat 19 out of 20 (or 95%) different confidence intervals contain the assumed value of \np = 0.50. Figure 7-1 is trying to tell this story: With a 95% confidence level, we expect \nabout 19 out of 20 confidence intervals (or 95%) to contain the true value of p.\nThis conﬁdence interval\ndoes not contain p 5 0.50.\n0.45\np 5 0.50\n0.55\nFIGURE 7-1  Confidence Intervals from  \n20 Different Samples\nCritical Values\nCritical values are formally defined on the next page and they are based on the follow-\ning observations:\n1. When certain requirements are met, the sampling distribution of sample propor-\ntions can be approximated by a normal distribution, as shown in Figure 7-2.\n2. A z score associated with a sample proportion has a probability of a>2 of fall-\ning in the right tail portion of Figure 7-2.\n3. The z score at the boundary of the right-tail region is commonly denoted \nby za>2 and is referred to as a critical value because it is on the borderline \nseparating z scores that are significantly high.\nza/2\na/2\na/2\nFound from\ntechnology or\nTable A-2\nz 5 0\nFIGURE 7-2\nCritical \nValue zA,2 in the Standard \nNormal Distribution\n",
    "7-1 Estimating a Population Proportion \n287\nExample 2 showed that a 95% confidence level results in a critical value of \nza>2 = 1.96. This is the most common critical value, and it is listed with two other \ncommon values in the table that follows.\nConfidence Level\na\nCritical Value, zA>2\n90%\n0.10\n1.645\n95%\n0.05\n     1.96\n99%\n0.01\n2.575\nDEFINITION\nA critical value is the number on the borderline separating sample statistics that \nare significantly high or low from those that are not significant. The number za>2 is a \ncritical value that is a z score with the property that it is at the border that separates \nan area of a>2 in the right tail of the standard normal distribution (as in Figure 7-2).\nEXAMPLE 2\nFinding a Critical Value\nFind the critical value za>2 corresponding to a 95% confidence level.\nSOLUTION\nA 95% confidence level corresponds to a = 0.05, so a>2 = 0.025. Figure 7-3 \nshows that the area in each of the green-shaded tails is a>2 = 0.025. We find \nza>2 = 1.96 by noting that the cumulative area to its left must be 1 - 0.025, or \n0.975. We can use technology or refer to Table A-2 to find that the cumulative left \narea of 0.9750 corresponds to z = 1.96. For a 95% confidence level, the critical \nvalue is therefore za>2 = 1.96.\nNote that when finding the critical z score for a 95% confidence level, we use a \ncumulative left area of 0.9750 (not 0.95). Think of it this way:\nThis is our \n The area in both  \nThe area in the right The cumulative area from the left,\nconfidence level: \ntails is: \n tail is: \nexcluding the right tail, is:\n95% \nu  A = 0.05 \nu  \nA,2 = 0.025 \nu  \n1 −0.025 = 0.975\nConﬁdence Level: 95%\nThe total area to the\nleft of this boundary\nis 0.975.\na/2 5 0.025\na/2 5 0.025\nz 5 0\nza/2 5 1.96\n2za/2 5 21.96\nFIGURE 7-3  Finding the Critical Value zA,2 for a 95%  \nConfidence Level\nHow the Poll Was \nConducted\nThe New York \nTimes is quite \ngood at report-\ning poll results. \nThat newspaper \noften reports on \npoll results with \nan accompanying article bearing \nthe headline “How the Poll Was \nConducted.” The description \ntypically includes the sample \nsize, the margin of error, and the \nfollowing statement disclosing \nthat the confidence level is 95%: \n“In theory, in 19 cases out of 20, \noverall results based on such \nsamples will differ by no more \nthan. . . .” One recent report also \nprovided information that the poll \nincluded adults who were regis-\ntered to vote; landline telephone \nnumbers were randomly selected \nby a computer; cell phone num-\nbers were also randomly gener-\nated; and results were weighted \naccording to geographic region, \nsex, race, marital status, age, \nand education. The “How the Poll \nWas Conducted” descriptions \nare a model for all media who \nreport on polls.\ni l\nb\ni\n",
    "288 \nCHAPTER 7 Estimating Parameters and Determining Sample Sizes\nDEFINITION\nWhen data from a simple random sample are used to estimate a population propor-\ntion p, the difference between the sample proportion pn and the population propor-\ntion p is an error. The maximum likely amount of that error is the margin of error, \ndenoted by E. There is a probability of 1 - a (such as 0.95) that the difference be-\ntween pn and p is E or less. The margin of error E is also called the maximum error \nof  the estimate and can be found by multiplying the critical value and the estimated \nstandard deviation of sample proportions, as shown in Formula 7-1.\nFORMULA 7-1\nE = za>2B\npnqn\nn  margin of error for proportions\nc \nc\nCritical value Estimated standard deviation of sample proportions\nConfidence Interval for Estimating a Population Proportion p\nObjective\nConstruct a confidence interval used to estimate a population proportion p.\nNotation\np =  population proportion\npn = sample proportion\nn = number of sample values\nE = margin of error\nza>2 =  critical value: the z score separating an area of a>2 \nin the right tail of the standard normal distribution\nKEY ELEMENTS\n1. The sample is a simple random sample.\n2. The conditions for the binomial distribution are satis-\nfied: There is a fixed number of trials, the trials are \nindependent, there are two categories of outcomes, and \nthe probabilities remain constant for each trial (as in \nSection 5-2).\n3. There are at least 5 successes and at least 5 failures. \n(This requirement is a way to verify that np Ú 5 and \nnq Ú 5, so the normal distribution is a suitable ap-\nproximation to the binomial distribution.)\nConfidence Interval Estimate of p\npn - E 6 p 6 pn + E  where  E = za>2B\npnqn\nn\nThe confidence interval is often expressed in the following two equivalent formats:\npn { E or \n1pn - E,  pn + E2\nRound-Off Rule for Confidence Interval Estimates of p\nRound the confidence interval limits for p to three significant digits.\nRequirements\nMargin of Error\nWe now formally define the margin of error E that we have all heard about so often in \nmedia reports.\n",
    "7-1 Estimating a Population Proportion \n289\nProcedure for Constructing a Confidence Interval for p\n1. Verify that the requirements in the preceding Key Elements box are satisfied.\n2. Use technology or Table A-2 to find the critical value za>2 that corresponds to \nthe desired confidence level.\n3. Evaluate the margin of error E = za>22pnqn>n.\n4. Using the value of the calculated margin of error E and the value of the sample \nproportion pn, find the values of the confidence interval limits pn - E and \npn + E. Substitute those values in the general format for the confidence interval.\n5. Round the resulting confidence interval limits to three significant digits.\nEXAMPLE 3  Constructing a Confidence Interval: Touch Therapy\nIn the Chapter Problem we noted that in an experiment with touch therapists, they \nmade correct responses in 123 of the 280 trials. The sample results are n = 280 and \npn = 123>280, or 0.439.\n \na. Find the margin of error E that corresponds to a 95% conﬁdence level.\n \nb. Find the 95% conﬁdence interval estimate of the population proportion p.\n \nc. Based on the results, can we safely conclude that the touch therapists had a \nsuccess rate equivalent to tossing a coin?\nSOLUTION\nREQUIREMENT CHECK (1) The experiment was examined and found to be sound, so \nwe will treat the results as simple random samples. (2) The conditions for a bino-\nmial experiment are satisfied, because there is a fixed number of trials (280), the \ntrials are independent (because the response from one touch therapist doesn’t affect \nthe probability of the response from another touch therapist), there are two catego-\nries of outcome (response was correct or incorrect), and the probability remains \nconstant and is not changing over time. (3) The number of successes (123 correct \nresponses) and the number of failures (157 incorrect responses) are both at least 5. \nThe check of requirements has been successfully completed. \nTechnology The confidence interval and margin of error can be easily found using \ntechnology. From the Statdisk display we can see the required entries on the left \nand the results displayed on the right. The results show that the margin of error is \nE = 0.0581 (rounded) and the confidence interval is 0.381 6 p 6 0.497 (round-\ned). (The Wilson score confidence interval included in the display will be discussed \nlater in Part 2 of this section.)\nStatdisk\ncontinued\n",
    "290 \nCHAPTER 7 Estimating Parameters and Determining Sample Sizes\nFinding the Point Estimate and E from a Confidence Interval\nSometimes we want to better understand a confidence interval that might have been \nobtained from a journal article or technology. If we already know the confidence inter-\nval limits, the sample proportion (or the best point estimate) pn and the margin of error \nE can be found as follows:\nPoint estimate of p: \npn = 1upper confidence interval limit2 + 1lower confidence interval limit2\n2\nMargin of error:\nE = 1upper confidence interval limit2 - 1lower confidence interval limit2\n2\nManual Calculation Here is how to find the confidence interval with manual cal-\nculations:\na. The margin of error is found by using Formula 7-1 with za>2 = 1.96 (as found \nin Example 2), pn = 0.439,  qn = 0.561, and n = 280.\nE = za>2 B\npnqn\nn = 1.96 B\n10.4392 10.5612\n280\n= 0.058129\n \nb. Constructing the conﬁdence interval is really easy now that we know that \npn = 0.439 and E = 0.058129. Simply substitute those values to obtain this \nresult:\n pn - E 6 p 6 pn + E\n 0.439 - 0.058129 6 p 6 0.439 + 0.058129\n 0.381 6 p 6 0.497 1rounded to three significant digits2\nThis same result could be expressed in the format of 0.439 { 0.058 or \n(0.381, 0.497). If we want the 95% conﬁdence interval for the true population \npercentage, we could express the result as 38.1% 6 p 6 49.7%.\n \nc. Based on the conﬁdence interval obtained in part (b), it appears that fewer \nthan 50% of the touch therapist responses are correct (because the interval of \nvalues from 0.381 to 0.497 is an interval that is completely below 0.50).\nEXAMPLE 4   Finding the Sample Proportion  \nand Margin of Error\nThe article “High-Dose Nicotine Patch Therapy,” by Dale, Hurt, et al. (Journal \nof the American Medical Association, Vol. 274, No. 17) includes this statement: \n “Of the 71 subjects, 70% were abstinent from smoking at 8 weeks (95% confidence \ninterval [CI], 58% to 81%).” Use that statement to find the point estimate pn and the \nmargin of error E.\n",
    "7-1 Estimating a Population Proportion \n291\nUsing Confidence Intervals for Hypothesis Tests\nA confidence interval can be used to informally address some claim made about a \npopulation proportion p. For example, if sample results consist of 70 girls in 100 \nbirths, the resulting 95% confidence interval of 0.610 6 p 6 0.790 can be used to \ninformally support a claim that the proportion of girls is different from 50% (because \n0.50 is not contained within the confidence interval).\nDetermining Sample Size\nIf we plan to collect sample data in order to estimate some population proportion, \nhow do we know how many sample units we must get? If we solve the formula for the \nmargin of error E (Formula 7-1) for the sample size n, we get Formula 7-2 that fol-\nlows. Formula 7-2 requires pn as an estimate of the population proportion p, but if no \nsuch estimate is known (as is often the case), we replace pn by 0.5 and replace qn by 0.5, \nwith the result given in Formula 7-3. Replacing pn and qn with 0.5 results in the largest \npossible sample size, so we are sure that the sample size is adequate for estimating p.\nSOLUTION\nWe get the 95% confidence interval of 0.58 6 p 6 0.81 from the given statement \nof “58% to 81%.” The point estimate pn is the value midway between the upper and \nlower confidence interval limits, so we get\n pn = 1upper confidence limit2 + 1lower confidence limit2\n2\n = 0.81 + 0.58\n2\n= 0.695\nThe margin of error can be found as follows:\n E = 1upper confidence limit2 - 1lower confidence limit2\n2\n = 0.81 - 0.58\n2\n= 0.115\nFinding the Sample Size Required to Estimate a Population Proportion\nObjective\nDetermine how large the sample size n should be in order to estimate the population proportion p.\nNotation\np = population proportion\npn = sample proportion\nn = number of sample values\nE = desired margin of error\nza>2 =  z score separating an area of a>2 in the right tail of the standard normal distribution\nKEY ELEMENTS\ncontinued\n",
    "292 \nCHAPTER 7 Estimating Parameters and Determining Sample Sizes\nRequirements\nThe sample must be a simple random sample of independent sample units.\nWhen an estimate pn is known:  Formula 7-2  n =\n3za>242 pnqn\nE2\nWhen no estimate pn is known:  Formula 7-3  n =\n3za>242 0.25\nE2\nIf a reasonable estimate of pn can be made by using previous samples, a pilot study, or someone’s expert knowledge, use \nFormula 7-2. If nothing is known about the value of pn, use Formula 7-3.\nRound-Off Rule for Determining Sample Size\nIf the computed sample size n is not a whole number, round the value of n up to the next larger whole number, so the \nsample size is sufficient instead of being slightly insufficient. For example, round 384.16 to 385.\nEXAMPLE 5   What Percentage of Children Have Received \n Measles Vaccinations?\nIf we were to conduct a survey to determine the percentage of children (older than \n1 year) who have received measles vaccinations, how many children must be sur-\nveyed in order to be 95% confident that the sample percentage is in error by no \nmore than three percentage points?\n \na. Assume that a recent survey showed that 90% of children have received \nmeasles vaccinations.\n \nb. Assume that we have no prior information suggesting a possible value of the \npopulation proportion.\nSOLUTION\n \na. With a 95% conﬁdence level, we have a = 0.05, so za>2 = 1.96. Also, the \nmargin of error is E = 0.03, which is the decimal equivalent of “three per-\ncentage points.” The prior survey suggests that pn = 0.90, so qn = 0.10 (found \nfrom qn = 1 - 0.90). Because we have an estimated value of pn, we use \n Formula 7-2 as follows:\n n =\n3za>242 pnqn\nE2\n= 31.9642 10.90210.102\n0.032\n \n= 384.16 = 385 1rounded up2\n \n We must obtain a simple random sample that includes at least 385 children.\n \nb. With no prior knowledge of pn (or qn), we use Formula 7-3 as follows:\nn =\n3za>242 # 0.25\nE2\n= 31.9642 # 0.25\n0.032\n \n= 1067.11 = 1068 1rounded  up2\n \n We must obtain a simple random sample that includes at least 1068 children.\n",
    "7-1 Estimating a Population Proportion \n293\nRole of the Population Size N Formulas 7-2 and 7-3 are remarkable because they \nshow that the sample size does not depend on the size (N) of the population; the \nsample size depends on the desired confidence level, the desired margin of error, and \nsometimes the known estimate of pn. (See Exercise 37 for dealing with cases in which \na relatively large sample is selected without replacement from a finite population, so \nthe sample size n does depend on the population size N.)\nPART 2\nBetter-Performing Confidence Intervals \nDisadvantage of Wald Confidence Interval\nCoverage Probability The coverage probability of a confidence interval is the ac-\ntual proportion of such confidence intervals that contain the true population propor-\ntion. If we select a specific confidence level, such as 0.95 (or 95%), we would like to \nget the actual coverage probability equal to our desired confidence level. However, for \nthe confidence interval described in Part 1 (called a “Wald confidence interval”), the \nactual coverage probability is usually less than or equal to the confidence level that we \nselect, and it could be substantially less. For example, if we select a 95% confidence \nlevel, we usually get 95% or fewer of confidence intervals containing the population \nproportion p. (This is sometimes referred to as being “too liberal.”) For this reason, \nthe Wald confidence interval is rarely used in professional applications and profes-\nsional journals.\nBetter-Performing Confidence Intervals\nImportant note about exercises: Except for some Beyond the Basics exercises, the \nexercises for this Section 7-1 are based on the method for constructing a Wald con-\nfidence interval as described in Part 1, not the confidence intervals described here. It \nis recommended that students learn the methods presented earlier, but recognize that \nthere are better methods available, and they can be used with suitable technology.\nINTERPRETATION\nTo be 95% confident that our sample percentage is within three percentage points \nof the true percentage for all children, we should obtain a simple random sample of \n1068 children, assuming no prior knowledge. By comparing this result to the sam-\nple size of 385 found in part (a), we can see that if we have no knowledge of a prior \nstudy, a larger sample is required to achieve the same results compared to when the \nvalue of pn can be estimated.\nCAUTION Try to avoid these three common errors when calculating sample size:\n1.  Don’t make the mistake of using E = 3 as the margin of error corresponding to \n“three percentage points.” If the margin of error is three percentage points, use \nE = 0.03.\n2.  Be sure to substitute the critical z score for za>2. For example, when working with \n95% conﬁdence, be sure to replace za>2 with 1.96. Don’t make the mistake of \nreplacing za>2 with 0.95 or 0.05.\n3.  Be sure to round up to the next higher integer; don’t round oﬀ using the usual \nround-oﬀ rules. Round 1067.11to 1068.\n",
    "294 \nCHAPTER 7 Estimating Parameters and Determining Sample Sizes\nPlus Four Method The plus four confidence interval performs better than the Wald \nconfidence interval in the sense that its coverage probability is closer to the confi-\ndence level that is used. The plus four confidence interval uses this very simple pro-\ncedure: Add 2 to the number of successes x, add 2 to the number of failures (so that \nthe number of trials n is increased by 4), and then find the Wald confidence interval \nas described in Part 1 of this section. The plus four confidence interval is very easy to \ncalculate and it has coverage probabilities similar to those for the Wilson score confi-\ndence interval that follows.\nWilson Score Another confidence interval that performs better than the Wald CI is \nthe Wilson score confidence interval:\n pn +\nz2\na>2\n2n { za>2 B\npnqn +\nz2\na>2\n4n\nn\n1 +\nz2\na>2\nn\nThe Wilson score confidence interval performs better than the Wald CI in the sense \nthat the coverage probability is closer to the confidence level. With a confidence level \nof 95%, the Wilson score confidence interval would get us closer to a 0.95 probability \nof containing the parameter p. The complexity of the above expression can be circum-\nvented by using some technologies, such as Statdisk or XLSTAT, that provide Wilson \nscore confidence interval results.\nClopper-Pearson Method The Clopper-Pearson method is an “exact” method in \nthe sense that it is based on the exact binomial distribution instead of an approxima-\ntion of a distribution. It is criticized for being too conservative in this sense: When we \nselect a specific confidence level, the coverage probability is usually greater than or \nequal to the selected confidence level. Select a confidence level of 0.95, and the actual \ncoverage probability is usually 0.95 or greater, so that 95% or more of such confidence \nintervals will contain p. Calculations with this method are too messy to consider here.\nWhich Method Is Best? There are other methods for constructing confidence inter-\nvals that are not discussed here. There isn’t universal agreement on which method is \nbest for constructing a confidence interval estimate of p.\n \n■The Wald confidence interval is best as a teaching tool for introducing students \nto confidence intervals.\n \n■The plus four confidence interval is almost as easy as Wald and it performs bet-\nter than Wald by having a coverage probability closer to the selected confidence \nlevel.\nAgain, note that except for some Beyond the Basic exercises, the exercises that fol-\nlow are based on the Wald confidence interval given earlier, not the better-performing \nconfidence intervals discussed here.\nProportions: Confidence Intervals & Sample Size Determination\nAccess tech instructions, videos, and data sets at www.TriolaStats.com\nTECH CENTER \n",
    "7-1 Estimating a Population Proportion \n295\nStatistical Literacy and Critical Thinking\n1. Reporting Results Here is a result stated in a format commonly used in the media: “In a \nclinical trial of 227 subjects treated with OxyContin (oxycodone), 13% of the subjects reported \ndizziness. The margin of error is {4 percentage points.” What important feature of the poll is \nomitted?\n2. Margin of Error For the poll described in Exercise 1, describe what is meant by the state-\nment that “the margin of error was given as {4 percentage points.”\n3. Notation For the poll described in Exercise 1, what values do pn, qn, n, E, and p represent? If \nthe confidence level is 95%, what is the value of a?\n4. Confidence Levels Given specific sample data, such as the data given in Exercise 1, which \nconfidence interval is wider: the 95% confidence interval or the 80% confidence interval? Why \nis it wider?\nFinding Critical Values. In Exercises 5–8, find the critical value zA, 2 that corresponds to \nthe given confidence level.\n5. 90%   6. 99%   7. 99.5%   8. 98%\nFormats of Confidence Intervals. In Exercises 9–12, express the confidence interval us-\ning the indicated format. (The confidence intervals are based on proportions of eye colors.)\n9. Brown Eyes Express 0.375 6  p 6 0.425 in the form of pn { E.\n10. Blue Eyes Express 0.275 6  p 6 0.425 in the form of pn { E.\n11. Green Eyes Express the confidence interval (0.0780, 0.162) in the form of \npn - E 6 p 6 pn + E.\n12. Gray Eyes Express the confidence interval 0.070 { 0.021 in the form of \npn - E 6 p 6 pn + E.\nConstructing and Interpreting Confidence Intervals. In Exercises 13–16, use the \ngiven sample data and confidence level. In each case, (a) find the best point estimate of the \npopulation proportion p; (b) identify the value of the margin of error E; (c) construct the \nconfidence interval; (d) write a statement that correctly interprets the confidence interval.\n13. OxyContin In a clinical trial of OxyContin (oxycodone), 16 subjects experienced head-\naches among the 227 subjects treated with OxyContin. Construct a 95% confidence interval for \nthe proportion of treated subjects who experience headaches.\n14. Eliquis The drug Eliquis (apixaban) is used to help prevent blood clots in certain patients. \nIn clinical trials, among 5924 patients treated with Eliquis, 153 developed the adverse reaction \nof nausea (based on data from Bristol-Myers Squibb Co.). Construct a 99% confidence interval \nfor the proportion of adverse reactions.\n15. Survey Return Rate In a study of cell phone use and brain hemispheric dominance, an \nInternet survey was e-mailed to 5000 subjects randomly selected from an online group whose \nfocus is related to ears. 717 surveys were returned. Construct a 90% confidence interval for the \nproportion of returned surveys.\n16. Medical Malpractice In a study of 1228 randomly selected medical malpractice lawsuits, \nit was found that 856 of them were dropped or dismissed (based on data from the Physicians \nInsurers Association of America). Construct a 95% confidence interval for the proportion of \nmedical malpractice lawsuits that are dropped or dismissed.\n7-1 Basic Skills and Concepts \n",
    "296 \nCHAPTER 7 Estimating Parameters and Determining Sample Sizes\nCritical Thinking. In Exercises 17–28, use the data and confidence level to construct a \nconfidence interval estimate of p, then address the given question.\n17. Births A random sample of 860 births in New York State included 426 boys. Construct \na 95% confidence interval estimate of the proportion of boys in all births. It is believed that \namong all births, the proportion of boys is 0.512. Do these sample results provide strong evi-\ndence against that belief?\n18. Mendelian Genetics One of Mendel’s famous genetics experiments yielded 580 peas, \nwith 428 of them green and 152 yellow.\na. Find a 99% confidence interval estimate of the percentage of green peas.\nb. Based on his theory of genetics, Mendel expected that 75% of the offspring peas would be \ngreen. Given that the percentage of offspring green peas is not 75%, do the results contradict \nMendel’s theory? Why or why not?\n19. OxyContin The drug OxyContin (oxycodone) is used to treat pain, but it is danger-\nous because it is addictive and can be lethal. In clinical trials, 227 subjects were treated with \n OxyContin and 52 of them developed nausea (based on data from Purdue Pharma L.P.).\na. Construct a 95% confidence interval estimate of the percentage of OxyContin users who \ndevelop nausea.\nb. Compare the result from part (a) to this 95% confidence interval for 5 subjects who developed \nnausea among the 45 subjects given a placebo instead of OxyContin: 1.93% 6 p 6 20.3%.\nWhat do you conclude?\n20. Medication Usage In a survey of 3005 adults aged 57 through 85 years, it was found that \n81.7% of them used at least one prescription medication (based on data from “Use of Prescrip-\ntion and Over-the-Counter Medications and Dietary Supplements Among Older Adults in the \nUnited States,” by Qato et al., Journal of the American Medical Association, Vol. 300, No. 24).\na. How many of the 3005 subjects used at least one prescription medication?\nb. Construct a 90% confidence interval estimate of the percentage of adults aged 57 through \n85 years who use at least one prescription medication.\nc. What do the results tell us about the proportion of college students who use at least one \n prescription medication?\n21. Cell Phones and Cancer A study of 420,095 Danish cell phone users found that 0.0321% \nof them developed cancer of the brain or nervous system. Prior to this study of cell phone use, \nthe rate of such cancer was found to be 0.0340% for those not using cell phones. The data are \nfrom the Journal of the National Cancer Institute.\na. Use the sample data to construct a 90% confidence interval estimate of the percentage of cell \nphone users who develop cancer of the brain or nervous system.\nb. Do cell phone users appear to have a rate of cancer of the brain or nervous system that is dif-\nferent from the rate of such cancer among those not using cell phones? Why or why not?\n22. Lipitor In clinical trials of the drug Lipitor (atorvastatin), 270 subjects were given a pla-\ncebo and 7 of them had allergic reactions. Among 863 subjects treated with 10 mg of the drug, \n8 experienced allergic reactions. Construct the two 95% confidence interval estimates of the \npercentages of allergic reactions. Compare the results. What do you conclude?\n23. Gender Selection Before its clinical trials were discontinued, the Genetics & IVF In-\nstitute conducted a clinical trial of the XSORT method designed to increase the probability of \nconceiving a girl and, among the 945 babies born to parents using the XSORT method, there \nwere 879 girls. Construct the 95% confidence interval estimate of the percentage of success. \nWhat do you conclude?\n",
    "7-1 Estimating a Population Proportion \n297\n 24. Gender Selection Before its clinical trials were discontinued, the Genetics & IVF In-\nstitute conducted a clinical trial of the YSORT method designed to increase the probability of \nconceiving a boy and, among the 291 babies born to parents using the YSORT method, there \nwere 239 boys. What do you conclude?\n25. Postponing Death An interesting hypothesis is that individuals can temporarily postpone \ntheir death to survive a major holiday or important event such as a birthday. In a study of this \nphenomenon, it was found that in the week before and the week after Thanksgiving, there were \n12,000 total deaths, and 6062 of them occurred in the week before Thanksgiving (based on data \nfrom “Holidays, Birthdays, and Postponement of Cancer Death,” by Young and Hade, Journal \nof the American Medical Association, Vol. 292, No. 24.) Construct a 95% confidence interval \nestimate of the proportion of number of deaths in the week before Thanksgiving to the total \ndeaths in the week before and the week after Thanksgiving. Based on the result, does there \nappear to be any indication that people can temporarily postpone their death to survive the \nThanksgiving holiday? Why or why not?\n26. Cloning Survey A Gallup poll included 1012 randomly selected adults who were asked \nwhether “cloning of humans should or should not be allowed.” Results showed that 901 of \nthose surveyed indicated that cloning should not be allowed. A news reporter wants to deter-\nmine whether these survey results constitute strong evidence that the majority (more than 50%) \nof people are opposed to such cloning. Construct a 99% confidence interval estimate of the \nproportion of adults believing that cloning of humans should not be allowed. Is there strong \nevidence supporting the claim that the majority is opposed to such cloning?\n27. Smoking Cessation In a program designed to help patients stop smoking, 198 patients \nwere given sustained care, and 82.8% of them were no longer smoking after one month. Among \n199 patients given standard care, 62.8% were no longer smoking after one month (based on \ndata from “Sustained Care Intervention and Postdischarge Smoking Cessation Among Hospi-\ntalized Adults,” by Rigotti et al., Journal of the American Medical Association, Vol. 312, No. \n7). Construct the two 95% confidence interval estimates of the percentages of success. Com-\npare the results. What do you conclude?\n28. Measured Results vs. Reported Results The same study cited in the preceding exer-\ncise produced these results after six months for the 198 patients given sustained care: 25.8% \nwere no longer smoking, and these results were biochemically confirmed, but 40.9% of these \npatients reported that they were no longer smoking. Construct the two 95% confidence inter-\nvals. Compare the results. What do you conclude?\nDetermining Sample Size. In Exercises 29–36, use the given data to find the minimum \nsample size required to estimate a population proportion or percentage.\n29. Lefties Find the sample size needed to estimate the percentage of California residents who \nare left-handed. Use a margin of error of three percentage points, and use a confidence level of \n99%.\na. Assume that pn and qn are unknown.\nb. Assume that based on prior studies, about 10% of Californians are left-handed.\nc. How do the results from parts (a) and (b) change if the entire United States is used instead \nof California?\n30. Chickenpox You plan to conduct a survey to estimate the percentage of adults who have \nhad chickenpox. Find the number of people who must be surveyed if you want to be 90% con-\nfident that the sample percentage is within two percentage points of the true percentage for the \npopulation of all adults.\na. Assume that nothing is known about the prevalence of chickenpox.\nb. Assume that about 95% of adults have had chickenpox.\nc. Does the added knowledge in part (b) have much of an effect on the sample size?\n",
    "298 \nCHAPTER 7 Estimating Parameters and Determining Sample Sizes\n 31. Bachelor’s Degree in Four Years In a study of government financial aid for college stu-\ndents, it becomes necessary to estimate the percentage of full-time college students who earn a \nbachelor’s degree in four years or less. Find the sample size needed to estimate that percentage. \nUse a 0.05 margin of error, and use a confidence level of 95%.\na. Assume that nothing is known about the percentage to be estimated.\nb. Assume that prior studies have shown that about 40% of full-time students earn bachelor’s \ndegrees in four years or less.\nc. Does the added knowledge in part (b) have much of an effect on the sample size?\n32. Astrology A sociologist plans to conduct a survey to estimate the percentage of health \ncare professionals who believe in astrology. How many health care professionals must be sur-\nveyed if we want a confidence level of 99% and a margin of error of four percentage points?\na. Assume that nothing is known about the percentage to be estimated.\nb. Use the information from a previous Harris survey in which 26% of respondents said that \nthey believed in astrology.\n33. Biometric Security In considering the use of biometric security (such as fingerprints) to \nreplace passwords, you want to estimate the percentage of adults who believe that passwords \nshould be replaced with biometric security. How many randomly selected adults must you sur-\nvey? Assume that you want to be 95% confident that the sample percentage is within 2.5 per-\ncentage points of the true population percentage.\na. Assume that nothing is known about the percentage of adults who believe that passwords \nshould be replaced with biometric security.\nb. Assume that a prior survey suggests that about 53% of adults believe that biometric security \nshould replace passwords (based on a USA Today report).\nc. Does the additional survey information from part (b) have much of an effect on the sample \nsize that is required?\n 34. Nicotine Patches You plan to conduct a clinical trial to test the effectiveness of nicotine \npatch therapy in helping smokers to stop smoking. How many smokers must be included in \norder to be 99% confident that the estimate is in error by no more than two percentage points?\na. Assume that nothing is known about the effectiveness of nicotine patch therapy.\nb. Assume that a prior clinical trial suggests that nicotine patch therapy has a success rate of \nabout 45% (based on data from “High-Dose Nicotine Patch Therapy,” by Dale et al., Journal of \nthe American Medical Association, Vol. 274, No. 17).\nc. Does the additional survey information from part (b) have much of an effect on the sample \nsize that is required?\n 35. Vision Correction A manufacturing company is considering entering the new market of \neyeglasses. How many people must be surveyed in order to be 90% confident that the estimated \npercentage of adults who wear eyeglasses is within three percentage points of the true popula-\ntion percentage?\na. Assume that nothing is known about the percentage of adults who wear eyeglasses.\nb. Assume that about 53% of adults wear eyeglasses (based on a Vision Council prior survey).\nc. Given that the required sample size is relatively small, could you simply survey the adults \nthat you know?\n36. Women Who Give Birth An epidemiologist plans to conduct a survey to estimate the \npercentage of women who give birth. How many women must be surveyed in order to be 99% \nconfident that the estimated percentage is in error by no more than two percentage points?\na. Assume that nothing is known about the percentage to be estimated.\ncontinued\n",
    "7-2 Estimating a Population Mean \n299\nb. Assume that a prior study conducted by the U.S. Census Bureau showed that 82% of women \ngive birth.\nc. What is wrong with surveying randomly selected adult women?\n37. Finite Population Correction Factor For Formulas 7-2 and 7-3 we assume that the pop-\nulation is infinite or very large and that we are sampling with replacement. When we sample \nwithout replacement from a relatively small population with size N, we modify E to include \nthe finite population correction factor shown here, and we can solve for n to obtain the result \nshown below. Use this result to repeat part (b) of Exercise 36, assuming that we limit our popu-\nlation to a county with 2500 women who have completed the time during which they can give \nbirth.\nE = za>2 B\npnqn\nn\n B\nN - n\nN - 1   n =\nNpnqn3za>242\npnqn 3za>242 + 1N - 12E2\n38. One-Sided Confidence Interval A one-sided claim about a population proportion is a \nclaim that the proportion is less than (or greater than) some specific value. Such a claim can \nbe formally addressed using a one-sided confidence interval for p, which can be expressed as \np 6 pn + E or p 7 pn - E, where the margin of error E is modified by replacing za>2 with \nza. (Instead of dividing a between two tails of the standard normal distribution, put all of it in \none tail.) Use the data given in Exercise 13 “OxyContin” to construct a one-sided 95% confi-\ndence interval that would be suitable for addressing the claim that the rate of headaches among \n OxyContin users is less than 10%.\n39. Coping with No Success According to the Rule of Three, when we have a sample size \nn with x = 0 successes, we have 95% confidence that the true population proportion has an \nupper bound of 3>n. (See “A Look at the Rule of Three,” by Jovanovic and Levy, American \nStatistician, Vol. 51, No. 2.)\na. If n independent trials result in no successes, why can’t we find confidence interval limits by \nusing the methods described in this section?\nb. If 40 couples use a method of gender selection and each couple has a baby girl, what is the \n95% upper bound for p, the proportion of all babies who are boys?\n7-1 Beyond the Basics \nKey Concept The main goal of this section is to present methods for using a sample \nmean x to make an inference about the value of the corresponding population mean m.\nThere are three main concepts included in this section:\n \n■Point Estimate: The sample mean x is the best point estimate (or single value \nestimate) of the population mean m.\n \n■Confidence Interval: Use sample data to construct and interpret a confidence \ninterval estimate of the true value of a population mean m.\n \n■Sample Size: Find the sample size necessary to estimate a population mean.\nPart 1 of this section deals with the very realistic and commonly used case in which \nwe want to estimate m and the population standard deviation s is not known. Part 2 \nincludes a brief discussion of the procedure used when s is known, which is very rare.\n7-2 \nEstimating a Population Mean\n",
    "300 \nCHAPTER 7 Estimating Parameters and Determining Sample Sizes\nPART 1\nEstimating a Population Mean When S\nIs Not Known \nIt’s rare that we want to estimate the unknown value of a population mean m but we \nsomehow know the value of the population standard deviation s, so Part 1 focuses on \nthe realistic situation in which s is not known.\nPoint Estimate As discussed in Section 6-3, the sample mean x is an unbiased es-\ntimator of the population mean m. Also, for many populations, sample means tend to \nvary less than other measures of center. For these reasons, the sample mean x is usu-\nally the best point estimate of the population mean m.\nThe sample mean x is the best point estimate of the population mean M.\nBecause even the best point estimate gives us no indication of how accurate it is, we \nuse a confidence interval (or interval estimate), which consists of a range (or an inter-\nval) of values instead of just a single value.\nConfidence Interval The accompanying Key Elements box includes the key ele-\nments for constructing a confidence interval estimate of a population mean m in the \ncommon situation where s is not known.\nConfidence Interval for Estimating a Population Mean with s Not Known\nObjective\nConstruct a confidence interval used to estimate a population mean.\nNotation\nm = population mean \nn = number of sample values\nx = sample mean \nE = margin of error\ns = sample standard deviation\nRequirements\nKEY ELEMENTS\n1. The sample is a simple random sample.\n2. Either or both of these conditions are satisfied: The \npopulation is normally distributed or n 7 30.\nConfidence Interval\nFormats: x - E 6 m 6 x + E  or  x { E  or  \n1x - E, x + E2\n • Margin of Error: E = ta>2 #\ns\n1n (Use df = n - 1.)\n • Confidence Level: The confidence interval is associ-\nated with a confidence level, such as 0.95 (or 95%), \nand a is the complement of the confidence level. For \na 0.95 (or 95%) confidence level, a = 0.05.\n • Critical Value: ta>2 is the critical t value separating an \narea of a>2 in the right tail of the Student t distribution.\n • Degrees of Freedom: df = n - 1 is the number of \ndegrees of freedom. Used when finding the critical \nvalue.\nRound-Off Rule\n1. Original Data: When using an original set of data val-\nues, round the confidence interval limits to one more \ndecimal place than is used for the original set of data.\n2. Summary Statistics: When using the summary statistics \nof n, x, and s, round the confidence interval limits to the \nsame number of decimal places used for the sample mean.\n",
    "7-2 Estimating a Population Mean \n301\nRequirement of “Normality or n + 30”\nNormality The method for finding a confidence interval estimate of m is robust \nagainst a departure from normality, which means that the normality requirement is \nloose. The distribution need not be perfectly bell-shaped, but it should appear to be \nsomewhat symmetric with one mode and no outliers.\nSample Size n + 30 This is a common guideline, but sample sizes of 15 to 30 are \nadequate if the population appears to have a distribution that is not far from being \nnormal and there are no outliers. For some population distributions that are extremely \nfar from normal, the sample size might need to be larger than 30. This text uses the \nsimplified criterion of n 7 30 as justification for treating the distribution of sample \nmeans as a normal distribution.\nStudent t Distribution\nIn this section we use a Student t distribution, which is commonly referred to as a t distri-\nbution. It was developed by William Gosset (1876–1937), who was a Guinness Brewery \nemployee who needed a distribution that could be used with small samples. The brewery \nprohibited publication of research results, but Gosset got around this by publishing under \nthe pseudonym “Student.” Here are some key points about the Student t distribution:\n \n■Student t Distribution If a population has a normal distribution, then the distri-\nbution of\nt = x - m\ns\n1n\nis a Student t distribution for all samples of size n. A Student t distribution is \ncommonly referred to as a t distribution.\n \n■Degrees of Freedom Finding a critical value ta>2 requires a value for the degrees \nof freedom (or df). In general, the number of degrees of freedom for a collection \nof sample data is the number of sample values that can vary after certain restric-\ntions have been imposed on all data values. (Example: If 10 test scores have the \nrestriction that their mean is 80, then their sum must be 800, and we can freely \nassign values to the first 9 scores, but the 10th score would then be determined, \nso in this case there are 9 degrees of freedom.) For the methods of this section, \nthe number of degrees of freedom is the sample size minus 1.\nDegrees of freedom = n −1\n \n■Finding Critical Value tA,2 A critical value ta>2 can be found using technology \nor Table A-3. Technology can be used with any number of degrees of freedom, \nbut Table A-3 can be used for select numbers of degrees of freedom only. If using \nTable A-3 to find a critical value of ta>2, but the table does not include the exact \nnumber of degrees of freedom, you could use the closest value, or you could be \nconservative by using the next lower number of degrees of freedom found in the \ntable, or you could interpolate.\n \n■The Student t distribution is different for different sample sizes. (See Figure 7-4 \non the next page for the cases n = 3 and n = 12.)\n \n■The Student t distribution has the same general symmetric bell shape as the stan-\ndard normal distribution, but has more variability (with wider distributions), as \nwe expect with small samples.\n \n■The Student t distribution has a mean of t = 0 (just as the standard normal distri-\nbution has a mean of z = 0).\nst\nis\nbe \nre\nEstimating Wildlife \nPopulation Sizes\nThe National \nForest Man-\nagement \nAct protects \nendangered \nspecies, includ-\ning the northern \nspotted owl, \nwith the result that the for-\nestry industry was not allowed \nto cut vast regions of trees in \nthe Pacific Northwest. Biologists \nand statisticians were asked to \nanalyze the problem, and they \nconcluded that survival rates and \npopulation sizes were decreas-\ning for the female owls, known to \nplay an important role in species \nsurvival. Biologists and statisti-\ncians also studied salmon in the \nSnake and Columbia rivers in \nWashington State, and penguins \nin New Zealand. In the article \n“Sampling Wildlife Popula-\ntions” (Chance, Vol. 9, No. 2), \nauthors Bryan Manly and Lyman \nMcDonald comment that in such \nstudies, “biologists gain through \nthe use of modeling skills that are \nthe hallmark of good statistics. \nStatisticians gain by being intro-\nduced to the reality of problems \nby biologists who know what the \ncrucial issues are.”\n",
    "302 \nCHAPTER 7 Estimating Parameters and Determining Sample Sizes\n \n■The standard deviation of the Student t distribution varies with the sample size, \nbut it is greater than 1 (unlike the standard normal distribution, which has s = 1).\n \n■As the sample size n gets larger, the Student t distribution gets closer to the stan-\ndard normal distribution.\n0\nStandard\nnormal\ndistribution\nStudent t\ndistribution\nwith n 5 12\nStudent t\ndistribution\nwith n 5 3\nFIGURE 7-4 Student t Distributions for n = 3 and n = 12\nThe Student t distribution has the same general shape and \nsymmetry as the standard normal distribution, but it has the \ngreater variability that is expected with small samples.\nProcedure for Constructing a Confidence Interval for M\nConfidence intervals can be easily constructed with technology or they can be manu-\nally constructed by using the following procedure.\n1. Verify that the two requirements are satisfied: The sample is a simple random \nsample and the population is normally distributed or n 7 30.\n2. With s unknown (as is usually the case), use n - 1 degrees of freedom and use \ntechnology or a t distribution table (such as Table A-3) to find the critical value \nta>2 that corresponds to the desired confidence level.\n3. Evaluate the margin of error using E = ta>2 # s> 1n.\n4. Using the value of the calculated margin of error E and the value of the sample \nmean x, substitute those values in one of the formats for the confidence inter-\nval: x - E 6 m 6 x + E or x { E or \n1x - E, x + E2.\n5. Round the resulting confidence interval limits as follows: With an original \nset of data values, round the confidence interval limits to one more decimal \nplace than is used for the original set of data, but when using the summary \nstatistics of n, x, and s, round the confidence interval limits to the same \nnumber of decimal places used for the sample mean.\nEXAMPLE 1  Finding a Critical Value tA,2\nFind the critical value ta>2 corresponding to a 95% confidence level given that the \nsample has size n = 15.\nSOLUTION\nBecause n = 15, the number of degrees of freedom is n - 1 = 14. The 95% confi-\ndence level corresponds to a = 0.05, so there is an area of 0.025 in each of the two \ntails of the t distribution, as shown in Figure 7-5.\ncontinued\n",
    "7-2 Estimating a Population Mean \n303\nUsing Technology Technology can be used to find that for 14 degrees of freedom \nand an area of 0.025 in each tail, the critical value is ta>2 = t0.025 = 2.145.\nUsing Table A-3 To find the critical value using Table A-3, use the column with \n0.05 for the “Area in Two Tails” (or use the same column with 0.025 for the “Area \nin One Tail”). The number of degrees of freedom is df = n - 1 = 14. We get \nta>2 = t0.025 = 2.145.\nt 5 0\nta/2 5 2.145\n 0.025\n 0.025\nFIGURE 7-5 Critical Value tA,2\nEXAMPLE 2  Confidence Interval Using Birth Weights\nListed below are weights (hectograms, or hg) of randomly selected girls at birth, \nbased on data from the National Center for Health Statistics. Here are the summary \nstatistics: n = 15, x = 30.9 hg, s = 2.9 hg. Use the sample data to construct a \n95% confidence interval for the mean birth weight of girls.\n33 28 33 37 31 32 31 28 34 28 33 26 30 31 28\nSOLUTION\nREQUIREMENT CHECK We must first verify that the requirements are satisfied.  \n(1) The sample is a simple random sample. (2) Because the sample size is n = 15, \nthe requirement that “the population is normally distributed or the sample size is \ngreater than 30” can be satisfied only if the sample data appear to be from a  \nnormally distributed population, so we need to investigate normality. The accompa-\nnying normal quantile plot shows that the sample data appear to be from a normally \ndistributed population, so this second requirement is satisfied. \ncontinued\n",
    "304 \nCHAPTER 7 Estimating Parameters and Determining Sample Sizes\nInterpreting the Confidence Interval The confidence interval is associated with \na confidence level, such as 0.95 (or 95%). When interpreting a confidence interval \nestimate of μ, know that the confidence level gives us the success rate of the procedure \nused to construct the confidence interval. For example, the 95% confidence interval \nestimate of 29.2 hg 6 m 6 32.5 hg can be interpreted as follows:\n“We are 95% conﬁdent that the interval from 29.2 hg to 32.5 hg actually \ndoes contain the true value of M.”\nBy “95% confident” we mean that if we were to select many different samples of the \nsame size and construct the corresponding confidence intervals, in the long run, 95% \nof the confidence intervals should actually contain the value of m.\nFinding a Point Estimate and Margin of Error E from a Confidence Interval\nTechnology and journal articles often express a confidence interval in a format such \nas (10.0, 30.0). The sample mean x is the value midway between those limits, and the \nUsing Technology Technology can be used to automatically construct the confi-\ndence interval. Shown here is the StatCrunch display resulting from the 15 birth \nweights. The display shows the lower confidence interval limit (29.247163) and \nthe upper confidence interval limit (32.486171). After rounding to one decimal \nplace (as in the sample mean), we can express the 95% confidence interval as \n29.2 hg 6 m 6 32.5 hg.\n StatCrunch\nUsing t Distribution Table Using Table A-3, the critical value is t0.025 = 2.145 as \nshown in Example 1. We now find the margin of error E as shown here:\nE = ta>2\n s\n1n = 2.145 # 2.9\n115 = 1.606126\nWith x = 30.9 hg and E = 1.606126 hg, we construct the confidence interval as \nfollows:\n x - E 6 m 6 x + E\n 30.9 - 1.606126 6 m 6 30.9 + 1.606126\n 29.3 hg 6 m 6 32.5 hg     1rounded to one decimal place2\nThe lower confidence interval limit of 29.3 hg is actually 29.2 hg if we use technol-\nogy or if we use summary statistics with more decimal places than the one decimal \nplace used in the preceding calculation.\nINTERPRETATION\nWe are 95% confident that the limits of 29.2 hg and 32.5 hg actually do contain \nthe value of the population mean m. If we were to collect many different random \nsamples of 15 newborn girls and find the mean weight in each sample, about 95% \nof the resulting confidence intervals should contain the value of the mean weight of \nall newborn girls.\nEstimating Sugar in \nOranges\nIn Florida, \nmembers \nof the citrus \nindustry make \nextensive use \nof statistical \nmethods. One \nparticular application involves the \nway in which growers are paid \nfor oranges used to make orange \njuice. An arriving truckload of \noranges is first weighed at the re-\nceiving plant, and then a sample \nof about a dozen oranges is \nrandomly selected. The sample is \nweighed and then squeezed, and \nthe amount of sugar in the juice \nis measured. Based on the sam-\nple results, an estimate is made \nof the total amount of sugar in \nthe entire truckload. Payment \nfor the load of oranges is based \non the estimate of the amount of \nsugar because sweeter oranges \nare more valuable than those less \nsweet, even though the amounts \nof juice may be the same.\ni\nl\nli\ni\n",
    "7-2 Estimating a Population Mean \n305\nmargin of error E is one-half the difference between those limits (because the upper \nlimit is x + E and the lower limit is x - E, the distance separating them is 2E).\nPoint estimate of m:   x = 1upper confidence limit2 + 1lower confidence limit2\n2\nMargin of error:     E = 1upper confidence limit2 - 1lower confidence limit2\n2\nFor example, the confidence interval (10.0, 30.0) yields x = 20.0 and E = 10.0.\nUsing Confidence Intervals to Describe, Explore, or Compare Data\nIn some cases, confidence intervals might be among the different tools used to \ndescribe, explore, or compare data sets, as in the following example.\nEXAMPLE 3  Second-Hand Smoke\nFigure 7-6 shows graphs of confidence interval estimates of the mean cotinine level \nin each of three samples: (1) people who smoke; (2) people who don’t smoke but \nare exposed to tobacco smoke at home or work; (3) people who don’t smoke and \nare not exposed to smoke. (The sample data are listed in Data Set 14 “Passive and \nActive Smoke” in Appendix B.) Because cotinine is produced by the body when \nnicotine is absorbed, cotinine is a good indication of nicotine intake. Figure 7-6 \nhelps us see the effects of second-hand smoke. In Figure 7-6, we see that the con-\nfidence interval for smokers does not overlap the other confidence intervals, so it \nappears that the mean cotinine level of smokers is different from that of the other \ntwo groups. The two nonsmoking groups have confidence intervals that do overlap, \nso it is possible that they have the same mean cotinine level. It is helpful to compare \nconfidence intervals or their graphs, but such comparisons should not be used for \nmaking formal and final conclusions about equality of means. Chapters 9 and 12 \nintroduce better methods for formal comparisons of means.\n225\n0\n25\n50\n75\n100\n125\n150\n175\n200\n225\nCotinine (ng/mL)\nPeople not exposed to smoke\nSmokers\nPeople  exposed to smoke\nFIGURE 7-6 Comparing Confidence Intervals\nCAUTION Confidence intervals can be used informally to compare different data \nsets, but the overlapping of  confidence intervals should not be used for making \nformal and final conclusions about equality of  means.\nDetermining Sample Size\nIf we want to collect a sample to be used for estimating a population mean m, how \nmany sample values do we need? When determining the sample size needed to esti-\nmate a population mean, we must have an estimated or known value of the population \nstandard deviation s, so that we can use Formula 7-4 shown in the accompanying Key \nElements box.\n",
    "306 \nCHAPTER 7 Estimating Parameters and Determining Sample Sizes\nPopulation Size Formula 7-4 does not depend on the size (N) of the population (ex-\ncept for cases in which a relatively large sample is selected without replacement from \na finite population).\nRounding The sample size must be a whole number because it is the number of sam-\nple values that must be found, but Formula 7-4 usually gives a result that is not a \nwhole number. The round-off rule is based on the principle that when rounding is \nnecessary, the required sample size should be rounded upward so that it is at least ad-\nequately large instead of being slightly too small.\nDealing with Unknown S When Finding Sample Size Formula 7-4 requires that \nwe substitute a known value for the population standard deviation s, but in reality, \nit is usually unknown. When determining a required sample size (not constructing a \nconfidence interval), here are some ways that we can work around the problem of not \nknowing the value of s:\n1. Use the range rule of thumb (see Section 3-2) to estimate the standard deviation \nas follows: s ≈range>4, where the range is determined from sample data. \n(With a sample of 87 or more values randomly selected from a normally distrib-\nuted population, range>4 will yield a value that is greater than or equal to s at \nleast 95% of the time.)\n2. Start the sample collection process without knowing s and, using the first \nseveral values, calculate the sample standard deviation s and use it in place of \ns. The estimated value of s can then be improved as more sample data are \nKEY ELEMENTS\nFinding the Sample Size Required to Estimate a Population Mean\nObjective\nDetermine the sample size n required to estimate the value of a population mean m.\nNotation\nm = population mean\ns = population standard deviation\nx = sample mean\nE = desired margin of error\nza>2 = z score separating an area of a>2 in the right \n   tail of the standard normal distribution\nRequirement\nThe sample must be a simple random sample.\nSample Size\nThe required sample size is found by using Formula 7-4.\nFORMULA 7-4    n = c\nza>2s\nE\nd\n2\nRound-Off Rule\nIf the computed sample size n is not a whole number, round the value of n up to the next larger whole number.\n",
    "7-2 Estimating a Population Mean \n307\nobtained, and the required sample size can be adjusted as you collect more \nsample data.\n3. Estimate the value of s by using the results of some other earlier study. In \naddition, we can sometimes be creative in our use of other known results. \nFor example, Wechsler IQ tests are designed so that the standard deviation \nis 15. Biostatistics students have IQ scores with a standard deviation less \nthan 15, because they are a more homogeneous group than people randomly \nselected from the general population. We do not know the specific value \nof s for Biostatistics students, but we can be safe by using s = 15. Using \na value for s that is larger than the true value will make the sample size \nlarger than necessary, but using a value for s that is too small would result \nin a sample size that is inadequate. When determining the sample size n, \nany errors should always be conservative in the sense that they make the \nsample size too large instead of too small.\nEXAMPLE 4  IQ Scores of Smokers\nAssume that we want to estimate the mean IQ score for the population of adults \nwho smoke. How many smokers must be randomly selected for IQ tests if we want \n95% confidence that the sample mean is within 3 IQ points of the population mean?\nSOLUTION\nFor a 95% confidence interval, we have a = 0.05, so za>2 = 1.96. Because we \nwant the sample mean to be within 3 IQ points of m, the margin of error is E = 3. \nAlso, we can assume that s = 15 (see the discussion that immediately precedes \nthis example). Using Formula 7-4, we get\nn = c\nza>2s\nE\nd\n2\n= c 1.96 # 15\n3\nd\n2\n= 96.04 = 97 1rounded up2\nINTERPRETATION\nAmong the thousands of adults who smoke, we need to obtain a simple random \nsample of at least 97 of their IQ scores. With a simple random sample of only 97 \nadult smokers, we will be 95% confident that the sample mean x is within 3 IQ \npoints of the true population mean m.\nPART 2\nEstimating a Population Mean  \nWhen S Is Known \nIn the real world of professional statisticians and professional journals and reports, it \nis extremely rare that we want to estimate an unknown value of a population mean m \nbut we somehow know the value of the population standard deviation s. If we some-\nhow do know the value of s, the confidence interval is constructed using the standard \nnormal distribution instead of the Student t distribution, so the same procedure from \nPart 1 can be used with this margin of error:\nMargin of error: E = za>2 # s\n1n 1used with known s2\n",
    "308\t\nChapter 7  Estimating Parameters and Determining Sample Sizes\nChoosing the Appropriate Distribution\nWhen constructing a confidence interval estimate of the population mean m, it is \nimportant to use the correct distribution. Table 7-1 summarizes the key points to \nconsider.\nExample 5   Confidence Interval Estimate of M with Known S\nUse the same 15 birth weights of girls given in Example 2, for which n = 15 \nand x = 30.9 hg. Construct a 95% confidence interval estimate of the mean birth \nweight of all girls by assuming that s is known to be 2.9 hg.\nsolution\nRequirement check  The requirements were checked in Example 2. The require-\nments are satisfied. \nWith a 95% confidence level, we have a = 0.05, and we get za>2 = 1.96 (as in \nExample 2 from Section 7-1). Using za>2 = 1.96, s = 2.9 hg, and n = 15, we find \nthe value of the margin of error E:\n E = za>2 # s\n1n\n = 1.96 # 2.9\n115 = 1.46760\nWith x = 30.9 and E = 1.46760, we find the 95% confidence interval as follows:\n x - E 6 m 6 x + E\n 30.9 - 1.46760 6 m 6 30.9 + 1.46760\n 29.4 hg 6 m 6 32.4 hg 1rounded to one decimal place2\nThe confidence interval found here using the normal distribution is slightly nar-\nrower than the confidence interval found using the t distribution in Example 2. \nBecause za>2 = 1.96 is smaller than ta>2 = 2.145, the margin of error E is smaller \nand the confidence interval is narrower. The critical value ta>2 is larger because the \nt distribution incorporates the greater amount of variation that we get with smaller \nsamples.\nRemember, this example illustrates the situation in which the population \nstandard deviation s is known, which is rare. The more realistic situation with s \nunknown is considered in Part 1 of this section.\nTable 7-1  Choosing Between Student t and z (Normal) Distributions\nConditions\nMethod\ns not known and normally distributed population\nor\ns not known and n 7 30\nUse Student t distribution.\ns known and normally distributed population\nor\ns known and n 7 30 (In reality, s is rarely \nknown.)\nUse normal (z) distribution.\nPopulation is not normally distributed and \nn … 30.\nUse the bootstrapping method (Section 7-4) \nor a nonparametric method.\n",
    "7-2 Estimating a Population Mean \n309\nMeans: Confidence Intervals & Sample Size Determination\nAccess tech instructions, videos, and data sets at www.TriolaStats.com\nTECH CENTER \nStatistical Literacy and Critical Thinking\nIn Exercises 1–3, refer to the accompanying screen display that results from measured \nhemoglobin levels (g , dL) in 100 randomly selected adult females. The confidence level of \n95% was used.\n7-2 Basic Skills and Concepts\nTI-83, 84 Plus\n1. Hemoglobin Refer to the accompanying screen display.\na. Express the confidence interval in the format that uses the “less than” symbol. If the original \nlisted data use two decimal places, round the confidence interval limits accordingly.\nb. Identify the best point estimate of m and the margin of error.\nc. In constructing the confidence interval estimate of m, why is it not necessary to confirm that \nthe sample data appear to be from a population with a normal distribution?\n2. Degrees of Freedom\na. What is the number of degrees of freedom that should be used for finding the critical \nvalue ta>2?\nb. Find the critical value ta>2 corresponding to a 95% confidence level.\nc. Give a brief general description of the number of degrees of freedom.\n3. Interpreting a Confidence Interval The results in the screen display are based on a 95% \nconfidence level. Write a statement that correctly interprets the confidence interval.\n4. Normality Requirement What does it mean when we say that the confidence interval \nmethods of this section are robust against departures from normality?\nUsing Correct Distribution. In Exercises 5–8, assume that we want to construct a confi-\ndence interval. Do one of the following, as appropriate: (a) Find the critical value tA,2,  \n(b) find the critical value zA,2, (c) state that neither the normal distribution nor the t distri-\nbution applies.\n5. Audiometry Confidence level is 95%, s is not known, and the normal quantile plot of \nmeasured right-ear hearing thresholds from 10 randomly selected adult females is shown on \nthe top of the next page.\ncontinued\n",
    "310 \nCHAPTER 7 Estimating Parameters and Determining Sample Sizes\n6. Vision Confidence level is 90%, s is not known, and the histogram of right-eye vision mea-\nsurements is obtained from a random sample of 61 adult males.\n7. Vision Confidence level is 99%, s = 24.8, and the histogram of 61 right-eye vision mea-\nsurements from a random sample of 61 adult males is shown in Exercise 6.\n8. Birth Weights Here are summary statistics for randomly selected weights of newborn girls: \nn = 205, x = 30.4 hg, s = 7.1 hg (based on Data Set 3 “Births” in Appendix B). The confi-\ndence level is 95%.\nConfidence Intervals. In Exercises 9–24, construct the confidence interval estimate of \nthe mean.\n9. Birth Weights of Girls Use these summary statistics given in Exercise 8: n = 205,\nx = 30.4 hg, s = 7.1 hg. Use a 95% confidence level. Are the results very different from those \nfound in Example 2 with only 15 sample values?\n10. Birth Weights of Boys Use these summary statistics for birth weights of 195 boys: \nx = 32.7 hg, s = 6.6 hg (based on Data Set 3 “Births” in Appendix B). Use a 95% confidence \nlevel. Are the results very different from those found in Exercise 9? Does it appear that boys \nand girls have very different birth weights?\n11. Mean Body Temperature Data Set 2 “Body Temperatures” in Appendix B includes a \nsample of 106 body temperatures having a mean of 98.20°F and a standard deviation of 0.62°F. \nConstruct a 95% confidence interval estimate of the mean body temperature for the entire pop-\nulation. What does the result suggest about the common belief that 98.6°F is the mean body \ntemperature?\n12. Atkins Weight Loss Program In a test of weight loss programs, 40 adults used the \n Atkins weight loss program. After 12 months, their mean weight loss was found to be 2.1 lb, \nwith a standard deviation of 4.8 lb. Construct a 90% confidence interval estimate of the mean \nweight loss for all such subjects. Does the Atkins program appear to be effective? Does it ap-\npear to be practical?\n",
    "7-2 Estimating a Population Mean \n311\n 13. Insomnia Treatment A clinical trial was conducted to test the effectiveness of the drug \nzopiclone for treating insomnia in older subjects. Before treatment with zopiclone, 16 subjects \nhad a mean wake time of 102.8 min. After treatment with zopiclone, the 16 subjects had a mean \nwake time of 98.9 min and a standard deviation of 42.3 min (based on data from “Cognitive \nBehavioral Therapy vs Zopiclone for Treatment of Chronic Primary Insomnia in Older Adults,” \nby Sivertsen et al., Journal of the American Medical Association, Vol. 295, No. 24). Assume \nthat the 16 sample values appear to be from a normally distributed population and construct a \n98% confidence interval estimate of the mean wake time for a population with zopiclone treat-\nments. What does the result suggest about the mean wake time of 102.8 min before the treat-\nment? Does zopiclone appear to be effective?\n14. Garlic for Reducing Cholesterol In a test of the effectiveness of garlic for lowering cho-\nlesterol, 49 subjects were treated with raw garlic. Cholesterol levels were measured before and \nafter the treatment. The changes (before minus after) in their levels of low-density lipoprotein \n(LDL) cholesterol (in mg>dL) had a mean of 0.4 and a standard deviation of 21.0 (based on \ndata from “Effect of Raw Garlic vs Commercial Garlic Supplements on Plasma Lipid Concen-\ntrations in Adults with Moderate Hypercholesterolemia,” by Gardner et al., Archives of Internal \nMedicine, Vol. 167). Construct a 98% confidence interval estimate of the mean net change in \nLDL cholesterol after the garlic treatment. What does the confidence interval suggest about the \neffectiveness of garlic in reducing LDL cholesterol?\n15. Genes Samples of DNA are collected, and the four DNA bases of A, G, C, and T are \ncoded as 1, 2, 3, and 4, respectively. The results are listed below. Construct a 95% confidence \ninterval estimate of the mean. What is the practical use of the confidence interval?\n2 2 1 4 3 3 3 3 4 1\n16. Arsenic in Rice Listed below are amounts of arsenic (mg, or micrograms, per serving) in \nsamples of brown rice from California (based on data from the Food and Drug Administration). \nUse a 90% confidence level. The Food and Drug Administration also measured amounts of ar-\nsenic in samples of brown rice from Arkansas. Can the confidence interval be used to describe \narsenic levels in Arkansas?\n5.4 5.6 8.4 7.3 4.5 7.5 1.5 5.5 9.1 8.7\n17. Cell Phone Radiation Listed below are the measured radiation emissions (in W>kg) \ncorresponding to these cell phones: Samsung SGH-tss9, Blackberry Storm, Blackberry Curve, \nMotorola Moto, T-Mobile Sidekick, Sanyo Katana Eclipse, Palm Pre, Sony Ericsson, Nokia \n6085, Apple iPhone 3GS, Kyocera Neo E1100. The data are from the Environmental Working \nGroup. The media often present reports about the dangers of cell phone radiation as a cause of \ncancer. Construct a 90% confidence interval estimate of the population mean. What does the \nresult suggest about the Federal Communications Commission (FCC) standard that cell phone \nradiation must be 1.6 W>kg or less?\n0.38 0.55 1.54 1.55 0.50 0.60 0.92 0.96 1.00 0.86 1.46\n18. Lead in Medicine Listed below are the lead concentrations (in mg>g) measured in dif-\nferent Ayurveda medicines. Ayurveda is a traditional medical system commonly used in India. \nThe lead concentrations listed here are from medicines manufactured in the United States. The \ndata are based on the article “Lead, Mercury, and Arsenic in US and Indian Manufactured \nAyurvedic Medicines Sold via the Internet,” by Saper et al., Journal of the American Medical \nAssociation, Vol. 300, No. 8. Use the sample data to construct a 95% confidence interval esti-\nmate of the mean of the lead concentrations for the population of all such medicines. If a safety \nstandard requires lead concentrations less than 7 mg>g, does it appear that the population mean \nis less than that level?\n3.0 6.5 6.0 5.5 20.5 7.5 12.0 20.5 11.5 17.5\n19. Mercury in Sushi A Food and Drug Administration (FDA) guideline is that the mer-\ncury in fish should be below 1 part per million (ppm). Listed below are the amounts of mer-\ncury (ppm) found in tuna sushi sampled at different stores in New York City. The study was \ncontinued\n",
    "312 \nCHAPTER 7 Estimating Parameters and Determining Sample Sizes\nsponsored by the New York Times, and the stores (in order) are D’Agostino, Eli’s Manhattan, \nFairway, Food Emporium, Gourmet Garage, Grace’s Marketplace, and Whole Foods. Construct \na 98% confidence interval estimate of the mean amount of mercury in the population. Given \nthat the FDA guideline is that fish should have a maximum of 1 ppm of mercury, what does the \nconfidence interval suggest?\n0.56 0.75 0.10 0.95 1.25 0.54 0.88\n20. Years in College Listed below are the numbers of years it took for a random sample of \ncollege students to earn bachelor’s degrees (based on data from the National Center for Educa-\ntion Statistics). Construct a 95% confidence interval estimate of the mean time required for all \ncollege students to earn bachelor’s degrees. Does it appear that college students typically earn \nbachelor’s degrees in four years? Is there anything about the data that would suggest that the \nconfidence interval might not be a good result?\n4 4 4 4 4 4 4.5 4.5 4.5 4.5 4.5 4.5 6 6 8 9 9 13 13 15\n21. Caffeine in Soft Drinks Listed below are measured amounts of caffeine (mg per 12 oz of \ndrink) obtained in one can from each of 20 brands (7-UP, A&W Root Beer, Cherry Coke,…, \nTaB). Use a confidence level of 99%. Does the confidence interval give us good information \nabout the population of all cans of the same 20 brands that are consumed? Does the sample ap-\npear to be from a normally distributed population? If not, how are the results affected?\n0 0 34 34 34 45 41 51 55 36 47 41 0 0 53 54 38 0 41 47\n22. Shoveling Heart Rates Because cardiac deaths appear to increase after heavy snow-\nfalls, an experiment was designed to compare cardiac demands of snow shoveling to those \nof using an electric snow thrower. Ten subjects cleared tracts of snow using both meth-\nods, and their maximum heart rates (beats per minute, or BPM) were recorded during both \nactivities. The following results were obtained (based on data from “Cardiac Demands of \nHeavy Snow Shoveling,” by Franklin et al., Journal of the American Medical Association, \nVol. 273, No. 11):\nManual Snow Shoveling Maximum Heart Rates: n = 10, x = 175 BPM, s = 15 BPM\nElectric Snow Thrower Maximum Heart Rates: n = 10, x = 124 BPM, s = 18 BPM\na. Find the 95% confidence interval estimate of the population mean for those people who \nshovel snow manually.\nb. Find the 95% confidence interval estimate of the population mean for those people who use \nthe electric snow thrower.\nc. If you are a physician with concerns about cardiac deaths fostered by manual snow shovel-\ning, what single value in the confidence interval from part (a) would be of greatest concern?\nd. Compare the confidence intervals from parts (a) and (b) and interpret your findings.\n23. Echinacea Treatment In a study designed to test the effectiveness of echinacea for treat-\ning upper respiratory tract infections in children, 337 children were treated with echinacea and \n370 other children were given a placebo. The numbers of days of peak severity of symptoms \nfor the echinacea treatment group had a mean of 6.0 and a standard deviation of 2.3. The num-\nbers of days of peak severity of symptoms for the placebo group had a mean of 6.1 days and a \nstandard deviation of 2.4 days (based on data from “Efficacy and Safety of Echinacea in Treat-\ning Upper Respiratory Tract Infections in Children,” by Taylor et al., Journal of the American \nMedical Association, Vol. 290, No. 21).\na. Construct the 95% confidence interval for the mean number of days of peak severity of \nsymptoms for those who receive echinacea treatment.\nb. Construct the 95% confidence interval for the mean number of days of peak severity of \nsymptoms for those who are given a placebo.\nc. Compare the two confidence intervals. What do the results suggest about the effectiveness \nof echinacea?\n",
    "7-2 Estimating a Population Mean \n313\n24. Acupuncture for Migraines In a study designed to test the effectiveness of acupuncture \nfor treating migraine, 142 subjects were treated with acupuncture and 80 subjects were given \na sham treatment. The numbers of migraine attacks for the acupuncture treatment group had \na mean of 1.8 and a standard deviation of 1.4. The numbers of migraine attacks for the sham \ntreatment group had a mean of 1.6 and a standard deviation of 1.2.\na. Construct the 95% confidence interval estimate of the mean number of migraine attacks for \nthose treated with acupuncture.\nb. Construct the 95% confidence interval estimate of the mean number of migraine attacks for \nthose given a sham treatment.\nc. Compare the two confidence intervals. What do the results suggest about the effectiveness \nof acupuncture?\nAppendix B Data Sets. In Exercises 25 and 26, use the Appendix B data sets to construct \nthe confidence interval estimates of the mean.\n25. Pulse Rates Refer to Data Set 1 “Body Data” in Appendix B and construct a 95% con-\nfidence interval estimate of the mean pulse rate of adult females; then do the same for adult \nmales. Compare the results.\n26. Nicotine in Cigarettes Refer to Data Set 15 “Cigarette Contents” in Appendix B and as-\nsume that the samples are simple random samples obtained from normally distributed popula-\ntions.\na. Construct a 95% confidence interval estimate of the mean amount of nicotine in cigarettes \nthat are king size, non-filtered, non-menthol, and non-light.\nb. Construct a 95% confidence interval estimate of the mean amount of nicotine in cigarettes \nthat are 100 mm, filtered, non-menthol, and non-light.\nc. Compare the results. Do filters on cigarettes appear to be effective?\nSample Size. In Exercises 27–34, find the sample size required to estimate the population \nmean.\n27. Mean IQ of Nurses The Wechsler IQ test is designed so that the mean is 100 and the \nstandard deviation is 15 for the population of normal adults. Find the sample size necessary to \nestimate the mean IQ score of nurses. We want to be 99% confident that our sample mean is \nwithin 4 IQ points of the true mean. The mean for this population is clearly greater than 100. \nThe standard deviation for this population is less than 15 because it is a group with less varia-\ntion than a group randomly selected from the general population; therefore, if we use s = 15 \nwe are being conservative by using a value that will make the sample size at least as large as \nnecessary. Assume then that s = 15 and determine the required sample size. Does the sample \nsize appear to be practical?\n28. Mean IQ of Psychologists See the preceding exercise, in which we can assume that \ns = 15 for the IQ scores. Psychologists are a group with IQ scores that vary less than the IQ \nscores of the general population. Find the sample size needed to estimate the mean IQ of psy-\nchologists, given that we want 98% confidence that the sample mean is within 3 IQ points of \nthe population mean. Does the sample size appear to be practical?\n29. Mean Grade-Point Average Assume that all grade-point averages are to be standard-\nized on a scale between 0 and 4. How many grade-point averages must be obtained so that the \nsample mean is within 0.01 of the population mean? Assume that a 95% confidence level is de-\nsired. If we use the range rule of thumb, we can estimate s to be range>4 = 14 - 02>4 = 1.\nDoes the sample size seem practical?\n30. Mean Weight of Male Medical Students Data Set 1 “Body Data” in Appendix B in-\ncludes weights of 153 randomly selected adult males, and those weights have a standard de-\nviation of 17.65 kg. Because it is reasonable to assume that weights of male medical students \ncontinued\n",
    "314 \nCHAPTER 7 Estimating Parameters and Determining Sample Sizes\nhave less variation than weights of the population of adult males, we can be conservative by \nletting s = 17.65 kg. How many male medical students must be weighed in order to estimate \nthe mean weight of all male medical students? Assume that we want 90% confidence that the \nsample mean is within 1.5 kg of the population mean. Does it seem reasonable to assume that \nweights of male medical students have less variation than weights of the population of adult \nmales?\n31. Mean Age of Female Medical Students Data Set 1 “Body Data” in Appendix B in-\ncludes ages of 147 randomly selected adult females, and those ages have a standard deviation \nof 17.7 years. Assume that ages of female medical students have less variation than ages of \nfemales in the general population, so let s = 17.7 years for the sample size calculation. How \nmany female medical student ages must be obtained in order to estimate the mean age of all \nfemale medical students? Assume that we want 95% confidence that the sample mean is within \none-half year of the population mean. Does it seem reasonable to assume that ages of female \nmedical students have less variation than ages of females in the general population?\n32. Mean Pulse Rate of Females Data Set 1 “Body Data” in Appendix B includes pulse \nrates of 147 randomly selected adult females, and those pulse rates vary from a low of 36 bpm \nto a high of 104 bpm. Find the minimum sample size required to estimate the mean pulse rate \nof adult females. Assume that we want 99% confidence that the sample mean is within 2 bpm \nof the population mean.\na. Find the sample size using the range rule of thumb to estimate s.\nb. Assume that s = 12.5 bpm, based on the value of s = 12.5 bpm for the sample of 147 \nfemale pulse rates.\nc. Compare the results from parts (a) and (b). Which result is likely to be better?\n33. Mean Pulse Rate of Males Data Set 1 “Body Data” in Appendix B includes pulse rates \nof 153 randomly selected adult males, and those pulse rates vary from a low of 40 bpm to a \nhigh of 104 bpm. Find the minimum sample size required to estimate the mean pulse rate of \nadult males. Assume that we want 99% confidence that the sample mean is within 2 bpm of the \npopulation mean.\na. Use the range rule of thumb to estimate s.\nb. Assume that s = 11.3 bpm, based on the value of s = 11.3 bpm for the sample of 153 male \npulse rates.\nc. Compare the results from parts (a) and (b). Which result is likely to be better?\n34. Mean Body Temperature Data Set 2 “Body Temperatures” in Appendix B includes 106 \nbody temperatures of adults for day 2 at 12 AM, and they vary from a low of 96.5°F to a high \nof 99.6°F. Find the minimum sample size required to estimate the mean body temperature of \nall adults. Assume that we want 98% confidence that the sample mean is within 0.1°F of the \npopulation mean.\na. Find the sample size using the range rule of thumb to estimate s.\nb. Assume that s = 0.62°F, based on the value of s = 0.62°F for the sample of 106 body \ntemperatures.\nc. Compare the results from parts (a) and (b). Which result is likely to be better?\n35. Finite Population Correction Factor If a simple random sample of size n is selected \nwithout replacement from a finite population of size N, and the sample size is more than 5% of \nthe population size 1n 7 0.05N2, better results can be obtained by using the finite population \ncorrection factor, which involves multiplying the margin of error E by 11N - n2>1N - 12. \n7-2 Beyond the Basics\ncontinued\n",
    "7-3 Estimating a Population Standard Deviation or Variance \n315\nFor a sample of 40 platelet counts of females from Data Set 1 “Body Data” in Appendix B, we \nget x = 255.1 and s = 65.4. All platelet counts are in 1000 cells>mL.\na. Construct a 95% confidence interval estimate of m assuming that the population is large.\nb. Construct a 95% confidence interval estimate of m assuming that the sample is selected \nwithout replacement from a population of 500 females.\nc. Compare the results.\nKey Concept This section presents methods for using a sample standard deviation s \n(or a sample variance s2) to estimate the value of the corresponding population stan-\ndard deviation s (or population variance s2). Here are the main concepts included in \nthis section:\n \n■Point Estimate: The sample variance s2 is the best point estimate (or single \nvalue estimate) of the population variance s2. The sample standard deviation s is \ncommonly used as a point estimate of s, even though it is a biased estimator, as \ndescribed in Section 6-3.\n \n■Confidence Interval: When constructing a confidence interval estimate of a \npopulation standard deviation (or population variance), we construct the con-\nfidence interval using the x2 distribution. (The Greek letter x is pronounced \n“kigh.”)\nChi-Square Distribution\nHere are key points about the x2(chi-square or chi-squared) distribution:\n \n■In a normally distributed population with variance s2, if we randomly select in-\ndependent samples of size n and, for each sample, compute the sample variance \ns2, the sample statistic x2 = 1n - 12s2>s2 has a sampling distribution called \nthe chi-square distribution, as shown in Formula 7-5.\n7-3 \nEstimating a Population Standard Deviation or Variance\nFORMULA 7-5\nx2 = 1n - 12s2\ns2\n \n■Critical Values of X2 We denote a right-tailed critical value by x2\nR and we de-\nnote a left-tailed critical value by x2\nL. Those critical values can be found by using \ntechnology or Table A-4, and they require that we first determine a value for the \nnumber of degrees of freedom.\n \n■Degrees of Freedom For the methods of this section, the number of degrees of \nfreedom is the sample size minus 1.\nDegrees of freedom: df = n −1\ncontinued\n",
    "316 \nCHAPTER 7 Estimating Parameters and Determining Sample Sizes\n \n■The chi-square distribution is skewed to the right, unlike the normal and Student \nt distributions (see Figure 7-7).\n \n■The values of chi-square can be zero or positive, but they cannot be negative, as \nshown in Figure 7-7.\n \n■The chi-square distribution is different for each number of degrees of freedom, \nas illustrated in Figure 7-8. As the number of degrees of freedom increases, the \nchi-square distribution approaches a normal distribution.\nNot symmetric\nAll values are nonnegative\n0\nx2\nFIGURE 7-7 Chi-Square Distribution\n0\n5\n10\n15\n20\n25\n30\n35\n40\n45\nx2\ndf 5 10\ndf 5 20\nFIGURE 7-8  Chi-Square Distribution for \ndf = 10 and df = 20\nBecause the chi-square distribution is not symmetric, a confidence interval esti-\nmate of s2 does not fit a format of s2 - E 6 s2 6 s2 + E, so we must do separate \ncalculations for the upper and lower confidence interval limits. If using Table A-4 for \nfinding critical values, note the following design feature of that table:\nIn Table A-4, each critical value of X2 in the body of the table corresponds \nto an area given in the top row of the table, and each area in that top row \nis a cumulative area to the right of the critical value.\nCAUTION Table A-2 for the standard normal distribution provides cumulative areas \nfrom the left, but Table A-4  for the chi-square distribution uses cumulative areas \nfrom the right.\nEXAMPLE 1  Finding Critical Values of X2\nA simple random sample of 22 IQ scores is obtained (as in Example 2, which fol-\nlows). Construction of a confidence interval for the population standard deviation s \nrequires the left and right critical values of x2 corresponding to a confidence level \nof 95% and a sample size of n = 22. Find x2\nL (the critical value of x2 separating an \narea of 0.025 in the left tail), and find x2\nR (the critical value of x2 separating an area \nof 0.025 in the right tail).\nSOLUTION\nWith a sample size of n = 22, the number of degrees of freedom is df = n - 1 = 21.\nSee Figure 7-9.\n",
    "7-3 Estimating a Population Standard Deviation or Variance \n317\nWhen obtaining critical values of x2 from Table A-4, if a number of degrees of \nfreedom is not found in the table, you can be conservative by using the next lower \nnumber of degrees of freedom, or you can use the closest critical value in the table, \nor you can get an approximate result with interpolation. For numbers of degrees of \nfreedom greater than 100, use the equation given in Exercise 23 on page 324, or use a \nmore extensive table, or use technology.\nAlthough s2 is the best point estimate of s2, there is no indication of how good \nit is, so we use a confidence interval that gives us a range of values associated with a \nconfidence level.\n0\nx2\nL 5 10.283\nx2\nR 5 35.479\nx2\n(df 5 21)\n 0.025\n 0.025\nTable A-4:\nUse df 5 21 and\na cumulative right\narea of 0.975.\nTable A-4:\nUse df 5 21 and\na cumulative right\narea of 0.025.\nFIGURE 7-9 Finding Critical Values of X2\nThe critical value to the right 1x2\nR = 35.4792 is obtained from Table A-4  in \na straightforward manner by locating 21 in the degrees-of-freedom column at the \nleft and 0.025 across the top row. The leftmost critical value of x2\nL = 10.283 also \ncorresponds to 21 in the degrees-of-freedom column, but we must locate 0.975 (or \n1 - 0.025) across the top row because the values in the top row are always areas \nto the right of the critical value. Refer to Figure 7-9 and see that the total area to the \nright of x2\nL = 10.283 is 0.975.\nConfidence Interval for Estimating a Population Standard Deviation or Variance\nObjective\nConstruct a confidence interval estimate of a population standard deviation or variance.\nNotation\ns = population standard deviation \ns2 = population variance\ns = sample standard deviation \ns2 = sample variance\nn = number of sample values \nE = margin of error\nx2\nL = left-tailed critical value of x2 \nx2\nR = right-tailed critical value of x2\nKEY ELEMENTS\ncontinued\n",
    "318 \nCHAPTER 7 Estimating Parameters and Determining Sample Sizes\nProcedure for Constructing a Confidence Interval for S or S2\nConfidence intervals can be easily constructed with technology or they can be con-\nstructed by using Table A-4 with the following procedure.\n1. Verify that the two requirements are satisfied: The sample is a random sample \nfrom a normally distributed population.\n2. Using n - 1 degrees of freedom, find the critical values x2\nR and x2\nL that corre-\nspond to the desired confidence level (as in Example 1).\n3. Construct a confidence interval estimate of s2 by using the following:\n1n - 12s2\nx2\nR\n6 s2 6 1n - 12s2\nx2\nL\n4. To get a confidence interval estimate of s, take the square root of each compo-\nnent of the above confidence interval.\n5. Round the confidence interval limits using the round-off rule given in the \npreceding Key Elements box.\nUsing Confidence Intervals for Comparisons or Hypothesis Tests\nComparisons Confidence intervals can be used informally to compare the varia-\ntion in different data sets, but the overlapping of confidence intervals should not be \nRequirements\n1. The sample is a simple random sample.\n2. The population must have normally distributed values (even if the sample is large). The requirement of a normal \ndistribution is much stricter here than in earlier sections, so large departures from normal distributions can result in \nlarge errors. (If the normality requirement is not satisfied, use the bootstrap method described in Section 7-4.)\nConfidence Interval for the Population Variance S2\n1n - 12s2\nx2\nR\n6 s2 6 1n - 12s2\nx2\nL\nConfidence Interval for the Population Standard Deviation S\nB\n1n - 12s2\nx2\nR\n6 s 6 B\n1n - 12s2\nx2\nL\nRound-Off Rule\n1. Original Data: When using the original set of data values, round the confidence interval limits to one more decimal \nplace than is used for the original data.\n2. Summary Statistics: When using the summary statistics (n, s), round the confidence interval limits to the same num-\nber of decimal places used for the sample standard deviation.\nCAUTION A confidence interval can be expressed in a format such as  \n11.0 6 s 6 20.4 or a format of (11.0, 20.4), but it cannot be expressed in a format \nof s { E.\n",
    "7-3 Estimating a Population Standard Deviation or Variance \n319\nused for making formal and final conclusions about equality of variances or standard \ndeviations.\nEXAMPLE 2  Confidence Interval for Estimating S of IQ Scores\nData Set 8 “IQ and Lead” in Appendix B lists IQ scores for subjects in three differ-\nent lead exposure groups. The 22 full IQ scores for the group with medium expo-\nsure to lead (Group 2) have a standard deviation of 14.29263. Consider the sample \nto be a simple random sample and construct a 95% confidence interval estimate of \ns, the standard deviation of the population from which the sample was obtained.\nSOLUTION\nREQUIREMENT CHECK\nStep 1: Check requirements. (1) The sample can be treated as a simple random \nsample. (2) The accompanying histogram has a shape very close to the bell shape of \na normal distribution, so the requirement of normality is satisfied. \nMinitab\nStep 2: Using Technology The confidence interval can be found using technology. \nThe StatCrunch display shows the lower and upper confidence interval limits for \nthe 95% confidence interval estimate of s2, so we get 120.9 6 s2 6 417.2. Tak-\ning square roots, we get 11.0 6 s 6 20.4\nStatCrunch\nUsing Table A-4  If using Table A-4, we first use the sample size of n = 22 to \nfind degrees of freedom: df = n - 1 = 21. In Table A-4, refer to the row cor-\nresponding to 21 degrees of freedom, and refer to the columns with areas of 0.975 \nand 0.025. (For a 95% confidence level, we divide a = 0.05 equally between the \ntwo tails of the chi-square distribution, and we refer to the values of 0.975 and \n0.025 across the top row of Table A-4.) The critical values are x2\nL = 10.283 and \nx2\nR = 35.479 (as shown in Example 1).\ncontinued\n",
    "320 \nCHAPTER 7 Estimating Parameters and Determining Sample Sizes\nRationale for the Confidence Interval See Figure 7-9 on page 317 to make sense \nof this statement: If we select random samples of size n from a normally distrib-\nuted population with variance s2, there is a probability of 1 - a that the statistic \n1n - 12s2>s2 will fall between the critical values of x2\nL and x2\nR. It follows that there \nis a 1 - a probability that both of the following are true:\n1n - 12s2\ns2\n6 x2\nR and 1n - 12s2\ns2\n7 x2\nL\nMultiply both of the preceding inequalities by s2, then divide each inequality by the \nappropriate critical value of x2, so the two preceding inequalities can be expressed in \nthese equivalent forms:\n1n - 12s2\nx2\nR\n6 s2 and 1n - 12s2\nx2\nL\n7 s2\nThe two preceding inequalities can be combined into one inequality to get the format \nof the confidence interval used in this section:\n1n - 12s2\nx2\nR\n6 s2 6 1n - 12s2\nx2\nL\nDetermining Sample Size\nThe procedures for finding the sample size necessary to estimate s are much more \ncomplex than the procedures given earlier for means and proportions. For normally \ndistributed populations, Table 7-2 or the formula given in Exercise 24 “Finding Sam-\nple Size” on page 324 can be used.\nStep 3: Using the critical values of 10.283 and 35.479, the sample standard devia-\ntion of s = 14.29263, and the sample size of n = 22, we construct the 95% confi-\ndence interval by evaluating the following:\n 1n - 12s2\nx2\nR\n6 s2 6 1n - 12s2\nx2\nL\n 122 - 12114.292632 2\n35.479\n6 s2 6 122 - 12114.292632 2\n10.283\nStep 4: Evaluating the expression above results in 120.9 6 s2 6 417.2. Finding \nthe square root of each part (before rounding), then rounding to one decimal place, \nyields this 95% confidence interval estimate of the population standard deviation: \n11.0 6 s 6 20.4.\nINTERPRETATION\nBased on this result, we have 95% confidence that the limits of 11.0 and 20.4 contain \nthe true value of s. The confidence interval can also be expressed as (11.0, 20.4), but \nit cannot be expressed in a format of s { E.\nTABLE 7-2 Finding Sample Size\ns\n \nTo be 95%  \nconfident that \ns is within . . .\nof the value  \nof s, the sample \nsize n should be \nat least\n1%\n19,205\n5%\n768\n10%\n192\n20%\n48\n30%\n21\n40%\n12\n50%\n8\n \nTo be 99%  \nconfident that \ns is within . . .\nof the value  \nof s, the sample \nsize n should be \nat least\n1%\n33,218\n5%\n1,336\n10%\n336\n20%\n85\n30%\n38\n40%\n22\n50%\n14\n",
    "7-3 Estimating a Population Standard Deviation or Variance \n321\nEXAMPLE 3  Finding Sample Size for Estimating S\nWe want to estimate the standard deviation s of all IQ scores of people with exposure to \nlead. We want to be 99% confident that our estimate is within 5% of the true value of s. \nHow large should the sample be? Assume that the population is normally distributed.\nSOLUTION\nFrom Table 7-2, we can see that 99% confidence and an error of 5% for s corre-\nspond to a sample of size 1336. We should obtain a simple random sample of 1336 \nIQ scores from the population of subjects exposed to lead.\nConfidence Interval Estimate for Standard Deviation or Variance\nAccess tech instructions, videos, and data sets at www.TriolaStats.com\nTECH CENTER \nStatistical Literacy and Critical Thinking\n1. Brain Volume Using all of the brain volumes listed in Data Set 9 “IQ and Brain Size,” we get \nthis 95% confidence interval estimate: 9027.8 6 s2 6 33,299.8, and the units of measurement \nare (cm3)2. Identify the corresponding confidence interval estimate of s and include the appropri-\nate units. Given that the original values are whole numbers, round the limits using the round-off rule \ngiven in this section. Write a statement that correctly interprets the confidence interval estimate of s.\n2. Expressing Confidence Intervals Example 2 showed how the statistics of n = 22 and \ns = 14.3 result in this 95% confidence interval estimate of s: 11.0 6 s 6 20.4. That confi-\ndence interval can also be expressed as (11.0, 20.4), but it cannot be expressed as 15.7 { 4.7.\nGiven that 15.7 { 4.7 results in values of 11.0 and 20.4, why is it wrong to express the confi-\ndence interval as 15.7 { 4.7?\n3. Last Digit Analysis The accompanying dotplot depicts the last digits of the weights of \n153 males in Data Set 1 “Body Data.” Do those digits appear to be from a normally distributed \npopulation? If not, does the large sample size of n = 153 justify treating the values as if they \nwere from a normal distribution? Can the sample be used to construct a 95% confidence inter-\nval estimate of s for the population of all such digits?\n7-3  Basic Skills and Concepts\n4. Normality Requirement What is different about the normality requirement for a confidence \ninterval estimate of s and the normality requirement for a confidence interval estimate of m?\nFinding Critical Values and Confidence Intervals. In Exercises 5–8, use the given infor-\nmation to find the number of degrees of freedom, the critical values X2\nL and X2\nR, and the confi-\ndence interval estimate of S. The samples are from Appendix B and it is reasonable to assume \nthat a simple random sample has been selected from a population with a normal distribution.\n5. Nicotine in Menthol Cigarettes 95% confidence; n = 25, s = 0.24 mg.\n6. White Blood Cell Counts of Men 95% confidence; n = 153, s = 1.86.\n",
    "322 \nCHAPTER 7 Estimating Parameters and Determining Sample Sizes\n7. Platelet Counts of Women 99% confidence; n = 147, s = 65.4.\n8. Heights of Men 99% confidence; n = 153, s = 7.10 cm.\nFinding Confidence Intervals. In Exercises 9–16, assume that each sample is a simple \nrandom sample obtained from a population with a normal distribution.\n9. Body Temperature Data Set 2 “Body Temperatures” in Appendix B includes a sample of \n106 body temperatures having a mean of 98.20°F and a standard deviation of 0.62°F (for day 2 \nat 12 AM). Construct a 95% confidence interval estimate of the standard deviation of the body \ntemperatures for the entire population.\n10. Atkins Weight Loss Program In a test of weight loss programs, 40 adults used the Atkins \nweight loss program. After 12 months, their mean weight loss was found to be 2.1 lb, with \na standard deviation of 4.8 lb. Construct a 90% confidence interval estimate of the standard \ndeviation of the weight loss for all such subjects. Does the confidence interval give us informa-\ntion about the effectiveness of the diet?\n11. Insomnia Treatment A clinical trial was conducted to test the effectiveness of the drug zop-\niclone for treating insomnia in older subjects. After treatment with zopiclone, 16 subjects had a \nmean wake time of 98.9 min and a standard deviation of 42.3 min (based on data from “Cognitive \nBehavioral Therapy vs Zopiclone for Treatment of Chronic Primary Insomnia in Older Adults,” \nby Sivertsen et al., Journal of the American Medical Association, Vol. 295, No. 24). Assume that \nthe 16 sample values appear to be from a normally distributed population and construct a 98% \nconfidence interval estimate of the standard deviation of the wake times for a population with \nzopiclone treatments. Does the result indicate whether the treatment is effective?\n12. Garlic for Reducing Cholesterol In a test of the effectiveness of garlic for lowering cho-\nlesterol, 49 subjects were treated with raw garlic. Cholesterol levels were measured before and \nafter the treatment. The changes (before minus after) in their levels of LDL cholesterol (in mg>dL) \nhad a mean of 0.4 and a standard deviation of 21.0 (based on data from “Effect of Raw Garlic \nvs Commercial Garlic Supplements on Plasma Lipid Concentrations in Adults with Moderate \nHypercholesterolemia,” by Gardner et al., Archives of Internal Medicine, Vol. 167). Construct \na 98% confidence interval estimate of the standard deviation of the changes in LDL cholesterol \nafter the garlic treatment. Does the result indicate whether the treatment is effective?\n 13. World’s Smallest Mammal The world’s smallest mammal is the bumblebee bat, also \nknown as the Kitti’s hog-nosed bat (or Craseonycteris thonglongyai as it is affectionately \ncalled). Such bats are roughly the size of a large bumblebee. Listed below are weights (in \ngrams) from a sample of these bats. Construct a 95% confidence interval estimate of the stan-\ndard deviation of weights for all such bats.\n1.7 1.6 1.5 2.0 2.3 1.6 1.6 1.8 1.5 1.7 2.2 1.4 1.6 1.6 1.6\n 14. Queues A Providence Hospital experiment involves two different waiting line configura-\ntions for patients arriving for admission. The waiting times (in seconds) are recorded with a \nsingle-line configuration that feeds four stations and another configuration with individual lines \nat the four stations. Determine whether there is a difference in variation between the two data \nsets. Which configuration appears to be better?\n  Single Line\n  390  396  402  408  426  438  444  462  462  462 \n Individual Lines  252  324  348  372  402  462  462  510  558  600\n 15. Shoveling Heart Rates Because cardiac deaths appear to increase after heavy snowfalls, \nan experiment was designed to compare cardiac demands of snow shoveling to those of using an \nelectric snow thrower. Ten subjects cleared tracts of snow using both methods, and their maxi-\nmum heart rates (beats per minute, or BPM) were recorded during both activities. The results \nshown below were obtained (based on data from “Cardiac Demands of Heavy Snow Shoveling,” \nby Franklin et al., Journal of the American Medical Association, Vol. 273, No. 11).\n  Manual Snow Shoveling:  n = 10, x = 175 BPM, s = 15 BPM\n Electric Snow Thrower:  n = 10, x = 124 BPM, x = 124, s = 18 BPM\ncontinued\n",
    "7-3 Estimating a Population Standard Deviation or Variance \n323\na. Construct a 95% confidence interval estimate of the population standard deviation s for \nthose who did manual snow shoveling.\nb. Construct a 95% confidence interval estimate of the population standard deviation s for \nthose who used the automated electric snow thrower.\nc. Compare the results. Does the variation appear to be different for the two groups?\n16. Acupuncture for Migraines In a study designed to test the effectiveness of acupuncture \nfor treating migraine headaches, 142 subjects were treated with acupuncture and 80 subjects \nwere given a sham treatment. The numbers of migraine attacks for the acupuncture treatment \ngroup had a mean of 1.8 and a standard deviation of 1.4. The numbers of migraine attacks for \nthe sham treatment group had a mean of 1.6 and a standard deviation of 1.2. Construct a 95% \nconfidence interval estimate of s for each of the two groups, and then compare the results.\nLarge Data Sets from Appendix B. In Exercises 17 and 18, use the data set in \n Appendix B. Assume that each sample is a simple random sample obtained from a popula-\ntion with a normal distribution.\n17. Birth Length of Stay Refer to Data Set 3 “Births” in Appendix B.\na. Use the lengths of stay (days) for the 205 girls to construct a 95% confidence interval esti-\nmate of the standard deviation of the population from which the sample was obtained. For criti-\ncal values, use x2\nL = 166.337 and x2\nR = 245.449. Does the distribution of those data appear to \nbe approximately normal? How does that affect the results?\nb. Repeat part (a) using the 195 boys and, for critical values, use x2\nL = 157.321 and \nx2\nR = 234.465.\nc. Compare the results from part (a) and part (b).\n18. Birth Weights Refer to Data Set 3 “Births” in Appendix B\na. Use the 205 birth weights of girls to construct a 95% confidence interval estimate of the \nstandard deviation of the population from which the sample was obtained. For critical values, \nuse x2\nL = 166.337 and x2\nR = 245.449.\nb. Repeat part (a) using the 195 birth weights of boys and, for critical values, use x2\nL = 157.321 \nand x2\nR = 234.465.\nc. Compare the results from part (a) and part (b).\nDetermining Sample Size. In Exercises 19–22, assume that each sample is a simple ran-\ndom sample obtained from a normally distributed population. Use Table 7-2 on page 320 to \nfind the indicated sample size.\n 19. IQ of Biostatistics Professors You want to estimate s for the population of IQ scores \nof biostatistics professors. Find the minimum sample size needed to be 95% confident that the \nsample standard deviation s is within 1% of s. Is this sample size practical?\n20. ER Waiting Times You want to estimate s for the population of waiting times for hos-\npital emergency rooms. You want to be 99% confident that the sample standard deviation is \nwithin 1% of s. Find the minimum sample size. Is this sample size practical?\n21. Statistics Student Incomes You want to estimate the standard deviation of the annual \nincomes of all current statistics students. Find the minimum sample size needed to be 95% con-\nfident that the sample standard deviation is within 20% of the population standard deviation. \nAre those incomes likely to satisfy the requirement of a normal distribution?\n22. Aspirin Quality When attempting to verify the aspirin contents in manufactured tablets, \nyou must estimate the standard deviation of the population of aspirins in use. Find the mini-\nmum sample size needed to be 99% confident that the sample standard deviation is within 10% \nof the population standard deviation.\n",
    "324 \nCHAPTER 7 Estimating Parameters and Determining Sample Sizes\n23. Finding Critical Values In constructing confidence intervals for s or s2, Table A-4  can \nbe used to find the critical values x2\nL and x2\nR only for select values of n up to 101, so the number \nof degrees of freedom is 100 or smaller. For larger numbers of degrees of freedom, we can ap-\nproximate x2\nL and x2\nR by using\nx2 = 1\n23 {za>2 + 22k - 142\nwhere k is the number of degrees of freedom and za>2 is the critical z score described in Sec-\ntion 7-1. Use this approximation to find the 95% critical values x2\nL and x2\nR for the acupuncture \ntreatment group in Exercise 16 “Acupuncture for Migraines” where n = 142. How do the \nresults compare to the actual critical values of x2\nL = 110.020 and x2\nR = 175.765?\n24. Finding Sample Size Instead of using Table 7-2 for determining the sample size required \nto estimate a population standard deviation s, the following formula can be used:\nn = 1\n2\n a\nza>2\nd b\n2\nwhere za>2 corresponds to the confidence level and d is the decimal form of the percentage \n error. For example, to be 95% confident that s is within 15% of the value of s, use za>2 = 1.96\nand d = 0.15 to get a sample size of n = 86. Find the sample size required to estimate s, \n assuming that we want 98% confidence that s is within 15% of s.\n7-3 Beyond the Basics\nKey Concept The preceding sections presented methods for estimating population pro-\nportions, means, and standard deviations (or variances). All of those methods have certain \nrequirements that limit the situations in which they can be used. When some of the require-\nments are not satisfied, we can often use the bootstrap method to estimate a parameter with \na confidence interval. The bootstrap method typically requires the use of software.\nSampling Requirement The preceding methods of this chapter all have a require-\nment that the sample must be a simple random sample. If the sample is not collected \nin an appropriate way, there’s a good chance that nothing can be done to get a us-\nable confidence interval estimate of a parameter. Bootstrap methods do not correct for \npoor sampling methods.\nRequirements Listed below are important requirements from the preceding sections \nof this chapter:\n \n■CI for Proportion (Section 7-1): There are at least 5 successes and at least 5 \nfailures, or np Ú 5 and nq Ú 5.\n \n■CI for Mean (Section 7-2): The population is normally distributed or n 7 30.\n \n■CI for S or S2 (Section 7-3): The population must have normally distributed \nvalues, even if the sample is large.\nWhen the above requirements are not satisfied, we should not use the methods pre-\nsented in the preceding sections of this chapter, but we can use the bootstrap method \ninstead. The bootstrap method does not require large samples. This method does not \nrequire the sample to be collected from a normal or any other particular distribution, \nand so it is called a nonparametric or distribution-free method; other nonparamet-\nric methods are included in Chapter 13.\n7-4 \nBootstrapping: Using Technology for Estimates\n",
    "7-4 Bootstrapping: Using Technology for Estimates \n325\nWhy Is It Called “Bootstrap”? The term “bootstrap” is used because the data “pull \nthemselves up by their own bootstraps” to generate new data sets. In days of yore, \n“pulling oneself up by one’s bootstraps” meant that an impossible task was somehow \naccomplished, and the bootstrap method described in this section might seem impos-\nsible, but it works!\nHow Many? In the interest of providing manageable examples that don’t occupy mul-\ntiple pages each, the examples in this section involve very small data sets and no more \nthan 20 bootstrap samples, but we should use at least 1000 bootstrap samples when \nwe use bootstrap methods in serious applications. Professional statisticians commonly \nuse 10,000 or more bootstrap samples.\nBootstrap Procedure for a Confidence Interval Estimate of a Parameter\n1. Given a simple random sample of size n, obtain many (such as 1000 or more) \nbootstrap samples of the same size n.\n2. For the parameter to be estimated, find the corresponding statistic for each \nof the bootstrap samples. (Example: For a confidence estimate of m, find the \n sample mean x from each bootstrap sample.)\n3. Sort the list of sample statistics from low to high.\nDEFINITION\nGiven a simple random sample of size n, a bootstrap sample is another random \nsample of n values obtained with replacement from the original sample.\nCAUTION Note that a bootstrap sample involves sampling with replacement, so \nthat when a sample value is selected, it is replaced before the next selection is \nmade.\nWithout replacement, every sample would be the same as the original sample, so the \nproportions or means or standard deviations or variances would all be the same, and \nthere would be no confidence “interval.”\nEXAMPLE 1  Bootstrap Sample of Incomes\nWhen one of the authors collected annual incomes of current statistics students, he \nobtained these results (in thousands of dollars): 0, 2, 3, 7.\nOriginal Sample\nBootstrap Sample\n0\n7\n2\n2\n3\n2\n7\n3\nThe sample of {7, 2, 2, 3} is one bootstrap sample obtained from the original sam-\nple. Other bootstrap samples may be different.\nIncomes tend to have distributions that are skewed instead of being normal, so \nwe should not use the methods of Section 7-2 with a small sample of incomes. This \nis a situation in which the bootstrap method comes to the rescue.\nhe\nHow Many People  \nDo You Know?\nIt’s difficult for \nanyone to count \nthe number \nof people he \nor she knows, \nbut statistical \nmethods can \nbe used to estimate the mean \nnumber of people that we all \nknow. The simple approach of \njust asking someone how many \npeople are known has worked \npoorly in the past. A much \nbetter approach is to select a \nrepresentative sample of people \nand ask each person how many \npeople he or she knows who \nare named Marc, Mario, Jason, \nGinny, Rachel, or Todd. (Uncom-\nmon names are more effective \nbecause people with more com-\nmon names are more difficult to \naccurately recall.) Responses \nare then used to project the total \nnumber of people that are known. \n(If sample subjects know a mean \nof 1.76 people with those names, \nand we know that 0.288% of the \npopulation has those names, \nthen the mean number of people \nknown is 1.76>0.00288 = 611.) \nAccording to one estimate, the \nmean number of people known \nis 611, and the median is 472. \n(See “How Many People Do \nYou Know? Efficiently Estimat-\ning Personal Network Size,” by \n McCormick, Salganik, and Zheng, \nJournal of the American Statisti-\ncal Association, Vol. 105, No. 4.)\ncontinued\n",
    "326 \nCHAPTER 7 Estimating Parameters and Determining Sample Sizes\n4. Using the sorted list of the statistics, create the confidence interval by find-\ning corresponding percentile values. Procedures for finding percentiles are \ngiven in Section 3-3. (Example: Using a list of sorted sample means, the \n90% confidence interval limits are P5 and P95. The 90% confidence interval \nestimate of m is P5 6 m 6 P95.)\nUsefulness of Results For the purpose of illustrating the bootstrap procedure, \n Examples 2, 3, and 4 all involve very small samples with only 20 bootstrap samples. \nConsequently, the resulting confidence intervals include almost the entire range of \nsample values, and those confidence intervals are not very useful. Larger samples \nwith 1000 or more bootstrap samples will provide much better results than those \nfrom Examples 2, 3, and 4.\nProportions\nWhen working with proportions, it is very helpful to represent the data from the two \ncategories by using 0’s and 1’s, as in the following example.\nTABLE 7-3 Bootstrap Samples for p\nBootstrap Sample\npn\nSorted pn\n1\n0\n0\n1\n0.50\n0.00\nP5 = 0.00\n1\n0\n1\n0\n0.50\n0.00\n0\n1\n1\n1\n0.75\n0.00\n0\n0\n0\n0\n0.00\n0.00\n0\n1\n0\n0\n0.25\n0.25\n1\n0\n0\n0\n0.25\n0.25\n0\n1\n0\n1\n0.50\n0.25\n1\n0\n0\n0\n0.25\n0.25\n0\n0\n0\n0\n0.00\n0.25\n0\n0\n1\n1\n0.50\n0.25\n90% Confidence Interval:\n0\n0\n0\n1\n0.25\n0.25\n0.00 6 p 6 0.75\n0\n0\n1\n0\n0.25\n0.25\n1\n1\n1\n0\n0.75\n0.50\n0\n0\n0\n0\n0.00\n0.50\n0\n0\n0\n0\n0.00\n0.50\n0\n1\n1\n0\n0.50\n0.50\n0\n0\n1\n0\n0.25\n0.50\n1\n0\n0\n0\n0.25\n0.75\n1\n1\n1\n0\n0.75\n0.75\nP95 = 0.75\n0\n0\n0\n1\n0.25\n0.75\nEXAMPLE 2  Eye Color Survey: Bootstrap CI for Proportion\nIn a survey, four randomly selected subjects were asked if they have brown eyes, and here are the results: 0, \n0, 1, 0 (where 0 = no and 1 = yes). Use the bootstrap resampling procedure to construct a 90% confidence \ninterval estimate of the population proportion p, the proportion of people with brown eyes in the population.\nSOLUTION\nREQUIREMENT CHECK The sample is a simple random sample. \n(There is no requirement of at least 5 successes and at least 5 \nfailures, or np Ú 5 and nq Ú 5. There is no requirement that \nthe sample must be from a normally distributed population.) \nStep 1: In Table 7-3, we created 20 bootstrap samples from \nthe original sample of 0, 0, 1, 0.\nStep 2: Because we want a confidence interval estimate of the \npopulation proportion p, we want the sample proportion pn for \neach of the 20 bootstrap samples, and those sample propor-\ntions are shown in the column to the right of the bootstrap \nsamples.\nStep 3: The column of data shown farthest to the right is a list \nof the 20 sample proportions arranged in order (“sorted”) from \nlowest to highest.\nStep 4: Because we want a confidence level of 90%, we want \nto find the percentiles P5 and P95. Recall that P5 separates the \nlowest 5% of values, and P95 separates the top 5% of values. \nUsing the methods from Section 3-3 for finding percentiles, \nwe use the sorted list of bootstrap sample proportions to find \nthat P5 = 0.00 and P95 = 0.75. The 90% confidence interval \nestimate of the population proportion is 0.00 6 p 6 0.75.\nINTERPRETATION\nThe confidence interval of 0.00 6 p 6 0.75 is quite wide. After all, every confidence interval for every pro-\nportion must fall between 0 and 1, so the 90% confidence interval of 0.00 6 p 6 0.75 doesn’t seem to be \nhelpful, but it is based on only four sample values.\n",
    "7-4 Bootstrapping: Using Technology for Estimates \n327\nMeans\nIn Section 7-2 we noted that when constructing a confidence interval estimate of a \npopulation mean, there is a requirement that the sample is from a normally distributed \npopulation or the sample size is greater than 30. The bootstrap method can be used \nwhen this requirement is not satisfied.\nHINT Example 2 uses only 20 bootstrap samples, but effective use of the bootstrap \nmethod typically requires the use of software to generate 1000 or more bootstrap \nsamples.\nTABLE 7-4 Bootstrap Samples for m\nBootstrap Sample\nx\nSorted x\n3\n3\n0\n2\n2.00\n1.75\nP5 = 1.75\n0\n3\n2\n2\n1.75\n1.75\n7\n0\n2\n7\n4.00\n1.75\n3\n2\n7\n3\n3.75\n2.00\n0\n0\n7\n2\n2.25\n2.00\n7\n0\n0\n3\n2.50\n2.25\n3\n0\n3\n2\n2.00\n2.50\n3\n7\n3\n7\n5.00\n2.50\n0\n3\n2\n2\n1.75\n2.50\n0\n3\n7\n0\n2.50\n2.75\n90% Confidence Interval:\n0\n7\n2\n2\n2.75\n3.00\n1.75 6 m 6 4.875\n7\n2\n2\n3\n3.50\n3.25\n7\n2\n3\n7\n4.75\n3.25\n2\n7\n2\n7\n4.50\n3.50\n0\n7\n2\n3\n3.00\n3.75\n7\n3\n7\n2\n4.75\n4.00\n3\n7\n0\n3\n3.25\n4.50\n0\n0\n3\n7\n2.50\n4.75\n3\n3\n7\n0\n3.25\n4.75\nP95 = 4.875\n2\n0\n2\n3\n1.75\n5.00\nEXAMPLE 3  Incomes: Bootstrap CI for Mean\nWhen one of the authors collected a simple random sample of annual incomes of his statistics students, he obtained \nthese results (in thousands of dollars): 0, 2, 3, 7. Use the bootstrap resampling procedure to construct a 90% confi-\ndence interval estimate of the mean annual income of the population of all of the author’s statistics students.\nSOLUTION\nREQUIREMENT CHECK The sample is a simple random sample and there is no requirement that the sample must be from \na normally distributed population. Because distributions of incomes are typically skewed instead of normal, we should \nnot use the methods of Section 7-2 for finding the confidence interval, but the bootstrap method can be used. \nStep 1: In Table 7-4, we created 20 bootstrap samples \n(with replacement!) from the original sample of 0, 2, 3, \n7. (Here we use only 20 bootstrap samples, so we have a \nmanageable example that doesn’t occupy many pages of \ntext, but we usually want at least 1000 bootstrap samples.)\nStep 2: Because we want a confidence interval estimate \nof the population mean m, we want the sample mean x for \neach of the 20 bootstrap samples, and those sample means \nare shown in the column to the right of the bootstrap \nsamples.\nStep 3: The column of data shown farthest to the right is \na list of the 20 sample means arranged in order (“sorted”) \nfrom lowest to highest.\nStep 4: Because we want a confidence level of 90%, we \nwant to find the percentiles P5 and P95. Again, P5 separates \nthe lowest 5% of values, and P95 separates the top 5% of \nvalues. Using the methods from Section 3-3 for finding \npercentiles, we use the sorted list of bootstrap sample \nmeans to find that P5 = 1.75 and P95 = 4.875. The 90% \nconfidence interval estimate of the population mean is \n1.75 6 m 6 4.875, where the values are in thousands of \ndollars.\nStandard Deviations\nIn Section 7-3 we noted that when constructing confidence interval estimates of popu-\nlation standard deviations or variances, there is a requirement that the sample must \nbe from a population with normally distributed values. Even if the sample is large, \n",
    "328 \nCHAPTER 7 Estimating Parameters and Determining Sample Sizes\nthis normality requirement is much stricter than the normality requirement used for \nestimating population means. Consequently, the bootstrap method becomes more im-\nportant for confidence interval estimates of s or s2.\nEXAMPLE 4  Incomes: Bootstrap CI for Standard Deviation\nUse these same incomes (thousands of dollars) from Example 3: 0, 2, 3, 7. Use the \nbootstrap resampling procedure to construct a 90% confidence interval estimate of \nthe population standard deviation s, the standard deviation of the annual incomes of \nthe population of the author’s statistics students.\nSOLUTION\nREQUIREMENT CHECK The same requirement check used in Example 3 applies  \nhere. \nThe same basic procedure used in Example 3 is used here. Example 3 already \nincludes 20 bootstrap samples, so here we find the standard deviation of each \nbootstrap sample, and then we sort them to get this sorted list of sample standard \ndeviations:\n1.26 1.26 1.26 1.41 1.41 2.22 2.31 2.38 2.63 2.63\n2.87 2.87 2.89 2.94 2.99 3.30 3.32 3.32 3.32 3.56\nThe 90% confidence interval limits are found from this sorted list of standard devia-\ntions by finding P5 and P95. Using the methods from Section 3-3, we get P5 = 1.26 \nand P95 = 3.44. The 90% confidence interval estimate of the population standard \ndeviation s is 1.26 6 s 6 3.44, where the values are in thousands of dollars.\nAgain, know that for practical reasons, the examples of this section involved very \nsmall data sets and no more than 20 bootstrap samples, but use at least 1000 bootstrap \nsamples. The use of 10,000 or more bootstrap samples is common.\nBootstrap Resampling\nAccess tech instructions, videos, and data sets at www.TriolaStats.com\nTECH CENTER \nStatistical Literacy and Critical Thinking \n1. Replacement Why does the bootstrap method require sampling with replacement? What \nwould happen if we used the methods of this section but sampled without replacement?\n2. Bootstrap Sample Here is a random sample of numbers of patients in a day who required \nmedication at a clinic: 12, 19, 13, 43, 15. For this sample, what is a bootstrap sample?\n3. Bootstrap Sample Given the sample data from Exercise 2, which of the following are not \npossible bootstrap samples?\na. 12, 19, 13, 43, 15 \nb. 12, 19, 15 \nc. 12, 12, 12, 43, 43\nd. 14, 20, 12, 19, 15 \ne. 12, 13, 13, 12, 43, 15, 19\n7-4 Basic Skills and Concepts\n",
    "7-4 Bootstrapping: Using Technology for Estimates \n329\n4. How Many? The examples in this section all involved no more than 20 bootstrap samples. \nHow many should be used in real applications?\nIn Exercises 5–8, use the relatively small number of given bootstrap samples to construct \nthe confidence interval.\n5. Survey Responses In a physician’s office, four patients are asked if they would be willing \nto complete a survey before leaving. Responses included these: no, yes, no, no. Letting “yes”\n= 1 and letting “no” = 0, here are ten bootstrap samples for those responses: {0, 0, 0, 0}, \n{1, 0, 1, 0}, {1, 0, 1, 0}, {0, 0, 0, 0}, {0, 0, 0, 0}, {0, 1, 0, 0}, {0, 0, 0, 0}, {0, 0, 0, 0}, \n{0, 1, 0, 0}, {1, 1, 0, 0}. Using only the ten given bootstrap samples, construct a 90% confi-\ndence interval estimate of the proportion of patients who said that they would be willing to \ncomplete the survey.\n6. ER Admissions An emergency room official records whether patients are admitted to the \nhospital, and the results include these: admitted, admitted, not admitted, not admitted. Letting \n“admitted” = 1 and letting “not admitted” = 0, here are ten bootstrap samples for these pa-\ntients: {0, 0, 0, 0}, {0, 1, 0, 0}, {0, 1, 0, 1}, {0, 0, 1, 0}, {1, 1, 1, 0}, {0, 1, 1, 0}, {1, 0, 0, 1}, \n{0, 1, 1, 1}, {1, 0, 1, 0}, {1, 0, 0, 1}. Using only the ten given bootstrap samples, construct an \n80% confidence interval estimate of the proportion of patients who are admitted.\n7. Freshman 15 Here is a sample of amounts of weight change (kg) of college students in their \nfreshman year (from Data Set 10 “Freshman 15” in Appendix B): 11, 3, 0, -2, where -2 repre-\nsents a loss of 2 kg and positive values represent weight gained. Here are ten bootstrap samples: \n{11, 11, 11, 0}, {11, -2, 0, 11}, {11, -2, 3, 0}, {3, -2, 0, 11}, {0, 0, 0, 3}, {3, -2, 3, -2}, \n{11, 3, -2, 0}, {-2, 3, -2, 3}, {-2, 0, -2, 3}, {3, 11, 11, 11}.\na. Using only the ten given bootstrap samples, construct an 80% confidence interval estimate \nof the mean weight change for the population.\nb. Using only the ten given bootstrap samples, construct an 80% confidence interval estimate \nof the standard deviation of the weight changes for the population.\n8. Cell Phone Radiation Here is a sample of measured radiation emissions (cW>kg) for cell \nphones (based on data from the Environmental Working Group): 38, 55, 86, 145. Here are \nten bootstrap samples: {38, 145, 55, 86}, {86, 38, 145, 145}, {145, 86, 55, 55}, {55, 55, 55, \n145}, {86, 86, 55, 55}, {38, 38, 86, 86}, {145, 38, 86, 55}, {55, 86, 86, 86}, {145, 86, 55, 86}, \n{38, 145, 86, 55}.\na. Using only the ten given bootstrap samples, construct an 80% confidence interval estimate \nof the population mean.\nb. Using only the ten given bootstrap samples, construct an 80% confidence interval estimate \nof the population standard deviation.\nIn Exercises 9–22, use technology to create the large number of bootstrap samples.\n9. Freshman 15 Repeat Exercise 7 “Freshman 15” using a confidence level of 90% for parts \n(a) and (b) and using 1000 bootstrap samples instead of the 10 that were given in Exercise 7.\n10. Cell Phone Radiation Repeat Exercise 8 “Cell Phone Radiation” using a confidence \nlevel of 90% for parts (a) and (b), using 1000 bootstrap samples instead of the 10 that were \ngiven in Exercise 8.\n11. ER Wait Times The District of Columbia has some of the longest emergency room wait-\ning times in the United States. Here are times (minutes) patients waited in District of Columbia \nemergency rooms before seeing a physician: 40, 68, 72, 67, 54, 59, 68, 47, 55, 74, 63, 73. Use \nthe bootstrap method with 1000 bootstrap samples.\na. Construct a 99% confidence interval estimate of the population mean. Is the result dramati-\ncally different from the 99% confidence interval that would be found using the confidence \ninterval constructed by using the t distribution, as in Section 7-2?\ncontinued\n",
    "330 \nCHAPTER 7 Estimating Parameters and Determining Sample Sizes\nb. Construct a 95% confidence interval estimate of the population standard deviation. Is the \nresult dramatically different from the 95% confidence interval that would be found using the x2\ndistribution, as in Section 7-3?\n12. ER Wait Times Repeat Exercise 11 “ER Wait Times” using these emergency room wait-\ning times (minutes) from Florida: 29, 49, 31, 24, 14, 37, 43, 40, 35, 34, 10, 38, 2, 54.\n13. Lipitor In clinical trials of the drug Lipitor (atorvastatin), 863 subjects were treated with \n10 mg of the drug, and 8 of them experienced allergic reactions. Use the bootstrap method to \nconstruct a 95% confidence interval estimate of the percentage of treated subjects who experi-\nence allergic reactions. Use 1000 bootstrap samples. How does the result compare to the confi-\ndence interval found in Exercise 22 from Section 7-1 on page 296?\n14. Eliquis The drug Eliquis (apixaban) is used to help prevent blood clots in certain patients. \nIn clinical trials, among 5924 patients treated with Eliquis, 153 developed the adverse reaction \nof nausea (based on data from Bristol-Myers Squibb Co.). Use the bootstrap method to con-\nstruct a 99% confidence interval estimate of the proportion of patients who experience nausea. \nUse 1000 bootstrap samples. How does the result compare to the confidence interval found in \nExercise 14 “Eliquis” from Section 7-1 on page 295?\n15. Survey Return Rate In a study of cell phone use and brain hemispheric dominance, an In-\nternet survey was e-mailed to 5000 subjects randomly selected from an online otological group \n(focused on ears), and 717 surveys were returned. Use the bootstrap method to construct a 90% \nconfidence interval estimate of the proportion of returned surveys. Use 1000 bootstrap samples. \nHow does the result compare to the confidence interval found in Exercise 15 “Survey Return \nRate” from Section 7-1 on page 295?\n16. Medical Malpractice In a study of 1228 randomly selected medical malpractice lawsuits, \nit was found that 856 of them were dropped or dismissed (based on data from the Physicians \nInsurers Association of America). Use the bootstrap method to construct a 95% confidence in-\nterval estimate of the proportion of lawsuits that are dropped or dismissed. Use 1000 bootstrap \nsamples. How does the result compare to the confidence interval found in Exercise 16 “Medi-\ncal Malpractice” from Section 7-1 on page 295?\n17. Student Evaluations Listed below are student evaluation ratings of courses, where a \nrating of 5 is for “excellent.” The ratings were obtained at the University of Texas at Austin. \nUsing the bootstrap method with 1000 bootstrap samples, construct a 90% confidence interval \nestimate of m. How does the result compare to the result that would be obtained by using the \nmethods from Section 7-2?\n3.8 3.0 4.0 4.8 3.0 4.2 3.5 4.7 4.4 4.2 4.3 3.8 3.3 4.0 3.8\n18. Caffeine in Soft Drinks Listed below are measured amounts of caffeine (mg per 12 oz of \ndrink) obtained in one can from each of 20 brands. Using the bootstrap method with 1000 bootstrap \nsamples, construct a 99% confidence interval estimate of m. How does the result compare to the \nconfidence interval found in Exercise 21 “Caffeine in Soft Drinks” in Section 7-2 on page 312?\n0 0 34 34 34 45 41 51 55 36 47 41 0 0 53 54 38 0 41 47\n 19. Cell Phone Radiation Here are the measured radiation emissions (in W>kg) from differ-\nent cell phones: 0.38, 0.55, 1.54, 1.55, 0.50, 0.60, 0.92, 0.96, 1.00, 0.86, 1.46. Use the bootstrap \nmethod with 1000 bootstrap samples to find a 90% confidence interval estimate of m. How does \nthe result compare to the confidence interval found for Exercise 17 in Section 7-2 on page 311?\n 20. Cell Phone Radiation Repeat Exercise 19 using the standard deviation instead of the mean. \nCompare the confidence interval to the one that would be found using the methods of Section 7-3.\n21. Analysis of Last Digits Weights of respondents were recorded as part of the California \nHealth Interview Survey. The last digits of weights from 50 randomly selected respondents are \nlisted below.\n5 0 1 0 2 0 5 0 5 0 3 8 5 0 5 0 5 6 0 0 0 0 0 0 8\n5 5 0 4 5 0 0 4 0 0 0 0 0 8 0 9 5 3 0 5 0 0 0 5 8\ncontinued\n",
    "a. Use the bootstrap method with 1000 bootstrap samples to find a 95% confidence interval \nestimate of s.\nb. Find the 95% confidence interval estimate of s found by using the methods of Section 7-3.\nc. Compare the results. If the two confidence intervals are different, which one is better? Why?\n22. Analysis of Last Digits Repeat Exercise 21 “Analysis of Last Digits” using the mean in-\nstead of the standard deviation. Compare the confidence interval to the one that would be found \nusing the methods of Section 7-2.\n23. Effect of the Number of Bootstrap Samples Repeat Exercise 21 “Analysis of Last \nDigits” using 10,000 bootstrap samples instead of 1000. What happens?\n24. Distribution Shapes Use the sample data given in Exercise 21 “Analysis of Last Digits.” \na. Do the original sample values appear to be from a normally distributed population? Explain.\nb. Do the 1000 bootstrap samples appear to have means that are from a normally distributed \npopulation? Explain.\nc. Do the 1000 bootstrap samples appear to have standard deviations that are from a normally \ndistributed population? Explain.\n7-4 Beyond the Basics\n1. Vision Correction Here is a 95% confidence interval estimate of the proportion of adults \nwho correct their vision by wearing contact lenses: 0.110 6 p 6 0.150 (based on data from a \nVision Council survey). What is the best point estimate of the proportion of adults in the popu-\nlation who correct their vision by wearing contact lenses?\n2.  Interpreting CI Write a brief statement that correctly interprets the confidence interval \ngiven in Exercise 1.\n3. Critical Value For the survey described in Exercise 1, find the critical value that would be \nused for constructing a 99% confidence interval estimate of the population proportion.\n4. Vision Correction From the same survey results cited in Exercise 1 “Vision Correction,” it \nwas reported that 3% of adults correct their vision with surgery, and the margin of error is {1.0\npercentage points. Identify the confidence interval.\n5. Sample Size for Proportion Find the sample size required to estimate the percentage of \ncollege students who take a statistics course. Assume that we want 95% confidence that the \nproportion from the sample is within four percentage points of the true population percentage.\n6. Sample Size for Mean Find the sample size required to estimate the mean IQ of surgeons. \nAssume that we want 98% confidence that the mean from the sample is within three IQ points \nof the true population mean. Also assume that s = 15.\n7. Requirements A quality control analyst has collected a random sample of 12 batteries used \nin heart pacemakers and she plans to test their voltage level and construct a 95% confidence \ninterval estimate of the mean voltage level for the population of batteries. What requirements \nmust be satisfied in order to construct the confidence interval using the method with the t dis-\ntribution?\n8. Degrees of Freedom In general, what does “degrees of freedom” refer to? For the sample \ndata described in Exercise 7, find the number of degrees of freedom, assuming that you want to \nconstruct a confidence interval estimate of m using the t distribution.\nChapter Quick Quiz\nCHAPTER 7 Chapter Quick Quiz \n331\n",
    "332 \nCHAPTER 7 Estimating Parameters and Determining Sample Sizes\n9. Critical Value Refer to Exercise 7 and assume that the requirements are satisfied. Find the \ncritical value that would be used for constructing a 95% confidence interval estimate of m using \nthe t distribution.\n10. Which Method? Refer to Exercise 7 and assume that a sample of 12 voltage levels ap-\npears to be from a population with a distribution that is substantially far from being normal. \nShould a 95% confidence interval estimate of s be constructed using the x2 distribution? If \nnot, what other method could be used to find a 95% confidence interval estimate of s?\nReview Exercises\n1. Brain Cancer Cluster In a study designed to determine whether there was a cluster of brain \ncancer cases at a Pratt & Whitney plant, records from 223,000 employees were studied and \n723 employees with brain tumors were found. Treat those employees as a random sample and \nconstruct a 95% confidence interval estimate of the proportion of all adults who develop such \ntumors. Write a brief statement interpreting that confidence interval.\n2. Medicare A hospital wants to estimate the percentage of admitted patients who receive \nMedicare benefits. If we want to estimate that percentage based on examination of randomly \nselected patient payment records, how many patient records must be examined in order to be \n90% confident that we are within four percentage points of the population percentage?\n3. Cuckoo Egg Lengths Listed below are lengths (mm) of cuckoo eggs.\na. Identify the best point estimate of the population mean m.\nb. Construct a 95% confidence interval estimate of the mean length of all cuckoo eggs.\nc. Write a statement that interprets the confidence interval.\n22.05 22.05 22.05 22.05 22.05 22.05 22.05 22.05 22.05 22.05 22.25 22.25\n4. Lefties There have been several studies conducted in an attempt to identify ways in which \nleft-handed people are different from those who are right handed. Assume that you want to \nestimate the mean IQ of all left-handed adults. How many random left-handed adults must \nbe tested in order to be 99% confident that the mean IQ of the sample group is within four IQ \npoints of the mean IQ of all left-handed adults? Assume that s is known to be 15.\n5. Distributions Identify the distribution (normal, Student t, chi-square) that should be used \nin each of the following situations. If none of the three distributions can be used, what other \nmethod could be used?\na. In constructing a confidence interval of m, you have 75 sample values and they appear to be \nfrom a population with a skewed distribution. The population standard deviation is not known.\nb. In constructing a confidence interval estimate of m, you have 75 sample values and they ap-\npear to be from a population with a skewed distribution. The population standard deviation is \nknown to be 18.2 cm.\nc. In constructing a confidence interval estimate of s, you have 75 sample values and they \n appear to be from a population with a skewed distribution.\nd. In constructing a confidence interval estimate of s, you have 75 sample values and they \n appear to be from a population with a normal distribution.\ne. In constructing a confidence interval estimate of p, you have 1200 survey respondents and \n5% of them answered “yes” to the first question.\n6. Sample Size You have been assigned the task of conducting a survey to study prescription \nmedication purchases of adults.\na. If you want to estimate the percentage of adults who have purchased prescription medication \nduring the past 30 days, how many adults must you survey if you want 95% confidence that \nyour percentage has a margin of error of three percentage points?\ncontinued\n",
    "b. If you want to estimate the mean amount that adults have spent on prescription medications \nduring the past 30 days, how many adults must you survey if you want 95% confidence that your \nsample mean is in error by no more than $5? (Based on results from a pilot study, assume that \nthe standard deviation of amounts spent on prescription medications in the past 30 days is $39.)\nc. If you plan to obtain the estimates described in parts (a) and (b) with a single survey having \nseveral questions, how many adults must be surveyed?\n7. Aspirin Generic aspirin tablets are supposed to contain 325 mg of aspirin. Listed below are \nthe measured amounts of aspirin (mg) found in randomly selected tablets. Construct a 95% \nconfidence interval estimate of the mean amount of aspirin in tablets. Do these tablets appear \nto be acceptable?\n330 358 318 338 317 329 339 324 409 248 357 315\n8. Aspirin\na. Use the sample data from Exercise 7 and construct a 95% confidence interval estimate of s.\nb. Assume that we want almost all of the tablets to contain between 315 mg and 335 mg of aspi-\nrin. Find the range, then use the range rule of thumb to estimate the desired standard deviation.\nc. Based on the results from parts (a) and (b), what do you conclude?\n9. Bootstrap for Aspirin Repeat Exercise 7 using 1000 bootstrap samples. How does the re-\nsult compare to the confidence interval found in Exercise 7?\n10. CI for Proportion In a TE Connectivity survey of 1000 randomly selected adults, 2% said \nthat they “did not know” when asked if they felt comfortable being in a self-driving vehicle. \nThere is a need to construct a 95% confidence interval estimate of the proportion of all adults in \nthe population who don’t know.\na. Find the confidence interval using the normal distribution as an approximation to the \n binomial distribution.\nb. Find the confidence interval using 1000 bootstrap samples.\nc. Compare the results.\nCHAPTER 7 Cumulative Review Exercises \n333\nFeet. Listed below are lengths (cm) of feet of adult males. Use these values for Exercises 1–5.\n26.7 25.9 26.4 29.2 26.8 28.1 25.4 27.9 27.5 28.8\n1. Statistics Find the mean, median, standard deviation, and range. Are the results statistics or \nparameters?\n2. Range Rule of Thumb Use the results from Exercise 1 with the range rule of thumb to find \nthe limits separating those that are significantly low and those that are significantly high. Is a \nfoot length of 30 cm significantly high (or long)?\n3. Level of Measurement What is the level of measurement of the foot lengths (nominal, or-\ndinal, interval, ratio)? Are the original unrounded foot lengths continuous data or discrete data?\n4. Distribution Do the given data appear to be from a normally distributed population? Explain.\n5. Confidence Interval Construct a 95% confidence interval estimate of the mean foot length \nfor the population of all adult males.\n6. Sample Size Find the sample size necessary to estimate the mean foot length for the popu-\nlation of adult females. Assume that we want 95% confidence that the sample mean is in error \nby no more than 0.1 cm. Based on a prior study, assume that adult females have foot lengths \nwith a standard deviation of 1.12 cm.\nCumulative Review Exercises\n",
    "334 \nCHAPTER 7 Estimating Parameters and Determining Sample Sizes\n7. Foot Lengths Based on Data Set 7 “Foot and Height,” assume that women have foot lengths \nthat are normally distributed with a mean of 24.20 cm and a standard deviation of 1.12 cm.\na. Find the probability that a randomly selected woman has a foot length greater than 25.00 cm.\nb. Find the probability that 25 randomly selected women have foot lengths with a mean greater \nthan 25.00 cm.\nc. For the population of foot lengths of women, find the 95th percentile.\n8. Piercing, Tattoos, Infections Survey subjects were asked if they knew that body pierc-\nings and tattoos can transmit infectious disease. There were 1440 responses of “yes” and 48 \nresponses of “no” (based on data from “Body Piercing and Tattoos: A Survey on Young Adults’ \nKnowledge of the Risks and Practices in Body Art,” by Quaranta et al., BioMed Central Public \nHealth, published online). Find the 99% confidence interval estimate of the percentage of those \nwho know that body piercings and tattoos can transmit infectious disease. Does the population \nappear to be well informed about the risk of infectious disease?\nBody Temperatures Data Set 2 “Body Temperatures” in Appendix B includes body tempera-\ntures (°F) of a sample of healthy adults. Use technology for the following.\na. Find the mean and standard deviation of the body temperatures at 8 AM on day 2.\nb. Generate a histogram and normal quantile plot of the body temperatures at 8 AM on day \n2. Does it appear that the temperatures are from a population having a normal distribution? \nExplain.\nc. In obtaining a 95% confidence interval estimate of the body temperatures of all adults, are \nthe requirements for using a t distribution satisfied? Explain.\nd. Find a 95% confidence interval estimate of the mean body temperature of all adults.\ne. Find a 95% confidence interval estimate of the mean body temperature of all adults, using \n1000 bootstrap samples.\nf. What do you conclude about the common belief that the mean body temperature is 98.6°F?\nTechnology Project\nFROM DATA TO DECISION\nCritical Thinking: What does the survey tell us?\nSurveys have become an integral part of our lives. Because \nit is so important that every citizen has the ability to interpret \nsurvey results, surveys are the focus of this project.\nFour researchers conducted a survey of 717 subjects. Here \nare some findings (based on data from “Hemispheric Domi-\nnance and Cell Phone Use,” by Seidman et al., JAMA  \nOtolaryngology - Head Neck Surgery, Vol. 139, No. 5):\n•  The respondents include 642 right-handed subjects, 69 left-\nhanded subjects, and 6 ambidextrous subjects.\n•  Among the 642 right-handed subjects, 436 prefer to use \ntheir right ear for cell phone use, 166 prefer their left ear, \nand 40 have no preference.\n•  Among the 69 left-handed subjects, 16 prefer to use their \nright ear for cell phone use, 50 prefer their left ear, and 3 \nhave no preference.\nAnalyzing the Data\n1. Use the survey results to construct a 95% confidence inter-\nval estimate of the proportion of all right-handed people who \nprefer their right ear for cell phone use.\n2. Use the result from part (a) and identify the margin of error.\n3. A common criticism of surveys is that they poll only a very \nsmall percentage of the population and therefore cannot be \naccurate. Is a sample of only 717 people taken from a large \npopulation a sample size that is too small? Write a brief ex-\nplanation of why the sample size of 717 is or is not too small.\n4. Does it appear that most right-handed people prefer their \nright ear for cell phone use? Does it appear that most left-\nhanded people prefer their left ear for cell phone use?\n5. The survey was e-mailed to 5000 people and 717 surveys \nwere returned. What does the response rate suggest about the re-\nsults? What does the sampling method suggest about the results?\n",
    "1. Out-of-class activity Collect sample data, and use the methods of this chapter to construct \nconfidence interval estimates of population parameters. Here are some suggestions for parameters:\n• Proportion of students at your college who can raise one eyebrow without raising the other \neyebrow.\n• Mean pulse rate of male college students, or mean pulse rate of female college students.\n• Mean length of words in New York Times editorials and mean length of words in a profes-\nsional journal, such as Journal of the American Medical Association.\n• Proportion of students at your college who have consumed an alcoholic beverage within the \nlast seven days.\n• Mean number of hours that students at your college study each week.\n2. In-class activity Without using any measuring device, each student should draw a line \nbelieved to be 3 in. long and another line believed to be 3 cm long. Then use rulers to measure \nand record the lengths of the lines drawn. Find the means and standard deviations of the two \nsets of lengths. Use the sample data to construct a confidence interval for the length of the line \nestimated to be 3 in., and then do the same for the length of the line estimated to be 3 cm. Do \nthe confidence interval limits actually contain the correct length? Compare the results. Do the \nestimates of the 3-in. line appear to be more accurate than those for the 3-cm line?\n3. In-class activity Assume that a method of gender selection can affect the probability of a baby \nbeing a girl, so that the probability becomes 1>4. Each student should simulate 20 births by drawing \n20 cards from a shuffled deck. Replace each card after it has been drawn, then reshuffle. Consider \nthe hearts to be girls and consider all other cards to be boys. After making 20 selections and record-\ning the “genders” of the babies, construct a confidence interval estimate of the proportion of girls. \nDoes the result appear to be effective in identifying the true value of the population proportion? (If \ndecks of cards are not available, use some other way to simulate the births, such as using the random \nnumber generator on a calculator or using digits from phone numbers or Social Security numbers.)\n4. Out-of-class activity Groups of three or four students should go to the library and collect \na sample consisting of the ages of books (based on copyright dates). Plan and describe the \nsampling procedure, execute the sampling procedure, and then use the results to construct a \nconfidence interval estimate of the mean age of all books in the library.\n5. In-class activity Each student should estimate the length of the classroom. The values \nshould be based on visual estimates, with no actual measurements being taken. After the es-\ntimates have been collected, construct a confidence interval, then measure the length of the \nroom. Does the confidence interval contain the actual length of the classroom? Is there a “col-\nlective wisdom,” whereby the class mean is approximately equal to the actual room length?\n6. In-class activity Divide into groups of three or four. Examine a sample of different issues \nof a current magazine and find the proportion of pages that include advertising. Based on the \nresults, construct a 95% confidence interval estimate of the percentage of all such pages that \nhave advertising. Compare results with other groups.\n7. Out-of-class activity Identify a topic of general interest and coordinate with all members \nof the class to conduct a survey. Instead of conducting a “scientific” survey using sound prin-\nciples of random selection, use a convenience sample consisting of respondents who are read-\nily available, such as friends, relatives, and other students. Analyze and interpret the results. \nIdentify the population. Identify the shortcomings of using a convenience sample, and try to \nidentify how a sample of subjects randomly selected from the population might be different.\n8. Out-of-class activity Each student should find an article in a professional journal that in-\ncludes a confidence interval of the type discussed in this chapter. Write a brief report describing \nthe confidence interval and its role in the context of the article.\nCooperative Group Activities\nCHAPTER 7 Cooperative Group Activities \n335\n",
    "336\nBasics of Hypothesis \nTesting\nTesting a Claim About a \nProportion\nTesting a Claim About a \nMean\nTesting a Claim About \na Standard Deviation or \nVariance\n8-1\n8-2\n8-3\n8-4\nDoes the MicroSort Method of Gender Selection \nIncrease the Likelihood That a Baby Will Be a Girl?\nCHAPTER \nPROBLEM\nHypothesis Testing\nGender selection methods are somewhat controversial. Some \npeople believe that use of such methods should be prohib-\nited, regardless of the reason. Others believe that limited use \nshould be allowed for medical reasons, such as to prevent \ngender-specific hereditary disorders. For example, some cou-\nples carry X-linked recessive genes, so that a male child has a \n50% chance of inheriting a serious disorder and a female child \nhas no chance of inheriting the disorder. These couples may \nwant to use a gender selection method to increase the likeli-\nhood of having a baby girl so that none of their children inherit \nthe disorder.\nMethods of gender selection have been around for many \nyears. In the 1980s, ProCare Industries sold a product called \nGender Choice. It cost only $49.95, but the Food and Drug \n8 \n",
    "Administration told the company to stop distributing Gender \nChoice because there was no evidence to support the claim \nthat it was 80% reliable.\nThe Genetics & IVF Institute developed a newer gen-\nder selection method called MicroSort. Clinical trials for \nthis method were never completed and MicroSort was not \nbrought to market. The MicroSort XSORT method was de-\nsigned to increase the likelihood of a baby girl, and the \nYSORT method was designed to increase the likelihood of \na boy. The MicroSort website included this statement: “The \nGenetics & IVF Institute is offering couples the ability to in-\ncrease the chance of having a child of the desired gender \nto reduce the probability of X-linked diseases or for family \nbalancing.” For a cost exceeding $3000, the Genetics & IVF \nInstitute claimed that it could increase the probability of hav-\ning a baby of the gender that a couple prefers. In clinical tri-\nals, among 945 babies born to parents who used the XSORT \nmethod in trying to have a baby girl, 879 couples did have \nbaby girls, for a success rate of 93%. Under normal circum-\nstances with no special treatment, girls occur in about 50% \nof births. (Actually, the current birth rate of girls is 48.8%, but \nwe will use 50% to keep things simple.) These results provide \nus with an interesting question: Given that 879 out of 945 \ncouples had girls, can we actually support the claim that the \nXSORT technique is effective in increasing the probability of \na girl? When the Genetics & IVF Institute chose to discontinue \nthe clinical trials, does it appear that a major reason was inef-\nfectiveness of their methods?\nHere are the chapter objectives:\nBasics of Hypothesis Testing\n• Develop the ability to identify the null and alternative hypotheses when given some \nclaim about a population parameter (such as a proportion, mean, standard deviation, \nor variance).\n• Develop the ability to calculate a test statistic, find critical values, calculate P-values, \nand state a final conclusion that addresses the original claim. Here are the compo-\nnents that should be included in the hypothesis test:\n• Statements of the null and alternative hypotheses expressed in symbolic form\n• Value of the test statistic\n• Selection of the sampling distribution to be used for the hypothesis test\n• Identification of a P-value and>or critical value(s)\n• Statement of a conclusion rejecting the null hypothesis or failing to reject the \nnull hypothesis\n• Statement of a final conclusion that uses simple and nontechnical terms to \naddress the original claim\nTesting a Claim About a Proportion\n• Develop the ability to conduct a formal hypothesis test of a claim about a popula-\ntion proportion. The procedure should include the components listed above with the \n objectives for Section 8-1.\nTesting a Claim About a Mean\n• Develop the ability to use sample data to conduct a formal hypothesis test of a claim \nmade about a population mean. The procedure should include the same compo-\nnents listed above with the objectives for Section 8-1.\n8-1\n8-2\n8-3\nChapter Objectives \n337\nCHAPTER OBJECTIVES\n>>>\n",
    "338 \nCHAPTER 8 Hypothesis Testing\nKey Concept In this section we present key components of a formal hypothesis test. \nThe concepts in this section are general and apply to hypothesis tests involving pro-\nportions, means, or standard deviations or variances. In Part 1, we begin with the “big \npicture” to understand the basic underlying approach to hypothesis tests. Then we de-\nscribe null and alternative hypotheses, significance level, types of tests (two-tailed, \nleft-tailed, right-tailed), test statistic, P-value, critical values, and statements of conclu-\nsions. In Part 2 we describe types of errors (type I and type II). In Part 3 we describe \nthe power of a hypothesis test.\nPART 1\n Basic Concepts of Hypothesis Testing\nWe begin with two very basic definitions.\n8-1 \nBasics of Hypothesis Testing\nTesting a Claim About a Standard Deviation or Variance\n• Develop the ability to use sample data to conduct a formal hypothesis test of a claim \nmade about a population standard deviation or variance. The procedure should in-\nclude the same components listed with the objectives for Section 8-1.\n8-4\nTesting a Claim About a Standard Deviation or Variance\n• Develop the ability to use sample data to conduct a formal hypothesis test of a claim\nmade about a population standard deviation or variance. The procedure should in-\nclude the same components listed with the objectives for Section 8-1.\nDEFINITIONS\nIn statistics, a hypothesis is a claim or statement about a property of a population.\nA hypothesis test (or test of significance) is a procedure for testing a claim about \na property of a population.\nThe “property of a population” referred to in the preceding definitions is often the \nvalue of a population parameter, so here are some examples of typical hypotheses (or \nclaims):\n \n■m 6 98.6°F “The mean body temperature of humans is less than 98.6°F.”\n \n■p 7 0.5 “The proportion of girls born to parents using the XSORT method of \ngender selection is greater than 0.5.”\n \n■s = 15 “The population of nurses has IQ scores with a standard deviation equal \nto 15.”\nEXAMPLE 1  XSORT Method of Gender Selection\nConsider the claim from the Chapter Problem that “the XSORT technique is effec-\ntive in increasing the probability of a girl.” Using p to denote the proportion of girls \nborn to parents using the XSORT method of gender selection, the “effective” claim \nis equivalent to the claim that the proportion is significantly greater than half, or \np 7 0.5. The expression p 7 0.5 is the symbolic form of the original claim.\n",
    "8-1 Basics of Hypothesis Testing \n339\nThe Big Picture In Example 1, we have the claim that the proportion p is such that \np 7 0.5. Among 945 babies, how many do we need to get a significantly high number \nof girls?\n \n■A result of 473 girls (or 50.1%) could easily occur by chance under normal cir-\ncumstances with no treatment, so 473 is not significantly high.\n \n■The actual result of 879 girls (or 93.0%) appears to be significantly high.\nThe method of hypothesis testing gives us a standard and widely accepted procedure \nfor deciding whether such results are significant.\nUsing Technology It is easy to obtain hypothesis-testing results using technology. The \naccompanying screen displays show results from different technologies, so we can use \ncomputers or calculators to do all of the computational heavy lifting. Examining the \nscreen displays, we see some common elements. They all display a “test statistic” of \nz = 26.45 (rounded), and they all include a “P-value” of 0.0000 (rounded). These two \nresults are important, but understanding the hypothesis-testing procedure is critically \nimportant. Focus on understanding how the hypothesis-testing procedure works and \nlearn the associated terminology. Only then will results from technology make sense.\nStatdisk\nMinitab\nTI-83 , 84 Plus\nXLSTAT\nStatCrunch\nSignificance Hypothesis tests are also called tests of significance. In Section 4-1 we \nused probabilities to determine when sample results are significantly low or signifi-\ncantly high. This chapter formalizes those concepts in a unified procedure that is used \noften throughout many different fields of application. Figure 8-1 on the next page \nsummarizes the procedures used in two slightly different methods for conducting a \nformal hypothesis test. We will proceed to conduct a formal test of the claim from \nExample 1 that p 7 0.5. In testing that claim, we will use the sample data from the \nresults cited in the Chapter Problem, with x = 879 girls among n = 945 births.\nat \ner \nAspirin Not Helpful for \nGeminis and Libras\nPhysician \nRichard Peto \nsubmitted an ar-\nticle to Lancet, a \nBritish medical \njournal. The \narticle showed \nthat patients \nhad a better chance of surviving \na heart attack if they were treated \nwith aspirin within a few hours of \ntheir heart attacks. Lancet editors \nasked Peto to break down his \nresults into subgroups to see if \nrecovery worked better or worse \nfor different groups, such as \nmales or females. Peto believed \nthat he was being asked to use \ntoo many subgroups, but the edi-\ntors insisted. Peto then agreed, \nbut he supported his objections \nby showing that when his pa-\ntients were categorized by signs \nof the zodiac, aspirin was useless \nfor Gemini and Libra heart attack \npatients, but aspirin is a lifesaver \nfor those born under any other \nsign. This shows that when con-\nducting multiple hypothesis tests \nwith many different subgroups, \nthere is a very large chance of \ngetting some wrong results.\n",
    "340 \nCHAPTER 8 Hypothesis Testing\n8. Restate Decision in Nontechnical Terms\nConstruct a conﬁdence interval with a conﬁdence \nlevel selected as in Table 8-1.\nBecause a conﬁdence interval estimate of a population\nparameter contains the likely values of that parameter,\nreject a claim that the population parameter has a value\nthat is not included in the conﬁdence interval.\nTable 8-1\nSigniﬁcance \n0.01\nLevel for \n0.05\nHypothesis \n0.10\nTest\nTwo-Tailed Test\nOne-Tailed Test\n99%\n95%\n90%\n98%\n90%\n80%\nConﬁdence Level for Conﬁdence Interval\nConﬁdence Interval Method\nRestate this previous decision in simple nontechnical terms, and \naddress the original claim.\n5. Identify the Test Statistic\nIdentify the test statistic that is relevant to the test and determine its \nsampling distribution (such as normal, t, chi-square).\n4. Select Signiﬁcance Level\nSelect the signiﬁcance level A based on the seriousness of a type type I error. \nMake A small if the consequences of rejecting a true H0 are severe.\n \n• The values of 0.05 and 0.01 are very common.\n2. Give Symbolic Form\nGive the symbolic form that must be true when the original claim is false.\n1. Identify the Claim\nIdentify the claim to be tested and express it in symbolic form.\n3. Identify Null and Alternative Hypothesis\nConsider the two symbolic expressions obtained so far:\n \n• Alternative hypothesis H1 is the one NOT containing equality, so H1 uses \n \n the symbol . or , or Þ.\n \n• Null hypothesis H0 is the symbolic expression that the parameter equals\n \n the ﬁxed value being considered.\n7. Make a Decision\n• Reject H0 if P-value # a.\n• Fail to reject H0 if P-value . a.\n6. Find Values\nFind the value of the test statistic and the \nP-value (see Figure 8-3). Draw a graph and \nshow the test statistic and P-value.\n7. Make a Decision\n• Reject H0 if the test statistic is in the\ncritical region.\n• Fail to reject H0 if the test statistic is not in \nthe critical region.\n6. Find Values\nP-Value Method\nCritical Value Method\nFind the value of the test statistic and the \ncritical values. Draw a graph showing the test \nstatistic, critical value(s) and critical region.\nFIGURE 8-1  \nProcedure for \nHypothesis Tests\n",
    "8-1 Basics of Hypothesis Testing \n341\nSteps 1, 2, 3: Use the Original Claim to Create a Null \nHypothesis H0 and an Alternative Hypothesis H1\nThe objective of Steps 1, 2, 3 is to identify the null hypothesis and alternative \nhypothesis so that the formal hypothesis test includes these standard components that \nare often used in many different disciplines. The null hypothesis includes the working \nassumption for the purposes of conducting the test.\nDEFINITIONS\nThe null hypothesis (denoted by H0) is a statement that the value of a popula-\ntion parameter (such as proportion, mean, or standard deviation) is equal to some \nclaimed value.\nThe alternative hypothesis (denoted by H1 or Ha or HA) is a statement that the pa-\nrameter has a value that somehow differs from the null hypothesis. For the methods \nof this chapter, the symbolic form of the alternative hypothesis must use one of \nthese symbols: 6, 7, ≠.\nThe term null is used to indicate no change or no effect or no difference. We conduct \nthe hypothesis test by assuming that the parameter is equal to some specified value so \nthat we can work with a single distribution having a specific value.\nExample: Here is an example of a null hypothesis involving a proportion:\nH0: p = 0.5\nExample: Here are different examples of alternative hypotheses involving proportions:\nH1: p 7 0.5  H1: p 6 0.5  H1: p ≠0.5\nGiven the claim from Example 1 that the gender selection method is effective in \nincreasing the probability that a baby will be a girl, we can apply Steps 1, 2, and 3 in \nFigure 8-1 as follows.\nStep 1:  Identify the claim to be tested and express it in symbolic form. Using p to \ndenote the probability of selecting a girl, the claim that the gender selection is effec-\ntive can be expressed in symbolic form as p 7 0.5.\nStep 2:  Give the symbolic form that must be true when the original claim is false. If \nthe original claim of p 7 0.5 is false, then p … 0.5 must be true.\nStep 3:  This step is in two parts: Identify the alternative hypothesis H1 and identify \nthe null hypothesis H0.\n• Identify H1: Using the two symbolic expressions p 7 0.5 and p … 0.5, the alter-\nnative hypothesis H1 is the one that does not contain equality. Of those two ex-\npressions, p 7 0.5 does not contain equality, so we get\nH1: p 7 0.5\n• Identify H0: The null hypothesis H0 is the symbolic expression that the parameter \nequals the fixed value being considered, so we get\nH0: p = 0.5\nThe result of the first three steps is the identification of the null and alternative \nhypotheses:\nH0: p = 0.5 1null hypothesis2\nH1: p 7 0.5 1alternative hypothesis2\n",
    "342 \nCHAPTER 8 Hypothesis Testing\nNote About Forming Your Own Claims (Hypotheses): If you are conducting a study \nand want to use a hypothesis test to support your claim, your claim must be worded so \nthat it becomes the alternative hypothesis (and can be expressed using only the symbols \n6, 7, or ≠). You can never support a claim that a parameter is equal to a specified value.\nStep 4: Select the Significance Level A\nTABLE 8-2\nParameter\nSampling Distribution\nRequirements\nTest Statistic\nProportion p\nNormal (z)\nnp Ú 5 and nq Ú 5\nz = pn - p\nA\npq\nn\nMean m\nt\ns not known and normally \ndistributed population\nor\ns not known and n 7 30\nt =\nx - m\ns\n2n\nMean m\nNormal (z)\ns known and normally dis-\ntributed population\nor\ns known and n 7 30\nz =\nx - m\ns\n2n\nSt. dev. s or  \nvariance s2\nx2\nStrict requirement: normally \ndistributed population\nx2 =\n1n - 12s2\ns2\nStep 6: Find the Value of the Test Statistic, Then Find \nEither the P-Value or the Critical Value(s)\nDEFINITION\nThe test statistic is a value used in making a decision about the null hypothesis. It \nis found by converting the sample statistic (such as pn, x, or s) to a score (such as \nz, t, or x2) with the assumption that the null hypothesis is true.\nDEFINITION\nThe significance level A for a hypothesis test is the probability value used as the \ncutoff for determining when the sample evidence constitutes significant evidence \nagainst the null hypothesis. By its nature, the significance level a is the probability \nof mistakenly rejecting the null hypothesis when it is true:\nSignificance level A = P1rejecting H0 when H0 is true2\nThe significance level a is the same a introduced in Section 7-1, where we defined \n“critical value.” Common choices for a are 0.05, 0.01, and 0.10; 0.05 is the most com-\nmon choice.\nStep 5: Identify the Statistic Relevant to the Test and \nDetermine Its Sampling Distribution (such as normal, t,  \nor X2 )\nTable 8-2 lists parameters along with the corresponding sampling distributions.\nExample: The claim p 7 0.5 is a claim about the population proportion p, so use \nthe normal distribution provided that the requirements are satisfied. (With n = 945, \np = 0.5, and q = 0.5 from Example 1, np Ú 5 and nq Ú 5 are both true.)\n",
    "8-1 Basics of Hypothesis Testing \n343\nIn this chapter we use the test statistics listed in the last column of Table 8-2.\nExample: Preliminary results from the XSORT method of gender selection in-\nvolved 14 babies, with 13 of them being girls. Here we have n = 14 and x = 13, so \npn = x>n = 13>14 = 0.929. With the null hypothesis of H0: p = 0.5, we are working \nwith the assumption that p = 0.5, and it follows that q = 1 - p = 0.5. We can evalu-\nate the test statistic as shown below (or technology can find the test statistic for us).\nz = pn - p\nA\npq\nn\n=\n13\n14 - 0.5\nB\n10.5210.52\n14\n= 3.21\nFinding the P-value and>or critical value(s) requires that we first consider whether the \nhypothesis test is two-tailed, left-tailed, or right-tailed, which are described as follows.\nTwo-Tailed, Left-Tailed, Right-Tailed\nDEFINITION\nThe critical region (or rejection region) is the area corresponding to all values of \nthe test statistic that cause us to reject the null hypothesis.\nDepending on the claim being tested, the critical region could be in the two extreme \ntails, it could be in the left tail, or it could be in the right tail.\n \n■Two-tailed test: The critical region is in the two extreme regions (tails) under \nthe curve (as in the top graph in Figure 8-2).\n \n■Left-tailed test: The critical region is in the extreme left region (tail) under the \ncurve (as in the middle graph in Figure 8-2).\n \n■Right-tailed test: The critical region is in the extreme right region (tail) under \nthe curve (as in the bottom graph in Figure 8-2).\nSign used in H1: Þ\nTwo-tailed test\nSign used in H1: ,\nLeft-tailed test\nSign used in H1: .\nRight-tailed test\nFIGURE 8-2 Critical \nRegion in Two-Tailed, \nLeft-Tailed, and Right-\nTailed Tests\nHINT Look at the symbol used in the alternative hypothesis H1.\n• The symbol 7 points to the right and the test is right-tailed.\n• The symbol 6 points to the left and the test is left-tailed.\n• The symbol ≠is used for a two-tailed test.\nExample: With H0: p = 0.5 and H1: p 7 0.5, we reject the null hypothesis and \n support the alternative hypothesis only if the sample proportion is greater than 0.5 \nby a signiﬁcant amount, so the hypothesis test in this case is right-tailed.\nP-Value Method\nWith the P-value method of testing hypotheses, we make a decision by comparing \nthe P-value to the significance level.\nDEFINITION\nIn a hypothesis test, the P-value is the probability of getting a value of the test sta-\ntistic that is at least as extreme as the test statistic obtained from the sample data, \nassuming that the null hypothesis is true.\n",
    "344 \nCHAPTER 8 Hypothesis Testing\nTo find the P-value, first find the area beyond the test statistic, then use the procedure \ngiven in Figure 8-3. That procedure can be summarized as follows:\n \n■Critical region in left tail:  P-value = area to the left of the test statistic\n \n■Critical region in right tail: P-value = area to the right of the test statistic\n \n■Critical region in two tails: P-value = twice the area in the tail beyond the test \nstatistic\nP-value\nP-value is\ntwice this area.\nTest statistic\nTest statistic\nTest statistic\nTest statistic\nP-value is\ntwice this area.\nP-value\nIs the test\nstatistic to the\nright or left of\ncenter?\nLeft\nRight\nLeft-tailed\nRight-tailed\nP-value 5 twice the\narea to the left of\nthe test statistic\nP-value 5 area to\nthe left of the\ntest statistic\nP-value 5 twice the\narea to the right of\nthe test statistic\nP-value 5 area to\nthe right of the\ntest statistic\nWhat type\nof test?\nStart\nFIGURE 8-3 Finding P-Values\nExample: Using only the preliminary results of the XSORT method of gender selec-\ntion, we have 13 girls in 14 births and the test statistic is z = 3.21 and it has a normal \ndistribution area of 0.0007 to its right, so a right-tailed test with test statistic z = 3.21\nhas a P-value of 0.0007.\nCAUTION Don’t confuse a P-value with the parameter p or the statistic pn. Know the \nfollowing notation:\nP-value = probability of a test statistic at least as extreme as the one obtained\np = population proportion\npn = sample proportion\nP-Value and Hypothesis Testing Controversy\nThe standard method of testing hypotheses and the use of P-values have very wide-\nspread acceptance and use, but not everyone is convinced that these methods are \nT\ng\nJournal Bans P-Values!\nThe P-value \nmethod \nof testing \nhypotheses \nhas received \nwidespread \nacceptance in \nthe research community, but the \neditors of the journal Basic and \nApplied Social Psychology took a \ndramatic stance when they said \nthat they would no longer publish \narticles that included P-values. In \nan editorial, David Trafimow and \nMichael Marks stated their belief \nthat “the P-value bar is too easy \nto pass and sometimes serves \nas an excuse for lower quality \nresearch.” David Trafimow stated \nthat he did not know which \nstatistical method should replace \nthe use of P-values.\nMany reactions to the P-value \nban acknowledged that although \nP-values can be misused and \nmisinterpreted, their use as a \nvaluable research tool remains.\n",
    "8-1 Basics of Hypothesis Testing \n345\nsound. Editors of the Journal of Basic and Applied Social Psychology took a strong \nstand when they said that they would no longer publish articles that included P-values. \nThey said that P-values are an excuse for lower-quality research and the P-value cri-\nterion is too easy to pass. In the past, P-values have been misinterpreted and misused, \nso a serious and important statistical analysis should not rely solely on P-value results. \nInstead, it would be wise to consider other aspects, such as the following.\n \n■Sample Size: Very large samples could result in small P-values suggesting that \nresults are significant when the results don’t really make much of a practical dif-\nference.\n \n■Power: Part 3 of this section discusses the concept of power, and it is often help-\nful to analyze power as part of an analysis.\n \n■Other Factors: Instead of relying on just one outcome such as the P-value, it \nis generally better to also consider other results, such as a confidence interval, \nresults from simulations, practical significance, design of the study, quality of \nthe sample, consequences of type I and type II errors (discussed in Part 2 of this \n section), and replication of results.\nThis chapter presents the same methods of hypothesis testing and the same use of \nP-values that are currently being used, but again, it should be stressed that important \napplications should also consider other factors, such as those listed above.\nCritical Value Method\nWith the critical value method (or traditional method) of testing hypotheses, we \nmake a decision by comparing the test statistic to the critical value(s).\nDEFINITION\nIn a hypothesis test, the critical value(s) separates the critical region (where we \nreject the null hypothesis) from the values of the test statistic that do not lead to re-\njection of the null hypothesis.\nCritical values depend on the null hypothesis, the sampling distribution, and the sig-\nnificance level a.\nExample: The critical region in Figure 8-4 is shaded in green. Figure 8-4 shows that \nwith a significance level of a = 0.05, the critical value is z = 1.645.\np 5 0.5\nor\nz 5 0\nCritical Region:\nArea of a 5 0.05\nused to identify\nsigniﬁcantly high\nsample proportions\nCritical Value:\nz 5 1.645\nFIGURE 8-4 Critical Value and Critical Region\n",
    "346 \nCHAPTER 8 Hypothesis Testing\nStep 7: Make a Decision to Either Reject H0 or Fail  \nto Reject H0.\nDecision Criteria for the P-Value Method:\n \n■If P-value … a, reject H0. (“If the P is low, the null must go.”)\n \n■If P-value 7 a, fail to reject H0.\nExample: With significance level a = 0.05 and P-value = 0.0007, we have \nP-value … a, so reject H0. Remember, the P-value is the probability of getting a sample \nresult at least as extreme as the one obtained, so if the P-value is low (less than or \nequal to a), the sample statistic is significantly low or significantly high.\nDecision Criteria for the Critical Value Method:\n \n■If the test statistic is in the critical region, reject H0.\n \n■If the test statistic is not in the critical region, fail to reject H0.\nExample: With test statistic z = 3.21 and the critical region from z = 1.645 to infin-\nity, the test statistic falls within the critical region, so reject H0.\nStep 8: Restate the Decision Using Simple and  \nNontechnical Terms\nWithout using technical terms not understood by most people, state a final conclusion \nthat addresses the original claim with wording that can be understood by those with-\nout knowledge of statistical procedures.\nExample: There is sufficient evidence to support the claim that with the XSORT \nmethod of gender selection, the probability of getting a baby girl is greater than 0.5.\nWording the Final Conclusion For help in wording the final conclusion, refer to \nTable 8-3, which lists the four possible circumstances and their corresponding conclu-\nsions. Note that only the first case leads to wording indicating support for the original \nconclusion. If you want to support some claim, state it in such a way that it becomes \nthe alternative hypothesis, and then hope that the null hypothesis gets rejected.\nTABLE 8-3 Wording of the Final Conclusion\nCondition\nConclusion\nOriginal claim does not include equality,  \nand you reject H0.\n“There is sufficient evidence to support the claim \nthat . . . (original claim).”\nOriginal claim does not include equality,  \nand you fail to reject H0.\n“There is not sufficient evidence to support the \nclaim that . . . (original claim).”\nOriginal claim includes equality, and you  \nreject H0.\n“There is sufficient evidence to warrant rejection \nof the claim that . . . (original claim).”\nOriginal claim includes equality, and you fail  \nto reject H0.\n“There is not sufficient evidence to warrant rejec-\ntion of the claim that . . . (original claim).”\nAccept or Fail to Reject? We should say that we “fail to reject the null hypothesis” \ninstead of saying that we “accept the null hypothesis.” The term accept is misleading, \nbecause it implies incorrectly that the null hypothesis has been proved, but we can \nnever prove a null hypothesis. The phrase fail to reject says more correctly that the \navailable evidence isn’t strong enough to warrant rejection of the null hypothesis.\nMultiple Negatives Final conclusions can include as many as three negative terms. \n(Example: “There is not sufficient evidence to warrant rejection of the claim of no dif-\nference between 0.5 and the population proportion.”) For such confusing conclusions, \nS\nto\nLie Detectors  \nand the Law\nWhy not sim-\nply require all \ncriminal sus-\npects to take \npolygraph (lie \ndetector) tests \nand eliminate \ntrials by jury? According to the \nCouncil of Scientific Affairs of the \nAmerican Medical Association, \nwhen lie detectors are used to \ndetermine guilt, accuracy can \nrange from 75% to 97%. How-\never, a high accuracy rate of 97% \ncan still result in a high percent-\nage of false positives, so it is \npossible that 50% of innocent \nsubjects incorrectly appear to \nbe guilty. Such a high chance of \nfalse positives rules out the use \nof polygraph tests as the single \ncriterion for determining guilt.\n",
    "8-1 Basics of Hypothesis Testing \n347\nit is better to restate them to be understandable. Instead of saying that “there is not \nsufficient evidence to warrant rejection of the claim of no difference between 0.5 and \nthe population proportion,” a better statement would be this: “Until stronger evidence \nis obtained, continue to assume that the population proportion is equal to 0.5.”\nCAUTION Never conclude a hypothesis test with a statement of “reject the \nnull hypothesis” or “fail to reject the null hypothesis.” Always make sense of the \nconclusion with a statement that uses simple nontechnical wording that addresses \nthe original claim.\nConfidence Intervals for Hypothesis Tests\nIn this section we have described the individual components used in a hypothesis test, \nbut the following sections will combine those components in comprehensive proce-\ndures. We can test claims about population parameters by using the P-value method \nor the critical value method summarized in Figure 8-1, or we can use confidence \nintervals.\nA confidence interval estimate of a population parameter contains the likely val-\nues of that parameter. If a confidence interval does not include a claimed value of a \npopulation parameter, reject that claim. For two-tailed hypothesis tests, construct a \nconfidence interval with a confidence level of 1 - a, but for a one-tailed hypothesis \ntest with significance level a, construct a confidence interval with a confidence level \nof 1 - 2a. (See Table 8-1 on page 340 for common cases.) For a left-tailed test or a \nright-tailed test, we could also use a one-sided confidence interval; see Exercise 38 in \nSection 7-1. After constructing the confidence interval, use this criterion:\nA conﬁdence interval estimate of a population parameter contains the \nlikely values of that parameter. We should therefore reject a claim that the \npopulation parameter has a value that is not included in the  conﬁdence \ninterval.\nEquivalent Methods\nIn some cases, a conclusion based on a confidence interval may be different from a \nconclusion based on a hypothesis test. The P-value method and critical value method \nare equivalent in the sense that they always lead to the same conclusion. The following \ntable shows that for the methods included in this chapter, a confidence interval estimate \nof a proportion might lead to a conclusion different from that of a hypothesis test.\n \n \nParameter\nIs a confidence interval equivalent to a hypothesis \ntest in the sense that they always lead to the same \nconclusion?\nProportion\nNo\nMean\nYes\nStandard Deviation or Variance\nYes\nPART 2\n Type I and Type II Errors \nWhen testing a null hypothesis, we arrive at a conclusion of rejecting it or failing \nto reject it. Our conclusions are sometimes correct and sometimes wrong (even \nif we apply all procedures correctly). Table 8-4 includes two different types of \n",
    "348 \nCHAPTER 8 Hypothesis Testing\nerrors and we distinguish between them by calling them type I and type II errors, \nas  described here:\n \n■Type I error: The mistake of rejecting the null hypothesis when it is actually \ntrue. The symbol a (alpha) is used to represent the probability of a type I error.\nA = P1type I error2 = P1rejecting H0 when H0 is true2\n \n■Type II error: The mistake of failing to reject the null hypothesis when it is actu-\nally false. The symbol b (beta) is used to represent the probability of a type II error.\nB = P1type II error2 = P1failing to reject H0 when H0 is false2\nMemory Hint for Type I and Type II Errors Remember “routine for fun,” and use \nthe consonants from those words (RouTiNe FoR FuN) to remember that a type I er-\nror is RTN: Reject True Null (hypothesis), and a type II error is FRFN: Fail to Reject a \nFalse Null (hypothesis).\nHint for Describing Type I and Type II Errors Descriptions of a type I error and \na type II error refer to the null hypothesis being true or false, but when wording a \nstatement representing a type I error or a type II error, be sure that the conclusion \naddresses the original claim (which may or may not be the null hypothesis). See \nExample 2.\nTABLE 8-4 Type I and Type II Errors\nTrue State of Nature\nNull hypothesis is true\nNull hypothesis is false\nPreliminary \nConclusion\nReject H0\nType I error:\nReject a true H0.\nP (type I error) = a\nCorrect decision\nFail to reject H0\nCorrect decision\nType II error:\nFail to reject a false H0.\nP(type II error) = b\nEXAMPLE 2  Describing Type I and Type II Errors\nConsider the claim that the XSORT gender selection method is effective in increas-\ning the likelihood of a baby girl, so that the probability of a baby girl is p 7 0.5. \nGiven the following null and alternative hypotheses, write statements describing  \n(a) a type I error, and (b) a type II error.\nH0: p = 0.5\nH1: p 7 0.5 1original claim that will be addressed in the final conclusion2\nSOLUTION\n \na. Type I Error: A type I error is the mistake of rejecting a true null hypothesis, \nso the following is a type I error: In reality p = 0.5, but sample evidence \nleads us to conclude that p 7 0.5.\n \n •  In this case, a type I error is to conclude that the XSORT gender selection \nmethod is eﬀective when in reality it has no eﬀect.\n",
    "8-1 Basics of Hypothesis Testing \n349\nControlling Type I and Type II Errors Step 4 in our standard procedure for test-\ning hypotheses is to select a significance level a (such as 0.05), which is the prob-\nability of a type I error. The values of a, b, and the sample size n are all related, so if \nyou choose any two of them, the third is automatically determined (although b can’t \nbe determined until an alternative value of the population parameter has been speci-\nfied along with a and n). One common practice is to select the significance level a,\nthen select a sample size that is practical, so the value of b is determined. Generally, \ntry to use the largest a that you can tolerate, but for type I errors with more serious \nconsequences, select smaller values of a. Then choose a sample size n as large as is \nreasonable, based on considerations of time, cost, and other relevant factors. Another \ncommon practice is to select a and b so the required sample size n is automatically \ndetermined. (See Example 4 in Part 3 of this section.)\nPART 3\n Power of a Hypothesis Test \nWe use b to denote the probability of failing to reject a false null hypothesis, so \nP(type II error) = b. It follows that 1 - b is the probability of rejecting a false null \nhypothesis, so 1 - b is a probability that is one measure of the effectiveness of a \n hypothesis test.\n \nb. Type II Error: A type II error is the mistake of failing to reject the null hy-\npothesis when it is false, so the following is a type II error: In reality p 7 0.5, \nbut we fail to support that conclusion.\n \n •  In this case, a type II error is to conclude that the XSORT gender selection \nmethod has no eﬀect, when it really is eﬀective in increasing the likelihood \nof a baby girl.\nDEFINITION\nThe power of a hypothesis test is the probability 1 - b of rejecting a false null \nhypothesis. The value of the power is computed by using a particular significance \nlevel a and a particular value of the population parameter that is an alternative to \nthe value assumed true in the null hypothesis.\nBecause determination of power requires a particular value that is an alternative to the \nvalue assumed in the null hypothesis, a hypothesis test can have many different values \nof power, depending on the particular values of the population parameter chosen as \nalternatives to the null hypothesis.\nEXAMPLE 3  Power of a Hypothesis Test\nConsider these preliminary results from the XSORT method of gender selection: \nThere were 13 girls among the 14 babies born to couples using the XSORT method. \nIf we want to test the claim that girls are more likely 1p 7 0.52 with the XSORT \nmethod, we have the following null and alternative hypotheses:\nH0: p = 0.5  H1: p 7 0.5\nLet’s use a significance level of a = 0.05. In addition to all given test components, \nfinding power requires that we select a particular value of p that is an alternative to \ncontinued\n",
    "350 \nCHAPTER 8 Hypothesis Testing\nBecause the calculations of power are quite complicated, the use of technology is \nstrongly recommended. (In this section, only Exercises 33–35 involve power.)\nPower and the Design of Experiments\nJust as 0.05 is a common choice for a significance level, a power of at least 0.80 is a \ncommon requirement for determining that a hypothesis test is effective. (Some statisti-\ncians argue that the power should be higher, such as 0.85 or 0.90.) When designing an \nexperiment, we might consider how much of a difference between the claimed value of a \nparameter and its true value is an important amount of difference. If testing the effective-\nness of the XSORT gender selection method, a change in the proportion of girls from \n0.5 to 0.501 is not very important, whereas a change in the proportion of girls from 0.5 \nto 0.9 would be very important. Such magnitudes of differences affect power. When de-\nsigning an experiment, a goal of having a power value of at least 0.80 can often be used \nto determine the minimum required sample size, as in the following example.\nthe value assumed in the null hypothesis H0: p = 0.5. Find the values of power cor-\nresponding to these alternative values of p: 0.6, 0.7, 0.8, and 0.9.\nSOLUTION\nThe values of power in the following table were found by using Minitab, and exact \ncalculations are used instead of a normal approximation to the binomial distribution.\nSpecific Alternative Value of p\nb\nPower of Test = 1 −b\n0.6\n0.820\n0.180\n0.7\n0.564\n0.436\n0.8\n0.227\n0.773\n0.9\n0.012\n0.988\nINTERPRETATION\nOn the basis of the power values listed above, we see that this hypothesis test has a \npower of 0.180 (or 18.0%) of rejecting H0: p = 0.5 when the population proportion \np is actually 0.6. That is, if the true population proportion is actually equal to 0.6, \nthere is an 18.0% chance of making the correct conclusion of rejecting the false null \nhypothesis that p = 0.5. That low power of 18.0% is not so good.\nThere is a 0.436 probability of rejecting p = 0.5 when the true value of p is \nactually 0.7. It makes sense that this test is more effective in rejecting the claim \nof p = 0.5 when the population proportion is actually 0.7 than when the popula-\ntion proportion is actually 0.6. (When identifying animals assumed to be horses, \nthere’s a better chance of rejecting an elephant as a horse—because of the greater \ndifference—than rejecting a mule as a horse.) In general, increasing the difference \nbetween the assumed parameter value and the actual parameter value results in an \nincrease in power, as shown in the table above.\nEXAMPLE 4   Finding the Sample Size Required to  \nAchieve 80% Power\nHere is a statement similar to one in an article from the Journal of the American \nMedical Association: “The trial design assumed that with a 0.05 significance level, \n153 randomly selected subjects would be needed to achieve 80% power to detect \n",
    "8-1 Basics of Hypothesis Testing \n351\na reduction in the coronary heart disease rate from 0.5 to 0.4.” From that statement \nwe know the following:\n \n■Before conducting the experiment, the researchers selected a significance level \nof 0.05 and a power of at least 0.80.\n \n■The researchers decided that a reduction in the proportion of coronary heart \ndisease from 0.5 to 0.4 is an important and clinically significant difference that \nthey wanted to detect (by correctly rejecting the false null hypothesis).\n \n■Using a significance level of 0.05, power of 0.80, and the alternative proportion \nof 0.4, technology such as Minitab is used to find that the required minimum \nsample size is 153.\nThe researchers can then proceed by obtaining a sample of at least 153 randomly \nselected subjects. Because of factors such as dropout rates, the researchers are likely \nto need somewhat more than 153 subjects. (See Exercise 35.)\nStatistical Literacy and Critical Thinking \n1. Vitamin C and Aspirin A bottle contains a label stating that it contains Spring Valley pills \nwith 500 mg of vitamin C, and another bottle contains a label stating that it contains Bayer pills \nwith 325 mg of aspirin. When testing claims about the mean contents of the pills, which would \nhave more serious implications: rejection of the Spring Valley vitamin C claim or rejection of \nthe Bayer aspirin claim? Is it wise to use the same significance level for hypothesis tests about \nthe mean amount of vitamin C and the mean amount of aspirin?\n2. Estimates and Hypothesis Tests Data Set 2 “Body Temperatures” in Appendix B in-\ncludes sample body temperatures. We could use methods of Chapter 7 for making an estimate, \nor we could use those values to test the common belief that the mean body temperature is \n98.6°F. What is the difference between estimating and hypothesis testing?\n3. Mean Height of Men A formal hypothesis test is to be conducted using the claim that the \nmean height of men is equal to 174.1 cm.\na. What is the null hypothesis, and how is it denoted?\nb. What is the alternative hypothesis, and how is it denoted?\nc. What are the possible conclusions that can be made about the null hypothesis?\nd. Is it possible to conclude that “there is sufficient evidence to support the claim that the mean \nheight of men is equal to 174.1 cm”?\n4. Interpreting P-value The Ericsson method is one of several methods claimed to increase \nthe likelihood of a baby girl. In a clinical trial, results could be analyzed with a formal hypoth-\nesis test with the alternative hypothesis of p 7 0.5, which corresponds to the claim that the \nmethod increases the likelihood of having a girl, so that the proportion of girls is greater than \n0.5. If you have an interest in establishing the success of the method, which of the following \nP-values would you prefer: 0.999, 0.5, 0.95, 0.05, 0.01, 0.001? Why?\nIdentifying H0 and H1. In Exercises 5–8, do the following:\na. Express the original claim in symbolic form.\nb. Identify the null and alternative hypotheses.\n5. Hypertension Claim: Most adults do not have hypertension. When 983 randomly selected \nadults were tested, it was found that 70.9% of them do not have hypertension.\n8-1 Basic Skills and Concepts\n",
    "352 \nCHAPTER 8 Hypothesis Testing\n6. Cell Phones Claim: Fewer than 95% of nurses have a cell phone. In a survey of 1128 \nnurses, 87% said that they have a cell phone.\n7. Pulse Rates Claim: The mean pulse rate (in beats per minute, or bpm) of adult males is \nequal to 69 bpm. For the random sample of 153 adult males in Data Set 1 “Body Data” from \nAppendix B, the mean pulse rate is 69.6 bpm and the standard deviation is 11.3 bpm.\n8. Pulse Rates Claim: The standard deviation of pulse rates of adult males is more than 11 \nbpm. For the random sample of 153 adult males in Data Set 1 “Body Data” from Appendix B, \nthe pulse rates have a standard deviation of 11.3 bpm.\nConclusions. In Exercises 9–12, refer to the exercise identified. Make subjective esti-\nmates to decide whether results are significantly low or significantly high, then state a con-\nclusion about the original claim. For example, if the claim is that a coin favors heads and \nsample results consist of 11 heads in 20 flips, conclude that there is not sufficient evidence \nto support the claim that the coin favors heads (because it is easy to get 11 heads in 20 flips \nby chance with a fair coin).\n9. Exercise 5 “Hypertension” \n10. Exercise 6 “Cell Phone”\n11. Exercise 7 “Pulse Rates” \n12. Exercise 8 “Pulse Rates”\nTest Statistics. In Exercises 13–16, refer to the exercise identified and find the value of the \ntest statistic. (Refer to Table 8-2 on page 342 to select the correct expression for evaluating the \ntest statistic.)\n13. Exercise 5 “Hypertension” \n14. Exercise 6 “Cell Phone”\n15. Exercise 7 “Pulse Rates” \n16. Exercise 8 “Pulse Rates”\nP-Values. In Exercises 17–20, do the following:\na. Identify the hypothesis test as being two-tailed, left-tailed, or right-tailed.\nb. Find the P-value. (See Figure 8-3 on page 344.)\nc. Using a significance level of a = 0.05, should we reject H0 or should we fail to reject H0?\n17. The test statistic of z = 1.00 is obtained when testing the claim that p 7 0.3.\n18. The test statistic of z = -2.50 is obtained when testing the claim that p 6 0.75.\n19. The test statistic of z = 2.01 is obtained when testing the claim that p ≠0.345.\n20. The test statistic of z = -1.94 is obtained when testing the claim that p = 3>8.\nCritical Values. In Exercises 21–24, refer to the information in the given exercise and do \nthe following.\na. Find the critical value(s).\nb. Using a significance level of a = 0.05, should we reject H0 or should we fail to reject H0?\n21. Exercise 17 \n22. Exercise 18\n23. Exercise 19 \n24. Exercise 20\nFinal Conclusions. In Exercises 25–28, use a significance level of A = 0.05 and use the \ngiven information for the following:\na. State a conclusion about the null hypothesis. (Reject H0 or fail to reject H0.)\nb. Without using technical terms or symbols, state a final conclusion that addresses the original \nclaim.\n 25. Original claim: More than 70% of adults do not have hypertension. The hypothesis test \nresults in a P-value of 0.2678.\n",
    "8-1 Basics of Hypothesis Testing \n353\n 26. Original claim: Fewer than 90% of nurses have a cell phone. The hypothesis test results in \na P-value of 0.0003.\n27. Original claim: The mean pulse rate (in beats per minute) of adult males is 72 bpm. The \nhypothesis test results in a P-value of 0.0095.\n28. Original claim: The standard deviation of pulse rates of adult males is more than 11 bpm. \nThe hypothesis test results in a P-value of 0.3045.\nType I and Type II Errors. In Exercises 29–32, provide statements that identify the type I \nerror and the type II error that correspond to the given claim. (Although conclusions are \nusually expressed in verbal form, the answers here can be expressed with statements that \ninclude symbolic expressions such as p = 0.1.)\n29. The proportion of people who write with their left hand is equal to 0.1.\n30. The proportion of people with blue eyes is equal to 0.35.\n31. The proportion of adults who use the Internet is greater than 0.87.\n32. The proportion of people who require no vision correction is less than 0.25.\n33. Interpreting Power Chantix (varenicline) tablets are used as an aid to help people stop \nsmoking. In a clinical trial, 129 subjects were treated with Chantix twice a day for 12 weeks, \nand 16 subjects experienced abdominal pain (based on data from Pfizer, Inc.). If someone \nclaims that more than 8% of Chantix users experience abdominal pain, that claim is supported \nwith a hypothesis test conducted with a 0.05 significance level. Using 0.18 as an alternative \nvalue of p, the power of the test is 0.96. Interpret this value of the power of the test.\n34. Calculating Power Consider a hypothesis test of the claim that the Ericsson method of \ngender selection is effective in increasing the likelihood of having a baby girl, so that the claim \nis p 7 0.5. Assume that a significance level of a = 0.05 is used, and the sample is a simple \nrandom sample of size n = 64.\na. Assuming that the true population proportion is 0.65, find the power of the test, which is \nthe probability of rejecting the null hypothesis when it is false. (Hint: With a 0.05 significance \nlevel, the critical value is z = 1.645, so any test statistic in the right tail of the accompanying \ntop graph is in the rejection region where the claim is supported. Find the sample proportion pn\nin the top graph, and use it to find the power shown in the bottom graph.)\nb\nz 5 1.645\na 5 0.05\np 5 0.5\np 5 0.65\nPower\nb. Explain why the green-shaded region of the bottom graph represents the power of the test.\n35. Finding Sample Size to Achieve Power Researchers plan to conduct a test of a gender \nselection method. They plan to use the alternative hypothesis of H1: p 7 0.5 and a significance \nlevel of a = 0.05. Find the sample size required to achieve at least 80% power in detecting an \nincrease in p from 0.50 to 0.55. (This is a very difficult exercise. Hint: See Exercise 34.)\n8-1 Beyond the Basics\n",
    "354 \nCHAPTER 8 Hypothesis Testing\nKey Concept This section describes a complete procedure for testing a claim made \nabout a population proportion p. We illustrate hypothesis testing with the P-value \nmethod, the critical value method, and the use of confidence intervals. The methods of \nthis section can be used with claims about population proportions, probabilities, or the \ndecimal equivalents of percentages.\nThere are different methods for testing a claim about a population proportion. \nPart 1 of this section is based on the use of a normal approximation to a binomial \ndistribution, and this method serves well as an introduction to basic concepts, but it \nis not a method used by professional statisticians. Part 2 discusses other methods that \nmight require the use of technology.\nPART 1\n Normal Approximation Method\nThe following box includes the key elements used for testing a claim about a population \nproportion by using a normal distribution as an approximation to a binomial distribution.\n8-2 \nTesting a Claim About a Proportion\nTesting a Claim About a Population Proportion (Normal Approximation Method)\nObjective\nConduct a formal hypothesis test of a claim about a population proportion p.\nNotation\nKEY ELEMENTS \nn = sample size or number of trials\npn = x\nn (sample proportion)\np =  population proportion (p is the value used in the \nstatement of the null hypothesis)\nq = 1 - p\nRequirements\n1. The sample observations are a simple random sample.\n2. The conditions for a binomial distribution are satisfied:\n • There is a fixed number of trials.\n • The trials are independent.\n • Each trial has two categories of “success” and “failure.”\n • The probability of a success remains the same in all \ntrials.\n3. The conditions np Ú 5 and nq Ú 5 are both satisfied, \nso the binomial distribution of sample proportions \ncan be approximated by a normal distribution with \nm = np and s = 1npq (as described in Section 6-6). \nNote that p used here is the assumed proportion used in \nthe claim, not the sample proportion pn.\nTest Statistic for Testing a Claim About a Proportion\nz = pn - p\nA\npq\nn\nP-Values: P-values are automatically provided by technol-\nogy. If technology is not available, use the standard normal \ndistribution (Table A-2) and refer to Figure 8-1 on page 340.\nCritical Values: Use the standard normal distribution \n(Table A-2).\nThe test statistic does not include a correction for continuity (as described in Section 6-6), \nbecause its effect tends to be very small with large samples.\n",
    "8-2 Testing a Claim About a Proportion \n355\nEquivalent Methods\nWhen testing claims about proportions, the confidence interval method is not equiv-\nalent to the P-value and critical value methods, so the confidence interval method \ncould result in a different conclusion. (Both the P-value method and the critical value \nmethod use the same standard deviation based on the claimed proportion p, so they \nare equivalent to each other, but the confidence interval method uses an estimated \nstandard deviation based on the sample proportion.) Recommendation: Use a confi-\ndence interval to estimate a population proportion, but use the P-value method or criti-\ncal value method for testing a claim about a proportion. See Exercise 30.\nClaim: The XSORT Method of Gender Selection  \nIs Effective\nLet’s use the preliminary results from tests of the XSORT method of gender selection. \nThose preliminary results consisted of 14 babies born to couples using the XSORT \nmethod of gender selection, and 13 of the babies were girls. Use these results to test \nthe claim that most babies born to couples using the XSORT method are girls. We \ninterpret “most” to mean “more than half” or “greater than 0.5.”\nREQUIREMENT CHECK We first check the three requirements.\n1. The 14 babies are not randomly selected, but based on the design of the clinical \ntrial, they can be treated as being random.\n2. There is a fixed number (14) of independent trials with two categories (the baby \nis a girl or is not).\n3. The requirements np Ú 5 and nq Ú 5 are both satisfied with n = 14, \np = 0.5, and q = 0.5. [The value of p = 0.5 comes from the claim. We \nget np = 114210.52 = 7, which is greater than or equal to 5, and we get \nnq = 114210.52 = 7, which is also greater than or equal to 5.]\nThe three requirements are satisfied. \nSolution: P-Value Method\nTechnology Computer programs and calculators usually provide a P-value, so the \nP-value method is used. Different technologies will display the test statistic of \nz = 3.21 and the P-value of 0.0007.\nTable A-2 If technology is not available, Figure 8-1 on page 340 in the preceding sec-\ntion lists the steps for using the P-value method. Using those steps from Figure 8-1, \nwe can test the claim that “most babies born to couples using the XSORT method are \ngirls” as follows.\nStep 1: The original claim is that the XSORT method is effective in increasing the like-\nlihood of a baby girl, and that claim can be expressed in symbolic form as p 7 0.5.\nStep 2: The opposite of the original claim is p … 0.5.\nStep 3: Of the preceding two symbolic expressions, the expression p 7 0.5 does not \ncontain equality, so it becomes the alternative hypothesis. The null hypothesis is the state-\nment that p equals the fixed value of 0.5. We can therefore express H0 and H1 as follows:\nH0: p = 0.5\nH1: p 7 0.5 1original claim2\nv-\nd \nue \ny\nd \nProcess of Drug \nApproval\nGaining Food \nand Drug \nAdministration \n(FDA) approval \nfor a new drug \nis expensive \nand time- \nconsuming. \nHere are the different stages of \ngetting approval for a new drug:\n• Phase I study: The safety of \nthe drug is tested with a small \n(20–100) group of volunteers.\n• Phase II: The drug is tested for \neffectiveness in randomized tri-\nals involving a larger (100–300) \ngroup of subjects. This phase \noften has subjects randomly \nassigned to either a treatment \ngroup or a placebo group.\n• Phase III: The goal is to better \nunderstand the effective-\nness of the drug as well as its \nadverse reactions. This phase \ntypically involves 1,000–3,000 \nsubjects, and it might require \nseveral years of testing.\nLisa Gibbs wrote in Money \nmagazine that “the (drug) indus-\ntry points out that for every 5,000 \ntreatments tested, only 5 make it \nto clinical trials and only 1 ends \nup in drugstores.” Total cost \nestimates vary from a low of  \n$40 million to as much as  \n$1.5 billion.\ncontinued\n",
    "356 \nCHAPTER 8 Hypothesis Testing\nStep 4: For the significance level, we select a = 0.05, which is a very common \nchoice.\nStep 5: Because we are testing a claim about a population proportion p, the sample sta-\ntistic pn is relevant to this test. The sampling distribution of sample proportions pn can be \napproximated by a normal distribution in this case (as described in Section 6-3).\nStep 6: The test statistic z = 3.21 can be found by using technology, or it can be \ncalculated by using pn = 13>14 (sample proportion), n = 14 (sample size), p = 0.5 \n(assumed in the null hypothesis), and q = 1 - 0.5 = 0.5.\nz = pn - p\nA\npq\nn\n=\n13\n14 - 0.5\nB\n10.5210.52\n14\n= 3.21\nThe P-value can be found from technology, or it can be found by using the fol-\nlowing procedure, which is shown in Figure 8-3 on page 344:\nLeft-tailed test: \nP-value = area to left of test statistic z\nRight-tailed test: \nP-value = area to right of test statistic z\nTwo-tailed test: \nP-value =  twice the area of the extreme region bounded by \nthe test statistic z\nBecause this hypothesis test is right-tailed with a test statistic of z = 3.21, the \nP-value is the area to the right of z = 3.21. Referring to Table A-2, we see that the \ncumulative area to the left of z = 3.21 is 0.9993, so the area to the right of that test \nstatistic is 1 - 0.9993 = 0.0007. We get P-value = 0.0007. Figure 8-5 shows the \ntest statistic and P-value for this example.\nStep 7: Because the P-value of 0.0007 is less than or equal to the significance level \nof a = 0.05, we reject the null hypothesis.\nStep 8: Because we reject H0: p = 0.5, we support the alternative hypothesis of \np 7 0.5. We conclude that there is sufficient sample evidence to support the claim \nthat the XSORT method is effective in increasing the likelihood of a baby girl. (See \nTable 8-3 on page 346 for help with wording this final conclusion.)\np 5 0.5\nor\nz 5 0\nP-value 5 0.0007\np 5     5 0.929\nor\nz 5 3.21\nˆ\n13\n14\nFIGURE 8-5 P-Value Method\np 5 0.5\nor\nz 5 0\nCritical Region:\nArea of a 5 0.05\nused to identify\nsigniﬁcantly high\nsample proportions\nCritical Value:\nz 5 1.645\nFIGURE 8-6 Critical Value Method\n",
    "8-2 Testing a Claim About a Proportion \n357\nSolution: Critical Value Method\nThe critical value method of testing hypotheses is summarized in Figure 8-1 on \npage 340 in Section 8-1. When using the critical value method with the claim that \n“most babies born to couples using the XSORT method are girls,” Steps 1 through \n5 are the same as Steps 1 through 5 for the P-value method, as shown. We continue \nwith Step 6 of the critical value method.\nStep 6: The test statistic is computed to be z = 3.21, as shown for the preceding \nP-value method. With the critical value method, we now find the critical values (in-\nstead of the P-value). This is a right-tailed test, so the area of the critical region is an \narea of a = 0.05 in the right tail. Referring to Table A-2 and applying the methods \nof Section 6-1, we find that the critical value is z = 1.645, which is at the boundary \nof the critical region, as shown in Figure 8-6.\nStep 7: Because the test statistic does fall within the critical region, we reject the null \nhypothesis.\nStep 8: Because we reject H0: p = 0.5, we conclude that there is sufficient sample \nevidence to support the claim that for couples using the XSORT gender selection \nmethod, most (more than half) of their babies are girls.\nSolution: Confidence Interval Method\nThe claim that “with the XSORT method of gender selection, most babies are girls” is \na claim that can be tested with a 0.05 significance level by constructing a 90% confi-\ndence interval. (See Table 8-1 on page 340 to see why the 0.05 significance level cor-\nresponds to a 90% confidence interval.)\nThe 90% confidence interval estimate of the population proportion p is found \nusing the sample data consisting of n = 14 and pn = 13>14. Using the methods of \n Section 7-1 we get: 0.815 6 p 6 1.042. The entire range of values in this confidence \ninterval is greater than 0.5. Because we are 90% confident that the limits of 0.815 and \n1.042 contain the true value of p, the sample data appear to support the claim that \nmost (more than 0.5) XSORT babies are girls. In this case, the conclusion is the same \nas with the P-value method and the critical value method, but that is not always the \ncase. It is possible that a conclusion based on the confidence interval can be different \nfrom the conclusion based on the P-value method or critical value method.\nFinding the Number of Successes x\nWhen using technology for hypothesis tests of proportions, we must usually enter \nthe sample size n and the number of successes x, but in real applications the sample \nproportion pn is often given instead of x. The number of successes x can be found by \nevaluating x = npn, as illustrated in Example 1. Note that in Example 1, the result of \n5587.712 adults must be rounded to the nearest whole number of 5588.\nCAUTION: Don’t confuse the following notation.\n•  P-value = probability of getting a test statistic at least as extreme as the one repre-\nsenting the sample data, assuming that the null hypothesis H0 is true\n• p = population proportion\n• pn = sample proportion\n-\nIs 0.05 a Bad Choice?\nThe value of \n0.05 is a very \ncommon choice \nfor serving as \nthe cutoff sepa-\nrating results \nconsidered to \nbe significant from those that are \nnot. Science writer John Timmer \nwrote in Ars Technica that some \nproblems with conclusions in \nscience are attributable to the \nfact that statistics is sometimes \nweak because of the common \nuse of 0.05 for a significance \nlevel. He gives examples of \nparticle physics and genetics \nexperiments in which P-values \nmust be much lower than 0.05. \nHe cites a study by statistician \nValen Johnson, who suggested \nthat we should raise standards \nby requiring that experiments use \na P-value of 0.005 or lower. We \ndo know that the choice of 0.05 \nis largely arbitrary, and lowering \nthe significance level will result \nin fewer conclusions of signifi-\ncance, along with fewer wrong \nconclusions.\n",
    "358 \nCHAPTER 8 Hypothesis Testing\nEXAMPLE 1  Finding the Number of Successes x\nA study of sleepwalking or “nocturnal wandering” was described in the journal \nNeurology, and it included information that 29.2% of 19,136 American adults have \nsleepwalked. What is the actual number of adults who have sleepwalked?\nSOLUTION\nThe number of adults who have sleepwalked is 29.2% of 19,136, or 0.292 * 19,136\n= 5587.712, but the result must be a whole number, so we round the product to the \nnearest whole number of 5588.\nCAUTION When conducting hypothesis tests of claims about proportions, slightly \ndifferent results can be obtained when calculating the test statistic using a given \nsample proportion instead of using a rounded value of x found by using x = npn.\nEXAMPLE 2  Fewer Than 30% of Adults Have Sleepwalked\nUsing the same sleepwalking data from Example 1 (n = 19,136 and pn = 29.2%),  \nwould a reporter be justified in stating that “fewer than 30% of adults have sleep-\nwalked”? Let’s use a 0.05 significance level to test the claim that for the adult popu-\nlation, the proportion of those who have sleepwalked is less than 0.30.\nSOLUTION\nREQUIREMENT CHECK (1) The sample is a simple random sample. (2) There is a \nfixed number (19,136) of independent trials with two categories (a subject has \nsleepwalked or has not). (3) The requirements np Ú 5 and nq Ú 5 are both satisfied \nwith n = 19,136 and p = 0.30. [We get np = 119,136210.302 = 5740.8, which \nis greater than or equal to 5, and we also get nq = 119,136210.702 = 13,395.2, \nwhich is greater than or equal to 5.] The three requirements are all satisfied. \nStep 1: The original claim is expressed in symbolic form as p 6 0.30.\nStep 2: The opposite of the original claim is p Ú 0.30.\nStep 3: Because p 6 0.30 does not contain equality, it becomes H1. We get\nH0: p = 0.30 1null hypothesis2\nH1: p 6 0.30 1alternative hypothesis and original claim2\nStep 4: The significance level is a = 0.05.\nStep 5: Because the claim involves the proportion p, the statistic relevant to this test \nis the sample proportion pn and the sampling distribution of sample proportions can \nbe approximated by the normal distribution.\nStep 6: Technology If using technology, the test statistic and the P-value will be \nprovided. See the following results from StatCrunch showing that the test statistic is \nz = -2.41 (rounded) and the P-value = 0.008.\n",
    "8-2 Testing a Claim About a Proportion \n359\nCritical Value Method If we were to repeat Example 2 using the critical value method of \ntesting hypotheses, we would see that in Step 6 the critical value is z = -1.645, which \ncan be found from technology or Table A-2. In Step 7 we would reject the null hypothesis \nbecause the test statistic of z = -2.41 would fall within the critical region bounded by \nz = -1.645. We would then reach the same conclusion given in Example 2.\nConfidence Interval Method If we were to repeat Example 2 using the confidence \ninterval method, we would use a 90% confidence level because we have a left-tailed \ntest. (See Table 8-1.) We get this 90% confidence interval: 0.287 6 p 6 0.297. Be-\ncause the entire range of the confidence interval falls below 0.30, there is sufficient \nevidence to support the claim that fewer than 30% of adults have sleepwalked.\nPART 2\nExact Methods for Testing Claims About a \nPopulation Proportion p\nInstead of using the normal distribution as an approximation to the binomial distribu-\ntion, we can get exact results by using the binomial probability distribution itself. Bi-\nnomial probabilities are a real nuisance to calculate manually, but technology makes \nTable A-2 If technology is not available, proceed as follows to conduct the  \nhypothesis test using the P-value method summarized in Figure 8-1 on page 340.\nThe test statistic z = -2.41 is calculated as follows:\nz = pn - p\nA\npq\nn\n=\n5588\n19,136 - 0.30\nB\n10.30210.702\n19,136\n= -2.41\nRefer to Figure 8-3 on page 344 for the procedure for finding the P-value.  \nFigure 8-3 shows that for this left-tailed test, the P-value is the area to the left of \nthe test statistic. Using Table A-2, we see that the area to the left of z = -2.41 is \n0.0080, so the P-value is 0.0080.\nStep 7: Because the P-value of 0.0080 is less than or equal to the significance level \nof 0.05, we reject the null hypothesis.\nINTERPRETATION\nBecause we reject the null hypothesis, we support the alternative hypothesis. We \ntherefore conclude that there is sufficient evidence to support the claim that fewer \nthan 30% of adults have sleepwalked.\nStatCrunch\nLefties Die Sooner?\nA study by \npsychologists \nDiane Halpern \nand Stanley \nCoren received \nconsiderable \nmedia atten-\ntion and generated considerable \ninterest when it concluded that \nleft-handed people don’t live as \nlong as right-handed people. \nBased on their study, it appeared \nthat left-handed people live an \naverage of nine years less than \nrighties. The Halpern>Coren \nstudy has been criticized for \nusing flawed data. They used \nsecond-hand data by surveying \nrelatives about people who had \nrecently died. The myth of lefties \ndying younger became folklore \nthat has survived many years. \nHowever, more recent studies \nshow that left-handed people do \nnot have shorter lives than those \nwho are right-handed.\n",
    "360 \nCHAPTER 8 Hypothesis Testing\nthis approach quite simple. Also, this exact approach does not require that np Ú 5 and \nnq Ú 5, so we have a method that applies when that requirement is not satisfied. To \ntest hypotheses using the exact method, find P-values as follows:\nExact Method Identify the sample size n, the number of successes x, and the claimed \nvalue of the population proportion p (used in the null hypothesis); then find the P-value \nby using technology for finding binomial probabilities as follows:\nLeft-tailed test:   P-value = P1x or fewer successes among n trials2\nRight-tailed test:   P-value = P1x or more successes among n trials2\nTwo-tailed test:   P-value =  twice the smaller of the preceding left-tailed and \nright-tailed values\nNote: There is no universally accepted method for the above two-tailed exact case, \nso this case can be treated with other different approaches, some of which are quite \ncomplex. For example, Minitab uses a “likelihood ratio test” that is different from the \nabove approach that is commonly used.\nEXAMPLE 3  Using the Exact Method\nIn testing a method of gender selection, 10 randomly selected couples are treated \nwith the method, they each have a baby, and 9 of the babies are girls. Use a 0.05 \nsignificance level to test the claim that with this method, the probability of a baby \nbeing a girl is greater than 0.75.\nSOLUTION\nREQUIREMENT CHECK The normal approximation method described in Part 1 of \nthis section requires that np Ú 5 and nq Ú 5, but nq = (10)(0.25) = 2.5, so the \nrequirement is violated. The exact method has only the requirements of being a \nsimple random sample and satisfying the conditions for binomial distribution, and \nthose two requirements are satisfied. \nHere are the null and alternative hypotheses:\nH0: p = 0.75 1null hypothesis2\nH1: p 7 0.75 1alternative hypothesis and original claim2\nInstead of using the normal distribution, we use technology to find probabilities in a \nbinomial distribution with p = 0.75. Because this is a right-tailed test, the P-value \nis the probability of 9 or more successes among 10 trials, assuming that p = 0.75. \nSee the following Statdisk display of exact probabilities from the binomial distri-\nbution. This Statdisk display shows that the probability of 9 or more successes is \n0.2440252 when rounded to seven decimal places, so the P-value is 0.2440252. The \nP-value is high (greater than 0.05), so we fail to reject the null hypothesis. There is \nnot sufficient evidence to support the claim that with the gender selection method, \nthe probability of a girl is greater than 0.75.\n",
    "8-2 Testing a Claim About a Proportion \n361\nImproving the Exact Method A criticism of the exact method is that it is too conser-\nvative in the sense that the actual probability of a type I error is typically less than or \nequal to a, and it could be much lower than a.\nWith the exact method, the actual probability of a type I error is less than \nor equal to A, which is the desired probability of a type I error.\nA simple continuity correction improves the conservative behavior of the exact \nmethod with an adjustment to the P-value that is obtained by subtracting from it the \nvalue that is one-half the binomial probability at the boundary, as shown below. (See \nExercise 33.) This method is easy to apply if technology is available for finding bino-\nmial probabilities.\nSimple Continuity Correction to the Exact Method\nLeft-tailed test: \nP-value = P1x or fewer2 - 1\n2P1exactly x2\nRight-tailed test: \nP-value = P1x or more2 - 1\n2P1exactly x2\nTwo-tailed test: \n P-value =  twice the smaller of the preceding left-tailed \nand right-tailed values\nThe above “simple continuity correction” is described in “Modifying the Exact Test for a \nBinomial Proportion and Comparisons with Other Approaches,” by Alan Huston, Jour-\nnal of Applied Statistics, Vol. 33, No. 7. For another improvement that uses weighted tail \nareas based on a measure of skewness, see the preceding article by Alan Huston.\nStatdisk\nHypothesis Test: Proportion\nAccess tech instructions, videos, and data sets at www.TriolaStats.com\nTECH CENTER \n",
    "362 \nCHAPTER 8 Hypothesis Testing\nStatistical Literacy and Critical Thinking\nIn Exercises 1–4, use these results from a USA Today survey in which 510 people chose to \nrespond to this question that was posted on the USA Today website: “Should Americans \nreplace passwords with biometric security (fingerprints, etc)?” Among the respondents, 53% \nsaid yes. We want to test the claim that more than half of the population believes that pass-\nwords should be replaced with biometric security.\n1. Number and Proportion\na. Identify the actual number of respondents who answered yes.\nb. Identify the sample proportion and the symbol used to represent it.\n2. Null and Alternative Hypotheses Identify the null hypothesis and alternative hypothesis.\n3. Equivalence of Methods If we use the same significance level to conduct the hypoth-\nesis test using the P-value method, the critical value method, and a confidence interval, which \nmethod is not equivalent to the other two?\n4. Requirements and Conclusions\na. Are any of the three requirements violated? Can the methods of this section be used to test \nthe claim?\nb. It was stated that we can easily remember how to interpret P-values with this: “If the P is \nlow, the null must go.” What does this mean?\nc. Another memory trick commonly used is this: “If the P is high, the null will fly.” Given that \na hypothesis test never results in a conclusion of proving or supporting a null hypothesis, how \nis this memory trick misleading?\nd. Common significance levels are 0.01 and 0.05. Why would it be unwise to use a significance \nlevel with a number like 0.0483?\nUsing Technology. In Exercises 5–8, identify the indicated values or interpret the given \ndisplay. Use the normal distribution as an approximation to the binomial distribution as \n described in Part 1 of this section. Use a 0.05 significance level and answer the following:\na. Is the test two-tailed, left-tailed, or right-tailed?\nb. What is the test statistic?\nc. What is the P-value?\nd. What is the null hypothesis, and what do you conclude about it?\ne. What is the final conclusion?\n5. Adverse Reactions to Drug The drug Lipitor (atorvastatin) is used to treat high choles-\nterol. In a clinical trial of Lipitor, 47 of 863 treated subjects experienced headaches (based on \ndata from Pfizer). The accompanying TI-83>84 Plus calculator display shows results from a \ntest of the claim that fewer than 10% of treated subjects experience headaches.\n8-2 Basic Skills and Concepts\nTI-83 , 84 Plus\n",
    "8-2 Testing a Claim About a Proportion \n363\n6. Self-Driving Vehicles In a TE Connectivity survey of 1000 adults, 29% said that they \nwould feel comfortable in a self-driving vehicle. The accompanying StatCrunch display results \nfrom testing the claim that more than 1>4 of adults feel comfortable in a self-driving vehicle.\nStatCrunch\n7. Hygiene A KRC Research poll of 1020 randomly selected adults showed that 65% of them \nwash their hands after touching an animal. The following Minitab display results from a test of \nthe claim that 67% of adults wash their hands after touching an animal.\nMinitab\n8. Biometric Security In a USA Today survey of 510 people, 53% said that we should replace \npasswords with biometric security, such as fingerprints. The accompanying Statdisk display \nresults from a test of the claim that half of us say that we should replace passwords with bio-\nmetric security.\nTesting Claims About Proportions. In Exercises 9–28, test the given claim. Identify the \nnull hypothesis, alternative hypothesis, test statistic, P-value, or critical value(s), then state \nthe conclusion about the null hypothesis, as well as the final conclusion that addresses the \noriginal claim. Use the P-value method unless your instructor specifies otherwise. Use the \nnormal distribution as an approximation to the binomial distribution, as described in Part 1 \nof this section.\n9. Gender Selection The Genetics & IVF Institute conducted a clinical trial of the YSORT \nmethod designed to increase the probability of conceiving a boy. 291 babies were born to parents \nusing the YSORT method, and 239 of them were boys. Use a 0.01 significance level to test the \nclaim that the YSORT method is effective in increasing the likelihood that a baby will be a boy.\n10. Eliquis The drug Eliquis (apixaban) is used to help prevent blood clots in certain patients. \nIn clinical trials, among 5924 patients treated with Eliquis, 153 developed the adverse reaction \nof nausea (based on data from Bristol-Myers Squibb Co.). Use a 0.05 significance level to test \nthe claim that 3% of Eliquis users develop nausea. Does nausea appear to be a problematic \nadverse reaction?\n11. Stem Cell Survey Adults were randomly selected for a Newsweek poll. They were asked \nif they “favor or oppose using federal tax dollars to fund medical research using stem cells \nobtained from human embryos.” Of those polled, 481 were in favor, 401 were opposed, and \n120 were unsure. A politician claims that people don’t really understand the stem cell issue and \ntheir responses to such questions are random responses equivalent to a coin toss. Exclude the \n120 subjects who said that they were unsure, and use a 0.01 significance level to test the claim \nthat the proportion of subjects who respond in favor is equal to 0.5. What does the result sug-\ngest about the politician’s claim?\n12. Clinical Trial of Tamiflu Clinical trials involved treating flu patients with Tamiflu (osel-\ntamivir phosphate), which is a medicine intended to attack the influenza virus and stop it from \ncausing flu symptoms. Among 724 patients treated with Tamiflu, 72 experienced nausea as an \nadverse reaction. Use a 0.05 significance level to test the claim that the rate of nausea is greater \nthan the 6% rate experienced by flu patients given a placebo. Does nausea appear to be a con-\ncern for those given the Tamiflu treatment?\nStatdisk\n",
    "364 \nCHAPTER 8 Hypothesis Testing\n13. OxyContin The drug OxyContin (oxycodone) is used to treat pain, but it is dangerous \nbecause it is addictive and can be lethal. In clinical trials, 227 subjects were treated with \n OxyContin and 52 of them developed nausea (based on data from Purdue Pharma L.P.). Use a \n0.05 significance level to test the claim that more than 20% of OxyContin users develop nau-\nsea. Does the rate of nausea appear to be too high?\n14. Medical Malpractice In a study of 1228 randomly selected medical malpractice lawsuits, \nit was found that 856 of them were dropped or dismissed (based on data from the Physicians \nInsurers Association of America). Use a 0.01 significance level to test the claim that most medi-\ncal malpractice lawsuits are dropped or dismissed. Should this be comforting to physicians?\n15. Survey Return Rate In a study of cell phone use and brain hemispheric dominance, an \nInternet survey was e-mailed to 5000 subjects randomly selected from an online group involved \nwith ears. 717 surveys were returned. Use a 0.01 significance level to test the claim that the \nreturn rate is less than 15%.\n16. Drug Screening The company Drug Test Success provides a “1-Panel-THC” test for mar-\nijuana usage. Among 300 tested subjects, results from 27 subjects were wrong (either a false \npositive or a false negative). Use a 0.05 significance level to test the claim that less than 10% of \nthe test results are wrong. Does the test appear to be good for most purposes?\n17. Births A random sample of 860 births in New York State included 426 boys. Use a 0.05 \nsignificance level to test the claim that 51.2% of newborn babies are boys. Do the results sup-\nport the belief that 51.2% of newborn babies are boys?\n18. Mendelian Genetics When Mendel conducted his famous genetics experiments with \npeas, one sample of offspring consisted of 428 green peas and 152 yellow peas. Use a 0.01 \nsignificance level to test Mendel’s claim that under the same circumstances, 25% of offspring \npeas will be yellow. What can we conclude about Mendel’s claim?\n19. Predicting Gender of Baby A study addressed the issue of whether pregnant women can \ncorrectly guess the gender of their baby. Among 104 recruited subjects, 55% correctly guessed \nthe gender of the baby (based on data from “Are Women Carrying ‘Basketballs’ Really Having \nBoys? Testing Pregnancy Folklore,” by Perry, DiPietro, and Constigan, Birth, Vol. 26, No. 3). \nUse these sample data to test the claim that the success rate of such guesses is no different from \nthe 50% success rate expected with random chance guesses. Use a 0.05 significance level.\n20. Predicting Gender of Baby In the same study cited in the preceding exercise, 45 of the \npregnant women had more than 12 years of education, and 32 of them made correct predic-\ntions. Use these results to test the claim that women with more than 12 years of education have \na proportion of correct predictions that is greater than the 0.5 proportion expected with random \nguesses. Use a 0.01 significance level. Do these women appear to have an ability to correctly \npredict the gender of their babies?\n21. Touch Therapy When she was 9 years of age, Emily Rosa did a science fair experiment \nin which she tested professional touch therapists to see if they could sense her energy field. She \nflipped a coin to select either her right hand or her left hand, and then she asked the therapists \nto identify the selected hand by placing their hand just under Emily’s hand without seeing it \nand without touching it. Among 280 trials, the touch therapists were correct 123 times (based \non data in “A Close Look at Therapeutic Touch,” Journal of the American Medical Associa-\ntion, Vol. 279, No. 13). Use a 0.10 significance level to test the claim that touch therapists use a \nmethod equivalent to random guesses. Do the results suggest that touch therapists are effective?\n22. Touch Therapy Repeat the preceding exercise using a 0.01 significance level. Does the \nconclusion change?\n23. Cell Phones and Cancer In a study of 420,095 Danish cell phone users, 135 subjects de-\nveloped cancer of the brain or nervous system (based on data from the Journal of the National \nCancer Institute as reported in USA Today). Test the claim of a somewhat common belief that \nsuch cancers are affected by cell phone use. That is, test the claim that cell phone users develop \ncancer of the brain or nervous system at a rate that is different from the rate of 0.0340% for \n",
    "8-2 Testing a Claim About a Proportion \n365\npeople who do not use cell phones. Because this issue has such great importance, use a 0.005 \nsignificance level. Based on these results, should cell phone users be concerned about cancer of \nthe brain or nervous system?\n24. Lie Detectors Trials in an experiment with a polygraph yield 98 results that include 24 cases \nof wrong results and 74 cases of correct results (based on data from experiments conducted by \nresearchers Charles R. Honts of Boise State University and Gordon H. Barland of the Depart-\nment of Defense Polygraph Institute). Use a 0.05 significance level to test the claim that such \npolygraph results are correct less than 80% of the time. Based on the results, should polygraph \ntest results be prohibited as evidence in trials?\n25. Testing Effectiveness of Nicotine Patches In one study of smokers who tried to quit \nsmoking with nicotine patch therapy, 39 were smoking one year after the treatment and 32 \nwere not smoking one year after the treatment (based on data from “High-Dose Nicotine Patch \nTherapy,” by Dale et al., Journal of the American Medical Association, Vol. 274, No. 17). Use a \n0.05 significance level to test the claim that among smokers who try to quit with nicotine patch \ntherapy, the majority are smoking a year after the treatment. What do these results suggest \nabout the effectiveness of nicotine patch therapy for those trying to quit smoking?\n26. Postponing Death An interesting and popular hypothesis is that individuals can tem-\nporarily postpone death to survive a major holiday or important event such as a birthday. In \na study, it was found that there were 6062 deaths in the week before Thanksgiving, and 5938 \ndeaths the week after Thanksgiving (based on data from “Holidays, Birthdays, and Postpone-\nment of Cancer Death,” by Young and Hade, Journal of the American Medical Association, \nVol. 292, No. 24). If people can postpone death until after Thanksgiving, then the proportion \nof deaths in the week before should be less than 0.5. Use a 0.05 significance level to test the \nclaim that the proportion of deaths in the week before Thanksgiving is less than 0.5. Based on \nthe result, does there appear to be any indication that people can temporarily postpone death to \nsurvive the Thanksgiving holiday?\n27. Smoking Stopped In a program designed to help patients stop smoking, 198 patients \nwere given sustained care, and 82.8% of them were no longer smoking after one month (based \non data from “Sustained Care Intervention and Postdischarge Smoking Cessation Among \n Hospitalized Adults,” by Rigotti et al., Journal of the American Medical Association, Vol. 312, \nNo. 7). Use a 0.01 significance level to test the claim that 80% of patients stop smoking when \ngiven sustained care. Does sustained care appear to be effective?\n28. Medication Usage In a survey of 3005 adults aged 57 through 85 years, it was found that \n81.7% of them used at least one prescription medication (based on data from “Use of Prescrip-\ntion and Over-the-Counter Medications and Dietary Supplements Among Older Adults in the \nUnited States,” by Qato et al., Journal of the American Medical Association, Vol. 300, No. 24). \nUse a 0.01 significance level to test the claim that more than 3>4 of adults use at least one pre-\nscription medication. Does the rate of prescription use among adults appear to be high?\n29. Exact Method For each of the three different methods of hypothesis testing (identified in \nthe column at the left), enter the P-values corresponding to the given alternative hypothesis and \nsample data. Comment on the results.\nH1: p 3 0.5  \nn = 10, x = 9\nH1: p 3 0.4 \nn = 10, x = 9\nH1: p + 0.5 \nn = 1009, x = 545\nNormal approximation\nExact\nExact with simple  \ncontinuity correction\n8-2 Beyond the Basics\n",
    "366 \nCHAPTER 8 Hypothesis Testing\n30. Using Confidence Intervals to Test Hypotheses When analyzing the last digits of tele-\nphone numbers of hospital patients, it is found that among 1000 randomly selected digits, 119 \nare zeros. If the digits are randomly selected, the proportion of zeros should be 0.1.\na. Use the critical value method with a 0.05 significance level to test the claim that the propor-\ntion of zeros equals 0.1.\nb. Use the P-value method with a 0.05 significance level to test the claim that the proportion of \nzeros equals 0.1.\nc. Use the sample data to construct a 95% confidence interval estimate of the proportion of \nzeros. What does the confidence interval suggest about the claim that the proportion of zeros \nequals 0.1?\nd. Compare the results from the critical value method, the P-value method, and the confidence \ninterval method. Do they all lead to the same conclusion?\n31. Power For a hypothesis test with a specified significance level a, the probability of a type I \nerror is a, whereas the probability b of a type II error depends on the particular value of p that \nis used as an alternative to the null hypothesis.\na. Using an alternative hypothesis of p 6 0.4, using a sample size of n = 50, and assuming \nthat the true value of p is 0.25, find the power of the test. See Exercise 34 “Calculating Power” \nin Section 8-1. [Hint: Use the values p = 0.25 and pq>n = 10.25210.752>50.4\nb. Find the value of b, the probability of making a type II error.\nc. Given the conditions cited in part (a), find the power of the test. What does the power tell us \nabout the effectiveness of the test?\nKey Concept Testing a claim about a population mean is one of the most important \nmethods presented in this book. This section deals with the very realistic and com-\nmonly used case in which the population standard deviation s is not known.\nIn reality, it is very rare that we test a claim about an unknown value of a popula-\ntion mean m but we somehow know the value of the population standard deviation s. \nThe realistic situation is that we test a claim about a population mean and the value of \nthe population standard deviation s is not known. When s is not known, we estimate \nit with the sample standard deviation s. From the central limit theorem (Section 6-4), \nwe know that the distribution of sample means x is approximately a normal distribu-\ntion with mean mx = m and standard deviation sx = s> 1n, but if s is unknown, we \nestimate s> 1n with s> 1n, which is used in the test statistic for a “t test.” This test \nstatistic has a distribution called the Student t distribution. The requirements, test \nstatistic, P-value, and critical values are summarized in the Key Elements box that \nfollows.\nEquivalent Methods\nFor the t test described in this section, the P-value method, the critical value method, \nand the confidence interval method are all equivalent in the sense that they all lead to \nthe same conclusions.\n8-3 \nTesting a Claim About a Mean\n",
    "8-3 Testing a Claim About a Mean \n367\nRequirement of Normality or n + 30 This t test is robust against a departure \nfrom normality, meaning that the test works reasonably well if the departure from \nnormality is not too extreme. Verify that there are no outliers and that the histogram or \ndotplot has a shape that is not very far from a normal distribution.\nIf the original population is not itself normally distributed, we use the condition \nn 7 30 for justifying use of the normal distribution, but there is no exact specific \nminimum sample size that works for all cases. Sample sizes of 15 to 30 are sufficient \nif the population has a distribution that is not far from normal, but some populations \nhave distributions that are extremely far from normal, and sample sizes greater than \n30 might be necessary. In this text we use the simplified criterion of n 7 30 as justi-\nfication for treating the distribution of sample means as a normal distribution, regard-\nless of how far the distribution departs from a normal distribution.\nImportant Properties of the Student t Distribution\nHere is a brief review of important properties of the Student t distribution first pre-\nsented in Section 7-2:\n1. The Student t distribution is different for different sample sizes (see Figure 7-4 \nin Section 7-2).\n2. The Student t distribution has the same general bell shape as the standard nor-\nmal distribution; its wider shape reflects the greater variability that is expected \nwhen s is used to estimate s.\nTesting Claims About a Population Mean with s Not Known\nObjective\nUse a formal hypothesis test to test a claim about a population mean m.\nNotation\nKEY ELEMENTS \nn = sample size \nx = sample mean\ns = sample standard deviation \nmx =  population mean (this value is taken from the claim and is used in the \nstatement of the null hypothesis H0)\nRequirements\n1. The sample is a simple random sample.\n2. Either or both of these conditions are satisfied: The \npopulation is normally distributed or n 7 30.\nTest Statistic for Testing a Claim About a Mean\nt = x - mx\ns\n2n\n \n1Round t to three decimal places, as in Table A@3.2\nP-Values: Use technology or use the Student t distri-\nbution (Table A-3) with degrees of freedom given by \ndf = n - 1. (Figure 8-3 in Section 8-1 on page 344 sum-\nmarizes the procedure for finding P-values.)\nCritical Values: Use the Student t distribution (Table A-3) \nwith degrees of freedom given by df = n - 1. (When \n Table A-3 doesn’t include the number of degrees of free-\ndom, you could be conservative by using the next lower \nnumber of degrees of freedom found in the table, you \ncould use the closest number of degrees of freedom in the \ntable, or you could interpolate.)\ncontinued\n",
    "368 \nCHAPTER 8 Hypothesis Testing\n3. The Student t distribution has a mean of t = 0 (just as the standard normal dis-\ntribution has a mean of z = 0).\n4. The standard deviation of the Student t distribution varies with the sample size \nand is greater than 1 (unlike the standard normal distribution, which has s = 1).\n5. As the sample size n gets larger, the Student t distribution gets closer to the \nstandard normal distribution.\nP-Value Method with Technology\nIf suitable technology is available, the P-value method of testing hypotheses is the \nway to go.\nEXAMPLE 1  Adult Sleep: P-Value Method with Technology\nThe authors obtained times of sleep for randomly selected adult subjects in-\ncluded in the National Health and Nutrition Examination Study, and those times \n(hours) are listed below. Here are the unrounded statistics for this sample: n = 12, \nx = 6.83333333 hours, s = 1.99240984 hours. A common recommendation is \nthat adults should sleep between 7 hours and 9 hours each night. Use the P-value \nmethod with a 0.05 significance level to test the claim that the mean amount of \nsleep for adults is less than 7 hours.\n4 8 4 4 8 6 9 7 7 10 7 8\nSOLUTION\nREQUIREMENT CHECK (1) The sample is a simple random sample. (2) The second \nrequirement is that “the population is normally distributed or n 7 30.” The sample \nsize is n = 12, which does not exceed 30, so we must determine whether the sample \ndata appear to be from a normally distributed population. The accompanying histo-\ngram and normal quantile plot, along with the apparent absence of outliers, indicate \nthat the sample appears to be from a population with a distribution that is approxi-\nmately normal. Both requirements are satisfied. \nStatdisk\nHere are the steps that follow the procedure summarized in Figure 8-1 on page 340.\nStep 1: The claim that “the mean amount of adult sleep is less than 7 hours” be-\ncomes m 6 7 hours when expressed in symbolic form.\nStep 2: The alternative (in symbolic form) to the original claim is m Ú 7 hours.\nStep 3: Because the statement m 6 7 hours does not contain the condition of equal-\nity, it becomes the alternative hypothesis H1. The null hypothesis H0 is the state-\nment that m = 7 hours.\n“How Statistics Can Help \nSave Failing Hearts”\nA New York \nTimes ar-\nticle by David \nLeonhardt \nfeatured the \nheadline \nof “How \nStatistics Can Help Save Failing \nHearts.” Leonhardt writes that \npatients have the best chance of \nrecovery if their clogged arteries \nare opened within two hours \nof a heart attack. In 2005, the \nU.S. Department of Health and \nHuman Services began posting \nhospital data on its website  \nwww.hospitalcompare.hhs.gov, \nand it included the percentage \nof heart attack patients who re-\nceived treatment for blocked ar-\nteries within two hours of arrival \nat the hospital. Not wanting to be \nembarrassed by poor data, doc-\ntors and hospitals are reducing \nthe time it takes to unblock those \nclogged arteries. Leonhardt \nwrites about the University of \nCalifornia, San Francisco Medical \nCenter, which cut its time in half \nfrom almost three hours to about \n90 minutes. Effective use of \nsimple statistics can save lives.\n",
    "8-3 Testing a Claim About a Mean \n369\nH0: m = 7 hours 1null hypothesis2\nH1: m 6 7 hours 1alternative hypothesis and original claim2\nStep 4: As specified in the statement of the problem, the significance level is \na = 0.05.\nStep 5: Because the claim is made about the population mean m, the sample statistic \nmost relevant to this test is the sample mean x, and we use the t distribution.\nStep 6: The sample statistics of n = 12, x = 6.83333333 hours, s = 1.99240984 \nhours are used to calculate the test statistic as follows, but technologies provide the \ntest statistic of t = -0.290. In calculations such as the following, it is good to carry \nextra decimal places and not round.\nt = x - mx\ns\n2n\n= 6.83333333 - 7\n1.99240984\n212\n= -0.290\nP-Value with Technology We could use technology to obtain the P-value. Shown \nhere are results from several technologies, and we can see that the P-value is 0.3887 \n(rounded). (SPSS shows a two-tailed P-value of 0.777, so it must be halved for this \none-tailed test.)\nStep 7: Because the P-value of 0.3887 is greater than the significance level of \na = 0.05, we fail to reject the null hypothesis.\nINTERPRETATION\nStep 8: Because we fail to reject the null hypothesis, we conclude that there is not \nsufficient evidence to support the claim that the mean amount of adult sleep is less \nthan 7 hours.\nMinitab\nStatCrunch\nTI-83 , 84 Plus\nExcel (XLSTAT)\nStatdisk\nJMP\nSPSS\nc \nMeta-Analysis\nThe term meta-\nanalysis refers \nto a technique \nof conduct-\ning a study \nthat essen-\ntially combines \nresults of other studies. It has the \nadvantage that separate smaller \nsamples can be combined into \none big sample, making the \ncollective results more meaning-\nful. It also has the advantage \nof using work that has already \nbeen done. Meta-analysis has \nthe disadvantage of being only \nas good as the studies that are \nused. If the previous studies are \nflawed, the “garbage in, garbage \nout” phenomenon can occur. The \nuse of meta-analysis is currently \npopular in medical research and \npsychological research. As an \nexample, a study of migraine \nheadache treatments was based \non data from 46 other studies. \n(See “Meta-Analysis of Migraine \nHeadache Treatments: Combin-\ning Information from Heteroge-\nneous Designs,” by Dominici \net al., Journal of the American \nStatistical Association, Vol. 94, \nNo. 445.)\n",
    "370 \nCHAPTER 8 Hypothesis Testing\nExamine the technology displays to see that only two of them include critical values, \nbut they all include P-values. This is a major reason why the P-value method of test-\ning hypotheses has become so widely used in recent years.\nP-Value Method Without Technology\nIf suitable technology is not available, we can use Table A-3 to identify a range of \nvalues containing the P-value. In using Table A-3, keep in mind that it is designed for \npositive values of t and right-tail areas only, but left-tail areas correspond to the same \nt values with negative signs.\nEXAMPLE 2  Adult Sleep: P-Value Method Without Technology\nExample 1 is a left-tailed test with a test statistic of t = -0.290 (rounded) and a sam-\nple size of n = 12, so the number of degrees of freedom is df = n - 1 = 11. Using \nthe test statistic of t = -0.290 with Table A-3, examine the values of t in the row for  \ndf = 11 to see that 0.290 is less than all of the listed t values in the row, which indi-\ncates that the area in the left tail below the test statistic of t = -0.290 is greater than \n0.10. In this case, Table A-3 allows us to conclude that the P-value 7 0.10, but tech-\nnology provided the P-value of 0.3887. With a P-value 7 0.10, the conclusions are \nthe same as in Example 1.\nHINT: Because using Table A-3 to find a range of values containing the P-value \ncan be a bit tricky, the critical value method (see Example 3) might be easier than \nthe P-value method if suitable technology is not available.\nCritical Value Method\nEXAMPLE 3  Adult Sleep: Critical Value Method\nExample 1 is a left-tailed test with test statistic t = -0.290 (rounded). The \nsample size is n = 12, so the number of degrees of freedom is df = n - 1 = 11. \nGiven the significance level of a = 0.05, refer to the row of Table A-3 corre-\nsponding to 11 degrees of freedom, and refer to the column identifying an “area \nin one tail” of 0.05 (the significance level). The intersection of the row and col-\numn yields the critical value of t = 1.796, but this test is left-tailed, so the actual \ncritical value is t = -1.796. Figure 8-7 shows that the test statistic of t = -0.290 \ndoes not fall within the critical region bounded by the critical value t = -1.796, \nso we fail to reject the null hypothesis. The conclusions are the same as those \ngiven in  Example 1.\n",
    "8-3 Testing a Claim About a Mean \n371\nConfidence Interval Method\nEXAMPLE 4  Adult Sleep: Confidence Interval Method\nExample 1 is a left-tailed test with significance level a = 0.05, so we should use \n90% as the confidence level (as indicated by Table 8-1 on page 340). For the sample \ndata given in Example 1, here is the 90% confidence interval estimate of m:  \n5.80 hours 6 m 6 7.87 hours. In testing the claim that m 6 7 hours, we use  \nH0: m = 7 hours, but the assumed value of m = 7 hours is contained within the con-\nfidence interval limits, so the confidence interval is telling us that 7 hours could be \nthe value of m. We don’t have sufficient evidence to reject H0: m = 7 hours, so we \nfail to reject this null hypothesis and we get the same conclusions given in Example 1.\nEXAMPLE 5  Is the Mean Body Temperature Really 98.6°F?\nData Set 2 “Body Temperatures” in Appendix B includes measured body tempera-\ntures with these statistics for 12 AM on day 2: n = 106, x = 98.20°F, s = 0.62°F. \nUse a 0.05 significance level to test the common belief that the population mean  \nis 98.6°F.\nSOLUTION\nREQUIREMENT CHECK (1) With the study design used, we can treat the sample as a \nsimple random sample. (2) The second requirement is that “the population is nor-\nmally distributed or n 7 30.” The sample size is n = 106, so the second require-\nment is satisfied and there is no need to investigate the normality of the data. Both \nrequirements are satisfied. \nHere are the steps that follow the procedure summarized in Figure 8-1.\nStep 1: The claim that “the population mean is 98.6°F” becomes m = 98.6°F when \nexpressed in symbolic form.\nStep 2: The alternative (in symbolic form) to the original claim is m ≠98.6°F.\ncontinued\nHuman Lie Detectors\nResearchers \ntested 13,000 \npeople for \ntheir ability to \ndetermine when \nsomeone is ly-\ning. They found \n31 people with exceptional skills \nat identifying lies. These human \nlie detectors had accuracy rates \naround 90%. They also found \nthat federal officers and sheriffs \nwere quite good at detecting lies, \nwith accuracy rates around 80%. \nPsychology Professor Maureen \nO’Sullivan questioned those who \nwere adept at identifying lies, \nand she said that “all of them pay \nattention to nonverbal cues and \nthe nuances of word usages and \napply them differently to differ-\nent people. They could tell you \neight things about someone after \nwatching a two-second tape. It’s \nscary, the things these people \nnotice.” Methods of statistics can \nbe used to distinguish between \npeople unable to detect lying and \nthose with that ability.\ni\nl kill\nm 5 7\nor\nt 5 0\nCritical Value:\nt 5 21.796\na 5 0.05\nSample Mean:\nx 5 6.833 hours\nor t 5 20.290\n2\nFIGURE 8-7 t Test: Critical Value Method\n",
    "372 \nCHAPTER 8 Hypothesis Testing\nStep 3: Because the statement m ≠98.6°F does not contain the condition of equality, \nit becomes the alternative hypothesis H1. The null hypothesis H0 is the statement \nthat m = 98.6°F.\nH0: m = 98.6°F 1null hypothesis and original claim2\nH1: m ≠98.6°F 1alternative hypothesis2\nStep 4: As specified in the statement of the problem, the significance level is \na = 0.05.\nStep 5: Because the claim is made about the population mean m, the sample statistic \nmost relevant to this test is the sample mean x. We use the t distribution because \nthe relevant sample statistic is x and the requirements for using the t distribution are \nsatisfied.\nStep 6: The sample statistics are used to calculate the test statistic as follows, but \ntechnologies use unrounded values to provide the test statistic of t = -6.61.\nt = x - mx\ns\n2n\n= 98.20 - 98.6\n0.62\n2106\n= -6.64\nP-Value: The P-value is 0.0000 or 0+ (or “less than 0.01” if using Table A-3).\nCritical Values: The critical values are {1.983 (or {1.984 if using Table A-3).\nConfidence Interval: The 95% confidence interval is 98.08°F 6 m 6 98.32°F.\nStep 7: All three approaches lead to the same conclusion: Reject H0.\n \n■ P-Value: The P-value of 0.0000 is less than the significance level of a = 0.05.\n \n■Critical Values: The test statistic t = -6.64 falls in the critical region bounded \nby {1.983.\n \n■Confidence Interval: The claimed mean of 98.6°F does not fall within the con-\nfidence interval of 98.08°F 6 m 6 98.32°F.\nINTERPRETATION\nStep 8: There is sufficient evidence to warrant rejection of the common belief that \nthe population mean body temperature is 98.6°F.\nAlternative Methods Used When Population Is Not Normal and n \" 30\nThe methods of this section include two requirements: (1) The sample is a simple \nrandom sample; (2) either the population is normally distributed or n 7 30. If we \nhave sample data that are not collected in an appropriate way, such as a voluntary \n response sample, it is likely that there is nothing that can be done to salvage the \ndata, and the methods of this section should not be used. If the data are a simple \nrandom sample but the second condition is violated, there are alternative methods that \ncould be used, including these three alternative methods:\n \n■Bootstrap Resampling Use the confidence interval method of testing hypoth-\neses, but obtain the confidence interval using bootstrap resampling, as described \nin Section 7-4. Be careful to use the appropriate confidence level, as indicated by \nTable 8-1 on page 340. Reject the null hypothesis if the confidence interval limits do \nnot contain the value of the mean claimed in the null hypothesis. See Example 6.\n",
    "8-3 Testing a Claim About a Mean \n373\n \n■Sign Test See Section 13-2.\n \n■Wilcoxon Signed-Ranks Test See Section 13-3.\nEXAMPLE 6  Bootstrap Resampling\nListed below is a random sample of times (seconds) of tobacco use in animated \nchildren’s movies (from Data Set 13 “Alcohol and Tobacco in Movies”). Use a 0.05 \nsignificance level to test the claim that the sample is from a population with a mean \ngreater than 1 minute (or 60 seconds).\n0 223 0 176 0 548 0 37 158 51 0 0 299 37 0 11 0 0 0 0\nSOLUTION\nREQUIREMENT CHECK The t test described in this section requires that the popula-\ntion is normally distributed or n 7 30, but we have n = 20 and the accompanying \nnormal quantile plot shows that the sample does not appear to be from a normally \ndistributed population. The t test should not be used. \nSOLUTION\nInstead of incorrectly using the t test, we use the bootstrap resampling method de-\nscribed in Section 7-4. After obtaining 1000 bootstrap samples and finding the mean \nof each sample, we sort the means. Because the test is right-tailed with a 0.05 sig-\nnificance level, we use the 1000 sorted sample means to find the 90% confidence \ninterval limits of P5 = 29.9 seconds and P95 = 132.9 seconds. The 90% confidence \ninterval is 29.9 seconds 6 m 6 132.9 seconds. (These values can vary somewhat.) \nBecause the assumed mean of 60 seconds is contained within those confidence inter-\nval limits, we fail to reject H0: m = 60 seconds. There is not sufficient evidence to \nsupport H1: m 7 60 seconds.\nINTERPRETATION\nThere is not sufficient evidence to support the claim that the given sample is from a \npopulation with a mean greater than 60 seconds.\nHypothesis Test: Mean\nAccess tech instructions, videos, and data sets at www.TriolaStats.com\nTECH CENTER \n",
    "374 \nCHAPTER 8 Hypothesis Testing\nStatistical Literacy and Critical Thinking\n1. Alcohol Use and Video Games: Checking Requirements Twelve different video games \nshowing alcohol use were observed. The duration times of alcohol use were recorded, with the \ntimes (seconds) listed below (based on data from “Content and Ratings of Teen-Rated Video \nGames,” by Haninger and Thompson, Journal of the American Medical Association, Vol. 291, \nNo. 7). What requirements must be satisfied to test the claim that the sample is from a popula-\ntion with a mean greater than 90 sec? Are the requirements all satisfied?\n84 14 583 50 0 57 207 43 178 0 2 57\n2. df If we are using the sample data from Exercise 1 for a t test of the claim that the population \nmean is greater than 90 sec, what does df denote, and what is its value?\n3. t Test Exercise 2 refers to a t test. What is a t test? Why is the letter t used?\n4. Confidence Interval Assume that we will use the sample data from Exercise 1 “Alcohol \nUse and Video Games” with a 0.05 significance level in a test of the claim that the population \nmean is greater than 90 sec. If we want to construct a confidence interval to be used for testing \nthat claim, what confidence level should be used for the confidence interval? If the confidence \ninterval is found to be 21.1 sec 6 m 6 191.4 sec, what should we conclude about the claim?\nFinding P-values. In Exercises 5–8, either use technology to find the P-value or use \nTable A-3 to find a range of values for the P-value.\n5. Body Temperature The claim is that for 12 AM body temperatures, the mean is \nm 6 98.6°F. The sample size is n = 4 and the test statistic is t = -2.503.\n6. Body Temperature Data Set 2 “Body Temperatures” in Appendix B includes measured \nhuman body temperatures with these statistics for 12 AM on day 1: n = 93, x = 98.12°F,\ns = 0.65°F. In testing the claim that the mean body temperature is 98.6°F, the test statistic \nt = -7.122 is obtained.\n7. Platelets The claim is that for the population of adult females, the mean platelet count is \nm 6 300. The sample size is n = 15 and the test statistic is t = -0.666.\n8. Platelets The claim is that for the population of adult males, the mean platelet count is \nm 7 210. The sample size is n = 53 and the test statistic is t = 1.368.\nTesting Hypotheses. In Exercises 9–24, assume that a simple random sample has been \nselected and test the given claim. Unless specified by your instructor, use either the P-value \nmethod or the critical value method for testing hypotheses. Identify the null and alternative \nhypotheses, test statistic, P-value (or range of P-values), or critical value(s), and state the \nfinal conclusion that addresses the original claim.\n9. Body Temperatures Data Set 2 “Body Temperatures” in Appendix B includes 38 body \ntemperatures measured at 8 AM on day 1 of a study, and the accompanying XLSTAT dis-\nplay results from using those data to test the claim that the mean body temperature is equal to \n98.6°F. Conduct the hypothesis test using these results.\n8-3  Basic Skills and Concepts\n10. Body Temperatures Data Set 2 “Body Temperatures” in Appendix B includes 70 body \ntemperatures measured at 8 AM on day 2 of a study, and the accompanying JMP display results \nfrom using those data to test the claim that the mean body temperature is equal to 98.6oF. Con-\nduct the hypothesis test using these results.\n",
    "8-3 Testing a Claim About a Mean \n375\n 11. Platelets Data Set 1 “Body Data” in Appendix B includes platelet counts (1000 cells>mL) \nmeasured from 147 adult females. In testing the claim that the population of adult females has a \nmean platelet count less than 270, the accompanying Statdisk display is obtained by assuming \na 0.05 significance level.\n12. Platelets Data Set 1 “Body Data” in Appendix B includes platelet counts (1000 cells>mL) \nmeasured from 153 adult males. In testing the claim that the population of adult males has a \nmean platelet count greater than 220, the accompanying Minitab display is obtained.\n13. Birth Weight Data Set 3 “Births” in Appendix B includes birth weights of 205 females, and \nthe summary statistics are x = 3037.1 g and s = 706.3 g. Use a 0.01 significance level to test \nthe claim that the population of birth weights of females is greater than 3000 g.\n14. Birth Weight Data Set 1 “Body Data” in Appendix B includes birth weights of 195 males, \nand the summary statistics are x = 3272.8 g and s = 660.2 g. Use a 0.01 significance level to \ntest the claim that the population of birth weights of males is less than 3400 g.\n15. Garlic for Reducing Cholesterol In a test of the effectiveness of garlic for lowering cho-\nlesterol, 49 subjects were treated with raw garlic. Cholesterol levels were measured before and \nafter the treatment. The changes (before minus after) in their levels of low-density lipoprotein \n(LDL) cholesterol (in mg>dL) have a mean of 0.4 and a standard deviation of 21.0 (based on \ndata from “Effect of Raw Garlic vs Commercial Garlic Supplements on Plasma Lipid Concen-\ntrations in Adults with Moderate Hypercholesterolemia,” by Gardner et al., Archives of Internal \nMedicine, Vol. 167, No. 4). Use a 0.05 significance level to test the claim that with garlic treat-\nment, the mean change in LDL cholesterol is greater than 0. What do the results suggest about \nthe effectiveness of the garlic treatment?\n16. Insomnia Treatment A clinical trial was conducted to test the effectiveness of the drug \nzopiclone for treating insomnia in older subjects. Before treatment with zopiclone, 16 subjects \nhad a mean wake time of 102.8 min. After treatment with zopiclone, the 16 subjects had a \nmean wake time of 98.9 min and a standard deviation of 42.3 min (based on data from “Cog-\nnitive Behavioral Therapy vs Zopiclone for Treatment of Chronic Primary Insomnia in Older \nAdults,” by Sivertsen et al., Journal of the American Medical Association, Vol. 295, No. 24). \nAssume that the 16 sample values appear to be from a normally distributed population, and \ntest the claim that after treatment with zopiclone, subjects have a mean wake time of less than \n102.8 min. Does zopiclone appear to be effective?\n17. Is the Diet Practical? When 40 people used the Weight Watchers diet for one year, their \nmean weight loss was 3.0 lb and the standard deviation was 4.9 lb (based on data from “Com-\nparison of the Atkins, Ornish, Weight Watchers, and Zone Diets for Weight Loss and Heart \nDisease Reduction,” by Dansinger et al., Journal of the American Medical Association, \nVol. 293, No. 1). Use a 0.01 significance level to test the claim that the mean weight loss is \ngreater than 0. Based on these results, does the diet appear to have statistical significance? \nDoes the diet appear to have practical significance?\n18. Conductor Life Span A New York Times article noted that the mean life span for 35 male \nsymphony conductors was 73.4 years, in contrast to the mean of 69.5 years for males in the \ngeneral population. Assuming that the 35 males have life spans with a standard deviation of \n8.7 years, use a 0.05 significance level to test the claim that male symphony conductors have \na mean life span that is greater than 69.5 years. Does it appear that male symphony conduc-\ntors live longer than males from the general population? Why doesn’t the experience of being \na male symphony conductor cause men to live longer? (Hint: Are male symphony conductors \nborn as conductors, or do they become conductors at a much later age?)\n",
    "376 \nCHAPTER 8 Hypothesis Testing\n19. Course Evaluations Data from student course evaluations were obtained from the Uni-\nversity of Texas at Austin. The summary statistics are n = 436, x = 3.97, s = 0.55. Use a \n0.05 significance level to test the claim that the population of student course evaluations has a \nmean equal to 4.00. Do the results apply to the population of all students?\n20. Treating Chronic Fatigue Syndrome Patients with chronic fatigue syndrome were \ntested, and then retested after being treated with fludrocortisone. A standard scale from -7 \nto +7 is used to measure fatigue before and after the treatment. The changes are summarized \nwith these statistics: n = 21, x = 4.00, s = 2.17 (based on data from “The Relationship Be-\ntween Neurally Mediated Hypotension and the Chronic Fatigue Syndrome,” by Bou-Holaigah, \nRowe, Kan, and Calkins, Journal of the American Medical Association, Vol. 274, No. 12). The \nchanges were computed in a way that makes positive values represent improvements. Use a \n0.01 significance level to test the claim that the mean change is positive. Does the treatment \nappear to be effective?\n21. Lead in Medicine Listed below are the lead concentrations (in mg>g) measured in dif-\nferent Ayurveda medicines. Ayurveda is a traditional medical system commonly used in In-\ndia. The lead concentrations listed here are from medicines manufactured in the United States \n(based on data from “Lead, Mercury, and Arsenic in US and Indian Manufactured Ayurvedic \nMedicines Sold via the Internet,” by Saper et al., Journal of the American Medical Association, \nVol. 300, No. 8). Use a 0.05 significance level to test the claim that the mean lead concentration \nfor all such medicines is less than 14 mg>g.\n3.0 6.5 6.0 5.5 20.5 7.5 12.0 20.5 11.5 17.5\n22. Got a Minute? Students of one of the authors estimated the length of one minute without \nreference to a watch or clock, and the times (seconds) are listed below. Use a 0.05 significance \nlevel to test the claim that these times are from a population with a mean equal to 60 seconds. \nDoes it appear that students are reasonably good at estimating one minute?\n69 81 39 65 42 21 60 63 66 48 64 70 96 91 65\n 23. Car Booster Seats The National Highway Traffic Safety Administration conducted crash \ntests of child booster seats for cars. Listed below are results from those tests, with the measure-\nments given in hic (standard “head injury condition” units). The safety requirement is that the \nhic measurement should be less than 1000 hic. Use a 0.01 significance level to test the claim \nthat the sample is from a population with a mean less than 1000 hic. Do the results suggest that \nall of the child booster seats meet the specified requirement?\n774 649 1210 546 431 612\n24. Heights of Supermodels Listed below are the heights (cm) for the simple random sam-\nple of female supermodels Lima, Bundchen, Ambrosio, Ebanks, Iman, Rubik, Kurkova, Kerr, \nKroes, Swanepoel, Prinsloo, Hosk, Kloss, Robinson, Heatherton, and Refaeli. Use a 0.01 sig-\nnificance level to test the claim that supermodels have heights with a mean that is greater than \nthe mean height of 162 cm for women in the general population. Given that there are only 16 \nheights represented, can we really conclude that supermodels are taller than the typical woman?\n178  177  176  174  175  178  175  178  178  177  180  176  180  178  180  176\nLarge Data Sets from Appendix B. In Exercises 25–28, use the data set in Appendix B \nto test the given claim. Use the P-value method unless your instructor specifies otherwise.\n25. Pulse Rates Use the pulse rates of adult females listed in Data Set 1 “Body Data” in \n Appendix B to test the claim that the mean is less than 75 bpm. Use a 0.05 significance level.\n26. Pulse Rates Use the pulse rates of adult males listed in Data Set 1 “Body Data” in \n Appendix B to test the claim that the mean is less than 75 bpm. Use a 0.05 significance level.\n",
    "8-4 Testing a Claim About a Standard Deviation or Variance \n377\n27. Diastolic Blood Pressure for Women Use the diastolic blood pressure measurements \nfor adult females listed in Data Set 1 “Body Data” in Appendix B and test the claim that the \nadult female population has a mean diastolic blood pressure level less than 90 mm Hg. A dia-\nstolic blood pressure above 90 is considered to be hypertension. Use a 0.05 significance level. \nBased on the result, can we conclude that none of the adult females in the sample have hyper-\ntension?\n28. Diastolic Blood Pressure for Men Repeat the preceding exercise for adult males instead \nof adult females.\n29. Finding Critical t Values When finding critical values, we often need signifi-\ncance levels other than those available in Table A-3. One approach is to approximate \ncritical t values by calculating t = 2df # 1eA2>df - 12 where df = n - 1, e = 2.718,\nA = z18 # df + 32>18 # df + 12, and z is the critical z score. Use this approximation to find \nthe critical t score for Exercise 11 “Platelets,” using a significance level of 0.05. Compare the \nresult to the critical t value shown in the Statdisk display. Does this approximation appear to \nwork reasonably well?\n30. Interpreting Power For the sample data in Example 1 “Adult Sleep” from this section, \nMinitab and StatCrunch show that the hypothesis test has a power of 0.4943 of supporting \nthe claim that m 6 7 hours of sleep when the actual population mean is 6.0 hours of sleep. \nInterpret this value of the power, then identify the value of b and interpret that value. (For \nthe t test in this section, a “noncentrality parameter” makes calculations of power much more \ncomplicated than the process described in Section 8-1, so software is recommended for power \ncalculations.)\n8-3 Beyond the Basics\nKey Concept This section presents methods for conducting a formal hypothesis test \nof a claim made about a population standard deviation s or population variance s2.\nThe methods of this section use the chi-square distribution that was first introduced in \nSection 7-3. \n8-4 \nTesting a Claim About a Standard Deviation or Variance\nEquivalent Methods\nWhen testing claims about s or s2, the P-value method, the critical value method, \nand the confidence interval method are all equivalent in the sense that they will always \nlead to the same conclusion.\nCAUTION The x2 (chi-square) test of this section is not robust against a departure \nfrom normality, meaning that the test does not work well if the population has \na distribution that is far from normal. The condition of a normally distributed \npopulation is therefore a much stricter requirement when testing claims about s or \ns2 than when testing claims about a population mean m.\n",
    "378 \nCHAPTER 8 Hypothesis Testing\nCAUTION Table A-4 for the chi-square distribution uses cumulative areas from \nthe right (unlike Table A-2 for the standard normal distribution, which provides \ncumulative areas from the left.) See Example 1 in Section 7-3.\nTesting Claims About s or s2\nObjective:\nConduct a hypothesis test of a claim made about a population standard deviation s or population variance s2.\nNotation\nn = sample size \ns = sample standard deviation\ns = population standard deviation \ns2 =  sample variance\ns2 =  population variance\nKEY ELEMENTS \nRequirements\n1. The sample is a simple random sample.\n2. The population has a normal distribution. (This is a fairly strict requirement.)\nTest Statistic\nx2 = 1n - 12s2\ns2\n 1round to three decimal places, as in Table A@42\nP-Values: Use technology or Table A-4 with degrees of freedom of df = n - 1.\nCritical Values: Use Table A-4 with degrees of freedom df = n - 1.\nProperties of the Chi-Square Distribution\nThe chi-square distribution was introduced in Section 7-3, where we noted the follow-\ning important properties.\n1. All values of x2 are nonnegative, and the distribution is not symmetric (see \n Figure 8-8).\n2. There is a different x2 distribution for each number of degrees of freedom (see \nFigure 8-9).\n3. The critical values are found in Table A-4 using\ndegrees of freedom = n −1\nHere is an important note if using Table A-4 for finding critical values:\nIn Table A-4, each critical value of X2 in the body of the table corresponds \nto an area given in the top row of the table, and each area in that top row \nis a cumulative area to the right of the critical value.\n",
    "8-4 Testing a Claim About a Standard Deviation or Variance \n379\nNot symmetric\nAll values are nonnegative\nx2\n0\nFIGURE 8-8  Properties of the Chi-Square \nDistribution\n0\n5\n10\n15\n20\n25\n30\n35\n40\n45\nx2\ndf 5 20\ndf 5 10\nFIGURE 8-9  Chi-Square Distribution for \ndf = 10 and df = 20\nEXAMPLE 1   P-Value Method: Do Supermodel Heights  \nVary Less?\nListed below are the heights (cm) for the simple random sample of female super-\nmodels: Lima, Bundchen, Ambrosio, Ebanks, Iman, Rubik, Kurkova, Kerr, Kroes, \nSwanepoel, Prinsloo, Hosk, Kloss, Robinson, Heatherton, and Refaeli. Use a 0.01 \nsignificance level to test the claim that supermodels have heights with a standard \ndeviation that is less than s = 7.5 cm for the population of women. Does it appear \nthat heights of supermodels vary less than heights of women from the population?\n178 177 176 174 175 178 175 178 178 177 180 176 180 178 180 176\nSOLUTION\nREQUIREMENT CHECK (1) The sample is a simple random sample. (2) In checking for \nnormality, we see that the sample has no outliers, the accompanying normal quantile \nplot shows points that are reasonably close to a straight-line pattern, and there is no \nother pattern that is not a straight line. Both requirements are satisfied. \nStatdisk\nTechnology Technology capable of conducting this test will typically display the  \nP-value. The StatCrunch result is shown on the top of the next page. (Instead of  \nusing the assumed value of s for H0 and H1, StatCrunch uses s2. For the null  \nhypothesis, s = 7.5 is equivalent to s2 = 7.52 = 56.25.) The display shows that \nthe test statistic is x2 = 0.907 (rounded) and the P-value is less than 0.0001.\ncontinued\n",
    "380 \nCHAPTER 8 Hypothesis Testing\nCritical Value Method\nTechnology typically provides a P-value, so the P-value method is used. If technol-\nogy is not available, the P-value method of testing hypotheses is a bit challenging, \nbecause Table A-4 allows us to find only a range of values for the P-value. Instead, \nwe could use the critical value method. Steps 1 through 5 in Example 1 would be \nthe same. In Step 6, the test statistic is calculated by using s = 7.5 cm (as assumed \nin the null hypothesis in Example 1); n = 16, and s = 1.843909 cm, which is the \nunrounded standard deviation computed from the original list of 16 heights. We get \nthis test statistic:\nx2 = 1n - 12s2\ns2\n= 116 - 12 11.8439092 2\n7.52\n= 0.907\nThe critical value of x2 = 5.229 is found from Table A-4, and it corresponds to \n15 degrees of freedom and an “area to the right” of 0.99 (based on the significance \nlevel of 0.01 for a left-tailed test). See Figure 8-10. In Step 7 we reject the null \nhypothesis because the test statistic of x2 = 0.907 falls in the critical region, as \nshown in Figure 8-10. We conclude that there is sufficient evidence to support the \nclaim that supermodels have heights with a standard deviation that is less than 7.5 cm \nfor the population of women.\nStatCrunch\nStep 1: The claim that “the standard deviation is less than 7.5 cm” is expressed in \nsymbolic form as s 6 7.5 cm.\nStep 2: If the original claim is false, then s Ú 7.5 cm.\nStep 3: The expression s 6 7.5 cm does not contain equality, so it becomes the al-\nternative hypothesis. The null hypothesis is the statement that s = 7.5 cm.\nH0: s = 7.5 cm\nH1: s 6 7.5 cm 1original claim2\nStep 4: The significance level is a = 0.01.\nStep 5: Because the claim is made about s, we use the x2 (chi-square) distribution.\nStep 6: The StatCrunch display shows the test statistic of x2 = 0.907 (rounded), \nand it shows that the P-value is less than 0.0001.\nStep 7: Because the P-value is less than the significance level of a = 0.01, we \nreject H0.\nINTERPRETATION\nStep 8: There is sufficient evidence to support the claim that female supermodels \nhave heights with a standard deviation that is less than 7.5 cm for the population of \nwomen. It appears that heights of supermodels do vary less than heights of women \nin the general population.\n",
    "8-4 Testing a Claim About a Standard Deviation or Variance \n381\nConfidence Interval Method\nAs stated earlier, when testing claims about s or s2, the P-value method, the critical \nvalue method, and the confidence interval method are all equivalent in the sense that \nthey will always lead to the same conclusion. See Example 2.\na 5 0.01\nCritical Value:\nx2 5 5.229\nTest Statistic:\nx2 5 0.907\nFIGURE 8-10 Testing the Claim That S * 7.5 cm\nEXAMPLE 2  Supermodel Heights: Confidence Interval Method\nRepeat the hypothesis test in Example 1 by constructing a suitable confidence \ninterval.\nSOLUTION\nFirst, we should be careful to select the correct confidence level. Because the \nhypothesis test is left-tailed and the significance level is 0.01, we should use a \nconfidence level of 98%, or 0.98. (See Table 8-1 on page 340 for help in selecting \nthe correct confidence level.)\nUsing the methods described in Section 7-3, we can use the sample data listed \nin Example 1 to construct a 98% confidence interval estimate of s. We use n = 16, \ns = 1.843909 cm, x2\nL = 5.229, and x2\nR = 30.578. (The critical values x2\nL and x2\nR \nare found in Table A-4. Use the row with df = n - 1 = 15. The 0.98 confidence \nlevel corresponds to a = 0.02, and we divide that area of 0.02 equally between the \ntwo tails so that the areas to the right of the critical values are 0.99 and 0.01. Refer \nto Table A-4 and use the columns with areas of 0.99 and 0.01 and use the 15th row.)\n B\n1n - 12s2\nx2\nR\n6 s 6 B\n1n - 12s2\nx2\nL\n B\n116 - 1211.84390922\n30.578\n6 s 6 B\n116 - 1211.84390922\n5.229\n 1.3 cm 6 s 6 3.1 cm\nWith this confidence interval, we can support the claim that s 6 7.5 cm because all \nvalues of the confidence interval are less than 7.5 cm. We reach the same conclusion \nfound with the P-value method and the critical value method.\n",
    "382 \nCHAPTER 8 Hypothesis Testing\nAlternative Method Used When Population Is Not Normal\nThe methods of this section include two requirements: (1) The sample is a simple \nrandom sample; (2) the population is normally distributed. If sample data are not col-\nlected in a random manner, the methods of this section do not apply. If the sample \nappears to be from a population not having a normal distribution, we could use the \nconfidence  interval method of testing hypotheses, but obtain the confidence interval \nusing bootstrap resampling, as described in Section 7-4. Be careful to use the appropri-\nate confidence level, as indicated by Table 8-1 on page 340. Reject the null hypothesis \nif the confidence interval limits do not contain the value of the mean claimed in the null \nhypothesis. See the Technology Project near the end of this chapter.\nStatistical Literacy and Critical Thinking \n1. Birth Weights Shown below are birth weights (in kilograms) of male babies born to moth-\ners taking a special vitamin supplement (based on data from the New York State Department of \nHealth). Assume that we want to use the sample data to test the claim that the sample is from \na population with a standard deviation equal to 0.470 kg, which is the standard deviation for \nthe population not given the special vitamin supplement. What requirements must be satisfied? \nHow does the normality requirement for a hypothesis test of a claim about a standard deviation \ndiffer from the normality requirement for a hypothesis test of a claim about a mean?\n3.73 4.37 3.73 4.33 3.39 3.68 4.68 3.52\n3.02 4.09 2.47 4.13 4.47 3.22 3.43 2.54\n2. Birth Weights Use the data and the claim given in Exercise 1 to identify the null and alter-\nnative hypotheses and the test statistic. What is the sampling distribution of the test statistic?\n3. Birth Weights For the sample data from Exercise 1, we get a P-value of 0.0291 when test-\ning the claim that the sample is from a population with a standard deviation equal to 0.470 kg. \nAssume that the test is conducted with a significance level given by a = 0.05.\na. What should we conclude about the null hypothesis?\nb. What should we conclude about the original claim?\nc. Does the vitamin supplement appear to affect the variation among birth weights?\n4. Birth Weights: Confidence Interval If we use the data given in Exercise 1, we \nget this 95% confidence interval estimate of the standard deviation of birth weights: \n0.486 kg 6 s 6 1.017 kg. When testing the claim that the sample is from a population with a \nstandard deviation equal to 0.470 kg, what do we conclude from the confidence interval?\n8-4 Basic Skills and Concepts\nHypothesis Test: Standard Deviation or Variance\nAccess tech instructions, videos, and data sets at www.TriolaStats.com\nTECH CENTER \n",
    "8-4 Testing a Claim About a Standard Deviation or Variance \n383\nTesting Claims About Variation. In Exercises 5–16, test the given claim. Identify the null \nhypothesis, alternative hypothesis, test statistic, P-value, or critical value(s), then state the con-\nclusion about the null hypothesis, as well as the final conclusion that addresses the original \nclaim. Assume that a simple random sample is selected from a normally distributed population.\n5. Pulse Rates of Men A simple random sample of 153 men results in a standard deviation of \n11.3 beats per minute (based on Data Set 1 “Body Data” in Appendix B). The normal range of \npulse rates of adults is typically given as 60 to 100 beats per minute. If the range rule of thumb \nis applied to that normal range, the result is a standard deviation of 10 beats per minute. Use \nthe sample results with a 0.05 significance level to test the claim that pulse rates of men have a \nstandard deviation equal to 10 beats per minute; see the accompanying StatCrunch display for \nthis test. What do the results indicate about the effectiveness of using the range rule of thumb \nwith the “normal range” from 60 to 100 beats per minute for estimating s in this case?\n6. Pulse Rates of Women Repeat the preceding exercise using the pulse rates of women \nlisted in Data Set 1 “Body Data” in Appendix B. For the sample of pulse rates of women, \nn = 147 and s = 12.5. See the accompanying JMP display that results from using the original \nlist of pulse rates instead of the summary statistics. (Hint: The bottom three rows of the display \nprovide P-values for a two-tailed test, a left-tailed test, and a right-tailed test, respectively.) \nWhat do the results indicate about the effectiveness of using the range rule of thumb with the \n“normal range” from 60 to 100 beats per minute for estimating s in this case?\n7. Body Temperature Example 5 in Section 8-3 involved a test of the claim that humans \nhave body temperatures with a mean equal to 98.6°F. The sample of 106 body temperatures \nhas a standard deviation of 0.62°F. The conclusion in that example would change if the sample \nstandard deviation s were 2.08°F or greater. Use a 0.01 significance level to test the claim that \nthe sample of 106 body temperatures is from a population with a standard deviation less than \n2.08°F. What does the result tell us about the validity of the hypothesis test in Example 5 in \nSection 8-3?\n8. Birth Weights A simple random sample of birth weights of 30 girls has a standard devia-\ntion of 829.5 hg. Use a 0.01 significance level to test the claim that birth weights of girls have \nthe same standard deviation as the birth weights of boys, which is 660.2 hg (based on Data Set \n3 “Births” in Appendix B).\n9. Physician IQ Scores For a random sample of IQ scores of 18 physicians, the mean is \n124.2 and the standard deviation is 9.6 (based on data from a study conducted at the University \nof Wisconsin at Madison). Use a 0.05 significance level to test the claim that because physi-\ncians are a more homogeneous population than the general population, their IQ scores have a \nstandard deviation less than 15, which is the standard deviation for the general population.\n10. Statistics Test Scores Tests in one of the author’s statistics classes have scores with a \nstandard deviation equal to 14.1. One of his last classes had 27 test scores with a standard devi-\nation of 9.3. Use a 0.01 significance level to test the claim that this class has less variation than \nother past classes. Does a lower standard deviation suggest that this last class is doing better?\n11. New Filling Process The Orange Machine Company supplies a tool for pouring cold \nmedicine into bottles in such a way that the standard deviation of the contents is 4.25 g. A new \nfilling process is tested on 71 bottles and the standard deviation for this sample is 3.87 g. Use a \n0.05 significance level to test the claim that the new process dispenses amounts with a standard \ndeviation less than the standard deviation of 4.25 g for the old process. Is the new process better \nin the sense of dispensing amounts that are more consistent?\n",
    "384 \nCHAPTER 8 Hypothesis Testing\n 12. Spoken Words Couples were recruited for a study of how many words people speak in a \nday. A random sample of 56 males resulted in a mean of 16,576 words and a standard deviation \nof 7871 words. Use a 0.01 significance level to test the claim that males have a standard devia-\ntion that is greater than the standard deviation of 7460 words for females (based on data from \n“Are Women Really More Talkative Than Men?” by Mehl et al., Science, Vol. 317, No. 5834).\n13. Weight Loss from Diet When 40 people used the Weight Watchers diet for one year, \ntheir weight losses had a standard deviation of 4.9 lb (based on data from “Comparison of the \n Atkins, Ornish, Weight Watchers, and Zone Diets for Weight Loss and Heart Disease Reduc-\ntion,” by Dansinger, et al., Journal of the American Medical Association, Vol. 293, No. 1). Use \na 0.01 significance level to test the claim that the amounts of weight loss have a standard devia-\ntion equal to 6.0 lb, which appears to be the standard deviation for the amounts of weight loss \nwith the Zone diet.\n14. Sphygmomanometers An aneroid sphygmomanometer is a mechanical device used to \nmeasure blood pressure. A random sample of these devices is tested for accuracy and the errors \n(mm Hg) are listed below (based on data from “How Accurate Are Sphygmomanometers?” \nby Mion and Pierin, Journal of Human Hypertension, Vol. 12, No. 4). One of the devices is \nconsidered to be unacceptable if its error is more than 3 mm Hg. We will use this criterion for \nconcluding that the sample is from a population of unacceptable devices: s 7 1.5 mm Hg. Use \na 0.05 significance level with the sample data to test the claim that the sample is from a popula-\ntion with a standard deviation greater than 1.5 mm Hg. What does the result suggest about the \naccuracy of aneroid sphygmomanometers?\n-4 -11 5 5 8 14 -16 -12 4 6 -6\n15. Queues Providence Hospital once had separate waiting lines for patients arriving for ad-\nmission, but it now has a single waiting line that feeds the processing stations as vacancies \noccur. The standard deviation of waiting times with the old multiple-line configuration was \n109.3 sec. Listed below is a simple random sample of waiting times (minutes) with the single \nwaiting line. Use a 0.05 significance level to test the claim that with a single waiting line, the \nwaiting times have a standard deviation less than 109.3 sec. What improvement occurred when \nmultiple waiting lines were replaced by a single waiting line?\n390 396 402 408 426 438 444 462 462 462\n16. World’s Smallest Mammal The world’s smallest mammal is the bumblebee bat, also \nknown as the Kitti’s hog-nosed bat (or Craseonycteris thonglongyai). Such bats are roughly \nthe size of a large bumblebee. Listed below are weights (in grams) from a sample of these bats. \nUsing a 0.05 significance level, test the claim that these weights come from a population with a \nstandard deviation equal to 0.30 g, which is the standard deviation of weights of the bumblebee \nbats from one region in Thailand. Do these bats appear to have weights with the same variation \nas the bats from that region in Thailand?\n1.7 1.6 1.5 2.0 2.3 1.6 1.6 1.8 1.5 1.7 2.2 1.4 1.6 1.6 1.6\n17. Finding Critical Values of X2 For large numbers of degrees of freedom, we can approxi-\nmate critical values of x2 as follows:\nx2 = 1\n21z + 22k - 12 2\nHere k is the number of degrees of freedom and z is the critical value(s) found from technology \nor Table A-2. In Exercise 12 “Spoken Words,” we have df = 55, so Table A-4 does not list an \nexact critical value. If we want to approximate a critical value of x2 in the right-tailed hypoth-\nesis test with a = 0.01 and a sample size of 56, we let k = 55 with z = 2.33 (or the more \n8-4 Beyond the Basics\n",
    "accurate value of z = 2.326348 found from technology). Use this approximation to estimate \nthe critical value of x2 for Exercise 12. How close is it to the critical value of x2 = 82.292\nobtained by using Statdisk and Minitab?\n18. Finding Critical Values of X2 Repeat Exercise 17 using this approximation (with k and z \nas described in Exercise 19):\nx2 = k a1 - 2\n9k + zA\n2\n9k b\n3\n1. Distributions Using the methods of this chapter, identify the distribution that should be \nused for testing a claim about the given population parameter.\na. Mean\nb. Proportion\nc. Standard deviation\n2. Tails Determine whether the given claim involves a hypothesis test that is left-tailed, two-\ntailed, or right-tailed.\na. p ≠0.5\nb. m 6 98.6\nc. s 7 15\n3. Instagram Poll In a Pew Research Center poll of Internet users aged 18−29, 53% said that \nthey use Instagram. We want to use a 0.05 significance level to test the claim that the majority \nof Internet users aged 18−29 use Instagram.\na. Identify the null and alternative hypotheses.\nb. Using a sample size of 532, find the value of the test statistic.\nc. Technology is used to find that the P-value for the test is 0.0827. What should we conclude \nabout the null hypothesis?\nd. What should we conclude about the original claim?\n4. P-Value Find the P-value in a test of the claim that the mean annual income of a nurse is \ngreater than $60,000 (based on data from the Bureau of Labor Statistics) given that the test \nstatistic is t = 2.462 for a sample of 30 nurses.\n5. Conclusions True or false: In hypothesis testing, it is never valid to form a conclusion of \nsupporting the null hypothesis.\n6. Conclusions True or false: The conclusion of “fail to reject the null hypothesis” has exactly \nthe same meaning as “accept the null hypothesis.”\n7. Uncertainty True or false: If correct methods of hypothesis testing are used with a large \nsimple random sample that satisfies the test requirements, the conclusion will always be true.\n8. Chi-Square Test In a test of the claim that s = 10 for the population of IQ scores of \nnurses, we find that the rightmost critical value is x2\nR = 40.646. Is the leftmost critical x2\nL value \nequal to -40.646?\n9. Robust Explain what is meant by the statements that the t test for a claim about m is robust, \nbut the x2 test for a claim about s2 is not robust.\nChapter Quick Quiz\nCHAPTER 8 Chapter Quick Quiz \n385\n",
    "386 \nCHAPTER 8 Hypothesis Testing\n10. Equivalent Methods Which of the following statements are true?\na. When testing a claim about a population mean m, the P-value method, critical value method, \nand confidence interval method are all equivalent in the sense that they always yield the same \nconclusions.\nb. When testing a claim about a population proportion p, the P-value method, critical value \nmethod, and confidence interval method are all equivalent in the sense that they always yield \nthe same conclusions.\nc. When testing a claim about any population parameter, the P-value method, critical value \nmethod, and confidence interval method are all equivalent in the sense that they always yield \nthe same conclusions.\nReview Exercises\n1. True, False Characterize each of the following statements as being true or false.\na. In a hypothesis test, a very high P-value indicates strong support of the alternative hypoth-\nesis.\nb. The Student t distribution can be used to test a claim about a population mean whenever the \nsample data are randomly selected from a normally distributed population.\nc. When using a x2 distribution to test a claim about a population standard deviation, there is a \nvery loose requirement that the sample data are from a population having a normal distribution.\nd. When conducting a hypothesis test about the claimed proportion of surgeons who have cur-\nrent passports, the problems with a convenience sample can be overcome by using a larger \nsample size.\ne. When repeating the same hypothesis test with different random samples of the same size, the \nconclusions will all be the same.\n2. Is Nessie Real? This question was posted on the America Online website: Do you believe \nthe Loch Ness monster exists? Among 21,346 responses, 64% were “yes.” Use a 0.01 signifi-\ncance level to test the claim that most people believe that the Loch Ness monster exists. How \nis the conclusion affected by the fact that Internet users who saw the question could decide \nwhether to respond?\n3. Red Blood Cell Count A simple random sample of 40 adult males is obtained, and the \nred blood cell count (in cells per microliter) is measured for each of them, with these results: \nn = 40, x = 4.932 million cells per microliter, s = 0.504 million cells per microliter (from \nData Set 1 “Body Data” in Appendix B). Use a 0.01 significance level to test the claim that \nthe sample is from a population with a mean less than 5.4 million cells per microliter, which is \noften used as the upper limit of the range of normal values. Does the result suggest that each of \nthe 40 males has a red blood cell count below 5.4 million cells per microliter?\n4. Smoking Recently, a simple random sample of 572 adult males showed that 124 of them \nsmoke (based on data from the Centers for Disease Control and Prevention). It has been estab-\nlished that in 2008, 20.4% of adult males smoke. Use a 0.05 significance level to test the claim \nthat the rate of smoking by adult males is now the same as in 2008.\n5. Controlling Cholesterol The Westbrook Pharmaceutical Company manufactures atorv-\nastatin pills, designed to lower cholesterol levels. Listed below are the amounts (in mg) of \natorvastatin in a random sample of the pills. Use a 0.05 significance level to test the claim that \nthe pills come from a population in which the mean amount of atorvastatin is equal to 25 mg.\n24.1 24.4 24.3 24.9 24.1 26.2 25.1 24.7 24.4 25.0 24.7 25.1 25.3 25.5 25.5\n",
    "6. BMI for Miss America A claimed trend of thinner Miss America winners has generated \ncharges that the contest encourages unhealthy diet habits among young women. Listed below \nare body mass indexes (BMI) for recent Miss America winners. Use a 0.01 significance level \nto test the claim that recent winners are from a population with a mean BMI less than 20.16, \nwhich was the BMI for winners from the 1920s and 1930s. Given that BMI is a measure of the \nrelative amounts of body fat and height, do recent winners appear to be significantly smaller \nthan those from the 1920s and 1930s?\n19.5 20.3 19.6 20.2 17.8 17.9 19.1 18.8 17.6 16.8\n7. BMI for Miss America Use the same BMI indexes given in Exercise 6. Use a 0.01 signifi-\ncance level to test the claim that recent Miss America winners are from a population with a \nstandard deviation equal to 1.34, which was the standard deviation of BMI for winners from \nthe 1920s and 1930s. Do recent winners appear to have variation that is different from that of \nthe 1920s and 1930s?\n8. Type I Error and Type II Error\na. In general, what is a type I error? In general, what is a type II error?\nb. For the hypothesis test in Exercise 6 “BMI for Miss America,” write a statement that would \nbe a type I error, and write another statement that would be a type II error.\n1. Lightning Deaths Listed below are the numbers of deaths from lightning strikes in the \nUnited States each year for a sequence of 14 recent and consecutive years. Find the values of \nthe indicated statistics.\n51 44 51 43 32 38 48 45 27 34 29 26 28 23\na. Mean  b. Median  c. Standard deviation  d. Variance  e. Range\nf. What important feature of the data is not revealed from an examination of the statistics, and \nwhat tool would be helpful in revealing it?\n2. Lightning Deaths Refer to the sample data in Cumulative Review Exercise 1.\na. What is the level of measurement of the data (nominal, ordinal, interval, ratio)?\nb. Are the values discrete or continuous?\nc. Are the data categorical or quantitative?\nd. Is the sample a simple random sample?\n3. Confidence Interval for Lightning Deaths Use the sample values given in Cumulative \nReview Exercise 1 to construct a 99% confidence interval estimate of the population mean. \nAssume that the population has a normal distribution. Write a brief statement that interprets the \nconfidence interval.\n4. Hypothesis Test for Lightning Deaths Refer to the sample data given in Cumulative \nReview Exercise 1 and consider those data to be a random sample of annual lightning deaths \nfrom recent years. Use those data with a 0.01 significance level to test the claim that the \nmean number of annual lightning deaths is less than the mean of 72.6 deaths from the 1980s. \nIf the mean is now lower than in the past, identify one of the several factors that could ex-\nplain the decline.\nCumulative Review Exercises\nCHAPTER 8 Cumulative Review Exercises \n387\n",
    "388 \nCHAPTER 8 Hypothesis Testing\n5. Lightning Deaths The accompanying bar chart shows the numbers of lightning strike \ndeaths broken down by gender for a recent period of nine years. What is wrong with the graph?\n6. Lightning Deaths The graph in Cumulative Review Exercise 5 was created by using data \nconsisting of 232 male deaths from lightning strikes and 55 female deaths from lightning \nstrikes. Assume that these data are randomly selected lightning deaths and proceed to test the \nclaim that the proportion of male deaths is greater than 1>2. Use a 0.01 significance level. Any \nexplanation for the result?\n7. Lightning Deaths The graph in Cumulative Review Exercise 5 was created by using \ndata consisting of 232 male deaths from lightning strikes and 55 female deaths from light-\nning strikes. Assume that these data are randomly selected lightning deaths and proceed to \nconstruct a 95% confidence interval estimate of the proportion of males among all lightning \ndeaths. Based on the result, does it seem feasible that males and females have equal chances of \nbeing killed by lightning?\n8. Lightning Deaths Based on the results given in Cumulative Review Exercise 6, assume \nthat for a randomly selected lightning death, there is a 0.8 probability that the victim is a male.\na. Find the probability that three random people killed by lightning strikes are all males.\nb. Find the probability that three random people killed by lightning strikes are all females.\nc. Find the probability that among three people killed by lightning strikes, at least one is a male.\nd. If five people killed by lightning strikes are randomly selected, find the probability that ex-\nactly three of them are males.\ne. A study involves random selection of different groups of 50 people killed by lightning strikes. \nFor those groups, find the mean and standard deviation for the numbers of male victims.\nf. For the same groups described in part (e), would 46 be a significantly high number of males \nin a group? Explain.\n9. Odds Ratio In a study of the relationship between headaches and body weight, there were \n4489 overweight subjects, and 331 of them experienced migraine headaches. Among 5487 sub-\njects with normal weight, 358 experienced migraine headaches (based on data from “Body \nMass Index and Episodic Headaches,” by Bigal et al., Archives of Internal Medicine, Vol. 167, \nNo. 18). Find the odds ratio and interpret the result.\n",
    "Technology Project\n1.  Bootstrapping and Robustness Consider the probability distribution defined by the \nformula P1x2 =\n3x2\n1000 where x can be any value between 0 and 10 inclusive (not just integers). \nThe accompanying graph of this probability distribution shows that its shape is very far from the \nbell shape of a normal distribution. This probability distribution has parameters m = 7.5 and \ns = 1.93649. Listed below is a simple random sample of values from this distribution, and the \nnormal quantile plot for this sample is shown. Given the very non-normal shape of the distribution, \nit is not surprising to see the normal quantile plot with points that are far from a straight-line pattern, \nconfirming that the sample does not appear to be from a normally distributed population.\n8.69 2.03 9.09 7.15 9.05 9.40 6.30 7.89 7.98 7.67\n7.77 7.17 8.86 8.29 9.21 7.80 7.70 8.12 9.11 7.64\nP1x2 = 3x2\n1000  defined on [0, 10]\nNormal Quantile Plot of 20 Sample Values\na. Mean Test the claim that the 20 given sample values are from a population having a mean equal \nto 7.5, which is the known population mean. Because the sample is not from a normally distributed \npopulation and because n = 20 does not satisfy the requirement of n 7 30, we should not use the \nmethods of Section 8-3. Instead, test the claim by using the confidence interval method based on a \nbootstrap sample of size 1000 (See Section 7-4). Use a 0.05 significance level. Does the bootstrap \nconfidence interval contain the known population mean of 7.5? Is the bootstrap method effective \nfor this test? What happens if we conduct this test by throwing all caution to the wind and con-\nstructing the 95% confidence interval by using the t distribution as described in Section 7-2?\nb. Standard Deviation Test the claim that the 20 sample values are from a population with a \nstandard deviation equal to 1.93649, which is the known population standard deviation. Use the \nconfidence interval method based on a bootstrap sample of size 1000. (See Section 7-4.) Use \na 0.05 significance level. Does the bootstrap confidence interval contain the known population \nstandard deviation of 1.93649? Is the bootstrap method effective for this test? What happens if \nwe conduct the test by throwing all caution to the wind and constructing the 95% confidence \ninterval by using the x2 distribution as described in Section 7-3?\nCHAPTER 8 Technology Project \n389\n",
    "390 \nCHAPTER 8 Hypothesis Testing\nCooperative Group Activities\n1.  Out-of-class activity In the United States, 40% of us have brown eyes, according to \nDr. P. Sorita Soni at Indiana University. Groups of three or four students should randomly \n select people and identify the color of their eyes. The claim that 40% of us have brown eyes can \nthen be tested.\n2. In-class activity After dividing into groups of between 10 and 20 people, each group mem-\nber should record the number of heartbeats in a minute. After calculating the sample mean and \nstandard deviation, each group should proceed to test the claim that the mean is greater than \n48 beats per minute, which is the result for one of the authors. (When people exercise, they \ntend to have lower pulse rates.)\n3. In-class activity Without using any measuring device, each student should draw a line be-\nlieved to be 3 in. long and another line believed to be 3 cm long. Then use rulers to measure and \nrecord the lengths of the lines drawn. Find the means and standard deviations of the two sets \nof lengths. Test the claim that the lines estimated to be 3 in. have a mean length that is equal to \n3 in. Test the claim that the lines estimated to be 3 cm have a mean length that is equal to 3 cm. \nCompare the results. Do the estimates of the 3-in. line appear to be more accurate than those \nfor the 3-cm line? What do these results suggest?\n4. In-class activity Assume that a method of gender selection can affect the probability of a \nbaby being a girl so that the probability becomes 1>4. Each student should simulate 20 births \nby drawing 20 cards from a shuffled deck. Replace each card after it has been drawn, then \nreshuffle. Consider the hearts to be girls and consider all other cards to be boys. After making \n20 selections and recording the “genders” of the babies, use a 0.10 significance level to test the \nclaim that the proportion of girls is equal to 1>4. How many students are expected to get results \nleading to the wrong conclusion that the proportion is not 1>4? How does that relate to the \nprobability of a type I error? Does this procedure appear to be effective in identifying the ef-\nfectiveness of the gender selection method? (If decks of cards are not available, use some other \nway to simulate the births, such as using the random number generator on a calculator or using \ndigits from phone numbers or Social Security numbers.)\nFROM DATA TO DECISION\nCritical Thinking: Testing the Salk Vaccine\nThe largest health experiment ever conducted involved a test of \nthe Salk vaccine designed to protect children from the devastat-\ning effects of polio. The test included 201,229 children who \nwere given the Salk vaccine, and 33 of them developed polio. \nThe claim that the Salk vaccine is effective is equivalent to the \nclaim that the proportion of vaccinated children who develop \npolio is less than 0.0000573, which was the rate of polio among \nchildren not given the Salk vaccine. (Note: The actual Salk vac-\ncine experiment involved another group of 200,745 children \nwho were injected with an ineffective salt solution instead of \nthe Salk vaccine. This study design with a treatment group and \nplacebo group is very common and very effective. Methods for \ncomparing two proportions are presented in Chapter 9.)\nAnalyzing the Results\na. Test the given claim using a 0.05 significance level. Does \nthe Salk vaccine appear to be effective?\nb. For the hypothesis test from part (a), consider the follow-\ning two errors:\n•  Concluding that the Salk vaccine is effective when it is not \neffective.\n•  Concluding that the Salk vaccine is not effective when it is \neffective.\nDetermine which of the above two errors is a type I error \nand determine which is a type II error. Which error would \nhave worse consequences? How could the hypothesis test be \nconducted in order to reduce the chance of making the more \nserious error?\n",
    "5. Out-of-class activity Groups of three or four students should go to the library and collect a \nsample consisting of the ages of books (based on copyright dates). Plan and describe the sam-\npling plan, execute the sampling procedure, and then use the results to test the claim that the \nmean age of books in the library is greater than 20 years.\n6. In-class activity A class project should be designed to conduct a test in which each student \nis given a taste of Coke and a taste of Pepsi. The student is then asked to identify which sample \nis Coke. After all of the results are collected, test the claim that the success rate is better than \nthe rate that would be expected with random guesses.\n7.  In-class activity Each student should estimate the length of the classroom. The values \nshould be based on visual estimates, with no actual measurements being taken. After the esti-\nmates have been collected, measure the length of the room, then test the claim that the sample \nmean is equal to the actual length of the classroom. Is there a “collective wisdom,” whereby the \nclass mean is approximately equal to the actual room length?\n8. Out-of-class activity Using one wristwatch that is reasonably accurate, set the time to be \nexact. Visit www.time.gov to set the exact time. If you cannot set the time to the nearest sec-\nond, record the error for the watch you are using. Now compare the time on this watch to the \ntime on other watches that have not been set to the exact time. Record the errors with negative \nsigns for watches that are ahead of the actual time and positive signs for those watches that are \nbehind the actual time. Use the data to test the claim that the mean error of all wristwatches is \nequal to 0. Do we collectively run on time, or are we early or late? Also test the claim that the \nstandard deviation of errors is less than 1 min. What are the practical implications of a standard \ndeviation that is excessively large?\n9. In-class activity In a group of three or four people, conduct an extrasensory perception \n(ESP) experiment by selecting one of the group members as the subject. Draw a circle on one \nsmall piece of paper and draw a square on another sheet of the same size. Repeat this experi-\nment 20 times: Randomly select the circle or the square and place it in the subject’s hand be-\nhind his or her back so that it cannot be seen, then ask the subject to identify the shape (without \nseeing it); record whether the response is correct. Test the claim that the subject has ESP be-\ncause the proportion of correct responses is greater than 0.5.\n10. Out-of-class activity Each student should find an article in a professional journal that \nincludes a hypothesis test of the type discussed in this chapter. Write a brief report describing \nthe hypothesis test and its role in the context of the article.\nCHAPTER 8 Cooperative Group Activities \n391\n",
    "392\nTwo Proportions\nTwo Means: \nIndependent Samples\nTwo Dependent \nSamples (Matched \nPairs)\nTwo Variances or \nStandard Deviations\n9-1\n9-2\n9-3\n9-4\nIs the “Freshman 15” Real, or Is It a Myth?\nCHAPTER \nPROBLEM \nInferences from Two \nSamples\nThere is a common and popular belief that college students \ntypically gain 15 lb (or 6.8 kg) during their freshman year. \nThis 15-lb weight gain has been dubbed the “Freshman 15.” \nReasonable explanations for this phenomenon include the \nnew stresses of college life (not including a statistics class, \nwhich is just plain fun); new eating habits; less free time \nfor physical activities; cafeteria food with an abundance of \nfat and  carbohydrates; the new freedom to choose among \na variety of foods (including sumptuous pizzas that are \njust a phone call away); and a lack of sleep that results in \nlower levels of leptin, which helps regulate appetite and \nmetabolism. But is the Freshman 15 real, or is it a myth that \nhas been perpetuated through anecdotal evidence and>or \nflawed data?\n9 \n",
    "Several studies have focused on the credibility of the \nFreshman 15 belief. We will consider one reputable study \nwith results published in the article “Changes in Body Weight \nand Fat Mass of Men and Women in the First Year of College: \nA Study of the ‘Freshman 15’,” by Daniel Hoffman, Peggy \n Policastro, Virginia Quick, and Soo-Kyung Lee, Journal of \nAmerican College Health, Vol. 55, No. 1. The authors of that ar-\nticle have provided the data from their study, and much of it is \nlisted in Data Set 10 “Freshman 15” in Appendix B. If you exam-\nine the weights in Data Set 10, you should note the following:\n• The weights in Data Set 10 are in kilograms, not pounds, \nand 15 lb is equivalent to 6.8 kg. The “Freshman 15 \n(pounds)” is equivalent to the “Freshman 6.8 kilograms.”\n• Data Set 10 includes two weights for each of the 67 study \nsubjects. Each subject was weighed in September of the \nfreshman year, and again in April of the freshman year. These \ntwo measurements were made at the beginning and end of the \nseven months of campus life that passed between the mea-\nsurements. It is important to recognize that each individual pair \nof before and after measurements is from the same student, so \nthe lists of 67 “before” weights and 67 “after” weights consti-\ntute paired data from the 67 subjects in the study.\n• Because the Freshman 15 refers to weight gained,  \nwe will use weight changes in this format:  \n(April weight) - (September weight). If a student does \ngain 15 lb, the value of (April weight) - (September \nweight) is 15 lb, or 6.8 kg. (A negative weight “gain” indi-\ncates that the student lost weight.)\n• The published article about the Freshman 15 study is \nmarked by some limitations, including these:\n1. All subjects volunteered for the study.\n2.  All of the subjects were attending Rutgers, the State Uni-\nversity of New Jersey.\nThe Freshman 15 constitutes a claim made about the pop-\nulation of college students. If we use md to denote the mean of \nall (April weight) - (September weight) differences for college \nstudents during their freshman year, the Freshman 15 is the \nclaim that md = 15 lb or md = 6.8 kg. Because the sample \nweights are measured in kilograms, we will consider the claim \nto be md = 6.8 kg. Later in this chapter, a formal hypothesis \ntest will be used to test this claim. We will then be able to reach \none of two possible conclusions: Either there is sufficient evi-\ndence to warrant rejection of the claim that md = 6.8 kg (so \nthe Freshman 15 is rejected), or we will conclude that there is \nnot sufficient evidence to warrant rejection of the claim that  \nmd = 6.8 kg (so the Freshman 15 cannot be rejected). We will \nthen be better able to determine whether the Freshman 15 is a \nmyth.\nInferential statistics involves forming conclusions (or inferences) about a population pa-\nrameter. Two major activities of inferential statistics are estimating values of population \nparameters using confidence intervals (as in Chapter 7) and testing claims made about \npopulation parameters (as in Chapter 8). Chapters 7 and 8 both involved methods for \ndealing with a sample from one population, but this chapter extends those methods to \nsituations involving two populations. Here are the chapter objectives:\nTwo Proportions\n• Conduct a formal hypothesis test of a claim made about two population proportions.\n• Construct a confidence interval estimate of the difference between two population \nproportions.\nTwo Means: Independent Samples\n• Distinguish between a situation involving two independent samples and a situation \ninvolving two samples that are not independent.\n9-1\n9-2\nChapter Objectives \n393\nCHAPTER OBJECTIVES\n>>>\n",
    "394 \nCHAPTER 9 Inferences from Two Samples\nKey Concept In this section we present methods for (1) testing a claim made about \ntwo population proportions and (2) constructing a confidence interval estimate of the \ndifference between two population proportions. The methods of this chapter can also \nbe used with probabilities or the decimal equivalents of percentages.\n9-1 \nTwo Proportions\n• Conduct a formal hypothesis test of a claim made about two independent  populations.\n• Construct a confidence interval estimate of the difference between the means of \ntwo independent populations.\nTwo Dependent Samples (Matched Pairs)\n• Identify sample data consisting of matched pairs.\n• Conduct a formal hypothesis test of a claim made about the mean of the differences \nbetween matched pairs.\n• Construct a confidence interval estimate of the mean difference between matched pairs.\nTwo Variances or Standard Deviations\n• Develop the ability to conduct a formal hypothesis test of a claim made about two \npopulation standard deviations or variances.\n9-3\n9-4\n• Conduct a formal hypothesis test of a claim made about two independent populations.\n• Construct a confidence interval estimate of the difference between the means of\ntwo independent populations.\nTwo Dependent Samples (Matched Pairs)\n• Identify sample data consisting of matched pairs.\n• Conduct a formal hypothesis test of a claim made about the mean of the differences \nbetween matched pairs.\n• Construct a confidence interval estimate of the mean difference between matched pairs.\nTwo Variances or Standard Deviations\nTw\nT\n• Develop the ability to conduct a formal hypothesis test of a claim made about two\npopulation standard deviations or variances.\nInferences About Two Proportions\nObjectives\nKEY ELEMENTS \n1. Hypothesis Test: Conduct a hypothesis test of a claim \nabout two population proportions.\n2. Confidence Interval: Construct a confidence interval \nestimate of the difference between two population \nproportions.\nNotation for Two Proportions\nFor population 1 we let\np1 = population proportion \npn1 = x1\nn1\n  (sample proportion)\nn1 = size of the first sample \nqn1 = 1 - pn1 (complement of pn1)\nx1 = number of successes in the first sample\nThe corresponding notations p2, n2, x2, pn2, and qn2 apply to population 2.\nPooled Sample Proportion\nThe pooled sample proportion is denoted by p and it combines the two sample proportions into one proportion, as \nshown here:\np = x1 + x2\nn1 + n2\nq = 1 - p\ncontinued\n",
    "9-1 Two Proportions \n395\nEquivalent Methods\nWhen testing a claim about two population proportions:\n \n■The P-value method and the critical value method are equivalent.\n \n■The confidence interval method is not equivalent to the P-value method or the \ncritical value method.\nRecommendation: If you want to test a claim about two population proportions, use \nthe P-value method or critical value method; if you want to estimate the difference \nbetween two population proportions, use the confidence interval method.\nHypothesis Tests\nFor tests of hypotheses made about two population proportions, we consider only \ntests having a null hypothesis of p1 = p2 (so the null hypothesis is H0: p1 = p2).\nWith the assumption that p1 = p2, the estimates of pn1 and pn2 are combined to provide \nthe best estimate of the common value of pn1 and pn2, and that combined value is the \npooled sample proportion p given in the preceding Key Elements box. The follow-\ning example will help clarify the roles of x1, n1, pn1, p, and so on. Note that with the \nRequirements\n1. The sample proportions are from two simple random \nsamples.\n2. The two samples are independent. (Samples are inde-\npendent if the sample values selected from one popula-\ntion are not related to or somehow naturally paired or \nmatched with the sample values selected from the other \npopulation.)\n3. For each of the two samples, there are at least 5 suc-\ncesses and at least 5 failures. (That is, npn Ú 5 and \nnqn Ú 5 for each of the two samples).\nTest Statistic for Two Proportions (with H0: p1 = p2)\nz = 1pn1 - pn22 - 1p1 - p22\nA\np q\nn1\n+ p q\nn2\n where p1 - p2 = 0 (assumed in the null hypothesis)\nwhere p = x1 + x2\nn1 + n2\n (pooled sample proportion) and q = 1 - p\nP-Value: P-values are automatically provided by technol-\nogy. If technology is not available, use Table A-2 (standard \nnormal distribution) and find the P-value using the proce-\ndure given in Figure 8-3 on page 344 from Section 8-1.\nCritical Values: Use Table A-2. (Based on the signifi-\ncance level a, find critical values by using the same proce-\ndures introduced in Section 8-1.)\nConfidence Interval Estimate of p1 −p2\nThe confidence interval estimate of the difference p1 - p2 is\n1pn1 - pn22 - E 6 1p1 - p22 6 1pn1 - pn22 + E\nwhere the margin of error E is given by\nE = za>2B\npn1qn1\nn1\n+ pn2qn2\nn2\nRounding: Round the confidence interval limits to three significant digits.\n",
    "396 \nCHAPTER 9 Inferences from Two Samples\nassumption of equal population proportions, the best estimate of the common popula-\ntion proportion is obtained by pooling both samples into one big sample, so that p is \nthe estimator of the common population proportion.\nP-Value Method\nEXAMPLE 1  Do Airbags Save Lives?\nThe table below lists results from a simple random sample of front-seat occupants \ninvolved in car crashes (based on data from “Who Wants Airbags?” by Meyer and \nFinney, Chance, Vol. 18, No. 2). Use a 0.05 significance level to test the claim that \nthe fatality rate of occupants is lower for those in cars equipped with airbags.\nAirbag Available\nNo Airbag Available\nOccupant Fatalities\n41\n52\nTotal number of occupants\n11,541\n9,853\nSOLUTION\nREQUIREMENT CHECK We first verify that the three necessary requirements are sat-\nisfied. (1) The data are from two simple random samples. (2) The two samples are \nindependent of each other. (3) The airbag group includes 41 occupants who were \nkilled and 11,500 occupants who were not killed, so the number of successes is at \nleast 5 and the number of failures is at least 5. The second group includes 52 occu-\npants who were killed and 9801 who were not killed, so the number of successes is \nat least 5 and the number of failures is at least 5. The requirements are satisfied. \nWe will use the P-value method of hypothesis testing, as summarized in \n Figure 8-1 on page 340. In the following steps we stipulate that the group with \nairbags is Sample 1, and the group without airbags is Sample 2.\nStep 1: The claim that the fatality rate is lower for those with airbags can be ex-\npressed as p1 6 p2.\nStep 2: If p1 6 p2 is false, then p1 Ú p2.\nStep 3: Because the claim of p1 6 p2  does not contain equality, it becomes the al-\nternative hypothesis. The null hypothesis is the statement of equality, so we have\nH0: p1 = p2  H1: p1 6 p2 1original claim2\nStep 4: The significance level is a = 0.05.\nStep 5: This step and the following step can be circumvented by using technol-\nogy; see the display that follows this example. If not using technology, we use the \nnormal distribution (with the test statistic given earlier in the Key Elements box) as \nan approximation to the binomial distribution. We estimate the common value of \np1 and p2 with the pooled sample estimate p calculated as shown below, with extra \ndecimal places used to minimize rounding errors in later calculations.\np = x1 + x2\nn1 + n2\n=\n41 + 52\n11,541 + 9,853 = 0.004347\nWith p = 0.004347, it follows that q = 1 - 0.004347 = 0.995653.\n",
    "9-1 Two Proportions \n397\nStep 6: We can now find the value of the test statistic. Note that the null hypothesis \nassumption of p1 = p2 implies that p1 - p2 = 0 in the following calculation.\n z = 1pn1 - pn22 - 1p1 - p22\nA\np q\nn1\n+ p q\nn2\n \n =\na\n41\n11,541 -\n52\n9,853b - 0\nB\n10.0043472 10.9956532\n11,541\n+ 10.0043472 10.9956532\n9,853\n \n = -1.91\nThis is a left-tailed test, so the P-value is the area to the left of the test statistic \nz = -1.91 (as indicated by Figure 8-3 on page 344). Refer to Table A-2 and find \nthat the area to the left of the test statistic z = -1.91 is 0.0281, so the P-value is \n0.0281. (Technology provides a more accurate P-value of 0.0280.) The test statistic \nand P-value are shown in Figure 9-1(a).\nStep 7: Because the P-value of 0.0281 is less than the significance level of a = 0.05, \nwe reject the null hypothesis of p1 = p2. (“If the P is low, the null must go.”)\nINTERPRETATION\nWe must address the original claim that the fatality rate is lower for occupants in \ncars equipped with airbags. Because we reject the null hypothesis, we conclude \nthat there is sufficient evidence to support the claim that the proportion of accident \nfatalities for occupants in cars with airbags is less than the proportion of fatalities \nfor occupants in cars without airbags. (See Table 8-3 on page 346 for help in word-\ning the final conclusion.) Based on these results, there appears to be strong evidence \nthat drivers in cars with airbags are at lower risk of a fatality.\nThe sample data used in this example are only part of the data given in the \narticle cited in the statement of the problem. If all of the available data are used, the \ntest statistic becomes z = -57.76, and the P-value is very close to 0, so using all of \nthe data provides even more compelling evidence of the effectiveness of airbags in \nsaving lives.\np1 2 p2 5 0\n or\n  z  5 0\nTest Statistic:\nz 5 21.91\nP-value 5 0.0281\n \nTest Statistic:\nz 5 21.91\np1 2 p2 5 0\n or\n  z  5 0\na 5 0.05\nz  = –1.645\nFIGURE 9-1 Testing the Claim of a Lower Fatality Rate with Airbags\n(a) P-Value method \n(b) Critical Value Method\n",
    "398 \nCHAPTER 9 Inferences from Two Samples\nTechnology Software and calculators usually provide a P-value, so the P-value \nmethod is typically used for testing a claim about two proportions. See the accom-\npanying Statdisk results from Example 1 showing the test statistic of z = -1.91\n(rounded) and the P-value of 0.0280.\nStatdisk\nCritical Value Method\nThe critical value method of testing hypotheses can also be used for Example 1. In \nStep 6, instead of finding the P-value, find the critical value. With a significance level \nof a = 0.05 in a left-tailed test based on the normal distribution, we refer to Table A-2 \nand find that an area of a = 0.05 in the left tail corresponds to the critical value of \nz = -1.645. In Figure 9-1(b) we can see that the test statistic of z = -1.91 falls within \nthe critical region beyond the critical value of -1.645. We again reject the null hypoth-\nesis. The conclusions are the same as in Example 1.\nConfidence Intervals\nUsing the format given in the preceding Key Elements box, we can construct a confi-\ndence interval estimate of the difference between population proportions (p1 - p2). If \na confidence interval estimate of p1 - p2 does not include 0, we have evidence sug-\ngesting that p1 and p2 have different values. The confidence interval uses a standard \ndeviation based on the use of sample proportions, whereas a hypothesis test uses a \nstandard deviation based on the assumption that the two population proportions are \nequal and their common value is estimated by pooling the sample proportions. Conse-\nquently, a conclusion based on a confidence interval might be different from a conclu-\nsion based on a hypothesis test. See the caution that follows Example 2.\nEXAMPLE 2   Confidence Interval for Claim About  \nTwo Proportions\nUse the sample data given in Example 1 to construct a 90% confidence interval esti-\nmate of the difference between the two population proportions. What does the result \nsuggest about the claim that “the fatality rate of occupants is lower for those in cars \nequipped with airbags”?\nSOLUTION\nREQUIREMENT CHECK We are using the same data from Example 1, and the same \nrequirement check applies here, so the requirements are satisfied. \nThe confidence interval can be found using technology; see the preceding \n Statdisk display. If not using technology, proceed as follows.\n",
    "9-1 Two Proportions \n399\nWith a 90% confidence level, za>2 = 1.645 (from Table A-2). We first calculate \nthe value of the margin of error E as shown here.\n E = za>2 B\npn1qn1\nn1\n+ pn2qn2\nn2\n= 1.645 S\na\n41\n11,541ba11,500\n11,541b\n11,541\n+\na 52\n9,853ba 9801\n9,853b\n9,853\n= 0.001507\nWith pn1 - pn2 = 41>11,541 - 52>9,853 = -0.001725 and E = 0.001507, the \nconfidence interval is evaluated as follows, with the confidence interval limits \nrounded to three significant digits:\n 1pn1 - pn22 - E 6 1p1 - p22 6 1pn1 - pn22 + E\n-0.001725 - 0.001507 6 1p1 - p22 6 -0.001725 + 0.001507\n - 0.00323 6 1p1 - p22 6 -0.000218\nSee the preceding Statdisk display showing the same confidence interval obtained \nhere.\nINTERPRETATION\nThe confidence interval limits do not contain 0, suggesting that there is a significant \ndifference between the two proportions. The confidence interval suggests that the \nfatality rate is lower for occupants in cars with airbags than for occupants in cars \nwithout airbags. The confidence interval also provides an estimate of the amount of \nthe difference between the two fatality rates.\nA confidence interval provides additional information beyond just a decision on \nwhether or not to reject a hypothesis. It also provides information about the range \nof plausible values of the true risk difference. In this example, the range of values \nin the confidence interval is roughly -0.003 to -0.002. We can translate these \n numbers into rates by multiplying by some population size, say, 1000. Using the \n90% confidence interval, we estimate that drivers without airbags are at increased \nrisk of a fatal car accident by somewhere between 2 and 3 additional fatalities per \n1000 occupants.\nCAUTION Use of One Confidence Interval Don’t test for equality of two \npopulation proportions by determining whether there is an overlap between \ntwo individual confidence interval estimates of the two individual population \nproportions. When compared to the confidence interval estimate of p1 - p2, \nthe analysis of overlap between two individual confidence intervals is more \nconservative (by rejecting equality less often), and it has less power (because it is \nless likely to reject p1 - p2 when in reality p1 ≠p2). See Exercise 25 “Overlap of \nConfidence Intervals.”\nWhat Can We Do When the Requirements Are Not Satisfied?\nBad Samples If we violate the requirement that we have two simple random samples, \nwe could be in big trouble. For example, if we have two convenience samples, there is \nprobably nothing that can be done to salvage them.\nFewer Than 5 Successes or Fewer Than 5 Failures in a Hypothesis Test If we vio-\nlate the requirement that each of the two samples has at least 5 successes and at least 5 \n",
    "400 \nCHAPTER 9 Inferences from Two Samples\nfailures, we can use Fisher’s exact test, which provides an exact P-value instead of using \nthe method based on a normal distribution approximation. Fisher’s exact test involves \nvery complicated calculations, so the use of technology is strongly recommended. \nStatdisk, Minitab, XLSTAT, and StatCrunch all have the ability to perform Fisher’s ex-\nact test. (See Section 11-2.)\nFewer Than 5 Successes or Fewer Than 5 Failures in a Confidence Interval If we \nviolate the requirement that each of the two samples has at least 5 successes and at \nleast 5 failures, we can use bootstrap resampling methods to construct a confidence \ninterval. See Section 7-4.\nRationale: Why Do the Procedures of This Section Work?\nHypothesis Tests With n1pn1 Ú 5 and n1qn1 Ú 5, the distribution of pn1 can be approxi-\nmated by a normal distribution with mean p1, standard deviation 1p1q1>n1, and vari-\nance p1q1\n >  n1 (based on Sections 6-6 and 7-1). This also applies to the second sample. \nThe distributions of pn1 and pn2 are each approximated by a normal distribution, so \nthe difference pn1 - pn2 will also be approximated by a normal distribution with mean \np1 - p2 and variance\ns2\n1p1-p22 = s2\np1 + s2\np2 = p1q1\nn1\n+ p2q2\nn2\n(The result above is based on this property: The variance of the differences between \ntwo independent random variables is the sum of their individual variances.)\nThe pooled estimate of the common value of p1 and p2 is p =  \n1x1 + x22>1n1 + n22. If we replace p1 and p2 by p and replace q1 and q2 by \nq = 1 - p, the variance above leads to the following standard deviation:\ns1p1-p22 = A\np q\nn1\n+ p q\nn2\nWe now know that the distribution of pn1 - pn2 is approximately normal, with mean \np1 - p2 and standard deviation as shown above, so the z test statistic has the form \ngiven in the Key Elements box near the beginning of this section.\nConfidence Interval The form of the confidence interval requires an expression for \nthe variance different from the one given above. When constructing a confidence in-\nterval estimate of the difference between two proportions, we don’t assume that the \ntwo proportions are equal, and we estimate the standard deviation as\nB\npn1qn1\nn1\n+ pn2qn2\nn2\nIn the test statistic\nz = 1pn1 - pn22 - 1p1 - p22\nB\npn1qn1\nn1\n+ pn2qn2\nn2\nuse the positive and negative values of z (for two tails) and solve for p1 - p2. The \nresults are the limits of the confidence interval given in the Key Elements box near the \nbeginning of this section.\nn n\nn\nn\nn n\nInferences with Two Proportions\nAccess tech instructions, videos, and data sets at www.TriolaStats.com\nTECH CENTER \n",
    "9-1 Two Proportions \n401\nStatistical Literacy and Critical Thinking \n1. Verifying Requirements In the largest clinical trial ever conducted, 401,974 children were \nrandomly assigned to two groups. The treatment group consisted of 201,229 children given the \nSalk vaccine for polio, and 33 of those children developed polio. The other 200,745 children \nwere given a placebo, and 115 of those children developed polio. If we want to use the methods \nof this section to test the claim that the rate of polio is less for children given the Salk vaccine, \nare the requirements for a hypothesis test satisfied? Explain.\n2. Notation For the sample data given in Exercise 1, consider the Salk vaccine treatment group \nto be the first sample. Identify the values of n1, pn1, qn1, n2, pn2, qn2, p, and q. Round all values so \nthat they have six significant digits.\n3. Hypotheses and Conclusions Refer to the hypothesis test described in Exercise 1.\na. Identify the null hypothesis and the alternative hypothesis.\nb. If the P-value for the test is reported as “less than 0.001,” what should we conclude about the \noriginal claim?\n4. Using Confidence Intervals\na. Assume that we want to use a 0.05 significance level to test the claim that p1 6 p2. Which is \nbetter: a hypothesis test or a confidence interval?\nb. In general, when dealing with inferences for two population proportions, which two of the \nfollowing are equivalent: confidence interval method; P-value method; critical value method?\nc. If we want to use a 0.05 significance level to test the claim that p1 6 p2, what confidence \nlevel should we use for the confidence interval?\nd. If we test the claim in part (c) using the sample data in Exercise 1, we get this confidence \ninterval: -0.000508 6 p1 - p2 6 -0.000309. What does this confidence interval suggest \nabout the claim?\nInterpreting Displays. In Exercises 5 and 6, use the results from the given displays.\n5. Testing Laboratory Gloves The New York Times published an article about a study in \nwhich Professor Denise Korniewicz and other Johns Hopkins researchers subjected laboratory \ngloves to stress. Among 240 vinyl gloves, 63% leaked viruses. Among 240 latex gloves, 7% \nleaked viruses. See the accompanying display of the Statdisk results. Using a 0.01 significance \nlevel, test the claim that vinyl gloves have a greater virus leak rate than latex gloves.\n9-1  Basic Skills and Concepts\nStatdisk\n6. Treating Carpal Tunnel Syndrome Carpal tunnel syndrome is a common wrist complaint \nresulting from a compressed nerve, and it is often the result of extended use of repetitive wrist \nmovements, such as those associated with the use of a keyboard. In a randomized controlled \ntrial, 73 patients were treated with surgery and 67 were found to have successful treatments. \nAmong 83 patients treated with splints, 60 were found to have successful treatments (based on \ndata from “Splinting vs Surgery in the Treatment of Carpal Tunnel Syndrome,” by Gerritsen \nStatCrunch\ncontinued\n",
    "402 \nCHAPTER 9 Inferences from Two Samples\net al., Journal of the American Medical Association, Vol. 288, No. 10). Use the accompanying \nStatCrunch display with a 0.01 significance level to test the claim that the success rate is better \nwith surgery.\nTesting Claims About Proportions. In Exercises 7–22, test the given claim. Identify the \nnull hypothesis, alternative hypothesis, test statistic, P-value or critical value(s), then state \nthe conclusion about the null hypothesis, as well as the final conclusion that addresses the \noriginal claim.\n7. Ginkgo for Dementia The herb ginkgo biloba is commonly used as a treatment to prevent \ndementia. In a study of the effectiveness of this treatment, 1545 elderly subjects were given \nginkgo and 1524 elderly subjects were given a placebo. Among those in the ginkgo treatment \ngroup, 246 later developed dementia, and among those in the placebo group, 277 later devel-\noped dementia (based on data from “Ginkgo Biloba for Prevention of Dementia,” by DeKosky \net al., Journal of the American Medical Association, Vol. 300, No. 19). We want to use a 0.01 \nsignificance level to test the claim that ginkgo is effective in preventing dementia.\na. Test the claim using a hypothesis test.\nb. Test the claim by constructing an appropriate confidence interval.\nc. Based on the results, is ginkgo effective in preventing dementia?\n8. Clinical Trials of Lipitor Lipitor (atorvastatin) is a drug used to control cholesterol. In \nclinical trials of Lipitor, 94 subjects were treated with Lipitor and 270 subjects were given a \nplacebo. Among those treated with Lipitor, 7 developed infections. Among those given a pla-\ncebo, 27 developed infections. We want to use a 0.05 significance level to test the claim that the \nrate of infections was the same for those treated with Lipitor and those given a placebo.\na. Test the claim using a hypothesis test.\nb. Test the claim by constructing an appropriate confidence interval.\nc. Based on the results, is the rate of infections different for those treated with Lipitor?\n9. Smoking Cessation Programs Among 198 smokers who underwent a “sustained care” \nprogram, 51 were no longer smoking after six months. Among 199 smokers who underwent \na “standard care” program, 30 were no longer smoking after six months (based on data from \n“Sustained Care Intervention and Postdischarge Smoking Cessation Among Hospitalized \nAdults,” by Rigotti et al., Journal of the American Medical Association, Vol. 312, No. 7). We \nwant to use a 0.01 significance level to test the claim that the rate of success for smoking cessa-\ntion is greater with the sustained care program.\na. Test the claim using a hypothesis test.\nb. Test the claim by constructing an appropriate confidence interval.\nc. Does the difference between the two programs have practical significance?\n10. Are Radiation Effects the Same for Men and Women? Among 2739 female atom \nbomb survivors, 1397 developed thyroid diseases. Among 1352 male atom bomb survivors, \n436 developed thyroid diseases (based on data from “Radiation Dose-Response Relationships \nfor Thyroid Nodules and Autoimmune Thyroid Diseases in Hiroshima and Nagasaki Atomic \nBomb Survivors 55–58 Years After Radiation Exposure,” by Imaizumi et al., Journal of the \nAmerican Medical Association, Vol. 295, No. 9).\na. Use a 0.01 significance level to test the claim that female survivors and male survivors have \ndifferent rates of thyroid diseases.\nb. Construct the confidence interval corresponding to the hypothesis test conducted with a 0.01 \nsignificance level. What conclusion does the confidence interval suggest?\n11. Dreaming in Black and White A study was conducted to determine the proportion of peo-\nple who dream in black and white instead of color. Among 306 people over the age of 55, 68 \n",
    "9-1 Two Proportions \n403\ndream in black and white, and among 298 people under the age of 25, 13 dream in black and \nwhite (based on data from “Do We Dream in Color?” by Eva Murzyn, Consciousness and Cogni-\ntion, Vol. 17, No. 4). We want to use a 0.01 significance level to test the claim that the proportion \nof people over 55 who dream in black and white is greater than the proportion of those under 25.\na. Test the claim using a hypothesis test.\nb. Test the claim by constructing an appropriate confidence interval.\nc. An explanation given for the results is that those over the age of 55 grew up exposed to \nmedia that were mostly displayed in black and white. Can the results from parts (a) and (b) be \nused to verify that explanation?\n12. Clinical Trials of OxyContin OxyContin (oxycodone) is a drug used to treat pain, but \nit is well known for its addictiveness and danger. In a clinical trial, among subjects treated \nwith OxyContin, 52 developed nausea and 175 did not develop nausea. Among other subjects \ngiven placebos, 5 developed nausea and 40 did not develop nausea (based on data from Purdue \nPharma L.P.). Use a 0.05 significance level to test for a difference between the rates of nausea \nfor those treated with OxyContin and those given a placebo.\na. Use a hypothesis test.\nb. Use an appropriate confidence interval.\nc. Does nausea appear to be an adverse reaction resulting from OxyContin?\n13. Are Seat Belts Effective? A simple random sample of front-seat occupants involved in \ncar crashes is obtained. Among 2823 occupants not wearing seat belts, 31 were killed. Among \n7765 occupants wearing seat belts, 16 were killed (based on data from “Who Wants Airbags?” \nby Meyer and Finney, Chance, Vol. 18, No. 2). We want to use a 0.05 significance level to test \nthe claim that seat belts are effective in reducing fatalities.\na. Test the claim using a hypothesis test.\nb. Test the claim by constructing an appropriate confidence interval.\nc. What does the result suggest about the effectiveness of seat belts?\n14. Cardiac Arrest at Day and Night A study investigated survival rates for in-hospital pa-\ntients who suffered cardiac arrest. Among 58,593 patients who had cardiac arrest during the \nday, 11,604 survived and were discharged. Among 28,155 patients who suffered cardiac arrest \nat night, 4139 survived and were discharged (based on data from “Survival from In-Hospital \nCardiac Arrest During Nights and Weekends,” by Peberdy et al., Journal of the American Medi-\ncal Association, Vol. 299, No. 7). We want to use a 0.01 significance level to test the claim that \nthe survival rates are the same for day and night.\na. Test the claim using a hypothesis test.\nb. Test the claim by constructing an appropriate confidence interval.\nc. Based on the results, does it appear that for in-hospital patients who suffer cardiac arrest, the \nsurvival rate is the same for day and night?\n15. Is Echinacea Effective for Colds? Rhinoviruses typically cause common colds. In a test \nof the effectiveness of echinacea, 40 of the 45 subjects treated with echinacea developed rhi-\nnovirus infections. In a placebo group, 88 of the 103 subjects developed rhinovirus infections \n(based on data from “An Evaluation of Echinacea angustifolia in Experimental Rhinovirus In-\nfections,” by Turner et al., New England Journal of Medicine, Vol. 353, No. 4). We want to use \na 0.05 significance level to test the claim that echinacea has an effect on rhinovirus infections.\na. Test the claim using a hypothesis test.\nb. Test the claim by constructing an appropriate confidence interval.\nc. Based on the results, does echinacea appear to have any effect on the infection rate?\n",
    "404 \nCHAPTER 9 Inferences from Two Samples\n16. Bednets to Reduce Malaria In a randomized controlled trial in Kenya, insecticide-treated \nbednets were tested as a way to reduce malaria. Among 343 infants using bednets, 15 devel-\noped malaria. Among 294 infants not using bednets, 27 developed malaria (based on data from \n“Sustainability of Reductions in Malaria Transmission and Infant Mortality in Western Kenya \nwith Use of Insecticide-Treated Bednets,” by Lindblade et al., Journal of the American Medical \nAssociation, Vol. 291, No. 21). We want to use a 0.01 significance level to test the claim that the \nincidence of malaria is lower for infants using bednets.\na. Test the claim using a hypothesis test.\nb. Test the claim by constructing an appropriate confidence interval.\nc. Based on the results, do the bednets appear to be effective?\n17. Cell Phones and Handedness A study was conducted to investigate the association \nbetween cell phone use and hemispheric brain dominance. Among 216 subjects who prefer to \nuse their left ear for cell phones, 166 were right-handed. Among 452 subjects who prefer to \nuse their right ear for cell phones, 436 were right-handed (based on data from “Hemispheric \nDominance and Cell Phone Use,” by Seidman et al., JAMA Otolaryngology—Head & Neck \nSurgery, Vol. 139, No. 5). We want to use a 0.01 significance level to test the claim that the rate \nof right-handedness for those who prefer to use their left ear for cell phones is less than the rate \nof right-handedness for those who prefer to use their right ear for cell phones. (Try not to get \ntoo confused here.)\na. Test the claim using a hypothesis test.\nb. Test the claim by constructing an appropriate confidence interval.\n18. Denomination Effect A trial was conducted with 75 women in China given a 100-yuan \nbill, while another 75 women in China were given 100 yuan in the form of smaller bills (a \n50-yuan bill plus two 20-yuan bills plus two 5-yuan bills). Among those given the single bill, \n60 spent some or all of the money. Among those given the smaller bills, 68 spent some or all \nof the money (based on data from “The Denomination Effect,” by Raghubir and Srivastava, \n Journal of Consumer Research, Vol. 36). We want to use a 0.05 significance level to test the \nclaim that when given a single large bill, a smaller proportion of women in China spend some or \nall of the money when compared to the proportion of women in China given the same amount \nin smaller bills.\na. Test the claim using a hypothesis test.\nb. Test the claim by constructing an appropriate confidence interval.\nc. If the significance level is changed to 0.01, does the conclusion change?\n19. Headache Treatment In a study of treatments for very painful “cluster” headaches, 150 \npatients were treated with oxygen and 148 other patients were given a placebo consisting of \nordinary air. Among the 150 patients in the oxygen treatment group, 116 were free from head-\naches 15 minutes after treatment. Among the 148 patients given the placebo, 29 were free from \nheadaches 15 minutes after treatment (based on data from “High-Flow Oxygen for Treatment \nof Cluster Headache,” by Cohen, Burns, and Goadsby, Journal of the American Medical As-\nsociation, Vol. 302, No. 22). We want to use a 0.01 significance level to test the claim that the \noxygen treatment is effective.\na. Test the claim using a hypothesis test.\nb. Test the claim by constructing an appropriate confidence interval.\nc. Based on the results, is the oxygen treatment effective?\n20. Does Aspirin Prevent Heart Disease? In a trial designed to test the effectiveness of aspirin \nin preventing heart disease, 11,037 male physicians were treated with aspirin and 11,034 male \nphysicians were given placebos. Among the subjects in the aspirin treatment group, 139 experi-\nenced myocardial infarctions (heart attacks). Among the subjects given placebos, 239 experienced \n",
    "9-1 Two Proportions \n405\nmyocardial infarctions (based on data from “Final Report on the Aspirin Component of the Ongo-\ning Physicians’ Health Study,” New England Journal of Medicine, Vol. 321: 129–135). Use a 0.05 \nsignificance level to test the claim that aspirin has no effect on myocardial infarctions.\na. Test the claim using a hypothesis test.\nb. Test the claim by constructing an appropriate confidence interval.\nc. Based on the results, does aspirin appear to be effective?\n21. Lefties In a random sample of males, it was found that 23 write with their left hands and \n217 do not. In a random sample of females, it was found that 65 write with their left hands and \n455 do not (based on data from “The Left-Handed: Their Sinister History,” by Elaine Fowler \nCostas, Education Resources Information Center, Paper 399519). We want to use a 0.01 sig-\nnificance level to test the claim that the rate of left-handedness among males is less than that \namong females.\na. Test the claim using a hypothesis test.\nb. Test the claim by constructing an appropriate confidence interval.\nc. Based on the results, is the rate of left-handedness among males less than the rate of left-\nhandedness among females?\n22. Ground vs. Helicopter for Serious Injuries A study investigated rates of fatalities \namong patients with serious traumatic injuries. Among 61,909 patients transported by heli-\ncopter, 7813 died. Among 161,566 patients transported by ground services, 17,775 died (based \non data from “Association Between Helicopter vs Ground Emergency Medical Services and \nSurvival for Adults with Major Trauma,” by Galvagno et al., Journal of the American Medical \nAssociation, Vol. 307, No. 15). Use a 0.01 significance level to test the claim that the rate of \nfatalities is higher for patients transported by helicopter.\na. Test the claim using a hypothesis test.\nb. Test the claim by constructing an appropriate confidence interval.\nc. Considering the test results and the actual sample rates, is one mode of transportation better \nthan the other? Are there other important factors to consider?\n23. Determining Sample Size The sample size needed to estimate the difference between \ntwo population proportions to within a margin of error E with a confidence level of 1 - a can \nbe found by using the following expression:\nE = za>2A\np1q1\nn1\n+ p2q2\nn2\nReplace n1 and n2 by n in the formula above (assuming that both samples have the same size) \nand replace each of p1, q1, p2, and q2 by 0.5 (because their values are not known). Solving for \nn results in this expression:\nn =\nz2\na>2\n2E 2\nUse this expression to find the size of each sample if you want to estimate the difference \nbetween the proportions of men and women who consume medication daily. Assume that you \nwant 95% confidence that your error is no more than 0.03.\n24. Yawning and Fisher’s Exact Test In one segment of the TV series Mythbusters, an ex-\nperiment was conducted to test the common belief that people are more likely to yawn when \nthey see others yawning. In one group, 34 subjects were exposed to yawning, and 10 of them \n9-1  Beyond the Basics\ncontinued\n",
    "406 \nCHAPTER 9 Inferences from Two Samples\nyawned. In another group, 16 subjects were not exposed to yawning, and 4 of them yawned. We \nwant to test the belief that people are more likely to yawn when they are exposed to yawning.\na. Why can’t we test the claim using the methods of this section?\nb. If we ignore the requirements and use the methods of this section, what is the P-value? How \ndoes it compare to the P-value of 0.5128 obtained by using Fisher’s exact test?\nc. Comment on the conclusion of the Mythbusters segment that yawning is contagious.\n25. Overlap of Confidence Intervals In the article “On Judging the Significance of \n Differences by Examining the Overlap Between Confidence Intervals,” by Schenker and \nGentleman (American Statistician, Vol. 55, No. 3), the authors consider sample data in this \nstatement: “Independent simple random samples, each of size 200, have been drawn, and \n112 people in the first sample have the attribute, whereas 88 people in the second sample have \nthe attribute.”\na. Use the methods of this section to construct a 95% confidence interval estimate of the differ-\nence p1 - p2. What does the result suggest about the equality of p1 and p2?\nb. Use the methods of Section 7-1 to construct individual 95% confidence interval estimates \nfor each of the two population proportions. After comparing the overlap between the two confi-\ndence intervals, what do you conclude about the equality of p1 and p2?\nc. Use a 0.05 significance level to test the claim that the two population proportions are equal. \nWhat do you conclude?\nd. On the basis of the preceding results, what should you conclude about the equality of p1 \nand p2? Which of the three preceding methods is least effective in testing for the equality of \np1 and p2?\n26. Equivalence of Hypothesis Test and Confidence Interval Two different simple ran-\ndom samples are drawn from two different populations. The first sample consists of 20 people, \nwith 10 having a common attribute. The second sample consists of 2000 people, with 1404 of \nthem having the same common attribute. Compare the results from a hypothesis test of p1 = p2 \n(with a 0.05 significance level) and a 95% confidence interval estimate of p1 - p2.\nKey Concept This section presents methods for using sample data from two inde-\npendent samples to test hypotheses made about two population means or to construct \nconfidence interval estimates of the difference between two population means. In \nPart 1 we discuss situations in which the standard deviations of the two populations \nare unknown and are not assumed to be equal. In Part 2 we briefly discuss two other \nsituations: (1) The two population standard deviations are unknown but are assumed \nto be equal; (2) the unrealistic case in which two population standard deviations are \nboth known.\nPART 1\nIndependent Samples: S1 and S2 Unknown \nand Not Assumed Equal\nThis section involves two independent samples, and the following section deals with \nsamples that are dependent. It is important to know the difference between indepen-\ndent samples and dependent samples.\n9-2 \nTwo Means: Independent Samples\n",
    "9-2 Two Means: Independent Samples \n407\nHere is an example of independent samples and another example of dependent \nsamples:\n \n■Independent Samples: Heights of Men and Women Data Set 1 “Body Data” in \nAppendix B includes the following heights (cm) of samples of men and women, \nand the two samples are not matched according to some inherent relationship. \nThey are actually two independent samples that just happen to be listed in a way \nthat might cause us to incorrectly think that they are matched.\n Heights 1cm2 of Men \n 172 154 156 158 169\n Heights 1cm2 of Women  186 161 179 167 179\n \n■Dependent Samples: Heights of Husbands and Wives Students of one of the \nauthors collected data consisting of the heights (cm) of husbands and the heights \n(cm) of their wives. Five of those pairs of heights are listed below. These two \nsamples are dependent, because the height of each husband is matched with the \nheight of his wife.\n Height 1cm2 of Husband  175 180 173 176 178\n Height 1cm2 of Wife \n 160 165 163 162 166\nFor inferences about means from two independent populations, the following box \nsummarizes key elements of a hypothesis test and a confidence interval estimate of the \ndifference between the population means.\nDEFINITIONS\nTwo samples are independent if the sample values from one population are not \nrelated to or somehow naturally paired or matched with the sample values from the \nother population.\nTwo samples are dependent (or consist of matched pairs) if the sample values \nare somehow matched, where the matching is based on some inherent relation-\nship. (That is, each pair of sample values consists of two measurements from the \nsame subject—such as before>after data—or each pair of sample values consists \nof matched pairs—such as husband>wife data—where the matching is based on \nsome meaningful relationship. Caution: “Dependence” does not require a direct \ncause>effect relationship.)\nHINT If the two samples have different sample sizes with no missing data, they \nmust be independent. If the two samples have the same sample size, the samples \nmay or may not be independent.\nInferences About Two Means: Independent Samples\nObjectives\nKEY ELEMENTS \n1. Hypothesis Test: Conduct a hypothesis test of a \nclaim about two independent population means.\n2. Confidence Interval: Construct a confidence \ninterval estimate of the difference between two \nindependent population means.\ncontinued\n",
    "408 \nCHAPTER 9 Inferences from Two Samples\nNotation\nFor population 1 we let\nm1 = population mean \nx1 = sample mean\ns1 = population standard deviation \ns1 = sample standard deviation\nn1 = size of the first sample\nThe corresponding notations m2, s2, x2, s2, and n2, apply to population 2.\nRequirements\n1. The values of s1 and s2 are unknown and we do not as-\nsume that they are equal.\n2. The two samples are independent.\n3. Both samples are simple random samples.\n4. Either or both of these conditions are satisfied: The \ntwo sample sizes are both large (with n1 7 30 and \nn2 7 30) or both samples come from populations \nhaving normal distributions. (The methods used here \nare robust against departures from normality, so for \nsmall samples, the normality requirement is loose in \nthe sense that the procedures perform well as long as \nthere are no outliers and departures from normality \nare not too extreme.)\nHypothesis Test Statistic for Two Means: Independent Samples (with H0: M1 = M2)\nt = 1x1 - x22 - 1m1 - m22\nB\ns2\n1\nn1\n+ s2\n2\nn2\n \n1where m1 - m2 is often assumed to be 02\nDegrees of Freedom: When finding critical values or  \nP-values, use the following for determining the number of \ndegrees of freedom, denoted by df. (Although these two \nmethods typically result in different numbers of degrees of \nfreedom, the conclusion of a hypothesis test is rarely af-\nfected by the choice.)\n1. Use this simple and conservative estimate:\ndf = smaller of n1 −1 and n2 −1\n2. Technologies typically use the more accurate but \nmore difficult estimate given in Formula 9-1.\nFORMULA 9-1\ndf =\n1A + B2 2\nA2\nn1 - 1 +\nB2\nn2 - 1\nwhere A = s2\n1\nn1\n and B = s2\n2\nn2\nNote: Answers in Appendix D include technology answers \nbased on Formula 9-1 along with “Table” answers based \non using Table A-3 with the simple estimate of df given in \noption 1 above.\nP-Values: \n P-values are automatically provided by technology. If technology is not available, refer to the t distri-\nbution in Table A-3. Use the procedure summarized in Figure 8-3 on page 344.\nCritical Values: \nRefer to the t distribution in Table A-3.\nConfidence Interval Estimate of M1 −M2: Independent Samples\nThe confidence interval estimate of the difference m1 -  m2 is\n1x1 - x22 - E 6 1m1 - m22 6 1x1 - x22 + E\nwhere\nE = ta>2B\ns2\n1\nn1\n+ s2\n2\nn2\nand the number of degrees of freedom df is as described above for hypothesis tests.  \n(In this book, we use df = smaller of n1 - 1 and n2 - 1.)\n",
    "9-2 Two Means: Independent Samples \n409\nEquivalent Methods\nThe P-value method of hypothesis testing, the critical value method of hypothesis \ntesting, and confidence intervals all use the same distribution and standard error, so \nthey are all equivalent in the sense that they result in the same conclusions.\nP-Value Method\nEXAMPLE 1  Second-Hand Smoke\nData Set 14 “Passive and Active Smoke” includes measures of cotinine (ng>mL) in \nsubjects from different groups. Cotinine is produced when nicotine is absorbed by \nthe body, so cotinine is a good indicator of nicotine. Listed below are the summary \nstatistics from a group of smokers and another group of subjects who do not smoke \nbut are exposed to environmental tobacco smoke at home or work. Use a 0.05 sig-\nnificance level to test the claim that the population of smokers has a higher mean \ncotinine level than the nonsmokers exposed to smoke. Do smokers appear to have \nhigher of levels of cotinine than nonsmokers who are exposed to smoke?\nSmokers n = 40, x = 172.5 ng>mL, s = 119.5 ng>mL\nNonsmokers Exposed to Smoke n = 40, x = 60.6 ng>mL, s = 138.1 ng>mL\nSOLUTION\nREQUIREMENT CHECK (1) The values of the two population standard deviations are \nnot known and we are not making an assumption that they are equal. (2) The two \nsamples are independent. They are not matched or paired in any way. (3) The samples \nare simple random samples. (4) Both samples are large, with more than 30 subjects. \nThe requirements are all satisfied. \nUsing the P-value method summarized in Figure 8-1 on page 340, we can test \nthe claim as follows.\nStep 1: The claim that “the population of smokers has a higher mean cotinine level \nthan the nonsmokers exposed to smoke” can be expressed as m1 7 m2.\nStep 2: If the original claim is false, then m1 … m2.\nStep 3: The alternative hypothesis is the expression not containing equality, and the \nnull hypothesis is an expression of equality, so we have\nH0: m1 = m2        H1: m1 7 m2 \nWe now proceed with the assumption that m1 = m2, or m1 - m2 = 0.\nStep 4: The significance level is a = 0.05.\nStep 5: Because we have two independent samples and we are testing a claim about \nthe two population means, we use a t distribution with the test statistic given earlier \nin this section.\nStep 6: The test statistic is calculated using the statistics given in the statement of \nthe problem:\nt = 1x1 - x22 - 1m1 - m22\nB\ns2\n1\nn1\n+ s2\n2\nn2\n= 1172.5 - 60.62 - 0\nB\n119.52\n40\n+ 138.12\n40\n= 3.875\nis \no\nExpensive Diet Pill\nThere are many \npast examples \nin which ineffec-\ntive treatments \nwere marketed \nfor substan-\ntial profits. \nCapsules of “Fat Trapper” \nand  “Exercise in a Bottle,” \nmanufactured by the Enforma \nNatural Products company, were \nadvertised as being effective \ntreatments for weight reduction. \nAdvertisements claimed that after \ntaking the capsules, fat would be \nblocked and calories would be \nburned, even without exercise. \nBecause the Federal Trade Com-\nmission identified claims that \nappeared to be unsubstantiated, \nthe company was fined $10 mil-\nlion for deceptive advertising.\nThe effectiveness of such \ntreatments can be determined \nwith experiments in which one \ngroup of randomly selected \nsubjects is given the treatment, \nwhile another group of randomly \nselected subjects is given a \nplacebo. The resulting weight \nlosses can be compared using \nstatistical methods, such as \nthose described in this section.\nT\n”\ncontinued\n",
    "410 \nCHAPTER 9 Inferences from Two Samples\nTechnology The tricky part about the preceding P-value approach is that Table A-3 \ncan only give a range for the P-value, and determining that range is often a bit tricky. \nTechnology automatically provides the P-value, so technology makes the P-value \nmethod quite easy. See the accompanying XLSTAT display showing the test statistic \nof t = 3.8755 and the P-value of 0.0001.\nCritical Value Method\nIf technology is not available, the critical value method of testing a claim about two \nmeans is generally easier than the P-value method. Example 1 can be solved using the \ncritical value method. When finding critical values in Table A-3, we use df = smaller \nof n1 - 1 and n2 - 1 as a relatively easy way to avoid using the really messy calcu-\nlation required with Formula 9-1. In Example 1 with sample sizes of n1 = 40 and \nn2 = 40, the number of degrees of freedom is 39, so using Table A-3 with df = 39 \nand a = 0.05 in the right tail, we get the critical value of t = 1.685. Technology uses \nFormula 9-1 to find the more accurate critical value of t = 1.665. See Figure 9-2. The \ntest statistic of t = 3.875 falls in the critical region, so we reject the null hypothesis, \nas we did in Example 1.\nP-Value With test statistic t = 3.875, we refer to Table A-3 (t Distribution). The \nnumber of degrees of freedom is the smaller of n1 - 1 and n2 - 1, or the smaller \nof 140 - 12 and 140 - 12, which is 39. With df = 39 and a right-tailed test, \nTable A-3 indicates that the test statistic t = 3.875 results in a P-value that is less \nthan 0.005. Technology will provide the P-value of 0.0001 when using the original \ndata or unrounded sample statistics.\nStep 7: Because the P-value is less than the significance level of 0.05, we reject the \nnull hypothesis. (“If the P is low, the null must go.”)\nINTERPRETATION\nStep 8: There is sufficient evidence to support the claim that the population of \nsmokers has a higher mean cotinine level than the nonsmokers exposed to smoke. It \nappears that smoking is associated with higher levels of cotinine than nonsmokers \nexposed to smoke.\nXLSTAT\nt 5 0\na\u001f2 5 0.025\na\u001f2 5 0.025\nTest Statistic:\nt 5 20.660\nt 5 22.093\nt 5 2.093\nFIGURE 9-2  Hypothesis Test of Means from \nTwo Independent Populations\n",
    "9-2 Two Means: Independent Samples \n411\nConfidence Intervals\nEXAMPLE 2  Confidence Interval for Second-Hand Smoke\nUsing the sample data given in Example 1, construct a 90% confidence interval es-\ntimate of the difference between the mean cotinine level of smokers and the mean \ncotinine level of nonsmokers exposed to smoke.\nSOLUTION\nREQUIREMENT CHECK Because we are using the same data from Example 1, the \nsame requirement check applies here, so the requirements are satisfied. \nWe first find the value of the margin of error E. In Table A-3 with df = 39 and \na = 0.10 in two tails, we get critical values of t = {1.685. (Technology can be \nused to find the more accurate critical values of t = {1.665.)\nE = ta>2B\ns2\n1\nn1\n+ s2\n2\nn2\n= 1.685B\n119.52\n40\n+ 138.12\n40\n= 48.655276\nUsing E = 48.655276, x1 = 172.5, and x2 = 60.6, we can now find the confidence \ninterval as follows:\n1x1 - x22 - E 6 1m1 - m22 6 1x1 - x22 + E\n63.2 ng>mL 6 1m1 - m22 6 160.6 ng>mL\nIf we use technology to obtain more accurate results, we get the confidence interval \nof 63.8 ng>mL 6 1m1 - m22 6 160.0 ng>mL, so we can see that the confidence \ninterval above is quite good, even though we used a simplified method for finding \nthe number of degrees of freedom (instead of getting more accurate results by using \nFormula 9-1).\nINTERPRETATION\nWe are 90% confident that the limits of 63.2 ng>mL and 160.6 ng>mL actually \ndo contain the difference between the two population means. Because those limits \ndo not contain 0, this confidence interval suggests that the mean cotinine level of \nsmokers is greater than the mean cotinine level of nonsmokers exposed to smoke.\nPART 2\nAlternative Methods\nPart 1 of this section dealt with situations in which the two population standard devia-\ntions are unknown and are not assumed to be equal. In Part 2 we address two other \nsituations:\n1. The two population standard deviations are unknown but are assumed to be \nequal.\n2. The two population standard deviations are both known.\nAlternative Method: Assume That S1 = S2 and Pool the Sample Variances\nEven when the specific values of s1 and s2 are not known, if it can be assumed that \nthey have the same value, the sample variances s2\n1 and s2\n2 can be pooled to obtain an \n",
    "412 \nCHAPTER 9 Inferences from Two Samples\nestimate of the common population variance s2\n . The pooled estimate of S2 is denoted \nby s2\np and is a weighted average of s2\n1 and s2\n2, which is used in the test statistic for this \ncase:\nTest Statistic  t = 1x1 - x22 - 1m1 - m22\nB\ns2p\nn1\n+\ns2p\nn2\nwhere s2\np = 1n1 - 12s2\n1 + 1n2 - 12s2\n2\n1n1 - 12 + 1n2 - 12\n \n1pooled sample variance2\nand the number of degrees of freedom is df = n1 +  n2 - 2.\nThe requirements for this case are the same as in Part 1, except the first requirement \nis that s1 and s2 are not known but they are assumed to be equal. Confidence intervals \nare found by evaluating 1x1 - x22 - E 6 1m1 - m22 6 1x1 - x22 + E with the \nfollowing margin of error E.\nMargin of Error for Confidence Interval E = ta>2 B\ns2p\nn1\n+\ns2p\nn2\nwhere s2\np is as given in the test statistic above, and df = n1 + n2 - 2.\nWhen Should We Assume That S1 = S2? If we use randomness to assign subjects \nto treatment and placebo groups, we know that the samples are drawn from the same \npopulation. So if we conduct a hypothesis test assuming that two population means \nare equal, it is not unreasonable to also assume that the samples are from populations \nwith the same standard deviations (but we should still check that assumption).\nAdvantage of Pooling The advantage of this alternative method of pooling sample \nvariances is that the number of degrees of freedom is a little higher, so hypothesis tests \nhave more power and confidence intervals are a little narrower.\nIn the article “Homogeneity of Variance in the Two-Sample Means Test” (by \nMoser and Stevens, American Statistician, Vol. 46, No. 1), the authors note that we \nrarely know that s1 = s2. They analyze the performance of the different tests by con-\nsidering sample sizes and powers of the tests. They conclude that more effort should \nbe spent learning the method given in Part 1, and less emphasis should be placed on \nthe method based on the assumption of s1 = s2.\nAlternative Method Used When S1 and S2 Are Known\nIn reality, the population standard deviations s1 and s2 are almost never known, but \nif they are somehow known, the test statistic and confidence interval are based on the \nnormal distribution instead of the t distribution. The requirements are the same as \nthose given in Part 1, except for this first requirement: s1 and s2 are known. Critical \nvalues and P-values are found using technology or Table A-2, and the test statistic for \nthis case is as follows:\nTest Statistic z = 1x1 - x22 - 1m1 - m22\nB\ns2\n1\nn1\n+ s2\n2\nn2\nConfidence intervals are found by evaluating  \n1x1 - x22 - E 6 1m1 - m22 6 1x1 - x22 + E, where:\nMargin of Error for Confidence Interval E = za>2B\ns2\n1\nn1\n+ s2\n2\nn2\ne\nb\nc\nGender Gap in Drug \nTesting\nA study of the \nrelationship \nbetween \nheart attacks \nand doses \nof aspirin \ninvolved \n22,000 male physicians. \nThis study, like many others, \nexcluded women. The General \nAccounting Office criticized the \nNational Institutes of Health for \nnot including both genders in \nmany studies because results of \nmedical tests on males do not \nnecessarily apply to females. \nFor example, women’s hearts \nare different from men’s in many \nimportant ways. When forming \nconclusions based on sample \nresults, we should be wary of \nan inference that extends to a \npopulation larger than the one \nfrom which the sample was \ndrawn.\n",
    "9-2 Two Means: Independent Samples \n413\nWhat if One Standard Deviation Is Known and the Other Is Unknown? If s1\nis known but s2 is unknown, use the procedures in Part 1 of this section with these \nchanges: Replace s1 with the known value of s1 and use the number of degrees of free-\ndom found from the expression below. (See “The Two-Sample t Test with One Vari-\nance Unknown,” by Maity and Sherman, The American Statistician, Vol. 60, No. 2.)\ndf =\nas2\n1\nn1\n+ s2\n2\nn2\nb\n2\n1s2\n2>n22 2\nn2 - 1\nRecommended Strategy for Two Independent Means\nHere is the recommended strategy for the methods of this section:\nAssume that S1 and S2 are unknown, do not assume that S1 = S2, and use \nthe test statistic and confidence interval given in Part 1 of this section.\nInferences with Two Means: Independent Samples\nAccess tech instructions, videos, and data sets at www.TriolaStats.com\nTECH CENTER \nStatistical Literacy and Critical Thinking \n1. Independent and Dependent Samples Which of the following involve independent \n samples?\na. Data Set 2 “Body Temperatures” includes body temperatures of subjects measured at 8 AM \nand again at 12 AM on Day 1 of observation.\nb. Data Set 6 “Family Heights” includes heights of fathers and heights of their daughters.\nc. Data Set 1 “Body Data” includes pulse rates of 147 adult females and 153 adult males.\n2. Confidence Interval for Hemoglobin Large samples of women and men are ob-\ntained and the hemoglobin level is measured in each subject. Here is the 95% confidence \ninterval for the difference between the two population means, where the measures from \nwomen correspond to population 1 and the measures from men correspond to population 2: \n-1.76 g>dL 6 m1 - m2 6 -1.62 g>dL.\na. What does the confidence interval suggest about equality of the mean hemoglobin level in \nwomen and the mean hemoglobin level in men?\nb. Write a brief statement that interprets that confidence interval.\nc. Express the confidence interval with measures from men being population 1 and measures \nfrom women being population 2.\n3. Hypothesis Tests and Confidence Intervals for Hemoglobin\na. Exercise 2 includes a confidence interval. If you use the P-value method or the critical value \nmethod from Part 1 of this section to test the claim that women and men have the same mean \n9-2 Basic Skills and Concepts\ncontinued\n",
    "414 \nCHAPTER 9 Inferences from Two Samples\nhemoglobin levels, will the hypothesis tests and the confidence interval result in the same con-\nclusion?\nb. In general, if you conduct a hypothesis test using the methods of Part 1 of this section, will \nthe P-value method, the critical value method, and the confidence interval method result in the \nsame conclusion?\nc. Assume that you want to use a 0.01 significance level to test the claim that the mean hemo-\nglobin amount in women is less than the mean hemoglobin amount in men. What confidence \nlevel should be used if you want to test that claim using a confidence interval?\n4. Degrees of Freedom For Example 1 on page 409, we used df = smaller of n1 - 1 and \nn2 - 1, we got df = 39, and the corresponding critical value is t = 1.685. If we calculate \ndf using Formula 9-1, we get df = 76.423, and the corresponding critical value is t = 1.665.\nHow is using a critical value of t = 1.685 more “conservative” than using the critical value of \nt = 1.665? (Hint: What magnitude of difference between the two sample means is required \nwhen using a critical value of t = 1.685 compared to the critical value of 1.665?)\nIn Exercises 5–22, assume that the two samples are independent simple random samples \nselected from normally distributed populations, and do not assume that the population stan-\ndard deviations are equal. (Note: Answers in Appendix D include technology answers based \non Formula 9-1 along with “Table” answers based on Table A-3 with df equal to the smaller \nof n1 −1 and n2 −1.)\n5. Hypothesis Test of Effectiveness of Humidity in Treating Croup In a randomized \ncontrolled trial conducted with children suffering from viral croup, 46 children were treated \nwith low humidity while 46 other children were treated with high humidity. Researchers used \nthe Westley Croup Score to assess the results after one hour. The low-humidity group had a \nmean score of 0.98 with a standard deviation of 1.22, while the high-humidity group had a \nmean score of 1.09 with a standard deviation of 1.11 (based on data from “Controlled Delivery \nof High vs Low Humidity vs Mist Therapy for Croup Emergency Departments,” by Scolnik \net al., Journal of the American Medical Association, Vol. 295, No. 11). Use a 0.05 significance \nlevel to test the claim that the two groups are from populations with the same mean. What does \nthe result suggest about the common treatment of humidity?\n6. Effectiveness of Echinacea In a randomized, double-blind, placebo-controlled trial \nof children, echinacea was tested as a treatment for upper respiratory infections in children. \n“Days of fever” was one criterion used to measure effects. Among 337 children treated \nwith  echinacea, the mean number of days with fever was 0.81, with a standard deviation of \n1.50 days. Among 370 children given a placebo, the mean number of days with fever was 0.64 \nwith a standard  deviation of 1.16 days (based on data from “Efficacy and Safety of Echinacea \nin Treating  Upper Respiratory Tract Infections in Children,” by Taylor et al., Journal of the \n American Medical Association, Vol. 290, No. 21). Use a 0.05 significance level to test the claim \nthat echinacea affects the number of days with fever. Based on these results, does echinacea \nappear to be effective?\n7. Effects of Cocaine on Children A study was conducted to assess the effects that occur \nwhen children are exposed to cocaine before birth. Children were tested at age 4 for object \nassembly skill, which was described as “a task requiring visual-spatial skills related to math-\nematical competence.” The 190 children born to cocaine users had a mean of 7.3 and a standard \ndeviation of 3.0. The 186 children not exposed to cocaine had a mean score of 8.2 with a stan-\ndard deviation of 3.0. (The data are based on “Cognitive Outcomes of Preschool Children with \nPrenatal Cocaine Exposure,” by Singer et al., Journal of the American Medical Association, \nVol. 291, No. 20.)\na. Use a 0.05 significance level to test the claim that prenatal cocaine exposure is associated \nwith lower scores of four-year-old children on the test of object assembly.\nb. Test the claim in part (a) by using a confidence interval.\n",
    "9-2 Two Means: Independent Samples \n415\n8. Magnet Treatment of Pain People spend around $5 billion annually for the purchase of \nmagnets used to treat a wide variety of pains. Researchers conducted a study to determine \nwhether magnets are effective in treating back pain. Pain was measured using the visual ana-\nlog scale, and the results given below are among the results obtained in the study (based on \ndata from “Bipolar Permanent Magnets for the Treatment of Chronic Lower Back Pain: A Pi-\nlot Study,” by Collacott, Zimmerman, White, and Rindone, Journal of the American Medical \n Association, Vol. 283, No. 10).\na. Use a 0.05 significance level to test the claim that those treated with magnets have a greater \nmean reduction in pain than those given a sham treatment (similar to a placebo).\nb. Construct the confidence interval appropriate for the hypothesis test in part (a).\nc. Does it appear that magnets are effective in treating back pain? Is it valid to argue that mag-\nnets might appear to be effective if the sample sizes are larger?\n Reduction in Pain Level After Magnet Treatment:  n = 20, x = 0.49, s = 0.96\n Reduction in Pain Level After Sham Treatment:   n = 20, x = 0.44, s = 1.4\n9. Cigarette Tar The mean tar content of a simple random sample of 25 unfiltered king-size \ncigarettes is 21.1 mg, with a standard deviation of 3.2 mg. The mean tar content of a simple \nrandom sample of 25 filtered 100-mm cigarettes is 13.2 mg with a standard deviation of 3.7 mg \n(from Data Set 15 “Cigarette Contents” in Appendix B).\na. Use a 0.05 significance level to test the claim that unfiltered king-size cigarettes have a mean \ntar content greater than that of filtered 100-mm cigarettes. What does the result suggest about \nthe effectiveness of cigarette filters?\nb. Construct a 90% confidence interval estimate of the difference between the mean tar content \nof unfiltered king-size cigarettes and the mean tar content of filtered 100-mm cigarettes. Does \nthe result suggest that 100-mm filtered cigarettes have less tar than unfiltered king-size ciga-\nrettes?\n10. Bipolar Depression Treatment In clinical experiments involving different groups of in-\ndependent samples, it is important that the groups be similar in the important ways that affect \nthe experiment. In an experiment designed to test the effectiveness of paroxetine for treating bi-\npolar depression, subjects were measured using the Hamilton depression scale, with the results \ngiven below (based on data from “Double-Blind, Placebo-Controlled Comparison of Imipra-\nmine and Paroxetine in the Treatment of Bipolar Depression,” by Nemeroff et al., American \nJournal of Psychiatry, Vol. 158, No. 6). Use a 0.05 significance level to test the claim that the \ntreatment group and placebo group come from populations with the same mean. What does \nthe result of the hypothesis test suggest about paroxetine as a treatment for bipolar depression?\n Placebo group: \n n = 43, x = 21.57, s = 3.87\n Paroxetine treatment group:  n = 33, x = 20.38, s = 3.91\n11. Effects of Alcohol An experiment was conducted to test the effects of alcohol. The errors \nwere recorded in a test of visual and motor skills for a treatment group of people who drank \nethanol and another group given a placebo. The results are shown in the accompanying table \n(based on data from “Effects of Alcohol Intoxication on Risk Taking, Strategy, and Error Rate \nin Visuomotor Performance,” by Streufert et al., Journal of Applied Psychology, Vol. 77, No. 4).\na. Use a 0.05 significance level to test the claim that there is a difference between the treatment \ngroup and control group. If there is a significant difference, can we conclude that the treatment \ncauses a decrease in visual and motor skills?\nb. Construct a 95% confidence interval estimate of the difference between the two population \nmeans. Do the results support the common belief that drinking is hazardous for drivers, pilots, \nship captains, and so on? Why or why not?\nTreatment \nGroup\nPlacebo \nGroup\nn1 = 22\nn2 = 22\nx1 = 4.20\nx2 = 1.71\ns1 = 2.20\ns2 = 0.72\n",
    "416 \nCHAPTER 9 Inferences from Two Samples\n12. Effect of Marijuana Use on College Students Many studies have been conducted to \ntest the effects of marijuana use on mental abilities. In one such study, groups of light and heavy \nusers of marijuana in college were tested for memory recall, with the results given below (based \non data from “The Residual Cognitive Effects of Heavy Marijuana Use in College Students,” by \nPope and Yurgelun-Todd, Journal of the American Medical Association, Vol. 275, No. 7).\na. Use a 0.01 significance level to test the claim that the population of heavy marijuana users \nhas a lower mean than the light users. Should marijuana use be of concern to college students?\nb. Construct a 98% confidence interval for the difference between the two population means. \nDoes the confidence interval include zero? What does the confidence interval suggest about the \nequality of the two population means?\n Items sorted correctly by light marijuana users:  n = 64, x = 53.3, s = 3.6\n Items sorted correctly by heavy marijuana users:  n = 65, x = 51.3, s = 4.5\n13. Second-Hand Smoke Data Set 14 “Passive and Active Smoke” includes cotinine levels \nmeasured in a group of nonsmokers exposed to tobacco smoke (n = 40, x = 60.58 ng>mL,\ns = 138.09 ng>mL) and a group of nonsmokers not exposed to tobacco smoke (n = 40,\nx = 16.35 ng>mL, s = 62.53 ng>mL). Cotinine is a metabolite of nicotine, meaning that \nwhen nicotine is absorbed by the body, cotinine is produced.\na. Use a 0.05 significance level to test the claim that nonsmokers exposed to tobacco smoke \nhave a higher mean cotinine level than nonsmokers not exposed to tobacco smoke.\nb. Construct the confidence interval appropriate for the hypothesis test in part (a).\nc. What do you conclude about the effects of second-hand smoke?\n14. BMI We know that the mean weight of men is greater than the mean weight of women, and \nthe mean height of men is greater than the mean height of women. A person’s body mass index \n(BMI) is computed by dividing weight (kg) by the square of height (m). Given below are the \nBMI statistics for random samples of females and males taken from Data Set 1 “Body Data” in \nAppendix B.\na. Use a 0.05 significance level to test the claim that females and males have the same mean \nBMI.\nb. Construct the confidence interval that is appropriate for testing the claim in part (a).\nc. Do females and males appear to have the same mean BMI?\n Female BMI:  n = 70, x = 29.10, s = 7.39\n  Male BMI:  n = 80, x = 28.38, s = 5.37\n15. IQ and Lead Exposure Data Set 8 “IQ and Lead” in Appendix B lists full IQ scores for \na random sample of subjects with low lead levels in their blood and another random sample of \nsubjects with high lead levels in their blood. The statistics are summarized below.\na. Use a 0.05 significance level to test the claim that the mean IQ score of people with low \nblood lead levels is higher than the mean IQ score of people with high blood lead levels.\nb. Construct a confidence interval appropriate for the hypothesis test in part (a).\nc. Does exposure to lead appear to have an effect on IQ scores?\n Low Blood Lead Level:  n = 78, x = 92.88462, s = 15.34451\n High Blood Lead Level:  n = 21, x = 86.90476, s = 8.988352\n16. Seat Belts A study of seat belt use involved children who were hospitalized after motor \nvehicle crashes. For a group of 123 children who were wearing seat belts, the number of days \nin intensive care units (ICU) has a mean of 0.83 and a standard deviation of 1.77. For a group \nof 290 children who were not wearing seat belts, the number of days spent in ICUs has a mean \n",
    "9-2 Two Means: Independent Samples \n417\nof 1.39 and a standard deviation of 3.06 (based on data from “Morbidity Among Pediatric Mo-\ntor Vehicle Crash Victims: The Effectiveness of Seat Belts,” by Osberg and Di Scala, American \nJournal of Public Health, Vol. 82, No. 3).\na. Use a 0.05 significance level to test the claim that children wearing seat belts have a lower \nmean length of time in an ICU than the mean for children not wearing seat belts.\nb. Construct a confidence interval appropriate for the hypothesis test in part (a).\nc. What important conclusion do the results suggest?\n17. Bad Stuff in Children’s Movies Data Set 13 “Alcohol and Tobacco in Movies” includes \nlengths of times (seconds) of tobacco use shown in animated children’s movies. For the Disney \nmovies, n = 33, x =  61.6 sec, s = 118.8 sec. For the other movies, n = 17, x = 49.3 sec, \ns = 69.3 sec. The sorted times for the non-Disney movies are listed below.\na. Use a 0.05 significance level to test the claim that Disney animated children’s movies and \nother animated children’s movies have the same mean time showing tobacco use.\nb. Construct a confidence interval appropriate for the hypothesis test in part (a).\nc. Conduct a quick visual inspection of the listed times for the non-Disney movies and com-\nment on the normality requirement. How does the normality of the 17 non-Disney times affect \nthe results?\n0 0 0 0 0 0 1 5 6 17 24 55 91 117 155 162 205\n18. Radiation in Baby Teeth Listed below are amounts of strontium-90 (in millibecquerels, \nor mBq, per gram of calcium) in a simple random sample of baby teeth obtained from Pennsyl-\nvania residents and New York residents born after 1979 (based on data from “An Unexpected \nRise in Strontium-90 in U.S. Deciduous Teeth in the 1990s,” by Mangano et al., Science of the \nTotal Environment, Vol. 317).\na. Use a 0.05 significance level to test the claim that the mean amount of strontium-90 from \nPennsylvania residents is greater than the mean amount from New York residents.\nb. Construct a confidence interval for testing the claim in part (a).\nPennsylvania:\n155\n142\n149\n130\n151\n163\n151\n142\n156\n133\n138\n161\nNew York:\n133\n140\n142\n131\n134\n129\n128\n140\n140\n140\n137\n143\n19. Longevity Listed below are the numbers of years that popes and British monarchs (since \n1690) lived after their election or coronation (based on data from Computer-Interactive Data \nAnalysis, by Lunn and McNeil, John Wiley & Sons). Treat the values as simple random sam-\nples from a larger population.\na. Use a 0.01 significance level to test the claim that the mean longevity for popes is less than \nthe mean for British monarchs after coronation.\nb. Construct a confidence interval for testing the claim in part (a).\nPopes:\n 2\n 9\n21\n 3\n 6\n10\n18\n11\n6\n25\n23\n 6\n 2\n15\n32\n25\n11\n 8\n17\n19\n5\n15\n 0\n26\nKings and Queens:\n17\n 6\n13\n12\n13\n33\n59\n10\n7\n63\n 9\n25\n36\n15\n20. Blanking Out on Tests Many students have had the unpleasant experience of panick-\ning on a test because the first question was exceptionally difficult. The arrangement of test \nitems was studied for its effect on anxiety. The following scores are measures of “debilitating \ntest anxiety,” which most of us call panic or blanking out (based on data from “Item Arrange-\nment, Cognitive Entry Characteristics, Sex and Test Anxiety as Predictors of Achievement in \nExamination Performance,” by Klimko, Journal of Experimental Education, Vol. 52, No. 4.) Is \ncontinued\n",
    "418 \nCHAPTER 9 Inferences from Two Samples\nthere sufficient evidence to support the claim that the two populations of scores have different \nmeans? Is there sufficient evidence to support the claim that the arrangement of the test items \nhas an effect on the score?\nQuestions Arranged from Easy to Difficult\nQuestions Arranged from Difficult to Easy\n24.64\n39.29\n16.32\n32.83\n28.02\n33.62\n34.02\n26.63\n30.26\n33.31\n20.60\n21.13\n26.69\n28.90\n35.91\n26.68\n29.49\n35.32\n26.43\n24.23\n 7.10\n32.86\n21.06\n27.24\n32.34\n29.34\n33.53\n28.89\n28.71\n31.73\n30.02\n21.96\n27.62\n42.91\n30.20\n32.54\n25.49\n38.81\n27.85\n30.29\n30.72\n21. Do Men and Women Have the Same Mean Diastolic Blood Pressure? Refer to Data \nSet 1 “Body Data” and use a 0.05 significance level to test the claim that women and men have \nthe same mean diastolic blood pressure.\n22. Birth Weights Refer to Data Set 3 “Births” and use the birth weights of boys and girls. \nTest the claim that at birth, girls have a lower mean weight than boys.\n23. Pooling Repeat Exercise 15 “IQ and Lead Exposure” by assuming that the two population \nstandard deviations are equal, so s1 = s2. Use the appropriate method from Part 2 of this sec-\ntion. Does pooling the standard deviations yield results showing greater significance?\n24. Degrees of Freedom In Exercise 20 “Blanking Out on Tests,” using the “smaller of \nn1 - 1 and n2 - 1” for the number of degrees of freedom results in df = 15. Find the number \nof degrees of freedom using Formula 9-1. In general, how are hypothesis tests and confidence \nintervals affected by using Formula 9-1 instead of the “smaller of n1 - 1 and n2 - 1”?\n25. No Variation in a Sample An experiment was conducted to test the effects of alcohol. Re-\nsearchers measured the breath alcohol levels for a treatment group of people who drank ethanol \nand another group given a placebo. The results are given below (based on data from “Effects of \nAlcohol Intoxication on Risk Taking, Strategy, and Error Rate in Visuomotor Performance,” by \nStreufert et al., Journal of Applied Psychology, Vol. 77, No. 4). Use a 0.05 significance level to \ntest the claim that the two sample groups come from populations with the same mean.\n Treatment Group:  n1 = 22, x1 = 0.049, s1 = 0.015\n Placebo Group: \n n2 = 22, x2 = 0.000, s2 = 0.000\n9-2 Beyond the Basics\nKey Concept This section presents methods for testing hypotheses and construct-\ning confidence intervals involving the mean of the differences of the values from two \npopulations that are dependent in the sense that the data consist of matched pairs. The \npairs must be matched according to some relationship, such as before>after measure-\nments from the same subjects or husbands and wives.\nGood Experimental Design\nSuppose we want to test the effectiveness of a drug designed to lower blood pressure. \nIt would be better to use before>after measurements from a single group of subjects \ntreated with the drug than to use measurements from one group of subjects who were \n9-3 \nTwo Dependent Samples (Matched Pairs)\n",
    "9-3 Two Dependent Samples (Matched Pairs) \n419\nnot treated with the drug and a separate group who were treated. The advantage of \nusing matched pairs (before>after measurements) is that we reduce extraneous varia-\ntion, which could occur with the two different independent samples. This strategy for \ndesigning an experiment can be generalized by the following design principle:\nWhen designing an experiment or planning an observational study, using \ndependent samples with matched pairs is generally better than using two \nindependent samples.\nDéjà Vu All Over Again The methods of hypothesis testing in this section are the \nsame methods for testing a claim about a population mean (Part 1 of Section 8-3), ex-\ncept that here we use the differences from the matched pairs of sample data.\nThere are no exact procedures for dealing with dependent samples, but the fol-\nlowing approximation methods are commonly used.\nInferences About Differences from Matched Pairs\nObjectives\nKEY ELEMENTS \n1. Hypothesis Test: Use the differences from two dependent \nsamples (matched pairs) to test a claim about the mean \nof the population of all such differences.\n2. Confidence Interval: Use the differences from two \ndependent samples (matched pairs) to construct a con-\nfidence interval estimate of the mean of the population \nof all such differences.\nNotation for Dependent Samples\nd = individual difference between the two values in a single matched pair\nmd = mean value of the differences d for the population of all matched pairs of data\nd = mean value of the differences d for the paired sample data\nsd = standard deviation of the differences d for the paired sample data\nn = number of pairs of sample data\nRequirements\n1. The sample data are dependent (matched pairs).\n2. The matched pairs are a simple random sample.\n3. Either or both of these conditions are satisfied: The \nnumber of pairs of sample data is large (n 7 30) or the \npairs of values have differences that are from a popula-\ntion having a distribution that is approximately normal. \nThese methods are robust against departures for nor-\nmality, so the normality requirement is loose.\nTest Statistic for Dependent Samples (with H0: Md = 0)\nt = d - md\nsd\n2n\nP-Values: \n P-values are automatically provided by technology or the t distribution in Table A-3 can be used.  \nUse the procedure given in Figure 8-3 on page 344. \nCritical Values: Use Table A-3 (t distribution). For degrees of freedom, use df = n - 1.\nConfidence Intervals for Dependent Samples\nd - E 6 md 6 d + E\nwhere E = ta>2\nsd\n2n\n (Degrees of freedom: df = n - 1.)\n",
    "420 \nCHAPTER 9 Inferences from Two Samples\nProcedures for Inferences with Dependent Samples\n1. Verify that the sample data consist of dependent samples (or matched pairs), \nand verify that the requirements in the preceding Key Elements box are satis-\nfied.\n2. Find the difference d for each pair of sample values. (Caution: Be sure to sub-\ntract in a consistent manner, such as “before - after.”)\n3. Find the value of d (mean of the differences) and sd (standard deviation of the \ndifferences).\n4. For hypothesis tests and confidence intervals, use the same t test procedures \nused for a single population mean (described in Part 1 of Section 8-3).\nEquivalent Methods\nBecause the hypothesis test and confidence interval in this section use the same distri-\nbution and standard error, they are equivalent in the sense that they result in the same \nconclusions. Consequently, a null hypothesis that the mean difference equals 0 can be \ntested by determining whether the confidence interval includes 0.\nEXAMPLE 1   Are Body Temperatures Different in the Morning \nand at Night?\nTable 9-1 lists body temperatures of five subjects at 8 AM and at 12 AM. The data are \nmatched pairs because each pair of temperatures is measured in the same person. Data \nSet 2 in Appendix B lists 69 pairs of such data for Day 2 of the observations, but we \nuse only 5 of those pairs so that we can easily show the steps in the procedure.\nUse the data in Table 9-1 with a 0.05 significance level to test the claim that \nthere is no difference in body temperatures measured at 8 AM and at 12 AM.\nTABLE 9-1 Body Temperatures of Five Subjects on the Same Day\nTemperature (°F) at 8 AM\n98.0\n 97.6\n 97.2\n 97.0\n 98.0\nTemperature (°F) at 12 AM\n97.0\n 98.8\n 97.6\n 97.7\n 98.8\nDifference d\n 1.0\n−1.2\n−0.4\n−0.7\n−0.8\nSOLUTION\nREQUIREMENT CHECK We address the three requirements listed earlier in the  Key \nElements box. (1) The samples are dependent, since each pair of temperatures is \nmatched because the two values are from the same person. (2) The pairs of data are \nrandomly selected. We will consider the data to be a simple random sample. (3) Be-\ncause the number of pairs of data is n = 5, which is not large, we should check for \nnormality of the differences and we should check for outliers. There are no outliers, \nand a normal quantile plot would show that the points approximate a straight-line \npattern with no other pattern, so the differences satisfy the loose requirement of be-\ning from a normally distributed population. All requirements are satisfied. \nWe will follow the same method of hypothesis testing that we used for testing a \nclaim about a mean (see Figure 8-1 on page 340), but we use differences instead of \nraw sample data.\nStep 1: The claim that there is no difference in body temperatures measured at  \n8 AM and at 12 AM can be expressed as md =  0.\n",
    "9-3 Two Dependent Samples (Matched Pairs) \n421\nStep 2: If the original claim is not true, then md ≠0.\nStep 3: The null hypothesis must express equality and the alternative hypothesis \ncannot include equality, so we have\nH0: md = 0 1original claim2   H1: md ≠0 \nStep 4: The significance level is a = 0.05.\nStep 5: We use the Student t distribution.\nStep 6: Before finding the value of the test statistic, we must first find the values of \nd and sd. We use the differences from Table 9-1 (1, -1.2, -0.4, -0.7, -0.8) to find \nthese sample statistics: d = -0.42°F and sd = 0.84°F. Using these sample statis-\ntics and the assumption from the null hypothesis that md = 0, we can now find the \nvalue of the test statistic. (The value of t = -1.113 is obtained if unrounded values \nof d and sd are used; technology will provide a test statistic of t = -1.113.)\nt = d - md\nsd\n2n\n= -0.42 - 0\n0.84\n25\n= -1.118\nP-Value Method\nTechnology Technology will provide a P-value of 0.3281\nTable Because we are using a t distribution, we refer to Table A-3 for the row with \ndf = 4 and we see that the test statistic t = -1.118 corresponds to an “Area in Two \nTails” that is greater than 0.20, so P-value 7 0.20. See Figure 9-3(a).\nCritical Value Method Refer to Table A-3 to find the critical values of t = {2.776 \nas follows: Use the column for 0.05 (Area in Two Tails), and use the row with de-\ngrees of freedom of n - 1 = 4. Table A-3 shows a t value of 2.776, but this test is \ntwo-tailed so there are two critical values: t = {2.776. See Figure 9-3(b).\nStep 7: If we use the P-value method, we fail to reject H0 because the P-value of \n0.3281 is greater than the significance level of 0.05. If we use the critical value \nmethod, we fail to reject H0 because the test statistic does not fall in the critical \nregion.\ncontinued\nCrest and Dependent \nSamples\nIn the late \n1950s, Procter \n& Gamble in-\ntroduced Crest \ntoothpaste as \nthe first such \nproduct with \nfluoride. To test the effectiveness \nof Crest in reducing cavities, \nresearchers conducted experi-\nments with several sets of twins. \nOne of the twins in each set was \ngiven Crest with fluoride, while \nthe other twin continued to use \nordinary toothpaste without \nfluoride. It was believed that \neach pair of twins would have \nsimilar eating, brushing, and \ngenetic characteristics. Results \nshowed that the twins who used \nCrest had significantly fewer \ncavities than those who did not. \nThis use of twins as dependent \nsamples allowed the researchers \nto control many of the different \nvariables affecting cavities.\nh\nff\ni\nt 5 0\nArea 5 0.16405\nArea 5 0.16405\nTest Statistic:\nt 5 21.118\n \nt 5 0\nTest Statistic:\nt 5 21.118\nCritical Value:\nt 5 22.776\nCritical Value:\nt 5 2.776\n5 0.025\na\n2\n5 0.025\na\n2\nFIGURE 9-3 Hypothesis Test with Dependent Samples\n(a) P-Value Method \n(b) Critical Value Method\n",
    "422 \nCHAPTER 9 Inferences from Two Samples\nINTERPRETATION\nWe conclude that there is not sufficient evidence to warrant rejection of the null \nhypothesis that md = 0. There is not sufficient evidence to warrant rejection of the \nclaim of no difference in body temperatures measured at 8 AM and at 12 AM.\nTechnology Software and calculators typically provide a P-value, so the P-value \nmethod of testing hypotheses is usually used. See the accompanying Statdisk re-\nsults showing the test statistic of t = -1.113 and the P-value of 0.3281. Because \nthe P-value of 0.3281 is greater than the significance level of 0.05, we fail to reject \nthe null hypothesis and we conclude that there is not sufficient evidence to warrant \nrejection of the claim of no difference in body temperatures measured at 8 AM and \nat 12 AM.\nStatdisk\nEXAMPLE 2   Confidence Interval for Estimating the Mean of  \nthe Temperature Differences\nUsing the same sample data in Table 9-1, construct a 95% confidence interval \nestimate of md, which is the mean of the temperature differences. By using a con-\nfidence level of 95%, we get a result that could be used for the hypothesis test in \nExample 1.\nSOLUTION\nREQUIREMENT CHECK The solution for Example 1 includes verification that the re-\nquirements are satisfied. \nThe preceding Statdisk display shows the 95% confidence interval. It is found \nusing the values of d = -0.42, sd = 0.84, and ta>2 = 2.776 (found from Table A-3 \nwith n - 1 = 4 degrees of freedom and an area of 0.05 divided equally between \nthe two tails). We first find the value of the margin of error E.\nE = ta>2\nsd\n2n\n= 2.776 # 0.84\n25\n= 1.042831\nWe now find the confidence interval as shown below. If we use the unrounded  \nsd = 0.8438009, we get the more accurate confidence interval of  \n-1.47°F 6 md 6 0.63°F.\nd - E 6 md 6 d + E\n-0.42 - 1.042831 6 md 6 -0.42 + 1.042831\n-1.46oF 6 md 6 0.62oF\n",
    "9-3 Two Dependent Samples (Matched Pairs) \n423\nINTERPRETATION\nWe have 95% confidence that the limits of -1.47°F and 0.63°F contain the true \nvalue of the mean of the difference between body temperatures at 8 AM and 12 AM. \nIn the long run, 95% of such samples will lead to confidence interval limits that \nactually do contain the true population mean of the differences. See that the confi-\ndence interval includes the value of 0, so it is very possible that the mean of the dif-\nferences is equal to 0, indicating that there is no significant difference between the \n8 AM body temperatures and the 12 AM body temperatures. Keep in mind that this \nconclusion is based on the very small sample included in Table 9-1.\nEXAMPLE 3  Is the “Freshman 15” Real, or Is It a Myth?\nThe Chapter Problem states that according to the “Freshman 15,” college students \ntypically gain 15 lb (or 6.8 kg) during their freshman year. Data Set 10 “Freshman \n15” includes results from a study designed to test that common belief. Test that \nclaim using a 0.05 significance level.\nSOLUTION\nREQUIREMENT CHECK We address the three requirements. (1) The samples are de-\npendent, since each pair of weights is matched because the two values are from the \nsame person. (2) Although the sample isn’t really a simple random sample, we will \ntreat it as a simple random sample for the purposes of this example. (3) Because the \nnumber of pairs of data is n = 67, which is large, we satisfy the third requirement. \nAll requirements are satisfied. \nThe claim is that college students “typically” gain 15 lb (or 6.8 kg) during \ntheir freshman year. Using differences in the format of “April weight - September \nweight,” that claim is expressed as md = 6.8 kg, so we use the following null and \nalternative hypotheses:\nH0: md = 6.8 kg H1: md ≠6.8 kg\nUsing technology, we can easily find that the 95% confidence interval estimate of \nthe difference is 0.2 kg 6 md 6 2.1 kg. That confidence interval does not include \nthe value of 6.8 kg, so there is sufficient evidence to warrant rejection of the null \nhypothesis. That confidence interval consists of positive values only, so there does \nappear to be weight gain, but it is likely to be between 0.4 lb (or 0.2 kg) and 4.6 lb \n(or 2.1 kg), not 15 lb. The concept of the “Freshman 15” appears to greatly exaggerate \nthe typical freshman weight gain. The “Freshman 15” is therefore a myth, but we \nshould qualify that conclusion by noting that the sample of 67 subjects includes \nvolunteers from Rutgers University and it is not a simple random sample, so it is \npossible that the conclusion is not correct.\nM.\n-\nTwins in Twinsburg\nDuring the first \nweekend in \nAugust of each \nyear, Twinsburg, \nOhio, celebrates \nits annual \n“Twins Days in \nTwinsburg” festival. Thousands \nof twins from around the world \nhave attended this festival in the \npast. Scientists saw the festival \nas an opportunity to study identi-\ncal twins. Because they have the \nsame basic genetic structure, \nidentical twins are ideal for study-\ning the different effects of hered-\nity and environment on a variety \nof traits, such as male baldness, \nheart disease, and deafness—\ntraits that were recently studied \nat one Twinsburg festival. A study \nof twins showed that myopia \n(near-sightedness) is strongly af-\nfected by hereditary factors, not \nby environmental factors such as \nwatching television, surfing the \nInternet, or playing computer or \nvideo games.\nAlternative Method Used When Population Is Not Normal and n \" 30\nBootstrap The Key Elements box near the beginning of this section included the fol-\nlowing requirement: The number of pairs of sample data is large (n 7 30) or the pairs \nof values have differences that are from a population having a distribution that is ap-\nproximately normal. If that condition is violated, we can use the “Bootstrap Procedure \nfor a Confidence Interval Estimate of a Parameter” included in Section 7-4. For each \npair of data values, find the difference d, then use the list of differences and apply the \nbootstrap method described in Section 7-4. Use percentiles to find the confidence in-\nterval that can be used for hypothesis tests. See Exercise 22 “Bootstrap.”\n",
    "424 \nCHAPTER 9 Inferences from Two Samples\nInferences with Two Means: Dependent Samples\nAccess tech instructions, videos, and data sets at www.TriolaStats.com\nTECH CENTER \nStatistical Literacy and Critical Thinking \n1. True Statements? For the methods of this section, which of the following statements are true?\na. When testing a claim using a simple random sample of ten matched pairs of heights, hypoth-\nesis tests using the P-value method, critical value method, and confidence interval method will \nall result in the same conclusion.\nb. The methods of this section are robust against departures from normality, which means that \nthe distribution of sample differences must be very close to a normal distribution.\nc. If we want to use a confidence interval to test the claim that md 6 0 with a 0.01 significance \nlevel, the confidence interval should have a confidence level of 98%.\nd. The methods of this section can be used with annual incomes of 50 randomly selected nurses \nin North Carolina and 50 randomly selected nurses in South Carolina.\ne. If we have ten matched pairs of heights of nurses, the methods of this section require that we \nuse a sample size of n = 20.\n2. Notation Listed below are body temperatures from five different subjects measured at 8 AM \nand again at 12 AM (from Data Set 2 “Body Temperatures”). Find the values of d and sd. In \ngeneral, what does md represent?\nTemperature 1°F2 at 8 AM\n97.8\n99.0\n97.4\n97.4\n97.5\nTemperature 1°F2 at 12 AM\n98.6\n99.5\n97.5\n97.3\n97.6\n3. Units of Measure If the values listed in Exercise 2 are changed so that they are expressed \nin Celsius degrees instead of Fahrenheit degrees, how are hypothesis test results affected?\n4. Degrees of Freedom If we use the sample data in Exercise 2 for constructing a 99% con-\nfidence interval, what is the number of degrees of freedom that should be used for finding the \ncritical value of ta>2? What is the critical value ta>2?\nIn Exercises 5–16, use the listed paired sample data, and assume that the samples are simple \nrandom samples and that the differences have a distribution that is approximately normal.\n5. Is Blood Pressure the Same for Both Arms? Listed below are systolic blood pres-\nsure measurements (mm Hg) taken from the right and left arms of the same woman (based on \ndata from “Consistency of Blood Pressure Differences Between the Left and Right Arms,” by \n Eguchi et al., Archives of Internal Medicine, Vol. 167). Use a 0.01 significance level to test for a \ndifference between the measurements from the two arms. What do you conclude?\nRight arm\n102\n101\n 94\n 79\n 79\nLeft arm\n175\n169\n182\n146\n144\n6. Heights of Presidents A popular theory is that presidential candidates have an advantage \nif they are taller than their main opponents. Listed below are heights (cm) of presidents along \nwith the heights of their main opponents.\n9-3 Basic Skills and Concepts\n",
    "9-3 Two Dependent Samples (Matched Pairs) \n425\na. Use the sample data with a 0.05 significance level to test the claim that for the population of \nheights of presidents and their main opponents, the differences have a mean greater than 0 cm \n(so presidents tend to be taller than their opponents).\nb. Construct the confidence interval that could be used for the hypothesis test described in part (a). \nWhat feature of the confidence interval leads to the same conclusion reached in part (a)?\nHeight (cm) of President\n185\n178\n175\n183\n193\n173\nHeight (cm) of Main Opponent\n171\n180\n173\n175\n188\n178\n7. Body Temperatures Listed below are body temperatures from seven different subjects \n measured at two different times in a day (from Data Set 2 “Body Temperatures” in Appendix B).\na. Use a 0.05 significance level to test the claim that there is no difference between body tem-\nperatures measured at 8 AM and at 12 AM.\nb. Construct the confidence interval that could be used for the hypothesis test in part (a). What \nfeature of the confidence interval leads to the same conclusion reached in part (a)?\nBody Temperature 1°F2 at 8 AM\n96.6\n97.0\n97.0\n97.8\n97.0\n97.4\n96.6\nBody Temperature 1°F2 at 12 AM\n99.0\n98.4\n98.0\n98.6\n98.5\n98.9\n98.4\n8. The Spoken Word Listed below are the numbers of words spoken in a day by each member \nof six different couples.\na. Use a 0.05 significance level to test the claim that among couples, males speak fewer words \nin a day than females.\nb. Construct the confidence interval that could be used for the hypothesis test described in part (a). \nWhat feature of the confidence interval leads to the same conclusion reached in part (a)?\nMale\n15,684\n26,429\n1,411\n7,771\n18,876\n15,477\n14,069\n25,835\nFemale\n24,625\n13,397\n18,338\n17,791\n12,964\n16,937\n16,255\n18,667\n9. Heights of Mothers and Daughters Listed below are heights (in.) of mothers and their \nfirst daughters. The data are from a journal kept by Francis Galton. (See Data Set 6 “Family \nHeights.”) Use a 0.05 significance level to test the claim that there is no difference in heights \nbetween mothers and their first daughters.\nHeight of Mother\n68.0\n60\n61.0\n63.5\n69\n64.0\n69\n64\n63.5\n66\nHeight of Daughter\n68.5\n60\n63.5\n67.5\n68\n65.5\n69\n68\n64.5\n63\n10. Heights of Fathers and Sons Listed below are heights (in.) of fathers and their first \nsons. The data are from a journal kept by Francis Galton. (See Data Set 6 “Family Heights”) \nUse a 0.05 significance level to test the claim that there is no difference in heights between \nfathers and their first sons.\nHeight of Father\n72\n66\n69\n70\n70\n70\n70\n75\n68.2\n65\nHeight of Son\n73\n68\n68\n71\n70\n70\n71\n71\n70.0\n63\n11. Friday the 13th Researchers collected data on the numbers of hospital admissions result-\ning from motor vehicle crashes, and results are given below for Fridays on the 6th of a month \nand Fridays on the following 13th of the same month (based on data from “Is Friday the 13th \nBad for Your Health?” by Scanlon et al., British Medical Journal, Vol. 307, as listed in the Data \nand Story Line online resource of data sets). Construct a 95% confidence interval estimate of \nthe mean of the population of differences between hospital admissions on days that are Friday \ncontinued\n",
    "426 \nCHAPTER 9 Inferences from Two Samples\nthe 6th of a month and days that are Friday the 13th of a month. Use the confidence interval \nto test the claim that when the 13th day of a month falls on a Friday, the numbers of hospital \nadmissions from motor vehicle crashes are not affected.\nFriday the 6th\n 9\n 6\n11\n11\n3\n 5\nFriday the 13th\n13\n12\n14\n10\n4\n12\n12. Before, After Treatment Results Captopril is a drug designed to lower systolic blood \npressure. When subjects were treated with this drug, their systolic blood pressure readings (in \nmm Hg) were measured before and after the drug was taken. Results are given in the accom-\npanying table (based on data from “Essential Hypertension: Effect of an Oral Inhibitor of An-\ngiotensin-Converting Enzyme,” by MacGregor et al., British Medical Journal, Vol. 2). Using a \n0.01 significance level, is there sufficient evidence to support the claim that captopril is effec-\ntive in lowering systolic blood pressure?\nSubject\nA\nB\nC\nD\nE\nF\nG\nH\nI\nJ\nK\nL\nBefore\n200\n174\n198\n170\n179\n182\n193\n209\n185\n155\n169\n210\nAfter\n191\n170\n177\n167\n159\n151\n176\n183\n159\n145\n146\n177\n13. Two Heads Are Better Than One Listed below are brain volumes (cm3) of twins from \nData Set 9 “IQ and Brain Size” in Appendix B. Construct a 99% confidence interval estimate \nof the mean of the differences between brain volumes for the first-born and the second-born \ntwins. What does the confidence interval suggest?\nFirst Born\n1005\n1035\n1281\n1051\n1034\n1079\n1104\n1439\n1029\n1160\nSecond Born\n 963\n1027\n1272\n1079\n1070\n1173\n1067\n1347\n1100\n1204\n14. Hypnotism for Reducing Pain A study was conducted to investigate the effectiveness \nof hypnotism in reducing pain. Results for randomly selected subjects are given in the accom-\npanying table (based on “An Analysis of Factors That Contribute to the Efficacy of Hypnotic \nAnalgesia,” by Price and Barber, Journal of Abnormal Psychology, Vol. 96, No. 1). The values \nare before and after hypnosis; the measurements are in centimeters on a pain scale, with higher \nvalues representing greater pain. Construct a 95% confidence interval for the mean of the “be-\nfore>after” differences. Does hypnotism appear to be effective in reducing pain?\nSubject\nA\nB\nC\nD\nE\nF\nG\nH\nBefore\n6.6\n6.5\n9.0\n10.3\n11.3\n8.1\n6.3\n11.6\nAfter\n6.8\n2.4\n7.4\n 8.5\n 8.1\n6.1\n3.4\n 2.0\n15. Self-Reported and Measured Male Heights As part of the National Health and Nutri-\ntion Examination Survey, the Department of Health and Human Services obtained self-reported \nheights (in.) and measured heights (in.) for males aged 12–16. Listed below are sample results. \nConstruct a 99% confidence interval estimate of the mean difference between reported heights \nand measured heights. Interpret the resulting confidence interval, and comment on the implica-\ntions of whether the confidence interval limits contain 0.\nReported\n68\n71\n63\n70\n71\n60\n65\n64\n54\n63\n66\n72\nMeasured\n67.9\n69.9\n64.9\n68.3\n70.3\n60.6\n64.5\n67.0\n55.6\n74.2\n65.0\n70.8\n16. Historical Data Set In 1908, “Student” (William Gosset) published the article “The Prob-\nable Error of a Mean” (Biometrika, Vol. 6, No. 1). He included the data listed below for two dif-\nferent types of straw seed (regular and kiln dried) that were used on adjacent plots of land. The \nlisted values are the yields of straw in cwt (100 lb, or hundredweight) per acre, and the yields \nare paired by the plot of land that they share.\ncontinued\n",
    "9-3 Two Dependent Samples (Matched Pairs) \n427\na. Using a 0.05 significance level, test the claim that there is no difference between the yields \nfrom the two types of seed.\nb. Construct a 95% confidence interval estimate of the mean difference between the yields \nfrom the two types of seed.\nc. Does it appear that either type of seed is better?\nRegular\n19.25\n22.75\n23\n23\n22.5\n19.75\n24.5\n15.5\n18\n14.25\n17\nKiln dried\n25\n24\n24\n28\n22.5\n19.5\n22.25\n16\n17.25\n15.75\n17.25\nLarger Data Sets. In Exercises 17–20, use the indicated Data Sets from Appendix B.  \nThe complete data sets can be found at www.TriolaStats.com. Assume that the paired \nsample data are simple random samples and the differences have a distribution that is \n approximately normal.\n17. Body Temperatures Repeat Exercise 7 “Body Temperatures” using all of the 8 AM and \n12 AM body temperatures on Day 2 as listed in Data Set 2 “Body Temperatures” in Appendix B. \nUse a significance level of 0.05.\n18. Heights of Mothers and Daughters Repeat Exercise 9 “Heights of Mothers and Daugh-\nters” using all of the heights of mothers and daughters listed in Data Set 6 “Family Heights” in \nAppendix B.\n19. Heights of Fathers and Sons Repeat Exercise 10 “Heights of Fathers and Sons” using \nall of the heights of fathers and sons listed in Data Set 6 “Family Heights” in Appendix B.\n20. Tobacco and Alcohol in Children’s Movies Refer to Data Set 13 “Alcohol and Tobacco \nin Movies” in Appendix B and use the times (seconds) that animated Disney movies showed \nthe use of tobacco and the times that they showed the use of alcohol. Use a 0.05 significance \nlevel to test the claim that the mean of the differences is greater than 0 sec so that more time is \ndevoted to showing tobacco than alcohol.\n21. Body Temperatures Refer to Data Set 2 “Body Temperatures” in Appendix B and use \nall of the matched pairs of body temperatures at 8 AM and 12 AM on Day 1. When using a \n0.05 significance level for testing a claim of a difference between the temperatures at 8 AM \nand at 12 AM on Day 1, how are the hypothesis test results and confidence interval results af-\nfected if the temperatures are converted from degrees Fahrenheit to degrees Celsius? What is \nthe relationship between the confidence interval limits for the body temperatures in degrees \nFahrenheit and the confidence interval limits for the body temperatures in degrees Celsius?\nHint: C = 5\n91F - 322.\n22. Bootstrap\na. If paired sample data (x, y) are such that the values of x do not appear to be from a popula-\ntion with a normal distribution, and the values of y do not appear to be from a population with \na normal distribution, does it follow that the values of d will not appear to be from a population \nwith a normal distribution?\nb. For the hypothesis test described in Exercise 21, use the temperatures in degrees Fahrenheit \nand find the 95% confidence interval estimate of md based on 1000 bootstrap samples. Generate \nthe bootstrap samples using the values of d.\n9-3 Beyond the Basics\n",
    "428 \nCHAPTER 9 Inferences from Two Samples\nKey Concept In this section we present the F test for testing claims made about two \npopulation variances (or standard deviations). The F test (named for statistician Sir \nRonald Fisher) uses the F distribution introduced in this section. The F test requires \nthat both populations have normal distributions. Instead of being robust, this test is \nvery sensitive to departures from normal distributions, so the normality requirement is \nquite strict. Part 1 describes the F test procedure for conducting a hypothesis test, and \nPart 2 gives a brief description of two alternative methods for comparing variation in \ntwo samples.\nPART 1   F Test as a Hypothesis Test with Two \nVariances or Standard Deviations\nThe following Key Elements box includes elements of a hypothesis test of a claim \nabout two population variances or two population standard deviations. The procedure \nis based on using two sample variances, but the same procedure is used for claims \nmade about two population standard deviations.\nThe actual F test could be two-tailed, left-tailed, or right-tailed, but we can make \ncomputations much easier by stipulating that the larger of the two sample variances is \ndenoted by s2\n1. It follows that the smaller sample variance is denoted as s2\n2. This stipu-\nlation of denoting the larger sample variance by s2\n1 allows us to avoid the somewhat \nmessy problem of finding a critical value of F for the left tail.\n9-4 \nTwo Variances or Standard Deviations\nKEY ELEMENTS \nHypothesis Test with Two Variances or Standard Deviations\nObjective\nConduct a hypothesis test of a claim about two population \nvariances or standard deviations. (Any claim made about \ntwo population standard deviations can be restated with an \nequivalent claim about two population variances, so the \nsame procedure is used for two population standard devia-\ntions or two population variances.)\nNotation\ns2\n1 = larger of the two sample variances\nn1 = size of the sample with the larger variance\ns2\n1 = variance of the population from which the sample \nwith the larger variance was drawn\nThe symbols s2\n2, n2, and s2\n2 are used for the other sample \nand population.\nRequirements\n1. The two populations are independent.\n2. The two samples are simple random samples.\n3. Each of the two populations must be normally distrib-\nuted, regardless of their sample sizes. This F test is not \nrobust against departures from normality, so it performs \npoorly if one or both of the populations have a distri-\nbution that is not normal. The requirement of normal \ndistributions is quite strict for this F test.\ncontinued\n",
    "9-4 Two Variances or Standard Deviations \n429\nTest Statistic for Hypothesis Tests with Two Variances (with H0: S2\n1 = S2\n2)\nF = s2\n1\ns2\n2\n 1where s2\n1 is the larger of the two sample variances2\nExplore the Data! Because the F test requirement of normal distributions is quite \nstrict, be sure to examine the distributions of the two samples using histograms and \nnormal quantile plots, and confirm that there are no outliers. (See “Assessing Normal-\nity” in Section 6-5.)\nF Distribution\nFor two normally distributed populations with equal variances 1s2\n1 = s2\n22, the \nsampling distribution of the test statistic F = s2\n1>s2\n2 is the F distribution shown \nin Figure 9-4 (provided that we have not yet imposed the stipulation that the larger \nsample variance is s2\n1). If you repeat the process of selecting samples from two \nnormally distributed populations with equal variances, the distribution of the ratio \ns2\n1>s2\n2 is the F distribution.\nP-Values: P-values are automatically provided by tech-\nnology. If technology is not available, use the computed \nvalue of the F test statistic with Table A-5 to find a range \nfor the P-value.\nCritical Values: Use Table A-5 to find critical F values \nthat are determined by the following:\n1. The significance level a (Table A-5 includes critical \nvalues for a = 0.025 and a = 0.05.)\n2. Numerator degrees of freedom = n1 −1 \n (determines column of Table A-5)\n3. Denominator degrees of freedom = n2 −1 \n (determines row of Table A-5). For significance level \na = 0.05, refer to Table A-5 and use the right-tail  \narea of 0.025 or 0.05 depending on the type of test,  \nas shown here:\n • Two-tailed test: Use Table A-5 with 0.025 in the right \ntail. (The significance level of 0.05 is divided between \nthe two tails, so the area in the right tail is 0.025.)\n • One-tailed test: Use Table A-5 with a = 0.05 in the \nright tail.\nFind the critical F value for the right tail: Because we are stip-\nulating that the larger sample variance is s2\n1, all one-tailed tests \nwill be right-tailed and all two-tailed tests will require that we \nfind only the critical value located to the right. (We have no \nneed to find the critical value at the left tail, which is not very \ndifficult. See Exercise 19 “Finding Lower Critical F Values.”)\n0\nNot symmetric\n(skewed to the right)\nF\nNonnegative \nvalues only\na\nValue of F 5\ns1\n2\n2\ns2\nFIGURE 9-4 F Distribution\n",
    "430 \nCHAPTER 9 Inferences from Two Samples\nThere is a different F distribution for each different pair of degrees of freedom for the \nnumerator and denominator.\nSee Figure 9-4 and note these properties of the F distribution:\n \n■The F distribution is not symmetric.\n \n■Values of the F distribution cannot be negative.\n \n■The exact shape of the F distribution depends on the two different degrees of \nfreedom.\nInterpreting the Value of the F Test Statistic\nIf the two populations have equal variances, the ratio s2\n1>s2\n2 will tend to be close to 1. \nBecause we are stipulating that s2\n1 is the larger sample variance, the ratio s2\n1>s2\n2 will be \na large number whenever s2\n1 and s2\n2 are far apart in value. Consequently, a value of F \nnear 1 will be evidence in favor of s2\n1 = s2\n2, but a large value of F will be evidence \nagainst s2\n1 = s2\n2.\nLarge values of F are evidence against S2\n1 = S2\n2.\nEXAMPLE 1  Effect of Birth Weight on IQ Score\nWhen investigating a relationship between birth weight and IQ, researchers found \nthat 258 subjects with extremely low birth weights (less than 1000 g) had Wechsler \nIQ scores at age 8 with a mean of 95.5 and a standard deviation of 16.0. For 220 \nsubjects with normal birth weights, the mean IQ score at age 8 is 104.9 and the \nstandard deviation is 14.1. (Based on data from “Neurobehavioral Outcomes of \nSchool-Age Children Born Extremely Low Birth Weight or Very Preterm in the \n1990s,” by Anderson et al., Journal of the American Medical Association, Vol. 289, \nNo. 24.) Using a 0.05 significance level, test the claim that babies with extremely \nlow birth weights and babies with normal birth weights have different amounts of \nvariation.\nSOLUTION\nREQUIREMENT CHECK (1) The two populations are independent of each other. The \ntwo samples are not matched in any way. (2) Given the design for the study, we \n assume that the two samples can be treated as simple random samples. (3) Based on \nan analysis of the original data, assume that the two samples are from populations \nhaving normal distributions. \nInstead of using the sample standard deviations to test the claim of equal popu-\nlation standard deviations, we use the sample variances to test the claim of equal \npopulation variances, but we can state the hypotheses and conclusions in terms of \nstandard deviations. Because we stipulate in this section that the larger variance is \ndenoted by s2\n1, we let s2\n1 = 16.02 and s2\n2 = 14.12.\nStep 1: The claim of different amounts of variation is equivalent to a claim of dif-\nferent standard deviations, which is expressed symbolically as s1 ≠s2.\nStep 2: If the original claim is false, then s1 = s2.\nStep 3: Because the null hypothesis is the statement of equality and because the al-\nternative hypothesis cannot contain equality, we have\nH0\n : s1 = s2  H1\n : s1 ≠s2 1original claim2\n",
    "9-4 Two Variances or Standard Deviations \n431\nStep 4: The significance level is a = 0.05.\nStep 5: Because this test involves two population variances, we use the F \n distribution.\nStep 6: The test statistic is\nF = s2\n1\ns2\n2\n= 16.02\n14.12 = 1.2877\nP-Value Method\nTechnology Using technology, we can find that the P-value is 0.0537, so we fail to \nreject H0. (See the accompanying Statdisk display.)\nTable The format and limitations of Table A-5 make the P-value method a bit tricky \nwithout technology, but here goes. For a two-tailed test with significance level 0.05, \nthere is an area of 0.025 in the right tail, so we use the two pages for the F distribu-\ntion (Table A-5) with “0.025 in the right tail.” With numerator degrees of freedom =\nn1 - 1 = 257 and denominator degrees of freedom = n2 - 1 = 219, Table A-5 \ntells us that the critical value of F is somewhere between 1.0000 and 1.4327. The test \nstatistic of F = 1.2877 is between 1.000 and 1.4327, so Table A-5 is no help for this \nexample.\nCritical Value Method Using technology, we find that the critical values are 0.7755 \nand 1.2928. (See the accompanying Statdisk display.) The test statistic F = 1.2877 \nfalls between those two critical values, so the test statistic does not fall in the critical \nregion and we fail to reject H0.\nINTERPRETATION\nThere is not sufficient evidence to support the claim that the two populations have \ndifferent amounts of variation.\nStatdisk\nCaution: Part 2 of Section 9-2 includes methods for testing claims about two popula-\ntion means, and one of those methods has a requirement that s1 = s2. Using the F \ntest is not recommended as a way to decide whether this requirement is met. For Sec-\ntion 9-2, using the F test runs the risk of using differences that are too small to have an \neffect on the t test for two independent samples. That approach is often described as \nbeing analogous to sending someone out to sea in a rowboat (the preliminary F test) to \ndetermine whether the sea is safe for an ocean liner (the t test).\nPART 2\nAlternative Methods\nPart 1 of this section presents the F test for testing claims made about the standard \ndeviations (or variances) of two independent populations. Because that test is so sen-\nsitive to departures from normality, we now briefly describe two alternative methods \nthat are not so sensitive to departures from normality.\nCount Five\nThe count five method is a relatively simple alternative to the F test, and it does not \nrequire normally distributed populations. (See “A Quick, Compact, Two-Sample \nDispersion Test: Count Five,” by McGrath and Yeh, American Statistician, Vol. 59, \n",
    "432 \nCHAPTER 9 Inferences from Two Samples\nNo. 1.) If the two sample sizes are equal, and if one sample has at least five of the larg-\nest mean absolute deviations (MAD), then we conclude that its population has a larger \nvariance. See Exercise 17 “Count Five Test” for the specific procedure.\nLevene-Brown-Forsythe Test\nThe Levene-Brown-Forsythe test (or modified Levene’s test) is another alternative \nto the F test, and it is much more robust against departures from normality. This \ntest begins with a transformation of each set of sample values. Within the first sam-\nple, replace each x value with \u001ax - median\u001a, and apply the same transformation \nto the second sample. Using the transformed values, conduct a t test of equality of \nmeans for independent samples, as described in Part 1 of Section 9-2. Because the \ntransformed values are now deviations, the t test for equality of means is actually \na test comparing variation in the two samples. See Exercise 18 “Levene-Brown-\nForsythe Test.”\nThere are other alternatives to the F test, as well as adjustments that improve the \nperformance of the F test. See “Fixing the F Test for Equal Variances,” by Shoemaker, \nAmerican Statistician, Vol. 57, No. 2.\nInferences from Two Standard Deviations\nAccess tech instructions, videos, and data sets at www.TriolaStats.com\nTECH CENTER \n9-4 Basic Skills and Concepts\nStatistical Literacy and Critical Thinking \n1. F Test Statistic\na. If s2\n1 represents the larger of two sample variances, can the F test statistic ever be less than 1?\nb. Can the F test statistic ever be a negative number?\nc. If testing the claim that s2\n1 ≠s2\n2, what do we know about the two samples if the test statis-\ntic F is very close to 1.\nd. Is the F distribution symmetric, skewed left, or skewed right?\n2. F Test If using the sample data in Data Set 1 “Body Data” in Appendix B for a test of \nthe claim that heights of men and heights of women have different variances, we find that \ns = 7.48296 cm for women and s = 7.10098 cm for men.\na. Find the values of s2\n1 and s2\n2 and express them with appropriate units of measure.\nb. Identify the null and alternative hypotheses.\nc. Find the value of the F test statistic and round it to four decimal places.\nd. The P-value for this test is 0.5225. What do you conclude about the stated claim?\n3. Testing Normality For the hypothesis test described in Exercise 2, the sample sizes are \nn1 = 147 and n2 = 153. When using the F test with these data, is it correct to reason that there \nis no need to check for normality because n1 7 30 and n2 7 30?\n4. Robust What does it mean when we say that the F test described in this section is not robust \nagainst departures from normality?\n",
    "9-4 Two Variances or Standard Deviations \n433\nIn Exercises 5–16, test the given claim.\n5. Testing Effects of Alcohol Researchers conducted an experiment to test the effects of \nalcohol. Errors were recorded in a test of visual and motor skills for a treatment group of 22 \npeople who drank ethanol and another group of 22 people given a placebo. The errors for the \ntreatment group have a standard deviation of 2.20, and the errors for the placebo group have a \nstandard deviation of 0.72 (based on data from “Effects of Alcohol Intoxication on Risk Taking, \nStrategy, and Error Rate in Visuomotor Performance,” by Streufert et al., Journal of  Applied \nPsychology, Vol. 77, No. 4). Use a 0.05 significance level to test the claim that the treatment \ngroup has errors that vary significantly more than the errors of the placebo group.\n6. Second-Hand Smoke Data Set 14 “Passive and Active Smoke” includes cotinine lev-\nels measured in a group of smokers (n = 40, x = 172.48 ng>mL, s = 119.50 ng>mL) \nand a group of nonsmokers not exposed to tobacco smoke (n = 40, x = 16.35 ng>mL, \ns = 62.53 ng>mL). Cotinine is a metabolite of nicotine, meaning that when nicotine is ab-\nsorbed by the body, cotinine is produced.\na. Use a 0.05 significance level to test the claim that the variation of cotinine in smokers is \ngreater than the variation of cotinine in nonsmokers not exposed to tobacco smoke.\nb. The 40 cotinine measurements from the nonsmoking group consists of these values (all in \nng>mL): 1, 1, 90, 244, 309, and 35 other values that are all 0. Does this sample appear to be \nfrom a normally distributed population? If not, how are the results from part (a) affected?\n7. Baseline Characteristics In journal articles about clinical experiments, it is common to \ninclude baseline characteristics of the different treatment groups so that they can be compared. \nIn an article about the effects of different diets, a table of baseline characteristics showed that \n40 subjects treated with the Atkins diet had a mean age of 47 years with a standard deviation \nof 12 years. Also, 40 subjects treated with the Zone diet had a mean age of 51 years with a \nstandard deviation of 9 years. Use a 0.05 significance level to test the claim that subjects from \nboth treatment groups have ages with the same amount of variation. How are comparisons of \ntreatments affected if the treatment groups have different characteristics?\n8. IQ and Lead Exposure Data Set 8 “IQ and Lead” in Appendix B lists full IQ scores for a \nrandom sample of subjects with low lead levels in their blood and another random sample of \nsubjects with high lead levels in their blood. The statistics are summarized below. Use a 0.05 \nsignificance level to test the claim that IQ scores of people with low lead levels vary more than \nIQ scores of people with high lead levels.\n Low Lead Level:  n = 78, x = 92.88462, s = 15.34451\n High Lead Level:  n = 21, x = 86.90476, s = 8.988352\n9. Magnet Treatment of Pain Researchers conducted a study to determine whether magnets are \neffective in treating back pain, with results given below (based on data from “Bipolar  Permanent \nMagnets for the Treatment of Chronic Lower Back Pain: A Pilot Study,” by Collacott, Zimmerman, \nWhite, and Rindone, Journal of the American Medical Association, Vol. 283, No. 10). The values \nrepresent measurements of pain using the visual analog scale. Use a 0.05 significance level to test the \nclaim that those given a sham treatment (similar to a placebo) have pain reductions that vary more \nthan the pain reductions for those treated with magnets.\n Reduction in Pain Level After Sham Treatment:  n = 20, x = 0.44, s = 1.4\n Reduction in Pain Level After Magnet Treatment:  n = 20, x = 0.49, s = 0.96\n10. Humidity in Treating Croup In a randomized controlled trial conducted with children \nsuffering from viral croup, 46 children were treated with low humidity while 46 other children \nwere treated with high humidity. Researchers used the Westley Croup Score to assess the re-\nsults after one hour. The low-humidity group had a mean score of 0.98 with a standard devia-\ntion of 1.22, while the high-humidity group had a mean score of 1.09 with a standard deviation \nof 1.11 (based on data from “Controlled Delivery of High vs Low Humidity vs Mist Therapy \ncontinued\n",
    "434 \nCHAPTER 9 Inferences from Two Samples\nfor Croup Emergency Departments,” by Scolnik et al., Journal of the American Medical Asso-\nciation, Vol. 295, No. 11). Use a 0.05 significance level to test the claim that the two groups are \nfrom populations with the same standard deviation.\n11. Cigarette Filters and Nicotine Listed below are statistics from measured nicotine con-\ntents of randomly selected filtered and non-filtered king-size cigarettes (based on data from \nthe Federal Trade Commission). Use a 0.05 significance level to test the claim that king-size \ncigarettes with filters have amounts of nicotine that vary more than the amounts of nicotine in \nnon-filtered king-size cigarettes.\n Filtered Kings \n n = 21, x = 0.94 mg, s = 0.31 mg\n Non@filtered Kings  n = 8, x = 1.65 mg, s = 0.16 mg\n12. Zinc Treatment Use a 0.05 significance level to test the claim that weights of babies born \nto mothers given placebos vary more than weights of babies born to mothers given zinc supple-\nments. Use the following statistics (based on data from “The Effect of Zinc Supplementation \non Pregnancy Outcome,” by Goldenberg et al., Journal of the American Medical Association, \nVol. 274, No. 6).\n Placebo group: \n n = 16, x = 3088 g, s = 728 g\n Treatment group:  n = 16, x = 3214 g, s = 669 g\n13. Body Temperatures of Men and Women Listed below are the body temperatures (°F) mea-\nsured in males at 8 AM on Day 2 as listed in Data Set 2 “Body Temperatures” in  Appendix B. \nFor the body temperatures of females measured at the same time, we get n = 59, x = 97.45°F,\nand s = 0.66°F. Use a 0.05 significance level to test the claim that men have body tempera-\ntures that vary more than the body temperatures of women.\n97.0 98.0 96.4 98.2 98.8 98.6 97.8 98.7 97.8 96.4 96.9\n14. Radiation in Baby Teeth Listed below are amounts of strontium-90 (in millibecquerels, \nor mBq, per gram of calcium) in a simple random sample of baby teeth obtained from Pennsyl-\nvania residents and New York residents born after 1979 (based on data from “An Unexpected \nRise in Strontium-90 in U.S. Deciduous Teeth in the 1990s,” by Mangano et al., Science of the \nTotal Environment, Vol. 317). Use a 0.05 significance level to test the claim that amounts of \nstrontium-90 from Pennsylvania residents vary more than amounts from New York residents.\nPennsylvania:\n155\n142\n149\n130\n151\n163\n151\n142\n156\n133\n138\n161\nNew York:\n133\n140\n142\n131\n134\n129\n128\n140\n140\n140\n137\n143\n15. Longevity Listed below are the numbers of years that popes and British monarchs (since \n1690) lived after their election or coronation. Treat the values as simple random samples from \na larger population. Use a 0.05 significance level to test the claim that both populations of lon-\ngevity times have the same variation.\nPopes:\n2\n9\n21\n3\n6\n10\n18\n11\n6\n25\n23\n6\n2\n15\n32\n25\n11\n8\n17\n19\n5\n15\n0\n26\nKings and Queens:\n17\n6\n13\n12\n13\n33\n59\n10\n7\n63\n9\n25\n36\n15\n16. Blanking Out on Tests Many students have had the unpleasant experience of panicking \non a test because the first question was exceptionally difficult. The arrangement of test items \nwas studied for its effect on anxiety. The following scores are measures of “debilitating test \nanxiety,” which most of us call panic or blanking out (based on data from “Item Arrangement, \nCognitive Entry Characteristics, Sex and Test Anxiety as Predictors of Achievement in Exami-\nnation Performance,” by Klimko, Journal of Experimental Education, Vol. 52, No. 4.) Using a \n0.05 significance level, test the claim that the two populations of scores have different amounts \nof variation. The data are listed on the top of the next page.\n",
    "Questions Arranged from Easy to Difficult\nQuestions Arranged from Difficult to Easy\n24.64\n39.29\n16.32\n32.83\n28.02\n33.62\n34.02\n26.63\n30.26\n33.31\n20.60\n21.13\n26.69\n28.90\n35.91\n26.68\n29.49\n35.32\n26.43\n24.23\n 7.10\n32.86\n21.06\n27.24\n32.34\n29.34\n33.53\n28.89\n28.71\n31.73\n30.02\n21.96\n27.62\n42.91\n30.20\n32.54\n25.49\n38.81\n27.85\n30.29\n30.72\n17. Count Five Test for Comparing Variation in Two Populations Repeat Exercise 16 \n“Blanking Out on Tests,” but instead of using the F test, use the following procedure for the \n“count five” test of equal variations (which is not as complicated as it might appear).\na. For each value x in the first sample, find the absolute deviation \u001ax - x \u001a , then sort the abso-\nlute deviation values. Do the same for the second sample.\nb. Let c1 be the count of the number of absolute deviation values in the first sample that are \ngreater than the largest absolute deviation value in the second sample. Also, let c2 be the count \nof the number of absolute deviation values in the second sample that are greater than the largest \nabsolute deviation value in the first sample. (One of these counts will always be zero.)\nc. If the sample sizes are equal 1n1 = n22, use a critical value of 5. If n1 ≠n2, calculate the \ncritical value shown below.\n log1a>22\n log  a\nn1\nn1 + n2\nb\nd. If c1 Ú critical value, then conclude that s2\n1 7 s2\n2. If c2 Ú critical value, then conclude \nthat s2\n2 7 s2\n1. Otherwise, fail to reject the null hypothesis of s2\n1 = s2\n2.\n18. Levene-Brown-Forsythe Test Repeat Exercise 16 “Blanking Out on Tests” using the \nLevene-Brown-Forsythe test.\n19. Finding Lower Critical F Values For hypothesis tests that are two-tailed, the methods of \nPart 1 require that we need to find only the upper critical value. Let’s denote the upper critical \nvalue by FR, where the subscript indicates the critical value for the right tail. The lower critical \nvalue FL (for the left tail) can be found as follows: (1) Interchange the degrees of freedom used \nfor finding FR; (2) then, using the degrees of freedom found in Step 1, find the F value from \nTable A-5; (3) take the reciprocal of the F value found in Step 2, and the result is FL. Find the \ncritical values FL and FR for Exercise 16 “Blanking Out on Tests.”\n9-4 Beyond the Basics\nIn Exercises 1–5, use the following survey results: Randomly selected subjects were asked if \nthey were aware that the earth has lost half of its wildlife population during the past  \n50 years. Among 1121 women, 23% said that they were aware. Among 1084 men, 26% said \nthat they were aware (based on data from a Harris poll).\n1. Biodiversity Identify the null and alternative hypotheses resulting from the claim that for \nthe people who were aware of the statement, the proportion of women is equal to the propor-\ntion of men.\nChapter Quick Quiz\nCHAPTER 9 Chapter Quick Quiz \n435\n",
    "436 \nCHAPTER 9 Inferences from Two Samples\n2. Biodiversity Find the values of x1 (the number of women who were aware of the statement), \nx2 (the number of men who were aware of the statement), pn1, pn2, and the pooled proportion p\nobtained when testing the claim given in Exercise 1.\n3. Biodiversity When testing the claim that p1 = p2, a test statistic of z = -1.64 is obtained. \nFind the P-value for the hypothesis test.\n4. Biodiversity When using the given sample data to construct a 95% confidence interval esti-\nmate of the difference between the two population proportions, the result of (-0.0659, 0.00591) \nis obtained from technology.\na. Express that confidence interval in a format that uses the symbol 6.\nb. What feature of the confidence interval is a basis for deciding whether there is a significant \ndifference between the proportion of women aware of the statement and the proportion of men \nwho are aware?\n5.  Biodiversity Assume that a P-value of 0.1 is obtained when testing the claim given in \n Exercise 1 “Biodiversity.” What should be concluded about the null hypothesis? What should \nbe the final conclusion?\n6. True? Determine whether the following statement is true: When random samples of 50 male \nnurses and 50 female nurses are obtained and we want to test the claim that male nurses and \nfemale nurses have different mean annual incomes, there is no need to confirm that the samples \nare from populations with normal distributions.\n7.  True? When we collect random samples to test the claim that the proportion of female \nsurgeons in the United States is equal to the proportion of female surgeons outside the United \nStates, there is a requirement that np Ú 30 and nq Ú 30.\n8. Dependent or Independent? Listed below are measures of visual acuity of the right and \nleft eyes of five subjects (from Data Set 5 “Vision” in Appendix B). Are the data dependent or \nindependent?\nRight eye\n60\n25\n20\n50\n30\nLeft eye\n80\n20\n25\n50\n25\n9. Hypotheses Identify the null and alternative hypotheses for using the sample data from \n Exercise 8 in testing the claim that for differences between right-eye measurements and left-\neye measurements, those differences are from a population with a mean equal to 0.\n10. Test Statistics Identify the test statistics that should be used for testing the following \nclaims.\na. The mean of the differences between platelet counts of husbands and platelet counts of their \nwives is equal to 0.\nb. The mean platelet count of adult Californians is equal to the mean platelet count of adult Texans.\nc. The proportion of men with diabetes is equal to the proportion of women with diabetes.\nd. The variation among pulse rates of women is equal to the variation among pulse rates of men.\n1. Blinding Among 13,200 submitted abstracts that were blindly evaluated (with authors and \ninstitutions not identified), 26.7% were accepted for publication. Among 13,433 abstracts that \nwere not blindly evaluated, 29.0% were accepted (based on data from “Effect of Blinded Peer \nReview on Abstract Acceptance,” by Ross et al., Journal of the American Medical Association, \nVol. 295, No. 14). Use a 0.01 significance level to test the claim that the acceptance rate is the \nsame with or without blinding. How might the results be explained?\nReview Exercises\n",
    "2. Blinding Construct the confidence interval that could be used to test the claim in Exercise 1. \nWhat feature of the confidence interval leads to the same conclusion from Exercise 1?\n3. Heights Listed below are heights (cm) randomly selected from the sample of women and \nheights (cm) randomly selected from the sample of men (from Data Set 1 “Body Data” in \n Appendix B). Use a 95% confidence level to estimate the magnitude of the difference between \nthe mean height of women and the mean height of men.\nWomen:\n160.3\n167.7\n166.9\n153.3\n160.0\n177.3\n169.1\n134.5\n163.3\n171.1\nMen:\n190.3\n169.8\n179.8\n179.8\n177.0\n178.5\n173.5\n178.7\n179.0\n181.3\n4. Heights Use a 0.01 significance level with the sample data from Exercise 3 to test the claim \nthat women have heights with a mean that is less than the mean height of men.\n5. Effects of Physical Training A study was conducted to investigate effects of physical \ntraining. Sample data from ten subjects are listed below, with all weights given in kilograms. \n(See “Effect of Endurance Training on Possible Determinants of VO2 During Heavy Exercise,” \nby Casaburi et al., Journal of Applied Physiology, Vol. 62, No. 1.)\na. Is there sufficient evidence to conclude that there is a difference between the pre-training and \npost-training weights? What do you conclude about the effect of training on weight?\nb. Construct a 95% confidence interval for the mean of the differences between pre-training \nand post-training weights.\nPre-training:\n99\n57\n62\n69\n74\n77\n59\n92\n70\n85\nPost-training:\n94\n57\n62\n69\n66\n76\n58\n88\n70\n84\n6. Variation of Heights Use the sample data given in Exercise 3 “Heights” and test the claim \nthat women and men have heights with the same variation. Use a 0.05 significance level.\nCHAPTER 9 Cumulative Review Exercises \n437\nFamily Heights. In Exercises 1–5, use the following heights (in.) of fathers, mothers, and \ntheir adult sons (from Data Set 6 “Family Heights”). The data are matched so that each col-\numn consists of heights from the same family.\nFather\n68.0\n68.0\n65.5\n66.0\n67.5\n70.0\n68.0\n71.0\nMother\n64.0\n60.0\n63.0\n59.0\n62.0\n69.0\n65.5\n66.0\nSon\n71.0\n64.0\n71.0\n68.0\n70.0\n71.0\n71.7\n71.0\n1. a. Are the three samples independent or dependent? Why?\nb. Find the mean, median, range, standard deviation, and variance of the heights of the sons. \nExpress results with the appropriate units.\nc. What is the level of measurement of the sample data (nominal, ordinal, interval, ratio)?\nd. Are the original unrounded heights discrete data or continuous data?\n2. Scatterplot Construct a scatterplot of the paired father>son heights. What does the graph \nsuggest?\n3. Confidence Interval Construct a 95% confidence interval estimate of the mean height of \nsons. Write a brief statement that interprets the confidence interval.\n4. Hypothesis Test Use a 0.05 significance level to test the claim that differences between \nheights of fathers and their sons have a mean of 0 in.\nCumulative Review Exercises\n",
    "438 \nCHAPTER 9 Inferences from Two Samples\n5.  Assessing Normality Refer to the accompanying normal quantile plot to determine \nwhether the sample of heights of fathers appears to be from a normally distributed population.\n6. Braking Reaction Times: Histogram Listed below are sorted braking reaction times \n(in 1>10,000 sec) for male and female subjects (based on data from the RT-2S Brake Reac-\ntion Time Tester). Construct a histogram for the reaction times of males. Use a class width \nof 8 and use 28 as the lower limit of the first class. Instead of using class boundaries for the \nhorizontal axis, use class midpoint values. Does it appear that the data are from a population \nwith a normal distribution?\nMale\n28\n30\n31\n34\n34\n36\n36\n36\n36\n38\n39\n40\n40\n40\n40\n41\n41\n41\n42\n42\n44\n46\n47\n48\n48\n49\n51\n53\n54\n54\n56\n57\n60\n61\n61\n63\nFemale\n22\n24\n34\n36\n36\n37\n39\n41\n41\n43\n43\n45\n45\n47\n53\n54\n54\n55\n56\n57\n57\n57\n58\n61\n62\n63\n66\n67\n68\n71\n72\n76\n77\n78\n79\n80\n7. Braking Reaction Times: Normal? The accompanying normal quantile plot is obtained \nby using the braking reaction times of females listed in Exercise 6. Interpret this graph.\n8. Braking Reaction Times: Boxplots Use the same data from Exercise 6 and use the same \nscale to construct a boxplot of the braking reaction times of males and another boxplot for the \nbraking reaction times of females. What do the boxplots suggest?\n9. Braking Reaction Times: Hypothesis Test Use the sample data from Exercise 6 with \na 0.01 significance level to test the claim that males and females have the same mean braking \nreaction time.\n10. Braking Reaction Times: Confidence Intervals\na. Construct a 99% confidence interval estimate of the mean braking reaction time of males, \nconstruct a 99% confidence interval estimate of the mean braking reaction time of females, and \nthen compare the results.\nb. Construct a 99% confidence interval estimate of the difference between the mean braking \nreaction time of males and the mean braking reaction time of females.\nc. Which is better for comparing the mean reaction times of males and females: the results \nfrom part (a) or the results from part (b)?\n",
    "Many technologies are capable of generating normally distributed data drawn from a popula-\ntion with a specified mean and standard deviation. In Example 3 of Section 6-1, we noted that \nbone density test scores are measured as z scores having a normal distribution with a mean of \n0 and a standard deviation of 1. Generate two sets of sample data that represent simulated bone \ndensity scores, as shown below.\n• Treatment Group: Generate 10 sample values from a normally distributed population of \nbone density scores with mean 0 and standard deviation 1.\n• Placebo Group: Generate 15 sample values from a normally distributed population of bone \ndensity scores with mean 0 and standard deviation 1.\nStatdisk: \nSelect Data, then Normal Generator.\nMinitab: \nSelect Calc, Random Data, Normal.\nExcel: \nSelect Data Analysis, Random Number Generation.\nTI-83 , 84 Plus: \n Press MATH, select PROB, then use randNorm function with \nthe format of (x, s, n).\n \nStatCrunch: \nClick on Data, select Simulate, select Normal.\nBecause each of the two samples consists of random selections from a normally distributed \npopulation with a mean of 0 and a standard deviation of 1, the data are generated so that both \ndata sets really come from the same population, so there should be no difference between the \ntwo sample means.\na. After generating the two data sets, use a 0.10 significance level to test the claim that the two \nsamples come from populations with the same mean.\nb. If this experiment is repeated many times, what is the expected percentage of trials leading \nto the conclusion that the two population means are different? How does this relate to a type I \nerror?\nc. If your generated data lead to the conclusion that the two population means are different, \nwould this conclusion be correct or incorrect in reality? How do you know?\nd. If part (a) is repeated 20 times, what is the probability that none of the hypothesis tests leads \nto rejection of the null hypothesis?\ne. Repeat part (a) 20 times. How often was the null hypothesis of equal means rejected? Is this \nthe result you expected?\nTechnology Project\nCHAPTER 9 Technology Project \n439\n",
    "440 \nCHAPTER 9 Inferences from Two Samples\nFROM DATA TO DECISION\nCritical Thinking: Ages of workers killed  \nin the Triangle Factory fire\nListed below are the ages (years) of the 146 employees who \nperished in the Triangle Factory fire that occurred on March \n25, 1911, in Manhattan (based on data from the Kheel Cen-\nter and the New York Times). One factor contributing to the \nlarge number of deaths is that almost all exits were locked so \nthat employees could be checked for theft when they finished \nwork at the end of the day. That fire revealed grossly poor \nand unsafe working conditions that led to changes in building \ncodes and labor laws.\nAnalyzing the Results\n1. First explore the combined male and female ages using \nsuitable statistics and graphs. What is the mean age? What \nare the minimum and maximum ages? What is the standard \ndeviation of the ages? Are there any outliers? Describe the \ndistribution of the ages.\n2. Examination of the two lists shows that relatively few men \nperished in the fire. Treat the ages as sample data and deter-\nmine whether there is sufficient evidence to support the claim \nthat among the workers who perish in such circumstances, \nthe majority are women.\n3. Construct a 95% confidence interval estimate of the mean \nage of males and construct another 95% confidence interval \nestimate of the mean age of females. Compare the results.\n4. Treat the ages as sample data and determine whether there \nis sufficient evidence to support the claim that female work-\ners have a mean age that is less than that of male workers.\n5. Treat the ages as sample data and determine whether there \nis sufficient evidence to support the claim that ages of males \nand females have different standard deviations.\n6. Based on the preceding results, identify any particularly \nnotable features of the data.\nMales\n38\n19\n30\n24\n23\n23\n19\n18\n19\n33\n17\n22\n33\n25\n20\n23\n22\nFemales\n24\n16\n25\n31\n22\n18\n19\n22\n16\n23\n17\n15\n21\n18\n17\n17\n17\n31\n20\n36\n18\n25\n30\n16\n25\n25\n21\n19\n17\n18\n20\n18\n26\n26\n16\n18\n18\n17\n22\n17\n20\n22\n18\n20\n16\n25\n18\n40\n21\n18\n19\n19\n18\n18\n19\n16\n19\n16\n16\n21\n33\n21\n14\n22\n19\n19\n23\n19\n18\n21\n39\n20\n14\n27\n22\n15\n19\n16\n16\n19\n18\n21\n18\n19\n19\n20\n18\n43\n16\n20\n18\n30\n21\n22\n18\n21\n35\n22\n21\n22\n21\n22\n17\n24\n25\n20\n18\n32\n20\n21\n19\n24\n17\n18\n30\n18\n16\n22\n22\n17\n22\n20\n15\n20\n17\n21\n21\n18\n17\n",
    "Cooperative Group Activities\n1. Out-of-class activity Collect sample data and test the claim that people who exercise tend \nto have pulse rates that are lower than those who do not exercise.\n2. Out-of-class activity Collect sample data and test the claim that the proportion of female \nstudents who smoke is equal to the proportion of male students who smoke.\n3. Out-of-class activity Measure and record the height of the man and woman from each of \nseveral different couples. Estimate the mean of the differences between the heights of men and \nthe heights of their partners. Compare the result to the difference between the mean height of \nmen and the mean height of women included in Data Set 1 “Body Data” in Appendix B. Do the \nresults suggest that height is a factor when people select partners?\n4. In-class activity Divide into groups according to gender, with about 10 or 12 students in \neach group. Each group member should record his or her pulse rate by counting the number of \nheartbeats in 1 minute, and then the group statistics 1n, x, s2should be calculated. The groups \nshould test the null hypothesis of no difference between their mean pulse rate and the mean of \nthe pulse rates for the population from which subjects of the same gender were selected for \nData Set 1 “Body Data” in Appendix B.\n5. Out-of-class activity Randomly select a sample of male students and a sample of female \nstudents and ask each selected person a yes>no question, such as whether the federal govern-\nment should fund stem cell research. Record the response, the gender of the respondent, and \nthe gender of the person asking the question. Use a formal hypothesis test to determine whether \nthere is a difference between the proportions of yes responses from males and females. Also, \ndetermine whether the responses appear to be influenced by the gender of the interviewer.\n6. Out-of-class activity Construct a short survey of just a few questions, including a ques-\ntion asking the subject to report his or her height. After the subject has completed the survey, \nmeasure the subject’s height (without shoes) using an accurate measuring system. Record the \ngender, reported height, and measured height of each subject. Do male subjects appear to exag-\ngerate their heights? Do female subjects appear to exaggerate their heights? Do the errors for \nmales appear to have the same mean as the errors for females?\n7. In-class activity Without using any measuring device, ask each student to draw a line be-\nlieved to be 3 in. long and another line believed to be 3 cm long. Then use rulers to measure and \nrecord the lengths of the lines drawn. Record the errors along with the genders of the students \nmaking the estimates. Test the claim that when estimating the length of a 3-in. line, the mean \nerror from males is equal to the mean error from females. Also, do the results show that we \nhave a better understanding of the British system of measurement (inches) than the SI system \n(centimeters)?\n8. Out-of-class activity Obtain sample data and test the claim that husbands are older than \ntheir wives.\n9. Out-of-class activity Survey married couples and record the number of credit cards each \nperson has. Analyze the paired data to determine whether husbands have more credit cards, \nwives have more credit cards, or they both have about the same number of credit cards. Try to \nidentify reasons for any discrepancy.\n10. Out-of-class activity Obtain sample data to test the claim that in the college library, sci-\nence books have a mean age that is less than the mean age of novels.\n11. Out-of-class activity Conduct experiments and collect data to test the claim that there are \nno differences in taste between ordinary tap water and different brands of bottled water.\nCHAPTER 9 Cooperative Group Activities \n441\n",
    "442\nCorrelation\nRegression\nPrediction Intervals and \nVariation\nMultiple Regression\nDummy Variables and \nLogistic Regression\n10-1\n10-2\n10-3\n10-4\n10-5\nSave Money and Time (or Not?) with a Simpler  \nHealth Test?\nCHAPTER \nPROBLEM\nCorrelation and \nRegression\nWhen assessing the health of a person, some body measure-\nments are relatively easy, quick, and inexpensive, while others \nare more expensive and time consuming. Measuring pulse rate \ntakes only a minute and requires only a clock or watch, but \nmeasuring a person’s white blood cell count requires drawing \na blood sample that must be sent to a laboratory. Monitoring \nthe white blood cell count is important because those white \nblood cells help fight infections. If there is a strong correlation \nbetween pulse rate and white blood cell count, we could use \nthe pulse rate to predict the white blood cell count and thereby \nsave money and time. In this chapter, we will investigate the \ncorrelation between the pulse rate and white blood cell count \nof females. We will begin with the data in Table 10-1, which \nuses only five of the pairs of data available in Data Set 1  \n10 \n",
    "“Body Data” in Appendix B. We consider this smaller data set \nfor the purposes of illustrating the methods of this chapter. \nPulse rates are measured in beats per minute, and the white \nblood cell count gives the number of white blood cells  \nexpressed in units of 1000 cells>mL.\nUsing the methods of this chapter, we can address questions \nsuch as these:\n• Is there a correlation between pulse rates of females and \ntheir white blood cell counts?\n• If there is a correlation between pulse rates of females and \ntheir white blood cell counts, can we describe it with an equa-\ntion so that we can predict white blood cell count given a \npulse rate? If so, how accurate is the prediction likely to be?\nA major focus of this chapter is to analyze paired sample data. In Section 9-3 we \nconsidered sample data consisting of matched pairs, but the goal in Section 9-3 was \nto make inferences about the mean of  the differences from the matched pairs. In this \nchapter we again consider paired sample data, but the objective is fundamentally dif-\nferent from that of Section 9-3. In this chapter we present methods for determining \nwhether there is a correlation, or association, between two variables. For linear correla-\ntions, we can identify an equation of a straight line that best fits the data, and we can \nuse that equation to predict the value of one variable given the value of the other vari-\nable. Here are the chapter objectives:\nCorrelation\n• Use paired data to find the value of the linear correlation coefficient r.\n• Determine whether there is sufficient evidence to support a conclusion that there is \na linear correlation between two variables.\nRegression\n• Use paired sample data to find the equation of the regression line.\n• Find the best predicted value of a variable given some value of the other variable.\nPrediction Intervals and Variation\n• Use paired sample data to determine the value of the coefficient of determination  \nr 2, and to interpret that value.\n• Use paired sample data to use a given value of one variable to find a predicted \nvalue and a prediction interval for a second variable.\nMultiple Regression\n• Interpret results from technology to determine whether a multiple regression equa-\ntion is suitable for making predictions.\n• Compare results from different combinations of predictor variables and identify the \ncombination that results in the best multiple regression equation.\n10-1\n10-2\n10-3\n10-4\nChapter Objectives \n443\nCHAPTER OBJECTIVES\n>>>\nTABLE 10-1 Pulse Rates and White Blood Cell Counts  \nof Adult Females\nPulse Rate\n56.0\n82.0\n78.0\n86.0\n88.0\nWhite Blood Cell Count\n 6.9\n 8.1\n 6.4\n 6.3\n10.9\n",
    "444 \nCHAPTER 10 Correlation and Regression\nKey Concept In Part 1 we introduce the linear correlation coefficient r, which is a \nnumber that measures how well paired sample data fit a straight-line pattern when \ngraphed. We use the sample of paired data (sometimes called bivariate data) to find \nthe value of r (usually found using technology), then we use that value to decide \nwhether there is a linear correlation between the two variables. In this section we con-\nsider only linear relationships, which means that when graphed in a scatterplot, the \npoints approximate a straight-line pattern. In Part 2, we discuss methods for conduct-\ning a formal hypothesis test that can be used to decide whether there is a linear cor-\nrelation between all population values for the two variables.\nPART 1  Basic Concepts of Correlation \nWe begin with the basic definition of correlation, a term commonly used in the con-\ntext of an association between two variables.\n10-1 \nCorrelation\nDummy Variables and Logistic Regression\n• Find regression equations that include a dummy variable, which has only two  \npossible discrete values.\n• Apply methods of logistic regression when a dummy variable is the response (y) \nvariable.\n10-5\nDummy Variables and Logistic Regression\n• Find regression equations that include a dummy variable, which has only two \npossible discrete values.\n• Apply methods of logistic regression when a dummy variable is the response (y)\ny)\ny\nvariable.\nDEFINITIONS\nA correlation exists between two variables when the values of one variable are \nsomehow associated with the values of the other variable.\nA linear correlation exists between two variables when there is a correlation and \nthe plotted points of paired data result in a pattern that can be approximated by a \nstraight line.\nTable 10-1, for example, includes paired sample data consisting of pulse rates and \nwhite blood cell counts for five adult females. We will determine whether there is a \nlinear correlation between the variable x (pulse rate) and the variable y (white blood \ncell count). Instead of blindly jumping into the calculation of the linear correlation \ncoefficient r, it is wise to first explore the data.\nExplore!\nBecause it is always wise to explore sample data before applying a formal statistical \nprocedure, we should use a scatterplot to explore the paired data visually. Figure 10-1 \nshows a scatterplot of the data. The plotted points do not appear to follow a straight-\nline pattern very well, so it might appear that there is no linear correlation.\n",
    "10-1 Correlation \n445\nInterpreting Scatterplots\nFigure 10-2 shows four scatterplots with different characteristics.\n \n■Figure 10-2(a): Distinct straight-line, or linear, pattern. We say that there is a \npositive linear correlation between x and y, since as the x values increase, the cor-\nresponding y values also increase.\n \n■Figure 10-2(b): Distinct straight-line, or linear pattern. We say that there is a \nnegative linear correlation between x and y, since as the x values increase, the \ncorresponding y values decrease.\n \n■Figure 10-2(c): No distinct pattern which suggests that there is no correlation \nbetween x and y.\n \n■Figure 10-2(d): Distinct pattern suggesting a correlation between x and y, but the \npattern is not that of a straight line.\nFIGURE 10-1  Scatterplot of Pulse Rates and \nWhite Blood Cell Counts\n(a) Positive correlation: r = 0.859\n(b) Negative correlation: r = −0.971\n(c) No correlation: r = 0.074\n(d) Nonlinear relationship: r = 0.330\nFIGURE 10-2 Scatterplots\n",
    "446 \nCHAPTER 10 Correlation and Regression\nMeasure the Strength of the Linear Correlation with r\nBecause conclusions based on visual examinations of scatterplots are largely subjec-\ntive, we need more objective measures. We use the linear correlation coefficient r, \nwhich is a number that measures the strength of the linear association between the two \nvariables.\nDEFINITION\nThe linear correlation coefficient r measures the strength of the linear correlation \nbetween the paired quantitative x values and y values in a sample. The linear cor-\nrelation coefficient r is computed by using Formula 10-1 or Formula 10-2, included \nin the following Key Elements box. [The linear correlation coefficient is sometimes \nreferred to as the Pearson product moment correlation coefficient in honor of \nKarl Pearson (1857–1936), who originally developed it.]\nBecause the linear correlation coefficient r is calculated using sample data, it \nis a sample statistic used to measure the strength of the linear correlation between x \nand y. If we had every pair of x and y values from an entire population, the result of \nFormula 10-1 or Formula 10-2 would be a population parameter, represented by r\n(Greek letter rho).\nCalculating and Interpreting the Linear Correlation Coefficient r\nObjective\nDetermine whether there is a linear correlation between two variables.\nNotation for the Linear Correlation Coefficient\nn \nnumber of pairs of sample data.\nΣ \ndenotes addition of the items indicated.\nΣx \nsum of all x values.\nΣx2 \n indicates that each x value should be squared and then those squares added.\n(Σx)2 \n indicates that the x values should be added and the total then squared. Avoid confusing Σx2 and (Σx)2.\nΣxy \n indicates that each x value should first be multiplied by its corresponding y value. After obtaining all such prod-\nucts, find their sum.\nr \nlinear correlation coefficient for sample data.\nr \nlinear correlation coeﬃcient for a population of paired data.\nRequirements\nKEY ELEMENTS\nGiven any collection of sample paired quantitative data, \nthe linear correlation coefficient r can always be com-\nputed, but the following requirements should be satisfied \nwhen using the sample paired data to make a conclusion \nabout the linear correlation in the corresponding popula-\ntion of paired data.\n1. The sample of paired (x, y) data is a simple random \nsample of quantitative data. (It is important that the \nsample data have not been collected using some  \ninappropriate method, such as using a voluntary  \nresponse sample.)\ncontinued\n",
    "10-1 Correlation \n447\n2. Visual examination of the scatterplot must confirm \nthat the points approximate a straight-line pattern.*\n3. Because results can be strongly affected by the \npresence of outliers, any outliers must be removed \nif they are known to be errors. The effects of any \nother outliers should be considered by calculating \nr with and without the outliers included.*\nFormulas for Calculating r\nFORMULA 10-1 r =\nn1Σxy2 - 1Σx21Σy2\n2n1Σx22 - 1Σx2 22n1Σy22 - 1Σy2 2 1Good format for calculations2\nFORMULA 10-2 r =\nΣ1zx zy2\nn - 1  1Good format for understanding2\nwhere zx denotes the z score for an individual sample value x and zy is the z score for the corresponding sample value y.\nRounding the Linear Correlation Coefficient r\nRound the linear correlation coefficient r to three decimal places so that its value can be directly compared to critical \nvalues in Table A-6.\nInterpreting the Linear Correlation Coefficient r\n \n• Using P-Value from Technology to Interpret r: Use the P-value and significance level a as follows:\nP-value … a: Supports the claim of a linear correlation. \nP-value 7 a: Does not support the claim of a linear correlation.\n \n• Using Table A-6 to Interpret r: Consider critical values from Table A-6 or technology as being both positive and \nnegative, draw a graph similar to Figure 10-3 that accompanies Example 4 on page 451, and then use the follow-\ning decision criteria:\nCorrelation If the computed linear correlation coeﬃcient r lies in the left tail beyond the leftmost critical value \nor if it lies in the right tail beyond the rightmost critical value (that is, 0 r0 Ú critical value), conclude that there \nis suﬃcient evidence to support the claim of a linear correlation.\nNo Correlation If the computed linear correlation coeﬃcient lies between the two critical values (that is, \n0 r0 6 critical value), conclude that there is not suﬃcient evidence to support the claim of a linear correlation.\nCAUTION Remember, the methods of this section apply to a linear correlation. If \nyou conclude that there does not appear to be a linear correlation, it is possible \nthat there might be some other association that is not linear, as in Figure 10-2(d) on \npage 445. Always create a scatterplot to see relationships that might not be linear.\n*Note: Requirements 2 and 3 above are simplified at-\ntempts at checking this formal requirement: The pairs of \n(x, y) data must have a bivariate normal distribution. \nNormal distributions are discussed in Chapter 6, but this \nassumption basically requires that for any fixed value of x, \nthe corresponding values of y have a distribution that is ap-\nproximately normal, and for any fixed value of y, the val-\nues of x have a distribution that is approximately normal. \nThis requirement is usually difficult to check, so for now, \nwe will use Requirements 2 and 3 as listed above.\n",
    "448 \nCHAPTER 10 Correlation and Regression\nProperties of the Linear Correlation Coefficient r\n1. The value of r is always between -1 and 1 inclusive. That is, -1 … r … 1.\n2. If all values of either variable are converted to a different scale, the value of r \ndoes not change.\n3. The value of r is not affected by the choice of x or y. Interchange all x values \nand y values, and the value of r will not change.\n4. r measures the strength of a linear relationship. It is not designed to measure \nthe strength of a relationship that is not linear, as in Figure 10-2(d).\n5. r is very sensitive to outliers in the sense that a single outlier could dramati-\ncally affect its value.\nCalculating the Linear Correlation Coefficient r\nThe following three examples illustrate three different methods for finding the value \nof the linear correlation coefficient r, but you need to use only one method. The use \nof technology (as in Example 1) is strongly recommended. If manual calculations are \nabsolutely necessary, Formula 10-1 is recommended (as in Example 2). If a better un-\nderstanding of r is desired, Formula 10-2 is recommended (as in Example 3).\nStatdisk\nMinitab\nStatCrunch\nXLSTAT\nEXAMPLE 1  Finding r Using Technology\nTo better illustrate the calculation of r, we use the data from Table 10-1 reproduced \nhere. Use technology to find the value of the correlation coefficient r for the data in \nTable 10-1.\nTABLE 10-1 Pulse Rates and White Blood Cell Counts of Adult Females\nPulse Rate\n56.0\n82.0\n78.0\n86.0\n88.0\nWhite Blood Cell Count\n 6.9\n 8.1\n 6.4\n 6.3\n10.9\nSOLUTION\nThe value of r will be automatically calculated with software or a calculator. See the \naccompanying technology displays showing that r = 0.405 (rounded).\nP\nPalm Reading\nSome people \nbelieve that \nthe length of \ntheir palm’s \nlifeline can be \nused to predict \nlongevity. In a \nletter published in the Journal of \nthe American Medical Associa-\ntion, authors M. E. Wilson and \nL. E. Mather refuted that belief \nwith a study of cadavers. Ages \nat death were recorded, along \nwith the lengths of palm lifelines. \nThe authors concluded that there \nis no correlation between age \nat death and length of lifeline. \nPalmistry lost, hands down.\n",
    "10-1 Correlation \n449\nTI-83/84 Plus\nSPSS\nJMP\nEXAMPLE 2  Finding r Using Formula 10-1\nUse Formula 10-1 to find the value of the linear correlation coefficient r for the five \npairs of data listed in Table 10-1.\nSOLUTION\nUsing Formula 10-1, the value of r is calculated as shown below. Here, the variable \nx is used for the pulse rate, and the variable y is used for the white blood cell count. \nBecause there are five pairs of data, n = 5. Other required values are computed in \nTable 10-2.\nTABLE 10-2 Calculating r with Formula 10-1\n \nx (Pulse Rate)\ny (White Blood  \nCell Count)\n \nx2\n \ny2\n \nxy\n56\n 6.9\n3136\n 47.61\n386.4\n82\n 8.1\n6724\n 65.61\n664.2\n78\n 6.4\n6084\n 40.96\n499.2\n86\n 6.3\n7396\n 39.69\n541.8\n88\n10.9\n7744\n118.81\n959.2\nΣx = 390\nΣy = 38.6\nΣ x2 = 31,084\nΣy2 = 312.68\nΣxy = 3050.8\nUsing Formula 10-1 with the paired data in Table 10-2, r is calculated as follows:\n r =\nnΣ xy - 1Σx2 1Σy2\n2n1Σx22 - 1Σx2 22n1Σy22 - 1Σy2 2\n =\n513050.82 - 13902138.62\n25131,0842 - 13902 2251312.682 - 138.62 2\n =\n200\n23320273.44\n= 0.405\n",
    "450 \nCHAPTER 10 Correlation and Regression\nTABLE 10-3 Calculating r with Formula 10-2\n \nx (Pulse Rate)\ny (White Blood \nCell Count)\n \nzx\n \nzy\n \nzx # zy\n56\n 6.9\n-1.707531\n  -0.427920\n0.730687\n82\n 8.1\n0.310460\n0.198304\n0.061566\n78\n 6.4\n0\n  -0.688847\n0\n86\n 6.3\n0.620920\n  -0.741032\n-0.460122\n88\n10.9\n0.776151\n1.659495\n1.288018\nΣ1zx # zy2 = 1.620148\nEXAMPLE 3  Finding r Using Formula 10-2\nUse Formula 10-2 to find the value of the linear correlation coefficient r for the five \npairs of data listed in Table 10-1.\nSOLUTION\nIf manual calculations are absolutely necessary, Formula 10-1 is much easier than \nFormula 10-2, but Formula 10-2 has the advantage of making it easier to understand \nhow r works. (See the rationale for r discussed later in this section.) As in Example 2,  \nthe variable x is used for the pulse rates, and the variable y is used for the white \nblood cell counts. In Formula 10-2, each sample value is replaced by its correspond-\ning z score. For example, using unrounded numbers, the pulse rates have a mean of \nx = 78.0 and a standard deviation of sx = 12.884099, so the first pulse rate of 56 is \nconverted to a z score of -1.707531 as shown here:\nzx = x - x\nsx\n= 56 - 78.0\n12.884099 = -1.707531\nTable 10-3 lists the z scores for all of the pulse rates (see the third column) and the \nz scores for all of the white blood cell counts (see the fourth column). The last col-\numn of Table 10-3 lists the products zx # zy.\nUsing Σ1zx # zy2 = 1.620148 from Table 10-3, the value of r is calculated by using \nFormula 10-2 as shown below.\nr =\nΣ1zx # zy2\nn - 1\n= 1.620148\n4\n= 0.405\nIs There a Linear Correlation?\nWe know from the preceding three examples that the value of the linear correlation \ncoefficient is r = 0.405 for the five pairs of sample data in Table 10-1. We now pro-\nceed to interpret the meaning of r = 0.405 found from the five pairs of sample data, \nand our goal is to decide whether there appears to be a linear correlation between \npulse rates and white blood cell counts of all adult females. Using the criteria given \nin the preceding box, we can base our interpretation on a P-value or a critical value \nfrom Table A-6. See the criteria for “Interpreting the Linear Correlation Coefficient \nr” given in the preceding Key Elements box.\n",
    "10-1 Correlation \n451\nEXAMPLE 4  Is There a Linear Correlation?\nUsing the value of r = 0.405 for the five pairs of values in Table 10-1 and using a \nsignificance level of 0.05, is there sufficient evidence to support a claim that there is \na linear correlation between pulse rates and white blood cell counts?\nSOLUTION\nREQUIREMENT CHECK The first requirement of a simple random sample is satis-\nfied by the design of the study. The data are quantitative. The second require-\nment of a scatterplot showing a straight-line pattern is very questionable; see the \nscatterplot in Figure 10-1 on page 445. The scatterplot of Figure 10-1 also shows \nthat the third requirement of no outliers is questionable because the leftmost \npoints appear to be relatively far from the other points. We will proceed as if the \nrequirements are satisfied. \nWe can base our conclusion about correlation on either the P-value obtained from \ntechnology or the critical value found in Table A-6. (See the criteria for “Interpreting \nthe Linear Correlation Coefficient r” given in the preceding Key Elements box.)\n • Using P-Value from Technology to Interpret r: Use the P-value and signifi-\ncance level a as follows:\n \n \nP@value … a: Supports the claim of a linear correlation.\n \n \nP@value 7 a: Does not support the claim of a linear correlation.\nFor the data in Table 10-1, technology can be used to find that the P-value is \n0.4988. Because that P-value is greater than the significance level of 0.05, we \nconclude that there is not sufficient evidence to support the conclusion of a \nlinear correlation between pulse rates and white blood cell counts for all adult \nfemales.\n • Using Table A-6 to Interpret r: Consider critical values from Table A-6 as  \nbeing both positive and negative, and draw a graph similar to Figure 10-3. For \nthe data in Table 10-1, Table A-6 yields a critical value of 0.878 (for a 0.05 \nsignificance level). We now compare the computed value of r = 0.405 to the \ncritical values of r = {0.878 as shown in Figure 10-3.\nCorrelation If the computed linear correlation coefficient r lies in the left or \nright tail region beyond the critical value for that tail, conclude that there is suf-\nficient evidence to support the claim of a linear correlation.\ncontinued\n0\n−1\n1\nCorrelation\nCorrelation\nNo correlation\nSample Data:\nr = 0.405\nr = 0.878\nCritical Value\nr = −0.878\nCritical Value\nFIGURE 10-3 Critical r Values and the Computed r Value\n",
    "452 \nCHAPTER 10 Correlation and Regression\nExample 4 led to the conclusion of no linear correlation, but if we use the 147 \npairs of pulse rates and white blood cell counts for all of the females included in Data \nSet 1 “Body Data” in Appendix B, we get r = 0.221 and a P-value of 0.007, so the \nlarger data set leads to the conclusion that there is sufficient evidence to support the \nclaim that there is a linear correlation. But even though we have evidence to support \nthe claim of a linear correlation, the low value of r = 0.221 suggests that the correla-\ntion is not very strong. See the following interpretation based on the value of r2.\nInterpreting r: Explained Variation\nIf we conclude that there is a linear correlation between x and y, we can find a linear \nequation that expresses y in terms of x, and that equation can be used to predict values \nof y for given values of x. In Section 10-2 we will describe a procedure for finding \nsuch equations and show how to predict values of y when given values of x. But a \npredicted value of y will not necessarily be the exact result that occurs because in \naddition to x, there are other factors affecting y, such as random variation and other \ncharacteristics not included in the study. In Section 10-3 we will present a rationale \nand more details about this principle:\nThe value of r2 is the proportion of the variation in y that is explained by the \nlinear relationship between x and y.\nEXAMPLE 5  Explained Variation\nUsing the 147 pairs of pulse rates and white blood cell counts from females in Data \nSet 1, we get r = 0.221. What proportion of the variation in white blood cell counts \ncan be explained by the variation in the pulse rates?\nSOLUTION\nWith r = 0.221 we get r2 = 0.049.\nINTERPRETATION\nWe conclude that 0.049 (or about 5%) of the variation in white blood cell counts \ncan be explained by the linear relationship between pulse rates and white blood cell \ncounts. That’s not much. This also implies that about 95% of the variation in white \nblood cell counts cannot be explained by pulse rates.\nNo Correlation If the computed linear correlation coefficient lies between the \ntwo critical values, conclude that there is not sufficient evidence to support the \nclaim of a linear correlation.\nBecause Figure 10-3 shows that the computed value of r = 0.405 lies between \nthe two critical values, we conclude that there is not sufficient evidence to support \nthe claim of a linear correlation between pulse rates and white blood cell counts for \nadult females.\nINTERPRETATION\nBased on the five pairs of data in Table 10-1, we do not have sufficient evidence to \nconclude that there is a linear correlation between pulse rates and white blood cell \ncounts (but a larger data set might lead to a different conclusion).\n",
    "10-1 Correlation \n453\nInterpreting r with Causation: Don’t Go There!\nUsing the 147 pairs of pulse rates and white blood cell counts from females in Data \nSet 1 “Body Data” in Appendix B, we conclude that there is a linear correlation. We \nshould not make any conclusion that includes a statement about a cause-effect rela-\ntionship between the two variables. We should not conclude that higher pulse rates \ncause higher white blood cell counts. See the first of the following common errors, \nand know this:\nCorrelation does not imply causality!\nCommon Errors Involving Correlation\nHere are three of the most common errors made in interpreting results involving \ncorrelation:\n1. Assuming that correlation implies causality. One classic example involves \npaired data consisting of the stork population in Copenhagen and the \nnumber of human births. For several years, the data suggested a linear cor-\nrelation. Bulletin: Storks do not actually cause births, and births do not \ncause storks. Both variables were affected by another variable lurking in \nthe background. (A lurking variable is one that affects the variables being \nstudied but is not included in the study.) Here, an increasing human popu-\nlation resulted in more births and increased construction of thatched roofs \nthat attracted storks!\n2. Using data based on averages. Averages suppress individual variation and may \ninflate the correlation coefficient. One study produced a 0.4 linear correlation \ncoefficient for paired data relating income and education among individuals, \nbut the linear correlation coefficient became 0.7 when regional averages were \nused.\n3. Ignoring the possibility of a nonlinear relationship. If there is no linear  \ncorrelation, there might be some other correlation that is not linear, as in \nFigure 10-2(d) on page 445.\nPART 2\n Formal Hypothesis Test \nHypotheses If conducting a formal hypothesis test to determine whether there is \na significant linear correlation between two variables, use the following null and \nalternative hypotheses that use r to represent the linear correlation coefficient of \nthe population:\nNull Hypothesis\n   H0\n : r = 0 1No correlation2\nAlternative Hypothesis  H1\n : r ≠0 1Correlation2\nTest Statistic The same methods of Part 1 can be used with the test statistic r, or the \nt test statistic can be found using the following:\nTest Statistic  t =\nr\nB\n1 - r2\nn - 2\n 1with n - 2 degrees of freedom2\nIf the above t test statistic is used, P-values and critical values can be found \nusing technology or Table A-3 as described in earlier chapters. See the follow-\ning example.\n",
    "454 \nCHAPTER 10 Correlation and Regression\nEXAMPLE 6  Hypothesis Test Using the P-Value from the t Test\nUse the paired pulse rates and white blood cell counts from Table 10-1 on page 443 \nto conduct a formal hypothesis test of the claim that there is a linear correlation \nbetween the two variables. Use a 0.05 significance level with the P-value method \nof testing hypotheses.\nSOLUTION\nREQUIREMENT CHECK The requirements were addressed in Example 4. \nTo claim that there is a linear correlation is to claim that the population  \nlinear correlation coefficient r is different from 0. We therefore have the following \nhypotheses:\n H0\n : r = 0 1There is no linear correlation.2\n H1\n : r ≠0 1There is a linear correlation.2\nThe linear correlation coefficient is r = 0.405 and n = 5 (because there are 5 pairs \nof sample data), so the test statistic is\nt =\nr\nB\n1 - r2\nn - 2\n=\n0.405\nB\n1 - 0.4052\n5 - 2\n= 0.767\nWith n - 2 = 3 degrees of freedom, Table A-3 shows that the test statistic of  \nt = 0.767 yields a P-value that is greater than 0.20. Technologies show that the \nP-value is 0.499 when rounded. Because the P-value of 0.499 is greater than the \nsignificance level of 0.05, we fail to reject H0. (“If the P is low, the null must go.” \nThe P-value of 0.499 is not low.)\nINTERPRETATION\nWe conclude that there is not sufficient evidence to support the claim of a linear \ncorrelation between pulse rates and white blood cell counts of adult females.\nOne-Tailed Tests The examples and exercises in this section generally involve \ntwo-tailed tests, but one-tailed tests can occur with a claim of a positive linear correla-\ntion or a claim of a negative linear correlation. In such cases, the hypotheses will be as \nshown below.\nClaim of Negative Correlation \n(Left-Tailed Test)\nClaim of Positive Correlation \n(Right-Tailed Test)\nH0: r = 0\nH0: r = 0\nH1: r 6 0\nH1: r 7 0\nFor these one-tailed tests, the P-value method can be used as in earlier chapters.\nRationale for Methods of This Section We have presented Formulas 10-1 and \n10-2 for calculating r and have illustrated their use. Those formulas are given on the \nnext page, along with some other formulas that are “equivalent,” in the sense that they \nall produce the same values.\n",
    "10-1 Correlation \n455\nFIGURE 10-4   Scatterplot of z Scores from Pulse Rates and \nWhite Blood Cell Counts in Table 10-1\nFORMULA 10-1  r =\nnΣxy - 1Σx2 1Σy2\n2n1Σx22 - 1Σx2 22n1Σy22 - 1Σy2 2\nFORMULA 10-2  r =\nΣ1zx zy2\nn - 1\nr = Σ1x - x 2 1 y - y 2\n1n - 12sx sy\n  r =\na c 1x - x 2\nsx\n1 y - y 2\nsy\nd\nn - 1\nr =\nsxy\n1sxx 1syy\nWe will use Formula 10-2 to help us understand the reasoning that underlies the \ndevelopment of the linear correlation coefficient. Because Formula 10-2 uses z scores, \nthe value of Σ1zxzy2 does not depend on the scale that is used for the x and y values. \nFigure 10-1 on page 445 shows the scatterplot of the pulse rate and white blood cell \ncount data from Table 10-1, and Figure 10-4 shows the scatterplot of the z scores from \nthe same sample data. Compare Figure 10-1 to Figure 10-4 and see that they are es-\nsentially the same scatterplots with different scales. Figure 10-4 shows the same coor-\ndinate axes that we have all come to know and love from earlier mathematics courses. \nFigure 10-4 shows the scatterplot partitioned into four quadrants.\nIf the points of the scatterplot approximate an uphill line, individual values of the \nproduct zx # zy tend to be positive (because most of the points are found in the first and \nthird quadrants, where the values of zx and zy are either both positive or both negative), \nso Σ1zx zy2 tends to be positive. If the points of the scatterplot approximate a downhill \nline, most of the points are in the second and fourth quadrants, where zx and zy are \nopposite in sign, so Σ1zx zy2 tends to be negative. Points that follow no linear pattern \ntend to be scattered among the four quadrants, so the value of Σ1zx zy2 tends to be \nclose to 0.\nWe can therefore use Σ1zx zy2 as a measure of how the points are configured \namong the four quadrants. A large positive sum suggests that the points are predomi-\nnantly in the first and third quadrants (corresponding to a positive linear correlation), a \nlarge negative sum suggests that the points are predominantly in the second and fourth \n",
    "456 \nCHAPTER 10 Correlation and Regression\nquadrants (corresponding to a negative linear correlation), and a sum near 0 suggests \nthat the points are scattered among the four quadrants (with no linear correlation). We \ndivide Σ1zx zy2 by n - 1 to get an average instead of a statistic that becomes larger \nsimply because there are more data values. (The reasons for dividing by n - 1 instead \nof n are essentially the same reasons that relate to the standard deviation.) The end \nresult is Formula 10-2, which can be algebraically manipulated into any of the other \nexpressions for r.\nStatistical Literacy and Critical Thinking\n1. Notation Twenty different statistics students are randomly selected. For each of them, their \nbody temperature (oC) is measured and their head circumference (cm) is measured.\na. For this sample of paired data, what does r represent, and what does r represent?\nb. Without doing any research or calculations, estimate the value of r.\nc. Does r change if the body temperatures are converted to Fahrenheit degrees?\n2. Interpreting r For the same two variables described in Exercise 1, if we find that r = 0, does \nthat indicate that there is no association between those two variables?\n3. Global Warming If we find that there is a linear correlation between the concentration of \ncarbon dioxide (CO2) in our atmosphere and the global mean temperature, does that indicate \nthat changes in CO2 cause changes in the global mean temperature? Why or why not?\n4. Scatterplots Match these values of r with the five scatterplots shown here and on the top of \nthe next page: 0.268, 0.992, -1, 0.746, and 1.\n10-1 Basic Skills and Concepts \n(a)\n(b)\n(c)\n(d)\nCorrelation\nAccess tech instructions, videos, and data sets at www.TriolaStats.com\nTECH CENTER\n",
    "10-1 Correlation \n457\nInterpreting r. In Exercises 5–8, use a significance level of A = 0.05 and refer to the  \naccompanying displays.\n5.  Bear Weight and Chest Size Fifty-four wild bears were anesthetized, and then their \nweights and chest sizes were measured and listed in Data Set 11 “Bear Measurements.” Results \nare shown in the accompanying Statdisk display. Is there sufficient evidence to support the \nclaim that there is a linear correlation between the weights of bears and their chest sizes? When \nmeasuring an anesthetized bear, is it easier to measure chest size than weight? If so, does it ap-\npear that a measured chest size can be used to predict the weight?\n(e)\n6. Cereal Killers The amounts of sugar (grams of sugar per gram of cereal) and calories (per \ngram of cereal) were recorded for a sample of 16 different cereals. TI-83>84 Plus calculator \nresults are shown here. Is there sufficient evidence to support the claim that there is a linear cor-\nrelation between sugar and calories in a gram of cereal? Explain.\nTI-83 , 84 Plus\n7. Heights of Fathers and Sons The heights (in inches) of a sample of 134 father>son pairs of \nsubjects were measured and the results are listed in Data Set 6 “Family Heights” in Appendix B. \nXLSTAT results are shown below. Is there sufficient evidence to support the claim that there is a \nlinear correlation between the heights of fathers and the heights of their sons? Explain.\n",
    "458 \nCHAPTER 10 Correlation and Regression\n8. Heights of Mothers and Daughters The heights (in inches) of a sample of 134 mother>\ndaughter pairs of subjects were measured and the results are listed in Data Set 6 “Family \nHeights” in Appendix B. StatCrunch results are shown below. StatCrunch also indicates that \nthe P-value is less than 0.0001. Is there sufficient evidence to support the claim that there is a \nlinear correlation between the heights of mothers and the heights of their daughters? Explain.\nExplore! Exercises 9 and 10 provide two data sets from “Graphs in Statistical Analysis,” \nby F. J. Anscombe, The American Statistician, Vol. 27. For each exercise,\na. Construct a scatterplot.\nb. Find the value of the linear correlation coefficient r, then determine whether there is suffi-\ncient evidence to support the claim of a linear correlation between the two variables.\nc. Identify the feature of the data that would be missed if part (b) was completed without con-\nstructing the scatterplot.\n9. \nx\n10\n8\n13\n9\n11\n14\n6\n4\n12\n7\n5\ny\n9.14\n8.14\n8.74\n8.77\n9.26\n8.10\n6.13\n3.10\n9.13\n7.26\n4.74\n10. \nx\n10\n8\n13\n9\n11\n14\n6\n4\n12\n7\n5\ny\n7.46\n6.77\n12.74\n7.11\n7.81\n8.84\n6.08\n5.39\n8.15\n6.42\n5.73\n11. Outlier Refer to the accompanying Minitab-generated scatterplot.\na. Examine the pattern of all 10 points and subjectively determine whether there appears to be \na correlation between x and y.\nb. After identifying the 10 pairs of coordinates corresponding to the 10 points, find the value of \nthe correlation coefficient r and determine whether there is a linear correlation.\nc. Now remove the point with coordinates (10, 10) and repeat parts (a) and (b).\nd. What do you conclude about the possible effect from a single pair of values?\nMinitab\n12. Clusters Refer to the following Minitab-generated scatterplot. The four points in the lower \nleft corner are measurements from women, and the four points in the upper right corner are \nfrom men.\n",
    "10-1 Correlation \n459\na. Examine the pattern of the four points in the lower left corner (from women) only, and sub-\njectively determine whether there appears to be a correlation between x and y for women.\nb. Examine the pattern of the four points in the upper right corner (from men) only, and subjec-\ntively determine whether there appears to be a correlation between x and y for men.\nc. Find the linear correlation coefficient using only the four points in the lower left corner (for \nwomen). Will the four points in the upper left corner (for men) have the same linear correlation \ncoefficient?\nd. Find the value of the linear correlation coefficient using all eight points. What does that \nvalue suggest about the relationship between x and y?\ne. Based on the preceding results, what do you conclude? Should the data from women and the \ndata from men be considered together, or do they appear to represent two different and distinct \npopulations that should be analyzed separately?\nMinitab\nTesting for a Linear Correlation. In Exercises 13–28, construct a scatterplot, and find \nthe value of the linear correlation coefficient r. Also find the P-value or find the critical \nvalues of r from Table A-6. Use a significance level of A = 0.05. Determine whether there \nis sufficient evidence to support a claim of a linear correlation between the two variables. \n(Save your work because the same data sets will be used in Section 10-2 exercises.)\n13. IQ and Brain Volume The table below lists IQ scores and brain volumes (cm3) and body \nweights (kg) of subjects (from Data Set 9 “IQ and Brain Size” in Appendix B). Is there suf-\nficient evidence to conclude that there is a linear correlation between IQ scores and brain vol-\numes? Does it appear that people with larger brains have higher IQ scores?\nIQ\n87\n101\n103\n96\n101\n96\n93\n88\n97\n114\n113\nBrain \nVolume\n \n1027\n \n1281\n \n1051\n \n1079\n \n1173\n \n1079\n \n1067\n \n1104\n \n1029\n \n1100\n \n1204\nBody \nWeight\n \n58.514\n \n63.958\n \n133.358\n \n107.503\n \n61.236\n \n61.236\n \n83.916\n \n79.38\n \n81.648\n \n88.452\n \n79.38\n14. IQ and Weight Use the paired IQ and body weight data from the preceding exercise. Is \nthere sufficient evidence to conclude that there is a linear correlation between IQ scores and \nbody weights?\n15. CSI Statistics Police sometimes measure shoe prints at crime scenes so that they can learn \nsomething about criminals. Listed below are shoe print lengths, foot lengths, and heights of males \n(from Data Set 7 “Foot and Height” in Appendix B). Is there sufficient evidence to conclude that \nthere is a linear correlation between shoe print lengths and heights of males? Based on these re-\nsults, does it appear that police can use a shoe print length to estimate the height of a male?\nShoe Print (cm)\n29.7\n29.7\n31.4\n31.8\n27.6\nFoot Length (cm)\n25.7\n25.4\n27.9\n26.7\n25.1\nHeight (cm)\n175.3\n177.8\n185.4\n175.3\n172.7\n",
    "460 \nCHAPTER 10 Correlation and Regression\n16. CSI Statistics Use the paired foot length and height data from the preceding exercise. Is \nthere sufficient evidence to conclude that there is a linear correlation between foot lengths and \nheights of males? Based on these results, does it appear that police can use foot length to esti-\nmate the height of a male?\n17. Lemons and Car Crashes Listed below are annual data for various years. The data are \nweights (metric tons) of lemons imported from Mexico and U.S. car crash fatality rates per \n100,000 population [based on data from “The Trouble with QSAR (or How I Learned to Stop \nWorrying and Embrace Fallacy),” by Stephen Johnson, Journal of Chemical Information and \nModeling, Vol. 48, No. 1]. Is there sufficient evidence to conclude that there is a linear correla-\ntion between weights of lemon imports from Mexico and U.S. car fatality rates? Do the results \nsuggest that imported lemons cause car fatalities?\nLemon Imports\n230\n265\n358\n480\n530\nCrash Fatality Rate\n15.9\n15.7\n15.4\n15.3\n14.9\n18. Crickets and Temperature A classic application of correlation involves the association \nbetween the temperature and the number of times a cricket chirps in 1 minute. Listed below \nare the numbers of chirps in 1 min and the corresponding temperatures in °F (based on data \nfrom The Song of Insects, by George W. Pierce, Harvard University Press). Is there sufficient \nevidence to conclude that there is a linear correlation between the number of chirps in 1 min \nand the temperature?\nChirps in 1 min\n882\n1188\n1104\n864\n1200\n1032\n960\n900\nTemperature  1°F2\n69.7\n93.3\n84.3\n76.3\n88.6\n82.6\n71.6\n79.6\n19. Pulse Rate and Blood Pressure The table below lists pulse rates, systolic blood pres-\nsures (mm Hg), and diastolic blood pressures (mm Hg) of adult females (from Data Set 1 \n“Body Data” in Appendix B). Is there sufficient evidence to conclude that there is a linear cor-\nrelation between pulse rate and systolic blood pressure?\nPulse\n 86\n 72\n 82\n 82\n 64\n68\n 70\n 78\n 96\n 72\n 60\n 98\nSystolic\n126\n104\n130\n106\n158\n96\n156\n112\n122\n114\n102\n126\nDiastolic\n 70\n 66\n 74\n 64\n 74\n52\n 90\n 70\n 68\n 74\n 60\n 68\n20. Blood Pressure Use the paired systolic and diastolic data from the preceding exercise. Is \nthere sufficient evidence to conclude that there is a linear correlation between systolic blood \npressures and diastolic blood pressures of adult females?\n21.  Weighing Seals with a Camera Listed below are the overhead widths (cm) of seals \nmeasured from photographs and the weights (kg) of the seals (based on “Mass Estimation of \nWeddell Seals Using Techniques of Photogrammetry,” by R. Garrott of Montana State Univer-\nsity). The purpose of the study was to determine if weights of seals could be determined from \noverhead photographs. Is there sufficient evidence to conclude that there is a linear correlation \nbetween overhead widths of seals from photographs and the weights of the seals?\nOverhead Width\n7.2\n7.4\n9.8\n9.4\n8.8\n8.4\nWeight\n116\n154\n245\n202\n200\n191\n22. Manatees Listed below are numbers of registered pleasure boats in Florida (tens of thou-\nsands) and the numbers of manatee fatalities from encounters with boats in Florida for each \nof several recent years. The values are from Data Set 12 “Manatee Deaths.” Is there sufficient \nevidence to conclude that there is a linear correlation between numbers of registered pleasure \nboats and numbers of manatee boat fatalities?\nPleasure Boats\n99\n99\n97\n95\n90\n90\n87\n90\n90\nManatee Fatalities\n92\n73\n90\n97\n83\n88\n81\n73\n68\n",
    "10-1 Correlation \n461\n23. POTUS Media periodically discuss the issue of heights of winning presidential candidates \nand heights of their main opponents. Listed below are those heights (cm) from several recent \npresidential elections. Is there sufficient evidence to conclude that there is a linear correla-\ntion between heights of winning presidential candidates and heights of their main opponents? \nShould there be such a correlation?\nPresident\n178\n182\n188\n175\n179\n183\n192\n182\n177\n185\n188\n188\n183\n188\nOpponent\n180\n180\n182\n173\n178\n182\n180\n180\n183\n177\n173\n188\n185\n175\n24. Tree Circumference and Height Listed below are the circumferences (in feet) and the heights \n(in feet) of trees in Marshall, Minnesota (based on data from “Tree Measurements,” by Stanley Rice, \nAmerican Biology Teacher, Vol. 61, No. 9). Is there sufficient evidence to support the claim of a linear \ncorrelation between circumferences and heights of trees? Why should there be a correlation?\nCircumference\n1.8\n1.9\n1.8\n2.4\n5.1\n3.1\n5.5\n5.1\n8.3\n13.7\n5.3\n4.9\nHeight\n21.0\n33.5\n24.6\n40.7\n73.2\n24.9\n40.4\n45.3\n53.5\n93.8\n64.0\n62.7\nAppendix B Data Sets. In Exercises 25–32, use the data in Appendix B to construct a \nscatterplot, find the value of the linear correlation coefficient r, and find either the P-value \nor the critical values of r using A = 0.05. Determine whether there is sufficient evidence to \nsupport the claim of a linear correlation between the two variables. (Save your work  \nbecause the same data sets will be used in Section 10-2 exercises.)\n25. IQ and Brain Volume Use all of the paired IQ scores and brain volumes in Data Set 9 \n“IQ and Brain Size” in Appendix B.\n26. IQ and Weight Use all of the paired IQ scores and body weights in Data Set 9 “IQ and \nBrain Size” in Appendix B.\n27. CSI Statistics Use the paired shoe print lengths and heights of the 19 males from Data Set \n7 “Foot and Height.”\n28. CSI Statistics Use the paired foot lengths and heights of the 19 males from Data Set 7 \n“Foot and Height.”\n29. Pulse Rate and Blood Pressure Use all of the paired pulse rates and systolic blood \npressure amounts for adult females from Data Set 1 “Body Data” in Appendix B.\n30. Blood Pressure Use all of the paired systolic and diastolic data for adult females as listed \nin Data Set 1 “Body Data” in Appendix B. Is there sufficient evidence to conclude that there is a \nlinear correlation between systolic blood pressures and diastolic blood pressures of adult females?\n31.  Audiometry Use the right ear threshold measurements and the corresponding left ear \nthreshold measurements from Data Set 4 “Audiometry” in Appendix B. Is there sufficient evi-\ndence to support the claim of a linear correlation?\n32. Vision Use the measurements of visual acuity from the right eye and left eye as listed in Data Set 5 \n“Vision” in Appendix B. Is there sufficient evidence to support the claim of a linear correlation?\n10-1 Beyond the Basics \n33. Transformed Data In addition to testing for a linear correlation between x and y, we can \noften use transformations of data to explore other relationships. For example, we might replace \neach x value by x2 and use the methods of this section to determine whether there is a linear \ncorrelation between y and x2. Given the paired data in the accompanying table, construct the \nscatterplot and then test for a linear correlation between y and each of the following. Which \ncase results in the largest value of r?\na. x  b. x2  c. log x  d. 1x  e. 1>x\nx\n2\n3\n20\n50\n95\ny\n0.3\n0.5\n1.3\n1.7\n2.0\n",
    "462 \nCHAPTER 10 Correlation and Regression\n34. Finding Critical r Values Table A-6 lists critical values of r for selected values of n and a. \nMore generally, critical r values can be found by using the formula\nr =\nt\n2t2 + n - 2\nwhere the t value is found from the table of critical t values (Table A-3) assuming a two-tailed case with \nn - 2 degrees of freedom. Use the formula for r given here and Table A-3 (with n - 2 degrees \nof freedom) to find the critical r values corresponding to H1: r ≠0, a = 0.02, and n = 27.\nKey Concept This section presents methods for finding the equation of the straight \nline that best fits the points in a scatterplot of paired sample data. That best-fitting \nstraight line is called the regression line, and its equation is called the regression equa-\ntion. We can use the regression equation to make predictions for the value of one of \nthe variables, given some specific value of the other variable. In Part 2 of this section \nwe discuss marginal change, influential points, and residual plots as tools for analyz-\ning correlation and regression results.\nPART 1\n Basic Concepts of Regression \nIn some cases, two variables are related in a deterministic way, meaning that given a value \nfor one variable, the value of the other variable is exactly determined without any error, \nas in the equation y = 2.54x for converting a distance x from inches to centimeters. Such \nequations are considered in algebra courses, but statistics courses focus on probabilistic \nmodels, which are equations with a variable that is not determined completely by the \nother variable. For example, the height of a child cannot be determined completely by the \nheight of the father and>or mother. Sir Francis Galton (1822–1911) studied the phenom-\nenon of heredity and showed that when tall or short couples have children, the heights \nof those children tend to regress, or revert to the more typical mean height for people of \nthe same gender. We continue to use Galton’s “regression” terminology, even though our \ndata do not always involve the same height phenomena studied by Galton.\n10-2 \nRegression\nDEFINITIONS\nGiven a collection of paired sample data, the regression line (or line of best fit, or least-\nsquares line) is the straight line that “best” fits the scatterplot of the data. (The specific \ncriterion for the “best-fitting” straight line is the “least-squares” property described later.)\nThe regression equation\nyn = b0 + b1x\nalgebraically describes the regression line. The regression equation expresses a  \nrelationship between x (called the explanatory variable, or predictor variable, or  \nindependent variable) and yn (called the response variable or dependent variable).\nThe preceding definition shows that in statistics, the typical equation of a straight \nline y = mx + b is expressed in the form yn = b0 + b1x, where b0 is the y-intercept \nand b1 is the slope. The values of the slope b1 and y-intercept b0 can be easily found \nby using any one of the many computer programs and calculators designed to provide \nthose values, as illustrated in Example 1. The values of b1 and b0 can also be found \nwith manual calculations, as shown in Example 2.\n",
    "10-2 Regression \n463\nFinding the Equation of the Regression Line\nObjective\nFind the equation of a regression line.\nNotation for the Equation of a Regression Line\nSample Statistic\nPopulation Parameter\ny-intercept of regression equation\nb0\nb0\nSlope of regression equation\nb1\nb1\nEquation of the regression line\nyn = b0 + b1x\ny = b0 + b1x\nRequirements\nKEY ELEMENTS\nFormulas for Finding the Slope b1 and y-Intercept b0 in the Regression Equation yn = b0 + b1x\n*Note: Requirements 2 and 3 above are simpliﬁed attempts \nat checking the following formal requirements for regres-\nsion analysis:\n• For each fixed value of x, the corresponding values of y \nhave a normal distribution.\n1. The sample of paired (x, y) data is a random sample of \nquantitative data.\n2. Visual examination of the scatterplot shows that the \npoints approximate a straight-line pattern.*\n3. Outliers can have a strong effect on the regression \nequation, so remove any outliers if they are known to \nbe errors. Consider the effects of any outliers that are \nnot known errors.*\n• For the different fixed values of x, the distributions of \nthe corresponding y values all have the same standard \ndeviation. (This is violated if part of the scatterplot \nshows points very close to the regression line while \nanother portion of the scatterplot shows points that are \nmuch farther away from the regression line. See the \ndiscussion of residual plots in Part 2 of this section.)\n• For the different fixed values of x, the distributions of \nthe corresponding y values have means that lie along \nthe same straight line.\nThe methods of this section are not seriously affected if \ndepartures from normal distributions and equal standard \ndeviations are not too extreme.\nFORMULA 10-3\nSlope: \nb1 = r \nsy\nsx\nwhere r is the linear correlation coefficient, sy is the \nstandard deviation of the y values, and sx is the stan-\ndard deviation of the x values.\nFORMULA 10-4\ny-intercept: b0 = y - b1x\nThe slope b1 and y-intercept b0 can also be found using the following formulas that are useful for manual calculations or \ncomputer programs:\nb1 = n1Σxy2 - 1Σx2 1Σy2\nn1Σx22 - 1Σx2 2\n  b0 = 1Σy2 1Σx22 - 1Σx2 1Σxy2\nn1Σx22 - 1Σx2 2\nRounding the Slope b1 and the y-Intercept b0\nRound b1 and b0 to three significant digits. It’s difficult to provide a simple universal rule for rounding values of b1 and b0, \nbut this rule will work for most situations in this book. (Depending on how you round, this book’s answers to examples \nand exercises may be slightly different from your answers.)\n",
    "464 \nCHAPTER 10 Correlation and Regression\nEXAMPLE 1  Using Technology to Find the Regression Equation\nRefer to the sample data given in Table 10-1 on page 443 in the Chapter Problem. \nUse technology to find the equation of the regression line in which the explanatory \nvariable (or x variable) is pulse rate and the response variable (or y variable) is the \ncorresponding white blood cell count.\nSOLUTION\nREQUIREMENT CHECK (1) The data are assumed to be a simple random sample.  \n(2) Figure 10-1 is a scatterplot of the data. It is very questionable whether the points \nroughly follow a straight-line pattern. (3) There are no outliers. We will proceed as \nif the requirements are satisfied. \nTechnology The use of technology is recommended for finding the equation of a \nregression line. Shown below are the results from different technologies. Some tech-\nnologies provide the actual equation, and some technologies list the values of the \ny-intercept and the slope. All of these technologies show that the regression equa-\ntion can be expressed as yn = 3.02 + 0.0602x, where yn is the predicted white blood \ncell count and x is the pulse rate.\nStatdisk\nExcel (XLSTAT)\nMinitab\nTI-83 , 84 Plus\nStatCrunch\nSPSS\nJMP\nWe should know that the regression equation is an estimate of the true  \nregression equation for the population of paired data. This estimate is based on one \nparticular set of sample data, but another sample drawn from the same population \nwould probably lead to a slightly different equation.\nPostponing Death\nSeveral stud-\nies addressed \nthe ability \nof people to \npostpone their \ndeath until \nafter an impor-\ntant event. For example, sociolo-\ngist David Phillips analyzed death \nrates of Jewish men who died \nnear Passover, and he found \nthat the death rate dropped \ndramatically in the week before \nPassover, but rose the week \nafter. Other researchers of cancer \npatients concluded that there is \n“no pattern to support the con-\ncept that ‘death takes a holiday.’” \n(See “Holidays, Birthdays, and \nPostponement of Cancer Death,” \nby Young and Hade, Journal of \nthe American Medical Associa-\ntion, Vol. 292, No. 24.) Based \non records of 1.3 million deaths, \nthis more recent study found no \nrelationship between the time of \ndeath and Christmas, Thanksgiv-\ning, or the person’s birthday. The \nfindings were disputed by David \nPhillips, who said that the study \nfocused on cancer patients, \nbut they are least likely to have \npsychosomatic effects.\n",
    "10-2 Regression \n465\nEXAMPLE 2   Using Manual Calculations to Find the  \nRegression Equation\nRefer to the sample data given in Table 10-1 on page 443 in the Chapter Problem. \nUse Formulas 10-3 and 10-4 to find the equation of the regression line in which the \nexplanatory variable (or x variable) is pulse rate and the response variable (or y vari-\nable) is the corresponding white blood cell count.\nSOLUTION\nREQUIREMENT CHECK The requirements are addressed in Example 1. \nWe begin by finding the slope b1 using Formula 10-3 as follows (with extra dig-\nits included for greater accuracy). Remember, r is the linear correlation coefficient, \nsy is the standard deviation of the sample y values, and sx is the standard deviation of \nthe sample x values.\nb1 = r \nsy\nsx\n= 0.405037 # 1.916246\n12.884099 = 0.060241\nAfter finding the slope b1, we can now use Formula 10-4 to find the y-intercept as \nfollows:\nb0 = y - b1x = 7.72 - 10.0602412178.02 = 3.021202\nAfter rounding, the slope is b1 = 0.0602 and the y-intercept is b0 = 3.02. We  \ncan now express the regression equation as yn = 3.02 + 0.0602x, where yn is the \npredicted white blood cell count and x is the pulse rate.\nEXAMPLE 3  Graphing the Regression Line\nGraph the regression equation yn = 3.02 + 0.0602x (found in Examples 1 and 2) \non the scatterplot of the pulse and white blood cell count data from Table 10-1 \nand examine the graph to subjectively determine how well the regression line fits \nthe data.\nSOLUTION\nShown below is the Minitab display of the scatterplot with the graph of the regression \nline included. We can see that the regression line does not fit the points very well.\n",
    "466 \nCHAPTER 10 Correlation and Regression\nMaking Predictions\nRegression equations are often useful for predicting the value of one variable, given \nsome specific value of the other variable. When making predictions, we should \nconsider the following:\n1. Bad Model: If the regression equation does not appear to be useful for making \npredictions, don’t use the regression equation for making predictions. For bad \nmodels, the best predicted value of a variable is simply its sample mean.\n2. Good Model: Use the regression equation for predictions only if the graph of \nthe regression line on the scatterplot confirms that the regression line fits the \npoints reasonably well.\n3. Correlation: Use the regression equation for predictions only if the linear cor-\nrelation coefficient r indicates that there is a linear correlation between the two \nvariables (as described in Section 10-1).\n4. Scope: Use the regression line for predictions only if the data do not go \nmuch beyond the scope of the available sample data. (Predicting too far \nbeyond the scope of the available sample data is called extrapolation, and it \ncould result in bad predictions.)\nFigure 10-5 summarizes a strategy for predicting values of a variable y when \ngiven some value of x. Figure 10-5 shows that if the regression equation is a good \nmodel, then we substitute the value of x into the regression equation to find the pre-\ndicted value of y. However, if the regression equation is not a good model, the best \npredicted value of y is simply y, the mean of the y values. Remember, this strategy ap-\nplies to linear patterns of points in a scatterplot. If the scatterplot shows a pattern that \nis nonlinear (not a straight-line) pattern, other methods apply.\nIs the regression equation a good model?\n \n• The regression line graphed in the scatterplot\n \n shows that the line ﬁts the points well.\n \n• r indicates that there is a linear correlation.\n \n• The prediction is not much beyond the scope\n \n of the available sample data.\nStrategy for Predicting Values of y\nYes.\nThe regression\nequation is a\ngood model.\nNo.\nThe regression\nequation is not\na good model.\nSubstitute the given value of x\ninto the regression equation\ny 5 b0 1 b1x\nRegardless of the value of x,\nthe best predicted value of y is\nthe value of y (the mean of the \ny values).\nˆ\nFIGURE 10-5 Recommended Strategy for Predicting Values of y\nEXAMPLE 4  Making Predictions\na. Use the ﬁve pairs of pulse rates and white blood cell counts from Table 10-1 \non page 463 to predict the white blood cell count for an adult female with a \npulse rate of 80 beats per minute.\n \nb. Use the pulse rates and white blood cell counts for females in Data Set 1 \n“Body Data” in Appendix B to predict the white blood cell count for an adult \nM\nR\nso\nc\nClinical Trial Cut Short\nWhat do you \ndo when \nyou’re testing \na new treat-\nment and, \nbefore your \nstudy ends, \nyou find that it is clearly effec-\ntive? You should cut the study \nshort and inform all participants \nof the treatment’s effectiveness. \nThis happened when hydroxy-\nurea was tested as a treatment \nfor sickle cell anemia. The study \nwas scheduled to last about  \n40 months, but the effectiveness \nof the treatment became obvious \nand the study was stopped after \n36 months. (See “Trial Halted \nas Sickle Cell Treatment Proves \nItself,” by Charles Marwick, \nJournal of the American Medical \nAssociation, Vol. 273, No. 8.)\n",
    "10-2 Regression \n467\nfemale with a pulse rate of 80 beats per minute. This data set includes 147 \npairs of values, and the linear correlation coeﬃcient is r = 0.221 with a  \nP-value of 0.007. Also, the regression equation is yn = 4.06 + 0.0345x.\nSOLUTION\na. Bad Model: Use y for Predictions. The regression line does not ﬁt the points \nwell, as shown in Example 3. Also, there does not appear to be a linear  \ncorrelation between pulse rates and white blood cell counts as shown in \nSection 10-1. Because the regression equation is not a good model, the best \npredicted white blood cell count is y = 7.72, which is the mean of the ﬁve \nwhite blood cell counts from Table 10-1.\n \nb. Good Model: Use the Regression Equation for Predictions. Because the \nregression equation yn = 4.06 + 0.0345x is a good model, substitute x = 80 \ninto the equation to get the predicted white blood cell count of 6.8.\nINTERPRETATION\nNote that in part (a), the paired data result in a poor regression model, so the best \npredicted white blood cell count is the sample mean of the five white blood cell \ncounts: y = 7.72. However, in part (b) there is a linear correlation between pulse \nrates and white blood cell counts, so the best predicted value is found by substitut-\ning x = 80 into the regression equation.\nKey point: Use the regression equation for predictions only if it is a good \nmodel. If the regression equation is not a good model, use the predicted value of y.\nPART 2  Beyond the Basics of Regression \nIn Part 2 we consider the concept of marginal change, which is helpful in interpreting \na regression equation; then we consider the effects of outliers and special points called \ninfluential points. We also consider residual plots.\nInterpreting the Regression Equation: Marginal Change\nWe can use the regression equation to see the effect on one variable when the other \nvariable changes by some specific amount.\nDEFINITION\nIn working with two variables related by a regression equation, the marginal \nchange in a variable is the amount that it changes when the other variable changes \nby exactly one unit. The slope b1 in the regression equation represents the marginal \nchange in y that occurs when x changes by one unit.\nLet’s consider the 147 pairs of pulse rates and white blood cell counts for females \nfrom Data Set 1 “Body Data” in Appendix B. Those 147 pairs of data result in this \nregression equation: yn = 4.06 + 0.0345x. The slope of 0.0345 tells us that if we in-\ncrease x (pulse rate) by 1 (beat per minute), the predicted white blood cell count will \nincrease by 0.0345. That is, for every additional 1 beat per minute increase in pulse \nrate, we expect the white blood cell count to increase by 0.0345.\n",
    "468 \nCHAPTER 10 Correlation and Regression\nOutliers and Influential Points\nA correlation>regression analysis of bivariate (paired) data should include an investi-\ngation of outliers and influential points, defined as follows.\nDEFINITIONS\nIn a scatterplot, an outlier is a point lying far away from the other data points.\nPaired sample data may include one or more influential points, which are points \nthat strongly affect the graph of the regression line.\nTo determine whether a point is an outlier, examine the scatterplot to see if the \npoint is far away from the others. Here’s how to determine whether a point is an influ-\nential point: First graph the regression line resulting from the data with the point in-\ncluded, then graph the regression line resulting from the data with the point excluded. \nIf the regression line changes by a considerable amount, the point is influential.\nEXAMPLE 5  Influential Point\nConsider the 147 pairs of pulse rates and white blood cell counts for adult females \nfrom Data Set 1 “Body Data” in Appendix B. The scatterplot located to the left be-\nlow shows the regression line. If we include an additional pair of data, x = 30 and \ny = 100, we get the regression line shown to the right below. The additional point \n(30, 100) is an influential point because the graph of the regression line did change \nconsiderably, as shown by the regression line located to the right below. Compare the \ntwo graphs to see clearly that the addition of this one pair of values has a very dra-\nmatic effect on the regression line, so that the additional point (30, 100) is an influen-\ntial point. The additional point is also an outlier because it is far from the other points.\nPulse Rates and White Blood Cell  \nCounts for Females from Table 10-1\nPulse Rates and White Blood Cell  \nCounts with Additional Point: (30, 100)\nResiduals and the Least-Squares Property\nWe stated that the regression equation represents the straight line that “best” fits the \ndata. The criterion to determine the line that is better than all others is based on the \nvertical distances between the original data points and the regression line. Such dis-\ntances are called residuals.\nDEFINITION\nFor a pair of sample x and y values, the residual is the difference between the  \nobserved sample value of y and the y value that is predicted by using the regres-\nsion equation. That is,\nResidual = 1observed y - predicted y2 = y - yn\n",
    "10-2 Regression \n469\nSo far, this definition hasn’t yet won any prizes for simplicity, but you can easily under-\nstand residuals by referring to Figure 10-6, which corresponds to the paired sample data \nshown in the margin. In Figure 10-6, the residuals are represented by the dashed lines.\nx\n8\n12\n20\n24\ny\n4\n24\n 8\n32\nThe paired data are plotted as points in Figure 10-6.\nConsider the sample point with coordinates of (8, 4). If we substitute x = 8 into the \nregression equation yn = 1 + x, we get a predicted value of yn = 9. But for x = 8, the ac-\ntual observed sample value is y = 4. The difference y - yn = 4 - 9 = -5 is a residual.\nThe regression equation represents the line that “best” fits the points according to \nthe following least-squares property.\n0\n0\n10\n20\n30\n40\n10\n20\n30\n40\nResidual = –5\nResidual = 11\nResidual = –13\nResidual = 7\ny\nx\ny = 1 + x\nˆ\nFIGURE 10-6  Residuals and Squares of Residuals\nDEFINITION\nA straight line satisfies the least-squares property if the sum of the squares of the \nresiduals is the smallest sum possible.\nFrom Figure 10-6, we see that the residuals are -5, 11,-13, and 7, so the sum of their \nsquares is\n1-52 2 + 112 + 1-132 2 + 72 = 364\nWe can visualize the least-squares property by referring to Figure 10-6, where the \nsquares of the residuals are represented by the shaded square areas. The sum of the shaded \nsquare areas is 364, which is the smallest sum possible. Use any other straight line, and the \nshaded squares will combine to produce an area larger than the combined shaded area of 364.\nFortunately, we need not deal directly with the least-squares property when we \nwant to find the equation of the regression line. Calculus has been used to build the \nleast-squares property into Formulas 10-3 and 10-4. Because the derivations of these \nformulas require calculus, we don’t include the derivations in this text.\nResidual Plots\nIn this section and the preceding section we listed simplified requirements for the ef-\nfective analyses of correlation and regression results. We noted that we should always \nbegin with a scatterplot, and we should verify that the pattern of points is approxi-\nmately a straight-line pattern. We should also consider outliers. A residual plot can be \nanother helpful tool for analyzing correlation and regression results and for checking \nthe requirements necessary for making inferences about correlation and regression.\n",
    "470 \nCHAPTER 10 Correlation and Regression\nDEFINITION\nA residual plot is a scatterplot of the (x, y) values after each of the y-coordinate \nvalues has been replaced by the residual value y - yn (where yn denotes the pre-\ndicted value of y). That is, a residual plot is a graph of the points 1x, y - yn2.\nTo construct a residual plot, draw a horizontal reference line through the residual value of \n0, then plot the paired values of 1x, y - yn2. Because the manual construction of residual \nplots can be tedious, the use of technology is strongly recommended. When analyzing a \nresidual plot, look for a pattern in the way the points are configured, and use these criteria:\n \n■The residual plot should not have any obvious pattern (not even a straight-line \npattern). (This lack of a pattern confirms that a scatterplot of the sample data is a \nstraight-line pattern instead of some other pattern.)\n \n■The residual plot should not become much wider (or thinner) when viewed from left \nto right. (This confirms the requirement that for the different fixed values of x, the \ndistributions of the corresponding y values all have the same standard deviation.)\nEXAMPLE 6  Residual Plot\nThe 147 pairs of pulse rates and white blood cell counts for females in Data Set 1 \n“Body Data” in Appendix B are used to obtain the accompanying Minitab-generated \nresidual plot. When the first sample x value of 80 is substituted into the regression \nequation of yn = 4.06 + 0.0345x (found in Examples 1 and 2), we get the  \npredicted value of yn = 6.8. For the first x value of 80, the actual corresponding y \nvalue is 8.7, so the value of the residual is\n1Observed y - predicted y2 = y - yn = 8.7 − 6.8 =  1.9\nUsing the x value of 80 and the residual of 1.9, we get the coordinates of the \npoint (80, 1.9), which is one of the points in the residual plot shown here.\nMinitab\nSee the three residual plots on the top of the next page.\n \n■Leftmost Residual Plot: This graph suggests that the regression equation is a \ngood model.\n \n■Middle Residual Plot: This graph shows a distinct pattern, suggesting that the \nsample data do not follow a straight-line pattern as required.\n \n■Rightmost Residual Plot: This graph becomes thicker, which suggests that the \nrequirement of equal standard deviations is violated.\n",
    "10-2 Regression \n471\nResidual Plot Suggesting That the  \nRegression Equation Is a Good Model\nResidual Plot with an Obvious Pattern, \nSuggesting That the Regression  \nEquation Is Not a Good Model\nResidual Plot That Becomes Wider,  \nSuggesting That the Regression  \nEquation Is Not a Good Model\nStatistical Literacy and Critical Thinking\n1. Notation Different patients are randomly selected and measured for pulse rate and body \ntemperature. Using technology with x representing the pulse rates and y representing tempera-\ntures, we find that the regression equation has a slope of -0.001 and a y-intercept of 98.3.\na. What is the equation of the regression line?\nb. What does the symbol yn represent?\n2. Notation What is the difference between the regression equation yn = b0 + b1x and the re-\ngression equation y = b0 + b1x?\n3. Best-Fit Line\na. What is a residual?\nb. In what sense is the regression line the straight line that “best” fits the points in a scatterplot?\n4. Correlation and Slope What is the relationship between the linear correlation coefficient r \nand the slope b1 of a regression line?\nMaking Predictions. In Exercises 5–8, let the predictor variable x be the first variable \ngiven. Use the given data to find the regression equation and the best predicted value of the \nresponse variable. Be sure to follow the prediction procedure summarized in Figure 10-5 on \npage 466. Use a 0.05 significance level.\n5. Arm Circumference and Height Arm circumferences (cm) and heights (cm) are mea-\nsured from randomly selected adult females (from Data Set 1 “Body Data”). The 147 pairs \nof measurements yield x = 32.49 cm, y = 161.69 cm, r = 0.066, P-value = 0.428, and \nyn = 159 + 0.0916x. Find the best predicted value of yn (height) given an adult female with an \narm circumference of 40.0 cm.\n6. Bear Measurements Head widths (in.) and weights (lb) were measured for 20 randomly \nselected bears (from Data Set 11 “Bear Measurements”). The 20 pairs of measurements yield \nx = 6.9 in., y = 214.3 lb, r = 0.879, P-value = 0.000, and yn = -212 + 61.9x. Find the \nbest predicted value of yn (weight) given a bear with a head width of 6.5 in.\n7. Height and Weight Heights (cm) and weights (kg) are measured for 100 randomly se-\nlected adult males (from Data Set 1 “Body Data”). The 100 pairs of measurements yield \nx = 173.79 cm, y = 85.93 kg, r = 0.418, P-value = 0.000, and yn = -106 + 1.10x. Find \nthe best predicted value of yn (weight) given an adult male who is 180 cm tall.\n10-2 Basic Skills and Concepts\nRegression\nAccess tech instructions, videos, and data sets at www.TriolaStats.com\nTECH CENTER \n",
    "472 \nCHAPTER 10 Correlation and Regression\n8. White BCCs and Systolic BP White blood cell counts (BCCs) and systolic blood pres-\nsure (BP) amounts are measured for 50 randomly selected adult males (from Data Set 1 “Body \nData”). The 50 pairs of measurements yield x = 125.4 mm Hg, y = 6.75 (1000 cells>mL), \nr = 0.055, P-value = 0.702, and yn = 5.66 + 0.009x. Find the best predicted value of yn\n(white blood cell count) for an adult male with systolic blood pressure of 150 mm Hg.\nFinding the Equation of the Regression Line. In Exercises 9 and 10, use the given \ndata to find the equation of the regression line. Examine the scatterplot and identify a  \ncharacteristic of the data that is ignored by the regression line.\n9.  \nx\n10\n8\n13\n9\n11\n14\n6\n4\n12\n7\n5\ny\n9.14\n8.14\n8.74\n8.77\n9.26\n8.10\n6.13\n3.10\n9.13\n7.26\n4.74\n10. \nx\n10\n8\n13\n9\n11\n14\n6\n4\n12\n7\n5\ny\n7.46\n6.77\n12.74\n7.11\n7.81\n8.84\n6.08\n5.39\n8.15\n6.42\n5.73\n11. Effects of an Outlier Refer to the Minitab-generated scatterplot given in Exercise 11 of \nSection 10-1 on page 458.\na. Using the pairs of values for all 10 points, find the equation of the regression line.\nb. After removing the point with coordinates (10, 10), use the pairs of values for the remaining \n9 points and find the equation of the regression line.\nc. Compare the results from parts (a) and (b).\n12. Effects of Clusters Refer to the Minitab-generated scatterplot given in Exercise 12 of \nSection 10-1 on page 459.\na. Using the pairs of values for all 8 points, find the equation of the regression line.\nb. Using only the pairs of values for the 4 points in the lower left corner, find the equation of \nthe regression line.\nc. Using only the pairs of values for the 4 points in the upper right corner, find the equation of \nthe regression line.\nd. Compare the results from parts (a), (b), and (c).\nRegression and Predictions. Exercises 13–24 use the same data sets as Exercises 13–24 \nin Section 10-1. In each case, find the regression equation, letting the first variable be the \npredictor (x) variable. Find the indicated predicted value by following the prediction proce-\ndure summarized in Figure 10-5 on page 466.\n13. Brain Volume and IQ Use the following brain volumes (x) and IQ scores (y). If a subject \nhas a brain volume of 1200 cm3, what is the best predicted IQ score?\nIQ\n87\n101\n103\n96\n101\n96\n93\n88\n97\n114\n113\nBrain \nVolume\n \n1027\n \n1281\n \n1051\n \n1079\n \n1173\n \n1079\n \n1067\n \n1104\n \n1029\n \n1100\n \n1204\nBody \nWeight\n \n58.514\n \n63.958\n \n133.358\n \n107.503\n \n61.236\n \n61.236\n \n83.916\n \n79.38\n \n81.648\n \n88.452\n \n79.38\n14. Weight and IQ Use the weights (x) and IQ scores (y) from the preceding exercise. If a sub-\nject weighs 79.380 kg, what is the best predicted IQ score? How does it compare to the actual \nIQ score of 88 for the subject who weighed 79.380 kg?\n15. Predicting Height Use the shoe print lengths and heights to find the best predicted height \nof a male who has a shoe print length of 31.3 cm. Would the result be helpful to police crime \nscene investigators in trying to describe the male?\nShoe Print (cm)\n 29.7\n 29.7\n 31.4\n 31.8\n 27.6\nFoot Length (cm)\n 25.7\n 25.4\n 27.9\n 26.7\n 25.1\nHeight (cm)\n175.3\n177.8\n185.4\n175.3\n172.7\n",
    "10-2 Regression \n473\n16. Predicting Height Use the foot lengths and heights from the preceding exercise to find the \nbest predicted height of a male who has a foot length of 28 cm. Would the result be helpful to \npolice crime scene investigators in trying to describe the male?\n17. Lemons and Car Crashes Using the listed lemon>crash data, find the best predicted \ncrash fatality rate for a year in which there are 500 metric tons of lemon imports. Is the predic-\ntion worthwhile?\nLemon Imports\n230\n265\n358\n480\n530\nCrash Fatality Rate\n15.9\n15.7\n15.4\n15.3\n14.9\n18. Crickets and Temperature Find the best predicted temperature at a time when a cricket \nchirps 3000 times in 1 minute. What is wrong with this predicted temperature?\nChirps in 1 min\n882\n1188\n1104\n864\n1200\n1032\n960\n900\nTemperature 1°F2\n69.7\n93.3\n84.3\n76.3\n88.6\n82.6\n71.6\n79.6\n19. Pulse Rate and Systolic Blood Pressure Use the following pulse rates and systolic \nblood pressures. If a subject has a pulse rate of 80 beats per minute, what is the best predicted \nsystolic blood pressure?\nPulse\n 86\n 72\n 82\n 82\n 64\n68\n 70\n 78\n 96\n 72\n 60\n 98\nSystolic\n126\n104\n130\n106\n158\n96\n156\n112\n122\n114\n102\n126\nDiastolic\n 70\n 66\n 74\n 64\n 74\n52\n 90\n 70\n 68\n 74\n 60\n 68\n20. Systolic and Diastolic Blood Pressure Use the systolic and diastolic blood pressures \nfrom the preceding exercise. If a female has a systolic blood pressure of 120 mm Hg, what is \nthe best predicted diastolic blood pressure?\n21. Weighing Seals with a Camera Using the listed width>weight data, find the best pre-\ndicted weight of a seal if the overhead width measured from a photograph is 2 cm. Can the \nprediction be correct? If not, what is wrong?\nOverhead Width\n7.2\n7.4\n9.8\n9.4\n8.8\n8.4\nWeight\n116\n154\n245\n202\n200\n191\n22. Manatees Use the listed boat>manatee data. In a year not included in the data below, there \nwere 970,000 registered pleasure boats in Florida. Find the best predicted number of manatee \nfatalities resulting from encounters with boats. Is the result reasonably close to 79, which was \nthe actual number of manatee fatalities?\nPleasure Boats\n99\n99\n97\n95\n90\n90\n87\n90\n90\nManatee Fatalities\n92\n73\n90\n97\n83\n88\n81\n73\n68\n23. POTUS Using the president>opponent heights, find the best predicted height of an \nopponent of a president who is 190 cm tall. Does it appear that heights of opponents can be \npredicted from the heights of the presidents?\nPresident\n178\n182\n188\n175\n179\n183\n192\n182\n177\n185\n188\n188\n183\n188\nOpponent\n180\n180\n182\n173\n178\n182\n180\n180\n183\n177\n173\n188\n185\n175\n24. Tree Circumference and Height Using the circumference>height data, find the best pre-\ndicted height of a tree with a circumference of 5.0 feet. What is a big advantage of being able to \npredict height given a known circumference?\nCircumference\n1.8\n1.9\n1.8\n2.4\n5.1\n3.1\n5.5\n5.1\n8.3\n13.7\n5.3\n4.9\nHeight\n21.0\n33.5\n24.6\n40.7\n73.2\n24.9\n40.4\n45.3\n53.5\n93.8\n64.0\n62.7\n",
    "474 \nCHAPTER 10 Correlation and Regression\nLarge Data Sets. Exercises 25–32 use the same Appendix B data sets as Exercises 25–32 \nin Section 10-1. In each case, find the regression equation, letting the first variable be the \npredictor (x) variable. Find the indicated predicted values following the prediction proce-\ndure summarized in Figure 10-5 on page 466.\n25. Brain Volume and IQ Repeat Exercise 13 using all of the brain volumes and IQ scores in \nData Set 9 “IQ and Brain Size” in Appendix B.\n26. Weight and IQ Repeat Exercise 14 “Weight and IQ” using all of the weights and IQ scores \nin Data Set 9 “IQ and Brain Size” in Appendix B.\n27. Predicting Height Use the shoe print lengths and heights of the 19 males from Data Set 7 \n“Foot and Height.” Find the best predicted height of a male who has a shoe print length of 31.3 cm.\n28. Predicting Height Use the foot lengths and heights from the 19 males in Data Set 7 “Foot \nand Height.” Find the best predicted height of a male who has a foot length of 28 cm.\n29. Pulse Rate and Blood Pressure Use all of the pulse rates and systolic blood pressure \namounts for adult females in Data Set 1 “Body Data” in Appendix B. If a subject has a pulse \nrate of 80 beats per minute, what is the best predicted systolic blood pressure?\n30. Blood Pressure Use the systolic and diastolic blood pressures from the females in Data \nSet 1 “Body Data” in Appendix B. If a female has a systolic blood pressure of 120 mm Hg, \nwhat is the best predicted diastolic blood pressure?\n31. Audiometry Use the right ear threshold measurements and the corresponding left ear \nthreshold measurements from Data Set 4 “Audiometry” in Appendix B. What is the best pre-\ndicted threshold measurement for the left ear given a measurement of 20 for the right ear?\n32. Vision Use the measurements of visual acuity from the right eye and left eye as listed in \nData Set 5 “Vision” in Appendix B. What is the best predicted measurement for the left ear \ngiven a reading of 50 for the right ear?\n10-2 Beyond the Basics\n33. Least-Squares Property According to the least-squares property, the regression line \nminimizes the sum of the squares of the residuals. Refer to the data in Table 10-1 on page 443.\na. Find the sum of squares of the residuals.\nb. Show that the regression equation yn = 3.00 + 0.0500x results in a larger sum of squares of \nresiduals.\nKey Concept In Section 10-2 we presented a method for using a regression equa-\ntion to find a predicted value of y, but it would be great to have a way of determining \nthe accuracy of such predictions. In this section we introduce the prediction interval, \nwhich is an interval estimate of a predicted value of y. See the following definitions \nfor the distinction between confidence interval and prediction interval.\n10-3 \nPrediction Intervals and Variation\nDEFINITIONS\nA prediction interval is a range of values used to estimate a variable (such as a \npredicted value of y in a regression equation).\nA confidence interval is a range of values used to estimate a population param-\neter (such as m or p or s).\n",
    "10-3 Prediction Intervals and Variation \n475\nIn Example 4(b) from the preceding section, we showed that when using 147 \npairs of pulse rates and white blood cell counts for females, the regression equation is \nyn = 4.06 + 0.0345x. Given a female pulse rate of 80 (x = 80), the best predicted white \nblood cell count is 6.8 (which is found by substituting x = 80 in the regression equation). \nFor x = 80, the “best” predicted white blood cell count is 6.8, but we have no sense of the \naccuracy of that estimate, so we need an interval estimate. A prediction interval estimate of \na predicted value yn can be found using the components in the following Key Elements box. \nGiven the nature of the calculations, the use of technology is strongly recommended.\nPrediction Intervals\nObjective\nFind a prediction interval, which is an interval estimate of a predicted value of y.\nRequirement\nFor each fixed value of x, the corresponding sample values of y are normally distributed about the regression line, and \nthose normal distributions have the same variance.\nFormulas for Creating a Prediction Interval\nGiven a fixed and known value x0, the prediction interval for an individual y value is\nyn - E 6 y 6 yn + E\nwhere the margin of error is\nE = ta>2 seB1 + 1\nn +\nn1x0 - x 2 2\nn1Σx22 - 1Σx2 2\nand x0 is a given value of x, ta>2 has n − 2 degrees of free-\ndom, and se is the standard error of estimate found from \nFormula 10-5 or Formula 10-6. (The standard error of es-\ntimate se is a measure of variation of the residuals, which \nare the differences between the observed sample y values \nand the predicted values yn that are found from the regres-\nsion equation.)\nKEY ELEMENTS\nFORMULA 10-5 \n \n \n se = B\nΣ1 y - yn2 2\nn - 2\nFORMULA  10-6     se = B\nΣy2 - b0Σy - b1Σxy\nn - 2\n(This is an equivalent form of Formula 10-5 that is \ngood for manual calculations.)\nEXAMPLE 1   Pulse Rates and White Blood Cell Counts:  \nFinding a Prediction Interval\nFor the 147 pairs of pulse rates and white blood cell counts for females from Data \nSet 1 “Body Data” in Appendix B, we found that there is sufficient evidence to sup-\nport the claim of a linear correlation between those two variables, and the regression \nequation is yn = 4.06 + 0.0345x. For a female with a pulse rate of 80, the best pre-\ndicted white blood cell count is 6.8 (found by substituting x = 80 in the regression \nequation). For a female with pulse rate of 80, construct a 95% prediction interval \nfor the white blood cell count.\ncontinued\n",
    "476 \nCHAPTER 10 Correlation and Regression\nSOLUTION\nThe accompanying StatCrunch and Minitab displays provide the 95% prediction \ninterval, which is 3.0 6 y 6 10.6 when rounded.\nMinitab\nStatCrunch\nThe same 95% prediction interval could be manually calculated using these components:\nx0 = 80 (given)\nse = 1.92241 (provided by many technologies, including Statdisk, Minitab,  \n   Excel, StatCrunch, and TI-83>84 Plus calculator)\nyn = 6.82624 (predicted value of y found by substituting x = 80 into the  \n  regression equation)\nta>2 = 1.976 (with df = 145 and an area of 0.05 in two tails)\nn = 147, x = 74.04082, Σx = 10,884, Σx2 = 828,832\nINTERPRETATION\nThe 95% prediction interval is 3.0 6 y 6 10.6. This means that if we select a \nrandom female with a pulse rate of 80 (x = 80), we have 95% confidence that the \nlimits of 3.0 and 10.6 contain the white blood cell count. That is a wide range of \nvalues. The prediction interval would be much narrower and our estimated white \nblood cell count would be much better if the linear correlation were much stronger.\nExplained and Unexplained Variation\nAssume that we have a sample of paired data having the following properties shown \nin Figure 10-7:\n \n■There is sufficient evidence to support the claim of a linear correlation  \nbetween x and y.\n \n■The equation of the regression line is yn = 3 + 2x.\n \n■The mean of the y values is given by y = 9.\n \n■One of the pairs of sample data is x = 5 and y = 19.\n \n■The point (5, 13) is one of the points on the regression line, because substituting \nx = 5 into the regression equation of yn = 3 + 2x yields yn = 13.\nFigure 10-7 shows that the point (5, 13) lies on the regression line, but the point \n(5, 19) from the original data set does not lie on the regression line. If we completely ignore \ncorrelation and regression concepts and want to predict a value of y given a value of x \nand a collection of paired (x, y) data, our best guess would be the mean y = 9. But in \nthis case there is a linear correlation between x and y, so a better way to predict the value \nof y when x = 5 is to substitute x = 5 into the regression equation to get yn = 13. We \ncan explain the discrepancy between y = 9 and yn = 13 by noting that there is a linear \nrelationship best described by the regression line. Consequently, when x = 5, the pre-\ndicted value of y is 13, not the mean value of 9. For x = 5, the predicted value of y is 13, \n",
    "10-3 Prediction Intervals and Variation \n477\nbut the observed sample value of y is actually 19. The discrepancy between yn = 13 and \ny = 19 cannot be explained by the regression line, and it is called a residual or unex-\nplained deviation, which can be expressed in the general format of y - yn.\nAs in Section 3-2 where we defined the standard deviation, we again consider \na deviation to be a difference between a value and the mean. (In this case, the \nmean is y = 9.) Examine Figure 10-7 carefully and note these specific deviations \nfrom y = 9:\nTotal deviation 1from y = 92 of the point 15, 192 = y - y = 19 - 9 = 10\nExplained deviation 1from y = 92 of the point 15, 192 = yn - y = 13 - 9 = 4\nUnexplained deviation 1from y = 92 of the point 15, 192 = y - yn = 19 - 13 = 6\nThese deviations from the mean are generalized and formally defined as follows.\nExplained\ndeviation\n(y – y)\ny = 3 + 2x\n0\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n0\n1\n2\n3\n4\n5\n6\n7\n8\n9\n(5, 9)\n(5, 13)\n(5, 19)\nTotal\ndeviation\n(y – y)\nUnexplained\ndeviation\n(y – y)\ny = 9\nx\ny\nˆ\nˆ\nˆ\nFIGURE 10-7 Total, Explained, and Unexplained Deviation\nDEFINITIONS\nAssume that we have a collection of paired data containing the sample point (x, y), \nthat yn is the predicted value of y (obtained by using the regression equation), and \nthat the mean of the sample y values is y.\nThe total deviation of (x, y) is the vertical distance y - y, which is the distance  \nbetween the point (x, y) and the horizontal line passing through the sample mean y.\nThe explained deviation is the vertical distance yn - y, which is the distance be-\ntween the predicted y value and the horizontal line passing through the sample \nmean y.\nThe unexplained deviation is the vertical distance y - yn, which is the vertical dis-\ntance between the point (x, y) and the regression line. (The distance y - yn is also \ncalled a residual, as defined in Section 10-2.)\nIn Figure 10-7 we can see the following relationship for an individual point (x, y):\n1total deviation2 = 1explained deviation2 + 1unexplained deviation2\n1y - y2   =    \n1yn - y2    +     1y - yn2\nIs It Ethical to Experiment \nwith Prisoners?\nThere was a \ntime when \ncompanies were \nallowed to con-\nduct research \non prisoners. \nFor example, \nbetween 1962 and 1966,  \n33 pharmaceutical companies \ntested 153 experimental drugs on \nprisoners at Holmesburg Prison in \nPhiladelphia (based on data from \n“Biomedical Research Involving \nPrisoners,” by Lawrence Gostin, \nJournal of the American Medical \nAssociation, Vol. 297, No. 7).\nThe Common Rule has been \nestablished in the United States \nas the standard of ethics for bio-\nmedical and behavioral research \ninvolving human subjects. Central \nto the Common Rule are these \nrequirements: (1) Participating \nsubjects are selected equitably \nand give their fully informed, fully \nvoluntary written consent; (2) pro-\nposed research must be reviewed \nby an independent oversight \ngroup and approved only if risks \nto subjects have been minimized \nand are reasonable in relation to \nanticipated benefits, if any, to the \nsubjects, and the importance of \nthe knowledge that may reason-\nably be expected to result. The \ndetailed text of the Common Rule \ncan be found on the U.S. Depart-\nment of Health & Human Services \nwebsite at www.hhs.gov.\n",
    "478 \nCHAPTER 10 Correlation and Regression\nThe previous expression involves deviations away from the mean, and it applies to any \none particular point (x, y). If we sum the squares of deviations using all points (x, y), we \nget amounts of variation. The same relationship applies to the sums of squares shown in \nFormula 10-7, even though the expression is not algebraically equivalent to Formula 10-7. \nIn Formula 10-7, the total variation is the sum of the squares of the total deviation values, \nthe explained variation is the sum of the squares of the explained deviation values, and the \nunexplained variation is the sum of the squares of the unexplained deviation values.\nFORMULA 10-7\n1total variation2 = 1explained variation2 + 1unexplained variation2\nΣ1y - y2 2  =   \nΣ1yn - y2 2    +    \nΣ1y - yn2 2\nCoefficient of Determination\nIn Section 10-1 we saw that the linear correlation coefficient r can be used to find the \nproportion of the total variation in y that can be explained by the linear correlation. \nThis statement was made in Section 10-1:\nThe value of r2 is the proportion of the variation in y that is explained by the \nlinear relationship between x and y.\nThis statement about the explained variation is formalized with the following definition.\nDEFINITION\nThe coefficient of determination is the proportion of the variation in y that is  \nexplained by the regression line. It is computed as\nr 2 = explained variation\ntotal variation\nWe can compute r2 by using the definition just given with Formula 10-7, or we \ncan simply square the linear correlation coefficient r. Go with squaring r.\nEXAMPLE 2   Pulse Rates and White Blood Cell Counts:  \nFinding a Coefficient of Determination\nIf we use the 147 pairs of pulse rates and white blood cell counts of females in  \nData Set 1 “Body Data” in Appendix B, we find that the linear correlation coeffi-\ncient is r = 0.221. Find the coefficient of determination. Also, find the percentage \nof the total variation in y (white blood cell count) that can be explained by the linear \ncorrelation between pulse rate and white blood cell count.\nSolution\nWith r = 0.221 the coefficient of determination is r2 = 0.049.\nINTERPRETATION\nBecause r2 is the proportion of total variation that can be explained, we conclude \nthat 4.9% of the total variation in the white blood cell count can be explained by \npulse rate, and the other 95.1% cannot be explained by pulse rate. The other 95.1% \nmight be explained by some other factors and>or random variation.\n",
    "10-3 Prediction Intervals and Variation \n479\nStatistical Literacy and Critical Thinking\n1. se Notation Using Data Set 1 “Body Data” in Appendix B, if we let the predictor variable \nx represent heights of males and let the response variable y represent weights of males, the \nsample of 153 heights and weights results in se = 16.27555 cm. In your own words, describe \nwhat that value of se represents.\n2. Prediction Interval Using the heights and weights described in Exercise 1, a height of \n180 cm is used to find that the predicted weight is 91.3 kg, and the 95% prediction interval \nis (59.0 kg, 123.6 kg). Write a statement that interprets that prediction interval. What is the \nmajor advantage of using a prediction interval instead of simply using the predicted weight of \n91.3 kg? Why is the terminology of prediction interval used instead of confidence interval?\n3. Coefficient of Determination Using the heights and weights described in Exercise 1, the \nlinear correlation coefficient r is 0.394. Find the value of the coefficient of determination. What \npractical information does the coefficient of determination provide?\n4. Standard Error of Estimate A random sample of 118 different female statistics students \nis obtained, and their weights are measured in kilograms and in pounds. Using the 118 paired \nweights (weight in kg, weight in lb), what is the value of se? For a female statistics student who \nweighs 100 lb, the predicted weight in kilograms is 45.4 kg. What is the 95% prediction interval?\nInterpreting the Coefficient of Determination. In Exercises 5–8, use the value of the  \nlinear correlation coefficient r to find the coefficient of determination and the percentage of \nthe total variation that can be explained by the linear relationship between the two variables.\n5. Crickets and Temperature r = 0.874 (x = number of cricket chirps in 1 minute, \ny = temperature in oF)\n6. Weight , Waist r = 0.885 1x = weight of male, y = waist size of male2\n7. Bear Neck Size and Weight r = 0.934 (x = neck size, y = weight)\n8. Bears r = 0.783 1x = head width of a bear, y = weight of a bear2\nInterpreting a Computer Display. In Exercises 9–12, refer to the display obtained by using \nthe paired data consisting of Florida registered boats (tens of thousands) and numbers  \nof manatee deaths from encounters with boats in Florida for different recent years (from  \nData Set 12 in Appendix B). Along with the paired boat, manatee sample data, StatCrunch was \nalso given the value of 85 (tens of thousands) boats to be used for predicting manatee fatalities.\n10-3 Basic Skills and Concepts\nStatCrunch\n9. Testing for Correlation Use the information provided in the display to determine the value \nof the linear correlation coefficient. Is there sufficient evidence to support a claim of a linear \ncorrelation between numbers of registered boats and numbers of manatee deaths from encoun-\nters with boats?\nPrediction Intervals\nAccess tech instructions, videos, and data sets at www.TriolaStats.com\nTECH CENTER \n",
    "480 \nCHAPTER 10 Correlation and Regression\n10. Identifying Total Variation What percentage of the total variation in manatee fatalities \ncan be explained by the linear correlation between registered boats and manatee fatalities?\n11. Predicting Manatee Fatalities Using x = 85 (for 850,000 registered boats), what is the \nsingle value that is the best predicted number of manatee fatalities resulting from encounters \nwith boats?\n12. Finding a Prediction Interval For a year with 850,000 (x = 85) registered boats in \nFlorida, identify the 95% prediction interval estimate of the number of manatee fatalities result-\ning from encounters with boats. Write a statement interpreting that interval.\nFinding a Prediction Interval. In Exercises 13–16, use the paired data consisting of \nregistered Florida boats (tens of thousands) and manatee fatalities from boat encounters \nlisted in Data Set 12 “Manatee Deaths” in Appendix B. Let x represent number of regis-\ntered boats and let y represent the corresponding number of manatee deaths. Use the given \nnumber of registered boats and the given confidence level to construct a prediction interval \nestimate of manatee deaths.\n13. Boats Use x = 85 (for 850,000 registered boats) with a 99% confidence level.\n14. Boats Use x = 98 (for 980,000 registered boats) with a 95% confidence level.\n15. Boats Use x = 96 (for 960,000 registered boats) with a 95% confidence level.\n16. Boats Use x = 87 (for 870,000 registered boats) with a 99% confidence level.\nVariation and Prediction Intervals. In Exercises 17–20, find the (a) explained varia-\ntion, (b) unexplained variation, and (c) indicated prediction interval. In each case, there is \nsufficient evidence to support a claim of a linear correlation, so it is reasonable to use the \nregression equation when making predictions.\n17. Blood Pressure The table below lists systolic blood pressures (mm Hg) and diastolic blood \npressures (mm Hg) of adult females (from Data Set 1 “Body Data” in Appendix B). For the pre-\ndiction interval, use a systolic blood pressure of 120 mm Hg and use a 95% confidence level.\nSystolic\n126\n104\n130\n106\n158\n96\n156\n112\n122\n114\n102\n126\nDiastolic\n 70\n 66\n 74\n 64\n 74\n52\n 90\n 70\n 68\n 74\n 60\n 68\n18. Tree Circumference and Height The table below lists circumferences (in feet) and the \nheights (in feet) of trees in Marshall, Minnesota (based on data from “Tree Measurements,” \nby Stanley Rice, American Biology Teacher, Vol. 61, No. 9). For the prediction interval, use a \ncircumference of 4.0 ft and use a 99% confidence level. Comment on the range of values in the \nprediction interval.\nCircumference\n1.8\n1.9\n1.8\n2.4\n5.1\n3.1\n5.5\n5.1\n8.3\n13.7\n5.3\n4.9\nHeight\n21.0\n33.5\n24.6\n40.7\n73.2\n24.9\n40.4\n45.3\n53.5\n93.8\n64.0\n62.7\n19. Crickets and Temperature The table below lists numbers of cricket chirps in 1 minute \nand the temperature in oF. For the prediction interval, use 1000 chirps in 1 minute and use a \n90% confidence level.\nChirps in 1 min\n882\n1188\n1104\n864\n1200\n1032\n960\n900\nTemperature 1°F2\n69.7\n93.3\n84.3\n76.3\n88.6\n82.6\n71.6\n79.6\n20. Weighing Seals with a Camera The table below lists overhead widths (cm) of seals \nmeasured from photographs and the weights (kg) of the seals (based on “Mass Estimation of \nWeddell Seals Using Techniques of Photogrammetry,” by R. Garrott of Montana State Univer-\nsity). For the prediction interval, use a 99% confidence level with an overhead width of 9.0 cm.\nOverhead Width\n7.2\n7.4\n9.8\n9.4\n8.8\n8.4\nWeight\n116\n154\n245\n202\n200\n191\n",
    "10-4 Multiple Regression \n481\n21. Confidence Interval for Mean Predicted Value Example 1 in this section illustrated the \nprocedure for finding a prediction interval for an individual value of y. When using a specific \nvalue x0 for predicting the mean of all values of y, the confidence interval is as follows:\nyn - E 6 y 6 yn + E\nwhere\nE =  ta>2 # se B\n1\nn +\nn1x0 - x2 2\nn1Σx22 - 1Σx2 2\nThe critical value ta>2 is found with n - 2 degrees of freedom. Using the 147 pairs of pulse \nrates and white blood cell counts of females in Data Set 1 “Body Data” in Appendix B, find a \n95% confidence interval estimate of the mean white blood cell count given that a female has a \npulse rate of (a) 80 beats per minute and (b) 70 beats per minute.\n10-3 Beyond the Basics\nKey Concept So far in this chapter we have discussed the linear correlation between \ntwo variables, but this section presents methods for analyzing a linear relationship \nwith more than two variables. We focus on these two key elements: (1) finding the \nmultiple regression equation and (2) using the value of adjusted R2 and the P-value as \nmeasures of how well the multiple regression equation fits the sample data. Because \nthe required calculations are so difficult, manual calculations are impractical, so this \nsection emphasizes the use and interpretation of results from technology.\nAs in the preceding sections of this chapter, we will consider linear relationships \nonly. The following multiple regression equation describes linear relationships involv-\ning more than two variables.\n10-4 \nMultiple Regression\nDEFINITION\nA multiple regression equation expresses a linear relationship between a response \nvariable y and two or more predictor variables (x1, x2, . . . , xk). The general form of a \nmultiple regression equation obtained from sample data is\nyn = b0 + b1x1 + b2x2 + g + bkxk\nThe following Key Elements box includes the key components of this section. \nFor notation, see that the coefficients b0, b1, b2, c, bk are sample statistics used to \nestimate the corresponding population parameters b0, b1, b2, c, bk. Also, note that \nthe multiple regression equation is a natural extension of the format yn = b0 + b1x1\nused in Section 10-2 for regression equations with a single independent variable x1. \nIn Section 10-2, it would have been reasonable to question why we didn’t use the \nmore common and familiar format of y = mx + b, and we can now see that using \nyn = b0 + b1x1 allows us to easily extend that format to include additional predictor \nvariables.\n",
    "482 \nCHAPTER 10 Correlation and Regression\nFinding a Multiple Regression Equation\nObjective\nUse sample matched data from three or more variables to find a multiple regression equation that is useful for predicting \nvalues of the response variable y.\nNotation\nyn = b0 + b1x1 + b2x2 + g + bk xk (multiple regression equation found from sample data)\ny = b0 + b1x1 + b2x2 + g + bk xk (multiple regression equation for the population of data)\nyn = predicted value of y (computed using the multiple regression equation)\nk = number of predictor variables (also called independent variables or x variables)\nn = sample size (number of values for any one of the variables)\nRequirements\nFor any specific set of x values, the regression equation is associated with a random error often denoted by e. We assume \nthat such errors are normally distributed with a mean of 0 and a standard deviation of s and that the random errors are \nindependent.\nProcedure for Finding a Multiple Regression Equation\nManual calculations are not practical, so technology must be used.\nKEY ELEMENTS\nEXAMPLE 1  Predicting Weight\nData Set 1 “Body Data” includes heights (cm), waist circumferences (cm), and \nweights (kg) from a sample of 153 males. Find the multiple regression equation in \nwhich the response variable (y) is the weight of a male and the predictor variables \nare height (x1) and waist circumference (x2).\nSOLUTION\nUsing Statdisk with the sample data in Data Set 1 “Body Data,” we obtain the  \nresults shown in the display on the top of the next page. The coefficients b0, b1, and \nb2 are used in the multiple regression equation:\n  yn = -149 + 0.769x1 + 1.01x2\nor \nWeight = -149 + 0.769 Height + 1.01 Waist\nThe obvious advantage of the second format above is that it is easier to keep track \nof the roles that the variables play.\n",
    "10-4 Multiple Regression \n483\nStatdisk\nIf a multiple regression equation fits the sample data well, it can be used for predic-\ntions. For example, if we determine that the multiple regression equation in Example 1 is \nsuitable for predictions, we can use the height and waist circumference of a male to predict \nhis weight. But how do we determine whether the multiple regression equation fits the \nsample data well? Two very helpful tools are the values of adjusted R2 and the P-value.\nR2 and Adjusted R2\nR2 denotes the multiple coefficient of determination, which is a measure of how well \nthe multiple regression equation fits the sample data. A perfect fit would result in R2 = 1,\nand a very good fit results in a value near 1. A very poor fit results in a value of R2 close \nto 0. The value of R2 = 0.878 (“Coeff of Det, R2”) in the Statdisk display for Example 1 \nindicates that 87.8% of the variation in weights of males can be explained by their heights \nand waist circumferences. However, the multiple coefficient of determination R2 has a se-\nrious flaw: As more variables are included, R2 increases. (R2 could remain the same, but it \nusually increases.) The largest R2 is obtained by simply including all of the available vari-\nables, but the best multiple regression equation does not necessarily use all of the available \nvariables. Because of that flaw, it is better to use the adjusted coefficient of determination, \nwhich is R2 adjusted for the number of variables and the sample size.\nDEFINITION\nThe adjusted coefficient of determination is the multiple coefficient of determina-\ntion R2 modified to account for the number of variables and the sample size. It is \ncalculated by using Formula 10-8.\nFORMULA 10-8\nAdjusted R2 = 1 -\n1n - 12\n3n - 1k + 12 4 11 - R22\nwhere\n n = sample size\n k = number of predictor 1x2 variables\n",
    "484 \nCHAPTER 10 Correlation and Regression\nThe preceding Statdisk display shows the adjusted coefficient of determination as \n“Adjusted R^2” = 0.877 (rounded). If we use Formula 10-8 with R2 = 0.8783478,\nn = 153, and k = 2, we get adjusted R2 = 0.877 (rounded). When comparing this \nmultiple regression equation to others, it is better to use the adjusted R2 of 0.877. \nWhen considering the adjusted R2 of 0.877 by itself, we see that it is fairly high (close \nto 1), suggesting that the regression equation is a good fit with the sample data.\nP-Value\nThe P-value is a measure of the overall significance of the multiple regression equa-\ntion. The displayed P-value of 0 (rounded) is small, indicating that the multiple re-\ngression equation has good overall significance and is usable for predictions. We can \npredict weights of males based on their heights and waist circumferences. Like the \nadjusted R2, this P-value is a good measure of how well the equation fits the sample \ndata. The P-value results from a test of the null hypothesis that b1 = b2 = 0. Rejec-\ntion of b1 = b2 = 0 implies that at least one of b1 and b2 is not 0, indicating that this \nregression equation is effective in predicting weights of males. A complete analysis \nof results might include other important elements, such as the significance of the in-\ndividual coefficients, but we are keeping things simple (!) by limiting our discussion \nto the three key components—multiple regression equation, adjusted R2, and P-value.\nFinding the Best Multiple Regression Equation\nWhen trying to find the best multiple regression equation, we should not necessarily \ninclude all of the available predictor variables. Finding the best multiple regression \nequation requires abundant use of judgment and common sense, and there is no exact \nand automatic procedure that can be used to find the best multiple regression equa-\ntion. Determination of the best multiple regression equation is often quite difficult and \nis beyond the scope of this section, but the following guidelines are helpful.\nGuidelines for Finding the Best Multiple Regression Equation\n1. Use common sense and practical considerations to include or exclude vari-\nables. For example, when trying to find a good multiple regression equation for \npredicting the height of a daughter, we should exclude the height of the physi-\ncian who delivered the daughter, because that height is obviously irrelevant.\n2. Consider the P-value.  Select an equation having overall significance, as deter-\nmined by a low P-value found in the technology results display.\n3. Consider equations with high values of adjusted R2, and try to include \nonly a few variables. Instead of including almost every available variable, \ntry to include relatively few predictor (x) variables. Use these guidelines:\n \n■Select an equation having a value of adjusted R2 with this property: If an \nadditional predictor variable is included, the value of adjusted R2 does not \nincrease very much.\n \n■For a particular number of predictor (x) variables, select the equation with the \nlargest value of adjusted R2.\n \n■In excluding predictor (x) variables that don’t have much of an effect on the \nresponse (y) variable, it might be helpful to find the linear correlation coef-\nficient r for each pair of variables being considered. If two predictor values \nhave a very high linear correlation coefficient (called multicollinearity), there \nis no need to include them both, and we should exclude the variable with the \nlower value of adjusted R2.\nThe following example illustrates that common sense and critical thinking are es-\nsential tools for effective use of methods of statistics.\n",
    "10-4 Multiple Regression \n485\nTABLE 10-4 Selected Results from Data Set 7 “Foot and Height” in Appendix B\nPredictor Variables\nAdjusted R2\nP-Value\nAge\n0.1772\n0.004\nd Not best: Adjusted R2 is far less than \n0.7014 for Foot Length.\nFoot Length\n0.7014\n0.000\nd Best: High adjusted R2 and lowest \nP-value.\nShoe Print Length\n0.6520\n0.000\nd Not best: Adjusted R2 is less than \n0.7014 for Foot Length.\nFoot Length>Shoe \nPrint Length\n0.7484\n0.000\nd Not best: The adjusted R2 value is not \nvery much higher than 0.7014 for the single \nvariable of Foot Length.\nAge>Foot Length>\nShoe Print Length>\nShoe Size\n0.7585\n0.000\nd Not best: There are other cases using \nfewer variables with adjusted R2 that are \nnot too much smaller.\nEXAMPLE 2  Predicting Height from Footprint Evidence\nData Set 7 “Foot and Height” in Appendix B includes the age, foot length, shoe \nprint length, shoe size, and height for each of 40 different subjects. Using those \nsample data, find the regression equation that is best for predicting height. Is the \n“best” regression equation a good equation for predicting height?\nSOLUTION\nUsing the response variable of height and possible predictor variables of age, foot \nlength, shoe print length, and shoe size, there are 15 different possible combinations \nof predictor variables. Table 10-4 includes key results from five of those combinations. \nBlind and thoughtless application of regression methods would suggest that the best \nregression equation uses all four of the predictor variables, because that combination \nyields the highest adjusted R2 value of 0.7585. However, given the objective of using \nevidence to estimate the height of a suspect, we use critical thinking as follows.\n \n1. Delete the variable of age, because criminals rarely leave evidence identifying \ntheir ages.\n \n2. Delete the variable of shoe size, because it is really a rounded form of  \nfoot length.\n \n3. For the remaining variables of foot length and shoe print length, use only foot \nlength because its adjusted R2 value of 0.7014 is greater than 0.6520 for shoe \nprint length, and it is not very much less than the adjusted R2 value of 0.7484 \nfor both foot length and shoe print length. In this case, it is better to use one \npredictor variable instead of two.\n \n4. Although it appears that the use of the single variable of foot length is best, \nwe also note that criminals usually wear shoes, so shoe print lengths are more \nlikely to be found than foot lengths.\nINTERPRETATION\nBlind use of regression methods suggests that when estimating the height of a sub-\nject, we should use all of the available data by including all four predictor variables \nof age, foot length, shoe print length, and shoe size, but other practical consider-\nations suggest that it is best to use the single predictor variable of foot length. So the \nbest regression equation appears to be this: Height = 64.1 + 4.29 (Foot Length). \nHowever, given that criminals usually wear shoes, it is best to use the single predictor \ncontinued\n",
    "486 \nCHAPTER 10 Correlation and Regression\nvariable of shoe print length, so the best practical regression equation appears to be \nthis: Height = 80.9 + 3.22 (Shoe Print Length). The P-value of 0.000 suggests that \nthe regression equation yields a good model for estimating height.\nBecause the results of this example are based on sample data from only 40 \nsubjects, estimates of heights will not be very accurate. As is usually the case, better \nresults could be obtained by using larger samples.\nTests of Regression Coefficients The preceding guidelines for finding the best \nmultiple regression equation are based on the adjusted R2 and the P-value, but we \ncould also conduct individual hypothesis tests based on values of the regression coef-\nficients. Consider the regression coefficient of b1. A test of the null hypothesis b1 = 0\ncan tell us whether the corresponding predictor variable should be included in the \nregression equation. Rejection of b1 = 0 suggests that b1 has a nonzero value and is \ntherefore helpful for predicting the value of the response variable. Procedures for such \ntests are described in Exercise 17.\nPredictions With Multiple Regression\nWhen we discussed regression in Section 10-2, we listed (on page 466) four points \nto consider when using regression equations to make predictions. These same points \nshould be considered when using multiple regression equations.\nStatistical Literacy and Critical Thinking \n1. Terminology Using the lengths (in.), chest sizes (in.), and weights (lb) of bears from Data \nSet 11 “Bear Measurements” in Appendix B, we get this regression equation: Weight =\n-274 + 0.426 Length + 12.1 Chest Size. Identify the response and predictor variables.\n2. Best Multiple Regression Equation For the regression equation given in Exercise 1, the \nP-value is 0.000 and the adjusted R2 value is 0.925. If we were to include an additional predic-\ntor variable of neck size (in.), the P-value becomes 0.000 and the adjusted R2 becomes 0.933. \nGiven that the adjusted R2 value of 0.933 is larger than 0.925, is it better to use the regression \nequation with the three predictor variables of length, chest size, and neck size? Explain.\n3. Adjusted Coefficient of Determination For Exercise 2, why is it better to use values of \nadjusted R2 instead of simply using values of R2?\n4. Interpreting R2 For the multiple regression equation given in Exercise 1, we get \nR2 = 0.928. What does that value tell us?\nInterpreting a Computer Display. In Exercises 5–8, we want to consider the correlation \nbetween heights of fathers and mothers and the heights of their sons. Refer to the following \nStatCrunch display and answer the given questions or identify the indicated items.  \nThe display is based on Data Set 6 “Family Heights” in Appendix B.\n10-4 Basic Skills and Concepts\nMultiple Regression\nAccess tech instructions, videos, and data sets at www.TriolaStats.com\nTECH CENTER \n",
    "10-4 Multiple Regression \n487\n5. Height of Son Identify the multiple regression equation that expresses the height of a son in \nterms of the height of his father and mother.\n6. Height of Son Identify the following:\na. The P-value corresponding to the overall significance of the multiple regression equation\nb. The value of the multiple coefficient of determination R2\nc. The adjusted value of R2\n7. Height of Son Should the multiple regression equation be used for predicting the height of \na son based on the height of his father and mother? Why or why not?\n8. Height of Son A son will be born to a father who is 70 in. tall and a mother who is 60 in. \ntall. Use the multiple regression equation to predict the height of the son. Is the result likely to \nbe a good predicted value? Why or why not?\nPredicting Weights of Males. In Exercises 9–12, refer to the accompanying table, which \nwas obtained by using the data for males in Data Set 1 “Body Data” in Appendix B. The \nresponse (y) variable is weight (kg), and the predictor (x) variables are HT (height in cm), \nWAIST (waist circumference in cm), and ARM (arm circumference in cm).\nPredictor (x) Variables\nP-Value\nR2\nAdjusted R2\nRegression Equation\nHT, WAIST, ARM\n0.000\n0.941\n0.939\nyn = -147 + 0.632 HT +\n0.697 WAIST + 1.58 ARM\nHT, WAIST\n0.000\n0.878\n0.877\nyn = -149 + 0.769 HT + 1.01 WAIST\nHT, ARM\n0.000\n0.777\n0.774\nyn = -124 + 0.541 HT + 3.44 ARM\nWAIST, ARM\n0.000\n0.879\n0.878\nyn = -45.0 + 0.659 WAIST + 1.92 ARM\nHT\n0.000\n0.155\n0.150\nyn = -85.1 + 0.980 HT\nWAIST\n0.000\n0.784\n0.782\nyn = -19.1 + 1.05 WAIST\nARM\n0.000\n0.732\n0.731\nyn = -37.1 + 3.65 ARM\n9. If only one predictor (x) variable is used to predict weight, which single variable is best? Why?\n10. If exactly two predictor (x) variables are to be used to predict weight, which two variables \nshould be chosen? Why?\n11. Which regression equation is best for predicting the weight? Why?\n12. If a male has a height of 186 cm, a waist circumference of 107.8 cm, and an arm circumfer-\nence of 37.0 cm, what is the best predicted weight? Is that predicted value likely to be a good \nestimate? Is that predicted value likely to be very accurate?\n",
    "488 \nCHAPTER 10 Correlation and Regression\nAppendix B Data Sets. In Exercises 13–16, refer to the indicated data set in Appendix B \nand use technology to obtain results.\n13. Predicting Nicotine in Cigarettes Refer to Data Set 15 “Cigarette Contents” in \nAppendix B and use the tar, nicotine, and CO amounts for the cigarettes that are 100 mm \nlong, filtered, nonmenthol, and nonlight (the last set of measurements). Find the best regression \nequation for predicting the amount of nicotine in a cigarette using the predictor variables of (1) \ntar; (2) carbon monoxide; (3) tar and carbon monoxide. Why is it best? Is the best regression \nequation a good regression equation for predicting the nicotine content? Why or why not?\n14. Predicting Nicotine in Cigarettes Repeat the preceding exercise using the sample data \nfrom the Menthol cigarettes listed in Data Set 15 in Appendix B.\n15. Predicting IQ Score Refer to Data Set 9 “IQ and Brain Size” in Appendix B and find the \nbest regression equation with IQ score as the response (y) variable. Use predictor variables of \nbrain volume and>or body weight. Why is this equation best? Based on these results, can we \npredict someone’s IQ score if we know their brain volume and body weight? Based on these \nresults, does it appear that people with larger brains have higher IQ scores?\n16. Full IQ Score Refer to Data Set 8 “IQ and Lead” in Appendix B and find the best regres-\nsion equation with IQF (full IQ score) as the response (y) variable. Use predictor variables of \nIQV (verbal IQ score) and IQP (performance IQ score). Why is this equation best? Based on \nthese results, can we predict someone’s full IQ score if we know their verbal IQ score and their \nperformance IQ score? Is such a prediction likely to be very accurate?\n10-4 Beyond the Basics\n17. Testing Hypotheses About Regression Coefficients If the coefficient b1 has a nonzero \nvalue, then it is helpful in predicting the value of the response variable. If b1 = 0, it is not helpful \nin predicting the value of the response variable and can be eliminated from the regression equation. \nTo test the claim that b1 = 0 use the test statistic t = 1b1 - 02>sb1. Critical values or P-values \ncan be found using the t distribution with n - 1k + 12 degrees of freedom, where k is the number \nof predictor (x) variables and n is the number of observations in the sample. The standard error sb1 \nis often provided by software. For example, see the accompanying StatCrunch display for \nExample 1, which shows that sb1 = 0.071141412 (found in the column with the heading of “Std. \nErr.” and the row corresponding to the first predictor variable of height). Use the sample data in \nData Set 1 “Body Data” and the StatCrunch display to test the claim that b1 = 0. Also test the \nclaim that b2 = 0. What do the results imply about the regression equation?\n18. Confidence Intervals for Regression Coefficients A confidence interval for the \nregression coefficient b1 is expressed as\nb1 - E 6 b1 6 b1 + E\nwhere\nE = ta>2sb1\nThe critical t score is found using n - (k + 1) degrees of freedom, where k, n, and sb1 are de-\nscribed in Exercise 17. Using the sample data from Example 1, n = 153 and k = 2, so df = 150 \nand the critical t scores are {1.976 for a 95% confidence level. Use the sample data for Example 1, \nthe Statdisk display in Example 1 on page 483, and the StatCrunch display in Exercise 17 to con-\nstruct 95% confidence interval estimates of b1 (the coefficient for the variable representing height) \nand b2 (the coefficient for the variable representing waist circumference). Does either confidence \ninterval include 0, suggesting that the variable be eliminated from the regression equation?\n",
    "10-5 Dummy Variables and Logistic Regression \n489\nSo far in this chapter, all variables have represented continuous data, but many situa-\ntions involve a variable with only two possible qualitative values (such as male>female \nor dead>alive or cured>not cured). To obtain regression equations that include such \nvariables, we must somehow assign numbers to the two different categories. A com-\nmon procedure is to represent the two possible values by 0 and 1, where 0 represents a \n“failure” and 1 represents a “success.” For disease outcomes, 1 is often used to repre-\nsent the event of the disease or death, and 0 is used to represent the nonevent.\n10-5 \nDummy Variables and Logistic Regression\nDEFINITION\nA dummy variable is a variable having only the values of 0 and 1 that are used to \nrepresent the two different categories of a qualitative variable.\nThe word “dummy” is used because the variable does not actually have any quanti-\ntative value, but we use it as a substitute to represent the different categories of the \nqualitative variable.\nDummy Variable as a Predictor Variable\nProcedures of regression analysis differ dramatically depending on whether the \ndummy variable is a predictor (x) variable or the response (y) variable. If we include \na dummy variable as another predictor (x) variable, we can use the same methods of \nSection 10-4, as illustrated in Example 1.\nEXAMPLE 1  Using a Dummy Variable as a Predictor Variable\nTable 10-5 on the next page is adapted from Data Set 6 “Family Heights” and it \nis in a more convenient format for this example. Use the dummy variable of sex \n(coded as 0 = female, 1 = male). Given that a father is 69 in. tall and a mother is \n63 in. tall, find the multiple regression equation and use it to predict the height of \n(a) a daughter and (b) a son.\nSOLUTION\nUsing the methods of multiple regression from Section 10-4 with technology, we get \nthis regression equation:\nHeight of Child = 36.5 - 0.0336 1Height of Father2 +  \n        0.461 1Height of Mother2 + 6.14 1Sex2 \nwhere the value of the dummy variable of sex is 0 for a daughter or 1 for a son.\n \na. To ﬁnd the predicted height of a daughter, we substitute 0 for the sex variable, \nand we also substitute 69 in. for the father’s height and 63 in. for the mother’s \nheight. The result is a predicted height of 63.2 in. for a daughter.\n \nb. To ﬁnd the predicted height of a son, we substitute 1 for the sex variable, and \nwe also substitute 69 in. for the father’s height and 63 in. for the mother’s \nheight. The result is a predicted height of 69.4 in. for a son.\nThe coefficient of 6.14 in the regression equation shows that when given the height \nof a father and the height of a mother, a son will have a predicted height that is  \n6.14 in. more than the height of a daughter.\ncontinued\n",
    "490 \nCHAPTER 10 Correlation and Regression\nDummy Variable as a Response Variable: Logistic Regression\nIn Example 1, we could use the same methods of Section 10-4 because the dummy \nvariable of sex is a predictor variable. However, if the dummy variable is the response \n(y) variable, we cannot use the methods of Section 10-4, and we should use a different \nmethod known as logistic regression.\nDEFINITION\nLogistic regression is a procedure used for finding a regression equation in which \nthe response variable is a dummy variable.\nDummy response variables are common in clinical research where the response \nvariable might be the yes>no indication for the occurrence of a disease such as diabe-\ntes, cancer, hypertension, or chronic kidney disease. Other dummy response variables \ninclude yes>no values for hospitalization, death, or need of a kidney transplant. As \nwith dummy predictor variables, dummy response variables are typically coded as 0 \nand 1. For example, the response variable of “hospitalization” could be coded as 1 for \npatients who were hospitalized and 0 for patients who were not hospitalized.\nSimple Logistic Regression We use simple logistic regression when these condi-\ntions are met:\n \n■There is a single predictor x variable.\n \n■The sample y data have values of 0 and 1.\nTABLE 10-5 Heights (in inches) of Fathers, Mothers, and Their Children\nHeight of Father\nHeight of Mother\nHeight of Child\nSex of Child (1 = Male)\n66.5\n62.5\n70.0\n1\n70.0\n64.0\n68.0\n1\n67.0\n65.0\n69.7\n1\n68.7\n70.5\n71.0\n1\n69.5\n66.0\n71.0\n1\n70.0\n65.0\n73.0\n1\n69.0\n66.0\n70.0\n1\n68.5\n67.0\n73.0\n1\n65.5\n60.0\n68.0\n1\n69.5\n66.5\n70.5\n1\n70.5\n63.0\n64.5\n0\n71.0\n65.0\n62.0\n0\n70.5\n62.0\n60.0\n0\n66.0\n66.0\n67.0\n0\n68.0\n61.0\n63.5\n0\n68.0\n63.0\n63.0\n0\n71.0\n62.0\n64.5\n0\n65.5\n63.0\n63.5\n0\n64.0\n60.0\n60.0\n0\n71.0\n63.0\n63.5\n0\n",
    "10-5 Dummy Variables and Logistic Regression \n491\nInstead of yielding predicted values of y itself, the method of simple logistic regres-\nsion yields an equation with the following format:\n ln a\np\n1 - p b = b0 + b1x\nIn the above expression, p is the probability that y = 1. Given a specific value for x, \nwe can solve for p by first substituting that x value in the right side of the above equa-\ntion to obtain a value v; then we can solve for p by evaluating the following, where \ne = 2.71828:\np =\nev\n1 + ev\nEXAMPLE 2  Simple Logistic Regression\nUse the paired height>gender data from Data Set 1 “Body Data” to find the simple \nlogistic regression equation, and let the response variable (y) be gender with \n0 = female and 1 = male. Then find the probability that a person with a height of \n190 cm (or 74.8 in.) is a male.\nSOLUTION  \nWe can use technology with the gender>height data to find this equation:\n ln a\np\n1 - pb = -40.6 + 0.2421Height2\nGiven a height of x = 190 cm, we substitute that value in the right side of the \nabove equation to get the value v = -40.6 + 0.242(190) = 5.38. We can now \nsolve for p as follows (using e = 2.71828):\np =\nev\n1 + ev =\ne5.38\n1 + e5.38 = 0.995\nOn the basis of this simple logistic regression model, a person with a height of  \n190 cm (or 74.8 in.) has a probability of 0.995 of being a male.\nThe ratio p>(1 - p) is the odds in favor of y = 1 (as defined in Section 4-4), \nand ln(p>(1 - p)) is the natural logarithm of the odds that y = 1. It is the natural \nlogarithm of those odds that are assumed to be linear in x, but the relationship between \nx and p is a curve that is bounded between 0 and 1, as shown in Figure 10-8 on the next \npage. Figure 10-8 uses the same gender>height data from Example 2. The simple logis-\ntic regression curve takes the shape of a stretched-out “S.” See that as x gets smaller, the \ncurve gets closer to 0, but never quite reaches it. Similarly, as x increases, the curve gets \ncloser to 1. The simple logistic regression curve can be thought of as representing prob-\nabilities that y = 1 (male) for each possible value of x (height). In this particular case, x \nand y have a positive relationship, so that as height x increases, the probability of a male \n(y = 1) also increases. This also implies that b1 7 0. If x and y had a negative rela-\ntionship, then the curve would be an inverted S shape; and as x increases, the probabil-\nity that y = 1 would decrease.\n",
    "492 \nCHAPTER 10 Correlation and Regression\nMultiple Logistic Regression\nWe use multiple logistic regression when there is a dummy response variable and more \nthan one predictor variable. Instead of yielding predicted values of y itself, the method of \nmultiple logistic regression yields an equation with the following format:\n ln a\np\n1 - p b = b0 + b1x1 + b2x2 + c + bkxk\nIn the above expression, p is the probability that y = 1. Given specific values for the \ndifferent x predictor variables, we can solve for p by first substituting those values in \nthe right side of the above equation to obtain a value v; then we can solve for p by \nevaluating the following:\np =\nev\n1 + ev\nFIGURE 10-8 Simple Logistic Regression Curve\nEXAMPLE 3  Multiple Logistic Regression\nLet a sample data set consist of the heights (cm) and arm circumferences (cm) of \nwomen and men as listed in Data Set 1 “Body Data” in Appendix B, and let the  \nresponse y variable represent gender (0 = female, 1 = male). With this list of  \ngenders, heights, and arm circumferences, logistic regression could be used with \nsoftware to obtain this model:\nln a\np\n1 - p b = -40.6 + 0.2421HT2 + 0.001291ArmCirc2\nIn the expression above, p is the probability of a male, so a value of p close to  \n1 indicates that the person is likely a male, and a value of p close to 0 indicates  \nthat the person is not likely a male (so the person is likely to be a female). See the \nfollowing two sets of results.\n \n■If we use the model above and substitute a height of 183 cm (or 72.0 in.) and an \narm circumference of 33 cm (or 13.0 in.), we can solve for p to get p = 0.977, \nindicating that such a large person has a 97.7% chance of being a male.\n \n■In contrast, a small person with a height of 150 cm (or 59.1 in.) and an arm cir-\ncumference of 20 cm (or 7.9 in.) results in a probability of p = 0.014, indicat-\ning that such a small person is very unlikely to be a male.\n",
    "10-5 Dummy Variables and Logistic Regression \n493\nIn clinical research, there is much interest in finding biomarkers that are good pre-\ndictors of disease. In particular, if it is hypothesized that some new biomarker might \nimprove predictions, one method of testing this hypothesis is to include the biomarker \nas one of the variables in a multiple logistic regression model. The other predictors in \nthe model could be established risk factors, such as age and sex. If the new biomarker \nadds predictive value, then its coefficient in the logistic regression model should be \ndifferent from 0. See Example 4.\nEXAMPLE 4  Multiple Logistic Regression\nResearchers were interested in determining whether “distortion product otoacoustic \nemissions” (DPOAEs) were a useful tool for identification of hearing impairment in \nnewborns. The dummy response variable was hearing impairment (1 = impaired,  \n0 = not impaired), as defined from a gold standard test when the infants were at  \nleast 8 months of age. The multiple logistic regression model included DPOAE  \n(a continuous variable), age (weeks), and sex (0 = female, 1 = male) as predictor \nvariables. Use of multiple logistic regression yielded the following model (based  \non data from “Identification of Neonatal Hearing Impairment,” by Norton et al.,  \nEar and Hearing, Vol. 21):\n ln a\np\n1 - pb = 3.84 - 0.061DPOAE2 + 0.021Sex2 - 0.021Age2\nIn the expression above, p is the probability of hearing impairment. We can obtain \nP-values from statistical software packages, and the above equation resulted in the \nfollowing P-values:\nVariable \nP-Value\nDPOAE \n60.01\nSex \n \n 0.91\nAge \n \n 0.4\nThe P-value for the variable DPOAE is very small, which shows strong evidence \nagainst the null hypothesis that DPOAE is not a predictor of impairment. It appears \nthat DPOAE might be a useful test of hearing impairment in newborns. For the \nvariable Sex, the P-value of 0.91 indicates that we do not have sufficient evidence to \nsupport the claim that sex is a predictor of impairment. Similarly, Age was also not \na statistically significant predictor.\nWhy can’t we use the same regression methods from the preceding sections \nwhen the dummy variable is the response variable? Suppose we have one inde-\npendent variable, and we use the methods of Section 10-2 to find a linear regres-\nsion equation using sample data for which the values of y are all 0’s and 1’s. There \nis nothing that prevents some of the predicted y values from being greater than 1 or \nless than 0, but that would be inconsistent with the requirement that probabilities \nmust be between 0 and 1. See Figure 10-9 on the following page, which shows a \ncontinuous predictor variable x (height) plotted against a dummy response variable \ny (gender with values of 0 = female and 1 = male). Figure 10-9 uses the same \ngender>height data from Example 2. The straight regression line in Figure 10-9 re-\nsults from using the methods of linear regression in Section 10-2. See that the line \n",
    "494 \nCHAPTER 10 Correlation and Regression\ndips below 0 for small values of x and it rises above 1 for large values of x. These \nresults violate the requirement that probability values must be between 0 and 1. \nThe straight line from linear regression is not a good model here. The S curve from \nlogistic regression (Figure 10-8) is a far better model.\nAssessing the Quality of Predictions When assessing the quality of predictions made \nwith logistic regression, one consideration might be the P-value for the overall sig-\nnificance of the regression equation. Another approach might be use of the Hosmer-\nLemeshow test, which assesses whether the model is calibrated well, which means \nthat the observed risks from the sample data match the predicted risks (or probabili-\nties). But in addition to being well calibrated, the model should discriminate between \nobservations at high risk and those at low risk. The area under the curve (AUC) of a \nreceiver operating characteristic (ROC) curve is also used as a measure of the qual-\nity of the model. These and other more detailed methods are included in many books \ndevoted to logistic regression.\nFIGURE 10-9  Linear Regression Line with a Dummy  \nResponse Variable\nStatistical Literacy and Critical Thinking \n1. Dummy Variable What is a dummy variable?\n2. Logistic Regression What is the fundamental difference between logistic regression and \nlinear regression?\n3. Simple Logistic Regression How is simple logistic regression different from multiple \nlogistic regression?\n4. True or False Determine whether this statement is true or false: If a multiple regression \nequation has a continuous response variable and three predictor variables, including one that is \na dummy variable, then we must use methods of logistic regression because a dummy variable \nis included.\n10-5 Basic Skills and Concepts\n",
    "10-5 Dummy Variables and Logistic Regression \n495\nIn Exercises 5–8, use the following logistic regression equation found from Data Set 11 \n“Bear Measurements” in Appendix B. The value of p is the probability that the bear is male.\nln a\np\n1 - pb = 2.40 - 0.05531Length2 + 0.008261Weight2\n5. Bears Identify the predictor and response variables. Which of these are dummy variables?\n6. Bears The given regression equation has an overall P-value of 0.218. What does that sug-\ngest about the quality of predictions made using the regression equation?\n7. Bears Use a length of 60 in. and a weight of 300 lb to find the probability that the bear is a \nmale. Also, what is the probability that the bear is a female?\n8. Bears Use a length of 40 in. and a weight of 50 lb to find the probability that the bear is \na male. What is the probability that the bear is a female? Considering the given length and \nweight, what do we know about this bear?\n9. Weight of a Bear Refer to Data Set 11 “Bear Measurements” in Appendix B and use the \nsex, age, and weight of the bears. For sex, let 0 represent female and let 1 represent male. Let-\nting the response (y) variable represent weight, use the variable of age and the dummy variable \nof sex to find the multiple regression equation. Use the equation to find the predicted weight of \na bear with the characteristics given below. Does sex appear to have much of an effect on the \nweight of a bear?\na. Female bear that is 20 years of age\nb. Male bear that is 20 years of age\n10. Sex, Height, and Weight Refer to Data Set 1 “Body Data” in Appendix B and use the sex, \nheight, and weight of the human subjects. Letting the response (y) variable represent weight, \nuse the dummy variable of sex and use the height to find the multiple regression equation. Use \nthe equation to find the predicted weight of a subject with the characteristics given below. Do \nthe results make sense?\na. Female with a height of 170 cm\nb. Male with a height of 170 cm\n11. Sex, Height, and Weight Refer to Data Set 1 “Body Data” in Appendix B and use the \nsex, height, and weight of the human subjects. Letting the response (y) variable represent sex \n(0 = female, 1 = male), use the variables of height and weight to find the multiple regression \nequation. Use the equation to find the probability that the subject is a male, given that the sub-\nject has a height of 170 cm and a weight of 90 kg.\n12. Sex, Height, and Pulse Rate Refer to Data Set 1 “Body Data” in Appendix B and use the \nsex, height, and pulse rate of the human subjects. Letting the response (y) variable represent sex \n(0 = female, 1 = male), use the variables of height and pulse rate to find the multiple regres-\nsion equation. Use the equation to find the probability that the subject is a male, given that the \nsubject has a height of 170 cm and a pulse rate of 60 beats per minute. Do higher pulse rates \nmake males more likely or less likely?\n13. Sex, Foot Length, and Height Refer to Data Set 7 “Foot and Height” in Appendix B and \nuse the sex, foot length, and height of the subjects. Letting the response (y) variable represent \nsex (0 = female, 1 = male), use the variables of foot length and height to find the multiple \nregression equation. Use the equation to find the probability that the subject is a male, given \nthat the subject has a foot length of 28 cm and a height of 190 cm.\n14. Sex, Shoe Size, and Height Refer to Data Set 7 “Foot and Height” in Appendix B and \nuse the sex, shoe size, and height of the subjects. Letting the response (y) variable represent sex \n(0 = female, 1 = male), use the variables of shoe size and height to find the multiple regres-\nsion equation. Use the equation to find the probability that the subject is a male, given that the \nsubject has a shoe size of 9 and a height of 170 cm. Are predictions of sex made using shoe size \nand height likely to be more or less accurate than predictions of sex made using foot length and \nheight (as in the preceding exercise)?\n",
    "496 \nCHAPTER 10 Correlation and Regression\nThe following exercises are based on the following sample data consisting of systolic blood \npressure measurements (in mm Hg) obtained from the same woman (based on data from \n“Consistency of Blood Pressure Differences Between the Left and Right Arms,” by Eguchi \net al., Archives of Internal Medicine, Vol. 167).\nRight Arm\n102\n101\n 94\n 79\n 79\nLeft Arm\n175\n169\n182\n146\n144\n1. Conclusion The linear correlation coefficient r is found to be 0.867, the P-value is 0.057, \nand the critical values for a 0.05 significance level are {0.878. If you are using a 0.05 signifi-\ncance level, what should you conclude?\n2. Switched Variables Which of the following change if the two variables of right arm and \nleft arm blood pressure measurements are switched: the value of r = 0.867, the P-value of \n0.057, the critical values of {0.878?\n3. Change in Scale Exercise 1 stated that r is found to be 0.867. How does the value of r \nchange if the scale for the right arm measurements is changed from mm Hg to in. Hg, so that all \nof the values for the right arm are multiplied by 0.0394?\n4. Values of r If you had computed the value of the linear correlation coefficient to be 1.500, \nwhat should you conclude?\n5. Predictions The sample data result in a linear correlation coefficient of r = 0.867 and the \nregression equation yn = 43.6 + 1.31x. What is the best predicted value for the left arm given \nthat the measurement for the right arm is 100 mm Hg?\n6. Predictions Repeat the preceding exercise, assuming that the linear correlation coefficient \nfor the paired sample data is r = 0.997.\n7. Explained Variation Given that the linear correlation coefficient r is found to be 0.867, \nwhat is the proportion of the variation in left arm measurements that is explained by the rela-\ntionship between the right and left arm measurements?\n8. Linear Correlation and Relationships True or false: If there is no linear correlation be-\ntween right arm measurements and left arm measurements, then those two variables are not \nrelated in any way.\n9. Causality True or false: If the sample data lead us to conclude that there is sufficient evi-\ndence to support the claim of a linear correlation between right and left arm measurements, \nthen we could also conclude that increases in right arm measurements cause increases in left \narm measurements.\n10. Interpreting Scatterplot If the sample data were to result in the scatterplot shown here, \nwhat is the value of the linear correlation coefficient r?\nChapter Quick Quiz\n",
    "1. Cigarette Tar and Nicotine The table below lists measured amounts (mg) of tar, carbon \nmonoxide (CO), and nicotine in king size cigarettes of different brands (from Data Set 15 \n“Cigarette Contents”).\na. Is there is sufficient evidence to support a claim of a linear correlation between tar and nicotine?\nb. What percentage of the variation in nicotine can be explained by the linear correlation \nbetween nicotine and tar?\nc. Letting y represent the amount of nicotine and letting x represent the amount of tar, identify \nthe regression equation.\nd. The Raleigh brand king size cigarette is not included in the table, and it has 23 mg of tar. \nWhat is the best predicted amount of nicotine? How does the predicted amount compare to the \nactual amount of 1.3 mg of nicotine?\nTar\n25\n27\n20\n24\n20\n20\n21\n24\nCO\n18\n16\n16\n16\n16\n16\n14\n17\nNicotine\n1.5\n1.7\n1.1\n1.6\n1.1\n1.0\n1.2\n1.4\n2. Cigarette Nicotine and Carbon Monoxide Refer to the table of data given in Exercise 1 \nand use the amounts of nicotine and carbon monoxide (CO).\na. Construct a scatterplot using nicotine for the x scale or horizontal axis. What does the scat-\nterplot suggest about a linear correlation between amounts of nicotine and carbon monoxide?\nb. Find the value of the linear correlation coefficient and determine whether there is sufficient evi-\ndence to support a claim of a linear correlation between amounts of nicotine and carbon monoxide.\nc. Letting y represent the amount of carbon monoxide and letting x represent the amount of \nnicotine, find the regression equation.\nd. The Raleigh brand king size cigarette is not included in the table, and it has 1.3 mg of nico-\ntine. What is the best predicted amount of carbon monoxide? How does the predicted amount \ncompare to the actual amount of 15 mg of carbon monoxide?\n3. Cigarette Tar and Carbon Monoxide Refer to the table of data given in Exercise 1 and \nuse the amounts of tar and carbon monoxide.\na. Construct a scatterplot using the horizontal scale to represent the amount of tar. What does \nthe scatterplot suggest?\nb. Does the scatterplot show eight points corresponding to the eight pairs of sample data? If \nnot, why not?\nc. Find the value of the linear correlation coefficient and determine whether there is sufficient \nevidence to support a claim of a linear correlation between amount of tar and amount of carbon \nmonoxide.\nd. Letting y represent amount of carbon monoxide and letting x represent amount of tar, find \nthe regression equation.\ne. The Raleigh brand king size cigarette is not included in the table, and it has 23 mg of tar. \nWhat is the best predicted amount of carbon monoxide? How does the predicted amount com-\npare to the actual amount of 15 mg of carbon monoxide?\n4. Multiple Regression with Cigarettes Use the sample data given in Exercise 1 “Cigarette \nTar and Nicotine.”\na. Find the multiple regression equation with the response (y) variable of amount of nicotine \nand predictor (x) variables of amounts of tar and carbon monoxide.\nReview Exercises\nCHAPTER 10 Review Exercises \n497\ncontinued\n",
    "498 \nCHAPTER 10 Correlation and Regression\nb. Identify the value of the multiple coefficient of determination R2, the adjusted R2, and the \nP-value representing the overall significance of the multiple regression equation.\nc. Use a 0.05 significance level and determine whether the regression equation can be used to \npredict the amount of nicotine given the amounts of tar and carbon monoxide.\nd. The Raleigh brand king size cigarette is not included in the table, and it has 23 mg of tar \nand 15 mg of carbon monoxide. What is the best predicted amount of nicotine? How does the \npredicted amount compare to the actual amount of 1.3 mg of nicotine?\n5. Bacteria Growth In an experiment, the numbers of bacteria in a controlled environment are \nrecorded over time. The table below lists the time (days) that has lapsed and the population size \n(thousands). What do you conclude about the relationship between time and population size? \nWhat horrible mistake would be easy to make if the analysis is conducted without a scatterplot?\nTime (days)\n1\n3\n5\n7\n9\n11\n13\n15\n17\n19\nPopulation (thousands)\n0.1\n1.8\n3.2\n4.0\n4.6\n4.8\n4.7\n4.2\n3.4\n2.2\n6. Logistic Regression with Smoking and Body Temperature Refer to Data Set 2 “Body \nTemperatures” in Appendix B and use the body temperatures at 8 AM on Day 1 and at 12 AM \non Day 1. Let the response variable be whether the subject smokes (1 = smokes, 0 = does not \nsmoke). Find the multiple regression equation. Use the equation to find the probability that the \nsubject smokes, given that the 8 AM body temperature and the 12 AM body temperature are \nboth 98.25oF. Use the P-value for the multiple regression equation to determine whether the \npredicted value is likely to be fairly accurate.\nEffectiveness of Diet. Listed below are weights (lb) of subjects before and after the Zone \ndiet. (Data are based on results from “Comparison of the Atkins, Ornish, Weight Watchers, \nand Zone Diets for Weight Loss and Heart Disease Risk Reduction,” by Dansinger et al.,  \nJournal of the American Medical Association, Vol. 293, No. 1.) Use the data for Exercises 1–5.\nBefore\n183\n212\n177\n209\n155\n162\n167\n170\nAfter\n179\n198\n180\n208\n159\n155\n164\n166\n1. Diet Clinical Trial: Statistics Find the mean and standard deviation of the “before-after” \ndifferences.\n2. Diet Clinical Trial: z Score Using only the weights before the diet, identify the highest \nweight and convert it to a z score. In the context of these sample data, is that highest value \n“significantly” high? Why or why not?\n3. Diet Clinical Trial: Hypothesis Test Use a 0.05 significance level to test the claim that the \ndiet is effective.\n4. Diet Clinical Trial: Confidence Interval Construct a 95% confidence interval estimate of the \nmean weight of subjects before the diet. Write a brief statement interpreting the confidence interval.\n5. Diet Clinical Trial: Correlation Use the before>after weights listed above.\na. Test for a correlation between the before and after weights.\nb. If each subject were to weigh exactly the same after the diet as before, what would be the \nvalue of the linear correlation coefficient?\nc. If all subjects were to lose 5% of their weight from the diet, what would be the value of the \nlinear correlation coefficient found from the before>after weights?\nd. What do the preceding results suggest about the suitability of correlation as a tool for testing \nthe effectiveness of the diet?\nCumulative Review Exercises\n",
    "6. Birth Weights Birth weights in the United States are normally distributed with a mean of \n3420 g and a standard deviation of 495 g.\na. What percentage of babies are born with a weight greater than 3500 g?\nb. Find P10, which is the 10th percentile.\nc. The Rockland Medical Center requires special treatment for babies that are less than \n2450 g (significantly underweight) or more than 4390 g (significantly overweight). What is the \npercentage of babies who require special treatment? Under these conditions, do many babies \nrequire special treatment?\n7. Measuring Lung Volumes In a study of techniques used to measure lung volumes, physi-\nological data were collected for 10 subjects. The values given in the accompanying table are in \nliters, representing the measured forced vital capacities of the 10 subjects in a sitting position \nand in a supine (lying) position (based on data from “Validation of Esophageal Balloon Tech-\nnique at Different Lung Volumes and Postures,” by Baydur et al., Journal of Applied Physiol-\nogy, Vol. 62, No. 1). The issue we want to investigate is whether the position (sitting or supine) \nhas an effect on the measured values.\na. If we test for a correlation between the sitting values and the supine values, will the result \nallow us to determine whether the position (sitting or supine) has an effect on the measured \nvalues? Why or why not?\nb. Use an appropriate test for the claim that the position has no effect, so the mean difference is zero.\nSubject\nA\nB\nC\nD\nE\nF\nG\nH\nI\nJ\nSitting\n4.66\n5.70\n5.37\n3.34\n3.77\n7.43\n4.15\n6.21\n5.90\n5.77\nSupine\n4.63\n6.34\n5.72\n3.23\n3.60\n6.96\n3.66\n5.81\n5.61\n5.33\n8. Cell Phones and Crashes: Analyzing a News Report In an article from the Associated \nPress, it was reported that researchers “randomly selected 100 New York motorists who had \nbeen in an accident and 100 who had not. Of those in accidents, 13.7 percent owned a cellular \nphone, while just 10.6 percent of the accident-free drivers had a phone in the car.” Identify the \nmost notable feature of these results.\nData Set 1 “Body Data” from Appendix B includes low-density lipoprotein (LDL) and high-\ndensity lipoprotein (HDL) cholesterol measurements from 300 subjects. Download the data set \n(from www.TriolaStats.com) and proceed to generate a scatterplot and results from correlation \nand regression. Is there a linear correlation between HDL and LDL? What is the equation of the \nregression line? If the measurements are separated according to gender, do the results change \nvery much? Write a brief report and include appropriate results from technology.\nTechnology Project\nCHAPTER 10 Technology Project \n499\n",
    "500 \nCHAPTER 10 Correlation and Regression\nCooperative Group Activities\n1. In-class activity For each student in the class, measure shoe print length and height. Test \nfor a linear correlation and identify the equation of the regression line. Measure the shoe print \nlength of the professor and use it to estimate his or her height. How close is the estimated \nheight to the actual height?\n2. In-class activity Divide into groups of 8 to 12 people. For each group member, measure the \nheight and also measure his or her navel height, which is the height from the floor to the navel. \nIs there a correlation between height and navel height? If so, find the regression equation with \nheight expressed in terms of navel height. According to one theory, the average person’s ratio \nof height to navel height is the golden ratio: 11 + 252>2 ≈1.6. Does this theory appear to \nbe reasonably accurate?\n3. In-class activity Divide into groups of 8 to 12 people. For each group member, measure \nheight and arm span. For the arm span, the subject should stand with arms extended like the \nwings on an airplane. Using the paired sample data, is there a correlation between height and \narm span? If so, find the regression equation with height expressed in terms of arm span. Can \narm span be used as a reasonably good predictor of height?\nFROM DATA TO DECISION\nCritical Thinking: Is the pain medicine Duragesic  \neffective in reducing pain?\nListed below are measures of pain intensity before and after \nusing the drug Duragesic (fentanyl) (based on data from \nJanssen Pharmaceutical Products, L.P.). The data are listed in \norder by row, and corresponding measures are from the same \nsubject before and after treatment. For example, the first \nsubject had a measure of 1.2 before treatment and a measure \nof 0.4 after treatment. Each pair of measurements is from \none subject, and the intensity of pain was measured using the \nstandard visual analog score. A higher score corresponds to \nhigher pain intensity.\nPain Intensity Before Duragesic Treatment\n1.2\n1.3\n1.5\n1.6\n8.0\n3.4\n3.5\n2.8\n2.6\n2.2\n3.0\n7.1\n2.3\n2.1\n3.4\n6.4\n5.0\n4.2\n2.8\n3.9\n5.2\n6.9\n6.9\n5.0\n5.5\n6.0\n5.5\n8.6\n9.4\n10.0\n7.6\nPain Intensity After Duragesic Treatment\n0.4\n1.4\n1.8\n2.9\n6.0\n1.4\n0.7\n3.9\n0.9\n1.8\n0.9\n9.3\n8.0\n6.8\n2.3\n0.4\n0.7\n1.2\n4.5\n2.0\n1.6\n2.0\n2.0\n6.8\n6.6\n4.1\n4.6\n2.9\n5.4\n4.8\n4.1\nAnalyzing the Results\n1. Correlation Use the given data to construct a scatterplot, \nthen use the methods of Section 10-1 to test for a linear cor-\nrelation between the pain intensity before and after treatment. \nIf there does appear to be a linear correlation, can we con-\nclude that the drug treatment is effective?\n2. Regression Use the given data to find the equation of \nthe regression line. Let the response (y) variable be the pain \nintensity after treatment. What would be the equation of the \nregression line for a treatment having absolutely no effect?\n3. Two Independent Samples The methods of Section 9-2  \ncan be used to test the claim that two populations have the \nsame mean. Identify the specific claim that the treatment is \neffective, then use the methods of Section 9-2 to test that \nclaim. The methods of Section 9-2 are based on the require-\nment that the samples are independent. Are they independent \nin this case?\n4. Matched Pairs The methods of Section 9-3 can be  \nused to test a claim about matched data. Identify the specific \nclaim that the treatment is effective, then use the methods of \nSection 9-3 to test that claim.\n5. Best Method? Which of the preceding results is best for \ndetermining whether the drug treatment is effective in re-\nducing pain? Based on the preceding results, does the drug \nappear to be effective?\n",
    "4. In-class activity Divide into groups of 8 to 12 people. For each group member, use a string \nand ruler to measure head circumference and forearm length. Is there a relationship between \nthese two variables? If so, what is it?\n5. In-class activity Use a ruler as a device for measuring reaction time. One person should \nsuspend the ruler by holding it at the top while the subject holds his or her thumb and fore-\nfinger at the bottom edge ready to catch the ruler when it is released. Record the distance that \nthe ruler falls before it is caught. Convert that distance to the time (in seconds) that it took the \nsubject to react and catch the ruler. (If the distance is measured in inches, use t = 2d>192. If \nthe distance is measured in centimeters, use t = 2d>487.68.) Test each subject once with the \nright hand and once with the left hand, and record the paired data. Test for a correlation. Find \nthe equation of the regression line. Does the equation of the regression line suggest that the \ndominant hand has a faster reaction time?\n6. In-class activity Divide into groups of 8 to 12 people. Record the pulse rate of each group \nmember while he or she is seated. Then record the pulse rate of each group member while he or \nshe is standing. Is there a relationship between sitting and standing pulse rate? If so, what is it?\n7. In-class activity Divide into groups of three or four people. Appendix B includes many \ndata sets not yet used in examples or exercises in this chapter. Search Appendix B for a pair of \nvariables of interest, then investigate correlation and regression. State your conclusions and try \nto identify practical applications.\n8. Out-of-class activity Divide into groups of three or four people. Investigate the relation-\nship between two variables by collecting your own paired sample data and use the methods \nof this chapter to determine whether there is a significant linear correlation. Also identify the \nregression equation and describe a procedure for predicting values of one of the variables when \ngiven values of the other variable. Suggested topics:\n• Is there a relationship between taste and cost of different brands of chocolate chip cookies (or \ncolas)? Taste can be measured on some number scale, such as 1 to 10.\n• Is there a relationship between salaries of professional baseball (or basketball, or football) \nplayers and their season achievements?\n• Is there a relationship between student grade-point averages and the amount of television \nwatched? If so, what is it?\nCHAPTER 10 Cooperative Group Activities \n501\n",
    "502\nGoodness-of-Fit\nContingency Tables\n11-1\n11-2\nWhich Treatment Is Best?\nCHAPTER \nPROBLEM\nGoodness-of-Fit and \nContingency Tables\nThe options for treating a stress fracture in a foot bone  \ninclude surgery, applying a weight-bearing cast, applying a \nnon–weight-bearing cast for six weeks, and applying a  \nnon–weight-bearing cast for less than six weeks.\nTable 11-1 is a contingency table with four rows and two \ncolumns. The cells of the table contain frequency counts. The \nrow variable identifies the treatment used for a stress fracture \nin a foot bone, and the column variable identifies the outcome \nas a success or failure. The table is based on data from  \n“Management of Tarsal Navicular Stress Fractures: Conserva-\ntive Versus Surgical Treatment: A Meta-Analysis,” by Torc  \net al., American Journal of Sports Medicine, Vol. 38, No. 5. In \nthis chapter we will use the data in Table 11-1 to address  \nthese questions:\n11 \n",
    "• Do the four different treatments have different rates of  \nsuccess?\n• Is there a treatment that is best?\n• Should surgery be recommended for treating a stress  \nfracture in a foot bone?\nTABLE 11-1 Treatments for Stress Fracture in a Foot Bone\nSuccess\nFailure\nSurgery\n54\n12\nWeight-Bearing Cast\n41\n51\nNon–Weight-Bearing Cast for 6 Weeks\n70\n 3\nNon–Weight-Bearing Cast for Less  \nThan 6 Weeks\n \n17\n \n 5\nChapters 7 and 8 introduced important methods of inferential statistics, including con-\nfidence intervals for estimating population parameters (Chapter 7) and methods for \ntesting hypotheses or claims (Chapter 8). We then considered inferences involving two \npopulations (Chapter 9) and correlation>regression with paired data (Chapter 10). In \nthis chapter we use statistical methods for analyzing categorical (or qualitative, or at-\ntribute) data that can be partitioned into different cells. The methods of this chapter use \nthe same x2 (chi-square) distribution that was introduced in Section 7-3 and again in \nSection 8-4. See Section 7-3 or Section 8-4 for a quick review of properties of the x2 \ndistribution. Here are the chapter objectives:\nGoodness-of-Fit\n• Use frequency counts of categorical data partitioned into different categories and \ndetermine whether the data fit some claimed distribution.\nContingency Tables\n• Use categorical data summarized as frequencies in a two-way table with at least two \nrows and at least two columns to conduct a formal test of independence between \nthe row variable and column variable.\n• Be able to conduct a formal test of a claim that different populations have the same \nproportions of some characteristics.\n11-1\n11-2\nCHAPTER OBJECTIVES\nChapters 7 and 8 introduced important methods of inferential statistics, including con-\nfidence intervals for estimating population parameters (Chapter 7) and methods for \ntesting hypotheses or claims (Chapter 8). We then considered inferences involving two\npopulations (Chapter 9) and correlation>regression with paired data (Chapter 10). In\nthis chapter we use statistical methods for analyzing categorical (or qualitative, or at-\ntribute) data that can be partitioned into different cells. The methods of this chapter use \nthe same x2 (chi-square) distribution that was introduced in Section 7-3 and again in\nSection 8-4. See Section 7-3 or Section 8-4 for a quick review of properties of the x2\ndistribution. Here are the chapter objectives:\nGoodness-of-Fit\n• Use frequency counts of categorical data partitioned into different categories and\ndetermine whether the data fit some claimed distribution.\nContingency Tables\n• Use categorical data summarized as frequencies in a two-way table with at least two \nrows and at least two columns to conduct a formal test of independence between\nthe row variable and column variable.\n• Be able to conduct a formal test of a claim that different populations have the same\nproportions of some characteristics.\nS\nKey Concept By “goodness-of-fit” we mean that sample data consisting of observed \nfrequency counts arranged in a single row or column (called a one-way frequency \ntable) agree with some particular distribution (such as normal or uniform) being con-\nsidered. We will use a hypothesis test for the claim that the observed frequency counts \nagree with the claimed distribution.\n11-1 \nGoodness-of-Fit\n11-1 Goodness-of-Fit \n503\nDEFINITION\nA goodness-of-fit test is used to test the hypothesis that an observed frequency \ndistribution fits (or conforms to) some claimed distribution.\n",
    "504 \nCHAPTER 11 Goodness-of-Fit and Contingency Tables\nTesting for Goodness-of-Fit\nObjective\nConduct a goodness-of-fit test, which is a hypothesis test to determine whether a single row (or column) of frequency \ncounts agrees with some specific distribution (such as uniform or normal).\nNotation\nO represents the observed frequency of an outcome, found from the sample data.\nE represents the expected frequency of an outcome, found by assuming that the distribution is as claimed.\nk represents the number of different categories or cells.\nn represents the total number of trials (or the total of observed sample values).\np represents the probability that a sample value falls within a particular category\nRequirements\n1. The data have been randomly selected.\n2. The sample data consist of frequency counts for each of the different categories.\n3. For each category, the expected frequency is at least 5. (The expected frequency for a category is the frequency that \nwould occur if the data actually have the distribution that is being claimed. There is no requirement that the observed \nfrequency for each category must be at least 5.)\nNull and Alternative Hypotheses\nH0: The frequency counts agree with the claimed distribution.\nH1: The frequency counts do not agree with the claimed distribution.\nTest Statistic for Goodness-of-Fit Tests\nx2 = a\n(O - E)2\nE\nP-values: P-values are typically provided by technology, or a range of P-values can be found from Table A-4.\nCritical values:\n1. Critical values are found in Table A-4 by using k − 1 degrees of freedom, where k is the number of categories.\n2. Goodness-of-fit hypothesis tests are always right-tailed.\nKEY ELEMENTS \nFinding Expected Frequencies\nConducting a goodness-of-fit test requires that we identify the observed frequencies \ndenoted by O, then find the frequencies expected (denoted by E) with the claimed \ndistribution. There are two different approaches for finding expected frequencies E:\n \n■If the expected frequencies are all equal: Calculate E = n,k.\n \n■If the expected frequencies are not all equal: Calculate E = np for each  \nindividual category.\nAs good as these two preceding formulas for E might be, it is better to use an \ninformal approach by simply asking, “How can the observed frequencies be split up \n",
    "11-1 Goodness-of-Fit \n505\namong the different categories so that there is perfect agreement with the claimed \ndistribution?” Also, note that the observed frequencies are all whole numbers because \nthey represent actual counts, but the expected frequencies need not be whole numbers.\nExamples:\na. Equally Likely A single die is rolled 45 times with the following results.  \nAssuming that the die is fair and all outcomes are equally likely, ﬁnd the  \nexpected frequency E for each empty cell.\nOutcome\n 1\n2\n 3\n4\n5\n6\nObserved Frequency O\n13\n6\n12\n9\n3\n2\nExpected Frequency E\nWith n = 45 outcomes and k = 6 categories, the expected frequency for each \ncell is the same: E = n>k = 45>6 = 7.5. If the die is fair and the outcomes are \nall equally likely, we expect that each outcome should occur about 7.5 times.\n \nb. Not Equally Likely Using the same results from part (a), suppose that we claim \nthat instead of being fair, the die is loaded so that the outcome of 1 occurs 50% \nof the time and the other ﬁve outcomes occur 10% of the time. The probabilities \nare listed in the second row below. Using n = 45 and the probabilities listed \nbelow, we ﬁnd that for the ﬁrst cell, E = np = (45)(0.5) = 22.5. Each of the \nother ﬁve cells will have the expected value of E = np = (45)(0.1) = 4.5.\nOutcome\n1\n2\n3\n4\n5\n6\nProbability\n0.5\n0.1\n0.1\n0.1\n0.1\n0.1\nObserved Frequency O\n13\n6\n12\n9\n3\n2\nExpected Frequency E\n22.5\n4.5\n4.5\n4.5\n4.5\n4.5\nMeasuring Disagreement with the Claimed Distribution\nWe know that sample frequencies typically differ somewhat from the values we theo-\nretically expect, so we consider the key question:\nAre the diﬀerences between the actual observed frequencies O and the  \ntheoretically expected frequencies E signiﬁcant?\nTo measure the discrepancy between the O and E values, we use the test statistic given \nin the preceding Key Elements box. (Later we will explain how this test statistic was \ndeveloped, but it has differences of O - E as a key component.)\nx2 = a\n(O - E)2\nE\nThe x2 test statistic is based on differences between the observed and expected \nvalues. If the observed and expected values are close, the x2 test statistic will be small \nand the P-value will be large. If the observed and expected frequencies are far apart, \nthe x2 test statistic will be large and the P-value will be small. Figure 11-1 on the \nnext page summarizes this relationship. The hypothesis tests of this section are always \nright-tailed, because the critical value and critical region are located at the extreme \nright of the distribution. If confused, just remember this mnemonic:\n“If the P is low, the null must go.”\n(If the P-value is small, reject the null hypothesis that the distribution is  \nas claimed.)\nd\ne\ns.\nWhich Car Seats  \nAre Safest?\nMany people \nbelieve that the \nback seat of a \ncar is the safest \nplace to sit, but \nis it? Univer-\nsity of Buffalo \nresearchers analyzed more than \n60,000 fatal car crashes and \nfound that the middle back seat \nis the safest place to sit in a \ncar. They found that sitting in \nthat seat makes a passenger \n86% more likely to survive than \nthose who sit in the front seats, \nand they are 25% more likely to \nsurvive than those sitting in either \nof the back seats nearest the \nwindows. An analysis of seat belt \nuse showed that when not wear-\ning a seat belt in the back seat, \npassengers are three times more \nlikely to die in a crash than those \nwearing seat belts in that same \nseat. Passengers concerned with \nsafety should sit in the middle \nback seat and wear a seat belt.\n",
    "506 \nCHAPTER 11 Goodness-of-Fit and Contingency Tables\nGood ﬁt with assumed\ndistribution\nNot a good ﬁt with\nassumed distribution\nCompare the observed O\nvalues to the corresponding\nexpected E values.\nOs and Es\nare close\nOs and Es\nare far apart\n“If the P is low,\nthe null must go.”\nFail to reject H0\nReject H0\nSmall x2 value, large P-value\nLarge x2 value, small P-value\nx2 here\nx2 here\nFIGURE 11-1  Relationships Among the X2 Test Statistic,  \nP-Value, and Goodness-of-Fit\nEXAMPLE 1  Last Digits of Weights\nA random sample of 100 weights of Californians is obtained, and the last digits of those \nweights are summarized in Table 11-2 (based on data from the California Department \nof Public Health). When obtaining weights of subjects, it is extremely important to actu-\nally measure their weights instead of asking them to report their weights. By analyzing \nthe last digits of weights, researchers can verify that they were obtained through actual \nmeasurements instead of being reported. When people report weights, they tend to \nround down and they often round way down, so a weight of 197 lb might be rounded \nand reported as a more desirable 170 lb. Reported weights tend to have many last digits \nconsisting of 0 or 5. In contrast, if people are actually weighed, the weights tend to have \nlast digits that are uniformly distributed, with 0, 1, 2, . . . , 9 all occurring with roughly \nthe same frequencies. We could subjectively examine the frequencies in Table 11-2 to \nsee that the digits of 0 and 5 do seem to occur much more often than the other digits, but \nwe will proceed with a formal hypothesis test to reinforce that subjective conclusion.\nTest the claim that the sample is from a population of weights in which the \nlast digits do not occur with the same frequency. Based on the results, what can we \nconclude about the procedure used to obtain the weights?\nSOLUTION\nREQUIREMENT CHECK (1) The data come from randomly selected subjects. (2) The \ndata do consist of frequency counts, as shown in Table 11-2. (3) With 100 sample \nvalues and 10 categories that are claimed to be equally likely, each expected fre-\nquency is 10, so each expected frequency does satisfy the requirement of being a \nvalue of at least 5. All of the requirements are satisfied. \nThe claim that the digits do not occur with the same frequency is equivalent  \nto the claim that the relative frequencies or probabilities of the 10 cells (p0, p1, . . . , \np9) are not all equal. (This is equivalent to testing the claim that the distribution of \ndigits is not a uniform distribution.)\nTABLE 11-2  \nLast Digits of Weights\nLast Digit\nFrequency\n0\n46\n1\n1\n2\n2\n3\n3\n4\n3\n5\n30\n6\n4\n7\n0\n8\n8\n9\n3\n",
    "11-1 Goodness-of-Fit \n507\nStep 1: The original claim is that the digits do not occur with the same frequency. \nThat is, at least one of the probabilities p0, p1, . . ., p9 is different from the others.\nStep 2: If the original claim is false, then all of the probabilities are the same. That \nis, p0 = p1 = p2 = p3 = p4 = p5 = p6 = p7 = p8 = p9.\nStep 3: The null hypothesis must contain the condition of equality, so we have\nH0: p0 = p1 = p2 = p3 = p4 = p5 = p6 = p7 = p8 = p9\nH1: At least one of the probabilities is diﬀerent from the others.\nStep 4: No significance level was specified, so we select the common choice of \na = 0.05.\nStep 5: Because we are testing a claim about the distribution of the last digits being \na uniform distribution (with all of the digits having the same probability), we use \nthe goodness-of-fit test described in this section. The x2 distribution is used with \nthe test statistic given in the preceding Key Elements box.\nStep 6: The observed frequencies O are listed in Table 11-2. Each corresponding \nexpected frequency E is equal to 10 (because the 100 digits would be uniformly \ndistributed among the 10 categories). The Excel add-in XLSTAT is used to ob-\ntain the results shown in the accompanying screen display, and Table 11-3 on the \nnext page shows the manual computation of the x2 test statistic. The test statistic \nis x2 = 212.800. The critical value is x2 = 16.919 (found in Table A-4 with \na = 0.05 in the right tail and degrees of freedom equal to k - 1 = 9). The P-value \nis less than 0.0001. The test statistic and critical value are shown in Figure 11-2.\nStep 7: If we use the P-value method of testing hypotheses, we see that the P-value \nis small (less than 0.0001), so we reject the null hypothesis. If we use the critical \nvalue method of testing hypotheses, Figure 11-2 shows that the test statistic falls in \nthe critical region, so there is sufficient evidence to reject the null hypothesis.\nStep 8: There is sufficient evidence to support the claim that the last digits do not \noccur with the same relative frequency.\nXLSTAT\nReject\np0 5 p15 • • • 5 p9\nFail to reject\np0 5 p15 • • • 5 p9\n0\n \nCritical Value:\nx2 5 16.919\nCritical\nRegion\nTest Statistic:\nx2 5 212.800\nFIGURE 11-2  Test of p0 = p1 = p2 = p3 = p4 = p5 =  \np6 = p7 = p8 = p9\n",
    "508 \nCHAPTER 11 Goodness-of-Fit and Contingency Tables\nTABLE 11-3 Calculating the x2 Test Statistic for the Last Digits of Weights\n \nLast Digit\n \nObserved Frequency O\n \nExpected Frequency E\n \nO −E\n(O −E)2\n(O −E )2\nE\n0\n46\n10\n   36\n1296\n129.6\n1\n1\n10\n  -9\n  81\n8.1\n2\n2\n10\n  -8\n  64\n6.4\n3\n3\n10\n  -7\n  49\n4.9\n4\n3\n10\n  -7\n  49\n4.9\n5\n30\n10\n   20\n 400\n40.0\n6\n4\n10\n  -6\n  36\n3.6\n7\n0\n10\n-10\n 100\n10.0\n8\n8\n10\n  -2\n   4\n0.4\n9\n3\n10\n  -7\n  49\n4.9\nx2 = a\n1O - E 2 2\nE\n= 212.8\nINTERPRETATION\nThis goodness-of-fit test suggests that the last digits do not provide a good fit with \nthe claimed uniform distribution of equally likely frequencies. Instead of actually \nweighing the subjects, it appears that the subjects reported their weights. In fact, \nthe weights are from the California Health Interview Survey (CHIS), and the title of \nthat survey indicates that subjects were interviewed, not measured. Because those \nweights are reported, the reliability of the data is very questionable.\nExample 1 involves a situation in which the expected frequencies E for the dif-\nferent categories are all equal. The methods of this section can also be used when the \nexpected frequencies are different, as in Example 2.\nEXAMPLE 2  Benford’s Law and Ultrasound Images\nAccording to Benford’s law, a variety of different data sets include numbers with lead-\ning (first) digits that follow the distribution shown in the first two rows of Table 11-4. \nData sets that tend to follow Benford’s law include a class of errors in clinical trials, \nas well as magnitudes of gradients from magnetic resonance imaging (MRI) scans, \ncomputed tomography (CT) scans, and ultrasound images. (A gradient in an image \nis a change in intensity or color along with a direction. The magnitude of a gradient \nincludes only the amount of change without a direction.)\nThe bottom row of Table 11-4 lists the frequencies of leading digits of the mag-\nnitudes of gradients from an ultrasound image. Do the frequencies of leading digits \nin the bottom row appear to fit the distribution of Benford’s law, as expected, or does \nit appear that the image has been corrupted with a substantial amount of “noise” be-\ncause the leading digits do not fit the distribution of Benford’s law? (There are meth-\nods for using Benford’s law to enhance images that have been corrupted with noise.)\nTABLE 11-4 Leading Digits of Magnitudes of Ultrasound Image Gradients\nLeading Digit\n1\n2\n3\n4\n5\n6\n7\n8\n9\nBenford’s Law: Distribution \nof Leading Digits\n \n30.1%\n \n17.6%\n \n12.5%\n \n9.7%\n \n7.9%\n \n6.7%\n \n5.8%\n \n5.1%\n \n4.6%\nLeading Digits of Magni-\ntudes of Gradients in an \nUltrasound Image\n \n \n69\n \n \n40\n \n \n42\n \n \n26\n \n \n25\n \n \n16\n \n \n16\n \n \n17\n \n \n20\nSafest Seats in a \nCommercial Jet\nA study by \naviation writer \nand researcher \nDavid Noland \nshowed that \nsitting farther \nback in a \ncommercial jet will increase your \nchances of surviving in the event \nof a crash. The study suggests \nthat the chance of surviving is \nnot the same for each seat, so a \ngoodness-of-fit test would lead \nto rejection of the null hypothesis \nthat every seat has the same \nprobability of a passenger surviv-\ning. Records from the 20 com-\nmercial jet crashes that occurred \nsince 1971 were analyzed. It was \nfound that if you sit in business \nor first class, you have a 49% \nchance of surviving a crash; if \nyou sit in coach over the wing \nor ahead of the wing, you have \na 56% chance of surviving; and \nif you sit in the back behind the \nwing, you have a 69% chance of \nsurviving.\nIn commenting on this study, \nDavid Noland stated that he does \nnot seek a rear seat when he \nflies. He says that because the \nchance of a crash is so small, \nhe doesn’t worry about where \nhe sits, but he prefers a window \nseat.\n",
    "11-1 Goodness-of-Fit \n509\nSOLUTION\nREQUIREMENT CHECK (1) The sample data are randomly selected from a larger popu-\nlation. (2) The sample data do consist of frequency counts. (3) Each expected fre-\nquency is at least 5. The lowest expected frequency is 271 * 0.046 = 12.466. All \nof the requirements are satisfied. \nStep 1: The original claim is that the leading digits fit the distribution given as  \nBenford’s law. Using subscripts corresponding to the leading digits, we can express \nthis claim as p1 = 0.301 and p2 = 0.176 and p3 = 0.125 and . . . and p9 = 0.046.\nStep 2: If the original claim is false, then at least one of the proportions does not \nhave the value as claimed.\nStep 3: The null hypothesis must contain the condition of equality, so we have\nH0: p1 = 0.301 and p2 = 0.176 and p3 = 0.125 and c and p9 = 0.046.\n  H1: At least one of the proportions is not equal to the given claimed value.\nStep 4: The significance level is not specified, so we use the common choice of \na = 0.05.\nStep 5: Because we are testing a claim that the distribution of leading digits fits  \nthe distribution given by Benford’s law, we use the goodness-of-fit test described \nin this section. The x2 distribution is used with the test statistic given earlier in the \npreceding Key Elements box.\nStep 6: Table 11-5 shows the calculations of the components of the x2 test statistic \nfor the leading digits of 1 and 2. If we include all nine leading digits, we get the test \nstatistic of x2 = 11.2792, as shown in the accompanying TI-84 Plus calculator dis-\nplay. The critical value is x2 = 15.507 (found in Table A-4 with a = 0.05 in the \nright tail and degrees of freedom equal to k - 1 = 8). The TI-84 Plus C calculator \ndisplay shows the value of the test statistic as well as the P-value of 0.186. (The en-\ntire bottom row of the display can be viewed by scrolling to the right. CNTRB is an \nabbreviated form of “contribution,” and the values are the individual contributions \nto the total value of the x2 test statistic.)\nTABLE 11-5 Calculating the x2 Test Statistic for Leading Digits in Table 11-4\n \nLeading Digit\nObserved  \nFrequency O\nExpected Frequency \nE = np\n \nO −E\n \n(O −E)2\n(O −E )2\nE\n1\n69\n271 # 0.301 = 81.5710\n-12.5710\n158.0300\n1.9373\n2\n40\n271 # 0.176 = 47.6960   -7.6960\n  59.2284\n1.2418\nStep 7: The P-value of 0.186 is greater than the significance level of 0.05, so there \nis not sufficient evidence to reject the null hypothesis. (Also, the test statistic of \nx2 = 11.2792 does not fall in the critical region bounded by the critical value of \n15.507, so there is not sufficient evidence to reject the null hypothesis.)\nStep 8: There is not sufficient evidence to warrant rejection of the claim that the \n271 leading digits fit the distribution given by Benford’s law.\nINTERPRETATION\nThe sample of leading digits does not provide enough evidence to conclude that the \nBenford’s law distribution is not being followed. There is not sufficient evidence to \nsupport a conclusion that the ultrasound image has been corrupted with a substantial \namount of “noise.”\nTI-84 Plus C\nu-\nMendel’s Data Falsified?\nBecause some \nof Mendel’s data \nfrom his famous \ngenetics experi-\nments seemed \ntoo perfect to be \ntrue, statistician \nR. A. Fisher concluded that the \ndata were probably falsified. He \nused a chi-square distribution to \nshow that when a test statistic \nis extremely far to the left and \nresults in a P-value very close to \n1, the sample data fit the claimed \ndistribution almost perfectly, and \nthis is evidence that the sample \ndata have not been randomly \nselected. It has been suggested \nthat Mendel’s gardener knew \nwhat results Mendel’s theory \npredicted, and subsequently \nadjusted results to fit that theory.\nIra Pilgrim wrote in The Journal \nof Heredity that this use of the \nchi-square distribution is not \nappropriate. He notes that the \nquestion is not about goodness-\nof-fit with a particular distribution, \nbut whether the data are from \na sample that is truly random. \nPilgrim used the binomial prob-\nability formula to find the prob-\nabilities of the results obtained \nin Mendel’s experiments. Based \non his results, Pilgrim concludes \nthat “there is no reason whatever \nto question Mendel’s honesty.” It \nappears that Mendel’s results are \nnot too good to be true, and they \ncould have been obtained from a \ntruly random process.\n",
    "510 \nCHAPTER 11 Goodness-of-Fit and Contingency Tables\nIn Figure 11-3 we use a green line to graph the expected proportions given by \nBenford’s law (as in Table 11-4) along with a red line for the observed proportions from \nTable 11-4. Figure 11-3 allows us to visualize the “goodness-of-fit” between the distri-\nbution given by Benford’s law and the frequencies that were observed. In Figure 11-3, \nthe green and red lines agree reasonably well, so it appears that the observed data fit the \nexpected values reasonably well.\nRationale for the Test Statistic Examples 1 and 2 show that the x2 test statistic is a \nmeasure of the discrepancy between observed and expected frequencies. Simply sum-\nming the differences O - E between observed and expected values tells us nothing, \nbecause that sum is always 0. Squaring the O - E gives us a better statistic. (The rea-\nsons for squaring the O - E values are essentially the same as the reasons for squar-\ning the x - x values in the formula for standard deviation.) The value of Σ(O - E)2\nmeasures only the magnitude of the differences, but we need to find the magnitude of \nthe differences relative to what was expected. We need a type of average instead of a \ncumulative total. This relative magnitude is found through division by the expected \nfrequencies, as in the test statistic.\nThe theoretical distribution of Σ(O - E)2>E is a discrete distribution because \nthe number of possible values is finite. The distribution can be approximated by a \nchi-square distribution, which is continuous. This approximation is generally con-\nsidered acceptable, provided that all expected values E are at least 5. (There are \nways of circumventing the problem of an expected frequency that is less than 5, \nsuch as combining some categories so that all expected frequencies are at least 5. \nAlso, there are different procedures that can be used when not all expected fre-\nquencies are at least 5.)\nThe number of degrees of freedom reflects the fact that we can freely as-\nsign frequencies to k - 1 categories before the frequency for every category is \ndetermined. (Although we say that we can “freely” assign frequencies to k - 1\ncategories, we cannot have negative frequencies, nor can we have frequencies so \nlarge that their sum exceeds the total of the observed frequencies for all catego-\nries combined.)\nFIGURE 11-3  Observed Proportions and Propor-\ntions Expected with Benford’s Law\nGoodness-of-Fit Test\nAccess tech instructions, videos, and data sets at www.TriolaStats.com\nTECH CENTER \n",
    "11-1 Goodness-of-Fit \n511\nStatistical Literacy and Critical Thinking\n1. Hospital Cybersecurity The table below lists leading digits of 317 inter-arrival Internet \ntraffic times for a hospital computer along with the frequencies of leading digits expected with \nBenford’s law.\na. Identify the notation used for observed and expected values.\nb. Identify the observed and expected values for the leading digit of 2.\nc. Use the results from part (b) to find the contribution to the x2 test statistic from the category \nrepresenting the leading digit of 2.\nLeading Digit\n1\n2\n3\n4\n5\n6\n7\n8\n9\nBenford’s Law\n30.1%\n17.6%\n12.5%\n9.7%\n7.9%\n6.7%\n5.8%\n5.1%\n4.6%\nLeading Digits of  \nInter-Arrival Traffic Times\n \n76\n \n62\n \n29\n \n33\n \n19\n \n27\n \n28\n \n21\n \n22\n2. Hospital Cybersecurity When using the data from Exercise 1 to test for goodness-of-fit \nwith the distribution described by Benford’s law, identify the null and alternative hypotheses.\n3. Hospital Cybersecurity The accompanying Statdisk results shown in the margin are \n obtained from the data given in Exercise 1. What should be concluded when testing the claim \nthat the leading digits have a distribution that fits well with Benford’s law?\n4. Hospital Cybersecurity What do the results from the preceding exercises suggest about the \npossibility that the computer has been hacked? Is there any corrective action that should be taken?\nIn Exercises 5–20, conduct the hypothesis test and provide the test statistic and the P-value, \nand , or critical value, and state the conclusion.\n5. Occupational Injuries Randomly selected non-fatal occupational injuries and illnesses are \ncategorized according to the day of the week that they first occurred, and the results are listed \nbelow (based on data from the Bureau of Labor Statistics). Use a 0.05 significance level to test \nthe claim that such injuries and illnesses occur with equal frequency on the different days of \nthe week.\nDay\nMon.\nTues.\nWed.\nThurs.\nFri.\nNumber\n23\n23\n21\n21\n19\n6. Deaths from Car Crashes Randomly selected deaths from car crashes were obtained, \nand the results are included in the table below (based on data from the Insurance Institute for \nHighway Safety). Use a 0.05 significance level to test the claim that car crash fatalities occur \nwith equal frequency on the different days of the week. How might the results be explained? \nWhy does there appear to be an exceptionally large number of car crash fatalities on Saturday?\nDay\nSun.\nMon.\nTues.\nWed.\nThurs.\nFri.\nSat.\nNumber of Fatalities\n132\n98\n95\n98\n105\n133\n158\n7. Motorcycle Fatalities Randomly selected deaths of motorcycle riders are summarized in \nthe table below (based on data from the Insurance Institute for Highway Safety). Use a 0.05 \nsignificance level to test the claim that such fatalities occur with equal frequency in the differ-\nent months. How might the results be explained?\nMonth\nJan.\nFeb.\nMarch\nApril\nMay\nJune\nJuly\nAug.\nSept.\nOct.\nNov.\nDec.\nNumber\n6\n8\n10\n16\n22\n28\n24\n28\n26\n14\n10\n8\n11-1 Basic Skills and Concepts \n",
    "512 \nCHAPTER 11 Goodness-of-Fit and Contingency Tables\n8. Flat Tire and Missed Class A classic story involves four carpooling students who missed \na test and gave as an excuse a flat tire. On the makeup test, the instructor asked the students to \nidentify the particular tire that went flat. If they really didn’t have a flat tire, would they be able \nto identify the same tire? One of the authors asked 41 other students to identify the tire they \nwould select. The results are listed in the following table (except for one student who selected \nthe spare). Use a 0.05 significance level to test the author’s claim that the results fit a uniform \ndistribution. What does the result suggest about the likelihood of four students identifying the \nsame tire when they really didn’t have a flat?\nTire\nLeft Front\nRight Front\nLeft Rear\nRight Rear\nNumber Selected\n11\n15\n8\n6\n9. Baseball Player Births In his book Outliers, author Malcolm Gladwell argues that more \nbaseball players have birthdates in the months immediately following July 31, because that was \nthe age cutoff date for nonschool baseball leagues. Here is a sample of frequency counts of \nmonths of birthdates of American-born Major League Baseball players starting with January: \n387, 329, 366, 344, 336, 313, 313, 503, 421, 434, 398, 371. Using a 0.05 significance level, is \nthere sufficient evidence to warrant rejection of the claim that American-born Major League \nBaseball players are born in different months with the same frequency? Do the sample values \nappear to support Gladwell’s claim?\n10. Genetics The Advanced Placement Biology class at Mount Pearl Senior High School con-\nducted genetics experiments with fruit flies, and the results in the following table are based on \nthe results that they obtained. Use a 0.05 significance level to test the claim that the observed \nfrequencies agree with the proportions that were expected according to principles of genetics.\n \nCharacteristic\nRed Eye,  \nNormal Wing\nSepia Eye,  \nNormal Wing\nRed Eye,  \nVestigial Wing\nSepia Eye,  \nVestigial Wing\nFrequency\n59\n15\n2\n4\nExpected Proportion\n9>16\n3>16\n3>16\n1>16\n11. Eye Color A researcher has developed a theoretical model for predicting eye color. After \nexamining a random sample of parents, she predicts the eye color of the first child. The table \nbelow lists the eye colors of offspring. On the basis of her theory, she predicted that 87% of the \noffspring would have brown eyes, 8% would have blue eyes, and 5% would have green eyes. \nUse a 0.05 significance level to test the claim that the actual frequencies correspond to her pre-\ndicted distribution.\nBrown Eyes\nBlue Eyes\nGreen Eyes\nFrequency\n132\n17\n0\n12. Genotypes Based on the genotypes of parents, offspring are expected to have genotypes \ndistributed in such a way that 25% have genotypes denoted by AA, 50% have genotypes de-\nnoted by Aa, and 25% have genotypes denoted by aa. When 145 offspring are obtained, it is \nfound that 20 of them have AA genotypes, 90 have Aa genotypes, and 35 have aa genotypes. \nTest the claim that the observed genotype offspring frequencies fit the expected distribution of \n25% for AA, 50% for Aa, and 25% for aa. Use a significance level of 0.05.\n13. Bias in Clinical Trials Researchers investigated the issue of race and equality of access \nto clinical trials. The table on the top of the next page shows the population distribution and \nthe numbers of participants in clinical trials involving lung cancer (based on data from “Par-\nticipation in Cancer Clinical Trials,” by Murthy, Krumholz, and Gross, Journal of the American \nMedical Association, Vol. 291, No. 22). Use a 0.01 significance level to test the claim that the \ndistribution of clinical trial participants fits well with the population distribution. Is there a race>\nethnic group that appears to be very underrepresented?\n",
    "11-1 Goodness-of-Fit \n513\nRace, ethnicity\nWhite  \nnon-Hispanic\n \nHispanic\n \nBlack\nAsian, Pacific \nIslander\nAmerican Indian,\nAlaskan Native\nDistribution of  \nPopulation\n \n75.6%\n \n9.1%\n \n10.8%\n \n3.8%\n \n0.7%\nNumber in Lung  \nCancer Clinical Trials\n \n3855\n \n60\n \n316\n \n54\n \n12\n14. Mendelian Genetics Experiments are conducted with hybrids of two types of peas. If \nthe offspring follow Mendel’s theory of inheritance, the seeds that are produced are yellow \nsmooth, green smooth, yellow wrinkled, and green wrinkled, and they should occur in the ratio \nof 9:3:3:1, respectively. An experiment is designed to test Mendel’s theory, with the result that \nthe offspring seeds consist of 307 that are yellow smooth, 77 that are green smooth, 98 that are \nyellow wrinkled, and 18 that are green wrinkled. Use a 0.05 significance level to test the claim \nthat the results contradict Mendel’s theory.\nBenford’s Law. According to Benford’s law, a variety of different data sets include numbers \nwith leading (first) digits that follow the distribution shown in the table below. In Exercises 15 \nand 16, test for goodness-of-fit with the distribution described by Benford’s law.\nLeading Digit\n1\n2\n3\n4\n5\n6\n7\n8\n9\nBenford’s Law: Distribution \nof Leading Digits\n \n30.1%\n \n17.6%\n \n12.5%\n \n9.7%\n \n7.9%\n \n6.7%\n \n5.8%\n \n5.1%\n \n4.6%\n15. MRI When analyzing the leading digits of the magnitudes of gradients from an MRI (mag-\nnetic resonance image) of a patient, the frequencies were found to be 0, 15, 0, 76, 479, 183, \n8, 23, and 0, and those digits correspond to the leading digits of 1, 2, 3, 4, 5, 6, 7, 8, and 9, \nrespectively. Use a 0.01 significance level to test for goodness-of-fit with Benford’s law. Do \nthe leading digits appear to fit the distribution of Benford’s law, as expected, or does it ap-\npear that the image has been corrupted because the leading digits do not fit the distribution of \nBenford’s law?\n16. CT Scan When analyzing the leading digits of the magnitudes of gradients from a CT im-\nage, the frequencies were found to be 83, 58, 27, 21, 21, 21, 6, 4, 9, and those digits correspond \nto the leading digits of 1, 2, 3, 4, 5, 6, 7, 8, and 9, respectively. Use a 0.01 significance level to \ntest for goodness-of-fit with Benford’s law. Do the leading digits appear to fit the distribution \nof Benford’s law, as expected, or does it appear that the image has been corrupted because the \nleading digits do not fit the distribution of Benford’s law? Does the conclusion change if the \nsignificance level is 0.05?\nExercises 17 and 18 are based on data sets included in Appendix B. The complete data sets \ncan be found at www.TriolaStats.com.\n17. Admissions for Birth Data Set 3 “Births” includes the days of the weeks that prospec-\ntive mothers were admitted to a hospital to give birth. A physician claims that because many \nbirths are induced or involve cesarean section, they are scheduled for days other than Saturday \nor Sunday, so births do not occur on the seven different days of the week with equal frequency. \nUse a 0.01 significance level to test that claim.\n18. Discharges After Birth Data Set 3 “Births” includes the days of the weeks that newborn \nbabies were discharged from the hospital. A hospital administrator claims that such discharges \noccur on the seven different days of the week with equal frequency. Use a 0.01 significance \nlevel to test that claim.\n",
    "514 \nCHAPTER 11 Goodness-of-Fit and Contingency Tables\n11-1 Beyond the Basics \n19. Testing Goodness-of-Fit with a Normal Distribution Refer to Data Set 1 “Body Data” \nin Appendix B for the heights of females.\nHeight (cm)\nLess than 155.45\n155.45 - 162.05\n162.05 - 168.65\nGreater than 168.65\nFrequency\na. Enter the observed frequencies in the table above.\nb. Assuming a normal distribution with mean and standard deviation given by the sample mean \nand standard deviation, use the methods of Chapter 6 to find the probability of a randomly \nselected height belonging to each class.\nc. Using the probabilities found in part (b), find the expected frequency for each category.\nd. Use a 0.01 significance level to test the claim that the heights were randomly selected from \na normally distributed population. Does the goodness-of-fit test suggest that the data are from a \nnormally distributed population?\nKey Concept We now consider methods for analyzing contingency tables (or two-\nway frequency tables), which include frequency counts for categorical data arranged \nin a table with at least two rows and at least two columns. In Part 1 of this section, \nwe present a method for conducting a hypothesis test of the null hypothesis that the \nrow and column variables are independent of each other. This test of independence is \nwidely used in real-world applications. In Part 2, we will consider three variations of \nthe basic method presented in Part 1: (1) test of homogeneity, (2) Fisher’s exact test, \nand (3) McNemar’s test for matched pairs.\nPART 1\n Basic Concepts of Testing for Independence \nIn this section we use standard statistical methods to analyze frequency counts in a \ncontingency table (or two-way frequency table).\n11-2 \nContingency Tables\nDEFINITION\nA contingency table (or two-way frequency table) is a table consisting of frequency \ncounts of categorical data corresponding to two different variables. (One variable is \nused to categorize rows, and a second variable is used to categorize columns.)\nThe word contingent has a few different meanings, one of which refers to a de-\npendence on some other factor. We use the term contingency table because we test for \nindependence between the row and column variables. We first define a test of indepen-\ndence and we provide key elements of the test in the Key Elements box that follows.\nDEFINITION\nIn a test of independence, we test the null hypothesis that in a contingency table, \nthe row and column variables are independent. (That is, there is no dependency \nbetween the row variable and the column variable.)\n",
    "11-2 Contingency Tables \n515\nContingency Table\nObjective\nConduct a hypothesis test of independence between the row variable and column variable in a contingency table.\nNotation\nO represents the observed frequency in a cell of a contingency table.\nE represents the expected frequency in a cell, found by assuming that the row and column variables are independent.\nr represents the number of rows in a contingency table (not including labels or row totals).\nc represents the number of columns in a contingency table (not including labels or columns totals).\nRequirements\n1. The sample data are randomly selected.\n2. The sample data are represented as frequency counts in a two-way table.\n3. For every cell in the contingency table, the expected frequency E is at least 5. (There is no requirement that every  \nobserved frequency must be at least 5.)\nKEY ELEMENTS \nNull and Alternative Hypotheses\nThe null and alternative hypotheses are as follows:\nH0: The row and column variables are independent.\nH1: The row and column variables are dependent.\nTest Statistic for a Test of Independence\nx2 = a\n1O - E2 2\nE\nwhere O is the observed frequency in a cell and E is the \nexpected frequency in a cell that is found by evaluating\nE = 1row total21column total2\n1grand total2\nP-values\nP-values are typically provided by technology, or a range of P-values can be found from Table A-4.\nCritical values\n1. The critical values are found in Table A-4 using\nDegrees of freedom = 1r −12 1c −12\nwhere r is the number of rows and c is the number of columns.\n2. Tests of independence with a contingency table are always right-tailed.\nThe distribution of the test statistic x2 can be approximated by the chi-square \ndistribution, provided that all cells have expected frequencies that are at least 5. \nThe number of degrees of freedom (r - 1)(c - 1) reflects the fact that because \nwe know the total of all frequencies in a contingency table, we can freely assign \nfrequencies to only r - 1 rows and c - 1 columns before the frequency for every \ncell is determined. However, we cannot have negative frequencies or frequencies so \nlarge that any row (or column) sum exceeds the total of the observed frequencies for \nthat row (or column).\n",
    "516 \nCHAPTER 11 Goodness-of-Fit and Contingency Tables\nFinding Expected Values E\nAn individual expected frequency E for a cell can be found by simply multiplying the \ntotal of the row frequencies by the total of the column frequencies, then dividing by \nthe grand total of all frequencies, as shown in Example 1.\nE = 1row total21column total2\n1grand total2\nCompare the observed O\nvalues to the corresponding\nexpected E values.\nOs and Es\nare close\nOs and Es\nare far apart\n“If the P is low,\nindependence\nmust go.”\nFail to reject\nindependence\nReject\nindependence\nSmall x2 value, large P-value\nLarge x2 value, small P-value\nx2 here\nx2 here\nFIGURE 11-4  Relationships Among Key Components in a  \nTest of Independence\nEXAMPLE 1  Finding Expected Frequency\nTable 11-1 from the Chapter Problem (reproduced on the top of the next page) is a \ncontingency table with four rows and two columns. The cells of the table contain \nfrequency counts. The frequency counts are the observed values and the expected \nvalues are shown in parentheses. The row variable identifies the treatment used for \na stress fracture in a foot bone, and the column variable identifies the outcome as \na success or failure (based on data from “Surgery Unfounded for Tarsal Navicular \nStress Fracture,” by Bruce Jancin, Internal Medicine News, Vol. 42, No. 14). Refer \nto Table 11-1 and find the expected frequency for the cell in the first row and first \ncolumn, where the observed frequency is 54.\nObserved and Expected Frequencies The test statistic allows us to measure the \namount of disagreement between the frequencies actually observed and those that \nwe would theoretically expect when the two variables are independent. Large values \nof the x2 test statistic are in the rightmost region of the chi-square distribution, and \nthey reflect significant differences between observed and expected frequencies. As in \nSection 11-1, if observed and expected frequencies are close, the x2 test statistic will \nbe small and the P-value will be large. If observed and expected frequencies are far \napart, the x2 test statistic will be large and the P-value will be small. These relation-\nships are summarized and illustrated in Figure 11-4.\n",
    "11-2 Contingency Tables \n517\nSOLUTION\nTABLE 11-1 Treatments for Stress Fracture in a Foot Bone\nSuccess\nFailure\nSurgery\n54 (E = 47.478)\n12 (E = 18.522)\nWeight-Bearing Cast\n41 (E = 66.182)\n51 (E = 25.818)\nNon–Weight-Bearing Cast for 6 Weeks\n70 (E = 52.514)\n3 (E = 20.486)\nNon–Weight-Bearing Cast for Less Than 6 Weeks\n17 (E = 15.826)\n5 (E = 6.174)\nThe first cell lies in the first row (with a total row frequency of 66) and the first \ncolumn (with total column frequency of 182). The “grand total” is the sum of all fre-\nquencies in the table, which is 253. The expected frequency of the first cell is\nE = 1row total21column total2\n1grand total2\n= 166211822\n253\n= 47.478\nINTERPRETATION\nWe know that the first cell has an observed frequency of O = 54 and an expected \nfrequency of E = 47.478. We can interpret the expected value by stating that if \nwe assume that success is independent of the treatment, then we expect to find that \n47.478 of the subjects would be treated with surgery and that treatment would be \nsuccessful. There is a discrepancy between O = 54 and E = 47.478, and such  \ndiscrepancies are key components of the test statistic that is a collective measure  \nof the overall disagreement between the observed frequencies and the frequencies \nexpected with independence between the row and column variables.\nExample 2 illustrates the procedure for conducting a hypothesis test of independence \nbetween the row and column variables in a contingency table.\nEXAMPLE 2   Does the Choice of Treatment for a Fracture  \nAffect Success?\nUse the data from Table 11-1 with a 0.05 significance level to test the claim that \nsuccess of the treatment is independent of the type of treatment. What does the  \nresult indicate about the increasing trend to use surgery?\nSOLUTION\nREQUIREMENT CHECK (1) On the basis of the study description, we will treat the  \nsubjects as being randomly selected and randomly assigned to the different treat-\nment groups. (2) The results are expressed as frequency counts in Table 11-1.  \n(3) The expected frequencies are all at least 5. (The lowest expected frequency  \nis 6.174.) The requirements are satisfied. \nThe null hypothesis and alternative hypothesis are as follows:\nH0: Success is independent of the treatment.\n H1: Success and the treatment are dependent.\nThe significance level is a = 0.05.\nBecause the data in Table 11-1 are in the form of a contingency table, we use \nthe x2 distribution with this test statistic:\nAlternative to  \nClinical Trials\nRheumatolo-\ngist Jenni-\nfer Frankovich \ndiagnosed a \npatient with \nlupus, but \nshe noticed a \nspecific combination of symp-\ntoms that had led to blood clots \nin the past. Her colleagues at \nthe Stanford Packard Children’s \nHospital recommended that she \nnot treat with anti-clotting drugs, \nso she did research but could \nfind no relevant studies. She then \nretrieved the data from all lupus \npatients treated in the hospital \nover the last five years and used \nbasic statistics to find that her \npatient did have a higher risk \nof blood clots, so she then pro-\nceeded to treat with anti-clotting \ndrugs. A randomized clinical \ntrial with treatment and placebo \ngroups would be better, but such \ntrials are rarely conducted for \nsuch specific complications.\ncontinued\n",
    "518 \nCHAPTER 11 Goodness-of-Fit and Contingency Tables\n x2 = a\n1O - E2 2\nE\n= 154 - 47.4782 2\n47.478\n+ g + 15 - 6.1742 2\n6.174\n = 58.393\nP-Value from Technology If using technology, results typically include the  \nx2 test statistic and the P-value. For example, see the accompanying XLSTAT dis-\nplay showing the test statistic is x2 = 58.393 and the P-value is less than 0.0001.\nP-Value from Table A-4 If using Table A-4 instead of technology, first find the number \nof degrees of freedom: (r - 1)(c - 1) = (4 - 1)(2 - 1) = 3 degrees of freedom. \nBecause the test statistic of x2 = 58.393 exceeds the highest value (12.838) in Table A-4 \nfor the row corresponding to 3 degrees of freedom, we know that P-value 6 0.005.\nBecause the P-value is less than the significance level of 0.05, we reject the null \nhypothesis of independence between success and treatment.\nCritical Value If using the critical value method of hypothesis testing, the critical \nvalue of x2 = 7.815 is found from Table A-4 with a = 0.05 in the right tail and the \nnumber of degrees of freedom given by (r - 1)(c - 1) = (4 - 1)(2 - 1) = 3. \nThe test statistic and critical value are shown in Figure 11-5. Because the test statis-\ntic does fall within the critical region, we reject the null hypothesis of independence \nbetween success and treatment.\nXLSTAT\nCritical\nRegion\n0\nFail to reject\nindependence.\nReject\nindependence.\nTest Statistic:\nx2 5 58.393\nCritical Value:\nx2 5 7.815\nFIGURE 11-5 X2 Test of Independence\nINTERPRETATION\nIt appears that success is dependent on the treatment. Although the results of this \ntest do not tell us which treatment is best, we can calculate from Table 11-1 that \nthe success rates are 81.8%, 44.6%, 95.9%, and 77.3%. This suggests that the best \ntreatment is to use a non–weight-bearing cast for 6 weeks. These results suggest \nthat the increasing use of surgery is a treatment strategy that is not supported by the \nevidence.\n",
    "11-2 Contingency Tables \n519\nRationale for Expected Frequencies E To better understand expected frequen-\ncies, pretend that we know only the row and column totals in Table 11-1. Let’s assume \nthat the row and column variables are independent and that 1 of the 253 study subjects \nis randomly selected. The probability of getting someone counted in the first cell of \nTable 11-1 is found as follows:\nP1surgery2 = 66>253 and P1success2 = 182>253\nIf the row and column variables are independent as we are assuming, we can use the \nmultiplication rule for independent events (see Section 4-2) as follows:\nP1surgery treatment and success2 = 66\n253 # 182\n253 = 0.187661\nWith a probability of 0.187661 for the first cell, we expect that among 253 subjects, \nthere are 253 # 0.187661 = 47.478 subjects in the first cell. If we generalize these \ncalculations, we get the following:\nExpected frequency E = 1grand total2 # 1row total2\n1grand total2 # 1column total2\n1grand total2\nThis expression can be simplified to\nE = 1row total21column total2\n1grand total2\nPART 2\n  Test of Homogeneity, Fisher’s Exact Test, \nand McNemar’s Test for Matched Pairs\nTest of Homogeneity\nIn Part 1 of this section, we focused on the test of independence between the row and \ncolumn variables in a contingency table. In Part 1, the sample data are from one popu-\nlation, and individual sample results are categorized with the row and column vari-\nables. In a chi-square test of homogeneity, we have samples randomly selected from \ndifferent populations, and we want to determine whether those populations have the \nsame proportions of some characteristic being considered. (The word homogeneous \nmeans “having the same quality,” and in this context, we are testing to determine \nwhether the proportions are the same.) Section 9-1 presented a procedure for testing a \nclaim about two populations with categorical data having two possible outcomes, but \na chi-square test of homogeneity allows us to use two or more populations with out-\ncomes from several categories.\nDEFINITION\nA chi-square test of homogeneity is a test of the claim that different populations \nhave the same proportions of some characteristics.\nSampling from Different Populations In a typical test of independence as de-\nscribed in Part 1 of this section, sample subjects are randomly selected from one \npopulation (such as people treated for stress fractures in a foot bone) and values of \ndifferent variables are observed (such as success>failure for people receiving differ-\nent treatments). In a typical chi-square test of homogeneity, subjects are randomly \nselected from the different populations separately.\n",
    "520 \nCHAPTER 11 Goodness-of-Fit and Contingency Tables\nProcedure In conducting a test of homogeneity, we can use the same notation, require-\nments, test statistic, critical value, and procedures given in the Key Elements box from \nPart 1 on page 515 of this section, with this exception: Instead of testing the null hypoth-\nesis of independence between the row and column variables, we test the null hypothesis \nthat the different populations have the same proportion of some characteristic.\nFisher’s Exact Test\nThe procedures for testing hypotheses with contingency tables have the requirement \nthat every cell must have an expected frequency of at least 5. This requirement is neces-\nsary for the x2 distribution to be a suitable approximation to the exact distribution of the \nx2 test statistic. Fisher’s exact test is often used for a 2 * 2 contingency table with one or \nmore expected frequencies that are below 5. Fisher’s exact test provides an exact P-value \nand does not require an approximation technique. Because the calculations are quite com-\nplex, it’s a good idea to use technology when using Fisher’s exact test. Statdisk, Minitab, \nXLSTAT, and StatCrunch all have the ability to perform Fisher’s exact test.\nEXAMPLE 3  Does Yawning Cause Others to Yawn?\nThe MythBusters show on the Discovery Channel tested the theory that when some-\none yawns, others are more likely to yawn. The results are summarized in Table 11-6. \nThe methods of Part 1 in this section should not be used because one of the cells has \nan expected frequency of 4.480, which violates the requirement that every cell must \nhave an expected frequency E of at least 5. Using Fisher’s exact test results in a  \nP-value of 0.513, so there is not sufficient evidence to support the myth that people \nexposed to yawning actually yawn more than those not exposed to yawning. (For  \ntesting the claim of no difference, the P-value is 1.000, indicating that there is not a \nsignificant difference between the two groups.)\nTABLE 11-6 Yawning Theory Experiment\nSubject Exposed to Yawning?\nYes\nNo\nDid Subject Yawn?\nYes\n10\n 4\nNo\n24\n12\nMcNemar’s Test for Matched Pairs\nThe methods in Part 1 of this section are based on independent data. For 2 * 2 ta-\nbles consisting of frequency counts that result from matched pairs, the frequency \ncounts within each matched pair are not independent and, for such cases, we can use \nMcNemar’s test of the null hypothesis that the frequencies from the discordant (different) \ncategories occur in the same proportion.\nTable 11-7 shows a general format for summarizing results from data consisting \nof frequency counts from matched pairs. Table 11-7 refers to two different treatments \n(such as two different eye drop solutions) applied to two different parts of each subject \n(such as left eye and right eye). We should be careful when reading a table such as \nTable 11-7. If a = 100, then 100 subjects were cured with both treatments. If b = 50 \nin Table 11-7, then each of 50 subjects had no cure with treatment X but they were \neach cured with treatment Y. The total number of subjects is a + b + c + d, and \neach of those subjects yields results from each of two parts of a matched pair. Remem-\nber, the entries in Table 11-7 are frequency counts of subjects, not the total number of \nindividual components in the matched pairs. If 500 people have each eye treated with \ntwo different ointments, the value of a + b + c + d is 500 (the number of subjects), \nnot 1000 (the number of treated eyes).\nP\nm\nP\ne\nPolls and Psychologists\nPoll results \ncan be \ndramatically \naffected by \nthe wording of \nquestions. A \nphrase such \nas “over the last few years” is \ninterpreted differently by different \npeople. Over the last few years \n(actually, since 1980), survey \nresearchers and psychologists \nhave been working together to \nimprove surveys by decreasing \nbias and increasing accuracy. In \none case, psychologists studied \nthe finding that 10 to 15 percent \nof those surveyed say they voted \nin the last election when they \ndid not. They experimented with \ntheories of faulty memory, a \ndesire to be viewed as respon-\nsible, and a tendency of those \nwho usually vote to say that they \nvoted in the most recent election, \neven if they did not. Only the last \ntheory was actually found to be \npart of the problem.\n",
    "11-2 Contingency Tables \n521\nTABLE 11-7 2 * 2 Table with Frequency Counts from Matched Pairs\nTreatment X\nCured\nNot Cured\nTreatment Y\nCured\na\nb\nNot Cured\nc\nd\nMcNemar’s test requires that for a table such as Table 11-7, the frequencies are such \nthat b + c Ú 10. The test is a right-tailed chi-square test with the following test statistic:\nx2 = 1 \u001eb - c \u001e - 12 2\nb + c\nP-values are typically provided by software, and critical values can be found in \nTable A-4 using 1 degree of freedom. Caution: When applying McNemar’s test, be \ncareful to use only the two frequency counts from discordant (different) pairs, such as \nthe frequency b in Table 11-7 (with different pairs of cured>not cured) and frequency \nc in Table 11-7 (with different pairs of not cured>cured).\nEXAMPLE 4  Are Hip Protectors Effective?\nA randomized controlled trial was designed to test the effectiveness of hip protectors \nin preventing hip fractures in the elderly. Nursing home residents each wore protec-\ntion on one hip, but not the other. Results are summarized in Table 11-8 (based on \ndata from Journal of the American Medical Association). McNemar’s test can be \nused to test the null hypothesis that the following two proportions are the same:\n \n■The proportion of subjects with no hip fracture on the protected hip and a hip \nfracture on the unprotected hip.\n \n■The proportion of subjects with a hip fracture on the protected hip and no hip \nfracture on the unprotected hip.\nUsing the discordant (different) pairs with the general format from Table 11-7, we \nhave b = 10 and c = 15, so the test statistic is calculated as follows:\nx2 = 1 \u001eb - c \u001e - 12 2\nb + c\n= 1 \u001e10 - 15\u001e - 12 2\n10 + 15\n= 0.640\nWith a 0.05 significance level and degrees of freedom given by df = 1, we refer to \nTable A-4 to find the critical value of x2 = 3.841 for this right-tailed test. The test \nstatistic of x2 = 0.640 does not exceed the critical value of x2 = 3.841, so we fail \nto reject the null hypothesis. (Also, the P-value is 0.424, which is greater than 0.05, \nindicating that we fail to reject the null hypothesis.) The proportion of hip fractures \nwith the protectors worn is not significantly different from the proportion of hip \nfractures without the protectors worn. The hip protectors do not appear to be effec-\ntive in preventing hip fractures.\nTABLE 11-8 Randomized Controlled Trial of Hip Protectors\nNo Hip Protector Worn\nNo Hip Fracture\nHip Fracture\nHip Protector Worn\nNo Hip Fracture\n309\n10\nHip Fracture\n 15\n 2\nContingency Tables\nAccess tech instructions, videos, and data sets at www.TriolaStats.com\nTECH CENTER \n",
    "522 \nCHAPTER 11 Goodness-of-Fit and Contingency Tables\nStatistical Literacy and Critical Thinking\n1. Handedness and Cell Phone Use The accompanying table is from a study conducted \nwith the stated objective of addressing cell phone safety by understanding why we use a partic-\nular ear for cell phone use. (See “Hemispheric Dominance and Cell Phone Use,” by Seidman, \nSiegel, Shah, and Bowyer, JAMA Otolaryngology—Head & Neck Surgery, Vol. 139, No. 5.) \nThe goal was to determine whether the ear choice is associated with auditory or language brain \nhemispheric dominance. Assume that we want to test the claim that handedness and cell phone \near preference are independent of each other.\na. Use the data in the table to find the expected value for the cell that has an observed fre-\nquency of 3. Round the result to three decimal places.\nb. What does the expected value indicate about the requirements for the hypothesis test?\nEar Preference for Cell Phone Use\nRight Ear\nLeft Ear\nNo Preference\nRight-Handed\n436\n166\n40\nLeft-Handed\n 16\n 50\n 3\n2. Hypotheses Refer to the data given in Exercise 1 and assume that the requirements are all \nsatisfied and we want to conduct a hypothesis test of independence using the methods of this \nsection. Identify the null and alternative hypotheses.\n3. Hypothesis Test The accompanying TI-83>84 Plus calculator display results from the \nhypothesis test described in Exercise 1. Assume that the hypothesis test requirements are all \nsatisfied. Identify the test statistic and the P-value (expressed in standard form and rounded to \nthree decimal places), and then state the conclusion about the null hypothesis.\n4. Right-Tailed, Left-Tailed, Two-Tailed Is the hypothesis test described in Exercise 1 \nright-tailed, left-tailed, or two-tailed? Explain your choice.\nIn Exercises 5–20, test the given claim.\n5. Splint or Surgery? A randomized controlled trial was designed to compare the effective-\nness of splinting versus surgery in the treatment of carpal tunnel syndrome. Results are given in \nthe table below (based on data from “Splinting vs. Surgery in the Treatment of Carpal Tunnel \nSyndrome,” by Gerritsen et al., Journal of the American Medical Association, Vol. 288, No. 10). \nThe results are based on evaluations made one year after the treatment. Using a 0.01 signifi-\ncance level, test the claim that success is independent of the type of treatment. What do the \nresults suggest about treating carpal tunnel syndrome?\nSuccessful Treatment\nUnsuccessful Treatment\nSplint Treatment\n60\n23\nSurgery Treatment\n67\n 6\n6. Texting and Drinking In a study of high school students at least 16 years of age, researchers \nobtained survey results summarized in the accompanying table (based on data from “Texting \nWhile Driving and Other Risky Motor Vehicle Behaviors Among U. S. High School Students,” \nby O’Malley, Shults, and Eaton, Pediatrics, Vol. 131, No. 6). Use a 0.05 significance level to test \nthe claim of independence between texting while driving and driving when drinking alcohol. \nAre those two risky behaviors independent of each other?\nDrove When Drinking Alcohol?\nYes\nNo\nTexted While Driving\n731\n3054\nNo Texting While Driving\n156\n4564\n11-2 Basic Skills and Concepts\n",
    "11-2 Contingency Tables \n523\n7. Tooth Fillings and Adverse Health Conditions The table below shows results from a \nstudy in which some dental patients were treated with amalgam restorations and others were \ntreated with composite restorations that do not contain mercury (based on data from “Neuro-\npsychological and Renal Effects of Dental Amalgam in Children,” by Bellinger et al., Journal \nof the American Medical Association, Vol. 295, No. 15). Use a 0.05 significance level to test \nfor independence between the type of restoration and the presence of any adverse health condi-\ntions. Do amalgam restorations appear to affect health conditions?\nAmalgam\nComposite\nAdverse Health Condition Reported\n135\n145\nNo Adverse Health Condition Reported\n132\n122\n8. Tooth Fillings and Sensory Disorders In recent years, concerns have been expressed \nabout adverse health effects from amalgam dental restorations, which include mercury. The \ntable below shows results from a study in which some patients were treated with amalgam \nrestorations and others were treated with composite restorations that do not contain mercury \n(based on data from “Neuropsychological and Renal Effects of Dental Amalgam in Children,” \nby Bellinger et al., Journal of the American Medical Association, Vol. 295, No. 15). Use a 0.05 \nsignificance level to test for independence between the type of restoration and sensory disor-\nders. Do amalgam restorations appear to affect sensory disorders?\nAmalgam\nComposite\nSensory Disorder\n 36\n 28\nNo Sensory Disorder\n231\n239\n9. Can Dogs Detect Cancer? An experiment was conducted to test the ability of dogs to detect \nbladder cancer. Dogs were tested with urine samples from bladder cancer patients and people in \na control group who did not have bladder cancer. Results are given in the table below (based on \ndata from the New York Times). Using a 0.01 significance level, test the claim that the source of \nthe sample (healthy or with bladder cancer) is independent of the dog’s selections. What do the \nresults suggest about the ability of dogs to detect bladder cancer? If the dogs did significantly \nbetter than random guessing, did they do well enough to be used for accurate diagnoses?\nSample from Subject  \nWith Bladder Cancer\nSample from Subject  \nWithout Bladder Cancer\nDog Identified Subject as Cancerous\n22\n 32\nDog Did Not Identify Subject as \nCancerous\n \n32\n \n282\n10. Lie Detector The table below includes results from polygraph (lie detector) experi-\nments conducted by researchers Charles R. Honts (Boise State University) and Gordon H. \nBarland (Department of Defense Polygraph Institute). In each case, it was known if the sub-\nject lied or did not lie, so the table indicates when the polygraph test was correct. Use a 0.05 \nsignificance level to test the claim that whether a subject lies is independent of the poly-\ngraph test indication. Do the results suggest that polygraphs are effective in distinguishing \nbetween truths and lies?\nDid the Subject Actually Lie?\nNo (Did Not Lie)\nYes (Lied)\nPolygraph Test Indicated that \nthe Subject Lied.\n \n15\n \n42\nPolygraph Test Indicated that \nthe Subject Did Not Lie.\n \n32\n \n 9\n11. Clinical Trial of Chantix Chantix (varenicline) is a drug used as an aid for those who want \nto stop smoking. The adverse reaction of nausea has been studied in clinical trials, and the table \nbelow summarizes results (based on data from Pfizer). Use a 0.01 significance level to test the \ncontinued\n",
    "524 \nCHAPTER 11 Goodness-of-Fit and Contingency Tables\nclaim that nausea is independent of whether the subject took a placebo or Chantix. Does nausea \nappear to be a concern for those using Chantix?\nPlacebo\nChantix\nNausea\n 10\n 30\nNo Nausea\n795\n791\n12. Is the Vaccine Effective? In a USA Today article about an experimental vaccine for chil-\ndren, the following statement was presented: “In a trial involving 1602 children, only 14 (1%) \nof the 1070 who received the vaccine developed the flu, compared with 95 (18%) of the 532 \nwho got a placebo.” The data are shown in the table below. Use a 0.05 significance level to \ntest for independence between the variable of treatment (vaccine or placebo) and the variable \nrepresenting flu (developed flu, did not develop flu). Does the vaccine appear to be effective?\nDeveloped Flu?\nYes\nNo\nVaccine Treatment\n14\n1056\nPlacebo\n95\n 437\n13. Texting and Seat Belt Use In a study of high school students at least 16 years of age, \nresearchers obtained survey results summarized in the accompanying table (based on data from \n“Texting While Driving and Other Risky Motor Vehicle Behaviors Among U. S. High School \nStudents,” by O’Malley, Shults, and Eaton, Pediatrics, Vol. 131, No. 6). Use a 0.05 significance \nlevel to test the claim of independence between texting while driving and irregular seat belt \nuse. Are those two risky behaviors independent of each other?\nIrregular Seat Belt Use?\nYes\nNo\nTexted While Driving\n1737\n2048\nNo Texting While Driving\n1945\n2775\n14. Unusual Patient Deaths Alert nurses at the Veteran’s Affairs Medical Center in \nNorthampton, Massachusetts, noticed an unusually high number of deaths at times when an-\nother nurse, Kristen Gilbert, was working. Those same nurses later noticed missing supplies of \nthe drug epinephrine, which is a synthetic adrenaline that stimulates the heart. Kristen Gilbert \nwas arrested and charged with four counts of murder and two counts of attempted murder. \nWhen seeking a grand jury indictment, prosecutors provided a key piece of evidence consisting \nof the table below. Use a 0.01 significance level to test the defense claim that deaths on shifts \nare independent of whether Gilbert was working. What does the result suggest about the guilt \nor innocence of Gilbert?\nShifts With a Death\nShifts Without a Death\nGilbert Was Working\n40\n 217\nGilbert Was Not Working\n34\n1350\n15. Clinical Trial of Campral Campral (acamprosate) is a drug used to help patients continue their \nabstinence from the use of alcohol. Adverse reactions of Campral have been studied in clinical trials, \nand the table below summarizes results for digestive system effects among patients from different \ntreatment groups (based on data from Forest Pharmaceuticals, Inc.). Use a 0.01 significance level \nto test the claim that experiencing an adverse reaction in the digestive system is independent of the \ntreatment group. Does Campral treatment appear to have an effect on the digestive system?\nPlacebo\nCampral 1332 mg\nCampral 1998 mg\nAdverse Effect on Digestive System\n 344\n 89\n 8\nNo Effect on Digestive System\n1362\n774\n71\n",
    "11-2 Contingency Tables \n525\n16. Clinical Trial of Lipitor Lipitor is the trade name of the drug atorvastatin, which is used \nto reduce cholesterol in patients. This is the largest-selling drug in the world, with $13 billion \nin sales for a recent year. Adverse reactions have been studied in clinical trials, and the table \nbelow summarizes results for infections in patients from different treatment groups (based on \ndata from Parke-Davis). Use a 0.05 significance level to test the claim that getting an infection \nis independent of the treatment. Does the atorvastatin treatment appear to have an effect on \ninfections?\nPlacebo\nAtorvastatin 10 mg\nAtorvastatin 40 mg\nAtorvastatin 80 mg\nInfection\n 27\n 89\n 8\n 7\nNo Infection\n243\n774\n71\n87\n17. Is Seat Belt Use Independent of Cigarette Smoking? A study of seat belt users and \nnonusers yielded the randomly selected sample data summarized in the given table (based \non data from “What Kinds of People Do Not Use Seat Belts?” by Helsing and Comstock, \nAmerican Journal of Public Health, Vol. 67, No. 11). Test the claim that the amount of smok-\ning is independent of seat belt use. A plausible theory is that people who smoke more are less \nconcerned about their health and safety and are therefore less inclined to wear seat belts. Is this \ntheory supported by the sample data?\nNumber of Cigarettes Smoked per Day\n0\n1–14\n15–34\n35 and over\nWear Seat Belts\n175\n20\n42\n6\nDon’t Wear Seat Belts\n149\n17\n41\n9\n18. Clinical Trial of Echinacea In a clinical trial of the effectiveness of echinacea for pre-\nventing colds, the results in the table below were obtained (based on data from “An Evalua-\ntion of Echinacea Angustifolia in Experimental Rhinovirus Infections,” by Turner et al., New \nEngland Journal of Medicine, Vol. 353, No. 4). Use a 0.05 significance level to test the claim \nthat getting a cold is independent of the treatment group. What do the results suggest about the \neffectiveness of echinacea as a prevention against colds?\nTreatment Group\nPlacebo\nEchinacea: 20% Extract\nEchinacea: 60% Extract\nGot a Cold\n88\n48\n42\nDid Not Get a Cold\n15\n 4\n10\n19. Injuries and Motorcycle Helmet Color A case-control (or retrospective) study was \nconducted to investigate a relationship between the colors of helmets worn by motorcycle \ndrivers and whether they are injured or killed in a crash. Results are given in the table below \n(based on data from “Motorcycle Rider Conspicuity and Crash Related Injury: Case-Control \nStudy,” by Wells et al., BMJ USA, Vol. 4). Test the claim that injuries are independent of \nhelmet color. Should motorcycle drivers choose helmets with a particular color? If so, which \ncolor appears best?\nColor of Helmet\nBlack\nWhite\nYellow, Orange\nRed\nBlue\nControls (not injured)\n491\n377\n31\n170\n55\nCases (injured or killed)\n213\n112\n 8\n 70\n26\n20. Baseball Player Births In his book Outliers, author Malcolm Gladwell argues that more \nAmerican-born baseball players have birthdates in the months immediately following July \n31 because that was the age cutoff date for nonschool baseball leagues. The table below lists \nmonths of births for a sample of American-born baseball players and foreign-born baseball \nplayers. Using a 0.05 significance level, is there sufficient evidence to warrant rejection of the \ncontinued\n",
    "526 \nCHAPTER 11 Goodness-of-Fit and Contingency Tables\nclaim that months of births of baseball players are independent of whether they are born in \nAmerica? Do the data appear to support Gladwell’s claim?\nJan.\nFeb.\nMarch\nApril\nMay\nJune\nJuly\nAug.\nSept.\nOct.\nNov.\nDec.\nBorn in \nAmerica\n \n387\n \n329\n \n366\n \n344\n \n336\n \n313\n \n313\n \n503\n \n421\n \n434\n \n398\n \n371\nForeign Born\n101\n 82\n 85\n 82\n 94\n 83\n 59\n 91\n 70\n100\n103\n 82\n21. Equivalent Tests A x2 test involving a 2 * 2 table is equivalent to the test for the dif-\nference between two proportions, as described in Section 9-1. Using the claim and table in \nExercise 5 “Splint or Surgery?” verify that the x2 test statistic and the z test statistic (found \nfrom the test of equality of two proportions) are related as follows: z2 = x2. Also show that the \ncritical values have that same relationship.\n22. Using Yates’s Correction for Continuity The chi-square distribution is continuous, \nwhereas the test statistic used in this section is discrete. Some statisticians use Yates’s correc-\ntion for continuity in cells with an expected frequency of less than 10 or in all cells of a contin-\ngency table with two rows and two columns. With Yates’s correction, we replace\na\n1O - E2 2\nE\n with a\n1 \u001dO - E \u001d - 0.52 2\nE\nGiven the contingency table in Exercise 5 “Splint or Surgery?” find the value of the x2 test \nstatistic using Yates’s correction in all cells. What effect does Yates’s correction have?\n11-2 Beyond the Basics\nChapter Quick Quiz\nExercises 1–5 refer to the sample data in the following table, which summarizes the last \ndigits of the heights (cm) of 300 randomly selected subjects (from Data Set 1 “Body Data”). \nAssume that we want to use a 0.05 significance level to test the claim that the data are from \na population having the property that the last digits are all equally likely.\nLast Digit\n 0\n 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\nFrequency\n30\n35\n24\n25\n35\n36\n37\n27\n27\n24\n1. What are the null and alternative hypotheses corresponding to the stated claim?\n2. When testing the claim in Exercise 1, what are the observed and expected frequencies for the \nlast digit of 7?\n3. Is the hypothesis test left-tailed, right-tailed, or two-tailed?\n4. If using a 0.05 significance level to test the stated claim, find the number of degrees of freedom.\n5. Given that the P-value for the hypothesis test is 0.501, what do you conclude? Does it appear \nthat the heights were obtained through measurement or that the subjects reported their heights?\nQuestions 6–10 refer to the sample data in the following table, which describes the fate of \nthe passengers and crew aboard the Titanic when it sank on April 15, 1912. Assume that the \ndata are a sample from a large population and we want to use a 0.05 significance level to test \nthe claim that surviving is independent of whether the person is a man, woman, boy, or girl.\nMen\nWomen\nBoys\nGirls\nSurvived\n 332\n318\n29\n27\nDied\n1360\n104\n35\n18\n",
    "6. Identify the null and alternative hypotheses corresponding to the stated claim.\n7. What distribution is used to test the stated claim (normal, t, F, chi-square, uniform)?\n8. Is the hypothesis test left-tailed, right-tailed, or two-tailed?\n9. Find the number of degrees of freedom.\n10. Given that the P-value for the hypothesis test is 0.0000 when rounded to four decimal \nplaces, what do you conclude? What do the results indicate about the rule that women and chil-\ndren should be the first to be saved?\n1.  Weather-Related Deaths For a recent year, the numbers of weather-related deaths for \neach month are 28, 17, 12, 24, 88, 61, 104, 32, 20, 13, 26, 25 (listed in order beginning with \nJanuary). Use a 0.01 significance level to test the claim that weather-related deaths occur in the \ndifferent months with the same frequency. Provide an explanation for the result.\n2. Norovirus on Cruise Ships The Queen Elizabeth II cruise ship and Royal Caribbean’s \nFreedom of the Seas cruise ship both experienced outbreaks of norovirus infection within two \nmonths of each other. Results are shown in the table below. Use a 0.05 significance level to test \nthe claim that getting norovirus infection is independent of the ship. Based on these results, \ndoes it appear that an outbreak of norovirus infection has the same effect on different ships?\nNorovirus Infection\nNo Norovirus Infection\nQueen Elizabeth II\n276\n1376\nFreedom of the Seas\n338\n3485\n3. NYC Homicides For a recent year, the following are the numbers of homicides that occurred \neach month in New York City, starting with January: 38, 30, 46, 40, 46, 49, 47, 50, 50, 42, 37, \nand 37. Use a 0.05 significance level to test the claim that homicides in New York City are \nequally likely for each of the 12 months. Is there sufficient evidence to support the police com-\nmissioner’s claim that homicides occur more often in the summer when the weather is warmer?\n4.  Genetics and Handedness In a study of left-handedness as a possible inherited trait, \nthe data in the table below were obtained (based on data from “Why Are Some People Left-\nHanded? An Evolutionary Perspective,” by Laurens and Faurie, Philosophical Transactions, \nVol. 364). Use a 0.01 significance level to test the claim that left-handedness is independent of \nparental handedness. What do the results suggest about the inheritability of left-handedness?\nParental Handedness\nOffspring Left-Handed?\nFather, Mother\nYes\nNo\nRight>Right\n5360\n50,928\nRight>Left\n 767\n   2736\nLeft>Right\n 741\n   3667\nLeft>Left\n  94\n    289\n5. Car Crashes and Age Brackets Among drivers who have had a car crash in the last year, \n88 are randomly selected and categorized by age, with the results listed in the accompanying \ntable (based on data from the Insurance Information Institute). If all ages have the same crash \nrate, we would expect (because of the age distribution of licensed drivers) the given categories \nto have 16%, 44%, 27%, and 13% of the subjects, respectively. At the 0.05 significance level, \ntest the claim that the distribution of crashes conforms to the distribution of ages. Does any age \ngroup appear to have a disproportionate number of crashes?\nAge\nUnder 25\n25–44\n45–64\nOver 64\nDrivers\n36\n21\n12\n19\nReview Exercises\nCHAPTER 11 Review Exercises \n527\n",
    "528 \nCHAPTER 11 Goodness-of-Fit and Contingency Tables\n1.  ICU Patients Listed below are the ages of randomly selected patients in intensive care \nunits (ICUs) (based on data from “A Multifaceted Intervention for Quality Improvement in a \nNetwork of Intensive Care Units,” by Scales et al., Journal of the American Medical Association, \nVol. 305, No. 4). Find the mean, median, standard deviation, and variance. Based on the results, \nis an age of 16 years significantly low? Why or why not?\n38 64 35 67 42 29 68 62 74 58\n2. ICU Patients Use the sample of ages from Exercise 1 to construct a 95% confidence in-\nterval estimate of the mean age of the population of ICU patients. Do the confidence interval \nlimits contain the value of 65.0 years that was found from a sample of 9269 ICU patients?\n3. Bicycle Helmets A study was conducted of 531 persons injured in bicycle crashes, and \nrandomly selected sample results are summarized in the accompanying table (based on results \nfrom “A Case-Control Study of the Effectiveness of Bicycle Safety Helmets in Preventing Fa-\ncial Injury,” by Thompson et al., American Journal of Public Health, Vol. 80, No. 12). Use a \n0.05 significance level to test the claim that wearing a helmet has no effect on whether facial \ninjuries are received. Based on these results, does a helmet seem to be effective in helping to \nprevent facial injuries in a crash?\nHelmet Worn\nNo Helmet\nFacial Injuries Received\n30\n182\nAll Injuries Nonfacial\n83\n236\n4. Bicycle Helmets Use the data in the table from Cumulative Review Exercise 3 and assume \nthat random selections are made from the 531 people included in the study.\na. Find the probability that if 1 of the 531 subjects is randomly selected, the result is someone \nwho had only nonfacial injuries or was someone who wore a helmet.\nb. Find the probability that if two different subjects are randomly selected, they are both sub-\njects who wore a helmet.\nc. Find the probability that if a subject is randomly selected, the result is someone who did not \nwear a helmet.\n5. Forward Grip Reach and Ergonomics When designing instrument controls, car dash-\nboards, and aircraft cockpits, we must consider the forward grip reach of women. Women have \nnormally distributed forward grip reaches with a mean of 686 mm and a standard deviation of \n34 mm (based on anthropometric survey data from Gordon, Churchill, et al.).\na. If a car dashboard is positioned so that it can be reached by 95% of women, what is the \nshortest forward grip reach that can access the dashboard?\nb. If a car dashboard is positioned so that it can be reached by women with a grip reach greater \nthan 650 mm, what percentage of women cannot reach the dashboard? Is that percentage too high?\nc. Find the probability that 16 randomly selected women have forward grip reaches with a \nmean greater than 680 mm. Does this result have any effect on the design?\n6. Diastolic BP and Height The table below lists diastolic blood pressure (BP) measurements \n(mm Hg) and height (cm) of randomly selected males from Data Set 1 “Body Data” in Appendix B. \nIdentify the analysis that should be conducted, then conduct that analysis.\nDiastolic BP\n70.0\n58.0\n40.0\n66\n66.0\n82.0\nHeight\n180.4\n166.3\n181.1\n170\n180.8\n174.7\nCumulative Review Exercises\n",
    "Use any software package or calculator capable of generating equally likely random digits be-\ntween 0 and 9 inclusive. Generate 5000 digits and record the results in the accompanying table. \nUse a 0.05 significance level to test the claim that the sample digits come from a population \nwith a uniform distribution with all digits being equally likely. Does the random number gen-\nerator appear to be working as it should?\nDigit\n0\n1\n2\n3\n4\n5\n6\n7\n8\n9\nFrequency\nTechnology Project\nFROM DATA TO DECISION\nCritical Thinking: Determining Whether a  \nVaccine Is Effective\nThe largest public health experiment involved 401,974 chil-\ndren who were randomly assigned to two groups. In one \ngroup, 201,229 children were given a placebo. In the other \ngroup, 200,745 children were treated with the Salk vaccine \ndesigned to prevent polio. Among the children in the placebo \ngroup, 115 developed polio, and among the children in the \nSalk vaccine treatment group, 33 developed polio.\nAnalyzing the Results\na. The experiment was a “double blind” experiment. What \ndoes that mean?\nb. Informally compare the results. Does it appear that the \nSalk vaccine is effective? Why or why not?\nc. Use the methods of Section 9-1 to determine whether there \nis sufficient evidence to support a claim that the Salk vaccine \nis effective. Does it appear that the Salk vaccine is effective? \nWhy or why not?\nd. Use the methods of Section 11-2 to determine whether \nthe treatment (vaccine or placebo) is independent of devel-\noping polio.\ne. Compare the results from parts (c) and (d).\n1.  Out-of-class activity Divide into groups of four or five students. Each group member \nshould survey at least 15 male students and 15 female students at the same college by asking \nthis question: If you were to make up an absence excuse of a flat tire, which tire would you say \nwent flat if the instructor asked? (See Exercise 8 in Section 11-1.) Ask the subject to write the \nresponses on an index card, and also record the gender of the subject and whether the subject \nwrote with the right or left hand. Use the methods of this chapter to analyze the data collected. \nInclude these claims:\n• The four possible choices for a flat tire are selected with equal frequency.\n• The tire identified as being flat is independent of the gender of the subject.\n• The tire identified as being flat is independent of whether the subject is right- or left-handed.\n• Gender is independent of whether the subject is right- or left-handed.\n2.  Out-of-class activity Divide into groups of four or five students. Each group member \nshould select about 15 other students and first ask them to “randomly” select four digits each. \nAfter the four digits have been recorded, ask each subject to write the last four digits of his or \nher Social Security number (for security, write these digits in any order). Take the “random” \nsample results of individual digits and mix them into one big sample, then mix the individual \nSocial Security digits into a second big sample. Using the “random” sample set, test the claim \nCooperative Group Activities\nCHAPTER 11 Cooperative Group Activities \n529\ncontinued\n",
    "530 \nCHAPTER 11 Goodness-of-Fit and Contingency Tables\nthat students select digits randomly. Then use the Social Security digits to test the claim that \nthey come from a population of random digits. Compare the results. Does it appear that stu-\ndents can randomly select digits? Are they likely to select any digits more often than others? \nAre they likely to select any digits less often than others? Do the last digits of Social Security \nnumbers appear to be randomly selected?\n3. In-class activity Divide into groups of three or four students. Each group should be given \na die along with the instruction that it should be tested for “fairness.” Is the die fair or is it \nbiased? Describe the analysis and results.\n4. Out-of-class activity Divide into groups of two or three students. The analysis of last digits \nof data can sometimes reveal whether values are the results of actual measurements or whether \nthey are reported estimates. Find the numbers of active physicians in each state, then analyze \nthe last digits to determine whether those numbers appear to be actual counts or whether they \nappear to be reported estimates.\n5. Out-of-class activity Divide into groups of four or five students. Example 2 in Section 11-1 \nnoted that according to Benford’s law, a variety of different data sets include numbers with \nleading (first) digits that follow the distribution shown in the table below. Collect original data \nand use the methods of Section 11-1 to support or refute the claim that the data conform rea-\nsonably well to Benford’s law. Here are some suggestions: (1) leading digits of the numbers of \nactive physicians in each of the states; (2) leading digits of smartphone passcodes; (3) leading \ndigits of the numbers of Facebook friends.\nLeading Digit\n1\n2\n3\n4\n5\n6\n7\n8\n9\nBenford’s Law\n30.1%\n17.6%\n12.5%\n9.7%\n7.9%\n6.7%\n5.8%\n5.1%\n4.6%\n",
    "531\nAn important environment>health study involved children \nwho lived within 7 km (about 4 miles) of a large ore smelter in \nEl Paso, Texas. A smelter is used to melt the ore in order to \nseparate the metals in it. Because the smelter emitted lead pol-\nlution, there was concern that these children would somehow \nsuffer. The focus of this Chapter Problem is to investigate the \npossible effect of lead exposure on “performance” IQ scores \nas measured by the Wechsler intelligence scale. (A full IQ \nscore is a combination of a performance IQ score and a verbal \nIQ score. The performance test includes components such as \npicture analysis, picture arrangement, and matching patterns.)\nData from the study are included in Data Set 8 “IQ and \nLead” in Appendix B. Based on measured blood lead levels, \nthe children were partitioned into a low lead level group, a \nDoes Exposure to Lead Affect IQ Scores of Children?\nCHAPTER \nPROBLEM\nOne-Way ANOVA\nTwo-Way ANOVA\n12-1\n12-2\n12 \nAnalysis of Variance\n",
    "is somewhat higher than the means of the medium and high \ngroups. The boxplots all overlap, so differences do not appear to \nbe dramatic. But we need more formal methods that allow us to \nrecognize any significant differences. We could use the methods \nof Section 9-2 to compare means from samples collected from \ntwo different populations, but here we need to compare means \nfrom samples collected from three different populations. When \nwe have samples from three or more populations, we can test for \nequality of the population means by using the method of analysis \nof variance, to be introduced in Section 12-1. In Section 12-1, \nwe will use analysis of variance to test the claim that the three \nsamples are from populations with the same mean.\nmedium lead level group, or a high lead level group. (See Data \nSet 8 for the specific blood lead level cutoff values.) The per-\nformance IQ scores are included in Table 12-1 (based on data \nfrom “Neuropsychological Dysfunction in Children with Chronic \nLow-Level Lead Absorption,” by P. J. Landrigan, R. H. Whitworth, \nR. W. Baloh, N. W. Staehling, W. F. Barthel, and B. F. Rosenblum, \nLancet, Vol. 1, Issue 7909).\nBefore jumping into the application of a particular statistical \nmethod, we should first explore the data. Sample statistics are \nincluded in the table below. Also refer to the following boxplots \nof the three sets of performance IQ scores. Informal and sub-\njective comparisons show that the low group has a mean that \nTABLE 12-1  Performance IQ Scores of Children\nLow Blood Lead Level\n  85\n  90\n107\n  85\n100\n  97\n101\n  64\n111\n100\n  76\n136\n100\n  90\n135\n104\n149\n  99\n107\n  99\n113\n104\n101\n111\n118\n  99\n122\n  87\n118\n113\n128\n121\n111\n104\n  51\n100\n113\n  82\n146\n107\n  83\n108\n  93\n114\n113\n  94\n106\n  92\n  79\n129\n114\n  99\n110\n  90\n  85\n  94\n127\n101\n  99\n113\n  80\n115\n  85\n112\n112\n  92\n  97\n  97\n  91\n105\n  84\n  95\n108\n118\n118\n  86\n  89\n100\nMedium Blood Lead Level\n  78\n  97\n107\n  80\n  90\n  83\n101\n121\n108\n100\n110\n111\n  97\n  51\n  94\n  80\n101\n  92\n100\n  77\n108\n  85\nHigh Blood Lead Level\n  93\n100\n  97\n  79\n  97\n  71\n111\n  99\n  85\n  99\n  97\n111\n104\n  93\n  90\n107\n108\n  78\n  95\n  78\n  86\nLow Blood Lead Level\nMedium Blood Lead Level\nHigh Blood Lead Level\nSample Size n\n78\n22\n21\nx\n102.7\n   94.1\n   94.2\ns\n  16.8\n   15.5\n   11.4\nDistribution\nApproximately normal\nApproximately normal\nApproximately normal\n \nOutliers\nPotential low outlier of 51 and high outliers of 146 and \n149, but they are not very far from the other data values.\n \nNone\n \nNone\nMinitab Boxplots of Performance IQ Scores\n532\t\nCHAPTER 12  Analysis of Variance\n",
    "Section 9-2 includes methods for testing equality of means from two independent \npopulations, but this chapter presents a method for testing equality of three or more \npopulation means. Here are the chapter objectives:\nOne-Way ANOVA\n•\t Apply the method of one-way analysis of variance to conduct a hypothesis test of \nequality of three or more population means. The focus of this section is the interpre-\ntation of results from technology.\nTwo-Way ANOVA\n•\t Analyze sample data from populations separated into categories using two charac-\nteristics (or factors), such as gender and eye color.\n•\t Apply the method of two-way analysis of variance to the following: (1) test for an \ninteraction between two factors, (2) test for an effect from the row factor, and (3) test \nfor an effect from the column factor. The focus of this section is the interpretation of \nresults from technology.\n12-1\n12-2\nCHAPTER OBJECTIVES\nKey Concept In this section we introduce the method of one-way analysis of vari-\nance, which is used for tests of hypotheses that three or more populations have means \nthat are all equal, as in H0: m1 = m2 = m3. Because the calculations are very compli-\ncated, we emphasize the interpretation of results obtained by using technology.\nF Distribution\nThe analysis of variance (ANOVA) methods of this chapter require the F distribution, \nwhich was first introduced in Section 9-4. In Section 9-4 we noted that the F distribu-\ntion has the following properties (see Figure 12-1):\nThere is a different F distribution for each different pair of degrees of freedom for \nnumerator and denominator.\n1.\t The F distribution is not symmetric. It is skewed right.\n2.\t Values of a variable with the F distribution cannot be negative.\n3.\t The exact shape of the F distribution depends on the two different degrees \nof freedom.\n\t 12-1\t\nOne-Way ANOVA\n\t\n12-1  One-Way ANOVA\t\n533\n0\nNot symmetric\n(skewed to the right)\nF\nNonnegative \nvalues only\na\nValue of F 5\ns1\n2\n2\ns2\nFIGURE 12-1  F Distribution\n",
    "534\t\nCHAPTER 12  Analysis of Variance\nPART 1\n  Basics of One-Way Analysis of Variance \nWhen testing for equality of three or more population means, use the method of \none-way analysis of variance.\nDEFINITION\nOne-way analysis of variance (ANOVA) is a method of testing the equality of \nthree or more population means by analyzing sample variances. One-way analysis \nof variance is used with data categorized with one factor (or treatment), so there \nis one characteristic used to separate the sample data into the different categories.\nThe term treatment is used because early applications of analysis of variance \ninvolved agricultural experiments in which different plots of farmland were treated \nwith different fertilizers, seed types, insecticides, and so on. Table 12-1 uses the one \n“treatment” (or factor) of blood lead level. That factor has three different categories: \nlow, medium, and high blood lead levels (as defined in Data Set 8 in Appendix B).\nOne-Way Analysis of Variance for Testing Equality of Three or More Population Means\nObjective\nUse samples from three or more different populations to test a claim that the populations all have the same mean.\nRequirements\n1.\t The populations have distributions that are approxi-\nmately normal. (This is a loose requirement, because \nthe method works well unless a population has a dis-\ntribution that is very far from normal. If a population \ndoes have a distribution that is far from normal, use the \nKruskal-Wallis test described in Section 13-5.)\n2.\t The populations have the same variance s2 (or stan-\ndard deviation s). This is a loose requirement, because \nthe method works well unless the population vari-\nances differ by large amounts. Statistician George E. P. \nBox showed that as long as the sample sizes are equal \n(or nearly equal), the largest variance can be up to nine \ntimes the smallest variance and the results of ANOVA \nwill continue to be essentially reliable.\n3.\t The samples are simple random samples of quantitative \ndata.\n4.\t The samples are independent of each other. (The sam-\nples are not matched or paired in any way.)\n5.\t The different samples are from populations that are cat-\negorized in only one way.\nKEY ELEMENTS \nProcedure for Testing H0: M1 = M2 = M3 = P = Mk\n1.\t Use technology to obtain results that include the test \nstatistic and P-value.\n2.\t Identify the P-value from the display. (The ANOVA \ntest is right-tailed because only large values of the test \nstatistic cause us to reject equality of the population \nmeans.)\n3.\t Form a conclusion based on these criteria that use the \nsignificance level a:\n\t •\t Reject: If the P-value … a, reject the null hypoth-\nesis of equal means and conclude that at least one of \nthe population means is different from the others.\n\t •\t Fail to Reject: If the P-value 7 a, fail to reject the \nnull hypothesis of equal means.\n",
    "\t\n12-1  One-Way ANOVA\t\n535\nBecause the calculations required for one-way analysis of variance are messy, we \nrecommend using technology with this study strategy:\n1.\t Understand that a small P-value (such as 0.05 or less) leads to rejection of the \nnull hypothesis of equal means. (“If the P is low, the null must go.”) With a \nlarge P-value (such as greater than 0.05), fail to reject the null hypothesis of \nequal means.\n2.\t Develop an understanding of the underlying rationale by studying the  \nexamples in this section.\nEXAMPLE 1   Lead and Performance IQ Scores\nUse the performance IQ scores listed in Table 12-1 and a significance level of \na = 0.05 to test the claim that the three samples come from populations with \nmeans that are all equal.\nSOLUTION\nREQUIREMENT CHECK  (1) Based on the three samples listed in Table 12-1, the three \npopulations appear to have distributions that are approximately normal, as indicated \nby normal quantile plots. (2) The three samples in Table 12-1 have standard devia-\ntions that are not dramatically different, so the three population variances appear to \nbe about the same. (3) On the basis of the study design, we can treat the samples as \nsimple random samples. (4) The samples are independent of each other; the perfor-\nmance IQ scores are not matched in any way. (5) The three samples are from popu-\nlations categorized according to the single factor of lead level (low, medium, high). \nThe requirements are satisfied. \nThe null hypothesis and the alternative hypothesis are as follows:\nH0: m1 = m2 = m3\nH1: At least one of the means is different from the others\nThe significance level is a = 0.05.\nStep 1: Use technology to obtain ANOVA results, such as one of those shown in \nthe following seven displays.\nStatdisk\nMinitab\ncontinued\nTI-83, 84 Plus\n",
    "536\t\nCHAPTER 12  Analysis of Variance\nHow Is the P-Value Related to the Test Statistic?  Larger values of the test sta-\ntistic result in smaller P-values, so the ANOVA test is right-tailed. Figure 12-2 shows \nthe relationship between the F test statistic and the P-value. Assuming that the popula-\ntions have the same variance s2 (as required for the test), the F test statistic is the ratio \nof these two estimates of s2: (1) variation between samples (based on variation among \nsample means); and (2) variation within samples (based on the sample variances).\nStep 2: In addition to the test statistic of F = 4.0711, the displays all show that the \nP-value is 0.020 when rounded.\nStep 3: Because the P-value of 0.020 is less than the significance level of a = 0.05, \nwe reject the null hypothesis of equal means. (If the P is low, the null must go.)\nINTERPRETATION\nThere is sufficient evidence to warrant rejection of the claim that the three samples \ncome from populations with means that are all equal. Using the samples of mea-\nsurements listed in Table 12-1, we conclude that those values come from popula-\ntions having means that are not all the same. On the basis of this ANOVA test, we \ncannot conclude that any particular mean is different from the others, but we can \ninformally note that the sample mean for the low blood lead group is higher than \nthe means for the medium and high blood lead groups. It appears that greater blood \nlead levels are associated with lower performance IQ scores.\nExcel\nStatCrunch\nSPSS\nJMP\nCAUTION  When we conclude that there is sufficient evidence to reject the claim of \nequal population means, we cannot conclude from ANOVA that any particular mean \nis different from the others. (There are several other methods that can be used to \nidentify the specific means that are different, and some of them are discussed in \nPart 2 of this section.)\nWhy 0.05?\nIn 1925,  \nR. A. Fisher \npublished \na book that \nintroduced \nthe method \nof analysis of \nvariance, and he needed a table \nof critical values based on nu-\nmerator degrees of freedom and \ndenominator degrees of freedom, \nas in Table A-5 in Appendix A. \nBecause the table uses two dif-\nferent degrees of freedom, it be-\ncomes very long if many different \ncritical values are used, so Fisher \nincluded a table using 0.05 only. \nIn a later edition he also included \nthe significance level of 0.01.\nStephen Stigler, a notable \nhistorian of statistics, wrote in \nChance magazine that the choice \nof a significance level of 0.05 is \na convenient round number that \nis somewhat arbitrary. Although \nit is arbitrary, the choice of 0.05 \naccomplishes the following \nimportant goals. (1) The value of \na 0.05 significance level results in \nsample sizes that are reasonable \nand not too large. (2) The choice \nof 0.05 is large enough to give us \na reasonable chance of identify-\ning important effects (by correctly \nrejecting a null hypothesis of no \neffect when there really is an ef-\nfect). (3) The choice of 0.05 is not \nso small that it forces us to miss \nimportant effects (by making the \nmistake of failing to reject a null \nhypothesis of no effect when \nthere really is an effect).\nTable A-5  F Distribution (a  =  0\n1\n2\n1 \n647.79 \n799.50\n2 \n38.506 \n39.00\n3 \n17.443 \n16.04\n4 \n12.218 \n10.6\n0 007\n8.4\n",
    "\t\n12-1  One-Way ANOVA\t\n537\nTest Statistic for One-Way ANOVA\nF = variance between samples\nvariance within samples\nThe numerator of the F test statistic measures variation between sample means. The \nestimate of variance in the denominator depends only on the sample variances and is \nnot affected by differences among the sample means. Consequently, sample means \nthat are close in value to each other result in a small F test statistic and a large P-value, \nso we conclude that there are no significant differences among the sample means. \nSample means that are very far apart in value result in a large F test statistic and a \nsmall P-value, so we reject the claim of equal means.\nWhy Not Just Test Two Samples at a Time?  If we want to test for equality among three \nor more population means, why do we need a new procedure when we can test for equality \nof two means using the methods presented in Section 9-2? For example, if we want to use the \nsample data from Table 12-1 to test the claim that the three populations have the same mean, \nwhy not simply pair them off and test two at a time by testing H0: m1 = m2, H0: m2 = m3, \nand H0: m1 = m3? For the data in Table 12-1, the approach of testing equality of two means \nat a time requires three different hypothesis tests. If we use a 0.05 significance level for each \nof those three hypothesis tests, the actual overall confidence level could be as low as 0.953 (or \n0.857). In general, as we increase the number of individual tests of significance, we increase \nthe risk of finding a difference by chance alone (instead of a real difference in the means). \nThe risk of a type I error—finding a difference in one of the pairs when no such difference \nactually exists—is far too high. The method of analysis of variance helps us avoid that par-\nticular pitfall (rejecting a true null hypothesis) by using one test for equality of several means, \ninstead of several tests that each compare two means at a time.\nSample means\nare all close\nAt least one sample\nmean is very diﬀerent\nFail to reject equality of\npopulation means\nReject equality of\npopulation means\nSmall F test statistic,\nlarge P-value\nLarge F test statistic,\nsmall P-value\nF here\nF here\nFIGURE 12-2  \u0007Relationship Between the F Test Statistic  \nand the P-Value\nCAUTION  When testing for equality of three or more populations, use analysis \nof variance. (Using multiple hypothesis tests with two samples at a time could \nadversely affect the confidence level.)\nPART 2   \u0007Calculations and Identifying Means  \nThat Are Different \nCalculating the Test Statistic F with Equal Sample Sizes n\nTable 12-2 on the next page can be very helpful in understanding the methods of \nANOVA. In Table 12-2, compare Data Set A to Data Set B to see that Data Set A is \n",
    "538\t\nCHAPTER 12  Analysis of Variance\nTABLE 12-2  Effect of a Mean on the F Test Statistic\nData Set A\nData Set B\nSample 1\nSample 2\nSample 3\nSample 1\nSample 2\nSample 3\n7\n6\n4\n17\n6\n4\n3\n5\n7\n13\n5\n7\n6\n5\n6\n16\n5\n6\n6\n8\n7\n16\n8\n7\nn1 = 4\nn2 = 4\nn3 = 4\nn1 = 4\nn2 = 4\nn3 = 4\n   x1 = 5.5\n   x2 = 6.0\n   x3 = 6.0\n     x1 = 15.5\n   x2 = 6.0\n   x3 = 6.0\n   s2\n1 = 3.0\n   s2\n2 = 2.0\n   s2\n3 = 2.0\n   s2\n1 = 3.0\n   s2\n2 = 2.0\n   s2\n3 = 2.0\nData Set A\nData Set B\nStep 1: Variance \nbetween samples\nnsx\n2 = 4(0.0833) = 0.3332\nnsx\n2 = 4(30.0833) = 120.3332\nStep 2: Variance \nwithin samples\ns 2\np = 3.0 + 2.0 + 2.0\n3\n= 2.3333\ns2\np = 3.0 + 2.0 + 2.0\n3\n= 2.3333\nStep 3:  \nF test statistic\nF = nsx\n2\ns 2\np\n= 0.3332\n2.3333 = 0.1428\nF = nsx\n2\ns 2\np\n= 120.3332\n2.3333\n= 51.5721\nP-value\nP-value = 0.8688\nP-value = 0.0000118\nAdd 10 to data in Sample 1\nthe same as Data Set B with this notable exception: The Sample 1 values each differ \nby 10. If the data sets all have the same sample size (as in n = 4 for Table 12-2), the \nfollowing calculations aren’t too difficult, as shown here.\nStep 1: Find the Variance Between Samples\nCalculate the variance between samples by evaluating ns2\nx where s2\nx is the variance of \nthe sample means and n is the size of each of the samples. That is, consider the sample \nmeans to be an ordinary set of values and calculate the variance. (From the central \nlimit theorem, sx = s> 1n can be solved for s to get s = 1n # sx, so that we can \nestimate s2 with ns2\nx.) For example, the sample means for Data Set A in Table 12-2 \nare 5.5, 6.0, and 6.0, and these three values have a variance of s2\nx = 0.0833, so that\nvariance between samples = ns2\nx = 410.08332 = 0.3332\nStep 2: Find the Variance Within Samples\nEstimate the variance within samples by calculating s2\np, which is the pooled vari-\nance obtained by finding the mean of the sample variances. The sample variances in \nTable 12-2 are 3.0, 2.0, and 2.0, so that\nvariance within samples = s2\np = 3.0 + 2.0 + 2.0\n3\n= 2.3333\nStep 3: Calculate the Test Statistic \nEvaluate the F test statistic as follows:\nF = variance between samples\nvariance within samples\n= ns2\nx\ns2\np\n= 0.3332\n2.3333 = 0.1428\n",
    "\t\n12-1  One-Way ANOVA\t\n539\nFinding the Critical Value\nThe critical value of F is found by assuming a right-tailed test because large values of \nF correspond to significant differences among means. With k samples each having n \nvalues, the numbers of degrees of freedom are as follows.\nDegrees of Freedom 1using k = number of samples and n = sample size2\nNumerator degrees of freedom = k - 1\nDenominator degrees of freedom = k1n - 12\nFor Data Set A in Table 12-2, k = 3 and n = 4, so the degrees of freedom are 2 for \nthe numerator and 314 - 12 = 9 for the denominator. With a = 0.05, 2 degrees of \nfreedom for the numerator, and 9 degrees of freedom for the denominator, the criti-\ncal F value from Table A-5 is 4.2565. If we were to use the critical value method of \nhypothesis testing with Data Set A in Table 12-2, we would see that this right-tailed \ntest has a test statistic of F = 0.1428 and a critical value of F = 4.2565, so the test \nstatistic is not in the critical region. We therefore fail to reject the null hypothesis of \nequal means.\nUnderstanding the Effect of a Mean on the F Test Statistic  To really under-\nstand how the method of analysis of variance works, consider Data Set A and Data Set \nB in Table 12-2 and note the following.\n■\n■The three samples in Data Set A are identical to the three samples in Data Set B, \nexcept for this: Each value in Sample 1 of Data Set B is 10 more than the corre-\nsponding value in Data Set A.\n■\n■Adding 10 to each data value in the first sample of Data Set A has a significant \neffect on the test statistic, with F changing from 0.1428 to 51.5721.\n■\n■Adding 10 to each data value in the first sample of Data Set A has a dramatic \neffect on the P-value, which changes from 0.8688 (not significant) to 0.0000118 \n(significant).\n■\n■The three sample means in Data Set A (5.5, 6.0, 6.0) are very close, but the \nsample means in Data Set B (15.5, 6.0, 6.0) are not close.\n■\n■The three sample variances in Data Set A are identical to those in Data Set B.\n■\n■The variance between samples in Data Set A is 0.3332, but for Data Set B it is \n120.3332 (indicating that the sample means in B are farther apart).\n■\n■The variance within samples is 2.3333 in both Data Set A and Data Set B, be-\ncause the variance within a sample isn’t affected when we add a constant to every \nsample value. The change in the F test statistic and the P-value is attributable \nonly to the change in x1. This illustrates the key point underlying the method of \none-way analysis of variance:\nThe F test statistic is very sensitive to sample means, even though it is \nobtained through two different estimates of the common population \nvariance.\nCalculations with Unequal Sample Sizes\nWhile the calculations for cases with equal sample sizes are somewhat reasonable, \nthey become much more complicated when the sample sizes are not all the same, but \nthe same basic reasoning applies. Instead of providing the relevant messy formulas \nrequired for cases with unequal sample sizes, we wisely and conveniently assume that \n",
    "540\t\nCHAPTER 12  Analysis of Variance\ntechnology should be used to obtain the P-value for the analysis of variance. We be-\ncome unencumbered by complex computations and we can focus on checking require-\nments and interpreting results.\nWe calculate an F test statistic that is the ratio of two different estimates of the \ncommon population variance s2. With unequal sample sizes, we must use weighted \nmeasures that take the sample sizes into account. The test statistic is essentially the \nsame as the one given earlier, and its interpretation is also the same as described earlier.\nDesigning Experiments\nWith one-way (or single-factor) analysis of variance, we use one factor as the basis \nfor partitioning the data into different categories. If we conclude that the differences \namong the means are significant, we can’t be absolutely sure that the differences can \nbe explained by the factor being used. It is possible that the variation of some other \nunknown factor is responsible. One way to reduce the effect of the extraneous fac-\ntors is to design the experiment so that it has a completely randomized design, in \nwhich each sample value is given the same chance of belonging to the different factor \ngroups. For example, you might assign subjects to two different treatment groups and \na third placebo group through a process of random selection equivalent to picking \nslips of paper from a bowl. Another way to reduce the effect of extraneous factors is \nto use a rigorously controlled design, in which sample values are carefully chosen \nso that all other factors have no variability. In general, good results require that the \nexperiment be carefully designed and executed.\nIdentifying Which Means Are Different\nAfter conducting an analysis of variance test, we might conclude that there is suf-\nficient evidence to reject a claim of equal population means, but we cannot conclude \nfrom ANOVA that any particular means are different from the others. There are sev-\neral formal and informal procedures that can be used to identify the specific means \nthat are different. Here are two informal methods for comparing means:\n■\n■Construct boxplots of the different samples and examine any overlap to see if one \nor more of the boxplots is very different from the others.\n■\n■Construct confidence interval estimates of the means for each of the different \nsamples, then compare those confidence intervals to see if one or more of them \ndoes not overlap with the others.\nThere are several formal procedures for identifying which means are different. \nSome of the tests, called range tests, allow us to identify subsets of means that are not \nsignificantly different from each other. Other tests, called multiple comparison tests, \nuse pairs of means, but they make adjustments to overcome the problem of having a \nconfidence level that increases as the number of individual tests increases. There is no \nconsensus on which test is best, but some of the more common tests are the Duncan \ntest, Student-Newman-Keuls test (or SNK test), Tukey test (or Tukey honestly signifi-\ncant difference test), Scheffé test, Dunnett test, least significant difference test, and the \nBonferroni test. Let’s consider the Bonferroni test to see one example of a multiple \ncomparison test. Here is the procedure.\nBonferroni Multiple Comparison Test\nStep 1:\t \u0007Do a separate t test for each pair of samples, but make the adjustments de-\nscribed in the following steps.\n",
    "\t\n12-1  One-Way ANOVA\t\n541\nStep 2:\t \u0007For an estimate of the variance s2 that is common to all of the involved \npopulations, use the value of MS(error), which uses all of the available \nsample data. The value of MS(error) is typically obtained when conducting \nthe analysis of variance test. Using the value of MS(error), calculate the \nvalue of the test statistic t, as shown below. The particular test statistic cal-\nculated below is based on the choice of Sample 1 and Sample 2; change the \nsubscripts and use another pair of samples until all of the different possible \npairs of samples have been tested.\nt =\nx1 - x2\nBMS1error2 # a 1\nn1\n+ 1\nn2\nb\nStep 3:\t \u0007After calculating the value of the test statistic t for a particular pair of sam-\nples, find either the critical t value or the P-value, but make the following \nadjustment so that the overall significance level does not increase.\n\t\n\u0007P-Value: Use the test statistic t with df = N - k, where N is the total \nnumber of sample values and k is the number of samples, and find the  \nP-value using technology or Table A-3, but adjust the P-value by multiply-\ning it by the number of different possible pairings of two samples. (For \nexample, with three samples, there are three different possible pairings, so \nadjust the P-value by multiplying it by 3.)\n\t\n\u0007Critical Value: When finding the critical value, adjust the significance \nlevel a by dividing it by the number of different possible pairings of two \nsamples. (For example, with three samples, there are three different  \npossible pairings, so adjust the significance level by dividing it by 3.)\nNote that in Step 3 of the preceding Bonferroni procedure, either an individual test is \nconducted with a much lower significance level or the P-value is greatly increased. \nRejection of equality of means therefore requires differences that are much farther \napart. This adjustment in Step 3 compensates for the fact that we are doing several \ntests instead of only one test.\nEXAMPLE 2   Bonferroni Test\nExample 1 in this section used analysis of variance with the sample data in Table 12-1. \nWe concluded that there is sufficient evidence to warrant rejection of the claim \nof equal means. Use the Bonferroni test with a 0.05 significance level to identify \nwhich mean is different from the others.\nSOLUTION  \nThe Bonferroni test requires a separate t test for each of three different possible pair \nof samples. Here are the null hypotheses to be tested:\nH0\n : m1 = m2  H0\n : m1 = m3  H0\n : m2 = m3\nWe begin with H0: m1 = m2. Using the sample data given in Table 12-1 and \ncarrying some extra decimal places for greater accuracy in the calculations, we have \nn1 = 78 and x1 = 102.705128. Also, n2 = 22 and x2 = 94.136364. From the tech-\nnology results shown in Example 1 we also know that MS(error) = 248.424127.\ncontinued\n",
    "542\t\nCHAPTER 12  Analysis of Variance\nWe now evaluate the test statistic using the unrounded sample means:\n t =\nx1 - x2\nBMS1error2 #  a 1\nn1\n+ 1\nn2\nb\n =\n102.705128 - 94.136364\nB248.424127 #  a 1\n78 + 1\n22b\n= 2.252\nThe number of degrees of freedom is df = N - k = 121 - 3 = 118. (N = 121 \nbecause there are 121 different sample values in all three samples combined, and \nk = 3 because there are three different samples.) With a test statistic of t = 2.252 \nand with df = 118, the two-tailed P-value is 0.026172, but we adjust this P-value \nby multiplying it by 3 (the number of different possible pairs of samples) to get a \nfinal P-value of 0.078516, or 0.079 when rounded. Because this P-value is not small \n(less than 0.05), we fail to reject the null hypothesis. It appears that Samples 1 and 2 \ndo not have significantly different means.\nInstead of continuing with separate hypothesis tests for the other two pairings, see \nthe SPSS display showing all of the Bonferroni test results. In these results, low lead \nlevels are represented by 1, medium levels are represented by 2, and high levels are \nrepresented by 3. (The first row of numerical results corresponds to the results found \nhere; see the value of 0.079, which was previously calculated.) The display shows that \nthe pairing of low>high yields a P-value of 0.090, so there is not a significant differ-\nence between the means from the low and high blood lead levels. Also, the SPSS dis-\nplay shows that the pairing of medium>high yields a P-value of 1.000, so there is not a \nsignificant difference between the means from the medium and high blood lead levels.\nSPSS Bonferroni Results\nINTERPRETATION  \nAlthough the analysis of variance test tells us that at least one of the means is different \nfrom the others, the Bonferroni test results do not identify any one particular sample \nmean that is significantly different from the others. In the original article discussing \nthese results, the authors state that “our findings indicate that a chronic absorption of \nparticulate lead . . . may result in subtle but statistically significant impairment in the \nnon-verbal cognitive and perceptual motor skills measured by the performance scale of \nthe Wechsler intelligence tests.” That statement confirms these results: From analysis of \nvariance we know that at least one mean is different from the others, but the Bonferroni \ntest failed to identify any one particular mean as being significantly different [although \nthe sample means of 102.7 (low blood lead level), 94.1 (medium blood lead level), and \n94.2 (high blood lead level) suggest that medium and high blood lead levels seem to be \nassociated with lower mean performance IQ scores than the low blood level group].\n",
    "\t\n12-1  One-Way ANOVA\t\n543\nStatistical Literacy and Critical Thinking \nIn Exercises 1–4, use the following listed chest deceleration measurements (in g, where g \nis the force of gravity) from samples of small, midsize, and large cars. (The data are from \nthe National Highway Traffic Safety Administration.) Also shown are the SPSS results for \nanalysis of variance. Assume that we plan to use a 0.05 significance level to test the claim \nthat the different size categories have the same mean chest deceleration in the standard \ncrash test.\n12-1  Basic Skills and Concepts\nChest Deceleration Measurements (g) from a Standard Crash Test\nSmall\n44\n39\n37\n54\n39\n44\n42\nMidsize\n36\n53\n43\n42\n52\n49\n41\nLarge\n32\n45\n41\n38\n37\n38\n33\nSPSS\n1. ANOVA\na. What characteristic of the data above indicates that we should use one-way analysis of variance?\nb. If the objective is to test the claim that the three size categories have the same mean chest \ndeceleration, why is the method referred to as analysis of variance?\n2. Why Not Test Two at a Time? Refer to the sample data given in Exercise 1. If we want \nto test for equality of the three means, why don’t we use three separate hypothesis tests for \nm1 = m2, m1 = m3, and m2 = m3?\n3. Test Statistic What is the value of the test statistic? What distribution is used with the test \nstatistic?\n4. P-Value If we use a 0.05 significance level in analysis of variance with the sample data \ngiven in Exercise 1, what is the P-value? What should we conclude?\nIn Exercises 5–16, use analysis of variance for the indicated test.\n5. Lead and Verbal IQ Scores Example 1 used measured performance IQ scores for three \ndifferent blood lead levels. If we use the same three categories of blood lead levels with mea-\nsured verbal IQ scores, we get the accompanying Minitab display. (The data are listed in Data \nSet 8 “IQ and Lead” in Appendix B.) Using a 0.05 significance level, test the claim that the \nthree categories of blood lead level have the same mean verbal IQ score. Does exposure to lead \nappear to have an effect on verbal IQ scores?\nMinitab\nOne-Way Analysis of Variance\nAccess tech instructions, videos, and data sets at www.TriolaStats.com\nTECH CENTER \n",
    "544\t\nCHAPTER 12  Analysis of Variance\n6. Lead and Full IQ Scores Example 1 used measured performance IQ scores for three dif-\nferent blood lead levels. If we use the same three categories of blood lead levels with the full IQ \nscores, we get the accompanying Excel display. Using a 0.05 significance level, test the claim \nthat the three categories of blood lead level have the same mean full IQ score. Does it appear \nthat exposure to lead has an effect on full IQ scores?\nExcel\n7. Head Injury Crash Test Data Exercises 1–4 use chest deceleration data for three different \nsize categories (small, midsize, large). If we use the head injury measurements (in HIC, which \nis a standard head injury criterion) with the same three size categories, we get the SPSS results \nshown here. Using a 0.05 significance level, test the claim that the three size categories have \nthe same mean head injury measurement. Does the size of a car appear to affect head injuries?\nSPSS\n8. Birth Weights Data Set 3 “Births” lists birth weights from babies born at four different hospi-\ntals. After partitioning the birth weights according to the hospital, we get the StatCrunch display \nshown here. Use a 0.05 significance level to test the claim that the different hospitals have the same \nmean birth weights. Do birth weights appear to be the same at these four hospitals?\nStatCrunch\n9. Male Pulse Rates and Age Using the pulse rates of males from Data Set 1 “Body Data” in \nAppendix B after they are partitioned into the three age brackets of 18–25, 26–40, and 41–80, \nwe get the following SPSS display. Using a 0.05 significance level, test the claim that males \nfrom the three age brackets have the same mean pulse rate. What do you conclude?\n10. Female Pulse Rates and Age Using the pulse rates of females from Data Set 1 “Body \nData” in Appendix B after they are partitioned into the three age brackets of 18–25, 26–40, and \n41–80, we get the following Statdisk display. Using a 0.05 significance level, test the claim that \nfemales from the three age brackets have the same mean pulse rate. What do you conclude?\nStatdisk\n",
    "\t\n12-1  One-Way ANOVA\t\n545\n11. Pelvis Injury Crash Test Data Exercises 1–4 use chest deceleration data for three differ-\nent size categories (small, midsize, large). If we use the pelvis injury measurements (g) with \nthe same three size categories, we get the XLSTAT results shown here. Using a 0.05 signifi-\ncance level, test the claim that the three size categories have the same mean pelvis injury mea-\nsurement. Does the size of a car appear to affect pelvis injuries?\nXLSTAT\n12. Arsenic in Rice Listed below are amounts of arsenic in samples of brown rice from three \ndifferent states. The amounts are in micrograms of arsenic and all samples have the same serv-\ning size. The data are from the Food and Drug Administration. Use a 0.05 significance level to \ntest the claim that the three samples are from populations with the same mean. Do the amounts \nof arsenic appear to be different in the different states? Given that the amounts of arsenic in the \nsamples from Texas have the highest mean, can we conclude that brown rice from Texas poses \nthe greatest health problem?\nArkansas\n4.8\n4.9\n5.0\n5.4\n5.4\n5.4\n5.6\n5.6\n5.6\n5.9\n6.0\n6.1\nCalifornia\n1.5\n3.7\n4.0\n4.5\n4.9\n5.1\n5.3\n5.4\n5.4\n5.5\n5.6\n5.6\nTexas\n5.6\n5.8\n6.6\n6.9\n6.9\n6.9\n7.1\n7.3\n7.5\n7.6\n7.7\n7.7\n13. Poplar Tree Weights Weights (kg) of poplar trees were obtained from trees planted in a \nrich and moist region. The trees were given different treatments identified in the table below. \n(The data are from Data Set 18 in Appendix B, and they were obtained from a study conducted \nby researchers at Pennsylvania State University and were provided by Minitab, Inc.) Use a 0.05 \nsignificance level to test the claim that the four treatment categories yield poplar trees with the \nsame mean weight. Is there a treatment that appears to be most effective?\nNo Treatment\nFertilizer\nIrrigation\nFertilizer and Irrigation\n1.21\n0.94\n0.07\n0.85\n0.57\n0.87\n0.66\n1.78\n0.56\n0.46\n0.10\n1.47\n0.13\n0.58\n0.82\n2.25\n1.30\n1.03\n0.94\n1.64\n14. Poplar Tree Weights Weights (kg) of poplar trees were obtained from trees planted in a \nsandy and dry region. The trees were given different treatments identified in the table below. (The \ndata are from Data Set 18 in Appendix B, and they were obtained from a study conducted by \nresearchers at Pennsylvania State University and were provided by Minitab, Inc.) Use a 0.05 sig-\nnificance level to test the claim that the four treatment categories yield poplar trees with the same \nmean weight. Is there a treatment that appears to be most effective in the sandy and dry region?\nNo Treatment\nFertilizer\nIrrigation\nFertilizer and Irrigation\n0.24\n0.92\n0.96\n1.07\n1.69\n0.07\n1.43\n1.63\n1.23\n0.56\n1.26\n1.39\n0.99\n1.74\n1.57\n0.49\n1.80\n1.13\n0.72\n0.95\nIn Exercises 15 and 16, use the data set in Appendix B.\n15. Nicotine in Cigarettes Refer to Data Set 15 “Cigarette Contents” in Appendix B and use \nthe amounts of nicotine (mg per cigarette) in the king-size cigarettes, the 100-mm menthol \ncigarettes, and the 100-mm nonmenthol cigarettes. The king-size cigarettes are nonfiltered, \ncontinued\n",
    "546\t\nCHAPTER 12  Analysis of Variance\nnonmenthol, and nonlight. The 100-mm menthol cigarettes are filtered and nonlight. The \n100-mm nonmenthol cigarettes are filtered and nonlight. Use a 0.05 significance level to test \nthe claim that the three categories of cigarettes yield the same mean amount of nicotine. Given \nthat only the king-size cigarettes are not filtered, do the filters appear to make a difference?\n16. Secondhand Smoke Refer to Data Set 14 “Passive and Active Smoke” in Appendix B \nand use the measured serum cotinine levels (in mg>mL) from the three groups of subjects \n(smokers, nonsmokers exposed to tobacco smoke, and nonsmokers not exposed to tobacco \nsmoke). When nicotine is absorbed by the body, cotinine is produced. Use a 0.05 significance \nlevel to test the claim that the three samples are from populations with the same mean. What do \nthe results suggest about the effects of secondhand smoke?\n17. Tukey Test A display of the Bonferroni test results from Table 12-1 (which is part of the \nChapter Problem) is provided on page 542. Shown here is the SPSS-generated display of re-\nsults from the Tukey test using the same data. Compare the Tukey test results to those from the \nBonferroni test.\n12-1  Beyond the Basics\nSPSS\n18. Bonferroni Test Exercise 13 lists weights (kg) of poplar trees obtained from trees planted \nin a rich and moist region. Shown below are partial results from using the Bonferroni test with \nthe sample data.\na. Use a 0.05 significance level to test the claim that the different treatments result in the same \nmean weight.\nb. What do the displayed Bonferroni SPSS results tell us?\nc. Use the Bonferroni test procedure with a 0.05 significance level to test for a significant dif-\nference between the mean amount of the irrigation treatment group and the group treated with \nboth fertilizer and irrigation. Identify the test statistic and either the P-value or critical values. \nWhat do the results indicate?\nBonferroni Results from SPSS\n",
    "\t\n12-2  Two-Way ANOVA\t\n547\nKey Concept Section 12-1 considered data partitioned using one factor, but this sec-\ntion describes the method of two-way analysis of variance, which is used with data \npartitioned into categories according to two factors. The method of this section re-\nquires that we first test for an interaction between the two factors, then we test for an \neffect from the row factor and we test for an effect from the column factor.\nTable 12-3 is an example of pulse rate (beats per minute) data categorized with \ntwo factors:\n1.\t Age Bracket (years): One factor is age bracket (18–29, 30–49, 50–80).\n2.\t Gender: The second factor is gender (female, male).\nThe subcategories in Table 12-3 are called cells, so Table 12-3 has six cells containing \nten values each.\nIn analyzing the sample data in Table 12-3, we have already discussed one-way \nanalysis of variance for a single factor, so it might seem reasonable to simply proceed \nwith one-way ANOVA for the factor of age bracket and another one-way ANOVA for \nthe factor of gender, but that approach wastes information and totally ignores a very \nimportant feature: the possible effect of an interaction between the two factors.\n\t 12-2\t\nTwo-Way ANOVA\nDEFINITION\nThere is an interaction between two factors if the effect of one of the factors \nchanges for different categories of the other factor.\nTABLE 12-3  Pulse Rates with Two Factors: Age Bracket and Gender\nFemale\nMale\n18–29\n104   82   80   78   80   84   82   66   70     78\n72     64   72   64   64   70   72   64   54   52\n30–49\n  66   74   96   86   98   88   82   72   80     80\n80     90   58   74   96   72   58   66   80   92\n50–80\n  94   72   82   86   72   90   64   72   72   100\n54   102   52   52   62   82   82   60   52   74\nAs an example of an interaction between two factors, consider food pairings. \nPeanut butter and jelly interact well, but ketchup and ice cream interact in a way that \nresults in a bad taste, so we rarely see someone eating ice cream topped with ketchup. \nPhysicians must be careful to avoid prescribing drugs with interactions that produce \nadverse effects. It was found that the antifungal drug Nizoral (ketoconazole) inter-\nacted with the antihistamine drug Seldane (terfenadine) in such a way that Seldane \nwas not metabolized properly, causing abnormal heart rhythms in some patients. \nSeldane was subsequently removed from the market. In general, consider an interaction \neffect to be an effect due to the combination of the two factors.\nExplore Data with Means and an Interaction Graph\nLet’s explore the data in Table 12-3 by calculating the mean for each cell and by con-\nstructing a graph. The individual cell means are shown in Table 12-4 on the next page. \nThose means vary from a low of 64.8 to a high of 82.2, so they vary considerably. \n­Figure 12-3 on the next page is an interaction graph, which shows graphs of those \nmeans. We can interpret an interaction graph as follows:\n",
    "548\t\nCHAPTER 12  Analysis of Variance\n■\n■Interaction Effect: An interaction effect is suggested when line segments are far \nfrom being parallel.\n■\n■No Interaction Effect: If the line segments are approximately parallel, as in  \nFigure 12-3, it appears that the different categories of a variable have the same \neffect for the different categories of the other variable, so there does not appear to \nbe an interaction effect.\nTABLE 12-4  Means of Cells  \nfrom Table 12-3\nFemale\nMale\n18–29\n80.4\n64.8\n30–49\n82.2\n76.6\n50–80\n80.4\n67.2\nFIGURE 12-3  \u0007Interaction Graph of Age Bracket and \nGender: Means from Table 12-4\nInstead of relying only on subjective judgments made by examining the means in \nTable 12-4 and the interaction graph in Figure 12-3, we will proceed with the more \nobjective procedure of two-way analysis of variance. Here are the requirements and \nbasic procedure for two-way analysis of variance (ANOVA). The procedure is also \nsummarized in Figure 12-4, which follows the Key Elements box.\nTwo-Way Analysis of Variance\nObjective\nWith sample data categorized with two factors (a row variable and a column variable), use two-way analysis of variance \nto conduct the following three tests:\n1.\t Test for an effect from an interaction between the row factor and the column factor.\n2.\t Test for an effect from the row factor.\n3.\t Test for an effect from the column factor.\nRequirements\n1.\t Normality For each cell, the sample values come from \na population with a distribution that is approximately \nnormal. (This procedure is robust against reasonable  \ndepartures from normal distributions.)\n2.\t Variation The populations have the same variance s2 \n(or standard deviation s). (This procedure is robust \nagainst reasonable departures from the requirement of \nequal variances.)\nKEY ELEMENTS \n",
    "\t\n12-2  Two-Way ANOVA\t\n549\n3.\t Sampling The samples are simple random samples of \nquantitative data.\n4.\t Independence The samples are independent of each \nother. (This procedure does not apply to samples lack-\ning independence.)\n5.\t Two-Way The sample values are categorized two ways. \n(This is the basis for the name of the method: two-way \nanalysis of variance.)\n6.\t Balanced Design All of the cells have the same number \nof sample values. (This is called a balanced design. \nThis section does not include methods for a design that \nis not balanced.)\nProcedure for Two-Way ANOVA (See Figure 12-4)\nStep 1: Interaction Effect: In two-way analysis of variance, begin by testing the null hypothesis that there is no interac-\ntion between the two factors. Use technology to find the P-value corresponding to the following test statistic:\nF = MS1interaction2\nMS1error2\nConclusion:\n\t•\t Reject: If the P-value corresponding to the above test \nstatistic is small (such as less than or equal to 0.05),  \nreject the null hypothesis of no interaction. Conclude \nthat there is an interaction effect.\n\t•\t Fail to Reject: If the P-value is large (such as greater \nthan 0.05), fail to reject the null hypothesis of no inter-\naction between the two factors. Conclude that there is \nno interaction effect.\nStep 2: Row, Column Effects: If we conclude that there is an interaction effect, then we should stop now; we should \nnot proceed with the two additional tests. (If there is an interaction between factors, we shouldn’t consider the effects of \neither factor without considering those of the other.)\nIf we conclude that there is no interaction effect, then we should proceed with the following two hypoth-\nesis tests.\nRow Factor\nFor the row factor, test the null hypothesis H0: There are no effects from the row factor (that is, the row values are from \npopulations with the same mean). Find the P-value corresponding to the test statistic F = MS1row2>MS1error2.\nConclusion:\n\t•\t Reject: If the P-value corresponding to the test statistic \nis small (such as less than or equal to 0.05), reject the \nnull hypothesis of no effect from the row factor. Con-\nclude that there is an effect from the row factor.\n\t•\t Fail to Reject: If the P-value is large (such as greater \nthan 0.05), fail to reject the null hypothesis of no effect \nfrom the row factor. Conclude that there is no effect \nfrom the row factor.\nColumn Factor\nFor the column factor, test the null hypothesis H0: There are no effects from the column factor (that is, the column values are \nfrom populations with the same mean). Find the P-value corresponding to the test statistic F = MS(column)>MS(error).\nConclusion:\n\t•\t Reject: If the P-value corresponding to the test statistic \nis small (such as less than or equal to 0.05), reject the \nnull hypothesis of no effect from the column factor. \nConclude that there is an effect from the column factor.\n\t•\t Fail to Reject: If the P-value is large (such as greater \nthan 0.05), fail to reject the null hypothesis of no effect \nfrom the column factor. Conclude that there is no effect \nfrom the column factor.\n",
    "550\t\nCHAPTER 12  Analysis of Variance\nNo\n(Fail to reject H0 of\nno interaction eﬀect.)\nYes\n(Reject H0 of\nno interaction\neﬀect.)\nStart\nStop. Don’t consider the\neﬀects of either factor\nwithout considering the\neﬀects of the other.\nIs there an eﬀect\ndue to interaction between\nthe two factors?\nTest for eﬀect from row factor using the P-value \nfor the test statistic \nIf the P-value is small (such as less than 0.05), \nconclude that there is an eﬀect from the \nrow factor.\nF 5\nMS (row factor)\nMS (error)\nTest for eﬀect from column factor using the \nP-value for the test statistic \nIf the P-value is small (such as less than 0.05), \nconclude that there is an eﬀect from the \ncolumn factor.\nF 5\nMS (column factor)\nMS (error)\nTest for an interaction between the two factors. \nUse the P-value for the test statistic \nIf the P-value is small (such as less than 0.05), \nconclude that there is an interaction eﬀect.\nF 5\nMS (interaction)\nMS (error)\nFIGURE 12-4  Procedure for Two-Way Analysis of Variance\nEXAMPLE 1   Pulse Rates\nGiven the pulse rates in Table 12-3 on page 547 (from Data Set 1 “Body Data” in \nAppendix B), use two-way analysis of variance to test for an interaction effect, an \neffect from the row factor of age bracket, and an effect from the column factor of \ngender. Use a 0.05 significance level.\nSOLUTION\nREQUIREMENT CHECK  (1) For each cell, the sample values appear to be from a popu-\nlation with a distribution that is approximately normal, as indicated by normal quan-\ntile plots. (2) The variances of the cells (100.3, 51.7, 103.5, 183.2, 138.5, 293.5)  \ndiffer considerably, but the test is robust against departures from equal variances. \n",
    "\t\n12-2  Two-Way ANOVA\t\n551\n(3) The samples are simple random samples of subjects. (4) The samples are inde-\npendent of each other; the subjects are not matched in any way. (5) The sample val-\nues are categorized in two ways (age bracket and gender). (6) All of the cells have \nthe same number (ten) of sample values. The requirements are satisfied. \nThe calculations are quite involved, so we use technology. The StatCrunch  \ntwo-way analysis of variance display for the data in Table 12-3 is shown here.\nStatCrunch\nStep 1: Interaction Effect: We begin by testing the null hypothesis that there is no \ninteraction between the two factors. Using StatCrunch for the data in Table 12-3, \nwe get the results shown in the preceding StatCrunch display and we can see that \nthe test statistic for the interaction is F = 0.9391 (rounded). This test statistic can \nbe calculated as follows:\nF = MS1interaction2\nMS1error2\n= 136.26667\n145.11111 = 0.9391\nInterpretation: The corresponding P-value is shown in the StatCrunch display as \n0.3973, so we fail to reject the null hypothesis of no interaction between the two \nfactors. It does not appear that pulse rates are affected by an interaction between \nage bracket (18–29, 30–49, 50–80) and gender. There does not appear to be an  \ninteraction effect.\nStep 2: Row, Column Effects: Because there does not appear to be an interaction \neffect, we proceed to test for effects from the row and column factors. The two  \nhypothesis tests use these null hypotheses:\nH0: There are no effects from the row factor (that is, the row values\n are from populations with equal means).\nH0: There are no effects from the column factor (that is, the column values\n are from populations with equal means).\nRow Factor: For the row factor (age bracket), we refer to the preceding StatCrunch \ndisplay of results to see that the test statistic for the row factor is F = 1.81856 \n(rounded). This test statistic can be calculated as follows:\nF = MS1age bracket2\nMS1error2\n= 263.46667\n145.11111 = 1.8156\nConclusion: The corresponding P-value is shown in the StatCrunch display as \n0.1725. Because that P-value is greater than the significance level of 0.05, we fail to \nreject the null hypothesis of no effects from age bracket. That is, pulse rates do not \nappear to be affected by the age bracket.\nColumn Factor: For the column factor (gender), we refer to the preceding  \nStatCrunch display of results to see that the test statistic for the column factor is  \nF = 13.5914 (rounded). This test statistic can be calculated as follows:\ncontinued\n",
    "552\t\nCHAPTER 12  Analysis of Variance\nF = MS1gender2\nMS1error2\n= 1972.2667\n145.11111 = 13.5914\nConclusion: The corresponding P-value is shown in the StatCrunch display as 0.0005. \nBecause that P-value is less than the significance level of 0.05, we reject the null hy-\npothesis of no effects from gender. Pulse rates do appear to be affected by gender.\nINTERPRETATION\nOn the basis of the sample data in Table 12-3, we conclude that pulse rates appear \nto be affected by gender, but not by age bracket and not by an interaction between \nage bracket and gender.\nStatistical Literacy and Critical Thinking\n1. Two-Way ANOVA The pulse rates in Table 12-3 from Example 1 are reproduced below with \nfabricated data (in red) used for the pulse rates of females aged 30–49. What characteristic of \nthe data suggests that the appropriate method of analysis is two-way analysis of variance? That \nis, what is “two-way” about the data entered in this table?\nFemale\nMale\n18–29\n104   82   80   78   80   84   82   66   70     78\n72     64   72   64   64   70   72   64   54   52\n30–49\n  46   54   76   66   78   68   62   52   60     60\n80     90   58   74   96   72   58   66   80   92\n50–80\n  94   72   82   86   72   90   64   72   72   100\n54   102   52   52   62   82   82   60   52   74\n2. Two-Way ANOVA If we have a goal of using the data described in Exercise 1 to (1) de-\ntermine whether age bracket has an effect on pulse rates and (2) to determine whether gender \nhas an effect on pulse rates, should we use one-way analysis of variance for the two individual \ntests? Why or why not?\n3. Interaction\na. What is an interaction between two factors?\nb. In general, when using two-way analysis of variance, if we find that there is an interaction \neffect, how does that affect the procedure?\nc. Shown below is an interaction graph constructed from the data in Exercise 1. What does the \ngraph suggest?\n12-2  Basic Skills and Concepts\nTwo-Way Analysis of Variance\nAccess tech instructions, videos, and data sets at www.TriolaStats.com\nTECH CENTER \n",
    "\t\n12-2  Two-Way ANOVA\t\n553\n4. Balanced Design Does the table given in Exercise 1 constitute a balanced design? Why or \nwhy not?\n5. Pulse Rates If we use the data given in Exercise 1 with two-way analysis of variance, we \nget the accompanying display. What do you conclude?\nStatdisk\n6. Weights The weights (kg) in the following table are from Data Set 1 “Body Data.” Results \nfrom two-way analysis of variance are also shown. Use the displayed results and use a 0.05 \nsignificance level. What do you conclude?\nFemale\nMale\n18–29\n  63.4  57.8    52.6    46.9   61.7    61.5  \n  77.2  50.4    97.0    76.1\n71.6    64.9  144.9  96.4    80.7  84.4  \n63.9    79.0    99.4  64.1\n30–49\n110.5  84.6  133.3    90.2  125.7  105.3  \n115.5  75.3    92.8    57.7\n96.2    56.4  107.4  99.5    64.8  94.7  \n74.2  112.8    72.6  91.4\n50–80\n103.2  48.3    87.8  101.3   67.8    45.2 \n  79.8  60.1    68.5    43.3\n84.8  127.5    89.9  75.3  110.2  72.3  \n77.2    86.5    71.3  73.1\nStatCrunch\n7. Heights The heights (cm) in the following table are from Data Set 1 “Body Data.” Results \nfrom two-way analysis of variance are also shown. Use the displayed results and use a 0.05 \nsignificance level. What do you conclude?\nFemale\nMale\n18–29\n161.2  170.2  162.9  155.5  168.0\n153.3  152.0  154.9  157.4  159.5\n172.8  178.7  183.1  175.9  161.8\n177.5  170.5  180.1  178.6  178.5\n30–49\n169.1  170.6  171.1  159.6  169.8\n169.5  156.5  164.0  164.8  155.6\n170.1  165.4  178.5  168.5  180.3\n178.2  174.4  174.6  162.8  174.4\n50–80\n146.7  160.9  163.3  176.1  163.1\n151.6  164.7  153.3  160.3  134.5\n181.9  166.6  171.7  170.0  169.1\n182.9  176.3  166.7  166.3  160.5\nXLSTAT\n8. Cholesterol Levels The following table lists measured cholesterol levels of randomly \nselected subjects. Results from two-way analysis of variance are shown on the top of the next \npage. Use a 0.05 significance level. Are cholesterol levels affected by an interaction between sex \nand age? Are cholesterol levels affected by sex? Are cholesterol levels affected by age?\nAge\nUnder 30\n30–50\nOver 50\nMale\n265  303  1252  230  957\n702  277  176  416  120\n  75  189  288  578    31\nFemale\n325  112      62  301  223\n146  173  149  462    94\n254  384  318  600  309\ncontinued\n",
    "554\t\nCHAPTER 12  Analysis of Variance\n9. Measuring Self-Esteem The following table lists measures of self-esteem obtained from a \nstudent project as supervised by Jannay Morrow at Vassar College (based on data from Richard \nLowry). The objective of the project was to study how levels of self-esteem in subjects relate \nto their perceptions of self-esteem in other target people who were described in writing. Self-\nesteem levels were measured using the Coopersmith Self-Esteem Inventory, and the test here \nworks well even though the data are at the ordinal level of measurement. Use a 0.05 signifi-\ncance level and apply the methods of two-way analysis of variance. What do you conclude?\nSubject’s Self-Esteem\nLow\nMedium\nHigh\nTarget’s Self-Esteem\nLow\n4  4  3  5\n4  4  5  4\n2  4  4  2\n3  3  3  4\n4  2  4  4\n1  2  2  3\n3  1  3  3\n3  5  3  2\n3  3  3  3\nHigh\n2  2  4  2\n2  3  2  4\n2  2  2  3\n4  3  1  2\n1  3  2  4\n3  1  1  4\n3  2  3  2\n3  4  3  4\n4  3  3  4\n10. Smoking, Gender, and Body Temperature The table below lists body temperatures \n(oF) obtained from randomly selected subjects (based on Data Set 2 “Body Temperatures” in \nAppendix B). Using a 0.05 significance level, test for an interaction between gender and smok-\ning, test for an effect from gender, and test for an effect from smoking. What do you conclude?\nSmokes\nDoes Not Smoke\nMale\n98.8  97.6  98.0  98.5\n98.4  97.8  98.0  97.0\nFemale\n98.0  98.5  98.3  98.7\n97.7  98.0  98.2  99.1\nMinitab\n12-2  Beyond the Basics\n11. Transformations of Data Example 1 illustrated the use of two-way ANOVA to analyze \nthe sample data in Table 12-3 on page 547. How are the results affected in each of the follow-\ning cases?\na. The same constant is added to each sample value.\nb. Each sample value is multiplied by the same nonzero constant.\nc. The format of the table is transposed so that the row and column factors are interchanged.\nd. The first sample value in the first cell is changed so that it becomes an outlier.\n1.  ANOVA Listed on the top of the next page are skull breadths obtained from skulls of \nEgyptian males from three different epochs (based on data from Ancient Races of the Thebaid, \nby Thomson and Randall-Maciver). Assume that we plan to use analysis of variance with a \n0.05 significance level to test the claim that the different epochs have mean skull breadths that \nare not all the same. The results from XLSTAT are shown on the next page. What characteristic \nof the data indicates that we should use one-way analysis of variance?\nChapter Quick Quiz\n",
    "2. Null and Alternative Hypotheses For the hypothesis test described in Exercise 1, identify \nthe null hypothesis and the alternative hypothesis.\n3. Test Statistic Identify the value of the test statistic in the display included with Exercise 1. \nIn general, do larger test statistics result in larger P-values, smaller P-values, or P-values that \nare unrelated to the value of the test statistic?\n4. Conclusions If the test described in Exercise 1 is conducted with a 0.05 significance level, \nwhat should be concluded about the null hypothesis? What do the results suggest about the data?\n5. Type of Test Is the hypothesis test described in Exercise 1 left-tailed, right-tailed or two-\ntailed? Are all one-way analysis of variance tests left-tailed, right-tailed, or two-tailed?\n6. Which Mean Is Different? For the three samples described in Exercise 1, if we use analysis \nof variance and reach a conclusion to reject equality of the three population means, can we then \nconclude that any of the specific populations has a mean that is different from the others?\n7. One vs Two What is the fundamental difference between one-way analysis of variance and \ntwo-way analysis of variance?\nHead Injuries in Car Crashes.  In Exercises 8–10, use the accompanying data and cor-\nresponding display that results from head injury measurements from dummies in car crash \ntests. The measurements are in HIC (head injury criterion) units.\nSize of Car\nSmall\nMedium\nLarge\nForeign\n290\n245\n342\n544\n502\n698\n501\n393\n332\nDomestic\n406\n474\n216\n371\n368\n335\n376\n349\n169\nMinitab\n8. Interaction Test the null hypothesis that head injury measurements are not affected by an \ninteraction between the type of car (foreign, domestic) and size of the car (small, medium \nlarge). What do you conclude?\n9. Effect from Type of Car Assume that head injury measurements are not affected by an interac-\ntion between type of car (foreign, domestic) and size of car (small, medium, large). Is there suffi-\ncient evidence to support the claim that the type of car has an effect on head injury measurements?\n10. Effect from Size of Car Assume that head injury measurements are not affected by an \ninteraction between type of car (foreign, domestic) and size of car (small, medium, large). Is \nthere sufficient evidence to support the claim that the size of the car (small, medium, large) has \nan effect on head injury measurements?\n\t\nCHAPTER 12  Chapter Quick Quiz\t\n555\n400 B.C.\n131\n138\n125\n129\n132\n135\n132\n134\n138\n1850 B.C.\n129\n134\n136\n137\n137\n129\n136\n138\n134\n150 A.D.\n128\n138\n136\n139\n141\n142\n137\n145\n137\n",
    "556\t\nCHAPTER 12  Analysis of Variance\n1. Baseline Characteristics Experiments and clinical trials with different treatment groups \ncommonly include “baseline characteristics,” which constitute information about the charac-\nteristics of the different treatment groups. In a study of four different weight loss programs, \neach program had 40 subjects. The means and standard deviations of the ages in each group are \nas follows: Atkins (x = 47 years, s = 12 years); Zone (x = 51 years, s = 9 years); Weight \nWatchers (x = 49 years, s = 10 years); Ornish (x = 49 years, s = 12 years). These statistics \nare listed along with a P-value of 0.41. These results are from “Comparison of the Atkins, Or-\nnish, Weight Watchers, and Zone Diets for Weight Loss and Heart Disease Risk Reduction,” by \nDansinger et al., Journal of the American Medical Association, Vol. 293, No. 1.\na. How many variables are used to categorize the sample data consisting of the ages of the \nsubjects?\nb. What specific method is used to find the P-value of 0.41?\nc. What does the P-value of 0.41 indicate about the baseline characteristic of age?\nd. What would a small P-value (such as 0.001) indicate about the ages, and how would that \naffect the results of the study?\n2. Tar in Cigarettes Listed below are amounts of tar (mg per cigarette) in king-size cigarettes, \n100-mm menthol cigarettes, and 100-mm nonmenthol cigarettes (from Data Set 15 “Cigarette \nContents” in Appendix B). The king-size cigarettes are nonfiltered, nonmenthol, and nonlight. \nThe 100-mm menthol cigarettes are filtered and nonlight. The 100-mm nonmenthol cigarettes \nare filtered and nonlight. Use a 0.05 significance level to test the claim that the three categories \nof cigarettes yield the same mean amount of tar. Given that only the king-size cigarettes are not \nfiltered, do the filters appear to make a difference?\nKing\n20\n27\n27\n20\n20\n24\n20\n23\n20\n22\n20\n20\n20\n20\n20\n10\n24\n20\n21\n25\n23\n20\n22\n20\n20\nMenthol\n16\n13\n16\n  9\n14\n13\n12\n14\n14\n13\n13\n16\n13\n13\n18\n  9\n19\n  2\n13\n14\n14\n15\n16\n  6\n  8\nOne Hundred\n  5\n16\n17\n13\n13\n14\n15\n15\n15\n  9\n13\n13\n13\n15\n  2\n15\n15\n13\n14\n15\n16\n15\n  7\n17\n15\n3. Car Crash Tests When car crash tests were conducted, data were collected that consist of \ncrash test loads (pounds) on the left femur and right femur. When those loads are partitioned into \nthe three car size categories of small, midsize, and large, the two-way analysis of results from \nXLSTAT are as shown below. (The row factor of femur has the two values of left femur and right \nfemur, and the column factor of size has the three values of small, midsize, and large.) Use a 0.05 \nsignificance level to apply the methods of two-way analysis of variance. What do you conclude?\nReview Exercises\n4. Smoking, Body Temperature, Gender The table below lists body temperatures obtained \nfrom randomly selected subjects (based on Data Set 2 “Body Temperatures” in Appendix B). \nThe temperatures are categorized according to gender and whether the subject smokes. Using \na 0.05 significance level, test for an interaction between gender and smoking, test for an effect \nfrom gender, and test for an effect from smoking. What do you conclude?\nSmokes\nDoes Not Smoke\nMale\n98.4  98.4  99.4  98.6\n98.0  98.0  98.8  97.0\nFemale\n98.8  98.0  98.7  98.4\n97.7  98.0  98.2  99.1\n",
    "In Exercises 1–5, refer to the following list of numbers of years that U.S. presidents, popes, \nand British monarchs lived after their inauguration, election, or coronation, respectively. \n(As of this writing, the last president is Gerald Ford, the last pope is John Paul II, and the \nlast British monarch is George VI.) Assume that the data are samples randomly selected \nfrom larger populations.\nPresidents\n10\n29\n26\n28\n15\n23\n17\n25\n  0\n20\n  4\n  1\n24\n16\n12\n  4\n10\n17\n16\n  0\n  7\n24\n12\n  4\n18\n21\n11\n  2\n  9\n36\n12\n28\n  3\n16\n  9\n25\n23\n32\nPopes\n  2\n  9\n21\n  3\n  6\n10\n18\n11\n  6\n25\n23\n  6\n  2\n15\n32\n25\n11\n  8\n17\n19\n  5\n15\n  0\n26\nMonarchs\n17\n  6\n13\n12\n13\n33\n59\n10\n  7\n63\n  9\n25\n36\n15\n1. Descriptive Statistics Include appropriate units in all answers.\na. Find the mean for each of the three groups.\nb. Find the standard deviation for each of the three groups.\nc. Find the variance for each of the three groups.\nd. What is the level of measurement of the data (nominal, ordinal, interval, ratio)?\n2. Comparing Two Means Treating the data as samples from larger populations, test the claim \nthat there is a difference between the mean for presidents and the mean for British monarchs.\n3. Normality Assessment Use the longevity times for presidents and determine whether they \nappear to come from a population having a normal distribution. Explain why the distribution \ndoes or does not appear to be normal.\n4. Confidence Interval Use the longevity times for presidents and construct a 95% confi-\ndence interval estimate of the population mean. Write a brief statement interpreting the confi-\ndence interval.\n5. ANOVA The display below results from using the one-way analysis of variance test with the \nthree samples.\na. What is the null hypothesis?\nb. Assuming a 0.05 significance level, what conclusion is indicated by the displayed results?\nCumulative Review Exercises\nMinitab\n6. Freshman 15: Correlation, Regression Listed below are weights (kg) of eight male col-\nlege students in September and April of their freshman year (from Data Set 10 “Freshman 15” \nin Appendix B).\na. Test for a linear correlation between September weights and the subsequent April weights.\nb. Find the equation of the regression line.\nc. Find the best predicted April weight for a male freshman student given that his weight in \nSeptember is 94 kg. How does that result compare to an actual male student who weighed \n94 kg in September and 105 kg in April?\nSeptember\n72\n97\n74\n93\n59\n54\n73\n77\nApril\n59\n86\n69\n88\n55\n56\n75\n79\n\t\nCHAPTER 12  Cumulative Review Exercises\t\n557\n",
    "558\t\nCHAPTER 12  Analysis of Variance\n7. Platelets: Normal Distribution Assume that adult females have blood platelet counts that \nare normally distributed with a mean of 280 and a standard deviation of 65. (All units are in \n1000 cells>mL.)\na. Find the probability that a randomly selected adult female has a platelet count greater than 345.\nb. Find the probability that a randomly selected adult female has a platelet count between 215 \nand 345.\nc. If 25 adult females are randomly selected, find the probability that the mean of their platelet \ncounts is less than 319.\nd. Find the value of P80, the 80th percentile.\n8. Health Benefits USA Today reported on an Adecco Staffing survey of 1000 randomly se-\nlected adults. Among those respondents, 20% chose health benefits as being most important to \ntheir job.\na. What is the number of respondents who chose health benefits as being most important to their job?\nb. Construct a 95% interval estimate of the proportion of all adults who choose health benefits \nas being most important to their job.\nc. Based on the result from part (b), can we safely conclude that the true proportion is different \nfrom 1>4? Why?\n9. Blue Genes Some couples have genetic characteristics configured so that one-quarter of \nall their offspring have blue eyes. A study is conducted of 100 couples believed to have those \ncharacteristics, with the result that 19 of their 100 offspring have blue eyes. Assuming that one-\nquarter of all offspring have blue eyes, estimate the probability that among 100 offspring, 19 or \nfewer have blue eyes. Based on that probability, does it seem that the one-quarter rate is wrong? \nWhy or why not?\n10. Firearm Injuries The table below lists numbers of firearm injuries arranged according \nto circumstances and whether the firearm was a handgun or a rifle or shotgun (based on data \nfrom “Hospitalization Charges, Costs, and Income for Firearm-Related Injuries at a Univer-\nsity Trauma Center,” by Kizer et al., Journal of the American Medical Association, Vol. 273, \nNo. 22). Use a 0.05 significance level to test the claim that the injury category is independent \nof the type of weapon.\nUnintentional\nSelf-Inflicted\nAssault\nHandgun\n31\n35\n162\nRifle or Shotgun\n13\n7\n  67\nDoes Weight Change with Age? Refer to Data Set 1 “Body Data” in Appendix B and use \nthe weights of males partitioned into the three different age brackets of 18–25, 26–40, and \n41–80. Use the methods of this chapter to test the claim that men in those three age brackets \nhave the same mean weight.\nSorting One challenge in this project is identifying the weights of men in the three age \nbrackets. First, use the sort feature of your technology to sort all of the columns using Gender \nas the basis for sorting. You can then delete all of the rows representing females. Then sort all \nof the columns using Age as the basis for sorting. It will then be much easier to identify the \nweights in the different age brackets.\nTechnology Project\n",
    "FROM DATA TO DECISION\nCritical Thinking: Is Lipitor Effective in Lowering  \nLDL Cholesterol?\nWith sales of Lipitor exceeding $13 billion each year, it has \nbeen the best-selling drug ever. One of the authors asked \nPfizer for original data from clinical drug trials of Lipitor, \nbut Pfizer declined to provide the data. The data shown are \nbased on results given in a Parke-Davis memo from David \nG. Orloff, M.D., the medical team leader in the clinical trials. \nThe data refer to atorvastatin, and Lipitor is the trade name \nof atorvastatin. Low-density lipoprotein (LDL) cholesterol \nis considered the bad cholesterol, so a subject’s condition is \ngenerally improved if the LDL cholesterol is lowered. The \nchanges in LDL cholesterol listed in the table are measured \nin mg>dL. Note that when compared to baseline values, \nnegative values in the following data indicate that the LDL \ncholesterol has been lowered.\nChanges in LDL Cholesterol from Baseline Values  \n(a negative value represents a decrease)\nPlacebo Group:\n  -3    5    6    -2   -7    8     5   -6    -1    7   -4    3\nGroup treated with 10 mg of atorvastatin:\n-28 -27 -23 -25 -27 -29 -22 -22 -26 -23 -23  \n-22 -24 -21 -25 -26 -23 -24 -23 -22 -22 -20 -29 \n-29 -27 -24 -28 -26 -22 -26 -23 -26 -25 -29 -27 \n-27 -23\nGroup treated with 20 mg of atorvastatin:\n-28 -32 -29 -39 -31 -35 -25 -36 -35 -26 -29  \n-34 -30\nGroup treated with 80 mg of atorvastatin:\n-42 -41 -38 -42 -41 -41 -40 -44 -32 -37 -41  \n-37 -34 -31\nCooperative Group Activities\n1. Out-of-class activity Flesch Reading Ease scores and Flesch-Kincaid Grade Level scores mea-\nsure readability of text. Some programs, such as Microsoft Word, include features that allow you to \nautomatically obtain readability scores. Divide into groups of three or four students. Using samples \nof writing from Journal of the American Medical Association, the American Journal of Nursing, \nand the American Journal of Public Health, obtain readability scores for ten samples of text from \neach source. Use the methods of this chapter to determine whether there are any differences.\n2. In-class activity Divide the class into three groups. One group should record the pulse rate \nof each member while he or she remains seated. The second group should record the pulse rate \nof each member while he or she is standing. The third group should record the pulse rate of \neach member immediately after he or she stands and sits 10 times. Analyze the results. What do \nthe results indicate?\n3. Out-of-class activity Biographyonline.net includes information on the lives of notable art-\nists, politicians, scientists, actors, and others. Design and conduct an observational study that \nbegins with choosing samples from select groups, followed by a comparison of life spans of \npeople from the different groups. Do any particular groups appear to have life spans that are \ndifferent from those of other groups? Can you explain such differences?\n4. Out-of-class activity Divide into groups of three or four students. Each group should survey \nother students at the same college by asking them to identify their major and gender. You might in-\nclude other factors, such as employment (none, part-time, full-time) and age (under 21, 21–30, over \n30). For each surveyed subject, determine the number of Twitter followers or Facebook friends.\n• Does gender appear to have an effect on the number of followers>friends?\n• Does major have an effect on the number of followers>friends?\n• Does an interaction between gender and major have an effect on the number of followers>friends?\n\t\nCHAPTER 12  Cooperative Group Activities\t\n559\nAnalyzing the Results\nAnalyze the data. Does it appear that atorvastatin treatment \nhas an effect? If atorvastatin treatment does have an effect, is \nit the desired effect? Does it appear that larger doses of ator-\nvastatin treatment result in greater beneficial effects? Write a \nbrief report summarizing your findings and include specific \nstatistical tests and results.\n",
    "560\nBasics of Nonparametric \nTests\nSign Test\nWilcoxon Signed-Ranks \nTest for Matched Pairs\nWilcoxon Rank-Sum Test \nfor Two Independent \nSamples\nKruskal-Wallis Test for \nThree or More Samples\nRank Correlation\n13-1\n13-2\n13-3\n13-4\n13-5\n13-6\nEffects of Second-Hand Smoke\nCHAPTER \nPROBLEM\nNonparametric Tests\nData Set 14 in Appendix B includes measured cotinine levels \n(ng>mL) of subjects from three different groups: (1) smokers; \n(2) nonsmokers who are exposed to tobacco smoke; and  \n(3) nonsmokers not exposed to tobacco smoke. Cotinine is a \nmetabolite of nicotine, meaning that when nicotine is absorbed \nby the body, cotinine is produced. We want to test the claim \nthat the three different groups have different levels of cotinine. \nThis seems like a good application of the method of one-way \nanalysis of variance that was presented in Section 12-1. How-\never, if we check the requirements for analysis of variance, we \nfind that the three samples should be from populations having \ndistributions that are approximately normal. The accompanying \nnormal quantile plot results from the sample of cotinine levels \nmeasured from the third group: nonsmokers not exposed to \n13 \n",
    "smoke. The normality requirement for analysis of variance is a \nloose requirement, but the normal quantile plot suggests a dra-\nmatic departure from normality, so the normality requirement \ndoes not appear to be met.\nThis chapter presents “nonparametric” or “distribution-\nfree” methods that do not require normal or any other specific \ndistribution. This chapter will present a method that allows us \nto compare the cotinine levels in the three groups, even though \nthe three samples appear to be from populations with distribu-\ntions that are not normal. Nonparametric methods therefore \nprovide us with tools that often enable us to do an analysis that \nHere are the main objectives for Chapter 13:\nBasics of Nonparametric Tests\n• Develop the ability to describe the difference between parametric tests and  \nnonparametric tests.\n• Identify advantages and disadvantages of nonparametric tests.\n• Know how nonparametric tests are generally less efficient than the corresponding \nparametric tests.\n• Develop the ability to convert data into ranks.\nSign Test\n• Develop the ability to conduct a sign test for claims involving matched pairs of  \nsample data, or claims involving nominal data, or claims made about the median  \nof a population.\nWilcoxon Signed-Rank Test for Matched Pairs\n• Develop the ability to apply the Wilcoxon signed-ranks test for sample data consist-\ning of matched pairs.\nWilcoxon Rank-Sum Test for Two Independent Samples\n• Develop the ability to apply the Wilcoxon rank-sum test for sample data from two  \nindependent populations.\n13-1\n13-2\n13-3\n13-4\nChapter Objectives \n561\nCHAPTER OBJECTIVES\n3\n2.4\n1.8\n1.2\n0.6\n0\n-0.6\n-1.2\n-1.8\n-2.4\n-3\n0\n31\n62\n93\n124\n155\nX Values\nz score\n186\n217\n248\n279\n310\ncannot be done with parametric methods having requirements \nabout distributions.\n>>>\n",
    "562 \nCHAPTER 13 Nonparametric Tests\nThis chapter introduces methods of nonparametric tests, which do not have the \nstricter requirements of corresponding parametric tests, which are based on samples \nfrom populations with specific parameters such as m or s.\n13-1 \nBasics of Nonparametric Tests\nDEFINITIONS\nParametric tests have requirements about the distribution of the populations  \ninvolved; nonparametric (or distribution-free) tests do not require that samples \ncome from populations with normal distributions or any other particular distributions.\nMisleading Terminology The term distribution-free test correctly indicates that a \ntest does not require a particular distribution. The term nonparametric tests is mis-\nleading in the sense that it suggests that the tests are not based on a parameter, but \nthere are some nonparametric tests that are based on a parameter such as the median. \nDue to the widespread use of the term nonparametric test, we use that terminology, \nbut we define it to be a test that does not require a particular distribution.\nAdvantages and Disadvantages\nAdvantages of Nonparametric Tests\n1. Because nonparametric tests have less rigid requirements than parametric tests, \nthey can be applied to a wider variety of situations.\n2. Nonparametric tests can be applied to more data types than parametric \ntests. For example, nonparametric tests can be used with data consisting of \nranks, and they can be used with categorical data, such as genders of survey \nrespondents.\nDisadvantages of Nonparametric Tests\n1. Nonparametric tests tend to waste information because exact numerical data are \noften reduced to a qualitative form. For example, with the nonparametric sign \ntest (Section 13-2), weight losses by dieters are recorded simply as negative \nsigns, and the actual magnitudes of the weight losses are ignored.\nKruskal-Wallis Test for Three or More Samples\n• Develop the ability to apply the Kruskal-Wallis test for sample data from three or \nmore independent populations.\nRank Correlation\n• Develop the ability to compute the value of the rank correlation coefficient rs, and \nuse it to determine whether there is a correlation between two variables.\n13-5\n13-6\nKruskal-Wallis Test for Three or More Samples\n• Develop the ability to apply the Kruskal-Wallis test for sample data from three or \nmore independent populations.\nRank Correlation\n• Develop the ability to compute the value of the rank correlation coefficient rsrsr , and\nuse it to determine whether there is a correlation between two variables.\n",
    "13-1 Basics of Nonparametric Tests \n563\nRanks\nSections 13-2 through 13-6 use methods based on ranks, defined as follows.\nTABLE 13-1 Efficiency: Comparison of Parametric and Nonparametric Tests\nApplication\nParametric Test\nNonparametric Test\nEfficiency Rating  \nof Nonparametric  \nTest with Normal \nPopulations\nMatched pairs of \nsample data\nt test\nSign test or  \nWilcoxon signed-ranks test\n0.63 \n0.95\nTwo independent \nsamples\n \nt test\n \nWilcoxon rank-sum test\n \n0.95\nThree or more  \nindependent samples\nAnalysis of variance \n(F test)\n \nKruskal-Wallis test\n \n0.95\nCorrelation\nLinear correlation\nRank correlation test\n0.91\nDEFINITION\nData are sorted when they are arranged according to some criterion, such as \nsmallest to largest or best to worst. A rank is a number assigned to an individual \nsample item according to its order in the sorted list. The first item is assigned a \nrank of 1, the second item is assigned a rank of 2, and so on.\nHandling Ties Among Ranks If a tie in ranks occurs, one very common procedure is \nto find the mean of the ranks involved in the tie and then assign this mean rank to each \nof the tied items, as in the following example.\n2. Nonparametric tests are not as efficient as parametric tests, so a nonpara-\nmetric test generally needs stronger evidence (such as a larger sample or \ngreater differences) in order to reject a null hypothesis.\nEfficiency of Nonparametric Tests When the requirements of population dis-\ntributions are satisfied, nonparametric tests are generally less efficient than their \ncorresponding parametric tests. For example, Section 13-6 presents the concept of rank \ncorrelation, which has an efficiency rating of 0.91 when compared to linear correlation \nin Section 10-1. This means that with all other things being equal, the nonparametric \nrank correlation method in Section 13-6 requires 100 sample observations to achieve \nthe same results as 91 sample observations analyzed through the parametric linear \ncorrelation in Section 10-1, assuming the stricter requirements for using the para-\nmetric test are met. Table 13-1 lists nonparametric tests along with the corresponding \nparametric test and efficiency rating. Table 13-1 shows that several nonparamet-\nric tests have efficiency ratings above 0.90, so the lower efficiency might not be an \nimportant factor in choosing between parametric and nonparametric tests. However, \nbecause parametric tests do have higher efficiency ratings than their nonparamet-\nric counterparts, it’s generally better to use the parametric tests when their required \nassumptions are satisfied.\n",
    "564 \nCHAPTER 13 Nonparametric Tests\nKey Concept This section introduces the sign test, which involves converting data \nvalues to positive and negative signs, then testing to determine whether either sign \noccurs significantly more often than the other sign.\n13-2 \nSign Test\nDEFINITION\nThe sign test is a nonparametric (distribution-free) test that uses positive and  \nnegative signs to test different claims, including these:\n1. Claims involving matched pairs of sample data\n2. Claims involving nominal data with two categories\n3. Claims about the median of a single population\nBasic Concept of the Sign Test The basic idea underlying the sign test is to ana-\nlyze the frequencies of positive and negative signs to determine whether they are sig-\nnificantly different. For example, consider the results of clinical trials of the MicroSort \nmethod of gender selection. Among 726 couples who used the XSORT method in \ntrying to have a baby girl, 668 couples did have baby girls. Is 668 girls in 726 births \nsignificant? Common sense should suggest that 668 girls in 726 births is significant, \nbut what about 365 girls in 726 births? Or 400 girls in 726 births? The sign test allows \nus to determine when such results are significant. Figure 13-1 summarizes the sign \ntest procedure.\nFor consistency and simplicity, we will use a test statistic based on the number of \ntimes that the less frequent sign occurs.\nEXAMPLE 1  Handling Ties Among Ranks\nThe numbers 4, 5, 5, 5, 10, 11, 12, and 12 are given ranks of 1, 3, 3, 3, 5, 6, 7.5, and \n7.5, respectively. The table below illustrates the procedure for handling ties.\nSorted Data\nPreliminary Ranking\nRank\n4\n1\n1\n5\n5\n5\n2\n3\n4\n3\n3\n3\n10\n5\n5\n11\n6\n6\n12\n12\n7\n8\n7.5\n7.5\n$1%1&\n$1%1&\nMean is 3.\nf\nf Mean is 7.5.\n",
    "Yes\nStart\nDo the sample\ndata contradict \nH1?\nIs n ◊ 25?\nConvert the test statistic x to\nthe test statistic\n(x 1 0.5) 2 (n/2)\nÏn/2\nFind the critical z value(s) from\nTable A-2 in the usual way.\nFind the critical value \nfrom Table A-7.\nIs the \ntest statistic\nless than or equal \nto the critical \nvalue(s)?\nFail to reject the null\nhypothesis.\nReject the null\nhypothesis.\nNo\nNo\nNo\nYes\nYes\nAssign positive and negative signs\nand discard any zeros.\nLet n equal the total number of signs.\nLet the test statistic x equal the \nnumber of the less frequent sign.\nz 5\nFIGURE 13-1 Sign Test Procedure\n13-2 Sign Test \n565\n",
    "566 \nCHAPTER 13 Nonparametric Tests\nSign Test\nObjective\nUse positive and negative signs to test a claim falling into one of the following three categories:\n1. Matched Pairs \n  •  Subtract the second value in each pair from the first, \nrecord the sign of the difference, and ignore any 0s.\nKEY ELEMENTS \n2. Nominal Data with Two Categories \n  •  Represent each member of one category by a posi-\ntive sign and represent each member of the other \ncategory by a negative sign.\n3. Median of a Single Population \n  •  Subtract the median from each sample value, re-\ncord the sign of the difference, and ignore any 0s.\nNotation\nx = the number of times the less frequent sign occurs\nn = the total number of positive and negative signs combined\nRequirements\nThe sample data are a simple random sample.\nNote: There is no requirement that the sample data come from a population with a particular distribution, such as a  \nnormal distribution.\nTest Statistic\nIf n … 25: Test statistic is x = the number of times the less frequent sign occurs.\nIf n 7 25: Test statistic is\nz =\n1x + 0.52 - an\n2b\n2n\n2\nP-Values\nP-values are often provided by technology, or P-values can often be found using the z test statistic.\nCritical Values\n1. If n … 25, critical x values are found in Table A-7.\n2. If n 7 25, critical z values are found in Table A-2.\nHint: Because z is based on the less frequent sign, all one-sided tests are treated as if they were left-tailed tests.\nCAUTION When using the sign test in a one-tailed test, be very careful to avoid \nmaking the wrong conclusion when one sign occurs significantly more often or \nsignificantly less often than the other sign but the sample data contradict the \nalternative hypothesis. A sample of 7% boys can never be used to support  \nthe claim that boys occur more than 50% of the time, as in Example 1.\n",
    "13-2 Sign Test \n567\nEXAMPLE 1  Data Contradicting the Alternative Hypothesis \nAmong 945 couples who used the XSORT method of gender selection, 66 had boys, \nso the sample proportion of boys is 66>945, or 0.0698 (based on data from the  \nGenetics & IVF Institute). Consider the claim that the XSORT method of gender  \nselection increases the likelihood of baby boys so that the probability of a boy is \np 7 0.5. This claim of p 7 0.5 becomes the alternative hypothesis.\nUsing common sense, we see that with a sample proportion of boys of 0.0698, \nwe can never support a claim that p 7 0.5. (We would need a sample proportion  \nof boys greater than 0.5 by a significant amount.) Here, the sample proportion of  \n66>945, or 0.0698, contradicts the alternative hypothesis because it is not greater \nthan 0.5.\nINTERPRETATION\nAn alternative hypothesis can never be supported with data that contradict it. The \nsign test will show that 66 boys in 945 births is significant, but it is significant in  \nthe wrong direction. We can never support a claim that p 7 0.5 with a sample  \nproportion of 66>945, or 0.0698, which is less than 0.5.\nClaims About Matched Pairs\nWhen using the sign test with data that are matched pairs, we convert the raw data to \npositive and negative signs as follows:\n1. Subtract each value of the second variable from the corresponding value of the \nfirst variable.\n2. Record only the sign of the difference found in Step 1. Exclude ties by  \ndeleting any matched pairs in which both values are equal.\nThe main concept underlying this use of the sign test is as follows:\nIf the two sets of data have equal medians, the number of positive signs \nshould be approximately equal to the number of negative signs.\nEXAMPLE 2  Freshman Weight Gain\nTable 13-2 includes some of the weights listed in Data Set 10 in Appendix B. Those \nweights were measured from college students in September and April of their fresh-\nman year. Use the sample data in Table 13-2 to test the claim that there is no differ-\nence between the September weights and the April weights. Use the sign test with a \n0.05 significance level.\nTABLE 13-2 Weight (kg) Measurements of Students in Their Freshman Year\nSeptember Weight\n67\n53\n64\n74\n67\n70\n55\n74\n62\n57\nApril Weight\n66\n52\n68\n77\n67\n71\n60\n82\n65\n58\nSign of Difference\n+\n+\n-\n-\n0\n-\n-\n-\n-\n-\nSOLUTION\nREQUIREMENT CHECK The only requirement of the sign test is that the sample data \nare a simple random sample. Instead of being a simple random sample of selected \nstudents, all subjects volunteered for the study, so the requirement is not satisfied. \nThis limitation is cited in the journal article describing the results of the study. We \nwill proceed as if the requirement of a simple random sample is satisfied. \ncontinued\n",
    "568 \nCHAPTER 13 Nonparametric Tests\nIf there is no difference between the April weights and the corresponding  \nSeptember weights, the numbers of positive and negative signs should be approxi-\nmately equal. In Table 13-2 we have 7 negative signs, 2 positive signs, and 1 differ-\nence of 0. The sign test tells us whether the numbers of positive and negative signs \nare approximately equal.\nThe null hypothesis is the claim of no difference between the April weights and \nthe September weights, and the alternative hypothesis is the claim that there is a \ndifference.\nH0: There is no difference. (The median of the differences is equal to 0.)\nH1: There is a difference. (The median of the differences is not equal to 0.)\nFollowing the sign test procedure summarized in Figure 13-1, we let n = 9 (the  \ntotal number of signs) and we let x = 2 (the number of the less frequent sign, or  \nthe smaller of 2 and 7).\nThe sample data do not contradict H1, because there is a difference between the \n2 positive signs and the 7 negative signs. The sample data show a difference, and we \nneed to continue with the test to determine whether that difference is significant.\nTest Statistic Because n … 25, the test statistic is x = 2 and we do not convert \nx to a z score.\nCritical Value Figure 13-1 shows that with n = 9, we should proceed to find \nthe critical value from Table A-7. We refer to Table A-7, where the critical value of \n1 is found for n = 9 and a = 0.05 in two tails.\nConclusion With a test statistic of x = 2 and a critical value of 1, we fail to \nreject the null hypothesis of no difference. (See Note 2 included with Table A-7: \n“Reject the null hypothesis if the number of the less frequent sign x is less than or \nequal to the value in the table.” Because x = 2 is not less than or equal to the criti-\ncal value of 1, we fail to reject the null hypothesis.) There is not sufficient evidence \nto warrant rejection of the claim that the median of the differences is equal to 0.\nINTERPRETATION\nWe conclude that the September and April weights appear to be about the same.  \n[If we use the parametric t test for matched pairs (Section 9-3), we conclude that the \nmean difference is not zero, so the September weights and April weights appear to \nbe different.]\nThe conclusion should be qualified with the limitations noted in the article \nabout the study. Only Rutgers students were used, and study subjects were volun-\nteers instead of being a simple random sample.\nClaims Involving Nominal Data with Two Categories\nIn Chapter 1 we defined nominal data to be data that consist of names, labels, or cat-\negories only. The nature of nominal data limits the calculations that are possible, but \nwe can identify the proportion of the sample data that belong to a particular category, \nand we can test claims about the corresponding population proportion p. The follow-\ning example uses nominal data consisting of genders (girls>boys). The sign test is \nused by representing girls with positive 1+ 2 signs and boys with negative 1- 2 signs. \n(Those signs are chosen arbitrarily—honest.)\n",
    "13-2 Sign Test \n569\nEXAMPLE 3  Gender Selection\nThe Genetics & IVF Institute conducted a clinical trial of its methods for gender se-\nlection for babies. Before the clinical trials were concluded, 879 of 945 babies born \nto parents using the XSORT method of gender selection were girls. Use the sign test \nand a 0.05 significance level to test the claim that this method of gender selection is \neffective in increasing the likelihood of a baby girl.\nSOLUTION\nREQUIREMENT CHECK The only requirement is that the sample is a simple random \nsample. Based on the design of this experiment, we can assume that the sample data \nare a simple random sample. \nLet p denote the population proportion of baby girls. The claim that girls are \nmore likely with the XSORT method can be expressed as p 7 0.5, so the null and \nalternative hypotheses are as follows:\n H0: p = 0.5 1the proportion of girls is equal to 0.52\n H1: p 7 0.5 1girls are more likely2\nDenoting girls by positive signs 1+ 2 and boys by negative signs 1- 2, we have 879 \npositive signs and 66 negative signs. Using the sign test procedure summarized in \nFigure 13-1, we let the test statistic x be the smaller of 879 and 66, so x = 66 boys. \nInstead of trying to determine whether 879 girls is high enough to be significantly \nhigh, we proceed with the equivalent goal of trying to determine whether 66 boys is \nlow enough to be significantly low, so we treat the test as a left-tailed test.\nThe sample data do not contradict the alternative hypothesis because the sample \nproportion of girls is 879>945, or 0.930, which is greater than 0.5, as in the above \nalternative hypothesis. Continuing with the procedure in Figure 13-1, we note that \nthe value of n = 945 is greater than 25, so the test statistic x = 66 is converted  \n(using a correction for continuity) to the test statistic z as follows:\n z =\n1x + 0.52 - an\n2b\n2n\n2\n =\n166 + 0.52 - a945\n2 b\n2945\n2\n= -26.41\nP-Value We could use the test statistic of z = -26.41 to find the left-tailed P-value \nof 0.0000 (Table: 0.0001), and that low P-value causes us to reject the null hypothesis.\nCritical Value With a = 0.05 in a left-tailed test, the critical value is z = -1.645.\nConclusion Figure 13-2 shows that the test statistic z = -26.41 is in the critical \nregion bounded by z = -1.645, so we reject the null hypothesis that the proportion \nof girls is equal to 0.5. There is sufficient sample evidence to support the claim that \ngirls are more likely with the XSORT method.\ncontinued\n",
    "570 \nCHAPTER 13 Nonparametric Tests\nINTERPRETATION\nThe XSORT method of gender selection does appear to be associated with an  \nincrease in the likelihood of a girl, so this method appears to be effective (but this  \nhypothesis test does not prove that the XSORT method is the cause of the increase).\nz 5 0\nReject\np 5 0.5\nFail to reject\np 5 0.5\nSample data:\nz 5 –26.41\nz 5 21.645\nFIGURE 13-2  Testing Effectiveness of the XSORT  \nGender Selection Method\nClaims About the Median of a Single Population\nThe next example illustrates the procedure for using the sign test in testing a claim \nabout the median of a single population. See how the negative and positive signs are \nbased on the claimed value of the median.\nEXAMPLE 4  Body Temperatures\nData Set 2 in Appendix B includes measured body temperatures of adults. Use  \nthe 106 temperatures listed for 12 AM on Day 2 with the sign test to test the claim \nthat the median is less than 98.6°F. Of the 106 subjects, 68 had temperatures  \nbelow 98.6°F, 23 had temperatures above 98.6°F, and 15 had temperatures equal  \nto 98.6°F.\nSOLUTION\nREQUIREMENT CHECK The only requirement is that the sample is a simple random \nsample. Based on the design of this experiment, we assume that the sample data are \na simple random sample. \nThe claim that the median is less than 98.6°F is the alternative hypothesis, \nwhile the null hypothesis is the claim that the median is equal to 98.6°F.\nH0: Median is equal to 98.6°F. 1median = 98.6°F2\nH1: Median is less than 98.6°F. 1median 6  98.6°F2\nFollowing the procedure outlined in Figure 13-1, we use a negative sign to represent \neach temperature below 98.6°F, and we use a positive sign for each temperature \nabove 98.6°F. We discard the 15 data values of 98.6°F, since they result in dif-\nferences of zero. We have 68 negative signs and 23 positive signs, so n = 91 and \nx = 23 (the number of the less frequent sign). The sample data do not contradict \nthe alternative hypothesis, because most of the 91 temperatures are below 98.6°F.\n",
    "13-2 Sign Test \n571\nTest Statistic The value of n exceeds 25, so we convert the test statistic x to the test \nstatistic z:\n z =\n1 x + 0.52 - an\n2b\n2n\n2\n =\n123 + 0.52 - a91\n2 b\n291\n2\n= -4.61\nP-Value In this left-tailed test, the test statistic of z = -4.61 yields a P-value of \n0.0000 (Table: 0.0001).\nCritical Value In this left-tailed test with a = 0.05, we use Table A-2 to get the \ncritical z value of -1.645.\nConclusion Using either the low P-value of 0.000 or the fact that the test statistic of \nz = -4.61 is within the critical region as shown in Figure 13-3, we reject the null \nhypothesis.\nz 5 0\nReject\nMedian 5 98.68\nFail to reject\nMedian 5 98.68\nSample data:\nz 5 24.61\nz 5 21.645\nFIGURE 13-3  Testing the Claim That the Median  \nIs Less Than 98.6°F\nINTERPRETATION\nThere is sufficient sample evidence to support the claim that the median body  \ntemperature of healthy adults is less than 98.6°F. It is not equal to 98.6, as is com-\nmonly believed.\nNonparametric vs. Parametric In Example 4, the sign test of the claim that the \nmedian is below 98.6°F results in a test statistic of z = -4.61 and a P-value of \n0.00000202. However, a parametric test of the claim that m 6 98.6°F results in a \ntest statistic of t = -6.611 with a P-value of 0.000000000813. Because the P-value \nfrom the sign test is not as low as the P-value from the parametric test, we see that the \nsign test isn’t as sensitive as the parametric test. Both tests lead to rejection of the null \nhypothesis, but the sign test doesn’t consider the sample data to be as extreme, partly \nbecause the sign test uses only information about the direction of the data, ignoring \nthe magnitudes of the data values. The next section introduces the Wilcoxon signed-\nranks test, which largely overcomes that disadvantage.\n",
    "572 \nCHAPTER 13 Nonparametric Tests\nRationale for the Test Statistic Used When n + 25 When finding critical values \nfor the sign test, we use Table A-7 only for n up to 25. When n 7 25, the test statistic \nz is based on a normal approximation to the binomial probability distribution with \np = q = 1>2. In Section 6-6 we saw that the normal approximation to the binomial \ndistribution is acceptable when both np Ú 5 and nq Ú 5. In Section 5-2 we saw that \nm = np and s = 1npq for binomial probability distributions. Because this sign test \nassumes that p = q = 1>2, we meet the np Ú 5 and nq Ú 5 prerequisites whenever \nn Ú 10. Also, with the assumption that p = q = 1>2, we get m = np = n>2 and \ns = 1npq = 1n>4 = 1n>2, so the standard z score\nz = x - m\ns\nbecomes\nz =\nx - an\n2b\n2n\n2\nWe replace x by x + 0.5 as a correction for continuity. That is, the values of x are \ndiscrete, but since we are using a continuous probability distribution, a discrete value \nsuch as 10 is actually represented by the interval from 9.5 to 10.5. Because x repre-\nsents the less frequent sign, we act conservatively by concerning ourselves only with \nx + 0.5; we get the test statistic z shown below and in the Key Elements box.\nz =\n1 x + 0.52 - an\n2b\n2n\n2\nStatistical Literacy and Critical Thinking\n1. Sign Test for Body Temperatures The table below lists body temperatures of five sub-\njects at 8 AM and at 12 AM (from Data Set 2 in Appendix B). The data are matched pairs be-\ncause each pair of temperatures is measured from the same person. Assume that we plan to use \nthe sign test to test the claim of no difference between body temperatures at 8 AM and 12 AM.\na. What requirements must be satisfied for this test?\nb. Is there any requirement that the samples must be from populations having a normal distri-\nbution or any other specific distribution?\nc. In what sense is this sign test a “distribution-free test”?\nTemperature (oF) at 8 AM\n98.0\n97.6\n97.2\n98.0\n97.0\n98.0\nTemperature (oF) at 12 AM\n97.0\n98.8\n97.6\n98.0\n97.7\n98.8\n2. Identifying Signs For the sign test described in Exercise 1, identify the number of positive \nsigns, the number of negative signs, the number of ties, the sample size n that is used for the \nsign test, and the value of the test statistic.\n13-2 Basic Skills and Concepts \nSign Test\nAccess tech instructions, videos, and data sets at www.TriolaStats.com\nTECH CENTER\n",
    "13-2 Sign Test \n573\n3. Contradicting H1 An important step in conducting the sign test is to determine whether the \nsample data contradict the alternative hypothesis H1. For the sign test described in Exercise 1, \nidentify the null hypothesis and the alternative hypothesis, and explain how the sample data \ncontradict or do not contradict the alternative hypothesis.\n4. Efficiency of the Sign Test Refer to Table 13-1 on page 563 and identify the efficiency of \nthe sign test. What does that value tell us about the sign test?\nMatched Pairs. In Exercises 5–8, use the sign test for the data consisting of matched pairs.\n5. Heights of Mothers and Daughters Listed below are heights (in.) of mothers and their \nfirst daughters. The data are from a journal kept by Francis Galton. (The data are from Data Set \n6 “Family Heights.”) Use a 0.05 significance level to test the claim of no difference in heights \nbetween mothers and their first daughters.\nHeight of Mother\n68.0\n60\n61.0\n63.5\n69\n64.0\n69\n64\n63.5\n66\nHeight of Daughter\n68.5\n60\n63.5\n67.5\n68\n65.5\n69\n68\n64.5\n63\n6. Heights of Fathers and Sons Listed below are heights (in.) of fathers and their first sons. \nThe data are from a journal kept by Francis Galton. (The data are from Data Set 6 “Family \nHeights.”) Use a 0.05 significance level to test the claim that there is no difference in heights \nbetween fathers and their first sons.\nHeight of Father\n72\n66\n69\n70\n70\n70\n70\n75\n68.2\n65\nHeight of Son\n73\n68\n68\n71\n70\n70\n71\n71\n70.0\n63\n7. Friday the 13th Researchers collected data on the numbers of hospital admissions resulting \nfrom motor vehicle crashes, and results are given below for Fridays on the 6th of a month and \nFridays on the following 13th of the same month (based on data from “Is Friday the 13th Bad \nfor Your Health?” by Scanlon et al., British Medical Journal, Vol. 307, as listed in the Data and \nStory Line online resource of data sets). Test the claim that when the 13th day of a month falls \non a Friday, the numbers of hospital admissions from motor vehicle crashes are not affected.\nFriday the 6th\n 9\n 6\n11\n11\n3\n 5\nFriday the 13th\n13\n12\n14\n10\n4\n12\n8. Before, After Treatment Results Captopril is a drug designed to lower systolic blood \npressure. When subjects were treated with this drug, their systolic blood pressure readings \n(in mm Hg) were measured before and after the drug was taken. Results are given in the ac-\ncompanying table (based on data from “Essential Hypertension: Effect of an Oral Inhibitor of \nAngiotensin-Converting Enzyme,” by MacGregor et al., British Medical Journal, Vol. 2). \nUsing a 0.01 significance level, is there sufficient evidence to support the claim that captopril \nhas an effect on systolic blood pressure?\nSubject\nA\nB\nC\nD\nE\nF\nG\nH\nI\nJ\nK\nL\nBefore\n200\n174\n198\n170\n179\n182\n193\n209\n185\n155\n169\n210\nAfter\n191\n170\n177\n167\n159\n151\n176\n183\n159\n145\n146\n177\nNominal Data. In Exercises 9–12, use the sign test for the claims involving nominal data.\n9. Stem Cell Survey Newsweek conducted a poll in which respondents were asked if they “fa-\nvor or oppose using federal tax dollars to fund medical research using stem cells obtained from \nhuman embryos.” Of those polled, 481 were in favor, 401 were opposed, and 120 were unsure. \nUse a 0.01 significance level to test the claim that there is no difference between the propor-\ntions of those opposed and those in favor.\n10. Medical Malpractice In a study of 1228 randomly selected medical malpractice lawsuits, \nit was found that 856 of them were dropped or dismissed (based on data from the Physicians \nInsurers Association of America). Use a 0.01 significance level to test the claim that there is a \ndifference between the rate of medical malpractice lawsuits that go to trial and the rate of such \nlawsuits that are dropped or dismissed.\n",
    "574 \nCHAPTER 13 Nonparametric Tests\n11. Births A random sample of 860 births in New York State included 426 boys and 434 girls. \nUse a 0.05 significance level to test the claim that when babies are born, boys and girls are \nequally likely.\n12. Touch Therapy At the age of 9, Emily Rosa tested professional touch therapists to see if \nthey could sense her energy field. She flipped a coin to select either her right hand or her left \nhand; then she asked the therapists to identify the selected hand by placing their hand just under \nEmily’s hand without seeing it and without touching it. Among 280 trials, the touch therapists \nwere correct 123 times and wrong the other times (based on data in “A Close Look at Thera-\npeutic Touch,” Journal of the American Medical Association, Vol. 279, No. 13). Use a 0.01 \nsignificance level to test the claim that the touch therapists make their selections with a method \nequivalent to random guesses. Based on the results, does it appear that therapists are effective \nat identifying the correct hand?\nAppendix B Data Sets. In Exercises 13–16, refer to the indicated data set in Appendix B \nand use the sign test for the claim about the median of a population.\n13. IQ Scores Use the 20 IQ scores listed in Data Set 9 “IQ and Brain Size” and test the claim \nthat they are from a population with a median IQ score of 100. Use a 0.05 significance level.\n14. IQ Scores and Lead Exposure Use the full IQ scores for the group with low lead expo-\nsure in Data Set 8 “IQ and Lead.” Test the claim that they are from a population with a median \nIQ score of 100. Use a 0.01 significance level.\n15. Diastolic Blood Pressure Use the complete list of diastolic blood pressure measure-\nments from Data Set 1 “Body Data” and test the claim that they are from a population with a \nmedian equal to 72. Use a 0.05 significance level.\n16. Systolic Blood Pressure Use the complete list of systolic blood pressure measurements \nfrom Data Set 1 “Body Data” and test the claim that they are from a population with a median \nequal to 125. Use a 0.05 significance level.\n13-2 Beyond the Basics \n17. Procedures for Handling Ties In the sign test procedure described in this section, we \nexclude ties (represented by 0 instead of a sign of + or -). Here is a second approach: Treat \nhalf of the 0s as positive signs and half as negative signs. (If the number of 0s is odd, exclude \none so that they can be divided equally.) Here is a third approach: For two-tailed tests make \nhalf of the 0s positive and half negative, and for one-tailed tests make all 0s either positive or \nnegative, whichever supports the null hypothesis. Repeat Example 4 “Body Temperatures” us-\ning the second and third approaches to handling ties. Do the different approaches lead to very \ndifferent test statistics, P-values, and conclusions?\n18. Finding Critical Values Table A-7 lists critical values for limited choices of a. Use Table A-1 \nto add a new column in Table A-7 (from n = 1 to n = 8) that represents a significance level \nof 0.03 in one tail or 0.06 in two tails. For any particular n, use p = 0.5, because the sign test \nrequires the assumption that P(positive sign) = P(negative sign) = 0.5. The probability of \nx or fewer like signs is the sum of the probabilities for values up to and including x.\n",
    "13-3 Wilcoxon Signed-Ranks Test for Matched Pairs \n575\nKey Concept This section introduces the Wilcoxon signed-ranks test, which begins \nwith the conversion of the sample data into ranks. This test can be used for the two \ndifferent applications described in the following definition.\n \n13-3\n \n Wilcoxon Signed-Ranks Test for \nMatched Pairs\nDEFINITION\nThe Wilcoxon signed-ranks test is a nonparametric test that uses ranks for these \napplications:\n1. Testing a claim that a population of matched pairs has the property that the \nmatched pairs have differences with a median equal to zero\n2. Testing a claim that a single population of individual values has a median equal \nto some claimed value\nWhen testing a claimed value of a median for a population of individual values, we \ncreate matched pairs by pairing each sample value with the claimed median, so the \nsame procedure is used for both of the applications above.\nClaims Involving Matched Pairs\nThe sign test (Section 13-2) can be used with matched pairs, but the sign test uses only \nthe signs of the differences. By using ranks instead of signs, the Wilcoxon signed-\nranks test takes the magnitudes of the differences into account, so it includes and uses \nmore information than the sign test and therefore tends to yield conclusions that better \nreflect the true nature of the data.\nWilcoxon Signed-Ranks Test\nObjective: Use the Wilcoxon signed-ranks test for the following tests:\n • Matched Pairs: Test the claim that a population of \nmatched pairs has the property that the matched pairs \nhave differences with a median equal to zero.\n • One Population of Individual Values: Test the \nclaim that a population has a median equal to some \nclaimed value. (By pairing each sample value with the \nclaimed median, we again work with matched pairs.)\nNotation\nT = the smaller of the following two sums:\n1. The sum of the positive ranks of the nonzero  \ndifferences d\n2. The absolute value of the sum of the negative ranks of \nthe nonzero differences d\n(Details for evaluating T are given in the procedure following this Key Elements box.)\nKEY ELEMENTS \ncontinued\n",
    "576 \nCHAPTER 13 Nonparametric Tests\nRequirements\n1. The data are a simple random sample.\n2. The population of differences has a distribution that \nis approximately symmetric, meaning that the left half \nof its histogram is roughly a mirror image of its right \nhalf. (For a sample of matched pairs, obtain differences \nby subtracting the second value from the first value in \neach pair; for a sample of individual values, obtain dif-\nferences by subtracting the value of the claimed median \nfrom each sample value.)\nNote: There is no requirement that the data have a normal \ndistribution.\nTest Statistic\nIf n … 30, the test statistic is T.\nIf n 7 30, the test statistic is z =\nT - n1n + 12\n4\nB\nn1n + 1212n + 12\n24\nP-Values\nP-values are often provided by technology or P-values can be found using the z test statistic and Table A-2.\nCritical Values\n1. If n … 30, the critical T value is found in Table A-8.\n2. If n 7 30, the critical z values are found in Table A-2.\nThe following procedure requires that you sort data, then assign ranks. When working \nwith larger data sets, sorting and ranking become tedious, but technology can be used \nto automate that process. Stemplots can also be very helpful in sorting data.\nWilcoxon Signed-Ranks Procedure To see how the following steps are applied, \nrefer to the sample of matched pairs listed in the first two rows of Table 13-3. Assume \nthat we want to test the null hypothesis that the matched pairs are from a population of \nmatched pairs with differences having a median equal to zero.\nTABLE 13-3 Weights (kg) of Students in Their Freshman Year\nSeptember weight\n 67\n 53\n 64\n   74\n67\n   70\n 55\n 74\n   62\n   57\nApril weight\n 66\n 52\n 68\n   77\n67\n   71\n 60\n 82\n   65\n   58\nd (difference)\n   1\n   1\n-4\n   -3\n 0\n   -1\n-5\n-8\n   -3\n   -1\nRank of |d|\n2.5\n2.5\n  7\n   5.5\n   2.5\n  8\n  9\n   5.5\n   2.5\nSigned rank\n2.5\n2.5\n-7\n-5.5\n-2.5\n-8\n-9\n-5.5\n-2.5\nStep 1:  For each pair of data, find the difference d by subtracting the second value \nfrom the first value. Discard any pairs that have a difference of 0.\n \n EXAMPLE: The third row of Table 13-3 lists the differences found by sub-\ntracting the April weights from the corresponding September weights.\nStep 2:  Ignore the signs of the differences, then sort the differences from lowest to \nhighest and replace the differences by the corresponding rank value (as  \ndescribed in Section 13-1). When differences have the same numerical \nvalue, assign to them the mean of the ranks involved in the tie.\n",
    "13-3 Wilcoxon Signed-Ranks Test for Matched Pairs \n577\nEXAMPLE: The fourth row of Table 13-3 shows the ranks of the values of \n\u001ed\u001e. Consider the d values of 1, 1, -1, -1. If we ignore their signs, they are \ntied for the rank values of 1, 2, 3, 4, so they are each assigned a rank of 2.5, \nwhich is the mean of the ranks involved in the tie (or the mean of 1, 2, 3, 4).\nStep 3:  Attach to each rank the sign of the difference from which it came. That is, \ninsert the signs that were ignored in Step 2.\n \n EXAMPLE: The bottom row of Table 13-3 lists the same ranks found in the \nfourth row, but the signs of the differences shown in the third row are inserted.\nStep 4:  Find the sum of the ranks that are positive. Also find the absolute value of \nthe sum of the negative ranks.\n \n EXAMPLE: The bottom row of Table 13-3 lists the signed ranks. The sum \nof the positive ranks is 2.5 + 2.5 = 5. The sum of the negative ranks is \n(-7) + (-5.5) + (-2.5) + (-8) + (-9) + (-5.5) + (-2.5) = -40,  \nand the absolute value of this sum is 40. The two rank sums are 5 and 40.\nStep 5:  Let T be the smaller of the two sums found in Step 4. Either sum could be used, \nbut for a simplified procedure we arbitrarily select the smaller of the two sums.\n \n EXAMPLE: The data in Table 13-3 result in the rank sums of 5 and 40, so \nthe smaller of those two sums is 5.\nStep 6: Let n be the number of pairs of data for which the difference d is not 0.\n \n EXAMPLE: The data in Table 13-3 have 9 differences that are not 0, so n = 9.\nStep 7:  Determine the test statistic and critical values based on the sample size, as \nshown in the preceding Key Elements box.\n \n EXAMPLE: For the data in Table 13-3 the test statistic is T = 5. The sample \nsize is n = 9, so the critical value is found in Table A-8. Using a 0.05 sig-\nnificance level with a two-tailed test, the critical value from Table A-8 is 6.\nStep 8:  When forming the conclusion, reject the null hypothesis if the sample data lead \nto a test statistic that is in the critical region—that is, the test statistic is less than \nor equal to the critical value(s). Otherwise, fail to reject the null hypothesis.\n \n EXAMPLE: If the test statistic is T (instead of z), reject the null hypothesis if \nT is less than or equal to the critical value. Fail to reject the null hypothesis \nif T is greater than the critical value. Since T = 5 and the critical value is 6, \nwe reject the null hypothesis that the matched pairs are from a population of \nmatched pairs with differences having a median equal to zero.\nEXAMPLE 1  Freshman Weight Gain \nThe first two rows of Table 13-3 include some of the weights from Data Set 10 \n“Freshman 15” in Appendix B. Those weights were measured from college students \nin September and April of their freshman year. Use the sample data in the first  \ntwo rows of Table 13-3 to test the claim that there is no difference between the  \nSeptember weights and the April weights. Use the Wilcoxon signed-ranks test with \na 0.05 significance level.\nSOLUTION\nREQUIREMENT CHECK (1) The data should be a simple random sample. Instead \nof being a simple random sample of selected students, all subjects volunteered, \ncontinued\n",
    "578 \nCHAPTER 13 Nonparametric Tests\nand this is discussed in the journal article describing the results of the study. We \nwill proceed as if the requirement of a simple random sample is satisfied. (2) The \nhistogram of the differences in the third row of Table 13-3 is shown here. The left \nside of the graph should be roughly a mirror image of the right side, which does \nnot appear to be the case. But with only 9 differences, the difference between the \nleft and right sides is not too extreme, so we will consider this requirement to be \nsatisfied. \nThe null hypothesis is the claim of no difference between the April weights  \nand the September weights, and the alternative hypothesis is the claim that there is a \ndifference.\nH0: There is no difference. 1The median of the differences is equal to 0.2\nH1: There is a difference. 1The median of the differences is not equal to 0.2\nTest Statistic Because we are using the Wilcoxon signed-ranks test, the test statis-\ntic is calculated by using the eight-step procedure presented earlier in this section. \nThose steps include examples illustrating the calculation of the test statistic with the \nsample data in Table 13-3, and the result is the test statistic of T = 5.\nCritical Value The sample size is n = 9, so the critical value is found in Table A-8. \nUsing a 0.05 significance level with a two-tailed test, the critical value from Table A-8 \nis found to be 6.\nConclusion Table A-8 includes a note stating that we should reject the null  \nhypothesis if the test statistic T is less than or equal to the critical value. Because \nthe test statistic of T = 5 is less than the critical value of 6, we reject the null  \nhypothesis.\nINTERPRETATION\nWe conclude that the September and April weights do not appear to be about the \nsame. The large number of negative differences indicates that most students gained \nweight during their freshman year. The conclusion should be qualified with the limi-\ntations noted in the article about the study. Only Rutgers students were used, and \nstudy subjects were volunteers instead of being a simple random sample.\nIn Example 1, if we use the parametric t test for matched pairs (Section 9-3), we \nconclude that the mean difference is not zero, so the September weights and April \nweights appear to be different, as in Example 1. However, the sign test in Section 13-2 \nled to the conclusion of no difference. By using only positive and negative signs, the \nsign test did not use the magnitudes of the differences, but the Wilcoxon signed-ranks \ntest was more sensitive to those magnitudes through its use of ranks.\n",
    "13-3 Wilcoxon Signed-Ranks Test for Matched Pairs \n579\nClaims About the Median of a Single Population\nThe Wilcoxon signed-ranks test can also be used to test a claim that a single popula-\ntion has some claimed value of the median.\nWhen testing a claim about the median of a single population, create \nmatched pairs by pairing each sample value with the claimed value of \nthe median. The preceding procedure can then be used.\nEXAMPLE 2  Body Temperatures\nData Set 2 “Body Temperatures” in Appendix B includes measured body tempera-\ntures of adults. Use the 106 temperatures listed for 12 AM on Day 2 with the  \nWilcoxon signed-ranks test to test the claim that the median is less than 98.6°F.  \nUse a 0.05 significance level.\nSOLUTION\nREQUIREMENT CHECK (1) The design of the experiment that led to the data in Data \nSet 2 justifies treating the sample as a simple random sample. (2) The requirement \nof an approximately symmetric distribution of differences is satisfied, because a  \nhistogram of those differences is approximately symmetric. \nBy pairing each individual sample value with the median of 98.6°F, we are \nworking with matched pairs. Shown in the margin is the Statdisk display showing the \ntest statistic of  T = 661, which converts to the test statistic z = -5.67. (The display \nis from a two-tailed test; for this left-tailed test, the critical value is -1.645.) The test \nstatistic of z = -5.67 yields a P-value of 0.000, so we reject the null hypothesis that \nthe population of differences between body temperatures and the claimed median of \n98.6°F is zero. There is sufficient evidence to support the claim that the median body \ntemperature is less than 98.6°F. This is the same conclusion that results from the sign \ntest in Example 4 in Section 13-2.\nRationale: In Example 1, the unsigned ranks of 1 through 9 have a total of 45, so \nif there are no significant differences, each of the two signed-rank totals should be \naround 45 , 2, or 22.5. That is, the negative ranks and positive ranks should split up \nas 22.5–22.5 or something close, such as 24–21. Table A-8, the table of critical values, \nshows that at the 0.05 significance level with 9 pairs of data, the critical value is 6, so a \nsplit of 6–39 represents a significant departure from the null hypothesis, and any split \nthat is further apart will also represent a significant departure from the null hypothesis. \nConversely, splits like 7–38 do not represent significant departures from a 22.5–22.5 \nsplit, and they would not justify rejecting the null hypothesis. The Wilcoxon signed-\nranks test is based on the lower rank total, so instead of analyzing both numbers con-\nstituting the split, we consider only the lower number.\nThe sum of all the ranks 1 + 2 + 3 + g + n is equal to n1n + 12>2. If this \nrank sum is to be divided equally between two categories (positive and negative), each \nof the two totals should be near n1n + 12>4, which is half of n1n + 12>2. Recogni-\ntion of this principle helps us understand the test statistic used when n 7 30.\nStatdisk\nWilcoxon Signed-Ranks Test\nAccess tech instructions, videos, and data sets at www.TriolaStats.com\nTECH CENTER\n",
    "580 \nCHAPTER 13 Nonparametric Tests\n13-3 Basic Skills and Concepts \nStatistical Literacy and Critical Thinking\n1. Wilcoxon Signed-Ranks Test for Body Temperatures The table below lists body tem-\nperatures of seven subjects at 8 AM and at 12 AM (from Data Set 2 in Appendix B). The \ndata are matched pairs because each pair of temperatures is measured from the same person. \nAssume that we plan to use the Wilcoxon signed-ranks test to test the claim of no difference \nbetween body temperatures at 8 AM and 12 AM.\na. What requirements must be satisfied for this test?\nb. Is there any requirement that the samples must be from populations having a normal distri-\nbution or any other specific distribution?\nc. In what sense is this sign test a “distribution-free test”?\nTemperature (oF) at 8 AM\n98.0\n97.6\n97.2\n98.0\n97.0\n98.0\n98.2\nTemperature (oF) at 12 AM\n97.0\n98.8\n97.6\n98.0\n97.7\n98.8\n97.6\n2. Body Temperatures For the matched pairs listed in Exercise 1, identify the following \ncomponents used in the Wilcoxon signed-ranks test:\na. Differences d\nb. The ranks corresponding to the nonzero values of \u001ed\u001e\nc. The signed ranks\nd. The sum of the positive ranks and the sum of the absolute values of the negative ranks\ne. The value of the test statistic T\nf. The critical value of T (assuming a 0.05 significance level in a test of no difference between \nbody temperatures at 8 AM and 12 AM)\n3. Sign Test vs. Wilcoxon Signed-Ranks Test Using the data in Exercise 1, we can test \nfor no difference between body temperatures at 8 AM and 12 AM by using the sign test or the \nWilcoxon signed-ranks test. In what sense does the Wilcoxon signed-ranks test incorporate and \nuse more information than the sign test?\n4. Efficiency of the Wilcoxon Signed-Ranks Test Refer to Table 13-1 on page 563 and iden-\ntify the efficiency of the Wilcoxon signed-ranks test. What does that value tell us about the test?\nUsing the Wilcoxon Signed-Ranks Test. In Exercises 5–8, refer to the sample data for \nthe given exercises in Section 13-2 on page 573. Use the Wilcoxon signed-ranks test to test \nthe claim that the matched pairs have differences that come from a population with a  \nmedian equal to zero. Use a 0.05 significance level.\n5. Exercise 5 “Heights of Mothers and Daughters”\n6. Exercise 6 “Heights of Fathers and Sons”\n7. Exercise 7 “Friday the 13th”\n8. Exercise 8 “Before>After Treatment Results”\nClaim About a Median In Exercises 9–12, refer to the sample data from the given exer-\ncises in Section 13-2 on pages 573–574. Use the Wilcoxon signed-ranks test for the claim \nabout the median of a population.\n9. Exercise 13 “IQ Scores”\n10. Exercise 14 “IQ Scores and Lead Exposure”\n11. Exercise 15 “Diastolic Blood Pressure”\n12. Exercise 16 “Systolic Blood Pressure”\n",
    "13-4 Wilcoxon Rank-Sum Test for Two Independent Samples  \n581\n13-3 Beyond the Basics \n13. Rank Sums Exercise 12 uses body measurement data from Data Set 1 “Body Data” in \nAppendix B, and the sample size is 300.\na. If we have sample paired data with 300 nonzero differences, what are the smallest and larg-\nest possible values of T?\nb. If we have sample paired data with 300 nonzero differences, what is the expected value of T \nif the population consists of matched pairs with differences having a median of 0?\nc. If we have sample paired data with 300 nonzero differences and the sum of the positive ranks \nis 12,345, find the absolute value of the sum of the negative ranks.\nd. If we have sample paired data with n nonzero differences and one of the two rank sums is k, \nfind an expression for the other rank sum.\nCAUTION Don’t confuse the Wilcoxon rank-sum test for two independent samples \nwith the Wilcoxon signed-ranks test for matched pairs. Use “Internal Revenue \nService” as the mnemonic for IRS to remind yourself of “Independent: Rank Sum.”\nDEFINITION\nThe Wilcoxon rank-sum test is a nonparametric test that uses ranks of sample \ndata from two independent populations to test this null hypothesis:\nH0: Two independent samples come from populations with equal medians.\n(The alternative hypothesis H1 can be any one of the following three possibilities: \nThe two populations have different medians, or the first population has a median \ngreater than the median of the second population, or the first population has a  \nmedian less than the median of the second population.)\nKey Concept This section describes the Wilcoxon rank-sum test, which uses ranks of \nvalues from two independent samples to test the null hypothesis that the samples are \nfrom populations having equal medians. The Wilcoxon rank-sum test is equivalent to \nthe Mann-Whitney U test (see Exercise 13), which is included in some textbooks \nand technologies (such as Minitab, StatCrunch, and XLSTAT).\nHere is the basic idea underlying the Wilcoxon rank-sum test: If two samples \nare drawn from identical populations and the individual values are all ranked as one \ncombined collection of values, then the high and low ranks should fall evenly between \nthe two samples. If the low ranks are found predominantly in one sample and the high \nranks are found predominantly in the other sample, we have an indication that the two \npopulations have different medians.\nUnlike the parametric t tests for two independent samples in Section 9-2, the \nWilcoxon rank-sum test does not require normally distributed populations and it can \nbe used with data at the ordinal level of measurement, such as data consisting of ranks. \nIn Table 13-1 we noted that the Wilcoxon rank-sum test has a 0.95 efficiency rating \nwhen compared to the parametric test. Because this test has such a high efficiency \nrating and involves easier calculations, it is often preferred over the parametric t test, \neven when the requirement of normality is satisfied.\n \n13-4\n \n Wilcoxon Rank-Sum Test for Two  \nIndependent Samples\n",
    "582 \nCHAPTER 13 Nonparametric Tests\nWilcoxon Rank-Sum Test\nObjective\nUse the Wilcoxon rank-sum test with samples from two independent populations for the following null and alternative \nhypotheses:\nH0: The two samples come from populations with equal medians.\nH1:  The median of the first population is different from (or greater than, or less than) the median from \nthe second population.\nNotation\n n1 = size of Sample 1\n n2 = size of Sample 2\n R1 = sum of ranks for Sample 1\n R2 = sum of ranks for Sample 2\n R = same as R1 (sum of ranks for Sample 1)\n mR =  mean of the sample R values that is expected when \nthe two populations have equal medians\n sR =  standard deviation of the sample R values that \nis expected with two populations having equal \nmedians\nRequirements\n1. There are two independent simple random samples.\n2. Each of the two samples has more than 10 values. (For \nsamples with 10 or fewer values, special tables are \navailable in reference books, such as CRC Standard \nProbability and Statistics Tables and Formulae, pub-\nlished by CRC Press.)\nNote: There is no requirement that the two populations \nhave a normal distribution or any other particular distri-\nbution.\nKEY ELEMENTS \nTest Statistic\nz = R - mR\nsR\n n1 = size of the sample from which the rank sum R is found\n n2 = size of the other sample\n R = sum of ranks of the sample with size n1\nP-Values\nP-values can be found from technology or by using the z test statistic and Table A-2.\nCritical Values\nCritical values can be found in Table A-2 (because the test statistic is based on the normal distribution).\nProcedure for Finding the Value of the Test Statistic To see how the following \nsteps are applied, refer to the sample data listed in Table 13-4.\nStep 1:  Temporarily combine the two samples into one big sample, then replace \neach sample value with its rank. (The lowest value gets a rank of 1, the next \nlowest value gets a rank of 2, and so on. If values are tied, assign to them the \nmean of the ranks involved in the tie. See Section 13-1 for a description of \nranks and the procedure for handling ties.)\n where mR = n11n1 + n2 + 12\n2\n  and sR = B\nn1n21n1 + n2 + 12\n12\n",
    "13-4 Wilcoxon Rank-Sum Test for Two Independent Samples  \n583\nEXAMPLE: In Table 13-4, the ranks of the 23 sample pulse rates are shown \nin parentheses. The rank of 1 is assigned to the lowest value of 54. The next \nlowest values are 56 and 56; because they are tied for the ranks of 2 and 3, \nwe assign the rank of 2.5 to each of them.\nStep 2: Find the sum of the ranks for either one of the two samples.\n \n EXAMPLE: In Table 13-4, the sum of the ranks from the first sample is \n123.5. (That is, R1 = 4.5 + 11 + 19 + g + 6 = 123.5.)\nStep 3:  Calculate the value of the z test statistic as shown in the preceding Key  \nElements box, where either sample can be used as “Sample 1.” (If both sam-\nple sizes are greater than 10, then the sampling distribution of R is approxi-\nmately normal with mean mR and standard deviation sR, and the test statistic \nis as shown in the preceding Key Elements box.)\n \n EXAMPLE: Calculations of mR and sR and z are shown in Example 1,  \nwhich follows.\nTABLE 13-4 Pulse Rates  \n(Ranks in parentheses)\nMales\nFemales\n60 (4.5)\n78 (14)\n74 (11)\n80 (17)\n86 (19)\n68 (9)\n54 (1)\n56 (2.5)\n90 (20.5)\n76 (12)\n80 (17)\n78 (14)\n66 (7)\n78 (14)\n68 (9)\n90 (20.5)\n68 (9)\n96 (22)\n56 (2.5)\n60 (4.5)\n80 (17)\n98 (23)\n62 (6)\nn1 = 12\nn2 = 11\nR1 = 123.5\nR2 = 152.5\nEXAMPLE 1  Pulse Rates of Males and Females\nTable 13-4 lists pulse rates of samples of males and females (from Data Set 1 “Body \nData” in Appendix B). Use a 0.05 significance level to test the claim that males and \nfemales have the same median pulse rate.\nSOLUTION\nREQUIREMENT CHECK (1) The sample data are two independent simple random \nsamples. (2) The sample sizes are 12 and 11, so both sample sizes are greater than \n10. The requirements are satisfied. \nThe null and alternative hypotheses are as follows:\nH0: The median pulse rate of males is equal to the median pulse rate of females.\nH1:  The median pulse rate of males is different from the median pulse  \nrate of females.\nRank the combined list of all 23 pulse rates, beginning with a rank of 1 (assigned to \nthe lowest value of 54). The ranks corresponding to the individual sample values are \nshown in parentheses in Table 13-4. R denotes the sum of the ranks for the sample \nwe choose as Sample 1. If we choose the pulse rates of males as Sample 1, we get\nR = 4.5 + 11 + 19 + g + 6 = 123.5\nBecause there are pulse rates from 12 males, we have n1 = 12. Also, n2 = 11 be-\ncause there are pulse rates from 11 females. We can now find the values of mR and \nsR and the test statistic z.\n mR = n11n1 + n2 + 12\n2\n= 12112 + 11 + 12\n2\n= 144\n sR = B\nn1n21n1 + n2 + 12\n12\n= B\n11221112112 + 11 + 12\n12\n= 16.248\n z = R - mR\nsR\n= 123.5 - 144\n16.248\n= -1.26\nThe test is two-tailed because a large positive value of z would indicate that dispro-\nportionately more higher ranks are found in Sample 1, and a large negative value of \nz would indicate that disproportionately more lower ranks are found in Sample 1. In \ncontinued\n",
    "584 \nCHAPTER 13 Nonparametric Tests\neither case, we would have strong evidence against the claim that the two samples \ncome from populations with equal medians.\nThe significance of the test statistic z can be treated as in previous chapters. \nWe are testing (with a = 0.05) the hypothesis that the two populations have equal \nmedians, so we have a two-tailed test with test statistic z = -1.26. The P-value is \n0.2077 and the critical values are z = {1.96. We fail to reject the null hypothesis \nthat the populations of males and females have the same median.\nINTERPRETATION\nThere is not sufficient evidence to warrant rejection of the claim that males and \nfemales have the same median pulse rate. Based on the sample data given in  \nTable 13-4, it appears that males and females have pulse rates with the same median.\nIn Example 1, if we interchange the two sets of sample values and consider the \npulse rates of females to be the first sample, then R = 152.5, mR = 132, sR = 16.248,\nand z = 1.26, so the conclusion is exactly the same.\nEXAMPLE 2  Pulse Rates of Males and Females \nExample 1 uses 23 pulse rates, but if we use the 300 pulse rates from Data Set 1 in \nAppendix B, we get the accompanying display. We can see that the test statistic is  \nz = 3.22 (rounded). The test statistic falls in the critical region bounded by the \ncritical values of -1.96 and 1.96. Also, the test statistic of z = 3.22 can be used to \nfind that the P-value in this two-tailed test is 0.0013. We reject the null hypothesis \nof equal medians. Based on the larger sample of 300 subjects, it does appear that \nfemales and males have different median pulse rates.\nStatdisk\nStatistical Literacy and Critical Thinking\n1. Birth Weights Listed below are birth weights (g) from Data Set 3 “Births” in Appendix B. \nIf we use these data for the Wilcoxon rank-sum test with a two-tailed test, what is the null hy-\npothesis?\nGirl\n3500\n 800\n2400 4200 3100 2000 2900\n3300\n2800 2500 4000 3100 3000 3400\nBoy\n3900\n2800 3700 4000 3400 1600 3500\n3900\n3000 3200 3300\n 300\n2. Rank Sum When applying the Wilcoxon rank-sum test, what is the sum of the ranks for the \nsample of birth weights of girls?\n3. Requirements Refer to the sample data in Exercise 1. Assuming that the samples are ran-\ndom, are the requirements for the Wilcoxon rank-sum test satisfied? Explain.\n4. Efficiency Refer to Table 13-1 in Section 13-1 on page 563 and identify the efficiency of the \nWilcoxon rank-sum test. What does that value tell us about the test?\n13-4 Basic Skills and Concepts \nWilcoxon Rank-Sum Test\nAccess tech instructions, videos, and data sets at www.TriolaStats.com\nTECH CENTER\n",
    "13-4 Wilcoxon Rank-Sum Test for Two Independent Samples  \n585\nWilcoxon Rank-Sum Test. In Exercises 5–8, use the Wilcoxon rank-sum test.\n5. Birth Weights Use the sample data given in Exercise 1 and test the claim that girls and boys \nhave the same median birth weight. Use a 0.05 significance level.\n6. Radiation in Baby Teeth Listed below are amounts of strontium-90 (in millibecquerels, or \nmBq, per gram of calcium) in a simple random sample of baby teeth obtained from Pennsylvania \nresidents and New York residents born after 1979 (based on data from “An Unexpected Rise in \nStrontium-90 in U.S. Deciduous Teeth in the 1990s,” by Mangano et al., Science of the Total \nEnvironment). Use a 0.05 significance level to test the claim that the median amount of stron-\ntium-90 from Pennsylvania residents is the same as the median from New York residents.\nPennsylvania\n155\n142\n149\n130\n151\n163\n151\n142\n156\n133\n138\n161\nNew York\n133\n140\n142\n131\n134\n129\n128\n140\n140\n140\n137\n143\n7. Clinical Trials of Lipitor The sample data below are changes in low-density lipoprotein (LDL) \ncholesterol levels in clinical trials of Lipitor (atorvastatin). It was claimed that Lipitor had an effect \non LDL cholesterol. (The data are based on results given in a Parke-Davis memo from David G. Orl-\noff, M.D., the medical team leader for clinical trials of Lipitor. Pfizer declined to provide the original \ndata values.) Negative values represent decreases in LDL cholesterol. Use a 0.05 significance level to \ntest the claim that for those treated with 20 mg of atorvastatin and those treated with 80 mg of atorv-\nastatin, changes in LDL cholesterol have the same median. What do the results suggest?\nGroup treated with 20 mg atorvastatin:\n-28\n-32\n-29\n-39\n-31\n-35\n-25\n-36\n-35\n-26\n-29\n-34\n-30\nGroup treated with 80 mg atorvastatin:\n-42\n-41\n-38\n-42\n-41\n-41\n-40\n-44\n-32\n-37\n-41\n-37\n-34\n-31\n8. Blanking Out on Tests In a study of students blanking out on tests, the arrangement of test \nitems was studied for its effect on anxiety. The following scores are measures of “debilitating test \nanxiety” (based on data from “Item Arrangement, Cognitive Entry Characteristics, Sex and Test \nAnxiety as Predictors of Achievement in Examination Performance,” by Klimko, Journal of Ex-\nperimental Education, Vol. 52, No. 4). Is there sufficient evidence to support the claim that the two \nsamples are from populations with different medians? Is there sufficient evidence to support the \nclaim that the arrangement of the test items has an effect on the score? Use a 0.01 significance level.\nQuestions Arranged from Easy to Difficult\nQuestions Arranged from Difficult to Easy\n24.64\n39.29\n16.32\n32.83\n28.02\n33.62\n34.02\n26.63\n30.26\n33.31\n20.60\n21.13\n26.69\n28.90\n35.91\n26.68\n29.49\n35.32\n26.43\n24.23\n7.10\n32.86\n21.06\n27.24\n32.34\n29.34\n33.53\n28.89\n28.71\n31.73\n30.02\n21.96\n27.62\n42.91\n30.20\n32.54\n25.49\n38.81\n27.85\n30.29\n30.72\nAppendix B Data Sets. In Exercises 9–12, refer to the indicated data set in Appendix B \nand use the Wilcoxon rank-sum test.\n9. Birth Weights Repeat Exercise 5 “Birth Weights” using all of the birth weights given in \nData Set 3 “Births” in Appendix B.\n10. Cigarettes Refer to Data Set 15 “Cigarette Contents” in Appendix B for the amounts of \nnicotine (mg per cigarette) in the sample of king-size cigarettes, which are nonfiltered, non-\nmenthol, and nonlight, and for the amounts of nicotine in the 100-mm cigarettes, which are fil-\ntered, nonmenthol, and nonlight. Use a 0.01 significance level to test the claim that the median \namount of nicotine in the nonfiltered king-size cigarettes is greater than the median amount of \nnicotine in the 100-mm filtered cigarettes.\n11. IQ and Lead Exposure Data Set 8 “IQ and Lead” in Appendix B lists full IQ scores for \na random sample of subjects with “medium” lead levels in their blood and another random \nsample of subjects with “high” lead levels in their blood. Use a 0.05 significance level to test \ncontinued\n",
    "586 \nCHAPTER 13 Nonparametric Tests\nthe claim that subjects with medium lead levels have a higher median of the full IQ scores than \nsubjects with high lead levels. Does lead level appear to affect full IQ scores?\n12. IQ and Lead Exposure Data Set 8 “IQ and Lead” in Appendix B lists performance  \nIQ scores for a random sample of subjects with low lead levels in their blood and another ran-\ndom sample of subjects with high lead levels in their blood. Use a 0.05 significance level to test \nthe claim that subjects with low lead levels have a higher median of the performance IQ score \nthan those with high lead levels. Does lead exposure appear to have an adverse effect?\n13. Using the Mann-Whitney U Test The Mann-Whitney U test is equivalent to the Wil-\ncoxon rank-sum test for independent samples in the sense that they both apply to the same \nsituations and always lead to the same conclusions. In the Mann-Whitney U test we calculate\nz =\nU - n1n2\n2\nB\nn1n21n1 + n2 + 12\n12\nwhere\nU = n1n2 +\nn11n1 + 12\n2\n- R\nand R is the sum of the ranks for Sample 1. Use the pulse rates in Table 13-4 on page 583 in this \nsection to find the z test statistic for the Mann-Whitney U test. Compare this value to the z test \nstatistic found using the Wilcoxon rank-sum test.\n14. Finding Critical Values Assume that we have two treatments (A and B) that produce \nquantitative results, and we have only two observations for treatment A and two observations \nfor treatment B. We cannot use the Wilcoxon signed ranks test given in this section because \nboth sample sizes do not exceed 10.\n \nRank\nRank Sum for \nTreatment A\n1\n2\n3\n4\nA\nA\nB\nB\n3\na. Complete the accompanying table by listing the five rows corresponding to the other five \npossible outcomes, and enter the corresponding rank sums for treatment A.\nb. List the possible values of R and their corresponding probabilities. [Assume that the rows of \nthe table from part (a) are equally likely.]\nc. Is it possible, at the 0.10 significance level, to reject the null hypothesis that there is no \ndifference between treatments A and B? Explain.\n13-4 Beyond the Basics \nKey Concept This section describes the Kruskal-Wallis test, which uses ranks of data \nfrom three or more independent simple random samples to test the null hypothesis \nthat the samples come from populations with the same median.\nSection 12-1 described one-way analysis of variance (ANOVA) as a method for \ntesting the null hypothesis that three or more populations have the same mean, but \n13-5 \nKruskal-Wallis Test for Three or More Samples\n",
    "13-5 Kruskal-Wallis Test for Three or More Samples \n587\nANOVA requires that all of the involved populations have normal distributions. The \nKruskal-Wallis test for equal medians does not require normal distributions, so it is a \ndistribution-free or nonparametric test.\nDEFINITION\nThe Kruskal-Wallis test (also called the H test) is a nonparametric test that uses ranks \nof combined simple random samples from three or more independent populations to \ntest the null hypothesis that the populations have the same median. (The alternative  \nhypothesis is the claim that the populations have medians that are not all equal.)\nKruskal-Wallis Test\nObjective\nUse the Kruskal-Wallis test with simple random samples from three or more independent populations for the following:\nH0: The samples come from populations with the same median.\nH1: The samples come from populations with medians that are not all equal.\nNotation\n N =  total number of observations in all samples  \ncombined\n k = number of different samples\n R1 = sum of ranks for Sample 1\nn1 =  number of observations in Sample 1\nFor Sample 2, the sum of ranks is R2 and the number of \nobservations is n2, and similar notation is used for the \nother samples.\nRequirements\n1. We have at least three independent samples.\n2. Each sample has at least five observations. (If samples \nhave fewer than five observations, refer to special tables \nof critical values.)\nNote: There is no requirement that the populations have \na normal distribution or any other particular distribution.\nKEY ELEMENTS \nTest Statistic\nH =\n12\nN 1N + 12 aR2\n1\nn1\n+ R2\n2\nn2\n+ g + R2\nk\nnk\nb - 31N + 12\nP-Values\nP-values are often provided by technology. By using the test statistic H and the number of degrees of freedom (k − 1), \nTable A-4 can be used to find a range of values for the P-value.\nCritical Values\n1. The test is right-tailed and critical values can be found \nfrom technology or from the chi-square distribution in \nTable A-4.\n2. df = k - 1 (where df is the number of degrees of  \nfreedom and k is the number of different samples)\n",
    "588 \nCHAPTER 13 Nonparametric Tests\nProcedure for Finding the Value of the H Test Statistic To see how the follow-\ning steps are applied, refer to the sample data listed in Table 13-5. Table 13-5 includes \nonly some of the data in Data Set 14 “Passive and Active Smoke” in Appendix B. This \nshortened data set is more suitable for illustrating the method of the Kruskal-Wallis test.\nStep 1:  Temporarily combine all samples into one big sample and assign a rank to \neach sample value. (Sort the values from lowest to highest, and in cases of \nties, assign to each observation the mean of the ranks involved.)\n \n EXAMPLE: In Table 13-5, the numbers in parentheses are the ranks of the com-\nbined data set. There are ten values of 0 tied for the lowest ranks of 1 through \n10, so each of them is assigned a rank of 5.5, which is the mean of the integers \nfrom 1 through 10. Next, there are two values of 1 tied for ranks 11 and 12, so \neach of them is assigned a rank of 11.5. The next lowest number is 19, which is \nassigned the next rank of 13, and so on.\nStep 2: For each sample, find the sum of the ranks and find the sample size.\n \n EXAMPLE: In Table 13-5, the sum of the ranks from the first sample is 65, the \nsum of the ranks for the second sample is 67.5, and the sum of the ranks for the \nthird sample is 38.5.\nStep 3:  Calculate H using the results of Step 2 and the notation and test statistic \ngiven in the preceding Key Elements box.\n \nEXAMPLE: The test statistic is computed in Example 1.\nTABLE 13-5 Cotinine Levels (Ranks in parentheses)\nSmokers\nETS\nNOETS\n1 (11.5)\n384 (18)\n0 (5.5)\n0 (5.5)\n0 (5.5)\n0 (5.5)\n131 (15)\n69 (14)\n0 (5.5)\n173 (16)\n19 (13)\n0 (5.5)\n265 (17)\n1 (11.5)\n0 (5.5)\n0 (5.5)\n0 (5.5)\n0 (5.5)\nn1 = 5\nn2 = 6\nn3 = 7\nR1 = 65\nR2 = 67.5\nR3 = 38.5\nIn applying the Kruskal-Wallis test, we compute the test statistic H, which has a dis-\ntribution that can be approximated by the chi-square distribution provided that each \nsample has at least five observations. (For a quick review of the key features of the \nchi-square distribution, see Section 7-3.)\nThe H test statistic measures the variance of the rank sums R1, R2, . . . , Rk from \nthe different samples. If the ranks are distributed evenly among the sample groups, \nthen H should be a relatively small number. If the samples are very different, then the \nranks will be excessively low in some groups and high in others, with the net effect \nthat H will be large. Consequently, only large values of H lead to rejection of the null \nhypothesis that the samples come from identical populations. The Kruskal-Wallis test \nis therefore a right-tailed test.\n",
    "13-5 Kruskal-Wallis Test for Three or More Samples \n589\nEXAMPLE 1  Effect of Second-Hand Smoke \nTable 13-5 lists some of the data from Data Set 14 “Passive and Active Smoke”  \nin Appendix B. Use a 0.05 significance level to test the claim that the three samples \nof cotinine levels come from populations with medians that are all equal.\nSOLUTION\nREQUIREMENT CHECK (1) Each of the three samples is a simple random independent \nsample. (2) Each sample size is at least 5. The requirements are satisfied. \nThe null and alternative hypotheses are as follows:\nH0:  The populations of smokers, nonsmokers exposed to tobacco smoke (ETS), \nand nonsmokers not exposed to tobacco smoke have cotinine levels with \nthe same median.\nH1:  The three populations have medians that are not all the same.\nTest Statistic First combine all of the sample data and rank them, then find the sum \nof the ranks for each category. In Table 13-5, ranks are shown in parentheses next \nto the original sample values. Next, find the sample size (n) and sum of ranks (R) \nfor each sample. Those values are shown at the bottom of Table 13-5. Because the \ntotal number of observations is 18, we have N = 18. We can now evaluate the test \nstatistic as follows:\n H =\n12\nN1N + 12 aR2\n1\nn1\n+ R2\n2\nn2\n+ g + R2\nk\nnk\nb - 31N + 12\n =\n12\n18118 + 12 a652\n5\n+ 67.52\n6\n+ 38.52\n7\nb - 3118 + 12\n = 6.724\nCritical Value Because each sample has at least five observations, the distribution \nof H is approximately a chi-square distribution with k - 1 degrees of freedom. The \nnumber of samples is k = 3, so we have 3 - 1 = 2 degrees of freedom. Refer to \nTable A-4 to find the critical value of 5.991, which corresponds to 2 degrees of free-\ndom and a 0.05 significance level (with an area of 0.05 in the right tail). Figure 13-4 \nshows that the test statistic H = 6.724 does fall within the critical region bounded \nby 5.991, so we reject the null hypothesis of equal population medians.\nFigure 13-4 shows the test statistic of H = 6.724 and the critical value of \n5.991. (The chi-square distribution has the general shape shown in Figure 13-4 \n0\nCritical value:\n5.991\nTest statistic:\nH 5 6.724\n0.05\nFIGURE 13-4 Chi-Square Distribution for Example 1\ncontinued\n",
    "590 \nCHAPTER 13 Nonparametric Tests\nwhenever the number of degrees of freedom is 1 or 2.) The test statistic does fall in \nthe critical region, so we reject the null hypothesis of equal medians.\nINTERPRETATION\nThere is sufficient evidence to reject the claim that the three samples of cotinine  \nlevels come from populations with medians that are all equal. The population  \nmedians do appear to be significantly different.\nRationale: The Kruskal-Wallis H test statistic is the rank version of the F test statis-\ntic used in analysis of variance discussed in Chapter 12. When we deal with ranks R \ninstead of original values x, many components are predetermined. For example, the \nsum of all ranks can be expressed as N1N + 12>2, where N is the total number of \nvalues in all samples combined. The expression\nH =\n12\nN1N + 12 Σni1Ri - R2 2\nwhere\nRi = Ri\nni  and  R = ΣRi\nΣni\ncombines weighted variances of ranks to produce the H test statistic given here, and \nthis expression for H is algebraically equivalent to the expression for H given earlier \nas the test statistic.\nStatistical Literacy and Critical Thinking\n1. Effect of Lead on IQ Score Listed below are full IQ scores from simple random samples of \nsubjects with low lead exposure, medium lead exposure, and high lead exposure (from Data Set 8 in \nAppendix B). In using the Kruskal-Wallis test, we must rank all of the data combined; then we must \nfind the sum of the ranks for each sample. Find the sum of the ranks for each of the three samples.\nLow Lead Level\nMedium Lead Level\nHigh Lead Level\n70\n72\n82\n85\n90\n93\n86\n92\n85\n76\n71\n75\n84\n86\n85\n79\n2. Requirements Assume that we want to use the data from Exercise 1 with the Kruskal-\nWallis test. Are the requirements satisfied? Explain.\n3. Notation For the data given in Exercise 1, identify the values of n1, n2, n3, and N.\n4. Efficiency Refer to Table 13-1 on page 563 and identify the efficiency of the Kruskal-Wallis \ntest. What does that value tell us about the test?\n13-5 Basic Skills and Concepts \nKruskal-Wallis Test\nAccess tech instructions, videos, and data sets at www.TriolaStats.com\nTECH CENTER\n",
    "13-5 Kruskal-Wallis Test for Three or More Samples \n591\nUsing the Kruskal-Wallis Test. In Exercises 5–8, use the Kruskal-Wallis test.\n5. Chest Injury in a Car Crash Use the following listed chest deceleration measurements (in \ng, where g is the force of gravity) from samples of small, midsize, and large cars. Use a 0.05 \nsignificance level to test the claim that the different size categories have the same median chest \ndeceleration in the standard crash test. Do the data suggest that larger cars are safer?\nSmall\n44\n39\n37\n54\n39\n44\n42\nMidsize\n36\n53\n43\n42\n52\n49\n41\nLarge\n32\n45\n41\n38\n37\n38\n33\n6. Femur Injury in a Car Crash Listed below are measured loads (in lb) on the left femur of \ncrash test dummies. Use a 0.05 significance level to test the null hypothesis that the different \ncar categories have the same median. Do these data suggest that larger cars are safer?\nSmall Cars\n548\n782\n1188\n 707\n324\n320\n634\n501\n274\n437\nMedium Cars\n194\n280\n1076\n 411\n617\n133\n719\n656\n874\n445\nLarge Cars\n215\n937\n 953\n1636\n937\n472\n882\n562\n656\n433\n7. Arsenic in Rice Listed below are amounts of arsenic in samples of brown rice from three \ndifferent states. The amounts are in micrograms of arsenic and all samples have the same serv-\ning size. The data are from the Food and Drug Administration. Use a 0.01 significance level to \ntest the claim that the three samples are from populations with the same median.\nArkansas\n4.8\n4.9\n5.0\n5.4\n5.4\n5.4\n5.6\n5.6\n5.6\n5.9\n6.0\n6.1\nCalifornia\n1.5\n3.7\n4.0\n4.5\n4.9\n5.1\n5.3\n5.4\n5.4\n5.5\n5.6\n5.6\nTexas\n5.6\n5.8\n6.6\n6.9\n6.9\n6.9\n7.1\n7.3\n7.5\n7.6\n7.7\n7.7\n8. Triathlon Times Jeff Parent is a statistics instructor who participates in triathlons. Listed be-\nlow are times (in minutes and seconds) he recorded while riding a bicycle for five laps through \neach mile of a 3-mile loop. Use a 0.05 significance level to test the claim that the samples are \nfrom populations with the same median. What do the data suggest?\nMile 1\n3:15\n3:24\n3:23\n3:22\n3:21\nMile 2\n3:19\n3:22\n3:21\n3:17\n3:19\nMile 3\n3:34\n3:31\n3:29\n3:31\n3:29\nAppendix B Data Sets. In Exercises 9–12, use the Kruskal-Wallis test with the data set  \nin Appendix B.\n9. Passive and Active Smoke Data Set 14 “Passive and Active Smoke” in Appendix B lists \nmeasured cotinine levels from a sample of subjects who smoke, another sample of subjects \nwho do not smoke but are exposed to environmental tobacco smoke, and a third sample of sub-\njects who do not smoke and are not exposed to environmental tobacco smoke. Cotinine is pro-\nduced when the body absorbs nicotine. Use a 0.01 significance level to test the claim that the \nthree samples are from populations with the same median. What do the results suggest about a \nsmoker who argues that he absorbs as much nicotine as people who don’t smoke?\n10. IQ and Lead Exposure Refer to Data Set 8 “IQ and Lead” and use the measured perfor-\nmance IQ scores from the three different blood lead levels. Use a 0.05 significance level to test the \nclaim that the three categories of blood lead level have the same median performance IQ score.\n11. Nicotine in Cigarettes Refer to Data Set 15 “Cigarette Contents” in Appendix B and \nuse the amounts of nicotine (mg per cigarette) in the king-size cigarettes, the 100-mm men-\nthol cigarettes, and the 100-mm nonmenthol cigarettes. The king-size cigarettes are nonfil-\ntered, nonmenthol, and nonlight. The 100-mm menthol cigarettes are filtered and nonlight. The \n100-mm nonmenthol cigarettes are filtered and nonlight. Use a 0.05 significance level to test the \nclaim that the three categories of cigarettes yield the same median amount of nicotine. Given that \nonly the king-size cigarettes are not filtered, do the filters appear to make a difference?\n",
    "592 \nCHAPTER 13 Nonparametric Tests\n12. Tar in Cigarettes Refer to Data Set 15 “Cigarette Contents” in Appendix B and use the \namounts of tar (mg per cigarette) in the three categories of cigarettes described in Exercise 11. \nUse a 0.05 significance level to test the claim that the three categories of cigarettes yield the \nsame median amount of tar. Given that only the king-size cigarettes are not filtered, do the fil-\nters appear to make a difference?\n13-5 Beyond the Basics \n13. Correcting the H Test Statistic for Ties In using the Kruskal-Wallis test, there is a cor-\nrection factor that should be applied whenever there are many ties: Divide H by\n1 -\nΣT\nN3 - N\nFirst combine all of the sample data into one list, and then in that combined list, identify the \ndifferent groups of sample values that are tied. For each individual group of tied observations, \nidentify the number of sample values that are tied and designate that number as t, then calculate \nT = t3 - t. Next, add the T values to get ΣT. The value of N is the total number of observa-\ntions in all samples combined. Use this procedure to find the corrected value of H for Example 1 \nin this section on page 589. Does the corrected value of H differ substantially from the value \nfound in Example 1?\nKey Concept This section describes the nonparametric method of the rank correla-\ntion test, which uses ranks of paired data to test for an association between two vari-\nables. In Section 10-1, paired sample data were used to compute values for the linear \ncorrelation coefficient r, but in this section we use ranks as the basis for computing \nthe rank correlation coefficient rs. As in Chapter 10, we should begin an analysis of \npaired data by exploring with a scatterplot so that we can identify any patterns in the \ndata as well as outliers.\n13-6 \nRank Correlation\nDEFINITION\nThe rank correlation test (or Spearman’s rank correlation test) is a nonparametric \ntest that uses ranks of sample data consisting of matched pairs. It is used to test \nfor an association between two variables.\nWe use the notation rs for the rank correlation coefficient so that we don’t con-\nfuse it with the linear correlation coefficient r. The subscript s does not refer to a \nstandard deviation; it is used in honor of Charles Spearman (1863–1945), who origi-\nnated the rank correlation approach. In fact, rs is often called Spearman’s rank \ncorrelation coefficient. Key components of the rank correlation test are given in the \nfollowing Key Elements box, and the rank correlation procedure is summarized in \nFigure 13-5 on page 594.\n",
    "13-6 Rank Correlation \n593\nRank Correlation\nObjective\nCompute the rank correlation coefficient rs and use it to \ntest for an association between two variables. The null and \nalternative hypotheses are as follows:\nH0: rs = 0 (There is no correlation.)\nH1: rs ≠0 (There is a correlation.)\nNotation\nrs =  rank correlation coefficient for sample paired data \n(rs is a sample statistic)\nrs =  rank correlation coefficient for all the population \ndata (rs is a population parameter)\nn = number of pairs of sample data\nd =  difference between ranks for the two values within an \nindividual pair\nRequirements\n1. The paired data are a simple random sample.\n2. The data are ranks or can be converted to ranks.\nNote: Unlike the parametric methods of Section 10-1, \nthere is no requirement that the sample pairs of data have a \nbivariate normal distribution (as described in Section 10-1). \nThere is no requirement of a normal distribution for any \npopulation.\nTest Statistic\nWithin each sample, first convert the data to ranks, then \nfind the exact value of the rank correlation coefficient rs by \nusing Formula 10-1:\nKEY ELEMENTS \nFORMULA 10-1\nrs =\nn1Σxy2 - 1Σx21Σy2\n2n1Σx22 - 1Σx2 22n1Σy22 - 1Σy2 2\nFORMULA 13-1\nrs =\n{z\n2n - 1\n 1critical values for n 7 302\nSimpler Test Statistic if There Are No Ties: After con-\nverting the data in each sample to ranks, if there are no \nties among ranks for the first variable and there are no ties \namong ranks for the second variable, the exact value of the \ntest statistic can be calculated using Formula 10-1 or with \nthe following relatively simple formula, but it is probably \neasier to use Formula 10-1 with technology:\nrs = 1 -\n6Σd2\nn1n2 - 12\nP-Values\nP-values are sometimes provided by technology, but use them only if they result from Spearman’s rank correlation. (Do \nnot use P-values resulting from tests of linear correlation; see the “caution” on the top of page 595.)\nCritical Values\n1. If n … 30, critical values are found in Table A-9.\nwhere the value of z corresponds to the significance level. \n(For example, if a = 0.05, z = 1.96.)\n2. If n 7 30, critical values of rs are found  \nusing Formula 13-1.\n",
    "594 \nCHAPTER 13 Nonparametric Tests\nYes\nYes\nNo\nYes\nNo\nNo\nStart\nDoes either variable\nhave ties among \nits ranks?\nCalculate rs using  Formula 10-1 with\nthe ranks:\nrs 5\nnΣxy – (Σx) (Σy) \nÏn(Σx2) – (Σx)2 Ïn(Σy2) – (Σy)2\nFind the negative and\npositive  critical values\nof rs from  Table A-9.\nCalculate the diﬀerence d for each pair \nof ranks by subtracting the lower rank\nfrom the higher rank.\nSquare each diﬀerence d and then ﬁnd \nthe sum of those squares to get Σ(d2).\n• If rs is between the negative and positive critical values, fail to reject the null\n \nhypothesis rs 5 0 (no correlation).\n• If rs is not between the negative and positive critical values, reject the null hypothesis\n rs 5 0 and conclude that there is suﬃcient evidence to support a claim of a correlation.\nAre the n pairs of\ndata in the form of \nranks?\nCalculate the\ncritical values\nwhere z\ncorresponds\nto the\nsigniﬁcance level.\nIs n ◊ 30?\nComplete the computation of\nto get the test statistic.\nrs 5 1 2\n6Σd 2\nn(n2 – 1)\nrs 5 6\nÏn  – 1\nz\nConvert the data of the ﬁrst sample to \nranks from 1 to n and then do the same \nfor the second sample.\nFIGURE 13-5 Rank Correlation Procedure for Testing H0: Rs = 0\n",
    "13-6 Rank Correlation \n595\nAdvantages of Rank Correlation Rank correlation has these advantages over the \nparametric methods discussed in Chapter 10:\n1. Rank correlation can be used with paired data that are ranks or can be converted \nto ranks. Unlike the parametric methods of Chapter 10, the method of rank  \ncorrelation does not require a normal distribution for any population.\n2. Rank correlation can be used to detect some (not all) relationships that are \nnot linear.\nDisadvantage of Rank Correlation: Efficiency A minor disadvantage of rank \ncorrelation is its efficiency rating of 0.91, as described in Section 13-1. This efficiency \nrating shows that with all other circumstances being the same, the nonparametric ap-\nproach of rank correlation requires 100 pairs of sample data to achieve the same results \nas only 91 pairs of sample observations analyzed through the parametric approach, \nassuming that the stricter requirements of the parametric approach are met.\nCAUTION Do not use P-values from linear correlation for methods of  rank \ncorrelation. When working with data having ties among ranks, the rank correlation \ncoefficient rs can be calculated using Formula 10-1. Technology can be used \ninstead of manual calculations with Formula 10-1, but the displayed P-values from \nlinear correlation do not apply to the methods of rank correlation.\nEXAMPLE 1  Bacteria Growth\nAn experiment involves a growing population of bacteria. Table 13-6 lists randomly \nselected times (in hr) after the experiment is begun and the number of bacteria \npresent. Use a 0.05 significance level to test the claim that there is a correlation  \nbetween time and population size.\nSOLUTION\nREQUIREMENT CHECK The data are a simple random sample and can be converted  \nto ranks. \nThe null and alternative hypotheses are as follows:\nH0\n :  rs = 0 1no correlation2\nH1\n :  rs ≠0 1correlation2\nWe follow the rank correlation procedure summarized in Figure 13-5. The original \nvalues are not ranks, so we convert them to ranks and enter the results in Table 13-7. \n(Section 13-1 describes the procedure for converting scores into ranks.) \ncontinued\nDirect Link Between \nSmoking and Cancer\nWhen we find a \nstatistical cor-\nrelation between \ntwo variables, \nwe must be \nextremely \ncareful to avoid \nthe mistake of concluding that \nthere is a cause-effect link. The \ntobacco industry has consistently \nemphasized that correlation \ndoes not imply causality as they \ndenied that tobacco products \ncause cancer. However, Dr. David \nSidransky of Johns Hopkins \nUniversity and other researchers \nfound a direct physical link that \ninvolves mutations of a specific \ngene among smokers. Molecu-\nlar analysis of genetic changes \nallows researchers to determine \nwhether cigarette smoking is the \ncause of a cancer. (See “Associa-\ntion Between Cigarette Smoking \nand Mutation of the p53 Gene in \nSquamous-Cell Carcinoma of the \nHead and Neck,” by Brennan, \nBoyle, et al., New England  \nJournal of Medicine, Vol 332,  \nNo. 11.) Although statistical \nmethods cannot prove that \nsmoking causes cancer, statisti-\ncal methods can be used to iden-\ntify an association, and physical \nproof of causation can then be \nsought by researchers.\nTABLE 13-6 Number of Bacteria in a Growing Population\nTime (hours)\n6\n107\n109\n125\n126\n128\n133\n143\n177\n606\nPopulation Size\n2\n  3\n  4\n 10\n 16\n 29\n 35\n 38\n 41\n 45\nTABLE 13-7 Ranks from Table 13-6\nRanks of Times\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\nRanks of Populations\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\nDifference d\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\nd2\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n",
    "596 \nCHAPTER 13 Nonparametric Tests\nThere are no ties among the ranks for the times, nor are there ties among the ranks for \npopulation size, so we find the differences, d, then square them. Next we find the sum \nof the d2 values, which is 0 in this case. We now calculate the value of the test statistic:\n rs = 1 -\n6Σd2\nn1n2 - 12 = 1 -\n6102\n101102 - 12\n = 1 -\n0\n990 = 1\nWith n = 10, we use Table A-9 to get the critical values of {0.648. Finally, the \ntest statistic of rs = 1 is not between -0.648 and 0.648, so we reject the null \nhypothesis of rs = 0. There is sufficient evidence to support the claim that for bac-\nteria, there is a correlation between time and population size.\nDetecting a Nonlinear Pattern In Example 1, if we test for a linear correlation using \nthe methods of Section 10-1, we get a test statistic of r = 0.621 and critical values of \n-0.632 and 0.632, so we conclude that there is not sufficient evidence to support a claim \nof a linear correlation between time and population size. If we examine the accompanying \nscatterplot, we can see that the pattern of points is not a straight-line pattern. Example 1 \nillustrates this advantage of the nonparametric approach over the parametric approach:\nWith rank correlation, we can sometimes detect relationships that are \nnot linear.\nNonlinear Pattern\nEXAMPLE 2  Large Sample Case \nRefer to the measured systolic and diastolic blood pressure measurements of 147 \nrandomly selected females in Data Set 1 “Body Data” in Appendix B and use a 0.05 \nsignificance level to test the claim that among women, there is a correlation between \nsystolic blood pressure and diastolic blood pressure.\nSOLUTION\nREQUIREMENT CHECK The data are a simple random sample and can be converted to \nranks. \nTest Statistic The value of the rank correlation coefficient is rs = 0.354, which can \nbe found by using technology.\nCritical Values Because there are 147 pairs of data, we have n = 147. Because \nn exceeds 30, we find the critical values from Formula 13-1 instead of Table A-9. \nWith a = 0.05 in two tails, we let z = 1.96 to get the critical values of -0.162 and \n0.162, as shown below.\nrs =\n{z\n2n - 1\n=\n{1.96\n2147 - 1\n= {0.162\nThe test statistic of rs = 0.354 is not between the critical values of -0.162 and \n0.162, so we reject the null hypothesis of rs = 0. There is sufficient evidence to \nsupport the claim that among women, there is a correlation between systolic blood \npressure and diastolic blood pressure.\nRank Correlation\nAccess tech instructions, videos, and data sets at www.TriolaStats.com\nTECH CENTER\n",
    "13-6 Rank Correlation \n597\nStatistical Literacy and Critical Thinking\n1. Regression If the methods of this section are used with paired sample data, and the conclu-\nsion is that there is sufficient evidence to support the claim of a correlation between the two \nvariables, can we use the methods of Section 10-2 to find the regression equation that can be \nused for predictions? Why or why not?\n2. Level of Measurement Which of the levels of measurement (nominal, ordinal, interval, \nratio) describe data that cannot be used with the methods of rank correlation? Explain.\n3. Notation What do r, rs, r, and rs denote? Why is the subscript s used? Does the subscript s \nrepresent the same standard deviation s introduced in Section 3-2?\n4. Efficiency Refer to Table 13-1 on page 563 and identify the efficiency of the rank correla-\ntion test. What does that value tell us about the test?\nIn Exercises 5 and 6, use the scatterplot to find the value of the rank correlation coefficient \nrs and the critical values corresponding to a 0.05 significance level used to test the null  \nhypothesis of Rs = 0. Determine whether there is a correlation.\n13-6  Basic Skills and Concepts \n5. Ages and Heights of Trees \n6. Numbers of Waiting Patients and Patient Service Times\nTesting for Rank Correlation. In Exercises 7–10, use the rank correlation coefficient to \ntest for a correlation between the two variables. Use a significance level of A = 0.05.\n7. Crickets and Temperature The association between the temperature and the number of \ntimes a cricket chirps in 1 min was studied. Listed below are the numbers of chirps in 1 min \nand the corresponding temperatures in degrees Fahrenheit (based on data from The Song of \nInsects by George W. Pierce, Harvard University Press). Is there sufficient evidence to con-\nclude that there is a relationship between the number of chirps in 1 min and the temperature?\nChirps in 1 min\n 882\n1188\n1104\n 864\n1200\n1032\n 960\n 900\nTemperature (°F)\n69.7\n 93.3\n 84.3\n76.3\n 88.6\n 82.6\n71.6\n79.6\n8. Measuring Seals from Photos Listed below are the overhead widths (in cm) of seals \nmeasured from photographs and the weights of the seals (in kg). The data are based on \n“Mass Estimation of Weddell Seals Using Techniques of Photogrammetry,” by R. Garrott of \nMontana State University. The purpose of the study was to determine if weights of seals could \nbe determined from overhead photographs. Is there sufficient evidence to conclude that there is \na correlation between overhead widths of seals from photographs and the weights of the seals?\nOverhead Width (cm)\n 7.2\n 7.4\n 9.8\n 9.4\n 8.8\n 8.4\nWeight (kg)\n116\n154\n245\n202\n200\n191\n",
    "598 \nCHAPTER 13 Nonparametric Tests\n9. Smoking and Nicotine When nicotine is absorbed by the body, cotinine is produced. \nA measurement of cotinine in the body is therefore a good indicator of how much a person \nsmokes. Listed below are the reported numbers of cigarettes smoked per day and the measured \namounts of nicotine (in ng>ml). (The values are from randomly selected subjects in the Na-\ntional Health Examination Survey.) Is there a significant linear correlation? Explain the result.\nx (cigarettes, day)\n 60\n 10\n   4\n 15\n 10\n   1\n 20\n   8\n   7\n  10\n 10\n 20\ny (cotinine)\n179\n283\n75.6\n174\n209\n9.51\n350\n1.85\n43.4\n25.1\n408\n344\n10. Tree Circumference and Height Listed below are the circumferences (in feet) and the \nheights (in feet) of trees in Marshall, Minnesota (based on data from “Tree Measurements,” by \nStanley Rice, American Biology Teacher, Vol. 61, No. 9). Is there a correlation?\nx (circ.)\n 1.8\n 1.9\n 1.8\n 2.4\n 5.1\n 3.1\n 5.5\n 5.1\n 8.3\n13.7\n 5.3\n 4.9\n 3.7\n 3.8\ny (ht.)\n21.0\n33.5\n24.6\n40.7\n73.2\n24.9\n40.4\n45.3\n53.5\n93.8\n64.0\n62.7\n47.2\n44.3\nAppendix B Data Sets. In Exercises 11–14, use the data in Appendix B to test for rank \ncorrelation with a 0.05 significance level.\n11. Blood Pressure Refer to the measured systolic and diastolic blood pressure measure-\nments of 153 randomly selected males in Data Set 1 “Body Data” in Appendix B and use a \n0.05 significance level to test the claim that among men, there is a correlation between systolic \nblood pressure and diastolic blood pressure.\n12. IQ and Brain Volume Refer to Data Set 9 “IQ and Brain Size” in Appendix B and test for \na correlation between brain volume (cm3) and IQ score.\n13. Chest Sizes and Weights of Bears Refer to Data Set 11 “Bear Measurements” in \nAppendix B and test for a correlation between chest sizes and weights of bears.\n14. Head Lengths and Neck Sizes of Bears Refer to Data Set 11 “Bear Measurements” in \nAppendix B and test for a correlation between head lengths and neck sizes of bears.\n15. Finding Critical Values An alternative to using Table A–9 to find critical values for rank \ncorrelation is to compute them using this approximation:\nrs = {B\nt2\nt2 + n - 2\nHere, t is the critical t value from Table A-3 corresponding to the desired significance level and \nn - 2 degrees of freedom. Use this approximation to find critical values of rs for Exercise 11 \n“Blood Pressure.” How do the resulting critical values compare to the critical values that would \nbe found by using Formula 13-1 on page 593?\n13-6 Beyond the Basics \n1. Cell Phone Radiation Some of the nonparametric methods in this chapter use ranks of \ndata. Find the ranks corresponding to these measured cell phone radiation absorption rates \n(in W>kg): 1.18, 1.41, 1.49, 1.04, 1.45, 0.74, 0.89, 1.42, 1.45, 0.51, 1.38.\n2. Efficiency What does it mean when we say that the rank correlation test has an efficiency \nrating of 0.91 when compared to the parametric test for linear correlation?\nChapter Quick Quiz\n",
    "3. Nonparametric Tests\na. Which of the following terms is sometimes used instead of “nonparametric test”: normality \ntest; abnormality test; distribution-free test; last testament; test of patience?\nb. Why is the term that is the answer to part (a) better than “nonparametric test”?\n4. Foot Length, Height Listed below are foot lengths (cm) and heights (cm) of males from \nData Set 7 “Foot and Height” in Appendix B. Which method of nonparametric statistics should \nbe used? What characteristic of the data is investigated with this test?\nFoot Length\n 27.8\n 25.7\n 26.7\n 25.9\n 26.4\n 29.2\n 26.8\n 28.1\n 25.4\n 27.9\nHeight\n180.3\n175.3\n184.8\n177.8\n182.3\n185.4\n180.3\n175.3\n177.8\n185.4\n5. Foot Length, Height When analyzing the paired data in Exercise 4, are the P-values and \nconclusions from the nonparametric test and the parametric test always the same?\n6. Foot Length, Height For the sample data given in Exercise 4, identify at least one advan-\ntage of using the appropriate nonparametric test over the parametric test.\n7. Sign Test and Wilcoxon Signed-Ranks Test What is a major advantage of the Wilcoxon \nsigned-ranks test over the sign test when analyzing data consisting of matched pairs?\n8. Which Test? Three different physicians each rank the quality of 10 different medical stu-\ndent diagnoses. What method of this chapter can be used to test for agreement among the three \nphysicians?\n9. Which Test? Given the following configurations of sample data, identify the one that can \nbe used with the Wilcoxon rank-sum test: one sample of individual values; two independent \nsamples; four independent samples; matched pairs.\n10.  Which Test? Given the following configurations of sample data, identify the one that \ncan be used with the Wilcoxon signed-ranks test: two independent samples; four independent \nsamples; matched pairs.\nUsing Nonparametric Tests. In Exercises 1–8, use a 0.05 significance level with the  \nindicated test. If no particular test is specified, use the appropriate nonparametric test from \nthis chapter.\n1. Internet or Doctor In a survey of 2015 adults, 1108 said that they obtain medical informa-\ntion more often from the Internet than a doctor (based on a Merck survey). Test the claim that \nthe majority of adults obtain medical information more often from the Internet than a doctor.\n2. Patient Wait Times In a study of times (min) patients wait before checking in for a physi-\ncal, the following random sample of times was collected. Use the sign test to test the claim that \nthe sample is from a population with a median equal to 5 min. Use a 0.05 significance level.\n5 8 3 8 6 10 3 7 9 8 5 5 6 8 8 7 3 5 5 6 8 7 8 8 8 7\n3. Patient Wait Times Repeat the preceding exercise using the Wilcoxon signed-ranks test.\n4. Longevity of Presidents, Popes, Monarchs Listed on the top of the next page are num-\nbers of years that U.S. presidents, popes, and British monarchs lived after their inauguration, \nelection, or coronation, respectively. Assume that the data are samples randomly selected from \nlarger populations. Test the claim that the three samples are from populations with the same \nmedian.\nReview Exercises\nCHAPTER 13 Review Exercises \n599\n",
    "600 \nCHAPTER 13 Nonparametric Tests\nPresidents\n10\n29\n26\n28\n15\n23\n17\n25\n 0\n20\n 4\n 1\n24\n16\n12\n 4\n10\n17\n16\n 0\n 7\n24\n12\n 4\n18\n21\n11\n 2\n 9\n36\nPopes\n12\n28\n 3\n16\n 9\n25\n23\n32\n 2\n 9\n21\n 3\n 6\n10\n18\n11\n 6\n25\n23\n 6\n 2\n15\n32\n25\n11\n 8\n17\n19\n 5\n15\n 0\n26\nMonarchs\n17\n 6\n13\n12\n13\n33\n59\n10\n 7\n63\n 9\n25\n36\n15\n5. Chocolate Diet for a Nobel Prize The table below lists chocolate consumption (kg per \ncapita) and the numbers of Nobel Laureates (per 10 million people) for several different coun-\ntries. Is there a correlation between chocolate consumption and the rate of Nobel Laureates? \nHow could such a correlation be explained?\nChocolate\n11.6\n2.5\n 8.8\n3.7\n1.8\n 4.5\n 9.4\n3.6\n2.0\n3.6\n 6.4\nNobel\n12.7\n1.9\n12.7\n3.3\n1.5\n11.4\n25.5\n3.1\n1.9\n1.7\n31.9\n6. Skull Breadths and Archeology Listed below are skull breadths obtained from skulls of \nEgyptian males from three different epochs (based on data from Ancient Races of the Thebaid, \nby Thomson and Randall-Maciver). Test the claim that the samples are from populations with \nthe same median. Changes in head shape over time suggest that interbreeding occurred with \nimmigrant populations. Is interbreeding of cultures suggested by the data?\n4000 B.C.\n125\n129\n131\n132\n132\n134\n135\n138\n138\n1850 B.C.\n129\n129\n134\n134\n136\n137\n137\n138\n136\nA.D. 150\n128\n136\n137\n137\n138\n139\n141\n142\n145\n7. Skull Breadths and Archeology Refer to the preceding exercise and use only the skull \nbreadths from 4000 B.C. and A.D. 150. Use the Wilcoxon rank-sum test to test the claim that \nthe two samples are from populations with the same median.\n8. Student and U.S. News & World Report Rankings of Colleges Each year, U.S. News \n& World Report publishes rankings of colleges based on statistics such as admission rates, \ngraduation rates, class size, faculty–student ratio, faculty salaries, and peer ratings of adminis-\ntrators. Economists Christopher Avery, Mark Glickman, Caroline Minter Hoxby, and Andrew \nMetrick took an alternative approach of analyzing the college choices of 3240 high-achieving \nschool seniors. They examined the colleges that offered admission along with the colleges that \nthe students chose to attend. The table below lists rankings for a small sample of colleges. Find \nthe value of the rank correlation coefficient and use it to determine whether there is a correla-\ntion between the student rankings and the rankings of the magazine.\nStudent ranks\n1\n2\n3\n4\n5\n6\n7\n8\nU.S. News & World Report ranks\n1\n2\n5\n4\n7\n6\n3\n8\nIn Exercises 1–5, use the data listed below. The values are the numbers of credit hours taken \nin the current semester by full-time biostatistics students. The data are from students in one \nclass of one of the authors.\n15 15 13 16 12 15 18 16 15 14 16 15 17 12 15 15 14 14 12 12\n1. Descriptive Statistics Find the mean, median, standard deviation, variance, and range of the \nsample data. Given that the data are in credit hours, include the appropriate units in the results.\n2. Sampling and Data Type\na. Which of the following best describes the sample: simple random sample, voluntary re-\nsponse sample, convenience sample?\nCumulative Review Exercises\n",
    "b. Is it likely that the sample is representative of the population of all full-time college students?\nc. Are the data discrete or continuous?\nd. What is the level of measurement of the data (nominal, ordinal, interval, ratio)?\n3. Credit Hours: Hypothesis Test Use the given data to test the claim that the sample is from \na population with a mean greater than 14 credit hours.\n4. Credit Hours: Sign Test Use the given data to test the claim that the sample is from a popu-\nlation with a median greater than 14 credit hours. Use the sign test with a 0.05 significance level.\n5. Credit Hours: Confidence Interval Use the data to construct a 95% confidence interval \nestimate of the number of credit hours taken by the population of full-time students. Write a \nbrief statement that interprets the result.\n6. Drug Tests There is a 3.9% rate of positive drug test results among workers in the United \nStates (based on data from Quest Diagnostics). Assuming that this statistic is based on a sample \nof size 2000, construct a 95% confidence interval estimate of the percentage of positive drug \ntest results. Write a brief statement that interprets the confidence interval.\n7. Drug Tests Use the data from the preceding exercise and test the claim that the rate of \npositive drug test results among workers in the United States is greater than 3.0%. Use a 0.05 \nsignificance level.\n8. Sample Size Advances in technology are dramatically affecting different aspects of our \nlives. Many people now use the Internet for medical advice before seeing a physician. To help \naddress such issues, we want to estimate the percentage of adults in the United States who use \na computer at least once each day. Find the sample size needed to estimate that percentage. As-\nsume that we want 95% confidence that the sample percentage is within two percentage points \nof the true population percentage.\n9. Fear of Heights Among readers of a USA Today website, 285 chose to respond to this \nposted question: “Are you afraid of heights in tall buildings?” Among those who chose to re-\nspond, 46% answered “yes” and 54% answered “no.” Use a 0.05 significance level to test the \nclaim that the majority of the population is not afraid of heights in tall buildings. What is wrong \nwith this hypothesis test?\n10.  Cell Phones and Crashes: Analyzing Newspaper Report In an article from the \nAssociated Press, it was reported that researchers “randomly selected 100 New York motorists \nwho had been in an accident and 100 who had not been in an accident. Of those in accidents, \n13.7 percent owned a cellular phone, while just 10.6 percent of the accident-free drivers had a \nphone in the car.” What is wrong with these results?\nMethods of gender selection can be tested in experiments that involve the treatment of parents \nand the subsequent analysis of generated offspring. Instead of actually generating offspring, \nwe will use technology to simulate their generation. Use SPSS, SAS, Statdisk, Minitab, Excel, \na TI–83>84 Plus calculator, or any other technology to randomly generate 1000 values, each \nof which is 0 or 1. (Refer to the Chapter 4 Technology Project on pages 177–178 for the sum-\nmary of simulation functions.) Representing boys by 1 and girls by 0, we have a simulated \nsample of 1000 offspring. We can then use the sign test to determine whether boys and girls are \nequally likely. In this case, we are actually testing the technology for a bias in favor of either 0s \nor 1s. Generate the 1000 values, then use the sign test to analyze the results. Does the technol-\nogy appear to have a bias? Could you detect a bias using larger sample sizes?\nTechnology Project\nCHAPTER 13 Technology Project \n601\n",
    "602 \nCHAPTER 13 Nonparametric Tests\nFROM DATA TO DECISION\nCritical Thinking: Does geographic location affect \nbirth weights?\nData Set 3 “Births” in Appendix B lists birth weights from \nfour different hospitals with very different geographic loca-\ntions in New York State. We want to investigate an effect of \ngeographic location on birth weights.\nAnalysis\n• Which nonparametric test applies?\n• Identify the requirements for the appropriate nonparametric \ntest and determine if they are satisfied.\n• Apply the test and state conclusions.\nCooperative Group Activities\n1. In-class activity Divide into groups of 8 to 12 people. For each group member, measure his \nor her height and measure his or her arm span. For the arm span, the subject should stand with \narms extended, like the wings on an airplane. Divide the following tasks among subgroups of \nthree or four people.\na. Use rank correlation with the paired sample data to determine whether there is a correlation \nbetween height and arm span.\nb. Use the sign test to test for a difference between the two variables.\nc. Use the Wilcoxon signed-ranks test to test for a difference between the two variables.\n2. In-class activity Do Activity 1 using pulse rate instead of arm span. Measure pulse rates by \ncounting the number of heartbeats in 1 minute.\n3. Out-of-class activity Divide into groups of three or four students. Investigate the relation-\nship between two variables by collecting your own paired sample data and using the methods \nof Section 13-6 to determine whether there is a correlation. Suggested topics:\n• Is there a correlation between the lengths of men’s (or women’s) feet and their heights?\n• Is there a correlation between heights of fathers (or mothers) and heights of their first sons \n(or daughters)?\n4. Out-of-class activity Divide into groups of three or four. Survey other students by asking \nthem to identify their major and gender. For each surveyed subject, determine the number of \nTwitter followers or Facebook friends. Use the sample data to address these questions:\n• Do the numbers of Twitter followers or Facebook friends appear to be the same for both genders?\n• Do the numbers of Twitter followers or Facebook friends appear to be the same for the differ-\nent majors?\n5. In-class activity Divide into groups of 8 to 12 people. For each group member, measure \nthe person’s height and also measure his or her navel height, which is the height from the floor \nto the navel. Use the rank correlation coefficient to determine whether there is a correlation \nbetween height and navel height.\n6. In-class activity Divide into groups of three or four people. Appendix B includes many \ndata sets not yet addressed by the methods of this chapter. Search Appendix B for variables of \ninterest, then investigate using appropriate methods of nonparametric statistics. State your con-\nclusions and try to identify practical applications.\n",
    "603\nMedia often report clusters of diseases or deaths along with \nsuggestions that some underlying cause should be inves-\ntigated. For example, the Pittsburgh Post Gazette reported \nthat in 14 western Pennsylvania counties, there were 14,636 \nmore deaths from heart disease, respiratory disease, and lung \ncancer than would be expected under normal circumstances. \nMany residents suspect environmental pollution as a cause for \nthe cluster, but the presence of a cluster has not been estab-\nlished and questions remain.\nSuppose a different region has 5000 people who reach \ntheir 16th birthday and 25 of them die before their 17th birthday. \nParents, expressing understandable concern, claim that this \nnumber of deaths is significantly high and the causes of death \nshould be investigated as part of a comprehensive study. \nSurvival Analysis\nCHAPTER \nPROBLEM\nIs the Cluster of Deaths Significantly High?\nLife Tables\nKaplan-Meier Survival \nAnalysis\n14-1\n14-2\n14 \ncontinued\n",
    "Others suggest that the number of deaths of 16-year-olds \nwill naturally vary from year to year. Some years have fewer \ndeaths than average, while other years have disproportionately \ngreater numbers of deaths, so that the 25 deaths is no cause \nfor concern.\nHow do we objectively address this issue? One essential \npiece of information is the death rate for people in this age \ngroup. That rate can be extracted from a life table, which can \nbe very helpful in situations such as the one presented here. \nWe will consider the different components of a life table, and \nwe will use a specific and real life table to address the ques-\ntions raised above.\nCHAPTER OBJECTIVES\nHere are the main objectives of this chapter:\nLife Tables\n• Develop the ability to use a life table for the analysis of mortality and longevity data.\nKaplan-Meier Survival Analysis\n• Develop the ability to construct and interpret tables and graphs of survival data us-\ning the Kaplan-Meier method for determining the probability of survival over periods \nof time.\n14-1\n14-2\nHere are the main objectives of this chapter:\nLife Tables\n• Develop the ability to use a life table for the analysis of mortality and longevity data.\nKaplan-Meier Survival Analysis\n• Develop the ability to construct and interpret tables and graphs of survival data us-\ning the Kaplan-Meier method for determining the probability of survival over periods\nof time.\nLife tables are routinely developed by government agencies and private companies, \nand their use is critical to a variety of different fields. Studies of wildlife populations \noften involve life tables. Insurance companies could not provide life insurance poli-\ncies without the information contained in life tables. A “term” life insurance policy \nis essentially a bet that a person will live or die within a certain time period, and the \namount of the bet (cost of the policy or the premium amount) must reflect the prob-\nability that the subject will live or die within that time period. Many professionals \nmonitor the health of the United States population, and their analyses often involve \nlife tables as the basis for such comparisons. Other policy planners need to know how \nlong people are expected to live, so that they can satisfy their health and financial \nneeds. For example, employees in the United States typically have funds contributed \nto a large Social Security account maintained by the government. It is intended that \nthese funds be used to provide financial support when employees age and retire. How-\never, as people tend to live longer, the payments continue for longer periods of time, \nand careful planning is required to ensure that future generations will continue to en-\njoy the benefits of the Social Security system. Such careful planning requires accurate \ninformation about changes in longevity—information that is available in life tables. \nLife tables therefore become key tools in many different applications.\n 14-1 \nLife Tables\n604 \nCHAPTER 14 Survival Analysis\n",
    "14-1 Life Tables \n605\nLife tables include information about death rates and longevity, but there are dif-\nferent types of life tables. A cohort (or generation) life table is a record of the actual \nobserved mortality experience for a particular group, such as everyone born in the \nyear 1960. Because cohort life tables require complete data collected over periods \nspanning decades of time, they aren’t very practical and are not commonly used. The \nmain focus of this section will be period life tables. In subsequent references to life \ntables, it is assumed that we are referring to period life tables defined as follows.\nDEFINITION\nA period (or current) life table describes mortality and longevity data for a  \nhypothetical (or “synthetic”) cohort, with the data computed with this assumption:\nThe conditions aﬀecting mortality in a particular basis year (such as 2010)  \nremain the same throughout the lives of everyone in the hypothetical cohort.\nA period life table shows the long-term results of mortality conditions that were \npresent during the particular basis year.\nTable 14-1 on the following two pages is an example of a period life table. Because \nTable 14-1 is a period life table for the United States for the year 2010, we know that it \nwas constructed with this important assumption: The death rates for the various age groups \nthat were in effect in the year 2010 continue to remain in effect during the entire lives of \nthe 100,000 hypothetical people assumed to be present at age 0. That is, we pretend that a \npopulation of 100,000 people is born in the year 2010, and they each live their entire lives \nin a world with the same constant death rates that were present in the year 2010.\nTable 14-1 was provided by the National Center for Health Statistics, and it is \nbased on actual data from the U.S. Census Bureau (for population estimates), the \nMedicare program (a government program providing financial support for health \ncare), and death certificates issued in different states. Actual mortality data were col-\nlected, but they were then used to describe the experience of 100,000 hypothetical \npeople.\nTable 14-1 describes 100,000 hypothetical people who are representative of the \ntotal population of the United States, including males and females of various races. \nBecause mortality experiences can be very different for various gender and race \ngroups, it is common to have tables for specific subgroups. As of this writing, pe-\nriod life tables were available for males, females, whites, white males, white females, \nblacks, black males, and black females. We do not provide these other tables, but they \nshould be used in place of Table 14-1 when appropriate. For example, if calculating \nthe cost of a term life insurance policy for a 19-year-old white male, more accurate \ninformation could be obtained from the period life table for white males than from \nTable 14-1, which includes the entire population.\n",
    "TABLE 14-1 Life Table for Total Population: U.S., 2010\n \n \n \n \nAge Interval\n \nProbability of \nDying  \nDuring the  \nInterval\n \nNumber  \nSurviving to  \nthe Beginning  \nof the Interval\n \n \nNumber of  \nDeaths During \nthe Interval\nPerson-Years Lived  \n(total time lived during  \nthe interval by those  \nalive at the beginning  \nof the interval)\nTotal Person-\nYears Lived  \n(in this and all \nsubsequent  \nintervals)\n \nExpected Remaining  \nLifetime (from the  \nbeginning of  \nthe interval)\n0–1\n0.006123\n100,000\n612\n99,465\n7,866,027\n78.7\n1–2\n0.000428\n99,388\n 43\n99,366\n7,766,561\n78.1\n2–3\n0.000275\n99,345\n 27\n99,331\n7,667,195\n77.2\n3–4\n0.000211\n99,318\n 21\n99,307\n7,567,864\n76.2\n4–5\n0.000158\n99,297\n 16\n99,289\n7,468,556\n75.2\n5–6\n0.000145\n99,281\n 14\n99,274\n7,369,267\n74.2\n6–7\n0.000128\n99,267\n 13\n99,260\n7,269,993\n73.2\n7–8\n0.000114\n99,254\n 11\n99,249\n7,170,733\n72.2\n8–9\n0.000100\n99,243\n 10\n99,238\n7,071,484\n71.3\n9–10\n0.000087\n99,233\n  9\n99,229\n6,972,246\n70.3\n10–11\n0.000079\n99,224\n  8\n99,220\n6,873,017\n69.3\n11–12\n0.000086\n99,216\n  9\n99,212\n6,773,797\n68.3\n12–13\n0.000116\n99,208\n 12\n99,202\n6,674,585\n67.3\n13–14\n0.000175\n99,196\n 17\n99,188\n6,575,383\n66.3\n14–15\n0.000252\n99,179\n 25\n99,167\n6,476,195\n65.3\n15–16\n0.000333\n99,154\n 33\n99,138\n6,377,028\n64.3\n16–17\n0.000412\n99,121\n 41\n99,101\n6,277,891\n63.3\n17–18\n0.000492\n99,080\n 49\n99,056\n6,178,790\n62.4\n18–19\n0.000573\n99,032\n 57\n99,003\n6,079,734\n61.4\n19–20\n0.000655\n98,975\n 65\n98,942\n5,980,731\n60.4\n20–21\n0.000744\n98,910\n 74\n98,873\n5,881,789\n59.5\n21–22\n0.000829\n98,836\n 82\n98,795\n5,782,916\n58.5\n22–23\n0.000892\n98,754\n 88\n98,710\n5,684,120\n57.6\n23–24\n0.000925\n98,666\n 91\n98,621\n5,585,410\n56.6\n24–25\n0.000934\n98,575\n 92\n98,529\n5,486,789\n55.7\n25–26\n0.000936\n98,483\n 92\n98,437\n5,388,260\n54.7\n26–27\n0.000943\n98,391\n 93\n98,344\n5,289,824\n53.8\n27–28\n0.000953\n98,298\n 94\n98,251\n5,191,479\n52.8\n28–29\n0.000971\n98,204\n 95\n98,157\n5,093,228\n51.9\n29–30\n0.000998\n98,109\n 98\n98,060\n4,995,071\n50.9\n30–31\n0.001029\n98,011\n101\n97,961\n4,897,011\n50.0\n31–32\n0.001063\n97,910\n104\n97,858\n4,799,051\n49.0\n32–33\n0.001099\n97,806\n108\n97,752\n4,701,193\n48.1\n33–34\n0.001137\n97,699\n111\n97,643\n4,603,440\n47.1\n34–35\n0.001180\n97,587\n115\n97,530\n4,505,797\n46.2\n35–36\n0.001235\n97,472\n120\n97,412\n4,408,267\n45.2\n36–37\n0.001302\n97,352\n127\n97,289\n4,310,855\n44.3\n37–38\n0.001377\n97,225\n134\n97,158\n4,213,567\n43.3\n38–39\n0.001461\n97,091\n142\n97,020\n4,116,408\n42.4\n39–40\n0.001557\n96,949\n151\n96,874\n4,019,388\n41.5\n40–41\n0.001663\n96,798\n161\n96,718\n3,922,514\n40.5\n41–42\n0.001793\n96,637\n173\n96,551\n3,825,796\n39.6\n42–43\n0.001962\n96,464\n189\n96,370\n3,729,245\n38.7\n43–44\n0.002177\n96,275\n210\n96,170\n3,632,875\n37.7\n44–45\n0.002423\n96,065\n233\n95,949\n3,536,705\n36.8\n45–46\n0.002676\n95,833\n256\n95,704\n3,440,756\n35.9\n46–47\n0.002931\n95,576\n280\n95,436\n3,345,052\n35.0\n47–48\n0.003205\n95,296\n305\n95,143\n3,249,616\n34.1\n48–49\n0.003505\n94,990\n333\n94,824\n3,154,473\n33.2\n49–50\n0.003830\n94,658\n363\n94,476\n3,059,649\n32.3\n50–51\n0.004177\n94,295\n394\n94,098\n2,965,173\n31.4\n",
    "From National Vital Statistics Reports, U.S. Department of Health and Human Services.\n \n \n \n \nAge Interval\n \nProbability of \nDying  \nDuring the  \nInterval\n \nNumber  \nSurviving to  \nthe Beginning  \nof the Interval\n \n \nNumber of  \nDeaths During \nthe Interval\nPerson-Years Lived  \n(total time lived during  \nthe interval by those  \nalive at the beginning  \nof the interval)\nTotal Person-\nYears Lived  \n(in this and all \nsubsequent  \nintervals)\n \nExpected Remaining  \nLifetime (from the  \nbeginning of  \nthe interval)\n51–52\n0.004535\n93,901\n426\n93,688\n2,871,075\n30.6\n52–53\n0.004903\n93,475\n458\n93,246\n2,777,386\n29.7\n53–54\n0.005284\n93,017\n491\n92,771\n2,684,140\n28.9\n54–55\n0.005684\n92,526\n526\n92,263\n2,591,369\n28.0\n55–56\n0.006117\n92,000\n563\n91,718\n2,499,106\n27.2\n56–57\n0.006589\n91,437\n603\n91,136\n2,407,388\n26.3\n57–58\n0.007095\n90,834\n644\n90,512\n2,316,253\n25.5\n58–59\n0.007626\n90,190\n688\n89,846\n2,225,741\n24.7\n59–60\n0.008180\n89,502\n732\n89,136\n2,135,895\n23.9\n60–61\n0.008767\n88,770\n778\n88,381\n2,046,759\n23.1\n61–62\n0.009397\n87,992\n827\n87,578\n1,958,378\n22.3\n62–63\n0.010085\n87,165\n879\n86,725\n1,870,800\n21.5\n63–64\n0.010863\n86,286\n937\n85,817\n1,784,075\n20.7\n64–65\n0.011758\n85,348\n1,004\n84,847\n1,698,258\n19.9\n65–66\n0.012810\n84,345\n1,080\n83,805\n1,613,411\n19.1\n66–67\n0.014011\n83,264\n1,167\n82,681\n1,529,606\n18.4\n67–68\n0.015290\n82,098\n1,255\n81,470\n1,446,925\n17.6\n68–69\n0.016601\n80,843\n1,342\n80,172\n1,365,455\n16.9\n69–70\n0.018005\n79,501\n1,431\n78,785\n1,285,283\n16.2\n70–71\n0.019548\n78,069\n1,526\n77,306\n1,206,499\n15.5\n71–72\n0.021294\n76,543\n1,630\n75,728\n1,129,192\n14.8\n72–73\n0.023275\n74,913\n1,744\n74,041\n1,053,464\n14.1\n73–74\n0.025528\n73,169\n1,868\n72,236\n979,423\n13.4\n74–75\n0.028061\n71,302\n2,001\n70,301\n907,188\n12.7\n75–76\n0.030820\n69,301\n2,136\n68,233\n836,886\n12.1\n76–77\n0.033775\n67,165\n2,268\n66,031\n768,654\n11.4\n77–78\n0.037252\n64,896\n2,418\n63,688\n702,623\n10.8\n78–79\n0.041136\n62,479\n2,570\n61,194\n638,935\n10.2\n79–80\n0.045411\n59,909\n2,721\n58,549\n577,741\n9.6\n80–81\n0.050146\n57,188\n2,868\n55,754\n519,193\n9.1\n81–82\n0.055445\n54,321\n3,012\n52,815\n463,438\n8.5\n82–83\n0.061272\n51,309\n3,144\n49,737\n410,624\n8.0\n83–84\n0.067764\n48,165\n3,264\n46,533\n360,887\n7.5\n84–85\n0.075818\n44,901\n3,404\n43,199\n314,354\n7.0\n85–86\n0.085319\n41,497\n3,540\n39,727\n271,155\n6.5\n86–87\n0.094975\n37,956\n3,605\n36,154\n231,429\n6.1\n87–88\n0.105525\n34,351\n3,625\n32,539\n195,275\n5.7\n88–89\n0.117007\n30,726\n3,595\n28,929\n162,736\n5.3\n89–90\n0.129450\n27,131\n3,512\n25,375\n133,807\n4.9\n90–91\n0.142873\n23,619\n3,375\n21,932\n108,432\n4.6\n91–92\n0.157280\n20,245\n3,184\n18,653\n86,500\n4.3\n92–93\n0.172661\n17,061\n2,946\n15,588\n67,847\n4.0\n93–94\n0.188988\n14,115\n2,668\n12,781\n52,259\n3.7\n94–95\n0.206214\n11,447\n2,361\n10,267\n39,478\n3.4\n95–96\n0.224274\n9,087\n2,038\n8,068\n29,211\n3.2\n96–97\n0.243080\n7,049\n1,713\n6,192\n21,144\n3.0\n97–98\n0.262527\n5,335\n1,401\n4,635\n14,951\n2.8\n98–99\n0.282492\n3,935\n1,112\n3,379\n10,316\n2.6\n99–100\n0.302838\n2,823\n855\n2,396\n6,937\n2.5\n100 and over\n1.000000\n1,968\n1,968\n4,542\n4,542\n2.3\n",
    "608 \nCHAPTER 14 Survival Analysis\nComponents of a Period Life Table\nThe seven columns in the period life Table 14-1 are described as follows.\nColumn 1: Age Interval The first column of Table 14-1 lists age categories. The first cat-\negory of 0–1 represents the age interval from birth to the first birthday. Note that some of \nthe other columns are based on the age at the beginning of the age interval. For example, \nthe last column lists expected ages, which are the expected remaining lifetime amounts \nmeasured from the beginning of the age interval. For the age interval of 0–1, the ex-\npected remaining lifetime is 78.7, which means that a newborn has an expected lifetime \nof 78.7 years. Also note that the age intervals overlap with a common value used for the \nupper boundary of one class as well as the lower boundary for the following class. When \nwe discussed frequency distributions in Chapter 2, we noted that the class limits should \nnot overlap, but the overlapping is not an important issue with period life tables. It would \nbe a very rare event to have someone die on the exact instant of the beginning of their \nbirth date, so we need not make adjustments for this event that will likely never occur.\nColumn 2: Probability of Dying The second column lists the probabilities of dy-\ning during the age interval listed in the first column. The first row of values shows \nthat there is a 0.006123 probability of someone dying between birth and their first \nbirthday. The second row shows that there is a 0.000428 probability of someone dy-\ning between their first birthday and their second birthday. These probabilities of death \nreflect the death rates for the various age groups that were observed in the year 2010.\nColumn 3: Number Surviving The third column lists the number of people alive at \nthe beginning of the age interval. Note that the first row lists the size of our hypotheti-\ncal population (100,000), and this value shows that there were 100,000 hypothetical \npeople who were born and alive at the beginning of the age interval from 0 to 1 year. \nThis number decreases as some of the hypothetical people have hypothetical deaths. \nThe second row shows that among the 100,000 hypothetical people who were born, \n99,388 of them are alive on their first birthday. The values in column 3 can be com-\nputed by using the death rates in column 2. For example, the first age interval of 0–1 \nhas a death rate of 0.006123, so we expect that 612.3 of the 100,000 people alive at \nbirth will die, leaving a population of 100,000 - 612.3 = 99,388 (rounded) people \nalive at the beginning of the second age interval of 1–2.\nColumn 4: Number of Deaths The fourth column shows the number of people who \ndied during the age interval in the column at the left. This value can be computed \nby multiplying the number of people alive at the beginning of the age interval (col-\numn 3) by the probability of dying during the age interval (column 2). For example, \nthe first row shows that 100,000 people were present at age 0 and the death rate for \nthose in the age interval of 0–1 is 0.006123, so we expect the number of deaths to be: \n100,000 * 0.006123 = 612 (rounded).\nColumn 5: Person-Years Lived This column lists the total time (in years) lived dur-\ning the age interval by those who were alive at the beginning of the age interval. \nFor example, the first row in column 5 has an entry of 99,465 (years), and this value \nshows that the 100,000 people who were present at age 0 lived a total of 99,465 years. \nIf none of those people had died, this entry would have been 100,000 years, but some \nof them did die, so the total is less than 100,000 years.\nColumn 6: Total Person-Years Lived The sixth column is somewhat similar to the \nfifth column in the sense that it lists the total number of years lived by those present \nat the beginning of the age interval, but column 5 lists the number of years lived dur-\ning the age interval, whereas column 6 lists the number of years lived during the age \ninterval and all of the following age intervals as well.\n",
    "14-1 Life Tables \n609\nColumn 7: Expected Remaining Lifetime The last column lists the expected re-\nmaining lifetime (in years), measured from the beginning of the age interval. For ex-\nample, the first row shows that the expected remaining lifetime is 78.7 years, so the \naverage expected lifetime of the 100,000 newborn people is 78.7 years. Each value in \nthe seventh column can be computed by dividing the total person-years lived (column \n6) by the number of people who were present at the beginning of the age interval. For \nexample, the age interval of 1–2 has an expected remaining lifetime of 78.1 years, and \nthe total person-years lived (column 6) divided by the number of people present at the \nbeginning of the age interval (column 3) yields 7,766,561 , 99,388 = 78.1 (rounded). \nAgain, we should remember that this assumes that the same mortality conditions \npresent in the year 2010 remain constant throughout the lifetimes of the 100,000 \nhypothetical people. We should also remember that Table 14-1 describes the total \npopulation, and expected remaining lifetime values will be different for different sub-\ngroups of genders and races.\nNotation: More formal mathematical notation is often used for the above compo-\nnents. For example, the age intervals can be expressed in general form as “x to x + 1,” \nthe probability of dying during an interval is expressed as qx, the number alive at the \nbeginning of an interval is expressed as lx, the number dying in an interval is ex-\npressed as dx, and so on. Such notation makes it easier to develop formulas describ-\ning components of the period life table. For example, the formula dx = qx # lx shows \nthat the number of deaths in an interval is equal to the probability of dying during the \ninterval multiplied by the number alive at the beginning of the interval. Also, such \nnotation is commonly used to describe the columns of a period life table. In Table 14-1, \nfor example, the original government report labels the columns with headings such \nas “probability of dying between ages x and x + 1” and “person-years lived between \nages x and x + 1.” The use of this more formal notation is not necessary for the pur-\nposes of this section, but this notation is commonly used in some fields.\nAbridged Life Table\nTable 14-1 is sometimes referred to as a complete life table, because it lists a separate \nrow of data for each year. An abridged life table uses age intervals for time periods \nlonger than one year. Age intervals of 5 years or 10 years are common in an abridged \nlife table.\nDEFINITION\nAn abridged life table is a life table in which the age intervals have been com-\nbined, so the age intervals are longer than one year. Age intervals of 5 years or  \n10 years are common.\nTable 14-2 is an abridged life table that condenses Table 14-1 by using age intervals of \n5 years. Table 14-2 was constructed by using the values found in Table 14-1.\n",
    "610 \nCHAPTER 14 Survival Analysis\nTABLE 14-2 Abridged Life Table for Total Population: U.S., 2010\n \n \n \n \n \nAge Interval\n \n \n \nProbability of  \nDying During  \nthe Interval\n \n \n \nNumber Surviving  \nto the Beginning of \nthe Interval\n \n \n \nNumber of  \nDeaths During \nthe Interval\nPerson-Years Lived  \n(total time lived  \nduring the interval  \nby those alive at the  \nbeginning of the  \ninterval)\n \nTotal Person- \nYears Lived  \n(in this and all  \nsubsequent  \nintervals)\n \nExpected  \nRemaining \nLifetime (from  \nthe beginning of  \nthe interval)\n0–5\n0.007190\n100,000\n719\n496,759\n7,866,027\n78.7\n5–10\n0.000573\n99,281\n57\n496,250\n7,369,267\n74.2\n10–15\n0.000708\n99,224\n70\n495,989\n6,873,017\n69.3\n15–20\n0.002463\n99,154\n244\n495,240\n6,377,028\n64.3\n20–25\n0.004317\n98,910\n427\n493,529\n5,881,789\n59.5\n25–30\n0.004791\n98,483\n472\n491,249\n5,388,260\n54.7\n30–35\n0.005497\n98,011\n539\n488,744\n4,897,011\n50.0\n35–40\n0.006913\n97,472\n674\n485,753\n4,408,267\n45.2\n40–45\n0.009979\n96,798\n966\n481,758\n3,922,514\n40.5\n45–50\n0.016044\n95,833\n1,538\n475,584\n3,440,756\n35.9\n50–55\n0.024343\n94,295\n2,295\n466,066\n2,965,173\n31.4\n55–60\n0.035106\n92,000\n3,230\n452,347\n2,499,106\n27.2\n60–65\n0.049847\n88,770\n4,425\n433,348\n2,046,759\n23.1\n65–70\n0.074406\n84,345\n6,276\n406,912\n1,613,411\n19.1\n70–75\n0.112315\n78,069\n8,768\n369,612\n1,206,499\n15.5\n75–80\n0.174782\n69,301\n12,113\n317,694\n836,886\n12.1\n80–85\n0.274384\n57,188\n15,692\n248,038\n519,193\n 9.1\n85–90\n0.430820\n41,497\n17,878\n162,723\n271,155\n 6.5\n90–95\n0.615282\n23,619\n14,532\n 79,220\n108,432\n 4.6\n95–100\n0.783397\n 9,087\n7,119\n 24,670\n29,211\n 3.2\n100+\n1.000000\n 1,968\n1,968\n  4,542\n4,542\n 2.3\nFrom National Vital Statistics Reports, U.S. Department of Health and Human Services.\nEXAMPLE 1\nExpected Remaining Life\nAn abridged life table is to be constructed using age intervals of 5 years. Use Table 14-1 \nto find the expected remaining lifetime for someone reaching their 25th birthday.\nSOLUTION\nFrom Table 14-1 we see that someone reaching their 25th birthday has an expected \nremaining lifetime of 54.7 years. In the abridged table, the expected remaining life-\ntime for someone reaching their 25th birthday will be the same value of 54.7 years, \nso the age interval of 25–30 will also have 54.7 years listed in the last column.\nEXAMPLE 2  Probability of Dying\nUse Table 14-1 on pages 606-607 to find the probability of a person dying between \nthe ages of 15 and 20.\nSOLUTION\nFrom Table 14-1 we see that there were 99,154 people alive on their 15th birthday, \nand there were 98,910 people alive on their 20th birthday. The probability of  surviving \n",
    "14-1 Life Tables \n611\nApplications of Life Tables\nThe following application is important because it relates to the Social Security pro-\ngram in the United States, and that program involves trillions of dollars.\nbetween the 15th and 20th birthdays is therefore 98,910>99,154 = 0.997539. Using \nthe rule of complements from Chapter 4, it follows that the probability of dying dur-\ning that interval is 1 - 0.997539 = 0.002461. (The abridged life table of Table 14-2 \nshows the entry of 0.002463.)\nEXAMPLE 3\nSocial Security\nAssume that there are 3,932,181 births in the United States this year (based on data \nfrom the U.S. National Center for Health Statistics). If the age for receiving full \nSocial Security payments is 67, how many of those born this year are expected to be \nalive on their 67th birthday?\nSOLUTION\nFrom Table 14-1 (pages 606-607), we see that among 100,000 people born, we ex-\npect that 82,098 of them will survive to their 67th birthday. It follows that the prob-\nability of someone surviving from birth to their 67th birthday is 0.82098. If each of \n3,932,181 newborn people has a 0.82098 probability of surviving to their 67th birth-\nday, the expected number of such survivors is 3,932,181 * 0.82098 = 3,228,242 \n(rounded). Such results are critically important for those professionals responsible \nfor effective administration of the Social Security program.\nAnother application is based on the property that a life table includes probabili-\nties, and they can be treated as the same probabilities used in preceding chapters of \nthis book. Consider the following example in which a hypothesis test is conducted \nwith a probability value found in Table 14-1.\nEXAMPLE 4  Hypothesis Test for Cluster of Deaths\nIn the Chapter Problem, we noted that for one region there are 5000 people who \nreach their 16th birthday. If 25 of them die before their 17th birthday, do we have \nsufficient evidence to conclude that this number of deaths is significantly high?\nSOLUTION\nFrom Table 14-1 (pages 606-607), we find that for the age interval of 16–17, the \nprobability of dying is 0.000412. However, the Chapter Problem refers to a region \nin which there were 25 deaths among 5000 people during the age interval from their \n16th birthday to their 17th birthday. For this region, the proportion of actual deaths \nis pn = x>n = 25>5000 = 0.005. We can proceed to test the claim that for this \nregion, the deaths are from a population with a death rate greater than the life table \nvalue of 0.000412. Using the methods of Chapter 8, we begin with the following \nnull and alternative hypotheses.\nH0: p = 0.000412\nH1: p 7 0.000412 1claim being tested2\ncontinued\n",
    "612 \nCHAPTER 14 Survival Analysis\nNo significance level was specified, so we will use the common value of a = 0.05. \nWe now proceed to find the test statistic (as in Section 8–2):\nz = pn - p\nA\npq\nn\n=\n0.005 - 0.000412\nA\n10.000412210.9995882\n5000\n= 15.99\nUsing the P-value approach, we can find that the test statistic of z = 15.99 corre-\nsponds to a P-value of 0.0000 (or 0.0001 if using Table A-2).\nBecause the P-value is less than 0.05, we reject the null hypothesis. There is \nsufficient evidence to support the claim that the proportion of deaths is significantly \ngreater than the proportion that is usually expected for this age interval. We should \nnote that this analysis assumed that p = 0.000412, which was found in Table 14-1. \nHowever, Table 14-1 was constructed under the assumption that the mortality condi-\ntions present in the year 2010 will remain constant throughout the lifetimes of the \nhypothetical population of 100,000 people. Also, Table 14-1 applies to a general \npopulation, so this analysis does not apply to specific subgroups.\nStatistical Literacy and Critical Thinking\n1. Types of Life Tables What is the difference between a cohort life table and a period life \ntable?\n2. Cohort and Period Life Tables Why are period life tables so much more practical than \ncohort life tables?\n3. Population Size Table 14-1 was constructed with the assumption that the initial population \nsize is 100,000. How are the values in the first row affected if a population size of 50,000 is \nused instead?\n4. Interpretation of Table Assume that someone was born on January 1, 2010, and that per-\nson is alive now. If we refer to Table 14-1 for his or her expected remaining lifetime, what basic \nassumption about the construction of Table 14-1 might make that value inaccurate?\nIn Exercises 5–8, refer to the accompanying life table for white females in the United States \nfor the year 2010.\n14-1 Basic Skills and Concepts\nLife Table for White Females: U.S., 2010\n \n \n \n \n \n \n \n \n \nAge Interval\n \n \n \n \n \n \nProbability \nof Dying \nDuring the \nInterval\n \n \n \n \nNumber \nSurviving \nto the  \nBeginning \nof the  \nInterval\n \n \n \n \n \n \nNumber  \nof Deaths \nDuring the \nInterval\nPerson- \nYears Lived \n(total time  \nlived during \nthe interval  \nby those  \nalive at the  \nbeginning  \nof the  \ninterval)\n \n \n \nTotal  \nPerson-\nYears  \nLived (in  \nthis and all  \nsubsequent  \nintervals)\n \n \n \nExpected \nRemaining \nLifetime \n(from the \nbeginning \nof the  \ninterval)\n0–1\n0.004710\n100,000\n471\n99,588\n8,128,871\n81.3\n1–2\n 99,529\n 38\n99,510\n8,029,283\n80.7\n2–3\n0.000204\n 99,491\n99,481\n7,929,773\n79.7\nFrom National Vital Statistics Reports, U.S. Department of Health and Human Services.\n",
    "14-1 Life Tables \n613\n5. Probability of Dying Find the missing value in the second column of the life table for \nwhite females.\n6. Finding the Number of Deaths Find the missing value in the fourth column of the life \ntable for white females.\n7. Finding Survival Rate Find the probability that a white female will live from birth to her \nsecond birthday.\n8. Constructing an Abridged Table Assume that you want to use the given life table for \nwhite females to construct an abridged table with 0–2 as the first age interval. Find the values \nin the first row of this abridged table.\n9. Probability of Surviving Using Table 14-1 on pages 606-607, find the probability that \nsomeone will survive from their 20th birthday to their 21st birthday. Given 5000 people who \nreach their 20th birthday, what is the expected number of people who survive to their 21st \nbirthday?\n10. Expected Remaining Lifetime Use Table 14-1 on pages 606-607 to find the following.\na. Find the expected remaining lifetime for a person who has just reached their 60th birthday, \nthen find the expected remaining lifetime for a person who has just reached their 61st birthday.\nb. Find the expected age at death of someone who has just reached their 60th birthday, and find \nthe expected age at death for someone who has just reached their 61st birthday.\nc. Why aren’t the two results from part (b) equal?\n11. Probability of Surviving Use Table 14-1 on pages 606-607 to find the probability that a \nperson will survive from their 16th birthday to their 66th birthday.\n12. Probability of Surviving Use Table 14-1 on pages 606-607 to find the probability that a \nperson will survive from their 21st birthday to their 80th birthday.\n13. Abridged Table Use Table 14-1 on pages 606-607 to find the probability of dying during \nthe following age intervals. Given that these age intervals are so close, why are the results so \ndifferent?\na. 0–2\nb. 2–4\n14. Abridged Table Use Table 14-1 on pages 606-607 to find the values in a row with an age \ninterval of 0–2.\n15. Abridged Table Use Table 14-1 on pages 606-607 to find the values in a row with an age \ninterval of 2–4.\n16. Abridged Table Use Table 14-1 on pages 606-607 to find the values in a row with an age \ninterval of 0–10.\n17. Hypothesis Test In one region, a researcher finds that among 12,500 people who survived \nto their 20th birthday, there are 15 deaths before they reached age 21. Using Table 14-1, test the \nclaim that this is a significantly high number of deaths. Use a 0.05 significance level.\n18. Hypothesis Test In one region, a researcher finds that among 6772 people who survived \nto their 50th birthday, there are 36 deaths before they reached age 51. Using Table 14-1, test the \nclaim that this is a significantly high number of deaths. Use a 0.05 significance level.\n19. Hypothesis Test In one region, a researcher finds that among 8774 people who survived \nto their 16th birthday, there are 147 deaths before they reached age 30. Using Table 14-1, test \nthe claim that this is a significantly high number of deaths. Use a 0.05 significance level.\n20. Hypothesis Test In one region, a researcher finds that among 4285 people who survived \nto their 60th birthday, there are 484 deaths before they reached age 70. Using Table 14-1, test \nthe claim that this is a significantly low number of deaths. Use a 0.05 significance level.\n",
    "614 \nCHAPTER 14 Survival Analysis\nKey Concept In this section we introduce the Kaplan-Meier method used to describe \nthe probability of surviving for a specific period of time. The life table method of \nsurvivor analysis introduced in Section 14-1 is based on fixed time intervals, but the \nKaplan-Meier method is based on intervals that vary according to the times of survival \nto some particular terminating event. Using the sample data, it is helpful to construct a \nKaplan-Meier cumulative survival curve.\nIn this context of survivor analysis, the term survivor does not necessarily mean \nliving. A patient might be considered a survivor if postoperative surgery did not re-\nquire a return to a physician or hospital. A patient trying to stop smoking might be \nconsidered a survivor as long as smoking has not resumed. A survivor might also be a \ncomputer hard drive that worked for some particular length of time.\n14-2 \nKaplan-Meier Survival Analysis\nDEFINITIONS\nIn survivor analysis, the time lapse from the beginning of observation to the time of \na terminating event is considered a survival time. Examples of a terminating event \ninclude death, divorce, or failure of a computer hard drive.\nA survivor is a subject that successfully lasted throughout a particular time period. \nExamples of survivors include people, marriages, or computer hard drives.\nDEFINITION\nThe Kaplan-Meier method is used to describe survival behavior for some specific \nevent, and it is based on varying survival time intervals for the terminating event being \nanalyzed. (Because cumulative probabilities are products of other individual probabili-\nties, the Kaplan-Meier method is sometimes called the product-limit method.)\nA common application of the Kaplan-Meier method is to study survival times of \npatients after they undergo some treatment, such as surgery. Some of the survival data \nin such a study is often lost because some of the surgery patients survive by living past \nthe end of the study and some patients move far away or no longer wish to be included \nin the study, or are dropped from the study for other reasons. The data for these pa-\ntients are referred to as censored data, defined as follows.\nDEFINITION\nSurvival times are censored data if the subjects survive past the end of the study \nor if they are dropped from the study for reasons not related to the terminating \nevent being studied.\nEXAMPLE 1  Medication Treatment for Smoking Cessation\nConsider an experimental medication tested with five smokers recruited for a smok-\ning cessation clinical trial. In this context, “surviving” means that the patient has not \nresumed smoking.\n",
    "14-2 Kaplan-Meier Survival Analysis \n615\nResults: The first patient disliked the taste of the medication and dropped out of \nthe study on the first day, so the data from this patient are censored. Despite using \nthe medication as directed, the remaining four patients resumed smoking after  \n3 days, 4 days, 7 days, and 21 days, respectively. See these survival data summa-\nrized in Table 14-3.\nTABLE 14-3 Medication Treatment: Survival Data and Kaplan-Meier Calculations\n1 \n \n \n \n \nDay\n2 \nStatus  \n0 = Censored  \n1 = Failed  \n(Resumed \nSmoking)\n3 \n \n \n \nNumber  \nof Patients\n4 \n \n \n \nPatients  \nNot Smoking\n5 \n \n \nProportion  \nof Patients  \nNot Smoking\n6 \n \nCumulative  \nProportion of  \nPatients Not  \nSmoking\n1\n0\n3\n1\n4\n3\n 3>4 = 0.75\n0.75\n4\n1\n3\n2\n2>3 = 0.667\n       0.5\n7\n1\n2\n1\n 1>2 = 0.5\n0.25\n21\n1\n1\n0\n0\n0\nHere are some relevant comments about the entries in Table 14-3.\nCensored Data The first row of data in Table 14-3 represents the subject who \ndropped out of the program, and the 0 in the first row is the code for censored data. \nNote that except for the entry of 0, the other columns in the row are empty. Remov-\ning the patient who dropped out does not affect the subsequent calculations except \nfor the reduction in the number of remaining survivors.\nSecond Row of Data:\n \n■The number 3 in the first column of the second row indicates that this patient \nresumed smoking 3 days after the start of the program. This patient “survived” \nfor 3 days.\n \n■The 1 in the second column is a code indicating that smoking was resumed.\n \n■The 4 in the third column shows 4 patients remaining in the program.\n \n■The 3 in the fourth column represents the number of remaining patients who \nhave “survived” in the sense that they are not smoking.\n \n■The proportion of 3/4 in the fifth column shows that 3 out of the 4 patients have \nsurvived (i.e., not smoking).\n \n■The proportion of 0.75 in the sixth column is the same proportion of 0.75 from \nthe fifth column, but for the remaining rows, the proportion in the sixth column \nwill be the product of the proportion from the fifth column and any preceding \nproportions in the fifth column. See below.\nSixth Column of Cumulative Proportions of Survivors:\n \n■First entry of 0.75: Same proportion from the fifth column.\n \n■Second entry of 0.5: Product of 0.667 (rounded) from the fifth column and the \npreceding entry of 0.75 in the fifth column. We get 0.667 * 0.75 = 0.5.\n \n■Third entry of 0.25: Product of 0.5 from the fifth column and the \npreceding entries of 0.667 and 0.75 from the fifth column. We get \n0.5 * 0.667 * 0.75 = 0.25.\n \n■Fourth entry of 0: Product of 0 from the fifth column and the preceding entries \nin the fifth column. We get 0 * 0.5 * 0.667 * 0.75 = 0.\n",
    "616 \nCHAPTER 14 Survival Analysis\nEXAMPLE 2\nCounseling Treatment for Smoking Cessation\nThe preceding Example 1 describes survival for five patients who were treated with \nmedication. In the same program, 10 different patients underwent counseling in the at-\ntempt to stop smoking, and the results from these patients are summarized in Table 14-4. \nThis counseling program was discontinued after 28 days. Table 14-4 is an example of \nsurvival data with Kaplan-Meier calculations. Note that in Table 14-4, the number of \npatients decreases when patients are censored, as indicated by 0 in column 2.\nTABLE 14-4 Counseling Treatment: Survival Data and Kaplan-Meier Calculations\n \n \n \n \nDay\nStatus  \n0 = Censored \n1 = Failed  \n(Resumed  \nSmoking)\n \n \n \nNumber of  \nPatients\n \n \n \nPatients Not  \nSmoking\n \n \nProportion of \nPatients Not  \nSmoking\n \nCumulative  \nProportion of  \nPatients Not  \nSmoking\n 2\n1\n10\n9\n9>10 = 0.9\n0.9\n 4\n1\n 9\n8\n8>9 = 0.889\n0.8\n 5\n0\n 8\n1\n 7\n6\n6>7 = 0.857\n0.686\n 9\n1\n 6\n5\n5>6 = 0.833\n0.571\n12\n0\n14\n1\n 4\n3\n 3>4 = 0.75\n0.429\n22\n1\n 3\n2\n2>3 = 0.667\n0.286\n24\n0\n28\n0\nEXAMPLE 3  Kaplan-Meier Cumulative Survival Curves\nAs interesting and revealing as Tables 14-3 and 14-4 might be (!), it is usually more \nhelpful to construct graphs that make it easier to understand the survivor data. See \nthe accompanying Kaplan-Meier cumulative survival curves in Figure 14-1 that \nincorporates the survivor data from Table 14-3 and Table 14-4. The graph is con-\nstructed by using the survival times (column 1) and the cumulative proportions of \npatients not smoking (column 6) from Table 14-3 and Table 14-4.\nFIGURE 14-1  Kaplan-Meier Cumulative  \nSurvival Curves\n",
    "14-2 Kaplan-Meier Survival Analysis \n617\nSurvival for a Specific Time Period We can use the cumulative survival curves \nin Figure 14-1 to estimate survival for a specific time period. For example, the prob-\nability of survival to 15 days is estimated to be 0.25 for the medication group and 0.43 \nfor the counseling group. (Use the graph to construct a vertical line at 15 days and \nidentify the intersection of that line with the curves, then estimate the heights at the \ntwo points of intersection.)\nSome technologies, such as Minitab, JMP, SPSS, and XLSTAT-Life, can auto-\nmatically generate Kaplan-Meier cumulative survival curves, and some technologies \ncan also include graphs representing confidence intervals around those curves.\nThe Kaplan-Meier cumulative survival curves in Figure 14-1 show that the \nproportions of survivors (patients who had not resumed smoking) with counsel-\ning are generally higher than the proportions of survivors with medication, so it \nbecomes clear that the counseling program had better results than the medication \nprogram. However, neither of the programs had very high rates of survivors, so \nneither program appears to be very effective in helping patients achieve success in \ntheir attempts to stop smoking.\nStatistical Literacy and Critical Thinking\n1. Survivor In the context of analyzing survivor data, what is a survivor? Is it somebody who \nsomehow managed to live through some time period?\n2. Censored Data In the context of analyzing survivor data, what are censored data?\n3. Kaplan-Meier Survival Analysis What is the main difference between a life table de-\nscribed in Section 14-1 and a table of survival data and Kaplan-Meier calculations as described \nin this section?\n4. Graph What is a Kaplan-Meier cumulative survival curve?\nIn Exercises 5–9, refer to the accompanying graph, which describes times of survival until \ndeath for three groups of older subjects. The subjects are partitioned into the three groups \naccording to gait speed, or how fast they can walk. At the beginning of the study, ten sub-\njects were identified with fast gait speeds, ten other subjects were identified with moder-\nate gait speeds, and ten more subjects were identified with slow gait speeds. Times (years) \nwere measured from the beginning of the study to the time of death. (Based on data from \n “Predicting Survival in Oldest People,” by Taekema et al., American Journal of Medicine.)\n14-2 Basic Skills and Concepts\n",
    "618 \nCHAPTER 14 Survival Analysis\n5. Conclusion A purpose of the study was to determine whether walking speed is an effective \npredictor of longevity among the oldest subjects. Which of the three curves do you think cor-\nresponds to each of the three groups (fast, moderate, slow). Provide a brief explanation.\n6. Probability The vertical scale represents probability values. Describe the event for which \nprobabilities are found. What do we know from the observation that the three curves all pro-\nceed downward as time progresses?\n7. Graphic Details \na. For the ten subjects in the group identified by the green curve, how much time elapsed be-\ntween the beginning of the study and the death of the first subject?\nb. For the ten subjects in the group identified by the red curve, how much time elapsed between \nthe beginning of the study and the death of the first subject?\n8. Survivors Did any of the slow walkers survive, or did they all die?\n9. Survival to Five Years Estimate the five-year survival rates for the three groups and com-\npare them. Do the data suggest that we can get older people to live longer by somehow getting \nthem to walk faster?\n10. Hospital Readmission Ten patients underwent surgery and were subsequently followed \nup for 14 days to determine whether they required readmission to a hospital. Readmission is \nconsidered a failure or terminating event. Complete the table. What do the last five 0’s in the \nsecond column indicate?\n \n \n \nDay\nStatus  \n0 = Censored  \n1 = Failed  \n(Readmitted)\n \n \nNumber  \nof Patients\n \n \nPatients Not  \nReadmitted\n \nProportion of \nPatients Not  \nReadmitted\nCumulative  \nProportion of \nPatients Not  \nReadmitted\n 2\n0\n 6\n1\n10\n1\n11\n1\n13\n1\n14\n0\n14\n0\n14\n0\n14\n0\n14\n0\n11. Graph of Cumulative Survival Construct the cumulative survival (probability) graph for \nthe completed table from Exercise 10.\n12. Blood Pressure For the purposes of a clinical trial, a patient was considered to have high \nblood pressure if the systolic blood pressure exceeded 140 mm Hg. Eight patients were treated \nfor their high blood pressure, and they were then followed up for 30 days. A failure of the \ntreatment was considered to be a terminating event consisting of a return of the systolic blood \npressure to a level that exceeded 140 mm Hg. Here are the results: One patient dropped out of \nthe study on day 2, the systolic blood pressure of a second patient returned to a high level on \nday 10, a third patient developed high blood pressure on day 12, and the remaining patients \nsustained systolic blood pressure levels below 140 mm Hg throughout the time of the clinical \ntrial. Construct a table containing survival data and Kaplan-Meier calculations.\n13. Graph of Cumulative Survival Construct the cumulative survival (probability) graph for \nthe completed table from Exercise 12. How many censored patient survival times are shown in \nthe graph?\n",
    "14. Graph of Cumulative Survival Refer to the accompanying cumulative survival graph. \nWhich is better: treatment or placebo? Estimate the five-year survival rates for the two groups, \nthen compare them. What does the graph suggest about the effectiveness of the treatment?\n1. Life Table or Survival Table Which tool would be better for estimating the probability that \na female of age 27 will live throughout her 28th year: life table or survival table with Kaplan-\nMeier calculations?\n2. Life Table or Survival Table Which tool would be better for estimating the probability that \nsomeone will live for at least 20 years after they start smoking: a life table or a survival table \nwith Kaplan-Meier calculations?\n3. Period Life Table What is a period life table?\n4. Cohort Life Table What is a cohort life table?\n5. Censored Data True or false: In survival analysis, censored data are records that have been \neliminated because they could potentially reveal the identities of subjects.\n6. Censored Data True or false: In survival analysis, if a subject survives for the entire dura-\ntion of the study, then the survival time for that subject is excluded.\n7. Survivor In survivor analysis, the term survivor always refers to a person who has lived \nsome specific amount of time.\n8. Period Life Table True or false: One disadvantage of a period life table is an assumption \nthat conditions affecting mortality will not change throughout the lives of everyone in a cohort.\n9. Survival Data Identify the missing entries in the bottom row of the following table of sur-\nvival data.\n \n \n \nDay\n \nStatus  \n0 = Censored  \n1 = Death\n \n \nNumber of  \nPatients\n \n \nPatients Not \nDead\n \nProportion of \nPatients Not  \nDead\nCumulative  \nProportion of  \nPatients Not \nDead\n1\n1\n3\n2\n2>3 = 0.667\n0.667\n5\n1\n2\n1\n 1>2 = 0.5\n0.333\n8\n1\nChapter Quick Quiz\nCHAPTER 14 Chapter Quick Quiz \n619\n",
    "620 \nCHAPTER 14 Survival Analysis\n10. Life Table Refer to the following portion of the life table taken from Table 14-1. Find the \nprobability that a randomly selected 19-year-old person will live one year. Express the result \nusing six significant digits.\n \n \n \n \n \n \nAge  \nInterval\n \n \n \n \nProbability  \nof Dying  \nDuring the  \nInterval\n \n \nNumber  \nSurviving  \nto the  \nBeginning  \nof the  \nInterval\n \n \n \n \nNumber  \nof Deaths  \nDuring the \nInterval\nPerson-Years \nLived (total \ntime lived  \nduring the  \ninterval by \nthose alive at \nthe beginning \nof the interval)\n \n \nTotal  \nPerson-Years \nLived (in this \nand all  \nsubsequent  \nintervals)\n \n \nExpected  \nRemaining  \nLifetime  \n(from the  \nbeginning of \nthe interval)\n19–20\n0.000655\n98,975\n65\n98,942\n5,980,731\n60.4\nIn Exercises 1–5, refer to the accompanying life table for Hispanic females in the United \nStates for the year 2010.\nReview Exercises\nLife Table for Hispanic Females: U.S., 2010\n \n \n \n \n \n \nAge  \nInterval\n \n \n \n \nProbability \nof Dying \nDuring the \nInterval\n \n \nNumber \nSurviving \nto the  \nBeginning \nof the  \nInterval\n \n \n \n \nNumber \nof Deaths \nDuring the \nInterval\nPerson-Years \nLived (total \ntime lived \n during the  \ninterval by \nthose alive at \nthe beginning \nof the interval)\n \nTotal  \nPerson-\nYears Lived \n(in this  \nand all \nsubsequent \nintervals)\n \nExpected \nRemaining \nLifetime \n(from the \nbeginning \nof the  \ninterval)\n0–1\n0.004729\n100,000\n473\n99,588\n8,382,303\n83.8\n1–2\n 99,527\n99,510\n8,282,715\n83.2\n2–3\n0.000194\n 99,492\n 19\n99,482\n8,183,206\n82.2\nFrom National Vital Statistics Reports, U.S. Department of Health and Human Services.\n1. Probability of Dying Find the missing value in the second column of the table.\n2. Finding the Number of Deaths Find the missing value in the fourth column of the table.\n3. Finding Survival Rate Find the probability that a Hispanic female will live from birth to \nher second birthday.\n4. Constructing an Abridged Table Assume that you want to use the given table for the \nconstruction of an abridged table with 0–2 as the first age interval. Find the values in the first \nrow of this abridged table.\n5. Expected Remaining Lifetime What is the expected remaining lifetime of a Hispanic fe-\nmale who was just born? What is the expected remaining lifetime of a Hispanic female who is \ncelebrating her first birthday? Compare those results and comment on the relationship between \nthem.\n6. Carpal Tunnel Syndrome For the purposes of a clinical trial, a patient undergoing surgery \nfor treatment of carpal tunnel syndrome was considered to survive if the patient had no retreat-\nments following surgery. Four patients underwent the surgery, and they were then followed up for \n30 days with these results: One patient required retreatment on day 3, a second patient required \nretreatment on day 12, a third patient required retreatment on day 20, and the fourth patient never \nrequired retreatment. Construct a table containing survival data and the Kaplan-Meier calculations.\n7. Graph of Cumulative Survival Construct the cumulative survival (probability) graph for \nthe completed table from Exercise 6.\n",
    "8. Graph of Cumulative Survival In the accompanying cumulative survival graph, which \ngroup had better overall success: the treatment group or the placebo group? What does the \ngraph suggest about the effectiveness of the treatment?\nIn Exercises 1–4, refer to the same life table used for Review Exercises 1–5.\n1. Hypothesis Test of Experimental Results In one region, a comprehensive community-\nwide program is implemented in an attempt to reduce the rate of mortality for young Hispanic \nfemales. Results from this program show that among 1328 births of Hispanic females, 1323 \nsurvived to their second birthday and 5 did not survive to their second birthday. Using the data \nin the life table for Hispanic females, test the claim that the program was effective in reducing \nthe mortality rate.\n2. Confidence Interval for Experimental Results Given the sample results from Cumula-\ntive Review Exercise 1, construct a 95% confidence interval for the survival rate (from birth to \nthe second birthday) for Hispanic females born in the region with the mortality reduction pro-\ngram in effect. Instead of using three significant digits, express the results with five significant \ndigits. What can be concluded about the fact that the confidence interval limits do (or do not) \ncontain the survival rate for Hispanic females, as suggested by the life table?\n3. Probability of Surviving If three different newborn Hispanic females are randomly se-\nlected, find the probability that they all survive to their first birthday.\n4. Probability of Surviving If four different newborn Hispanic females are randomly selected, \nfind the probability that at least one of them does not survive to her first birthday. Does this \nprobability apply to families in which there are four children, all of whom are Hispanic females?\n5. Internet Doctors In a survey of n = 2015 adults, 1108 of them said that they learn about medi-\ncal symptoms more often from the Internet than from their doctor (based on a MerckManuals.com \nreport). The accompanying graph was created to depict the results of the survey. Is the graph \nsomehow misleading? If so, how?\nCumulative Review Exercises\nCHAPTER 14 Cumulative Review Exercises \n621\n",
    "622 \nCHAPTER 14 Survival Analysis\n6. Heights Based on Data Set 1 “Body Data” in Appendix B, assume that heights of men are \nnormally distributed with a mean of 68.6 in. and a standard deviation of 2.8 in.\na. The U.S. Coast Guard requires that its men must have a height between 60 in. and 80 in. \nFind the percentage of men who satisfy that height requirement.\nb. Find the probability that 4 randomly selected men have heights with a mean greater than 70 in.\nTechnology Project\nIn Section 14-2 it was noted that some technologies, such as Minitab, JMP, SPSS, and XLSTAT-\nLife, can automatically generate Kaplan-Meier cumulative survival curves. Use a technology \ncapable of generating Kaplan-Meier cumulative survival curves and generate the graph corre-\nsponding to the following survival data for 20 patients who were treated with heart surgery. The \nstatus of 1 indicates that the patient required a follow-up treatment after the surgery; the status of \n0 represents a censored patient. Use the graph to estimate the seven-day survival rate, which is \nthe proportion of patients not requiring follow-up treatment.\nDay\n1\n5\n6\n9\n14\n23\n25\n27\n29\nStatus\n1\n1\n0\n1\n 1\n 1\n 1\n 0\n 1\nFROM DATA TO DECISION\nCritical Thinking: How do we reduce the high mortality rate among young black females?\nCompare the following life tables for black females and white females\nLife Tables for Females: U.S., 2010\n \n \n \n \n \nAge  \nInterval\n \n \n \n \nProbability of \nDying During \nthe Interval\n \n \n \nNumber  \nSurviving to \nthe Beginning \nof the Interval\n \n \n \n \nNumber of \nDeaths During \nthe Interval\nPerson-Years \nLived (total time \nlived during the \ninterval by those \nalive at the be-\nginning of the \ninterval)\n \n \nTotal Person-\nYears Lived \n(in this and all \nsubsequent \nintervals)\n \n \nExpected  \nRemaining Life-\ntime (from the \nbeginning of the \ninterval)\nBlack Females\n0–1\n0.010472\n100,000\n1,047\n99,075\n7,799,627\n78.0\n1–2\n0.000596\n 98,953\n59\n98,923\n7,700,551\n77.8\n2–3\n0.000339\n 98,894\n34\n98,877\n7,601,628\n76.9\nWhite Females\n0–1\n0.004710\n100,000\n471\n99,588\n8,128,871\n81.3\n1–2\n0.000382\n 99,529\n38\n99,510\n8,029,283\n80.7\n2–3\n0.000204\n 99,491\n20\n99,481\n7,929,773\n79.7\nFrom National Vital Statistics Reports, U.S. Department of Health and Human Services.\nAnalyze the Results\n1. What notable differences are apparent?\n2. Identify some reasons for the apparent differences.\n3. What are some steps that could be taken to effectively re-\nduce the high rate of mortality among young black females?\n4. What is a reasonable response to someone who argues that \na program for reducing mortality among young black females \nshould not be implemented because it discriminates on the \nbasis of race?\n",
    "1. In-class activity Table 14-1 on pages 606-607 describes the life and death experience of a \nhypothetical group of 100,000 people. That table was constructed using actual results obtained \nfrom a variety of different sources. Instead of using real sources of vital statistics, assume that \nthe death rate of some population is a constant 0.4 for each year. Construct as much of the life \ntable as possible. How many years will pass before none of the hypothetical population of \n100,000 people are alive?\n2. Out-of-class activity Repeat Cooperative Group Activity 1, but instead of using a constant \ndeath rate of 0.4 each year, use a computer or calculator to randomly generate the death rate for \neach year. For each year, generate a random number between 0 and 1, and assume that it is the \ndeath rate that applies to the particular year.\n3. Out-of-class activity Obtain Life Tables for Total Population: U.S. for years prior to 2010 \nand compare them. What are your observations? If differences exist, what do you think may \naccount for changes in these life tables over time?\nCooperative Group Activities\nCHAPTER 14 Cooperative Group Activities \n623\n",
    "This page intentionally left blank\n",
    "625\nTables\nAPPENDIX A\nTABLE A-1  Binomial Probabilities\np\nn\nx\n.01\n.05\n.10\n.20\n.30\n.40\n.50\n.60\n.70\n.80\n.90\n.95\n.99\nx\n2\n0\n.980\n.903\n.810\n.640\n.490\n.360\n.250\n.160\n.090\n.040\n.010\n.003\n 0+\n0\n1\n.020\n.095\n.180\n.320\n.420\n.480\n.500\n.480\n.420\n.320\n.180\n.095\n.020\n1\n2\n 0+\n.003\n.010\n.040\n.090\n.160\n.250\n.360\n.490\n.640\n.810\n.903\n.980\n2\n3\n0\n.970\n.857\n.729\n.512\n.343\n.216\n.125\n.064\n.027\n.008\n.001\n 0+\n 0+\n0\n1\n.029\n.135\n.243\n.384\n.441\n.432\n.375\n.288\n.189\n.096\n.027\n.007\n 0+\n1\n2\n 0+\n.007\n.027\n.096\n.189\n.288\n.375\n.432\n.441\n.384\n.243\n.135\n.029\n2\n3\n 0+\n 0+\n.001\n.008\n.027\n.064\n.125\n.216\n.343\n.512\n.729\n.857\n.970\n3\n4\n0\n.961\n.815\n.656\n.410\n.240\n.130\n.063\n.026\n.008\n.002\n 0+\n 0+\n 0+\n0\n1\n.039\n.171\n.292\n.410\n.412\n.346\n.250\n.154\n.076\n.026\n.004\n 0+\n 0+\n1\n2\n.001\n.014\n.049\n.154\n.265\n.346\n.375\n.346\n.265\n.154\n.049\n.014\n.001\n2\n3\n 0+\n 0+\n.004\n.026\n.076\n.154\n.250\n.346\n.412\n.410\n.292\n.171\n.039\n3\n4\n 0+\n 0+\n 0+\n.002\n.008\n.026\n.063\n.130\n.240\n.410\n.656\n.815\n.961\n4\n5\n0\n.951\n.774\n.590\n.328\n.168\n.078\n.031\n.010\n.002\n 0+\n 0+\n 0+\n 0+\n0\n1\n.048\n.204\n.328\n.410\n.360\n.259\n.156\n.077\n.028\n.006\n 0+\n 0+\n 0+\n1\n2\n.001\n.021\n.073\n.205\n.309\n.346\n.313\n.230\n.132\n.051\n.008\n.001\n 0+\n2\n3\n 0+\n.001\n.008\n.051\n.132\n.230\n.313\n.346\n.309\n.205\n.073\n.021\n.001\n3\n4\n 0+\n 0+\n 0+\n.006\n.028\n.077\n.156\n.259\n.360\n.410\n.328\n.204\n.048\n4\n5\n 0+\n 0+\n 0+\n 0+\n.002\n.010\n.031\n.078\n.168\n.328\n.590\n.774\n.951\n5\n6\n0\n.941\n.735\n.531\n.262\n.118\n.047\n.016\n.004\n.001\n 0+\n 0+\n 0+\n 0+\n0\n1\n.057\n.232\n.354\n.393\n.303\n.187\n.094\n.037\n.010\n.002\n 0+\n 0+\n 0+\n1\n2\n.001\n.031\n.098\n.246\n.324\n.311\n.234\n.138\n.060\n.015\n.001\n 0+\n 0+\n2\n3\n0+\n.002\n.015\n.082\n.185\n.276\n.312\n.276\n.185\n.082\n.015\n.002\n 0+\n3\n4\n0+\n 0+\n.001\n.015\n.060\n.138\n.234\n.311\n.324\n.246\n.098\n.031\n.001\n4\n5\n 0+\n 0+\n 0+\n.002\n.010\n.037\n.094\n.187\n.303\n.393\n.354\n.232\n.057\n5\n6\n 0+\n 0+\n 0+\n 0+\n.001\n.004\n.016\n.047\n.118\n.262\n.531\n.735\n.941\n6\n7\n0\n.932\n.698\n.478\n.210\n.082\n.028\n.008\n.002\n 0+\n 0+\n 0+\n 0+\n 0+\n0\n1\n.066\n.257\n.372\n.367\n.247\n.131\n.055\n.017\n.004\n 0+\n 0+\n 0+\n 0+\n1\n2\n.002\n.041\n.124\n.275\n.318\n.261\n.164\n.077\n.025\n.004\n 0+\n 0+\n 0+\n2\n3\n 0+\n.004\n.023\n.115\n.227\n.290\n.273\n.194\n.097\n.029\n.003\n 0+\n 0+\n3\n4\n 0+\n 0+\n.003\n.029\n.097\n.194\n.273\n.290\n.227\n.115\n.023\n.004\n 0+\n4\n5\n 0+\n 0+\n 0+\n.004\n.025\n.077\n.164\n.261\n.318\n.275\n.124\n.041\n.002\n5\n6\n 0+\n 0+\n 0+\n 0+\n.004\n.017\n.055\n.131\n.247\n.367\n.372\n.257\n.066\n6\n7\n 0+\n 0+\n 0+\n 0+\n 0+\n.002\n.008\n.028\n.082\n.210\n.478\n.698\n.932\n7\n8\n0\n.923\n.663\n.430\n.168\n.058\n.017\n.004\n.001\n 0+\n 0+\n 0+\n 0+\n 0+\n0\n1\n.075\n.279\n.383\n.336\n.198\n.090\n.031\n.008\n.001\n 0+\n 0+\n 0+\n 0+\n1\n2\n.003\n.051\n.149\n.294\n.296\n.209\n.109\n.041\n.010\n.001\n 0+\n 0+\n 0+\n2\n3\n 0+\n.005\n.033\n.147\n.254\n.279\n.219\n.124\n.047\n.009\n 0+\n 0+\n 0+\n3\n4\n 0+\n 0+\n.005\n.046\n.136\n.232\n.273\n.232\n.136\n.046\n.005\n 0+\n 0+\n4\n5\n 0+\n 0+\n 0+\n.009\n.047\n.124\n.219\n.279\n.254\n.147\n.033\n.005\n 0+\n5\n6\n 0+\n 0+\n 0+\n.001\n.010\n.041\n.109\n.209\n.296\n.294\n.149\n.051\n.003\n6\n7\n 0+\n 0+\n 0+\n 0+\n.001\n.008\n.031\n.090\n.198\n.336\n.383\n.279\n.075\n7\n8\n 0+\n 0+\n 0+\n 0+\n 0+\n.001\n.004\n.017\n.058\n.168\n.430\n.663\n.923\n8\nNOTE: 0+ represents a positive probability value less than 0.0005.\nFrom Frederick C. Mosteller, Robert E. K. Rourke, and George B. Thomas, Jr., Probability with Statistical Applications, 2nd ed., © 1970. Reprinted and electronically \nreproduced by permission of Pearson Education, Inc., Upper Saddle River, New Jersey.\n",
    "626\t\nAPPENDIX A  Tables\nTABLE A-2  Standard Normal (z) Distribution: Cumulative Area from the LEFT\nz\n.00\n.01\n.02\n.03\n.04\n.05\n.06\n.07\n.08\n.09\n-3.50 and \nlower\n \n.0001\n-3.4\n.0003\n.0003\n.0003\n.0003\n.0003\n.0003\n.0003\n.0003\n.0003\n.0002\n-3.3\n.0005\n.0005\n.0005\n.0004\n.0004\n.0004\n.0004\n.0004\n.0004\n.0003\n-3.2\n.0007\n.0007\n.0006\n.0006\n.0006\n.0006\n.0006\n.0005\n.0005\n.0005\n-3.1\n.0010\n.0009\n.0009\n.0009\n.0008\n.0008\n.0008\n.0008\n.0007\n.0007\n-3.0\n.0013\n.0013\n.0013\n.0012\n.0012\n.0011\n.0011\n.0011\n.0010\n.0010\n-2.9\n.0019\n.0018\n.0018\n.0017\n.0016\n.0016\n.0015\n.0015\n.0014\n.0014\n-2.8\n.0026\n.0025\n.0024\n.0023\n.0023\n.0022\n.0021\n.0021\n.0020\n.0019\n-2.7\n.0035\n.0034\n.0033\n.0032\n.0031\n.0030\n.0029\n.0028\n.0027\n.0026\n-2.6\n.0047\n.0045\n.0044\n.0043\n.0041\n.0040\n.0039\n.0038\n.0037\n.0036\n-2.5\n.0062\n.0060\n.0059\n.0057\n.0055\n.0054\n.0052\n.0051\n.0049\n.0048\n-2.4\n.0082\n.0080\n.0078\n.0075\n.0073\n.0071\n.0069\n.0068\n.0066\n.0064\n-2.3\n.0107\n.0104\n.0102\n.0099\n.0096\n.0094\n.0091\n.0089\n.0087\n.0084\n-2.2\n.0139\n.0136\n.0132\n.0129\n.0125\n.0122\n.0119\n.0116\n.0113\n.0110\n-2.1\n.0179\n.0174\n.0170\n.0166\n.0162\n.0158\n.0154\n.0150\n.0146\n.0143\n-2.0\n.0228\n.0222\n.0217\n.0212\n.0207\n.0202\n.0197\n.0192\n.0188\n.0183\n-1.9\n.0287\n.0281\n.0274\n.0268\n.0262\n.0256\n.0250\n.0244\n.0239\n.0233\n-1.8\n.0359\n.0351\n.0344\n.0336\n.0329\n.0322\n.0314\n.0307\n.0301\n.0294\n-1.7\n.0446\n.0436\n.0427\n.0418\n.0409\n.0401\n.0392\n.0384\n.0375\n.0367\n-1.6\n.0548\n.0537\n.0526\n.0516\n.0505\n.0495\n.0485\n.0475\n.0465\n.0455\n-1.5\n.0668\n.0655\n.0643\n.0630\n.0618\n.0606\n.0594\n.0582\n.0571\n.0559\n-1.4\n.0808\n.0793\n.0778\n.0764\n.0749\n.0735\n.0721\n.0708\n.0694\n.0681\n-1.3\n.0968\n.0951\n.0934\n.0918\n.0901\n.0885\n.0869\n.0853\n.0838\n.0823\n-1.2\n.1151\n.1131\n.1112\n.1093\n.1075\n.1056\n.1038\n.1020\n.1003\n.0985\n-1.1\n.1357\n.1335\n.1314\n.1292\n.1271\n.1251\n.1230\n.1210\n.1190\n.1170\n-1.0\n.1587\n.1562\n.1539\n.1515\n.1492\n.1469\n.1446\n.1423\n.1401\n.1379\n-0.9\n.1841\n.1814\n.1788\n.1762\n.1736\n.1711\n.1685\n.1660\n.1635\n.1611\n-0.8\n.2119\n.2090\n.2061\n.2033\n.2005\n.1977\n.1949\n.1922\n.1894\n.1867\n-0.7\n.2420\n.2389\n.2358\n.2327\n.2296\n.2266\n.2236\n.2206\n.2177\n.2148\n-0.6\n.2743\n.2709\n.2676\n.2643\n.2611\n.2578\n.2546\n.2514\n.2483\n.2451\n-0.5\n.3085\n.3050\n.3015\n.2981\n.2946\n.2912\n.2877\n.2843\n.2810\n.2776\n-0.4\n.3446\n.3409\n.3372\n.3336\n.3300\n.3264\n.3228\n.3192\n.3156\n.3121\n-0.3\n.3821\n.3783\n.3745\n.3707\n.3669\n.3632\n.3594\n.3557\n.3520\n.3483\n-0.2\n.4207\n.4168\n.4129\n.4090\n.4052\n.4013\n.3974\n.3936\n.3897\n.3859\n-0.1\n.4602\n.4562\n.4522\n.4483\n.4443\n.4404\n.4364\n.4325\n.4286\n.4247\n-0.0\n.5000\n.4960\n.4920\n.4880\n.4840\n.4801\n.4761\n.4721\n.4681\n.4641\nNOTE: For values of z below -3.49, use 0.0001 for the area.\n*Use these common values that result from interpolation:\nNEGATIVE z Scores\nz Score\nArea\n-1.645\n0.0500\n-2.575\n0.0050\n(continued )\n0\nz\n*\n*\n",
    "\t\nAPPENDIX A  Tables\t\n627\nPOSITIVE z Scores\nTABLE A-2 (continued)  Cumulative Area from the LEFT\nz\n.00\n.01\n.02\n.03\n.04\n.05\n.06\n.07\n.08\n.09\n0.0\n.5000\n.5040\n.5080\n.5120\n.5160\n.5199\n.5239\n.5279\n.5319\n.5359\n0.1\n.5398\n.5438\n.5478\n.5517\n.5557\n.5596\n.5636\n.5675\n.5714\n.5753\n0.2\n.5793\n.5832\n.5871\n.5910\n.5948\n.5987\n.6026\n.6064\n.6103\n.6141\n0.3\n.6179\n.6217\n.6255\n.6293\n.6331\n.6368\n.6406\n.6443\n.6480\n.6517\n0.4\n.6554\n.6591\n.6628\n.6664\n.6700\n.6736\n.6772\n.6808\n.6844\n.6879\n0.5\n.6915\n.6950\n.6985\n.7019\n.7054\n.7088\n.7123\n.7157\n.7190\n.7224\n0.6\n.7257\n.7291\n.7324\n.7357\n.7389\n.7422\n.7454\n.7486\n.7517\n.7549\n0.7\n.7580\n.7611\n.7642\n.7673\n.7704\n.7734\n.7764\n.7794\n.7823\n.7852\n0.8\n.7881\n.7910\n.7939\n.7967\n.7995\n.8023\n.8051\n.8078\n.8106\n.8133\n0.9\n.8159\n.8186\n.8212\n.8238\n.8264\n.8289\n.8315\n.8340\n.8365\n.8389\n1.0\n.8413\n.8438\n.8461\n.8485\n.8508\n.8531\n.8554\n.8577\n.8599\n.8621\n1.1\n.8643\n.8665\n.8686\n.8708\n.8729\n.8749\n.8770\n.8790\n.8810\n.8830\n1.2\n.8849\n.8869\n.8888\n.8907\n.8925\n.8944\n.8962\n.8980\n.8997\n.9015\n1.3\n.9032\n.9049\n.9066\n.9082\n.9099\n.9115\n.9131\n.9147\n.9162\n.9177\n1.4\n.9192\n.9207\n.9222\n.9236\n.9251\n.9265\n.9279\n.9292\n.9306\n.9319\n1.5\n.9332\n.9345\n.9357\n.9370\n.9382\n.9394\n.9406\n.9418\n.9429\n.9441\n1.6\n.9452\n.9463\n.9474\n.9484\n.9495\n.9505\n.9515\n.9525\n.9535\n.9545\n1.7\n.9554\n.9564\n.9573\n.9582\n.9591\n.9599\n.9608\n.9616\n.9625\n.9633\n1.8\n.9641\n.9649\n.9656\n.9664\n.9671\n.9678\n.9686\n.9693\n.9699\n.9706\n1.9\n.9713\n.9719\n.9726\n.9732\n.9738\n.9744\n.9750\n.9756\n.9761\n.9767\n2.0\n.9772\n.9778\n.9783\n.9788\n.9793\n.9798\n.9803\n.9808\n.9812\n.9817\n2.1\n.9821\n.9826\n.9830\n.9834\n.9838\n.9842\n.9846\n.9850\n.9854\n.9857\n2.2\n.9861\n.9864\n.9868\n.9871\n.9875\n.9878\n.9881\n.9884\n.9887\n.9890\n2.3\n.9893\n.9896\n.9898\n.9901\n.9904\n.9906\n.9909\n.9911\n.9913\n.9916\n2.4\n.9918\n.9920\n.9922\n.9925\n.9927\n.9929\n.9931\n.9932\n.9934\n.9936\n2.5\n.9938\n.9940\n.9941\n.9943\n.9945\n.9946\n.9948\n.9949\n.9951\n.9952\n2.6\n.9953\n.9955\n.9956\n.9957\n.9959\n.9960\n.9961\n.9962\n.9963\n.9964\n2.7\n.9965\n.9966\n.9967\n.9968\n.9969\n.9970\n.9971\n.9972\n.9973\n.9974\n2.8\n.9974\n.9975\n.9976\n.9977\n.9977\n.9978\n.9979\n.9979\n.9980\n.9981\n2.9\n.9981\n.9982\n.9982\n.9983\n.9984\n.9984\n.9985\n.9985\n.9986\n.9986\n3.0\n.9987\n.9987\n.9987\n.9988\n.9988\n.9989\n.9989\n.9989\n.9990\n.9990\n3.1\n.9990\n.9991\n.9991\n.9991\n.9992\n.9992\n.9992\n.9992\n.9993\n.9993\n3.2\n.9993\n.9993\n.9994\n.9994\n.9994\n.9994\n.9994\n.9995\n.9995\n.9995\n3.3\n.9995\n.9995\n.9995\n.9996\n.9996\n.9996\n.9996\n.9996\n.9996\n.9997\n3.4\n.9997\n.9997\n.9997\n.9997\n.9997\n.9997\n.9997\n.9997\n.9997\n.9998\n3.50 and up\n.9999\nNOTE: For values of z above 3.49, use 0.9999 for the area.\n*Use these common values that result from interpolation:\nCommon Critical Values\nConfidence\nLevel\nCritical\nValue\n0.90\n1.645\n0.95\n1.96\n0.99\n2.575\nz Score\nArea\n1.645\n0.9500\n2.575\n0.9950\n*\n*\n0\nz\n",
    "628\t\nAPPENDIX A  Tables\nTABLE A-3  t Distribution: Critical t Values\n \n0.005\n \n0.01\nArea in One Tail \n0.025\n \n0.05\n \n0.10\nDegrees of \nFreedom\n \n0.01\n \n0.02\nArea in Two Tails \n0.05\n \n0.10\n \n0.20\n  1\n \n63.657\n    31.821\n    12.706\n6.314\n3.078\n  2\n9.925\n6.965\n4.303\n2.920\n1.886\n  3\n5.841\n4.541\n3.182\n2.353\n1.638\n  4\n4.604\n3.747\n2.776\n2.132\n1.533\n  5\n4.032\n3.365\n2.571\n2.015\n1.476\n  6\n3.707\n3.143\n2.447\n1.943\n1.440\n  7\n3.499\n2.998\n2.365\n1.895\n1.415\n  8\n3.355\n2.896\n2.306\n1.860\n1.397\n  9\n3.250\n2.821\n2.262\n1.833\n1.383\n10\n3.169\n2.764\n2.228\n1.812\n1.372\n11\n3.106\n2.718\n2.201\n1.796\n1.363\n12\n3.055\n2.681\n2.179\n1.782\n1.356\n13\n3.012\n2.650\n2.160\n1.771\n1.350\n14\n2.977\n2.624\n2.145\n1.761\n1.345\n15\n2.947\n2.602\n2.131\n1.753\n1.341\n16\n2.921\n2.583\n2.120\n1.746\n1.337\n17\n2.898\n2.567\n2.110\n1.740\n1.333\n18\n2.878\n2.552\n2.101\n1.734\n1.330\n19\n2.861\n2.539\n2.093\n1.729\n1.328\n20\n2.845\n2.528\n2.086\n1.725\n1.325\n21\n2.831\n2.518\n2.080\n1.721\n1.323\n22\n2.819\n2.508\n2.074\n1.717\n1.321\n23\n2.807\n2.500\n2.069\n1.714\n1.319\n24\n2.797\n2.492\n2.064\n1.711\n1.318\n25\n2.787\n2.485\n2.060\n1.708\n1.316\n26\n2.779\n2.479\n2.056\n1.706\n1.315\n27\n2.771\n2.473\n2.052\n1.703\n1.314\n28\n2.763\n2.467\n2.048\n1.701\n1.313\n29\n2.756\n2.462\n2.045\n1.699\n1.311\n30\n2.750\n2.457\n2.042\n1.697\n1.310\n31\n2.744\n2.453\n2.040\n1.696\n1.309\n32\n2.738\n2.449\n2.037\n1.694\n1.309\n33\n2.733\n2.445\n2.035\n1.692\n1.308\n34\n2.728\n2.441\n2.032\n1.691\n1.307\n35\n2.724\n2.438\n2.030\n1.690\n1.306\n36\n2.719\n2.434\n2.028\n1.688\n1.306\n37\n2.715\n2.431\n2.026\n1.687\n1.305\n38\n2.712\n2.429\n2.024\n1.686\n1.304\n39\n2.708\n2.426\n2.023\n1.685\n1.304\n40\n2.704\n2.423\n2.021\n1.684\n1.303\n45\n2.690\n2.412\n2.014\n1.679\n1.301\n50\n2.678\n2.403\n2.009\n1.676\n1.299\n60\n2.660\n2.390\n2.000\n1.671\n1.296\n70\n2.648\n2.381\n1.994\n1.667\n1.294\n80\n2.639\n2.374\n1.990\n1.664\n1.292\n90\n2.632\n2.368\n1.987\n1.662\n1.291\n100\n2.626\n2.364\n1.984\n1.660\n1.290\n200\n2.601\n2.345\n1.972\n1.653\n1.286\n300\n2.592\n2.339\n1.968\n1.650\n1.284\n400\n2.588\n2.336\n1.966\n1.649\n1.284\n500\n2.586\n2.334\n1.965\n1.648\n1.283\n1000\n2.581\n2.330\n1.962\n1.646\n1.282\n2000\n2.578\n2.328\n1.961\n1.646\n1.282\nLarge\n2.576\n2.326\n1.960\n1.645\n1.282\nCritical t value\n(negative)\na\nLeft tail\nCritical t value\n(positive)\na\nRight tail\nCritical t value\n(positive)\nCritical t value\n(negative)\na\u001f2\na\u001f2\nTwo tails\n",
    "\t\nAPPENDIX A  Tables\t\n629\nTABLE A-4  Chi-Square 1x22 Distribution\nArea to the Right of the Critical Value\nDegrees of \nFreedom\n \n  0.995\n \n0.99\n \n  0.975\n \n0.95\n \n0.90\n \n  0.10\n \n  0.05\n \n    0.025\n \n  0.01\n \n    0.005\n  1\n—\n—\n  0.001\n  0.004\n  0.016\n    2.706\n    3.841\n    5.024\n    6.635\n    7.879\n  2\n  0.010\n  0.020\n  0.051\n  0.103\n  0.211\n    4.605\n    5.991\n    7.378\n    9.210\n  10.597\n  3\n  0.072\n  0.115\n  0.216\n  0.352\n  0.584\n    6.251\n    7.815\n    9.348\n  11.345\n  12.838\n  4\n  0.207\n  0.297\n  0.484\n  0.711\n  1.064\n    7.779\n    9.488\n  11.143\n  13.277\n  14.860\n  5\n  0.412\n  0.554\n  0.831\n  1.145\n  1.610\n    9.236\n  11.071\n  12.833\n  15.086\n  16.750\n  6\n  0.676\n  0.872\n  1.237\n  1.635\n  2.204\n  10.645\n  12.592\n  14.449\n  16.812\n  18.548\n  7\n  0.989\n  1.239\n  1.690\n  2.167\n  2.833\n  12.017\n  14.067\n  16.013\n  18.475\n  20.278\n  8\n  1.344\n  1.646\n  2.180\n  2.733\n  3.490\n  13.362\n  15.507\n  17.535\n  20.090\n  21.955\n  9\n  1.735\n  2.088\n  2.700\n  3.325\n  4.168\n  14.684\n  16.919\n  19.023\n  21.666\n  23.589\n10\n  2.156\n  2.558\n  3.247\n  3.940\n  4.865\n  15.987\n  18.307\n  20.483\n  23.209\n  25.188\n11\n  2.603\n  3.053\n  3.816\n  4.575\n  5.578\n  17.275\n  19.675\n  21.920\n  24.725\n  26.757\n12\n  3.074\n  3.571\n  4.404\n  5.226\n  6.304\n  18.549\n  21.026\n  23.337\n  26.217\n  28.299\n13\n  3.565\n  4.107\n  5.009\n  5.892\n  7.042\n  19.812\n  22.362\n  24.736\n  27.688\n  29.819\n14\n  4.075\n  4.660\n  5.629\n  6.571\n  7.790\n  21.064\n  23.685\n  26.119\n  29.141\n  31.319\n15\n  4.601\n  5.229\n  6.262\n  7.261\n  8.547\n  22.307\n  24.996\n  27.488\n  30.578\n  32.801\n16\n  5.142\n  5.812\n  6.908\n  7.962\n  9.312\n  23.542\n  26.296\n  28.845\n  32.000\n  34.267\n17\n  5.697\n  6.408\n  7.564\n  8.672\n10.085\n  24.769\n  27.587\n  30.191\n  33.409\n  35.718\n18\n  6.265\n  7.015\n  8.231\n  9.390\n10.865\n  25.989\n  28.869\n  31.526\n  34.805\n  37.156\n19\n  6.844\n  7.633\n  8.907\n10.117\n11.651\n  27.204\n  30.144\n  32.852\n  36.191\n  38.582\n20\n  7.434\n  8.260\n  9.591\n10.851\n12.443\n  28.412\n  31.410\n  34.170\n  37.566\n  39.997\n21\n  8.034\n  8.897\n10.283\n11.591\n13.240\n  29.615\n  32.671\n  35.479\n  38.932\n  41.401\n22\n  8.643\n  9.542\n10.982\n12.338\n14.042\n  30.813\n  33.924\n  36.781\n  40.289\n  42.796\n23\n  9.260\n10.196\n11.689\n13.091\n14.848\n  32.007\n  35.172\n  38.076\n  41.638\n  44.181\n24\n  9.886\n10.856\n12.401\n13.848\n15.659\n  33.196\n  36.415\n  39.364\n  42.980\n  45.559\n25\n10.520\n11.524\n13.120\n14.611\n16.473\n  34.382\n  37.652\n  40.646\n  44.314\n  46.928\n26\n11.160\n12.198\n13.844\n15.379\n17.292\n  35.563\n  38.885\n  41.923\n  45.642\n  48.290\n27\n11.808\n12.879\n14.573\n16.151\n18.114\n  36.741\n  40.113\n  43.194\n  46.963\n  49.645\n28\n12.461\n13.565\n15.308\n16.928\n18.939\n  37.916\n  41.337\n  44.461\n  48.278\n  50.993\n29\n13.121\n14.257\n16.047\n17.708\n19.768\n  39.087\n  42.557\n  45.722\n  49.588\n  52.336\n30\n13.787\n14.954\n16.791\n18.493\n20.599\n  40.256\n  43.773\n  46.979\n  50.892\n  53.672\n40\n20.707\n22.164\n24.433\n26.509\n29.051\n  51.805\n  55.758\n  59.342\n  63.691\n  66.766\n50\n27.991\n29.707\n32.357\n34.764\n37.689\n  63.167\n  67.505\n  71.420\n  76.154\n  79.490\n60\n35.534\n37.485\n40.482\n43.188\n46.459\n  74.397\n  79.082\n  83.298\n  88.379\n  91.952\n70\n43.275\n45.442\n48.758\n51.739\n55.329\n  85.527\n  90.531\n  95.023\n100.425\n104.215\n80\n51.172\n53.540\n57.153\n60.391\n64.278\n  96.578\n101.879\n106.629\n112.329\n116.321\n90\n59.196\n61.754\n65.647\n69.126\n73.291\n107.565\n113.145\n118.136\n124.116\n128.299\n100\n67.328\n70.065\n74.222\n77.929\n82.358\n118.498\n124.342\n129.561\n135.807\n140.169\nSource: Donald B. Owen, Handbook of Statistical Tables.\nDegrees of Freedom\nn - 1\nConfidence interval or hypothesis test for a standard deviation s or variance s2\nk - 1\nGoodness-of-fit test with k different categories\n(r - 1)(c - 1)\nContingency table test with r rows and c columns\nk - 1\nKruskal-Wallis test with k different samples\n",
    "630\t\nAPPENDIX A  Tables\nTABLE A-5  F Distribution (a = 0.025 in the right tail)\nNumerator degrees of freedom (df1)\n1\n2\n3\n4\n5\n6\n7\n8\n9\nDenominator degrees of freedom (df2)\n    1\n  647.79\n  799.50\n  864.16\n  899.58\n  921.85\n  937.11\n  948.22\n  956.66\n  963.28\n    2\n    38.506\n    39.000\n    39.165\n    39.248\n    39.298\n    39.331\n    39.335\n    39.373\n    39.387\n    3\n    17.443\n    16.044\n    15.439\n    15.101\n    14.885\n    14.735\n    14.624\n    14.540\n    14.473\n    4\n    12.218\n    10.649\n9.9792\n9.6045\n9.3645\n9.1973\n9.0741\n8.9796\n8.9047\n    5\n    10.007\n8.4336\n7.7636\n7.3879\n7.1464\n6.9777\n6.8531\n6.7572\n6.6811\n    6\n8.8131\n7.2599\n6.5988\n6.2272\n5.9876\n5.8198\n5.6955\n5.5996\n5.5234\n    7\n8.0727\n6.5415\n5.8898\n5.5226\n5.2852\n5.1186\n4.9949\n4.8993\n4.8232\n    8\n7.5709\n6.0595\n5.4160\n5.0526\n4.8173\n4.6517\n4.5286\n4.4333\n4.3572\n    9\n7.2093\n5.7147\n5.0781\n4.7181\n4.4844\n4.3197\n4.1970\n4.1020\n4.0260\n  10\n6.9367\n5.4564\n4.8256\n4.4683\n4.2361\n4.0721\n3.9498\n3.8549\n3.7790\n  11\n6.7241\n5.2559\n4.6300\n4.2751\n4.0440\n3.8807\n3.7586\n3.6638\n3.5879\n  12\n6.5538\n5.0959\n4.4742\n4.1212\n3.8911\n3.7283\n3.6065\n3.5118\n3.4358\n  13\n6.4143\n4.9653\n4.3472\n3.9959\n3.7667\n3.6043\n3.4827\n3.3880\n3.3120\n  14\n6.2979\n4.8567\n4.2417\n3.8919\n3.6634\n3.5014\n3.3799\n3.2853\n3.2093\n  15\n6.1995\n4.7650\n4.1528\n3.8043\n3.5764\n3.4147\n3.2934\n3.1987\n3.1227\n  16\n6.1151\n4.6867\n4.0768\n3.7294\n3.5021\n3.3406\n3.2194\n3.1248\n3.0488\n  17\n6.0420\n4.6189\n4.0112\n3.6648\n3.4379\n3.2767\n3.1556\n3.0610\n2.9849\n  18\n5.9781\n4.5597\n3.9539\n3.6083\n3.3820\n3.2209\n3.0999\n3.0053\n2.9291\n  19\n5.9216\n4.5075\n3.9034\n3.5587\n3.3327\n3.1718\n3.0509\n2.9563\n2.8801\n  20\n5.8715\n4.4613\n3.8587\n3.5147\n3.2891\n3.1283\n3.0074\n2.9128\n2.8365\n  21\n5.8266\n4.4199\n3.8188\n3.4754\n3.2501\n3.0895\n2.9686\n2.8740\n2.7977\n  22\n5.7863\n4.3828\n3.7829\n3.4401\n3.2151\n3.0546\n2.9338\n2.8392\n2.7628\n  23\n5.7498\n4.3492\n3.7505\n3.4083\n3.1835\n3.0232\n2.9023\n2.8077\n2.7313\n  24\n5.7166\n4.3187\n3.7211\n3.3794\n3.1548\n2.9946\n2.8738\n2.7791\n2.7027\n  25\n5.6864\n4.2909\n3.6943\n3.3530\n3.1287\n2.9685\n2.8478\n2.7531\n2.6766\n  26\n5.6586\n4.2655\n3.6697\n3.3289\n3.1048\n2.9447\n2.8240\n2.7293\n2.6528\n  27\n5.6331\n4.2421\n3.6472\n3.3067\n3.0828\n2.9228\n2.8021\n2.7074\n2.6309\n  28\n5.6096\n4.2205\n3.6264\n3.2863\n3.0626\n2.9027\n2.7820\n2.6872\n2.6106\n  29\n5.5878\n4.2006\n3.6072\n3.2674\n3.0438\n2.8840\n2.7633\n2.6686\n2.5919\n  30\n5.5675\n4.1821\n3.5894\n3.2499\n3.0265\n2.8667\n2.7460\n2.6513\n2.5746\n  40\n5.4239\n4.0510\n3.4633\n3.1261\n2.9037\n2.7444\n2.6238\n2.5289\n2.4519\n  60\n5.2856\n3.9253\n3.3425\n3.0077\n2.7863\n2.6274\n2.5068\n2.4117\n2.3344\n120\n5.1523\n3.8046\n3.2269\n2.8943\n2.6740\n2.5154\n2.3948\n2.2994\n2.2217\n∞\n5.0239\n3.6889\n3.1161\n2.7858\n2.5665\n2.4082\n2.2875\n2.1918\n2.1136\n(continued )\nF\n0.025\n",
    "\t\nAPPENDIX A  Tables\t\n631\nTABLE A-5  (continued) F Distribution (a = 0.025 in the right tail)\nNumerator degrees of freedom (df1)\n10\n12\n15\n20\n24\n30\n40\n60\n120\n∞\nDenominator degrees of freedom (df2)\n    1\n 968.63\n 976.71\n 984.87\n 993.10\n 997.25\n 1001.4\n 1005.6\n 1009.8\n 1014.0\n 1018.3\n    2\n   39.398\n   39.415\n   39.431\n   39.448\n   39.456\n   39.465\n   39.473\n   39.481\n   39.490\n   39.498\n    3\n   14.419\n   14.337\n   14.253\n   14.167\n   14.124\n   14.081\n   14.037\n   13.992\n   13.947\n   13.902\n    4\n8.8439\n8.7512\n8.6565\n8.5599\n8.5109\n8.4613\n8.4111\n8.3604\n8.3092\n8.2573\n    5\n6.6192\n6.5245\n6.4277\n6.3286\n6.2780\n6.2269\n6.1750\n6.1225\n6.0693\n6.0153\n    6\n5.4613\n5.3662\n5.2687\n5.1684\n5.1172\n5.0652\n5.0125\n4.9589\n4.9044\n4.8491\n    7\n4.7611\n4.6658\n4.5678\n4.4667\n4.4150\n4.3624\n4.3089\n4.2544\n4.1989\n4.1423\n    8\n4.2951\n4.1997\n4.1012\n3.9995\n3.9472\n3.8940\n3.8398\n3.7844\n3.7279\n3.6702\n    9\n3.9639\n3.8682\n3.7694\n3.6669\n3.6142\n3.5604\n3.5055\n3.4493\n3.3918\n3.3329\n  10\n3.7168\n3.6209\n3.5217\n3.4185\n3.3654\n3.3110\n3.2554\n3.1984\n3.1399\n3.0798\n  11\n3.5257\n3.4296\n3.3299\n3.2261\n3.1725\n3.1176\n3.0613\n3.0035\n2.9441\n2.8828\n  12\n3.3736\n3.2773\n3.1772\n3.0728\n3.0187\n2.9633\n2.9063\n2.8478\n2.7874\n2.7249\n  13\n3.2497\n3.1532\n3.0527\n2.9477\n2.8932\n2.8372\n2.7797\n2.7204\n2.6590\n2.5955\n  14\n3.1469\n3.0502\n2.9493\n2.8437\n2.7888\n2.7324\n2.6742\n2.6142\n2.5519\n2.4872\n  15\n3.0602\n2.9633\n2.8621\n2.7559\n2.7006\n2.6437\n2.5850\n2.5242\n2.4611\n2.3953\n  16\n2.9862\n2.8890\n2.7875\n2.6808\n2.6252\n2.5678\n2.5085\n2.4471\n2.3831\n2.3163\n  17\n2.9222\n2.8249\n2.7230\n2.6158\n2.5598\n2.5020\n2.4422\n2.3801\n2.3153\n2.2474\n  18\n2.8664\n2.7689\n2.6667\n2.5590\n2.5027\n2.4445\n2.3842\n2.3214\n2.2558\n2.1869\n  19\n2.8172\n2.7196\n2.6171\n2.5089\n2.4523\n2.3937\n2.3329\n2.2696\n2.2032\n2.1333\n  20\n2.7737\n2.6758\n2.5731\n2.4645\n2.4076\n2.3486\n2.2873\n2.2234\n2.1562\n2.0853\n  21\n2.7348\n2.6368\n2.5338\n2.4247\n2.3675\n2.3082\n2.2465\n2.1819\n2.1141\n2.0422\n  22\n2.6998\n2.6017\n2.4984\n2.3890\n2.3315\n2.2718\n2.2097\n2.1446\n2.0760\n2.0032\n  23\n2.6682\n2.5699\n2.4665\n2.3567\n2.2989\n2.2389\n2.1763\n2.1107\n2.0415\n1.9677\n  24\n2.6396\n2.5411\n2.4374\n2.3273\n2.2693\n2.2090\n2.1460\n2.0799\n2.0099\n1.9353\n  25\n2.6135\n2.5149\n2.4110\n2.3005\n2.2422\n2.1816\n2.1183\n2.0516\n1.9811\n1.9055\n  26\n2.5896\n2.4908\n2.3867\n2.2759\n2.2174\n2.1565\n2.0928\n2.0257\n1.9545\n1.8781\n  27\n2.5676\n2.4688\n2.3644\n2.2533\n2.1946\n2.1334\n2.0693\n2.0018\n1.9299\n1.8527\n  28\n2.5473\n2.4484\n2.3438\n2.2324\n2.1735\n2.1121\n2.0477\n1.9797\n1.9072\n1.8291\n  29\n2.5286\n2.4295\n2.3248\n2.2131\n2.1540\n2.0923\n2.0276\n1.9591\n1.8861\n1.8072\n  30\n2.5112\n2.4120\n2.3072\n2.1952\n2.1359\n2.0739\n2.0089\n1.9400\n1.8664\n1.7867\n  40\n2.3882\n2.2882\n2.1819\n2.0677\n2.0069\n1.9429\n1.8752\n1.8028\n1.7242\n1.6371\n  60\n2.2702\n2.1692\n2.0613\n1.9445\n1.8817\n1.8152\n1.7440\n1.6668\n1.5810\n1.4821\n120\n2.1570\n2.0548\n1.9450\n1.8249\n1.7597\n1.6899\n1.6141\n1.5299\n1.4327\n1.3104\n∞\n2.0483\n1.9447\n1.8326\n1.7085\n1.6402\n1.5660\n1.4835\n1.3883\n1.2684\n1.0000\nBased on data from Maxine Merrington and Catherine M. Thompson, “Tables of Percentage Points of the Inverted Beta (F ) Distribution,” Biometrika 33 (1943): 80–84.\n",
    "632\t\nAPPENDIX A  Tables\nTABLE A-5  (continued) F Distribution (a = 0.05 in the right tail)\nNumerator degrees of freedom (df1)\n1\n2\n3\n4\n5\n6\n7\n8\n9\nDenominator degrees of freedom (df2)\n    1\n  161.45\n  199.50\n  215.71\n  224.58\n  230.16\n  233.99\n  236.77\n  238.88\n 240.54\n    2\n    18.513\n    19.000\n    19.164\n    19.247\n    19.296\n    19.330\n    19.353\n    19.371\n   19.385\n    3\n    10.128\n9.5521\n9.2766\n9.1172\n9.0135\n8.9406\n8.8867\n8.8452\n8.8123\n    4\n7.7086\n6.9443\n6.5914\n6.3882\n6.2561\n6.1631\n6.0942\n6.0410\n6.9988\n    5\n6.6079\n5.7861\n5.4095\n5.1922\n5.0503\n4.9503\n4.8759\n4.8183\n4.7725\n    6\n5.9874\n5.1433\n4.7571\n4.5337\n4.3874\n4.2839\n4.2067\n4.1468\n4.0990\n    7\n5.5914\n4.7374\n4.3468\n4.1203\n3.9715\n3.8660\n3.7870\n3.7257\n3.6767\n    8\n5.3177\n4.4590\n4.0662\n3.8379\n3.6875\n3.5806\n3.5005\n3.4381\n3.3881\n    9\n5.1174\n4.2565\n3.8625\n3.6331\n3.4817\n3.3738\n3.2927\n3.2296\n3.1789\n  10\n4.9646\n4.1028\n3.7083\n3.4780\n3.3258\n3.2172\n3.1355\n3.0717\n3.0204\n  11\n4.8443\n3.9823\n3.5874\n3.3567\n3.2039\n3.0946\n3.0123\n2.9480\n2.8962\n  12\n4.7472\n3.8853\n3.4903\n3.2592\n3.1059\n2.9961\n2.9134\n2.8486\n2.7964\n  13\n4.6672\n3.8056\n3.4105\n3.1791\n3.0254\n2.9153\n2.8321\n2.7669\n2.7144\n  14\n4.6001\n3.7389\n3.3439\n3.1122\n2.9582\n2.8477\n2.7642\n2.6987\n2.6458\n  15\n4.5431\n3.6823\n3.2874\n3.0556\n2.9013\n2.7905\n2.7066\n2.6408\n2.5876\n  16\n4.4940\n3.6337\n3.2389\n3.0069\n2.8524\n2.7413\n2.6572\n2.5911\n2.5377\n  17\n4.4513\n3.5915\n3.1968\n2.9647\n2.8100\n2.6987\n2.6143\n2.5480\n2.4943\n  18\n4.4139\n3.5546\n3.1599\n2.9277\n2.7729\n2.6613\n2.5767\n2.5102\n2.4563\n  19\n4.3807\n3.5219\n3.1274\n2.8951\n2.7401\n2.6283\n2.5435\n2.4768\n2.4227\n  20\n4.3512\n3.4928\n3.0984\n2.8661\n2.7109\n2.5990\n2.5140\n2.4471\n2.3928\n  21\n4.3248\n3.4668\n3.0725\n2.8401\n2.6848\n2.5727\n2.4876\n2.4205\n2.3660\n  22\n4.3009\n3.4434\n3.0491\n2.8167\n2.6613\n2.5491\n2.4638\n2.3965\n2.3419\n  23\n4.2793\n3.4221\n3.0280\n2.7955\n2.6400\n2.5277\n2.4422\n2.3748\n2.3201\n  24\n4.2597\n3.4028\n3.0088\n2.7763\n2.6207\n2.5082\n2.4226\n2.3551\n2.3002\n  25\n4.2417\n3.3852\n2.9912\n2.7587\n2.6030\n2.4904\n2.4047\n2.3371\n2.2821\n  26\n4.2252\n3.3690\n2.9752\n2.7426\n2.5868\n2.4741\n2.3883\n2.3205\n2.2655\n  27\n4.2100\n3.3541\n2.9604\n2.7278\n2.5719\n2.4591\n2.3732\n2.3053\n2.2501\n  28\n4.1960\n3.3404\n2.9467\n2.7141\n2.5581\n2.4453\n2.3593\n2.2913\n2.2360\n  29\n4.1830\n3.3277\n2.9340\n2.7014\n2.5454\n2.4324\n2.3463\n2.2783\n2.2229\n  30\n4.1709\n3.3158\n2.9223\n2.6896\n2.5336\n2.4205\n2.3343\n2.2662\n2.2107\n  40\n4.0847\n3.2317\n2.8387\n2.6060\n2.4495\n2.3359\n2.2490\n2.1802\n2.1240\n  60\n4.0012\n3.1504\n2.7581\n2.5252\n2.3683\n2.2541\n2.1665\n2.0970\n2.0401\n120\n3.9201\n3.0718\n2.6802\n2.4472\n2.2899\n2.1750\n2.0868\n2.0164\n1.9588\n∞\n3.8415\n2.9957\n2.6049\n2.3719\n2.2141\n2.0986\n2.0096\n1.9384\n1.8799\nF\n0.05\n(continued )\n",
    "\t\nAPPENDIX A  Tables\t\n633\nTABLE A-5  (continued) F Distribution (a = 0.05 in the right tail)\nNumerator degrees of freedom (df1)\n10\n12\n15\n20\n24\n30\n40\n60\n120\n∞\nDenominator degrees of freedom (df2)\n    1\n 241.88\n 243.91\n 245.95\n248.01\n 249.05\n 250.10\n 251.14\n 252.20\n 253.25\n 254.31\n    2\n   19.396\n   19.413\n   19.429\n19.446\n   19.454\n   19.462\n   19.471\n   19.479\n   19.487\n   19.496\n    3\n8.7855\n8.7446\n8.7029\n8.6602\n8.6385\n8.6166\n8.5944\n8.5720\n8.5494\n8.5264\n    4\n5.9644\n5.9117\n5.8578\n5.8025\n5.7744\n5.7459\n5.7170\n5.6877\n5.6581\n5.6281\n    5\n4.7351\n4.6777\n4.6188\n4.5581\n4.5272\n4.4957\n4.4638\n4.4314\n4.3985\n4.3650\n    6\n4.0600\n3.9999\n3.9381\n3.8742\n3.8415\n3.8082\n3.7743\n3.7398\n3.7047\n3.6689\n    7\n3.6365\n3.5747\n3.5107\n3.4445\n3.4105\n3.3758\n3.3404\n3.3043\n3.2674\n3.2298\n    8\n3.3472\n3.2839\n3.2184\n3.1503\n3.1152\n3.0794\n3.0428\n3.0053\n2.9669\n2.9276\n    9\n3.1373\n3.0729\n3.0061\n2.9365\n2.9005\n2.8637\n2.8259\n2.7872\n2.7475\n2.7067\n  10\n2.9782\n2.9130\n2.8450\n2.7740\n2.7372\n2.6996\n2.6609\n2.6211\n2.5801\n2.5379\n  11\n2.8536\n2.7876\n2.7186\n2.6464\n2.6090\n2.5705\n2.5309\n2.4901\n2.4480\n2.4045\n  12\n2.7534\n2.6866\n2.6169\n2.5436\n2.5055\n2.4663\n2.4259\n2.3842\n2.3410\n2.2962\n  13\n2.6710\n2.6037\n2.5331\n2.4589\n2.4202\n2.3803\n2.3392\n2.2966\n2.2524\n2.2064\n  14\n2.6022\n2.5342\n2.4630\n2.3879\n2.3487\n2.3082\n2.2664\n2.2229\n2.1778\n2.1307\n  15\n2.5437\n2.4753\n2.4034\n2.3275\n2.2878\n2.2468\n2.2043\n2.1601\n2.1141\n2.0658\n  16\n2.4935\n2.4247\n2.3522\n2.2756\n2.2354\n2.1938\n2.1507\n2.1058\n2.0589\n2.0096\n  17\n2.4499\n2.3807\n2.3077\n2.2304\n2.1898\n2.1477\n2.1040\n2.0584\n2.0107\n1.9604\n  18\n2.4117\n2.3421\n2.2686\n2.1906\n2.1497\n2.1071\n2.0629\n2.0166\n1.9681\n1.9168\n  19\n2.3779\n2.3080\n2.2341\n2.1555\n2.1141\n2.0712\n2.0264\n1.9795\n1.9302\n1.8780\n  20\n2.3479\n2.2776\n2.2033\n2.1242\n2.0825\n2.0391\n1.9938\n1.9464\n1.8963\n1.8432\n  21\n2.3210\n2.2504\n2.1757\n2.0960\n2.0540\n2.0102\n1.9645\n1.9165\n1.8657\n1.8117\n  22\n2.2967\n2.2258\n2.1508\n2.0707\n2.0283\n1.9842\n1.9380\n1.8894\n1.8380\n1.7831\n  23\n2.2747\n2.2036\n2.1282\n2.0476\n2.0050\n1.9605\n1.9139\n1.8648\n1.8128\n1.7570\n  24\n2.2547\n2.1834\n2.1077\n2.0267\n1.9838\n1.9390\n1.8920\n1.8424\n1.7896\n1.7330\n  25\n2.2365\n2.1649\n2.0889\n2.0075\n1.9643\n1.9192\n1.8718\n1.8217\n1.7684\n1.7110\n  26\n2.2197\n2.1479\n2.0716\n1.9898\n1.9464\n1.9010\n1.8533\n1.8027\n1.7488\n1.6906\n  27\n2.2043\n2.1323\n2.0558\n1.9736\n1.9299\n1.8842\n1.8361\n1.7851\n1.7306\n1.6717\n  28\n2.1900\n2.1179\n2.0411\n1.9586\n1.9147\n1.8687\n1.8203\n1.7689\n1.7138\n1.6541\n  29\n2.1768\n2.1045\n2.0275\n1.9446\n1.9005\n1.8543\n1.8055\n1.7537\n1.6981\n1.6376\n  30\n2.1646\n2.0921\n2.0148\n1.9317\n1.8874\n1.8409\n1.7918\n1.7396\n1.6835\n1.6223\n  40\n2.0772\n2.0035\n1.9245\n1.8389\n1.7929\n1.7444\n1.6928\n1.6373\n1.5766\n1.5089\n  60\n1.9926\n1.9174\n1.8364\n1.7480\n1.7001\n1.6491\n1.5943\n1.5343\n1.4673\n1.3893\n120\n1.9105\n1.8337\n1.7505\n1.6587\n1.6084\n1.5543\n1.4952\n1.4290\n1.3519\n1.2539\n∞\n1.8307\n1.7522\n1.6664\n1.5705\n1.5173\n1.4591\n1.3940\n1.3180\n1.2214\n1.0000\nBased on data from Maxine Merrington and Catherine M. Thompson, “Tables of Percentage Points of the Inverted Beta (F ) Distribution,” Biometrika 33 (1943): 80–84.\n",
    "634\t\nAPPENDIX A  Tables\nTABLE A-6  \u0007Critical Values of the  \nPearson Correlation  \nCoefficient r\nn\na = .05\na = .01\n    4\n.950\n.990\n    5\n.878\n.959\n    6\n.811\n.917\n    7\n.754\n.875\n    8\n.707\n.834\n    9\n.666\n.798\n  10\n.632\n.765\n  11\n.602\n.735\n  12\n.576\n.708\n  13\n.553\n.684\n  14\n.532\n.661\n  15\n.514\n.641\n  16\n.497\n.623\n  17\n.482\n.606\n  18\n.468\n.590\n  19\n.456\n.575\n  20\n.444\n.561\n  25\n.396\n.505\n  30\n.361\n.463\n  35\n.335\n.430\n  40\n.312\n.402\n  45\n.294\n.378\n  50\n.279\n.361\n  60\n.254\n.330\n  70\n.236\n.305\n  80\n.220\n.286\n  90\n.207\n.269\n100\n.196\n.256\nNOTE: To test H0: r = 0 (no correlation) against  \nH1: r ≠0 (correlation), reject H0 if the absolute value of r \nis greater than or equal to the critical value in the table.\n",
    "\t\nAPPENDIX A  Tables\t\n635\nTABLE A-7  Critical Values for the Sign Test\na\n \n \n \n \nn\n.005 \n(one tail) \n.01 \n(two tails)\n.01 \n(one tail) \n.02 \n(two tails)\n.025 \n(one tail) \n.05 \n(two tails)\n.05 \n(one tail) \n.10 \n(two tails)\n  1\n*\n*\n*\n*\n  2\n*\n*\n*\n*\n  3\n*\n*\n*\n*\n  4\n*\n*\n*\n*\n  5\n*\n*\n*\n0\n  6\n*\n*\n0\n0\n  7\n*\n0\n0\n0\n  8\n0\n0\n0\n1\n  9\n0\n0\n1\n1\n10\n0\n0\n1\n1\n11\n0\n1\n1\n2\n12\n1\n1\n2\n2\n13\n1\n1\n2\n3\n14\n1\n2\n2\n3\n15\n2\n2\n3\n3\n16\n2\n2\n3\n4\n17\n2\n3\n4\n4\n18\n3\n3\n4\n5\n19\n3\n4\n4\n5\n20\n3\n4\n5\n5\n21\n4\n4\n5\n6\n22\n4\n5\n5\n6\n23\n4\n5\n6\n7\n24\n5\n5\n6\n7\n25\n5\n6\n7\n7\nNOTES:\n1.  \u0007*indicates that it is not possible to get a value in the critical region, so fail to reject the \nnull hypothesis.\n2.  \u0007Reject the null hypothesis if the number of the less frequent sign (x) is less than or \nequal to the value in the table.\n3.  \u0007For values of n greater than 25, a normal approximation is used with\nz =\n1x + 0.52 - an\n2 b\n1n\n2\n",
    "636\t\nAPPENDIX A  Tables\nTABLE A-8  Critical Values of T for the Wilcoxon Signed-Ranks Test\na\n \n \n \n \nn\n.005 \n(one tail) \n.01 \n(two tails)\n.01 \n(one tail) \n.02 \n(two tails)\n.025 \n(one tail) \n.05 \n(two tails)\n.05 \n(one tail) \n.10 \n(two tails)\n  5\n*\n*\n*\n  1\n  6\n*\n*\n  1\n  2\n  7\n*\n  0\n  2\n  4\n  8\n  0\n  2\n  4\n  6\n  9\n  2\n  3\n  6\n  8\n10\n  3\n  5\n  8\n11\n11\n  5\n  7\n11\n14\n12\n  7\n10\n14\n17\n13\n10\n13\n17\n21\n14\n13\n16\n21\n26\n15\n16\n20\n25\n30\n16\n19\n24\n30\n36\n17\n23\n28\n35\n41\n18\n28\n33\n40\n47\n19\n32\n38\n46\n54\n20\n37\n43\n52\n60\n21\n43\n49\n59\n68\n22\n49\n56\n66\n75\n23\n55\n62\n73\n83\n24\n61\n69\n81\n92\n25\n68\n77\n90\n101\n26\n76\n85\n98\n110\n27\n84\n93\n107\n120\n28\n92\n102\n117\n130\n29\n100\n111\n127\n141\n30\n109\n120\n137\n152\nNOTES:\n1.  \u0007*indicates that it is not possible to get a value in the critical region, so fail to reject the null \nhypothesis.\n2.  \u0007Conclusions:\n     \u0007Reject the null hypothesis if the test statistic T is less than or equal to the critical value found in \nthis table.\n     \u0007Fail to reject the null hypothesis if the test statistic T is greater than the critical value found  \nin the table.\nBased on data from Some Rapid Approximate Statistical Procedures, Copyright © 1949, 1964 \nLederle Laboratories Division of American Cyanamid Company.\n",
    "\t\nAPPENDIX A  Tables\t\n637\nTABLE A-9  \u0007Critical Values of Spearman’s Rank  \nCorrelation Coefficient rs\nn\na = 0.10\na = 0.05\na = 0.02\na = 0.01\n  5\n.900\n—\n—\n—\n  6\n.829\n.886\n.943\n—\n  7\n.714\n.786\n.893\n.929\n  8\n.643\n.738\n.833\n.881\n  9\n.600\n.700\n.783\n.833\n10\n.564\n.648\n.745\n.794\n11\n.536\n.618\n.709\n.755\n12\n.503\n.587\n.678\n.727\n13\n.484\n.560\n.648\n.703\n14\n.464\n.538\n.626\n.679\n15\n.446\n.521\n.604\n.654\n16\n.429\n.503\n.582\n.635\n17\n.414\n.485\n.566\n.615\n18\n.401\n.472\n.550\n.600\n19\n.391\n.460\n.535\n.584\n20\n.380\n.447\n.520\n.570\n21\n.370\n.435\n.508\n.556\n22\n.361\n.425\n.496\n.544\n23\n.353\n.415\n.486\n.532\n24\n.344\n.406\n.476\n.521\n25\n.337\n.398\n.466\n.511\n26\n.331\n.390\n.457\n.501\n27\n.324\n.382\n.448\n.491\n28\n.317\n.375\n.440\n.483\n29\n.312\n.368\n.433\n.475\n30\n.306\n.362\n.425\n.467\nNOTES:\n1.  \u0007For n 7 30 use rs { z> 1n - 1, where z corresponds to the level of significance. \nFor example, if a = 0.05, then z = 1.96.\n2.  \u0007If the absolute value of the test statistic rs is greater than or equal to the positive \ncritical value, then reject H0: rs = 0 and conclude that there is sufficient evidence to \nsupport the claim of a correlation.\nBased on data from Biostatistical Analysis, 4th edition © 1999, by Jerrold Zar, Prentice \nHall, Inc., Upper Saddle River, New Jersey, and “Distribution of Sums of Squares of Rank \nDifferences to Small Numbers with Individuals,” The Annals of Mathematical Statistics, \nVol. 9, No. 2.\nrs\n1\n21\n2rs\na\u001f2\na\u001f2\n",
    "APPENDIX B\nData Sets\nComplete data sets available at www.TriolaStats.com\nThis appendix lists only the first five rows of each data set. The complete data sets \nare available for download at www.TriolaStats.com for a variety of technologies, \nincluding Excel, SPSS, JMP, Minitab, and TI-83>84 Plus calculators. These data sets \nare included with Statdisk, which is free to users of this textbook; Statdisk can be \ndownloaded at www.statdisk.org.\nData Set 1:\t Body Data\nData Set 2:\t Body Temperatures\nData Set 3:\t Births\nData Set 4:\t Audiometry\nData Set 5:\t Vision\nData Set 6:\t Family Heights\nData Set 7:\t Foot and Height\nData Set 8:\t IQ and Lead\nData Set 9:\t IQ and Brain Size\nData Set 10:\tFreshman 15\nData Set 11:\tBear Measurements\nData Set 12:\tManatee Deaths\nData Set 13:\tAlcohol and Tobacco in Movies\nData Set 14:\tPassive and Active Smoke\nData Set 15:\tCigarette Contents\nData Set 16:\tIris Measurements\nData Set 17:\tCuckoo Egg Lengths\nData Set 18:\tPoplar Tree Weights\n638\n",
    "AGE\nGENDER (1 = M)\nPULSE\nSYSTOLIC\nDIASTOLIC\nHDL\nLDL\nWHITE\nRED\nPLATE\nWEIGHT\nHEIGHT\nWAIST\nARM CIRC\nBMI\n43\n0\n80\n100\n70\n73\n  68\n8.7\n4.80\n319\n  98.6\n172.0\n120.4\n40.7\n33.3\n57\n1\n84\n112\n70\n35\n116\n4.9\n4.73\n187\n  96.9\n186.0\n107.8\n37.0\n28.0\n38\n0\n94\n134\n94\n36\n223\n6.9\n4.47\n297\n108.2\n154.4\n120.3\n44.3\n45.4\n80\n1\n74\n126\n64\n37\n  83\n7.5\n4.32\n170\n  73.1\n160.5\n  97.2\n30.3\n28.4\n34\n1\n50\n114\n68\n50\n104\n6.1\n4.95\n140\n  83.1\n179.0\n  95.1\n34.0\n25.9\nData Set 1: Body Data\nBody and exam measurements are from 300 subjects (first five rows \nshown here). AGE is in years, for GENDER 0 = female and 1 =\nmale, PULSE is pulse rate (beats per minute), SYSTOLIC is systolic \nblood pressure (mm Hg), DIASTOLIC is diastolic blood pressure \n(mm Hg), HDL is HDL cholesterol (mg>dL), LDL is LDL choles-\nterol (mg>dL), WHITE is white blood cell count (1000 cells>mL),\n(1000 cells>mL), RED is red blood cell count (million cells>mL), \nPLATE is platelet count (1000 cells>mL), WEIGHT is weight (kg), \nHEIGHT is height (cm), WAIST is circumference (cm), ARM CIRC \nis arm circumference (cm), and BMI is body mass index (kg>m2). Data \nare from the National Center for Health Statistics.\nTI-83 , 84 list names  \u0007AGE, GENDR, PULSE, SYS, DIAS, HDL, \n(BODY):\t\n\u0007LDL, WHITE, REDBC, PLATE, WT, HT, \nWAIST, ARMC, BMI\nData Set 2: Body Temperatures\nBody temperatures (°F) are from 107 subjects taken on two consecu-\ntive days at 8 AM and 12 AM (first five rows shown here). SEX is gen-\nder of subject, and SMOKE indicates if subject smokes (Y) or does \nnot smoke (N). Data provided by Dr. Steven Wasserman, Dr. Philip \nMackowiak, and Dr. Myron Levine of the University of Maryland.\nTI-83 , 84 list names  D1T8, D1T12, D2T8, D2T12 \n(BODYTEMP):\t\n\u0007(no list for SEX and SMOKE). \nMissing data values are represented by 9999.\nSEX\nSMOKE\nDAY 1—8 AM\nDAY 1—12 AM\nDAY 2—8 AM\nDAY 2—12 AM\nM\nY\n98.0\n98.0\n98.0\n98.6\nM\nY\n97.0\n97.6\n97.4\n—\nM\nY\n98.6\n98.8\n97.8\n98.6\nM\nN\n97.4\n98.0\n97.0\n98.0\nM\nN\n98.2\n98.8\n97.0\n98.0\nData Set 3: Births\nData are from 400 births (first five rows shown here). For GENDER \n0 = female and 1 = male. LENGTH OF STAY is in days, BIRTH \nWEIGHT is in grams, and TOTAL CHARGES are in dollars.\nTI-83 , 84 list names  \u0007FLOS, MLOS, FBWT, MBWT, FCHRG, \n(BIRTHS):\t\n\u0007MCHRG [Separate lists provided for female \n(F) and male (M) babies. No list for  \nFACILITY, INSURANCE, ADMITTED,  \nand DISCHARGED]\nFACILITY\nINSURANCE\nGENDER (1 = M)\nLENGTH OF STAY\nADMITTED\nDISCHARGED\nBIRTH WEIGHT\nTOTAL CHARGES\nAlbany Medical Center Hospital\nInsurance Company\n0\n  2\nFRI\nSUN\n3500\n  13986\nAlbany Medical Center Hospital\nBlue Cross\n1\n  2\nFRI\nSUN\n3900\n    3633\nAlbany Medical Center Hospital\nBlue Cross\n0\n36\nWED\nTHU\n  800\n359091\nAlbany Medical Center Hospital\nInsurance Company\n1\n  5\nMON\nSAT\n2800\n    8537\nAlbany Medical Center Hospital\nInsurance Company\n1\n  2\nFRI\nSUN\n3700\n    3633\n\t\nAPPENDIX B  Data Sets\t\n639\n(Complete data sets available at www.TriolaStats.com)\n",
    "640\t\nAPPENDIX B  Data Sets\n(Complete data sets available at www.TriolaStats.com)\n640\t\nAPPENDIX B  Data Sets\nData Set 4: Audiometry\nData are from 350 subjects (first five rows shown here). AGE is in \nyears, for GENDER 0 = female and 1 = male, and RIGHT , LEFT \nTHRESHOLD are hearing measurements in each ear using pure tone \nsounds sent through earphones. Intensity of sound is varied until hear-\ning threshold at frequency of 1000 Hz (db) is identified. Data are from \nthe National Center for Health Statistics.\nTI-83 , 84 list names  AUDAG, AUDGN, AUDRT, AUDLT \n(AUDIO):\nAGE\nGENDER\nRIGHT THRESHOLD\nLEFT THRESHLOD\n42\n1\n  5\n  5\n46\n0\n  5\n15\n51\n0\n  5\n10\n70\n0\n15\n20\n78\n1\n  5\n10\nData Set 5: Vision\nData are from 300 subjects (first five rows shown here). AGE is in \nyears, for GENDER 0 = female and 1 = male, and RIGHT , LEFT \nEYE is measure of visual acuity with “usual correction,” which could \nbe eyeglasses, contacts, or no correction. Data are from the National \nCenter for Health Statistics.\nTI-83 , 84 list names  VISAG, VISGN, VISRT, VISLT\n(VISION):\nAGE\nGENDER\nRIGHT EYE\nLEFT EYE\n39\n1\n20\n20\n48\n1\n20\n20\n84\n0\n25\n20\n55\n0\n25\n20\n41\n1\n50\n50\nData Set 6: Family Heights\nHeight data are from 134 families (first five rows shown here). \nHeights are in inches. Only families with at least one child of each \ngender are included, and only heights of the first son and first \n­daughter are included. The data are from a journal of Francis Galton  \n(1822–1911), who developed the concepts of standard deviation, \n­regression line, and correlation between two variables.\nTI-83 , 84 list names  DAD, MOM, SON1, DGHT1\n(FAMHT):\nFATHER\nMOTHER\nFIRST SON\nFIRST DAUGHTER\n70.0\n64.0\n68.0\n65.0\n71.0\n65.5\n72.0\n66.0\n69.0\n63.5\n70.5\n65.0\n69.5\n66.0\n71.0\n66.5\n70.0\n58.0\n72.0\n66.0\n",
    "\t\nAPPENDIX B  Data Sets\t\n641\n(Complete data sets available at www.TriolaStats.com)\n\t\nAPPENDIX B  Data Sets\t\n641\nData Set 7: Foot and Height\nFoot and height measurements are from 40 subjects (first five rows \nshown here). SEX is gender of subject, AGE is age in years, FOOT \nLENGTH is length of foot (cm), SHOE PRINT is length of shoe \n(cm), SHOE SIZE is reported shoe size, and HEIGHT is height (cm) \nof the subject.\nData from Rohren, Brenda, “Estimation of Stature from Foot and \nShoe Length: Applications in Forensic Science.” Copyright © 2006. \nReprinted by permission of the author. Brenda Rohren (MA, MFS, \nLIMHP, LADC, MAC) was a graduate student at Nebraska Wesleyan \nUniversity when she conducted the research and wrote the report.\nTI-83 , 84 list names  \u0007FTSEX (1 = male), FTAGE, FTLN, SHOPT, \n(FOOTHT):\t\nSHOSZ, FHT\nSEX\nAGE\nFOOT LENGTH\nSHOE PRINT\nSHOE SIZE\nHEIGHT\nM\n67\n27.8\n31.3\n11.0\n180.3\nM\n47\n25.7\n29.7\n  9.0\n175.3\nM\n41\n26.7\n31.3\n11.0\n184.8\nM\n42\n25.9\n31.8\n10.0\n177.8\nM\n48\n26.4\n31.4\n10.0\n182.3\nData Set 8: IQ and Lead\nData are from 121 subjects (first five rows shown here). Data are mea-\nsured from children in two consecutive years, and the children were \nliving close to a lead smelter. LEAD is blood lead level group  \n[1 =  low lead level (blood lead levels 6 40 micrograms>100 mL \nin both years), 2 =  medium lead level (blood lead levels Ú  \n40 micrograms>100 mL in exactly one of two years), 3 =  high lead \nlevel (blood lead level Ú 40 micrograms>100 mL in both years)]. AGE \nis age in years, SEX is sex of subject (1 = male; 2 = female). YEAR1 \nis blood lead level in first year, and YEAR2 is blood lead level in \nsecond year. IQ VERB is measured verbal IQ score. IQ PERF is mea-\nsured performance IQ score. IQ FULL is measured full IQ score.\nData are from “Neuropsychological Dysfunction in Children \nwith Chronic Low-Level Lead Absorption,” by P. J. Landrigan,  \nR. H. Whitworth, R. W. Baloh, N. W. Staehling, W. F Barthel, and  \nB. F. Rosenblum, Lancet, Vol. 1, No. 7909.\nTI-83 , 84 list names  LEAD, IQAGE, IQSEX, YEAR1,  \n(IQLEAD):\t\nYEAR2, IQV, IQP, IQF\nLEAD\nAGE\nSEX\nYEAR1\nYEAR2\nIQ VERB\nIQ PERF\nIQ FULL\n1\n11\n1\n25\n18\n61\n  85\n70\n1\n  9\n1\n31\n28\n82\n  90\n85\n1\n11\n1\n30\n29\n70\n107\n86\n1\n  6\n1\n29\n30\n72\n  85\n76\n1\n11\n1\n  2\n34\n72\n100\n84\nData Set 9: IQ and Brain Size\nData are from 20 monozygotic (identical) twins (first five rows shown \nhere). PAIR identifies the set of twins, SEX is the gender of the \nsubject 11 = male, 2 = female2, ORDER is the birth order, IQ is \nmeasured full IQ score, VOL is total brain volume (cm3), AREA is \ntotal brain surface area (cm2), CCSA is corpus callosum (fissure con-\nnecting left and right cerebral hemispheres) surface area (cm2), CIRC \nis head circumference (cm), and WT is body weight (kg).\nData provided by M. J. Tramo, W. C. Loftus, T. A. Stukel,  \nJ. B. Weaver, M. S. Gazziniga. See “Brain Size, Head Size, and IQ in \nMonozygotic Twins,” Neurology, Vol. 50.\nTI-83 , 84 list names  PAIR, SEX, ORDER, IQ, VOL, AREA,  \n(IQBRAIN):\t\nCCSA, CIRC, BWT\nPAIR\nSEX (1 = M)\nORDER\nIQ\nVOL\nAREA\nCCSA\nCIRC\nWT\n1\n2\n1\n  96\n1005\n1913.88\n6.08\n54.7\n57.607\n1\n2\n2\n  89\n  963\n1684.89\n5.73\n54.2\n58.968\n2\n2\n1\n  87\n1035\n1902.36\n6.22\n53.0\n64.184\n2\n2\n2\n  87\n1027\n1860.24\n5.80\n52.9\n58.514\n3\n2\n1\n101\n1281\n2264.25\n7.99\n57.8\n63.958\n",
    "642\t\nAPPENDIX B  Data Sets\n(Complete data sets available at www.TriolaStats.com)\nData Set 10: Freshman 15\nWeights of 67 college students are provided (first five rows shown \nhere). SEX is gender of subject, WT is weight in kilograms, and BMI \nis measured body mass index. Measurements were made in September \nof freshman year and then later in April of freshman year.\nResults are published in Hoffman, D. J., Policastro, P., Quick, V., \nand Lee, S. K.: “Changes in Body Weight and Fat Mass of Men and \nWomen in the First Year of College: A Study of the ‘Freshman 15.’” \nJournal of American College Health, July 1, 2006, Vol. 55, No. 1,  \np. 41. Copyright © 2006. Reprinted by permission.\nTI-83 , 84 list names  WTSP, WTAPR, BMISP, BMIAP  \n(FRESH15): \t\n(no list for SEX)\nSEX\nWT SEPT\nWT APRIL\nBMI SEPT\nBMI APRIL\nM\n72\n59\n22.02\n18.14\nM\n97\n86\n19.70\n17.44\nM\n74\n69\n24.09\n22.43\nM\n93\n88\n26.97\n25.57\nF\n68\n64\n21.51\n20.10\nData Set 11: Bear Measurements\nData are from 54 anesthetized wild bears (first five rows shown \nhere). AGE is in months, MONTH is the month of measurement \nwith 1 = January, SEX is coded with 0 = female and 1 = male, \nHEADLEN is head length (inches), HEADWDTH is width of head \n(inches), NECK is distance around neck (in inches), LENGTH is \nlength of body (inches), CHEST is distance around chest (inches), \nand WEIGHT is measured in pounds. Data are from Gary Alt and \nMinitab, Inc.\nTI-83 , 84 list names   BAGE, BSEX, BHDLN, BHDWD, BNECK,  \n(BEARS):\t\n\u0007BLEN, BCHST, BWGHT (no list for \nMONTH)\nAGE\nMONTH\nSEX (1 = M)\nHEADLEN\nHEADWDTH\nNECK\nLENGTH\nCHEST\nWEIGHT\n  19\n7\n1\n11.0\n  5.5\n16.0\n53.0\n26.0\n  80\n  55\n7\n1\n16.5\n  9.0\n28.0\n67.5\n45.0\n344\n  81\n9\n1\n15.5\n  8.0\n31.0\n72.0\n54.0\n416\n115\n7\n1\n17.0\n10.0\n31.5\n72.0\n49.0\n348\n104\n8\n0\n15.5\n  6.5\n22.0\n62.0\n35.0\n166\nData Set 12: Manatee Deaths\nAnnual Florida data for 24 years are provided (first five rows shown \nhere). DEATHS is the annual number of manatee deaths caused by \nboats, BOATS is the number of registered pleasure boats (tens of \nthousands), POP is the Florida population (millions), and WATER \nTEMP is the annual mean water temperature 1°F2.\nTI-83 , 84 list names  DEATH, BOATS, POP, WTEMP  \n(MANATEE):\t\n(no list for YEAR)\nYEAR\nDEATHS\nBOATS\nPOP\nWATER TEMP\n1991\n53\n68\n13.3\n71.9\n1992\n38\n68\n13.5\n70.4\n1993\n35\n67\n13.7\n70.5\n1994\n49\n70\n14.0\n71.7\n1995\n42\n71\n14.3\n70.9\n",
    "\t\nAPPENDIX B  Data Sets\t\n643\n(Complete data sets available at www.TriolaStats.com)\nData Set 13: Alcohol and Tobacco in Movies\nData are from 50 animated children’s movies (first five rows shown \nhere). LENGTH is movie length in minutes, TOBACCO is tobacco \nuse time in seconds, and ALCOHOL is alcohol use time in seconds.\nThe data are based on Goldstein, Adam O., Sobel, Rachel A., \nNewman, Glen R., “Tobacco and Alcohol Use in G-Rated Children’s \nAnimated Films.” Journal of the American Medical Association, \nMarch 24/31, 1999, Vol. 281, No. 12, p. 1132. Copyright © 1999. All \nrights reserved.\nTI-83 , 84 list names   CHLEN, CHTOB, CHALC  \n(CHMOVIE): \t\n(no list for MOVIE and STUDIO)\nMOVIE\nSTUDIO\nLENGTH (MIN)\nTOBACCO (SEC)\nALCOHOL (SEC)\nSnow White\nDisney\n  83\n    0\n  0\nPinocchio\nDisney\n  88\n223\n80\nFantasia\nDisney\n120\n    0\n  0\nDumbo\nDisney\n  64\n176\n88\nBambi\nDisney\n  69\n    0\n  0\nData Set 14: Passive and Active Smoke\nData are from 120 subjects (first five rows shown here) in three \ngroups: SMOKER includes subjects who are smokers, ETS includes \nnonsmokers exposed to environmental tobacco smoke, and NOETS \nincludes nonsmokers not exposed to environmental tobacco smoke. \nAll values are measured levels of serum cotinine (in ng>mL), a  \nmetabolite of nicotine. (When nicotine is absorbed by the body, coti-\nnine is produced.) Data are from the U.S. Department of Health and \nHuman Services, National Center for Health Statistics, Third National \nHealth and Nutrition Examination Survey.\nTI-83 , 84 list names  SMKR, ETS, NOETS\n(SMOKE):\nSMOKER\nETS\nNOETS\n    1\n384\n0\n    0\n    0\n0\n131\n  69\n0\n173\n  19\n0\n265\n    1\n0\nData Set 15: Cigarette Contents\nData are from 75 cigarettes (first five rows shown here) from three  \ncategories: KING includes king-sized cigarettes that are nonfiltered, \nnonmenthol, and nonlight; MENTH includes menthol cigarettes that are \n100 mm long, filtered, and nonlight; and 100 includes 100-mm-long \ncigarettes that are filtered, nonmenthol, and nonlight. TAR is the \namount of tar per cigarette (milligrams), NICOTINE is the amount of \nnicotine per cigarette (milligrams), and CO is the amount of carbon \nmonoxide per cigarette (milligrams). Data are from the Federal Trade \nCommission.\nTI-83 , 84 list names  KGTAR, KGNIC, KGCO, MNTAR, MNNIC, \n(CIGARET):\t\nMNCO, FLTAR, FLNIC, FLCO\nKING TAR\nKING NICOTINE\nKING CO\nMENTH TAR\nMENTH NICOTINE\nMENTH CO\n100 TAR\n100 NIC\n100 CO\n20\n1.1\n16\n16\n1.1\n15\n  5\n0.4\n  4\n27\n1.7\n16\n13\n0.8\n17\n16\n1.0\n19\n27\n1.7\n16\n16\n1.0\n19\n17\n1.2\n17\n20\n1.1\n16\n  9\n0.9\n  9\n13\n0.8\n18\n20\n1.1\n16\n14\n0.8\n17\n13\n0.8\n18\n",
    "644\t\nAPPENDIX B  Data Sets\n(Complete data sets available at www.TriolaStats.com)\nData Set 16: Iris Measurements\nData are from 150 Iris Measurements (first five rows shown here) \nfrom three different classes (Setosa, Versicolor, Virginica). SL denotes \nsepal length (mm), SW denotes sepal width (mm), PL denotes petal \nlength (mm), and PW denotes petal width (mm). From “The Use \nof Multiple Measurements in Taxonomic Problems,” by Ronald A. \nFisher, Annals of Statistics, Vol. 7.\nTI-83 , 84 list names  \u0007SETSL, SETSW, SETPL, SETPW, VERSL, \n(IRIS):\t \t\n\u0007VERSW, VERPL, VERPW, VIRSL, VIRSW, \nVIRPL, VIRPW.\nCLASS\nSL\nSW\nPL\nPW\nsetosa\n5.1\n3.5\n1.4\n0.2\nsetosa\n4.9\n3.0\n1.4\n0.2\nsetosa\n4.7\n3.2\n1.3\n0.2\nsetosa\n4.6\n3.1\n1.5\n0.2\nsetosa\n5.0\n3.6\n1.4\n0.2\nData Set 17: Cuckoo Egg Lengths\nLengths (mm) of cuckoo eggs put in the nests of six other birds (first \nfive rows of data shown here). From The Methods of Statistics,  \n4th edition, by L. H. C. Tippett, John Wiley and Sons, Inc., as listed in \nthe Data and Story Library (online).\nTI-83 , 84 list names  MDW, TREE, HEDGE, ROBIN,  \n(CUCKOO):\t\nPIED, WREN.\nMEADOW PIPIT\nTREE PIPIT\nHEDGE SPARROW\nROBIN\nPIED WAGTAIL\nWREN\n19.65\n21.05\n20.85\n21.05\n21.05\n19.85\n20.05\n21.85\n21.65\n21.85\n21.85\n20.05\n20.65\n22.05\n22.05\n22.05\n21.85\n20.25\n20.85\n22.45\n22.85\n22.05\n21.85\n20.85\n21.65\n22.65\n23.05\n22.05\n22.05\n20.85\nData Set 18: Poplar Tree Weights\nData (first five rows shown here) are weights (kg) of trees in year 1 \nand year 2 grown with four different conditions (no treatment, fertil-\nizer, irrigation, fertilizer and irrigation) at two different sites. Site 1 is \nrich and moist, and Site 2 is sandy and dry. From a study conducted \nby researchers at Pennsylvania State University. Data obtained from \nMinitab, Inc.\nTI-83 , 84 list names  NONE, FERT, IRRIG, FRTIR\n(POPLAR):\nYEAR\nSITE\nNO TREATMENT\nFERTILIZER\nIRRIGATION\nFERT & IRRIG\n1\n1\n0.15\n1.34\n0.23\n2.03\n1\n1\n0.02\n0.14\n0.04\n0.27\n1\n1\n0.16\n0.02\n0.34\n0.92\n1\n1\n0.37\n0.08\n0.16\n1.07\n1\n1\n0.22\n0.08\n0.05\n2.38\n",
    "645\nWebsites and \nBibliography of Books\nAPPENDIX C \nWebsites\nTriola Stats: www.TriolaStats.com\nAccess continually updated digital resources, including download-\nable data sets, textbook supplements, online instructional videos, \nTriola Blog, and more.\nStatdisk: www.Statdisk.org\nDownload the free Statdisk statistical software that is designed spe-\ncifically for this book and contains all Appendix B data sets. Detailed \ninformation on using Statdisk is provided on the site’s Help page.\nStatCrunch: www.statcrunch.com\nBooks\n*An asterisk denotes a book recommended for reading. Other \nbooks are recommended as reference texts.\nBennett, D. 1998. Randomness. Cambridge, Mass.: Harvard ­University \nPress.\n*Best, J. 2012. Damned Lies and Statistics. Berkeley, Calif.: ­University \nof California Press.\n*Best, J. 2004. More Damned Lies and Statistics. Berkeley, Calif.: \nUniversity of California Press.\n*Campbell, S. 2004. Flaws and Fallacies in Statistical Thinking. \n­Mineola, N.Y.: Dover Publications.\n*Crossen, C. 1996. Tainted Truth: The Manipulation of Fact in \n­America. New York: Simon & Schuster.\n*Freedman, D., R. Pisani, R. Purves, and A. Adhikari. 2007. Statistics. \n4th ed. New York: W. W. Norton & Company.\n*Gonick, L., and W. Smith. 1993. The Cartoon Guide to Statistics. \nNew York: Harper Collins.\n*Heyde, C., and E. Seneta, eds. 2001. Statisticians of the Centuries. \nNew York: Springer-Verlag.\n*Hollander, M., and F. Proschan. 1984. The Statistical Exorcist: \n­Dispelling Statistics Anxiety. New York: Marcel Dekker.\n*Holmes, C. 1990. The Honest Truth About Lying with Statistics. \nSpringfield, Ill.: Charles C Thomas.\n*Hooke, R. 1983. How to Tell the Liars from the Statisticians. New \nYork: Marcel Dekker.\n*Huff, D. 1993. How to Lie with Statistics. New York: W. W. Norton \n& Company.\n*Jaffe, A., and H. Spirer. 1998. Misused Statistics. New York: Marcel \nDekker.\nKaplan, M. 2007. Chances Are. New York: Penguin Group.\nKotz, S., and D. Stroup. 1983. Educated Guessing—How to Cope in an \nUncertain World. New York: Marcel Dekker.\nMlodinow, L. 2009. The Drunkard’s Walk. New York: Vintage Books.\n*Moore, D., and W. Notz. 2012. Statistics: Concepts and Controver-\nsies. 8th ed. San Francisco: Freeman.\n*Paulos, J. 2001. Innumeracy: Mathematical Illiteracy and Its \n­Consequences. New York: Hill and Wang.\n*Reichmann, W. 1981. Use and Abuse of Statistics. New York: \n­Penguin.\n*Rossman, A., and B. Chance. 2011. Workshop Statistics: Discovery \nwith Data. 4th ed. Emeryville, Calif.: Key Curriculum Press.\n*Salsburg, D. 2001. The Lady Tasting Tea: How Statistics Revolution-\nized the Twentieth Century. New York: W. H. Freeman.\nSheskin, D. 2011. Handbook of Parametric and Nonparametric \n­Statistical Procedures. 5th ed. Boca Raton, Fla.: CRC Press.\nSimon, J. 1997. Resampling: The New Statistics. 2nd ed. Arlington, \nVa.: Resampling Stats.\n*Stigler, S. 1986. The History of Statistics. Cambridge, Mass.: ­Harvard \nUniversity Press.\nTaleb, N. 2010. The Black Swan. 2nd ed. New York: Random House.\n*Tufte, E. 2001. The Visual Display of Quantitative Information. 2nd \ned. Cheshire, Conn.: Graphics Press.\nTukey, J. 1977. Exploratory Data Analysis. Boston: Pearson.\nVickers, A. 2009. What Is a P-Value Anyway? Boston: Pearson.\nWhelan, C. 2013. Naked Statistics. New York: W. W. Norton & \n­Company.\nZwillinger, D., and S. Kokoska. 2000. CRC Standard Probability and \nStatistics Tables and Formulae. Boca Raton, Fla.: CRC Press.\n",
    "APPENDIX D\nAnswers to Odd-Numbered Section Exercises, plus \nAnswers to All Chapter Quick Quizzes, Chapter \nReview Exercises, and Cumulative Review Exercises\nChapter 1 Answers\nSection 1-1\n\t 1.\t The respondents are a voluntary response sample or a self-selected \nsample. Because those with strong interests in the topic are more \nlikely to respond, it is very possible that their responses do not \nreflect the opinions or behavior of the general population.\n\t 3.\t Statistical significance is indicated when methods of statistics \nare used to reach a conclusion that a treatment is effective, but \ncommon sense might suggest that the treatment does not make \nenough of a difference to justify its use or to be practical. Yes, it \nis possible for a study to have statistical significance but not prac-\ntical significance.\n\t 5.\t Yes, there does appear to be a potential to create a bias.\n\t 7.\t No, there does not appear to be a potential to create a bias.\n\t 9.\t The sample is a voluntary response sample and has strong poten-\ntial to be flawed.\n\t11.\t The sampling method appears to be sound.\n\t13.\t With only a 1% chance of getting such results with a program \nthat has no effect, the program appears to have statistical \n­significance. Also, because the average loss of 22 pounds does \nseem substantial, the program appears to also have practical \n­significance.\n\t15.\t Because there is a 19% chance of getting that many girls by \nchance, the method appears to lack statistical significance. The \nresult of 1020 girls in 2000 births (51% girls) is above the ap-\nproximately 50% rate expected by chance, but it does not ap-\npear to be high enough to have practical significance. Not many \ncouples would bother with a procedure that raises the likelihood \nof a girl from 50% to 51%.\n\t17.\t Yes. Each column of 8 AM and 12 AM temperatures is recorded \nfrom the same subject, so each pair is matched.\n\t19.\t The data can be used to address the issue of whether there is a \ncorrelation between body temperatures at 8 AM and at 12 AM. \nAlso, the data can be used to determine whether there are differ-\nences between body temperatures at 8 AM and at 12 AM.\n\t21.\t No. The white blood cell counts measure a different quantity than \nthe red blood cell counts, so their differences are meaningless.\n\t23.\t No. The National Center for Health Statistics has no reason to \ncollect or present the data in a way that is biased.\n\t25.\t It is questionable that the sponsor is the Idaho Potato Commis-\nsion and the favorite vegetable is potatoes.\n\t27.\t The correlation, or association, between two variables does not \nmean that one of the variables is the cause of the other. Cor-\nrelation does not imply causation. Common sense suggests that \ncheese consumption is not directly related in any way to fatalities \nfrom bedsheet entanglements.\n\t29.\t a.\t1356.3 adults \n\t \t b.\t \u0007No. Because the result is a count of the people among the \n3014 who were surveyed, the result must be a whole number.\n\t \t c.\t 1356 adults  d.  40%\n\t31.\t The wording of the question is biased and tends to encourage \nnegative responses. The sample size of 20 is too small. Survey re-\nspondents are self-selected instead of being selected by the news-\npaper. If 20 readers respond, the percentages should be multiples \nof 5, so 87% and 13% are not possible results.\nSection 1-2\n\t 1.\t a.  \u0007The population consists of all adults in the United States and \nthe sample is the 1020 adults who were surveyed.\n\t\n\t b.  Statistic\n\t 3.\t a.\tQuantitative  b.  Categorical  c.  Categorical  d.  Quantitative\n\t 5.\t Statistic\t\n7.\t Statistic\t\n9.\t Statistic\n\t11.\t Parameter\t\n13.\t Continuous\t\n15.\t Continuous\n\t17.\t Discrete\t\n19.\t Discrete\t\n21.\t Ratio\n\t23.\t Interval\t\n25.\t Nominal\t\n27.\t Ordinal\n29.\t The numbers are not counts or measures of anything. They are at \nthe nominal level of measurement, and it makes no sense to com-\npute the average (mean) of them.\n31.\t The temperatures are at the interval level of measurement. \n­Because there is no natural starting point with 0°F representing \n“no heat,” ratios such as “twice” make no sense, so it is wrong to \nsay that the person is twice as warm as the outside air.\n\t33.\t a.\t\u0007Continuous, because the number of possible values is infinite \nand not countable\n\t \t b.\t Discrete, because the number of possible values is finite\n\t \t c.\t Discrete, because the number of possible values is finite\n\t \t d.\t \u0007Discrete, because the number of possible values is infinite and \ncountable\nSection 1-3\n\t 1.\t The study is an experiment because subjects were given treatments.\n\t 3.\t The group sample sizes of 547, 550, and 546 are all large so that \nthe researchers could see the effects of the paracetamol treatment.\n\t 5.\t The sample appears to be a convenience sample. By e-mailing the \nsurvey to a readily available group of Internet users, it was easy \nto obtain results. Although there is a real potential for getting a \nsample group that is not representative of the population, indica-\ntions of which ear is used for cell phone calls and which hand \nis dominant do not appear to be factors that would be distorted \nmuch by a sample bias.\n\t 7.\t With 717 responses, the response rate is 14%, which does appear \nto be quite low. In general, a very low response rate creates a \nserious potential for getting a biased sample that consists of those \nwith a special interest in the topic.\n646\n",
    "\t\nAppendix D\t\n647\n\t 3.\t The sample is a voluntary response sample, so the results are \nquestionable.\n\t 4.\t a.  \u0007It uses a voluntary response sample, and those with special \ninterests are more likely to respond, so it is very possible that \nthe sample is not representative of the population.\n\t \t b.  \u0007Because the statement refers to 72% of all Americans, it is \na parameter (but it is probably based on a 72% rate from the \nsample, and the sample percentage is a statistic).\n\t\n\t c.  Observational study\n\t 5.\t a.  \u0007If they have no fat at all, they have 100% less than any other \namount with fat, so the 125% figure cannot be correct.\n\t \t b.  686    c.  28%\n\t 6.\t Only part (c) is a simple random sample.\n\t 7.\t Because there is only a 4% chance of getting the results by \nchance, the method appears to have statistical significance. The \nresult of 112 girls in 200 births is above the approximately 50% \nrate expected by chance, but it does not appear to be high enough \nto have practical significance. Not many couples would bother \nwith a procedure that raises the likelihood of a girl from 50%  \nto 56%.\n\t 8.\t a.  Random    b.  Stratified    c.  Nominal\n\t \t d.  Statistic, because it is based on a sample.\n\t\n\t e.  \u0007The mailed responses would be a voluntary response sample. \nThose with strong opinions about the topic would be more \nlikely to respond, so it is very possible that the results would \nnot reflect the true opinions of the population of all adults.\n\t 9.\t a.  Systematic. It is likely to result in a representative sample.\n\t \t b.  Random. It is likely to result in a representative sample.\n\t \t c.  Cluster. It is likely to result in a representative sample.\n\t \t d.  Stratified. It is likely to result in a representative sample.\n\t\n\t e.  \u0007Convenience. It is very possible that the sample is not repre-\nsentative.\n\t10.\t a.  780 adults    b.  23%\n\t \t c.  Men: 48.5%; women: 51.5%\n\t \t d.  No, although this is a subjective judgment.\n\t \t e.  No, although this is a subjective judgment.\nChapter 1: Cumulative Review Exercises\n\t 1.\t 3162.5 grams. The weights all end with 00, suggesting that all of \nthe weights are rounded so that the last two digits are always 00.\n\t 2.\t 0.015625\n\t 3.\t 16.00 is a significantly high value.\n\t 4.\t -6.64\t\n5.\t 1067\t\n6.\t 575 grams\n\t 7.\t 27343.75 grams2\t 8.\t 0.20\t\n9.\t 0.00065536\n\t10.\t 31,381,059,609 (or about 31,381,060,000)\n\t11.\t 78,364,164,096 (or about 78,364,164,000)\n\t12.\t 0.000000531441\n\t 9.\t Systematic\t\n11.\t Random\t\n13.\t Cluster\n\t15.\t Stratified\t\n17.\t Random\t\n19.\t Convenience\n\t21.\t Observational study. The sample is a convenience sample consist-\ning of subjects who decided themselves to respond. Such volun-\ntary response samples have a high chance of not being represen-\ntative of the larger population, so the sample may well be biased. \nThe question was posted in an electronic edition of a newspaper, \nso the sample is biased from the beginning.\n\t23.\t Experiment. This experiment would create an extremely danger-\nous and illegal situation that has a real potential to result in injury \nor death. It’s difficult enough to drive in New York City while be-\ning completely sober.\n\t25.\t Experiment. The biased sample created by using subjects from \nNew York City cannot be fixed by using a larger sample. The \nlarger sample will still be a biased sample that is not representa-\ntive of subjects in the United States.\n\t27.\t Observational study. Respondents who have been convicted of \nfelonies are not likely to respond honestly to the second question. \nThe survey will suffer from a “social desirability bias” because \nsubjects will tend to respond in ways that will be viewed favor-\nably by those conducting the survey.\n\t29.\t Prospective study\t\n31.  Cross-sectional study\n\t33.\t Matched pairs design\t\n35.  Completely randomized design\n\t37.\t Prospective: The experiment was begun and results were fol-\nlowed forward in time. Randomized: Subjects were assigned \nto the different groups through a process of random selection, \nwhereby they had the same chance of belonging to each group. \nDouble-blind: The subjects did not know which of the three \ngroups they were in, and the people who evaluated results did not \nknow either. Placebo-controlled: There was a group of subjects \nwho were given a placebo; by comparing the placebo group to the \ntwo treatment groups, the effects of the treatments might be bet-\nter understood.\nChapter 1: Quick Quiz\n\t 1.\t No. The numbers do not measure or count anything.\n\t 2.\t Nominal\t\n3.\t Continuous\t\n4.\t Quantitative data\n\t 5.\t Ratio\t\n6.\t No\t\n7.\t No\n\t 8.\t Statistic\t\n9.\t Observational study\t\n10.\t False\nChapter 1: Review Exercises\n\t 1.\t a  Discrete    b.  Ratio    c.  Stratified    d.  Cluster\n\t \t e.  \u0007The mailed responses would be a voluntary response sample, \nso those with strong opinions are more likely to respond. It is \nvery possible that the results do not reflect the true opinions of \nthe population of all customers.\n\t 2.\t The survey was sponsored by the American Laser Centers, and \n24% said that the favorite body part is the face, which happens to \nbe a body part often chosen for some type of laser treatment. The \nsource is therefore questionable.\n",
    "648\t\nAppendix D\nChapter 2 Answers\nSection 2-1 \n\t 1.\t The table summarizes measurements from 40 subjects. It is not \npossible to identify the exact values of all of the original cotinine \nmeasurements.\n\t 3.\t\n\t17.\t Yes. The distribution appears to be approximately normal.\nRed Blood Cell Count (Males)\nFrequency\n3.00–3.49\n  1\n3.50–3.99\n16\n4.00–4.49\n29\n4.50–4.99\n57\n5.00–5.49\n44\n5.50–5.99\n  6\n\t19.\t\nCotinine (ng, mL)\nRelative Frequency\n  0–99\n27.5%\n100–199\n30.0%\n200–299\n35.0%\n300–399\n  2.5%\n400–499\n  5.0%\n\t 5.\t Class width: 100. Class midpoints: 49.5, 149.5, 249.5, 349.5, \n449.5, 549.5. Class boundaries: -0.5, 99.5, 199.5, 299.5, 399.5, \n499.5, 599.5.\n\t 7.\t Class width: 100. Class midpoints: 49.5, 149.5, 249.5, 349.5, \n449.5, 549.5, 649.5. Class boundaries: -0.5, 99.5, 199.5, 299.5, \n399.5, 499.5, 599.5, 699.5.\n\t 9.\t No. The maximum frequency is in the first class instead of being \nnear the middle.\n\t11.\t 89, 18, 12, 2\n\t13.\t The pulse rates appear to have a distribution that is approxi-\nmately normal.\nPulse Rate (Male)\nFrequency\n40–49\n  2\n50–59\n23\n60–69\n53\n70–79\n43\n80–89\n25\n90–99\n  5\n100–109\n  2\n\t15.\t The verbal IQ scores appear to have a distribution that is ap-\nproximately normal.\nIQ (Verbal)\nFrequency\n50–59\n  3\n60–69\n  8\n70–79\n13\n80–89\n26\n90–99\n18\n100–109\n  6\n110–119\n  2\n120–129\n  2\nWeight (kg) in September\nFrequency\n50–59\n  2\n60–69\n12\n70–79\n11\n80–89\n  3\n90–99\n  4\n\t21.\t The frequency distribution suggests that the reported heights \nwere rounded with disproportionately many 0s and 5s. This sug-\ngests that the results are not very accurate.\nLast Digit\nFrequency\n0\n  9\n1\n  2\n2\n  1\n3\n  3\n4\n  1\n5\n15\n6\n  2\n7\n  0\n8\n  3\n9\n  1\n\t23.\t The two distributions differ substantially. The presence of coti-\nnine appears to be much higher for smokers than for nonsmokers \nexposed to smoke.\n \nCotinine (ng, mL)\n \nSmokers\nNonsmokers Exposed  \nto Smoke\n  0–99\n27.5%\n85.0%\n100–199\n30.0%\n  5.0%\n200–299\n35.0%\n  2.5%\n300–399\n  2.5%\n  2.5%\n400–499\n  5.0%\n             0%\n500–599\n       0%\n  5.0%\n",
    "\t\nAppendix D\t\n649\n\t11.\t The IQ scores appear to have a distribution that is approximately \nnormal.\n\t13.\t Yes. The red blood cell counts appear to have a distribution that \nis very approximately normal, although some might describe the \ndistribution as being left-skewed instead of normal.\n\t15.\t\n25.\t\nCotinine (Nonsmokers  \nExposed to Smoke in ng, mL)\n \nCumulative Frequency\nLess than 100\n34\nLess than 200\n36\nLess than 300\n37\nLess than 400\n38\nLess than 500\n38\nLess than 600\n40\n\t27.\t a.  \u0007The values of 551 and 543 are clearly outliers; the values of \n384, 241, 197, and 178 could also be outliers.\n\t\n\t b.  \u0007The number of classes increases from six to ten. The outlier \ncan greatly increase the number of classes. If there are too \nmany classes, we might use a larger class width with the effect \nthat the true nature of the distribution may be hidden.\nCotinine (Nonsmokers  \nExposed to Smoke in ng, mL)\n \nFrequency\n  0–99\n34\n100–199\n2\n200–299\n1\n300–399\n1\n400–499\n0\n500–599\n2\n600–699\n0\n700–799\n0\n800–899\n0\n900–999\n1\nSection 2-2 \n\t 1.\t It is easier to see the distribution of the data by examining the \ngraph of the histogram than by examining the numbers in a fre-\nquency distribution.\n\t 3.\t With a data set that is so small, the true nature of the distribution \ncannot be seen with a histogram.\n\t 5.\t Approximately 50\n\t 7.\t Approximately 4.5 mm; no\n\t 9.\t The pulse rates of males appear to have a distribution that is \n­approximately normal.\n\t17.\t The histogram suggests that the reported heights were rounded \nwith disproportionately many 0s and 5s. This suggests that the \nresults are not very accurate.\n\t19.\t Only part (c) appears to represent data from a normal distribu-\ntion. Part (a) has a systematic pattern that is not that of a straight \nline, part (b) has points that are not close to a straight-line pattern, \nand part (d) is really bad because it shows a systematic pattern \nand points that are not close to a straight-line pattern.\nSection 2-3 \n\t 1.\t The data set is too small for a graph to reveal important charac-\nteristics of the data. With such a small data set, it would be better \nto simply list the data or place them in a table.\n\t 3.\t No. Graphs should be constructed in a way that is fair and objec-\ntive. The readers should be allowed to make their own judgments, \ninstead of being manipulated by misleading graphs.\n\t 5.\t The pulse rate of 36 beats per minute appears to be an outlier.\n",
    "650\t\nAppendix D\n\t 7.\t The data are arranged in order from lowest to highest, as 36, 56, \n56, and so on.\n\t 9.\t There was a steep jump in the first four years, but the numbers of \ntriplets have shown a downward trend in the past several years.\n\t11.\t Misconduct includes fraud, duplication, and plagiarism, so it does \nappear to be a major factor.\n\t13.\t\ndata and to recognize that there may be a correlation between the \ntwo variables.\n\t 5.\t There does not appear to be a linear correlation between brain \nvolume and IQ score.\n\t 7.\t There does not appear to be a linear correlation between body tem-\nperature at 8 AM on one day and at 8 AM on the following day.\n\t 9.\t There does not appear to be a linear correlation.\n\t11.\t There does not appear to be a linear correlation.\nChapter 2: Quick Quiz\n\t 1.\t 0.04\t\n2.\t 0.075 and 0.115\n\t 3.\t No, it is impossible to determine the original values.\n\t 4.\t 16, 17, 18, 18, 19\t\n5.\t Bell-shaped\n\t 6.\t Variation\t\n7.\t Time-series graph\n\t 8.\t Scatterplot\t\n9.\t Pareto chart\n\t10.\t A frequency distribution is in the format of a table, but a histo-\ngram is a graph.\nChapter 2: Review Exercises\n\t 1.\t\n\t15.\t The distribution appears to be roughly bell-shaped, so the distri-\nbution is approximately normal.\n\t17.\t Because the vertical scale starts with a frequency of 200 instead \nof 0, the difference between the “no” and “yes” responses is \ngreatly exaggerated. The graph makes it appear that about five \ntimes as many respondents said “no,” when the ratio is actually a \nlittle less than 2.5 to 1.\nSection 2-4 \n\t 1.\t The term linear refers to a straight line, and r measures how well \na scatterplot of the sample paired data fits a straight-line pattern.\n\t 3.\t A scatterplot is a graph of paired (x, y) quantitative data. It helps \nus by providing a visual image of the data plotted as points, and \nsuch an image is helpful in enabling us to see any patterns in the \nTemperature (°F)\nFrequency\n97.0–97.4\n2\n97.5–97.9\n4\n98.0–98.4\n7\n98.5–98.9\n5\n99.0–99.4\n2\n\t 2.\t Yes, the data appear to be from a population with a normal \n­distribution because the bars start low and reach a maximum, \nthen decrease, and the left half of the histogram is approximately \na mirror image of the right half. The graph is approximately \n­bell-shaped.\n",
    "\t\nAppendix D\t\n651\n\t 3.\t By using fewer classes, the histogram does a better job of illus-\ntrating the distribution.\n\t 4.\t There are no outliers.\n\t 5.\t Yes. There is a pattern suggesting that there is a relationship.\n\t 6.\t a.  Time-series graph\n\t\n\t b.  Scatterplot\n\t\n\t c.  Pareto chart\n\t 7.\t By using a vertical scale that starts at 45% instead of 0%, the \ndifference is greatly exaggerated. The graph creates the false \nimpression that male enrollees outnumber female enrollees by a \nratio of about 3:1, but the actual percentages of 53% and 47% are \nmuch closer than that.\nChapter 2: Cumulative Review Exercises\n\t 1.\t\nGrooming Time (min)\nFrequency\n0–9\n2\n10–19\n3\n20–29\n9\n30–39\n4\n40–49\n2\n\t 2.\t The histogram is approximately bell-shaped. The frequencies \nincrease to a maximum and then decrease, and the left half of the \nhistogram is roughly a mirror image of the right half. The data do \nappear to be from a population with a normal distribution.\n\t 3.\t\n4.\t There are disproportionately many last digits of 0 and 5. Fourteen \nof the 20 times have last digits of 0 or 5. It appears that the sub-\njects reported their results and they tended to round the results. \nThe data do not appear to be very accurate.\nLast Digit\nFrequency\n0\n5\n1\n0\n2\n2\n3\n0\n4\n1\n5\n9\n6\n0\n7\n2\n8\n1\n9\n0\n\t 5.\t a.  Ratio    b.  Continuous\n\t\n\t c.  No. The grooming times are quantitative data.\n\t\n\t d.  Statistic\n\t 6.\t The scatterplot helps address the issue of whether there is a corre-\nlation between heights of mothers and heights of their daughters. \nThe scatterplot does not reveal a clear pattern suggesting that \nthere is a correlation.\nChapter 3 Answers\nSection 3-1 \n\t 1.\t The term average is not used in statistics. The term mean should \nbe used for the result obtained by adding all of the sample values \nand dividing the total by the number of sample values.\n\t 3.\t They use different approaches for providing a value (or values) of \nthe center or middle of the sorted list of data.\n\t 5.\t x = $266,594.0; median = $251,632.5; mode = none; midrange =  \n$313,459.5. Apart from the fact that the other charges are lower \nthan those given, nothing meaningful can be known about the \npopulation of all charges.\n\t 7.\t x = 57.1; median = 60.0; mode = none; midrange = 53.0. \nThe jersey numbers are nominal data that are just replacements \nfor names, and they do not measure or count anything, so the re-\nsulting statistics are meaningless.\n\t 9.\t x = 1.9; median = 2.0; mode = 1; midrange = 2.5. The mode \nof 1 correctly indicates that the smooth-yellow peas occur more \nthan any other phenotype, but the other measures of center don’t \nmake sense with these data at the nominal level of measurement.\n\t11.\t x = 1.178 W>kg; median = 1.380 W>kg; mode = 1.45 W>kg; \nmidrange = 1.000 W>kg. If concerned about radiation absorption,  \n",
    "652\t\nAppendix D\n652\t\nAPPENDIX D\nyou might purchase the cell phone with the lowest absorption \nrate. All of the cell phones in the sample have absorption levels \nbelow the FCC maximum of 1.6 W>kg.\n\t13.\t x = 18.9 firefighters; median = 19.0 firefighters; mode = 15 \nfirefighters and 20 firefighters; midrange = 21.0 firefighters. The \ndata are time-series data but the measures of center do not reveal \nanything about a trend consisting of a pattern of change over \ntime.\n\t15.\t x = $54,862.0; median = $54,590.5; mode = none; midrange =\n$55,292.0. Apart from the fact that all other colleges have tuition \nand fee amounts less than those listed, nothing meaningful can be \nknown about the population.\n\t17.\t Systolic: x = 127.6 mm Hg; median = 124.0 mm Hg. Diastolic: \nx = 73.6 mm Hg; median = 75.0 mm Hg. Given that systolic \nand diastolic blood pressures measure different characteristics, a \ncomparison of the measures of center doesn’t make much sense. \nBecause the data are matched, it would make more sense to in-\nvestigate whether there is an association or correlation between \nsystolic blood pressure measurements and diastolic blood pres-\nsure measurements.\n19.\t Female: x = 7.35; median = 7.05. Male: x = 6.17; median =\n5.70. (All units are 1000 cells>mL). Females appear to have \nhigher white blood cell counts.\n\t21.\t x = 53.7 mg>dL; median = 52.0 mg>dL. After excluding the \nhighest value of 138, which does appear to be an outlier, we get \nx = 53.4 mg>dL and median = 52.0 mg>dL, so excluding that \noutlier does not cause much of a change in the mean, and the me-\ndian remains the same.\n\t23.\t x = 98.20°F; median = 98.40°F. These results suggest that the \nmean is less than 98.6°F.\n\t25.\t x = 224.0. The mean from the frequency distribution is quite \nclose to the mean obtained by using the original list of values.\n\t27.\t 3.14; yes\n\t29.\t a. 90 beats per minute    b. n - 1\n\t31.\t Mean: 113.7 mg>dL; 10% trimmed mean: 112.2 mg>dL; 20% \ntrimmed mean: 111.8 mg>dL. The 10% trimmed mean and 20% \ntrimmed mean are both fairly close, but the untrimmed mean of \n113.7 mg>dL differs from them because it is more strongly af-\nfected by the outliers.\nSection 3-2\n\t 1.\t 119.0 cm3 is quite close to the exact value of the standard devia-\ntion of 124.9 cm3.\n\t 3.\t 401.6577 kg2\n\t 5.\t Range = $315,205.0; s2 = 8,502,938,525.9 dollars squared; \ns = $92,211.4. (Many technologies will not provide all of the \ndigits shown for the variance s2, so any result close to the value \nshown here is acceptable.) Because only the 10 highest sample \nvalues are used, nothing much can be known about the population \nof all such charges.\n\t 7.\t Range = 92.0; s2 = 1149.5; s = 33.9. The jersey numbers \nare nominal data that are just replacements for names, and they \ndo not measure or count anything, so the resulting statistics are \nmeaningless.\n\t 9.\t Range = 3.0; s2 = 0.9; s = 0.9. The measures of variation can \nbe found, but they make no sense because the data don’t measure \nor count anything. They are nominal data.\n\t11.\t Range = 0.980 W>kg; s2 = 0.114 1W>kg2 2; s = 0.337 W>kg. \nNo. Some models of cell phones have a much larger market share \nthan others, so the measures from the different models should be \nweighted according to their size in the population.\n\t13.\t Range = 26.0 firefighters; s2 = 60.9 firefighters2; s = 7.8 fire-\nfighters. The data are time-series data but the measures of varia-\ntion do not reveal anything about a trend consisting of a pattern \nof change over time.\n\t15.\t Range = $3938.0; s2 = 1,638,970.9 (dollars)2; s = $1280.2. \nBecause the data include only the 10 highest costs, the measures \nof variation don’t tell us anything about the variation among costs \nfor the population of all U.S. college tuitions.\n\t17.\t Systolic: 14.6%. Diastolic: 16.9%. The variation is roughly about \nthe same.\n\t19.\t Females: 21.3%. Males: 24.8%. The variation is roughly the same \nfor females and males.\n\t21.\t Range = 112.0 mg>dL; s2 = 238.3 1mg>dL2 2; s = 15.4 mg>dL. \nAfter excluding the highest value of 138 mg>dL, we get: Range =  \n87.0 mg>dL; s2 = 215.2 1mg>dL2 2; s = 14.7 mg>dL, so the \nmeasures of variation do change, but they don’t change by sub-\nstantial amounts.\n\t23.\t Range = 3.10°F; s2 = 0.39 1°F2 2; s = 0.62°F.\n\t25.\t The estimate of 28.0 mg>dL is far from s = 15.4 mg>dL.\n\t27.\t The estimate of 0.78°F is not substantially different from \ns = 0.62°F.\n\t29.\t Significantly low values are less than or equal to 49.0 beats per \nminute, and significantly high values are greater than or equal to \n99.0 beats per minute. A pulse rate of 44 beats per minute is sig-\nnificantly low.\n\t31.\t Significantly low values are less than or equal to 24.74 cm, and \nsignificantly high values are greater than or equal to 29.90 cm. A \nfoot length of 30 cm is significantly high.\n\t33.\t s = 68.4 is somewhat far from the exact value of 59.5.\n\t35.\t a. 24.7 cigarettes2    b. 24.7 cigarettes2    c. 12.3 cigarettes2\n\t\n\t d. \u0007Part (b), because repeated samples result in variances that \ntarget the same value (24.7 cigarettes2) as the population vari-\nance. Use division by n - 1.\n\t\n\t e. \u0007No. The mean of the sample variances (24.7 cigarettes2) equals \nthe population variance (24.7 cigarettes2), but the mean of the \nsample standard deviations (3.5 cigarettes) does not equal the \npopulation standard deviation (5.0 cigarettes).\nSection 3-3\n\t 1.\t James’s height is 4.07 standard deviations above the mean.\n\t 3.\t The bottom boxplot represents weights of women, because it de-\npicts weights that are generally lower.\n\t 5.\t a. 30.0 BPM    b. 2.40 standard deviations    c. z = 2.40\n\t\n\t d. Yes, the maximum pulse rate of 104 BPM is significantly high.\n\t 7.\t a. 1.70°F    b. 2.74 standard deviations    c. z = -2.74\n\t\n\t d. The minimum of 96.5°F is significantly low.\n\t 9.\t Significantly low values are less than or equal to 10.9; signifi-\ncantly high values are greater than or equal to 31.3.\n\t11.\t Significantly low weights are less than or equal to 1765.2 g; sig-\nnificantly high weights are greater than or equal to 4538.8 g.\n\t13.\t With z scores of 10.83 and -16.83, the z score of -16.83 is far-\nther from the mean, so the shortest man has a height that is more \nextreme.\n",
    "\t\nAppendix D\t\n653\n\t 3.\t 23.0. The numbers don’t measure or count anything. They are \nused as replacements for the names of the categories, so the \nnumbers are at the nominal level of measurement. In this case the \nmean is a meaningless statistic.\n\t 4.\t The girl has the larger relative birth weight because her z score of \n0.23 is larger than the z score of 0.19 for the boy.\n\t 5.\t The outlier is 646. The mean and standard deviation with the out-\nlier included are x = 267.8 and s = 131.6. Those statistics with \nthe outlier excluded are x = 230.0 and s = 42.0. Both statistics \nchanged by a substantial amount, so here the outlier has a very \nstrong effect on the mean and standard deviation.\n\t 6.\t The minimum is 119 mm, the first quartile Q1 is 128.0 mm, the \nsecond quartile Q2 (or median) is 131.0 mm, the third quartile Q3 \nis 135.0 mm, and the maximum is 141 mm.\n\t 7.\t Significantly low heights are 83.7 cm or less; significantly high \nheights are 111.3 cm or greater. The height of 87.8 cm is not sig-\nnificant, so the physician should not be concerned.\n\t 8.\t The median would be better because it is not affected much by \nthe one very large income.\nChapter 3: Cumulative Review Exercises\n\t 1.\t\n15.\t Male: z score = -2.69; female: z score = -2.18. The male \nhas the more extreme weight, but the female has the larger weight \nrelative to the group from which she came.\n\t17.\t 50th percentile\t\n19.\t 81st percentile\t\n21.\t 63.0 in.\n\t23.\t 66.5 in. (Tech: Minitab: 66.63 in.; Excel: 66.625 in.)\n\t25.\t 60.75 in.\n\t27.\t 50.0 in. (Tech: Minitab: 49.75 in.; Excel: 49.75 in.)\n\t29.\t 5-number summary: 25.1 in., 26.40 in., 27.50 in., 28.60 in.,  \n29.2 in.\n\t31.\t 5-number summary: 128 mBq, 140.0 mBq, 150.0 mBq,  \n158.5 mBq, 172 mBq (Tech: Minitab yields Q1 = 139.0 mBq \nand Q3 = 159.75 mBq. Excel yields Q1 = 141.0 mBq and \nQ3 = 157.25 mBq.)\n33. The top boxplot represents BMI values for females. The two box-\nplots do not appear to be very different, so BMI values of males \nand females appear to be about the same, except for a few high \nBMI values for females that caused the boxplot to extend farther \nto the right.\n\t35.\t Top boxplot represents females. The two boxplots are not dramati-\ncally different. Outliers for females: 48.0 in., 52.6 in., 56.8 in., \n59.0 in. Outliers for males: 43.2 in., 43.7 in., 44.2 in., 45.9 in.\nChapter 3: Quick Quiz\n\t 1.\t 6.8 hours\t\n2.\t 7.0 hours\n\t 3.\t Two modes: 7 hours, 8 hours\t\n4.\t 1.7 hours2\n\t 5.\t Yes, because 0 hours is substantially less than all of the other data \nvalues.\n\t 6.\t -0.93\t\n7.\t 75%, or 60 sleep times\n\t 8.\t Minimum, first quartile Q1, second quartile Q2 (or median), third \nquartile Q3, maximum\n\t 9.\t 1.5 hours (from range>4)\t\n10.\t x, m, s, s, s2, s2\nChapter 3: Review Exercises\n\t 1.\t a. 1559.6 mm;    b. 1550.0 mm;    c. none;    d. 1569.5 mm;\n\t\n\t e. 145.0 mm;    f. 53.4 mm;       g. 2849.3 mm2\n\t 2.\t z = 1.54. The eye height is not significantly low or high because \nits z score is between 2 and -2, so it is within 2 standard devia-\ntions of the mean.\nArsenic (Mg)\nFrequency\n0.0–1.9\n1\n2.0–3.9\n0\n4.0–5.9\n3\n6.0–7.9\n7\n8.0–9.9\n1\n2.\n3.\n\t 4.\t a. 6.09 mg        b. 6.45 mg    c. 1.75 mg\n\t\n\t d. 3.06 (mg)2    e. 6.70 mg\n\t 5.\t a. \u0007Mode, because the others are numerical measures that require \ndata at the interval or ratio levels of measurement.\n\t\n\t b. Convenience\n\t\n\t c. \u0007More consistency can be achieved by lowering the standard de-\nviation. (It is also important to keep the mean at an acceptable \nlevel.)\n",
    "654\t\nAppendix D\nChapter 4 Answers\nSection 4-1 \n\t 1.\t The probability of selecting someone with blue eyes is 0.35.\n\t 3.\t P1A2 = 0.488\t\n5.\t 0, 3>5, 1, 0.135\n\t 7.\t 1>9 or 0.111\t\n9.\t Significantly high\n\t11.\t Neither significantly low nor significantly high\n\t13.\t 1>2 or 0.5\t\n15.\t 1>4 or 0.25\n\t17.\t 1>10 or 0.1\t\n19.\t 0\n\t21.\t 5>555 or 0.00901. The employer would suffer because it would \nbe at risk by hiring someone who uses drugs.\n\t23.\t 50>555 or 0.0901. This result does appear to be a reasonable esti-\nmate of the prevalence rate.\n\t25.\t 879>945 or 0.930. Yes, the technique appears to be effective.\n\t27.\t 428>580 or 0.738; yes\n\t29.\t 0.130. No, it is not unlikely for someone to never seek medical \ninformation online. Because the responses are from a voluntary \nresponse survey, it is very possible that the results are not very \ngood.\n\t31.\t a. brown>brown, brown>blue, blue>brown, blue>blue\n\t\n\t b. 1>4      c. 3>4\n\t33.\t 3>8 or 0.375\t\n35.\t 4>16 or 1>4 or 0.25.\n\t37.\t The high probability of 0.327 shows that the sample results could \nhave easily occurred by chance. It appears that there is not suf-\nficient evidence to conclude that pregnant women can correctly \npredict the gender of their baby.\n\t39.\t The low probability of less than 0.001 shows that the sample \nresults could not have easily occurred by chance. It appears that \nOxyContin does have an effect on sleepiness.\nSection 4-2\n\t 1.\t P(A) represents the probability of selecting an adult with blue \neyes and P1A2 represents the probability of selecting an adult \nwho does not have blue eyes.\n\t 3.\t Because the selections are made without replacement, the events \nare dependent. Because the sample size of 1068 is less than 5% \nof the population size of 15,524,971, the selections can be treated \nas being independent (based on the 5% guideline for cumbersome \ncalculations).\n\t 5.\t 0.74\t\n7.\t 0.841\n\t 9.\t 91>152 or 0.599\t\n11.\t 138>152 or 0.908; not disjoint.\n\t13.\t a. 0.00974. Yes, the events are independent.\n\t\n\t b. 0.00915. The events are dependent.\n\t15.\t a. 0.731. Yes, the events are independent.\n\t\n\t b. 0.731. The events are dependent.\n\t17.\t 87>152 or 0.572\t\n19.\t 0.0627\n\t21.\t a. 300    b. 154    c. 0.513\n\t23.\t 0.990\n\t25.\t a. 0.03    b. 0.0009    c. 0.000027\n\t\n\t d. \u0007By using one drive without a backup, the probability of total \nfailure is 0.03, and with three independent disk drives, the \nprobability drops to 0.000027. By changing from one drive \nto three, the probability of total failure drops from 0.03 to \n0.000027, and that is a very substantial improvement in reli-\nability. Back up your data!\n\t27.\t 0.838. The probability of 0.838 is high, so it is likely that the en-\ntire batch will be accepted, even though it includes many defects.\n\t29.\t a. 0.299\n\t\n\t b. \u0007Using the 5% guideline for cumbersome calculations: 0.00239 \n[using the rounded result from part (a)]; or 0.00238\n\t31.\t a. 0.999775      b. 0.970225\n\t\n\t c. The series arrangement provides better protection.\n\t33.\t a. P1A or B2 = P1A2 + P1B2 - 2P1A and B2\n\t\n\t b. 85>152 or 0.559\nSection 4-3\n\t 1.\t The event of not getting at least 1 defect among the 3 batteries, \nwhich means that all 3 batteries are good.\n\t 3.\t The probability that the test indicates that the subject has glau-\ncoma given that the subject actually does have glaucoma.\n\t 5.\t 7>8 or 0.875\t\n7.\t 0.982\t\n9.\t 0.344\n\t11.\t 0.994. The probability is high enough so that she can be reason-\nably sure of getting a defective transducer for her work.\n\t13.\t a. 1>3 or 0.333      b. 0.5\n\t15.\t 0.5\n\t17.\t 2>1155 or 0.00173. This is the probability of the test making it \nappear that the subject has hepatitis C when the subject does not \nhave it, so the subject is likely to experience needless stress and \nadditional testing.\n\t19.\t 335>337 or 0.994. The very high result makes the test appear to \nbe effective in identifying hepatitis C.\n\t21.\t a. 0.9991\n\t\n\t b. \u00070.999973. The usual round-off rule for probabilities would \nresult in a probability of 1.00, which would incorrectly indicate \nthat we are certain to have at least one working hard drive.\n\t23.\t 0.490. The probability is not low, so further testing of the individ-\nual samples will be necessary in 49% of the combined samples.\n\t25.\t 0.569\nSection 4-4\n\t 1.\t pt is the proportion of the characteristic in the treatment group, \nand pc is the proportion of the characteristic in the control group.\n\t 3.\t We need to treat 37 subjects with the influenza vaccine in order \nto prevent one case of influenza. The result applies to a large \nnumber of subjects, not every particular group of 37 subjects.\n\t 5.\t Prospective\n\t 7.\t With treatment: 0.159; with placebo: 0.040. The risk of a head-\nache appears to be higher in the treatment group.\n\t 9.\t 9 (rounded up from 8.4)\n\t11.\t 3.99 or roughly 4. The risk of headaches among Viagra users is \nroughly 4 times the risk of headaches for those who take a placebo.\n\t13.\t a. 0.103    b. 0.100\n\t\n\t c. \u00070.00313. The chance of infection in the atorvastatin treatment \ngroup is slightly higher than for the placebo group. For those in \nthe placebo group, there is a 0.313% reduced chance of infec-\ntion when compared to the atorvastatin treatment group.\n\t15.\t Atorvastatin: 89:774 or roughly 1:9. Placebo: 27:243 or 1:9. \nThere is not much of a difference between these two results.\n\t17.\t Relative risk: 0.939; odds ratio: 0.938; the risk of a headache with \nNasonex treatment is slightly less than the risk of a headache \nwith a placebo.\n",
    "\t\nAppendix D\t\n655\nSection 4-5\n\t 1.\t During a year in China, there are 12.3 births for every 1000 \npeople in the population.\n\t 3.\t About 16,737,380 births are expected in a year.\n\t 5.\t 4.0 per 1000\t\n7.\t 10.6 per 1000\n\t 9.\t 64.3 per 1000 women aged 15–44\n\t11.\t 3.7 per 1000\n\t13.\t 0.008; the rate uses fewer decimal places and is easier to \n­understand.\n\t15\t a. 0.0083    b. 0.0000689\n\t\n\t c. \u00070.999931; using three significant digits would result in a prob-\nability of 1.00, which would be misleading because it would \nincorrectly suggest that it is certain that at least one survives \nthe year.\n\t17\t a. 31.3    b. 0.324\n\t19.\t No, the health of the nation is not necessarily declining. The in-\ncreasing number of deaths each year is probably due to the grow-\ning population.\n\t21.\t The United States has a population distribution of 33.10190862%, \n52.41701653%, and 14.48107485% for the three age categories. \nIf the 18,934,195 Florida residents have that same distribu-\ntion, the three age groups would have these numbers of people: \n6,267,580, 9,924,740, and 2,741,875, respectively. Using the \nsame Florida mortality rates for the three individual age groups \nand using the new adjusted population sizes for the three Florida \nage categories, we get these numbers of Florida deaths: 3974, \n40,155, and 105,112, respectively. Using the adjusted numbers of \ndeaths and the adjusted population sizes for the different catego-\nries, the crude mortality rate for Florida becomes 7.9 per 1000, \nwhich is much closer to the U.S. mortality rate of 8.0 per 1000 \nthan the mortality rate of 9.1 per 1000 found for Florida before \nthe adjustments.\nSection 4-6\n\t 1.\t The symbol ! is the factorial symbol that represents the product \nof decreasing whole numbers, as in 6! = 6 # 5 # 4 # 3 # 2 # 1 =\n720. Six people can be scheduled for X-ray films 720 different \nways.\n\t 3.\t The result of 126 is the number of different combinations that are \npossible when 4 items are selected without replacement from 9 \ndifferent items that are available.\n\t 5.\t 1>10,000\t\n7.\t 1>171\n\t 9.\t 1>40,320\t\n11.\t 1>254,251,200\n\t13.\t 1>100,000,000. No, there are too many different possibilities.\n\t15.\t 168,168,000\t\n17.\t 1>100,000\n\t19.\t Area codes: 800. Phone numbers: 6,400,000,000. Yes. (With a \ntotal population of about 400,000,000, there would be about 16 \nphone numbers for every adult and child.)\n\t21.\t a. 5040    b. 210    c. 1>210\n\t23.\t 6720\t\n25.\t 653,837,184,000\n\t27.\t 1>258,890,850. There is a much better chance of being struck by \nlightning.\n\t29.\t There are 62 different possible characters. The alphabet requires \n26 characters and there are 10 digits, so the Morse code system is \nmore than adequate.\n\t31.\t 2,095,681,645,538 (about 2 trillion)\nChapter 4: Quick Quiz\n\t 1.\t 4>5 or 0.8\t\n2.\t 0.7\n\t 3.\t 4>12 or 1>3\t\n4.\t 0.458\n\t 5.\t Answer varies, but the probability should be low, such as 0.01.\n\t 6.\t 0.0680\t\n7.\t 0.727\n\t 8.\t 0.00874\t\n9.\t 0.00459\n\t10.\t 0.0131\nChapter 4: Review Exercises\n\t 1.\t 0.814\n\t 2.\t 0.723\n\t 3.\t 0.918\n\t 4.\t 0.853\n\t 5.\t 0.571\n\t 6.\t 0.662 (not 0.663)\n\t 7.\t 0.663\n\t 8.\t A is the event of selecting a patient and getting someone who was \nnot treated with surgery. P1A2 = 0.532\n\t 9.\t A is the event of selecting a patient and getting someone who did \nnot have a successful treatment. P1A2 = 0.186.\n\t10.\t 0.537\n\t11.\t a. 0.25    b. 0.316\n\t\n\t c. \u0007No, because the probability of 0.316 shows that the event is \nlikely to occur quite often.\n\t12.\t a. 1>365    b. 31>365\n\t\n\t c. Answer varies, but it is probably quite small, such as 0.01 or \nless.    d. Yes\n\t13.\t 0.0335. No.\n\t14.\t a. 999>1000 or 0.999    b. 999,999>1,000,000 or 0.999999\nChapter 4: Cumulative Review Exercises\n\t 1.\t a. 0.168 g>dL    b. 0.160 g>dL    c. 0.220 g>dL\n\t\n\t d. 0.260 g>dL    e. 0.069 g>dL    f. 0.005 (g>dL)2\n\t 2.\t a. 0.09, 0.120, 0.160, 0.180, 0.35 (all in units of g>dL). Outlier: \n0.35 g>dL.\n\t\n\t b. \n\t\n\t c. \n\t 3.\t a. 46%    b. 0.460    c. Stratified sample\n\t 4.\t a. Convenience sample\n\t\n\t b. \u0007If the students at the college are mostly from a surrounding \nregion that includes a large proportion of one ethnic group,  \nthe results might not reflect the general population of the \nUnited States.\n\t\n\t c. 0.75    d. 0.64\n",
    "656\t\nAppendix D\n\t 5.\t The lack of any pattern of the points in the scatterplot suggests \nthat there does not appear to be an association between systolic \nblood pressure and blood platelet count.\nChapter 5 Answers\nSection 5-1 \n\t 1.\t The random variable is x, which is the number of girls in four \nbirths. The possible values of x are 0, 1, 2, 3, and 4. The values of \nthe random variable x are numerical.\n\t 3.\t ΣP1x2 = 0.063 + 0.250 + 0.375 + 0.250 + 0.063 = 1.001. \nThe sum is not exactly 1 because of a round-off error. The sum is \nclose enough to 1 to satisfy the requirement. Also, the variable x \nis a numerical random variable and its values are associated with \nprobabilities, and each of the probabilities is between 0 and 1 \ninclusive, as required. The table does describe a probability distri-\nbution.\n\t 5.\t a. Continuous random variable\n\t \t b. Not a random variable\t\nc. Discrete random variable\n\t \t d. Continuous random variable\t\ne. Discrete random variable\n\t 7.\t Probability distribution with m = 2.5, s = 1.1.\n\t 9.\t Not a probability distribution because the sum of the probabilities \nis 0.94, which is not 1, as required.\n\t11.\t Probability distribution with m = 0.7, s = 0.7.\n\t13.\t m = 4.0 girls, s = 1.4 girls\n\t15.\t Significantly high numbers of girls are greater than or equal to \nm + 2s, and m + 2s = 4.0 + 2(1.4) = 6.8 girls. Because  \n6 girls is not greater than or equal to 6.8 girls, it is not a signifi-\ncantly high number of girls.\n\t17.\t a. 0.109    b. 0.144    c. Part (b)\n\t \t d. No, because the probability of 0.144 is not very low (less than \nor equal to 0.05).\n\t19.\t m = 1.5 sleepwalkers, s = 1.0 sleepwalker\n\t21.\t Significantly high numbers of sleepwalkers are greater than or \nequal to m + 2s, and m + 2s = 1.5 + 211.02 = 3.5 sleep-\nwalkers. Because 3 sleepwalkers is not greater than or equal \nto 3.5 sleepwalkers, 3 sleepwalkers is not a significantly high \n­number.\n\t23.\t a. 0.363    b. 0.535    c. The probability from part (b).\n\t \t d. \u0007No, because the probability of 1 or fewer sleepwalkers is \n0.535, which is not low (not less than or equal to 0.05).\nSection 5-2 \n\t 1.\t The given calculation assumes that the first two peas have green \npods and the last three peas have yellow pods, but there are other \narrangements consisting of two peas with green pods and three \npeas with yellow pods. The probabilities corresponding to those \nother arrangements should also be included in the result.\n\t 3.\t Because the 30 selections are made without replacement, they \nare dependent, not independent. Based on the 5% guideline for \ncumbersome calculations, the 30 selections can be treated as be-\ning independent. (The 30 selections constitute about 3% of the \npopulation of 1020 responses, and 3% is not more than 5% of the \npopulation.) The probability could be found using the binomial \nprobability formula.\n\t 5.\t Not binomial. Each of the weights has more than two possible \noutcomes.\n\t 7.\t Binomial\n\t 9.\t Not binomial; there are more than two possible outcomes.\n\t11.\t Binomial\n\t13.\t a. 0.128    b. WWC, WCW, CWW; 0.128 for each    c. 0.384\n\t15.\t 0.0000819 (Table: 0+)\t\n17.\t 0.797 (Table: 0.798)\n\t19.\t 0.168\t\n21.\t 0.300\t\n23.\t 0.353\n\t25.\t a. m = 18.0 girls; s = 3.0 girls\n\t \t b. \u0007Values of 12.0 girls or fewer are significantly low, values of \n24.0 girls or greater are significantly high, and values between \n12.0 girls and 24.0 girls are not significant.\n\t \t c. \u0007Yes, because the result of 26 girls is greater than or equal to \n24.0 girls. A result of 26 girls would suggest that the XSORT \nmethod is effective.\n\t27.\t a. m = 7.5 peas; s = 1.4 peas\n\t \t b. \u0007Values of 4.7 or less are significantly low, values of 10.3 or \ngreater are significantly high, and values between 4.7 and 10.3 \nare not significant.\n\t \t c. \u0007No, because the result of 9 peas with green pods is not greater \nthan or equal to 10.3.\n\t29.\t 0.304; no.\n\t31.\t 0.662. The probability shows that about 2>3 of all shipments will \nbe accepted. With about 1>3 of the shipments rejected, the sup-\nplier would be wise to improve quality.\n\t33.\t a. \u00073.3 and 10.7. The result of 13 girls is greater than 10.7, so 13 is \na significantly high number of girls.\n\t \t b. 0.000854      c. 0.000916\n\t \t d. \u0007The probability from part (c) is relevant. The result of 13 girls \nis significantly high.\n\t \t e. \u0007The results suggest that the XSORT method is effective in in-\ncreasing the likelihood that a baby is a girl.\n\t35.\t a. \u000729.3 and 41.2. Because 34 falls between those limits, it is \n­neither significantly low nor significantly high.\n\t \t b. 0.118    c. 0.390\n\t \t d. \u0007The probability from part (c) is relevant. The result of 34 peas \nwith long stems is not significantly low.\n\t \t e. \u0007The results do not provide strong evidence against Mendel’s \nclaim of 75% for peas with long stems.\n\t37.\t 0.0468\n\t39.\t Without replacement: 0.139; with replacement: 0.147.\nSection 5-3 \n\t 1.\t m = 31,645>365 = 86.7, which is the mean number of patient \nadmissions per day. x = 85, because we want the probability that \na randomly selected day has exactly 85 admissions, and e ≈\n2.71828, which is a constant used in all applications of Formula 5-9.\n",
    "\t\nAppendix D\t\n657\n\t 3.\t Possible values of x: 0, 1, 2, . . . (with no upper bound). It is not \npossible to have x = 90.3 patient admissions in a day. x is a dis-\ncrete random variable.\n\t 5.\t P1122 = 0.114\t\n7.\t 0.999991\n\t 9.\t 0.9 murder; 0.402 (0.407 using the rounded mean). There should \nbe many days (roughly 40%) with no murders.\n\t11.\t a. 0.170\n\t \t b. \u0007The expected number is between 97.9 and 98.2, depending on \nrounding.\n\t \t c. \u0007The expected number of regions with 2 hits is close to 93, \nwhich is the actual number of regions with 2 hits.\n\t13.\t 0.9999876 or 0.9999877 (using unrounded mean). Very high \nchance, or “almost certain,” that at least one fatality will occur.\n\t15.\t a. 10.6154    b. 0.0000245.\n\t \t c. \u00070.116. With 2 of the 13 years having exactly 9 cases of ru-\nbella, the probability appears to be 2>13 or 0.154; the Poisson \ndistribution yields a probability of 0.116, which is in the gen-\neral ballpark, but it is off by a fairly large amount.\n\t17.\t The distribution is skewed to the right.\nChapter 5: Quick Quiz\n\t 1.\t m = 13.2 males\t\n2.\t s = 3.2 males\t\n3.\t Parameters\n\t 4.\t Significantly low: 6.8 or fewer. Significantly high: 19.6 or more.\n\t 5.\t 0.154\n\t 6.\t Yes. The sum of the probabilities is 1, and all of the probabilities \nare between 0 and 1 inclusive, and the values of x are numerical.\n\t 7.\t 0.3 male\n\t 8.\t 0.3 male2 (or 0.2 male2 if using the unrounded standard devia-\ntion)\n\t 9.\t 0+ indicates that the probability is a very small positive number. \nIt does not indicate that it is impossible for all five adult males to \nbe heavy drinkers.\n\t10.\t 0.999. Yes, 4 is significantly high.\nChapter 5: Review Exercises\n\t 1.\t 0.293\n\t 2.\t 0.807. No. The five subjects from the same family are not ran-\ndomly selected from the population of adults. Because they are \nfrom the same family, they are likely to share similar diet and \ngenetic factors, so they are not independent.\n\t 3.\t m = 1.4 adults and s = 1.0 adult.\n\t 4.\t Using m = 1.4 adults and s = 1.0 adult, values are significantly \nhigh if they are equal to or greater than m + 2s = 3.4 adults. \nThe result of five adults with high cholesterol is significantly \nhigh because it is equal to or greater than 3.4 adults. Also, the \nprobability that the five adults have high cholesterol is 0.00172, \nwhich is low (less than or equal to 0.05).\n\t 5.\t Using m = 1.4 adults and s = 1.0 adult, values are significantly \nlow if they are equal to or less than m - 2s = -0.6 adult, which \nis impossible. Also, the probability that 1 or fewer adults have \nhigh cholesterol is 0.570, which is not low (less than or equal to \n0.05). A result of 1 adult with high cholesterol is not a signifi-\ncantly low number.\n\t 6.\t No. The responses are not numerical.\n\t 7.\t a. Yes. The sum of the probabilities is 1. Each probability is be-\ntween 0 and 1 inclusive. The values of x are numerical.\n\t \t b. m = 1.1 condoms\n\t \t c. s = 0.9 condom\n\t \t d. \u0007Yes, 5 failures is significantly high. A number is significantly \nhigh if it is equal to or greater than m + 2s = 2.9, and 5 does \nexceed 2.9. Also, the probability of 5 or more failures is 0.001, \nwhich is a low probability.\n\t \t e. \u0007Here, the symbol 0+ represents a positive probability that is so \nsmall that it is 0.000 when rounded.\n\t 8.\t a. 143>365 or 0.392 death per day    b. 0.676\n\t \t c. 0.00750 (or 0.00749 if using the unrounded mean)\n\t \t d. No, because the event is so rare.\nChapter 5: Cumulative Review Exercises\n\t 1.\t a. 82.4 manatees    b. 82.0 manatees\n\t \t c. 28.0 manatees    d. 9.3 manatees\n\t \t e. \u000787.2 manatees2 (86.5 manatees2 results from using the rounded \nstandard deviation of 9.3 manatees)\n\t \t f. \u0007The trend of the manatee deaths over time is not addressed by \nthe preceding statistics.\n\t \t g. \u0007Significantly low numbers are 63.8 manatees or lower, and sig-\nnificantly high numbers are 101 manatees or higher. (If using \nunrounded statistics, the limits are 63.7 manatees and 101.1 \nmanatees.)\n\t \t h. \u0007None of the listed numbers are significantly low or signifi-\ncantly high.\n\t \t i. Ratio    j. Discrete\n\t 2.\t a. x = 4.6 and s = 2.7. They are statistics.\n\t \t b. \u0007The last digits appear to be random. None of the frequencies \nappears to be substantially different from the others.\n\t \t c. \u0007No. The values of x are numerical, but the frequencies are not \nprobabilities, as required.\n\t 3.\t No vertical scale is shown, but a comparison of the numbers \nshows that 7,066,000 is roughly 1.2 times the number 6,000,000; \nhowever, the graph makes it appear that the goal of 7,066,000 \npeople is roughly 3 times the number of people enrolled. The \ngraph is misleading in the sense that it creates the false impres-\nsion that actual enrollments are far below the goal, which is not \nthe case. Fox News apologized for this graph and provided a cor-\nrected graph.\n\t 4.\t a. 0.885    b. 0.0132    c. 0.307\n\t \t d. m = 4.6 adults, s = 2.0 adults. These results are parameters.\n\t \t e. \u0007Significantly low numbers are 0.6 or lower, and significantly \nhigh numbers are 8.6 and higher. Because 10 is greater than \n8.6, it is a significantly high number of adults with diabetes \n(among 40).\n",
    "658\t\nAppendix D\nChapter 6 Answers\nSection 6-1 \n\t 1.\t The word “normal” has a special meaning in statistics. It refers \nto a specific bell-shaped distribution that can be described by \nFormula 6-1. The lottery digits do not have a normal distribution.\n\t 3.\t The mean is m = 0 and the standard deviation is s = 1.\n\t 5.\t 0.4\t\n7.\t 0.2\t\n9.\t 0.6700\n\t11.\t 0.6993 (Table: 0.6992)\t\n13.\t 1.23\t\n15.\t -1.45\n\t17.\t 0.1093\t\n19.\t 0.8997\t\n21.\t 0.4013\n\t23.\t 0.9772\t\n25.\t 0.0214 (Table: 0.0215)\n\t27.\t 0.0174\t\n29.\t 0.9545 (Table: 0.9544)\n\t31.\t 0.8413 (Table: 0.8412)\t\n33.\t 0.999997 (Table: 0.9999).\n\t35.\t 0.5000\t\n37.\t 2.33\t\n39.\t -2.05, 2.05\n\t41.\t 1.28\t\n43.\t 1.75\n\t45.\t 68.27% (Table: 68.26%)\t\n47.\t 99.73% (Table: 99.74%)\n\t49.\t a. 2.28%    b. 2.28%    c. 95.45% (Table: 95.44%)\nSection 6-2 \n\t 1.\t a. m = 0; s = 1\n\t \t b. The z scores are numbers without units of measurement.\n\t 3.\t The standard normal distribution has a mean of 0 and a standard \ndeviation of 1, but a nonstandard normal distribution has a differ-\nent value for one or both of those parameters.\n\t 5.\t 0.8849\t\n7.\t 0.9053\t\n9.\t 136\n\t11.\t 69\t\n13.\t 0.9812\t\n15.\t 0.2431\n\t17.\t 90.0 beats per minute\n\t19.\t 44.9 beats per minute and 103.1 beats per minute. No, 102 beats \nper minute is not significantly high.\n\t21.\t 0.2015 (Table: 0.2005). No, the proportion of schizophrenics is \nnot at all likely to be as high as 0.2005, or about 20%.\n\t23.\t a. 0.1717 (Table: 0.1711)    b. 2011.5 g (Table: 2011.4 g)\n\t \t c. \u0007Birth weights are significantly low if they are 2011.4 g or less, \nand they are “low birth weights” if they are 2495 g or less. \nBirth weights between 2011.4 g and 2495 g are “low birth \nweights” but they are not significantly low.\n\t25.\t a. \u0007The mean is 71.320 mm Hg and the standard deviation is \n11.994 mm Hg. A histogram confirms that the distribution is \nroughly normal.\n\t \t b. 47.8 mm Hg; 94.8 mm Hg\n\t27.\t 0.0070\nSection 6-3 \n\t 1.\t a. \u0007In the long run, the sample proportions will have a mean of \n0.512.\n\t \t b. \u0007The sample proportions will tend to have a distribution that is \napproximately normal.\n\t 3.\t Sample mean; sample variance; sample proportion\n\t 5.\t No. The sample is not a simple random sample from the popu-\nlation of all births worldwide. The proportion of boys born in \nChina is substantially higher than in other countries.\n\t 7.\t a. 4.7\n\t\n\t b.\nSample  \nVariance s2\n \nProbability\n  0.0\n3>9\n  0.5\n2>9\n  8.0\n2>9\n12.5\n2>9\n\t\n\t c. 4.7\n\t \t d. \u0007Yes. The mean of the sampling distribution of the sample vari-\nances (4.7) is equal to the value of the population variance (4.7), so \nthe sample variances target the value of the population variance.\n\t 9.\t a. 5\n\t\n\t b.\nSample Median\nProbability\n4.0\n1>9\n4.5\n2>9\n5.0\n1>9\n6.5\n2>9\n7.0\n2>9\n9.0\n1>9\n\t\n\t c. 6.0\n\t \t d. \u0007No. The mean of the sampling distribution of the sample me-\ndians is 6.0, and it is not equal to the value of the population \nmedian (5.0), so the sample medians do not target the value of \nthe population median.\n\t11.\t a.\nx\nProbability\n34\n1>16\n35\n2>16\n36\n1>16\n37.5\n2>16\n38.5\n2>16\n41\n1>16\n42.5\n2>16\n43.5\n2>16\n46\n2>16\n51\n1>16\n\t\n\t b. \u0007The mean of the population is 40.5 and the mean of the sample \nmeans is also 40.5.\n\t \t c. \u0007The sample means target the population mean. Sample means \nmake good estimators of population means because they target \nthe value of the population mean instead of systematically un-\nderestimating or overestimating it.\n",
    "\t\nAppendix D\t\n659\n\t\nAPPENDIX D\t\n659\n\t13.\t a.\n\t \t c. \u0007Because the original population has a normal distribution, the \ndistribution of sample means is normal for any sample size.\n\t 9.\t a. 79.08% (Table 79.19%)    b. 99.44%\n\t11.\t a. 3.85% (Table 3.84%)    b. 0.02% (Table 0.01%)\n\t13.\t a. 131    b. 0.0000179 (Table: 0.0001)\n\t \t c.\t \u0007No. It is possible that the 4 subjects have a mean of 132 while \nsome of them have scores below the Mensa requirement of 131.\n\t15.\t a. 140 lb    b. 0.9999999998 (Table: 0.9999)\n\t\n\t c. 0.9458 (Table: 0.9463)\n\t \t d. \u0007The new capacity of 20 passengers does not appear to be safe \nenough because the probability of overloading is too high.\n\t17.\t a. 0.0047    b. 0.0000 (Table: 0.0001)\n\t \t c. \u0007The result from part (a) is relevant because the seats are occu-\npied by individuals.\n\t19.\t a. 0.8877 (Table: 0.8869)\n\t\n\t b. 1.0000 when rounded to four decimal places (Table: 0.9999).\n\t\n\t c. \u0007The probability from part (a) is more relevant because it shows \nthat 89% of male passengers will not need to bend. The result \nfrom part (b) gives us information about the mean for a group \nof 100 men, but it doesn’t give us useful information about the \ncomfort and safety of individual male passengers.\n\t \t d. \u0007Because men are generally taller than women, a design that \naccommodates a suitable proportion of men will necessarily \naccommodate a greater proportion of women.\n\t21.\t a. \u0007Yes. The sampling is without replacement and the sample size \nof n = 50 is greater than 5% of the finite population size of \n275. sx = 2.0504584.\n\t \t b. 0.5963 (Table: 0.5947)\nSection 6-5 \n\t 1.\t The histogram should be approximately bell-shaped, and the nor-\nmal quantile plot should have points that approximate a straight-\nline pattern.\n\t 3.\t We must verify that the sample is from a population having a nor-\nmal distribution. We can check for normality using a histogram, \nidentifying the number of outliers, and constructing a normal \nquantile plot.\n\t 5.\t Normal. The points are reasonably close to a straight-line pattern, \nand there is no other pattern that is not a straight-line pattern.\n\t 7.\t Not normal. The points are not reasonably close to a straight-line \npattern, and there appears to be a pattern that is not a straight-line \npattern.\n\t 9.\t Not normal\t\n11.\t Normal\n\t13.\t Not normal\nRange\nProbability\n  0\n4>16\n  2\n2>16\n  5\n2>16\n  7\n2>16\n10\n2>16\n15\n2>16\n17\n2>16\n\t\n\t b. \u0007The range of the population is 17, but the mean of the sample \nranges is 7. Those values are not equal.\n\t \t c. \u0007The sample ranges do not target the population range of 17, \nso sample ranges do not make good estimators of population \nranges.\n\t15.\t\nProportion of Girls\nProbability\n0\n0.25\n0.5\n0.50\n1\n0.25\n\t\n\t Yes. The proportion of girls in 2 births is 0.5, and the mean of the \nsample proportions is 0.5. The result suggests that a sample pro-\nportion is an unbiased estimator of a population proportion.\n\t17.\t a.\nProportion Correct\nProbability\n0\n16>25\n0.5\n8>25\n1\n1>25\n\t\n\t b. 0.2\n\t \t c. \u0007Yes. The sampling distribution of the sample proportions has a \nmean of 0.2 and the population proportion is also 0.2 (because \nthere is 1 correct answer among 5 choices). Yes, the mean of \nthe sampling distribution of the sample proportions is always \nequal to the population proportion.\n\t19.\t The formula yields P102 = 0.25, P10.52 = 0.5, and \nP112 = 0.25, which does describe the sampling distribution of \nthe sample proportions. The formula is just a different way of \npresenting the same information in the table that describes the \nsampling distribution.\nSection 6-4 \n\t 1.\t The sample must have more than 30 values, or there must be evi-\ndence that the population of grade-point averages from statistics \nstudents has a normal distribution.\n\t 3.\t mx represents the mean of all sample means, and sx represents the \nstandard deviation of all sample means. For the samples of 64 IQ \nscores, mx = 100 and sx = 15> 264 = 1.875.\n\t 5.\t a. 0.6844    b. 0.9726\n\t \t c. \u0007Because the original population has a normal distribution, the \ndistribution of sample means is a normal distribution for any \nsample size.\n\t 7.\t a. 0.1271 (Table: 0.1272)    b. 0.2510\n",
    "660\t\nAppendix D\n\t15.\t Normal\n\t17.\t Normal. The points have coordinates (32.5, -1.28),  \n(34.2, -0.52), (38.5, 0), (40.7, 0.52), (44.3, 1.28).\n\t19.\t a. Yes    b. Yes    c. No\nSection 6-6 \n\t 1.\t a. The area below (to the left of) 502.5\n\t\n\t b. The area between 501.5 and 502.5\n\t \t c. The area above (to the right of) 502.5\n\t 3.\t  p = 0.2; q = 0.8; m = 20; s = 4. The value of m = 20  \nshows that for people who make 100 random guesses for the  \n100 questions, the mean number of correct answers is 20. For \ngroups of 100 people who make random guesses, the standard \ndeviation of s = 4 is a measure of how much the numbers of \ncorrect ­responses vary.\n\t 5.\t 0.1102 (Table: 0.1093)\n\t 7.\t Normal approximation should not be used.\n\t 9.\t Using normal approximation: 0.1727 (Table: 0.1736); Tech using \nbinomial: 0.1724. The result of 40 people with blue eyes is not \nsignificantly high.\n\t11.\t Using normal approximation: 0.0105 (Table: 0.0104); Tech using \nbinomial: 0.0053. The result of 4 people with green eyes is sig-\nnificantly low.\n\t13.\t a. \u0007Using normal approximation: 0.0204; Tech using binomial: \n0.0205.\n\t\n\t b. \u0007Using normal approximation: 0.0569 (Table: 0.0571); Tech \n­using binomial: 0.0513.\n\t \t c. No\n\t15.\t a. \u0007Using normal approximation: 0.1008 (Table: 0.1003); Tech \n­using binomial: 0.1012.\n\t\n\t b. \u0007The result of 455 who have sleepwalked is not significantly \nhigh.\n\t \t c. \u0007The result of 455 does not provide strong evidence against the \nrate of 29.2%.\n\t17.\t (1) 0.1723; (2) 0.1704; (3) 0.1726. No, the approximations are \nnot off by very much.\nChapter 6: Quick Quiz\n\t 1.\t\n\t 2.\t z = -1.34\t\n3.\t 0.9983\n\t 4.\t  0.1546 (Table: 0.1547)\n\t 5.\t a. m = 0 and s = 1\n\t \t b. \u0007mx represents the mean of all sample means and sx represents \nthe standard deviation of all sample means.\n\t 6.\t 0.8092 (Table: 0.8106)\t\n7.\t 0.6280 (Table: 0.6292)\n\t 8.\t 84.6 mm Hg (Table: 84.5 mm Hg)\n\t 9.\t 0.9568 (Table: 0.9564)\n\t10.\t The normal quantile plot suggests that diastolic blood pressure \nlevels of women are normally distributed.\nChapter 6: Review Exercises\n\t 1.\t a. 0.9382    b. 0.9382    c. 0.8983\n\t\n\t d. -0.67    e. 0.0668\n\t 2.\t a. 1.13%    b. 63.8 in.\n\t 3.\t a. 1.42% (Table: 1.43%)    b. 59.0 in.\n\t 4.\t a. Normal    b. 100    c. 15> 264 = 1.875\n\t 5.\t a. \u0007An unbiased estimator is a statistic that targets the value of the \npopulation parameter in the sense that the sampling distribution \nof the statistic has a mean that is equal to the corresponding \nparameter.\n\t\n\t b. Mean; variance; proportion    c. True\n\t 6.\t a. \u000788.77% (Table: 88.69%). With about 11% of all men needing \nto bend, the design does not appear to be adequate, but the \nMark VI monorail appears to be working quite well in practice.\n\t \t b. 75.1 in\n\t 7.\t a. \u0007Because women are generally a little shorter than men, a door-\nway height that accommodates men will also accommodate \nwomen.\n\t\n\t b. 1, but actually a really small amount less than 1 (Table: 0.9999)\n\t \t c. \u0007Because the mean height of 60 men is less than 72 in., it does \nnot follow that the 60 individual men all have heights less than \n72 in. In determining the suitability of the door height for men, \nthe mean of 60 heights is irrelevant, but the heights of indi-\nvidual men are relevant.\n\t 8.\t a. \u0007No. A histogram is far from bell-shaped. A normal quantile \nplot reveals a pattern of points that is far from a straight-line \npattern.\n\t \t b. \u0007No. The sample size of n = 13 does not satisfy the condition \nof n 7 30, and the values do not appear to be from a popula-\ntion having a normal distribution.\n\t 9.\t Using normal approximation: 0.2286 (Table: 0.2296); Tech using \nbinomial: 0.2278. The occurrence of 787 offspring plants with \nlong stems is not significantly low because the probability of 787 \nor fewer plants with long stems is not small. The results are con-\nsistent with Mendel’s claimed proportion of 3>4.\n\t10.\t a. 1.49% (Table: 1.50%)    b. 69.4 in.\n",
    "\t\nAppendix D\t\n661\nChapter 6: Cumulative Review Exercises\n\t 1.\t a. 26.82    b. 28.90    c. 4.76    d. 0.96\n\t\n\t e. Ratio    f. Continuous\n\t 2.\t a. 26.45, 28.90, 29.05\n\t\n\t b.\n\t \t c. \u0007The sample does not appear to be from a population having a \nnormal distribution.\n\t 3.\t a. 0.001    b. 0.271\n\t\n\t c. \u0007The requirement that np Ú 5 is not satisfied, indicating that the \nnormal approximation would result in errors that are too large.\n\t\n\t d. 5.0 people    e. 2.1 people\n\t \t f. No, 8 is within two standard deviations of the mean and is \nwithin the range of values that could easily occur by chance.\n\t 4.\t a. \u0007B is the event of selecting someone who does not have blue \neyes.\n\t\n\t b. 0.65    c. 0.0429\n\t\n\t d. \u0007Using normal approximation: 0.0232 (Table: 0.0233); Tech us-\ning binomial: 0.0246.\n\t \t e. Yes\n\t 5.\t a. 0.7881    b. 0.9968 (Table: 0.9967)\n\t\n\t c. 10.4 in.     d. 0.0228\nChapter 7 Answers\nSection 7-1 \n\t 1.\t The confidence level, such as 95%, was not provided.\n\t 3.\t pn = 0.13 is the sample proportion; qn = 0.87 (found from evalu-\nating 1 - pn); n = 227 is the sample size; E = 0.04 is the margin \nof error; p is the population proportion, which is unknown. The \nvalue of a is 0.05.\n\t 5.\t 1.645\t\n7.\t 2.81\n\t 9.\t 0.400 { 0.025\t\n11.\t 0.0780 6 p 6 0.162\n\t13.\t a. 0.0705    b. E = 0.0333    c. 0.0372 6 p 6 0.104 \n\t \t d. \u0007We have 95% confidence that among subjects treated with \nOxyContin, the interval from 0.0372 to 0.104 actually does \ncontain the true value of the population proportion of subjects \nwho experience headaches.\n\t15.\t a. 0.143    b. E = 0.00815    c. 0.135 6 p 6 0.152\n\t \t d. \u0007We have 90% confidence that the interval from 0.135 to 0.152 \nactually does contain the true value of the population propor-\ntion of returned surveys.\n\t17.\t 0.462 6 p 6 0.529. Because 0.512 is contained within the con-\nfidence interval, there is not strong evidence against 0.512 as the \nvalue of the proportion of boys in all births.\n\t19.\t a. 17.4% 6 p 6 28.4%\n\t \t b. \u0007Because the two confidence intervals overlap, it is possible \nthat the OxyContin treatment group and the placebo group \nhave the same rate of nausea. Nausea does not appear to be an \nadverse reaction made worse with OxyContin.\n\t21.\t a. \u00070.0276% 6 p 6 0.0366% (using x = 135: 0.0276% 6 p 6\n0.0367%).\n\t \t b. No, because 0.0340% is included in the confidence interval.\n\t23.\t 91.4% 6 p 6 94.6%. It appears that the success rate for the \nXSORT method is much higher than the success rate of about \n50% expected with no treatment, so the XSORT method appears \nto be successful.\n\t25.\t 0.496 6 p 6 0.514. No, because the proportion could easily \nequal 0.5. The proportion does not appear to be significantly less \nthan 0.5 the week before Thanksgiving.\n\t27.\t Sustained care: 77.6% 6 p 6 88.1% (using x = 164). Standard \ncare: 56.1% 6 p 6 69.5% (using x = 125). The two confi-\ndence intervals do not overlap. It appears that the success rate is \nhigher with sustained care.\n\t29.\t a. 1844 (Table: 1842)    b. 664\n\t\n\t c. \u0007The added knowledge results in a very substantial decrease in \nthe required sample size.\n\t31.\t a. 385    b. 369\n\t \t c. No, the sample size doesn’t change much.\n\t33.\t a. 1537    b. 1532    c. No\n\t35.\t a. 752    b. 749\n\t \t c. \u0007No. A sample of the adults you know is a convenience sample, \nnot a simple random sample, so it is very possible that the re-\nsults would not be representative of the population.\n\t37.\t 1238 (Table: 1237)\n\t39.\t a. \u0007The requirement of at least 5 successes and at least 5 failures \nis not satisfied, so the normal distribution cannot be used.\n\t \t b. 0.075\nSection 7-2 \n\t 1.\t a. 12.855 g>dL 6 m 6 13.391 g>dL\n\t\n\t b. \u0007Best point estimate of m is 13.123 g>dL. The margin of error \nis E = 0.268 g>dL.\n\t \t c. \u0007Because the sample size of 100 is greater than 30, we can con-\nsider the sample mean to be from a population with a normal \ndistribution.\n\t 3.\t We have 95% confidence that the limits of 12.855 g>dL and \n13.391 g>dL contain the true value of the mean hemoglobin \nlevel of the population of all adult females.\n\t 5.\t Neither the normal nor the t distribution applies.\n\t 7.\t za>2 = 2.576 (Table: 2.575)\n\t 9.\t 29.4 hg 6 m 6 31.4 hg. No, the results do not differ by much.\n\t11.\t 98.08°F 6 m 6 98.32°F. Because the confidence interval does \nnot contain 98.6°F, it appears that the mean body temperature is \nnot 98.6°F, as is commonly believed.\n\t13.\t 71.4 min 6 m 6 126.4 min. The confidence interval includes \nthe mean of 102.8 min that was measured before the treatment, \nso the mean could be the same after the treatment. This result \nsuggests that the zopiclone treatment does not have a significant \neffect.\n\t15.\t 1.8 6 m 6 3.4. The given numbers are just substitutes for the \nfour DNA base names, so the numbers don’t measure or count \nanything, and they are at the nominal level of measurement. The \nconfidence interval has no practical use.\n\t17.\t The sample data meet the loose requirement of having a normal \ndistribution. CI: 0.707 W>kg 6 m 6 1.169 W>kg. Because the \nconfidence interval is entirely below the standard of 1.6 W>kg, it \nappears that the mean amount of cell phone radiation is less than \nthe FCC standard, but there could be individual cell phones that \nexceed the standard.\n\t19.\t 0.284 ppm 6 m 6 1.153 ppm. Using the FDA guideline, the \nconfidence interval suggests that there could be too much mer-\ncury in fish because it is possible that the mean is greater than \n",
    "662\t\nAppendix D\n1 ppm. Also, one of the sample values exceeds the FDA guideline \nof 1 ppm, so at least some of the fish have too much mercury.\n\t21.\t 19.5 mg 6 m 6 45.6 mg. People consume some brands much \nmore often than others, but the 20 brands are all weighted equally \nin the calculations, so the confidence interval might not be a \ngood estimate of the population mean. Just the presence of five \nzeros suggests that the sample is not from a normally distributed \npopulation, so the normality requirement is violated and the \nconfidence interval might not be good estimate of the population \nmean.\n\t23.\t a. 5.8 days 6 m 6 6.2 days    b. 5.9 days 6 m 6 6.3 days\n\t \t c. \u0007The two confidence intervals are very similar. The echinacea \ntreatment group does not appear to fare any better than the pla-\ncebo group, so the echinacea treatment does not appear to be \neffective.\n\t25.\t Females: 72.0 bpm 6 m 6 76.1 bpm. Males: 67.8 bpm 6 m 6\n71.4 bpm. Adult females appear to have a mean pulse rate that is \nhigher than the mean pulse rate of adult males. Good to know.\n\t27.\t The sample size is 94, and it does appear to be very practical.\n\t29.\t The required sample size is 38,415 (Table: 38,416). The sample \nappears to be too large to be practical.\n\t31.\t 4814 (Table: 4815). Yes, the assumption seems reasonable.\n\t33.\t a. 425    b. 212\n\t \t c. \u0007The result from part (a) is substantially larger than the result \nfrom part (b). The result from part (b) is likely to be better \nbecause it uses s instead of the estimated s obtained from the \nrange rule of thumb.\n\t35.\t a. 234.2 6 m 6 276.0    b. 235.0 6 m 6 275.2\n\t \t c. \u0007The second confidence interval is narrower, indicating that we \nhave a more accurate estimate when the relatively large sample \nis selected without replacement from a relatively small finite \npopulation.\nSection 7-3 \n\t 1.\t 95.0 cm3 6 s 6 182.5 cm3. We have 95% confidence that the \nlimits of 95.0 cm3 and 182.5 cm3 contain the true value of the \nstandard deviation of brain volumes.\n\t 3.\t The dotplot does not appear to depict sample data from a nor-\nmally distributed population. The large sample size does not \njustify treating the values as being from a normally distributed \npopulation. Because the normality requirement is not satisfied, \nthe confidence interval estimate of s should not be constructed \nusing the methods of this section.\n\t 5.\t df = 24. x2\nL = 12.401 and x2\nR = 39.364. CI: 0.19 mg 6 s 6  \n0.33 mg.\n\t 7.\t df = 146. x2\nL = 105.741 (Table: 67.328) and x2\nR = 193.761 \n(Table: 140.169). CI: 56.8 6 s 6 76.8 (Table: 66.7 6 s 6 96.3).\n\t 9.\t 0.55°F 6 s 6 0.72°F (Table: 0.56°F 6 s 6 0.74°F)\n\t11.\t 29.6 min 6 s 6 71.6 min. No, the ­confidence interval does not \nindicate whether the treatment is effective.\n\t13.\t 0.19 g 6 s 6 0.41 g\n\t15.\t a. 10 BPM 6 s 6 27 BPM  b. 12 BPM 6 s 6 33 BPM\n\t \t c. The variation does not appear to be significantly different.\n\t17.\t a. \u00078.8 days 6 s 6 10.7 days. The sample appears to be from a \npopulation with a distribution that is far from normal, so the \nconfidence interval estimate might not be very good.\n\t\n\t b. \u00077.5 days 6 s 6 9.2 days. The sample appears to be from a \npopulation with a distribution that is far from normal, so the \nconfidence interval estimate might not be very good.\n\t \t c. The amounts of variation are about the same.\n\t19.\t 19,205 is too large. There aren’t 19,205 biostatistics professors \nin the population, and even if there were, that sample size is too \nlarge to be practical.\n\t21.\t The sample size is 48. No, with many very low incomes and a \nfew high incomes, the distribution is likely to be skewed to the \nright and will not satisfy the requirement of a normal distribution.\n\t23.\t x2\nL = 109.565 and x2\nR = 175.276. The values from the approxi-\nmation are quite close to the actual critical values.\nSection 7-4 \n\t 1.\t Without replacement, every sample would be identical to the \noriginal sample, so the proportions or means or standard devia-\ntions or variances would all be the same, and there would be no \nconfidence “interval.”\n\t 3.\t Parts b, d, e are not possible bootstrap samples.\n\t 5.\t 0.000 6 p 6 0.500\n\t 7.\t a. 0.1 kg 6 m 6 8.6 kg    b. 1.9 kg 6 s 6 6.3 kg\n\t 9.\t Answers vary, but here are typical answers.\n\t\n\t a. -0.8 kg 6 m 6 7.8 kg    b. 1.2 kg 6 s 6 7.0 kg\n\t11.\t Answers vary, but here are typical answers.\n\t\n\t a. \u0007Bootstrap: 55.3 min 6 m 6 67.3 min. This isn’t dramatically \ndifferent from 51.9 min 6 m 6 71.4 min.\n\t \t b. \u0007Bootstrap: 6.2 min 6 s 6 13.7 min. This isn’t dramatically \ndifferent from 7.7 min 6 s 6 18.4 min.\n\t13.\t Answers vary, but here is a typical result: 0.348% 6 p 6 1.62%. \nThis is quite close to the confidence interval of 0.288% 6\np 6 1.57% found in Exercise 22 “Lipitor” from ­Section 7-1.\n\t15.\t Answers vary, but here is a typical result: 0.135 6 p 6 0.152. \nThe result is essentially the same as the confidence interval of \n0.135 6 p 6 0.152 found in Exercise 15 from Section 7-1.\n\t17.\t Answers vary, but here is a typical result: 3.69 6 m 6 4.15. This \nresult is very close to the confidence interval 3.67 6 m 6 4.17 \nthat would be found by using the methods from Section 7-2.\n\t19.\t Answers vary, but here is a typical result: \n0.712 W>kg 6 m 6 1.18 W>kg. This result is very close to the \nconfidence interval of 0.707 W>kg 6 m 6 1.169 W>kg found in \nExercise 17 of Section 7-2.\n\t21.\t a. Answers vary, but here is a typical result: 2.5 6 s 6 3.3.\n\t\n\t b. 2.4 6 s 6 3.7\n\t \t c. \u0007The confidence interval from the bootstrap method is not very \ndifferent from the confidence interval found using the methods \nof Section 7-3. Because a histogram or normal quantile plot \nshows that the sample appears to be from a population not hav-\ning a normal distribution, the bootstrap confidence interval of \n2.5 6 s 6 3.3 would be a better estimate of s.\n\t23.\t Answers vary, but here is a typical result using 10,000 bootstrap \nsamples: 2.5 6 s 6 3.3. This result is the same as the confi-\ndence interval found using 1000 bootstrap samples. In this  \ncase, increasing the number of bootstrap samples from 1000  \nto 10,000 does not have much of an effect on the confidence  \ninterval.\n",
    "\t\nAppendix D\t\n663\nChapter 7: Cumulative Review Exercises\n\t 1.\t x = 27.27 cm, median = 27.15 cm, s = 1.24 cm, \nrange = 3.80 cm. These results are statistics.\n\t 2.\t Significantly low values are 25.37 cm or lower, and significantly \nhigh values are 29.17 cm or higher. Because 30 cm exceeds \n29.17 cm, a foot length of 30 cm is significantly high (or long).\n\t 3.\t Ratio level of measurement; continuous data.\n\t 4.\t A histogram is not very helpful with only 10 data values, but \na normal quantile plot shows that the sample data appear to be \nfrom a population having a distribution that is approximately \nnormal.\n\t 5.\t 26.38 cm 6 m 6 28.16 cm\n\t 6.\t 482 adult females\n\t 7.\t a. 0.2375 (Table: 0.2389)    b. 0.0002 (Table: 0.0001)\n\t \t c. 26.04 cm\n\t 8.\t 95.6% 6 p 6 98.0%. Yes.\nChapter 8 Answers\nSection 8-1 \n\t 1.\t Rejection of the claim about aspirin is more serious because it \nis a drug used for medical treatments. The wrong aspirin dosage \ncould cause more serious adverse reactions than a wrong vitamin \nC dosage. It would be wise to use a smaller significance level for \ntesting the claim about the aspirin.\n\t 3.\t a.  H0: m = 174.1 cm\n\t\n\t b.  H1: m ≠174.1 cm\n\t\n\t c.  Reject the null hypothesis or fail to reject the null hypothesis.\n\t \t d.  \u0007No. In this case, the original claim becomes the null hypoth-\nesis. For the claim that the mean height of men is equal to \n174.1 cm, we can either reject that claim or fail to reject it, but \nwe cannot state that there is sufficient evidence to support that \nclaim.\n\t 5.\t a.  p 7 0.5\n\t \t b.  H0: p = 0.5; H1: p 7 0.5\n\t 7.\t a.  m = 69 bpm\n\t \t b.  H0: m = 69 bpm; H1: m ≠69 bpm\n\t 9.\t There is sufficient evidence to support the claim that most adults \ndo not have hypertension.\n\t11.\t There is not sufficient evidence to warrant rejection of the claim that \nthe mean pulse rate (in beats per minute) of adult males is 69 bpm.\n\t13.\t z = 13.11\n\t15.\t t = 0.657\n\t17.\t a.  Right-tailed\n\t\n\t b.  P-value = 0.1587\n\t \t c.  Fail to reject H0.\n\t19.\t a.  Two-tailed\n\t\n\t b.  P-value = 0.0444\n\t \t c.  Reject H0.\n\t21.\t a.  z = 1.645\n\t \t b.  Fail to reject H0.\n\t23.\t a.  z = {1.96\n\t \t b.  Reject H0.\n\t25.\t a.  Fail to reject H0.\n\t \t b.  \u0007There is not sufficient evidence to support the claim that more \nthan 70% of adults do not have hypertension.\nChapter 7: Quick Quiz\n\t 1.\t 0.130\n\t 2.\t We have 95% confidence that the limits of 0.110 and 0.150 con-\ntain the true value of the proportion of adults in the population \nwho correct their vision by wearing contact lenses.\n\t 3.\t  z = 2.576 (Table: 2.575)\n\t 4.\t 0.02 6 p 6 0.04 or 2% 6 p 6 4%\n\t 5.\t 601\n\t 6.\t 136\n\t 7.\t There is a loose requirement that the sample values are from a \nnormally distributed population.\n\t 8.\t The degrees of freedom is the number of sample values that can \nvary after restrictions have been imposed on all of the values. For \nthe sample data described in Exercise 7, df = 11.\n\t 9.\t t = 2.201\n\t10.\t No, the use of the x2 distribution has a fairly strict requirement that \nthe data must be from a normal distribution. The bootstrap method \ncould be used to find a 95% confidence interval estimate of s.\nChapter 7: Review Exercises\n\t 1.\t 0.00301 6 p 6 0.00348. We have 95% confidence that the lim-\nits of 0.00301 and 0.00348 contain the value of the population \nproportion.\n\t 2.\t 423\n\t 3.\t a. 22.083 mm    b. 22.034 mm 6 m 6 22.133 mm\n\t \t c. \u0007We have 95% confidence that the limits of 22.034 mm and \n22.133 mm contain the value of the population mean m.\n\t 4.\t 94\n\t 5.\t a. Student t distribution    b. Normal distribution\n\t\n\t c. \u0007None of the three distributions is appropriate, but a confidence \ninterval could be constructed by using bootstrap methods.\n\t\n\t d. x2 (chi-square distribution)\n\t \t e. Normal distribution\n\t 6.\t a. 1068    b. 234    c. 1068\n\t 7.\t 308.2 mg 6 m 6 355.4 mg. The confidence interval limits do \ncontain the desired amount of 325 mg, so the mean is not too \nbad, but examination of the individual amounts of aspirin shows \nthat some tablets have considerably more than the desired amount \nof 325 mg, while others have considerable less than that desired \namount. These tablets indicate a serious production problem that \nshould be corrected.\n\t 8.\t a. 26.3 mg 6 s 6 63.0 mg    b. 5 mg\n\t \t c. \u0007The desired s = 5 mg from part (b) is not contained within \nthe confidence interval from part (a). It appears that the cur-\nrent production method produces aspirin tablets with too much \nvariation, and that should be corrected.\n\t 9.\t Answers vary, but here is a typical result: \n310.6 mg 6 m 6 350.9 mg. The result is very close to the confi-\ndence interval found in Exercise 7.\n\t10.\t a. 0.0113 6 p 6 0.0287\n\t\n\t b. Answers vary, but here is a typical result: 0.0120 6 p 6 0.0290\n\t \t c. The confidence intervals are quite close.\n",
    "664\t\nAppendix D\n\t27.\t a.  Reject H0.\n\t \t b.  \u0007There is sufficient evidence to warrant rejection of the claim \nthat the mean pulse rate of adult males is 72 bpm.\n\t29.\t Type I error: In reality p = 0.1, but we reject the claim that \np = 0.1. Type II error: In reality p ≠0.1, but we fail to reject \nthe claim that p = 0.1.\n\t31.\t Type I error: In reality p = 0.87, but we support the claim that \np 7 0.87. Type II error: In reality p 7 0.87, but we fail to  \nsupport that conclusion.\n\t33.\t The power of 0.96 shows that there is a 96% chance of rejecting the \nnull hypothesis of p = 0.08 when the true proportion is actually \n0.18. That is, if the proportion of Chantix users who experience \nabdominal pain is actually 0.18, then there is a 96% chance of  \nsupporting the claim that the proportion of Chantix users who  \nexperience abdominal pain is greater than 0.08.\n\t35.\t 617\nSection 8-2 \n\t 1.\t a.  270\n\t \t b.  pn = 0.53\n\t 3.\t The method based on a confidence interval is not equivalent to \nthe P-value method and the critical value method.\n\t 5.\t a.  Left-tailed\n\t\n\t b.  z = -4.46\n\t\n\t c.  P-value: 0.000004\n\t\n\t d.  H0: p = 0.10. Reject the null hypothesis.\n\t \t e.  \u0007There is sufficient evidence to support the claim that fewer \nthan 10% of treated subjects experience headaches.\n\t 7.\t a.  Two-tailed\n\t\n\t b.  z = -1.36\n\t\n\t c.  P-value: 0.174\n\t\n\t d.  H0: p = 0.67. Fail to reject the null hypothesis.\n\t \t e.  \u0007There is not sufficient evidence to warrant rejection of the \nclaim that 67% of adults wash their hands after touching an \nanimal.\n\t 9.\t H0: p = 0.5. H1: p 7 0.5. Test statistic: z = 10.96. P-value: \n0.0000 (Table: 0.0001). Critical value: z = 2.33. Reject H0. There \nis sufficient evidence to support the claim that the YSORT method is \neffective in increasing the likelihood that a baby will be a boy.\n\t11.\t H0: p = 0.5. H1: p ≠0.5. Test statistic: z = 2.69. P-value: 0.0071 \n(Table: 0.0072). Critical values: z = {2.576 (Table: {2.575).  \nReject H0. There is sufficient evidence to reject the claim that the  \nproportion of those in favor is equal to 0.5. The result suggests that \nthe politician is wrong in claiming that the responses are random \nguesses equivalent to a coin toss.\n\t13.\t H0: p = 0.20. H1: p 7 0.20. Test statistic: z = 1.10.  \nP-value: 0.1367 (Table: 0.1357). Critical value: z = 1.645. Fail \nto reject H0. There is not sufficient evidence to support the claim \nthat more than 20% of OxyContin users develop nausea.  \nHowever, with pn = 0.229, we see that a large percentage of \nOxyContin users experience nausea, so that rate does appear to \nbe very high.\n\t15.\t H0: p = 0.15. H1: p 6 0.15. Test statistic: z = -1.31.  \nP-value = 0.0956 (Table: 0.0951). Critical value: z = -2.33. \nFail to reject H0. There is not sufficient evidence to support the \nclaim that the return rate is less than 15%.\n\t17.\t H0: p = 0.512. H1: p ≠0.512. Test statistic: z = -0.98.  \nP-value = 0.3286 (Table: 0.3270). Critical values: z = {1.96. \nFail to reject H0. There is not sufficient evidence to warrant  \nrejection of the claim that 51.2% of newborn babies are boys.  \nThe results do not support the belief that 51.2% of newborn \nbabies are boys; the results merely show that there is not strong \nevidence against the rate of 51.2%.\n\t19.\t H0: p = 0.5. H1: p ≠0.5. Test statistic: z = 0.98.  \nP-value: 0.3268 (Table: 0.3270). Critical values: z = {1.96.  \nFail to reject H0. There is not sufficient evidence to warrant rejec-\ntion of the claim that women who guess the gender of their babies \nhave a success rate equal to 50%.\n\t21.\t H0: p = 0.5. H1: p ≠0.5. Test statistic: z = -2.03.  \nP-value: 0.0422 (Table: 0.0424). Critical values: z = {1.645.  \nReject H0. There is sufficient evidence to warrant rejection of the \nclaim that touch therapists use a method equivalent to random \nguesses. However, their success rate of 123>280, or 43.9%, indi-\ncates that they performed worse than random guesses, so they do \nnot appear to be effective.\n\t23.\t H0: p = 0.000340. H1: p ≠0.000340. Test statistic: \nz = -0.66. P-value: 0.5122 (Table: 0.5092). Critical values: \nz = {2.81. Fail to reject H0. There is not sufficient evidence to \nsupport the claim that the rate is different from 0.0340%. Cell \nphone users should not be concerned about cancer of the brain  \nor nervous system.\n\t25.\t H0: p = 0.5. H1: p 7 0.5. Test statistic: z = 0.83.  \nP-value: 0.2031 (Table: 0.2033). Critical value: z = 1.645. Fail \nto reject H0. There is not sufficient evidence to support the claim \nthat among smokers who try to quit with nicotine patch therapy, \nthe majority are smoking a year after the treatment. The results \nshow that about half of those who use nicotine patch therapy are \nsuccessful in quitting smoking.\n\t27.\t H0: p = 0.80. H1: p ≠0.80. Test statistic: z = 0.98 (using \npn = 0.828) or z = 0.99 (using x = 164). If using pn = 0.828, \nP-value = 0.3246 (Table: 0.3270). If using x = 164,  \nP-value = 0.3198 (Table: 0.3222). Critical values: z = {2.576 \n(Table: {2.575). Fail to reject H0. There is not sufficient evi-\ndence to warrant rejection of the claim that 80% of patients stop \nsmoking when given sustained care. With a success rate around \n80%, it appears that sustained care is effective.\n\t29.\t Normal approximation entries: 0.0114, 0.0012, 0.0054. Exact \nentries: 0.0215, 0.0034, 0.0059. Exact with simple continuity \ncorrection: 0.0117, 0.0018, 0.0054. The P-values agree reason-\nably well with the large sample size of n = 1009. The normal \napproximation to the binomial distribution appears to work better \nas the sample size increases.\n\t31.\t a.  0.7219 (Table: 0.7224)\n\t\n\t b.  0.2781 (Table: 0.2776)\n\t \t c.  \u0007The power of 0.7219 shows that there is a reasonably good \nchance of making the correct decision of rejecting the false \nnull hypothesis. It would be better if the power were even \nhigher, such as greater than 0.8 or 0.9.\nSection 8-3 \n\t 1.\t The requirements are (1) the sample must be a simple random \nsample, and (2) either or both of these conditions must be satis-\n",
    "\t\nAppendix D\t\n665\n\t23.\t H0: m = 1000 hic. H1: m 6 1000 hic. Test statistic: t = -2.661. \nP-value = 0.0224 (Table: P-value is between 0.01 and 0.025). \nCritical value: t = -3.365. Fail to reject H0. There is not suf-\nficient evidence to support the claim that the population mean is \nless than 1000 hic. There is not strong evidence that the mean is \nless than 1000 hic, and one of the booster seats has a measure-\nment of 1210 hic, which does not satisfy the specified require-\nment of being less than 1000 hic.\n\t25.\t H0: m = 75 bpm. H1: m 6 75 bpm. Test statistic: t = -0.927. \nP-value = 0.1777 (Table: 70.10). Critical value: t = -1.655 \n(Table: -1.660 approximately). Fail to reject H0. There is not \nsufficient evidence to support the claim that the mean pulse rate \nof adult females is less than 75 bpm.\n\t27.\t H0: m = 90 mm Hg. H1: m 6 90 mm Hg. Test statistic: \nt = -21.435. P-value = 0.0000 (Table: 60.005). Critical value: \nt = -1.655 (Table: -1.660 approximately). Reject H0. There \nis sufficient evidence to support the claim that the adult female \npopulation has a mean diastolic blood pressure level less than  \n90 mm Hg. The conclusion addresses the mean of a population, \nnot individuals, so we cannot conclude that there are no female \nadults in the sample with hypertension.\n\t29.\t The computed critical t score is -1.6554, which is the same as \nthe value of -1.6554 found using Statdisk. The approximation \nappears to work quite well.\nSection 8-4 \n\t 1.\t The sample must be a simple random sample and the sample \nmust be from a normally distributed population. The normality \nrequirement for a hypothesis test of a claim about a standard \ndeviation is much stricter, meaning that the distribution of the \npopulation must be much closer to a normal distribution.\n\t 3.\t a.  Reject H0.\n\t\n\t b.  \u0007Reject the claim that the sample is from a population with a \nstandard deviation equal to 0.470 kg.\n\t \t c.  \u0007It appears that the vitamin supplement does affect the varia-\ntion among birth weights.\n\t 5.\t H0: s = 10 bpm. H1: s ≠10 bpm. Test statistic: \nx2 = 195.172. P-value = 0.0208. Reject H0. There is sufficient \nevidence to warrant rejection of the claim that pulse rates of men \nhave a standard deviation equal to 10 beats per minute. Using the \nrange rule of thumb with the normal range of 60 to 100 beats per \nminute is not very good for estimating s in this case.\n\t 7.\t H0: s = 2.08°F. H1: s 6 2.08oF. Test statistic: x2 = 9.329.  \nP-value = 0.0000 (Table: 60.005). Critical value : x2 = 74.252 \n(Table: 70.065 approximately). Reject H0. There is sufficient evi-\ndence to support the claim that body temperatures have a standard \ndeviation less than 2.08°F. It is very highly unlikely that the con-\nclusion in the hypothesis test in Example 5 from Section 8-3 would \nchange because of a standard deviation from a different sample.\n\t 9.\t H0: s = 15. H1: s 6 15. Test statistic: x2 = 6.963.  \nP-value = 0.0160 (Table: 60.025). Critical value: x2 = 8.672. \nReject H0. There is sufficient evidence to support the claim that \nIQ scores of physicians have a standard deviation less than 15.\n\t11.\t H0: s = 4.25 g. H1: s 6 4.25 g. Test statistic: x2 = 58.042.  \nP-value = 0.1545 (Table: 70.10). Critical value: x2 = 51.739. \nFail to reject H0. There is not sufficient evidence to support the \nfied: The population is normally distributed or n 7 30. There is \nnot enough information given to determine whether the sample is \na simple random sample. Because the sample size is not greater \nthan 30, we must check for normality, but the value of 583 sec \nappears to be an outlier, and a normal quantile plot or histogram \nsuggests that the sample does not appear to be from a normally \ndistributed population. The requirements are not satisfied.\n\t 3.\t A t test is a hypothesis test that uses the Student t distribution, \nsuch as the method of testing a claim about a population mean as \npresented in this section. The letter t is used in reference to the \nStudent t distribution, which is used in a t test.\n\t 5.\t P-value = 0.0437 (Table: 0.025 6 P-value 6 0.05).\n\t 7.\t P-value = 0.2581 (Table: 70.10)\n\t 9.\t H0: m = 98.6°F. H1: m ≠98.6°F. Test statistic: t = -3.865.  \nP-value: 0.0004. Critical values assuming a 0.05 significance \nlevel: t = {2.026. Reject H0. There is sufficient evidence to \nwarrant rejection of the claim that the mean body temperature is \nequal to 98.6°F.\n\t11.\t H0: m = 270. H1: m 6 270. Test statistic: t = -2.764.  \nP-value: 0.0032. Critical value assuming a 0.05 significance \nlevel: t = -1.655. Reject H0. There is sufficient evidence to  \nsupport the claim that the population of adult females has a mean \nplatelet count less than 270.\n\t13.\t H0: m = 3000 g. H1: m 7 3000 g. Test statistic: t = 0.752.  \nP-value = 0.2264 (Table: 70.10). Critical value: t = 2.345. Fail \nto reject H0. There is not sufficient evidence to support the claim that \nthe population of birth weights of females is greater than 3000 g.\n\t15.\t H0: m = 0. H1: m 7 0. Test statistic: t = 0.133.  \nP-value = 0.4472 (Table: 70.10). Critical value: t = 1.677 \n(Table: 1.676 approximately). Fail to reject H0. There is not suffi-\ncient evidence to support the claim that with garlic treatment, the \nmean change in LDL cholesterol is greater than 0. There is not \nsufficient evidence to support a claim that the garlic treatment is \neffective in reducing LDL cholesterol levels.\n\t17.\t H0: m = 0 lb. H1: m 7 0 lb. Test statistic: t = 3.872.  \nP-value = 0.0002 (Table: 60.005). Critical value: t = 2.426. \nReject H0. There is sufficient evidence to support the claim that \nthe mean weight loss is greater than 0. Although the diet appears \nto have statistical significance, it does not appear to have practical \nsignificance because the mean weight loss of only 3.0 lb does not \nseem to be worth the effort and cost.\n\t19.\t H0: m = 4.00. H1: m ≠4.00. Test statistic: t = -1.139.  \nP-value = 0.2554 (Table: 70.20). Critical values: t = {1.965 \n(Table: 1.966 approximately). Fail to reject H0. There is not  \nsufficient evidence to warrant rejection of the claim that the pop-\nulation of student course evaluations has a mean equal to 4.00. \nBecause the data are from the University of Texas at Austin, they \ndon’t necessarily apply to a larger population that extends beyond \nthat one institution.\n\t21.\t The sample data meet the loose requirement of having a normal \ndistribution. H0: m = 14 mg>g. H1: m 6 14 mg>g. Test  \nstatistic: t = -1.444. P-value = 0.0913 (Table: 70.05).  \nCritical value: t = -1.833. Fail to reject H0. There is not suffi-\ncient evidence to support the claim that the mean lead concentra-\ntion for all such medicines is less than 14 mg>g.\n",
    "666\t\nAppendix D\n(Table: 60.005). Critical value: t = -2.426. Reject H0. There \nis sufficient evidence to warrant rejection of the claim that the \nsample is from a population with a mean less than 5.4 million \ncells per microliter. The test deals with the distribution of sample \nmeans, not individual values, so the result does not suggest that \neach of the 40 males has a red blood cell count below 5.4 million \ncells per microliter.\n\t 4.\t H0: p = 0.204. H1: p ≠0.204. Test statistic: z = 0.76.  \nP-value: 0.4480 (Table: 0.4472). Critical values: z = {1.96. Fail \nto reject H0. There is not sufficient evidence to warrant rejection \nof the claim that the rate of smoking by adult males is now the \nsame as in 2008. The smoking rate appears to be about the same.\n\t 5.\t H0: m = 25 mg. H1: m ≠25 mg. Test statistic: t = -0.744.  \nP-value: 0.4694 (Table: 70.10). Critical values: t = {2.145. \nFail to reject H0. There is not sufficient evidence to warrant rejec-\ntion of the claim that the pills come from a population in which \nthe mean amount of atorvastatin is equal to 25 mg.\n\t 6.\t H0: m = 20.16. H1: m 6 20.16. Test statistic: t = -3.732.  \nP-value = 0.0023 (Table: 60.005). Critical value: t = -2.821. \nReject H0. There is sufficient evidence to support the claim that \nthe population of recent winners has a mean BMI less than 20.16. \nRecent winners appear to be significantly smaller than those from \nthe 1920s and 1930s.\n\t 7.\t H0: s = 1.34. H1: s ≠1.34. Test statistic: x2 = 7.053.  \nP-value = 0.7368 (Table: 70.20). Critical values: x2 = 1.735, \n23.589. Fail to reject H0. There is not sufficient evidence to  \nsupport the claim that the recent winners have BMI values with \nvariation different from that of the 1920s and 1930s.\n\t 8.\t a.  \u0007A type I error is the mistake of rejecting a null hypothesis \nwhen it is actually true. A type II error is the mistake of failing \nto reject a null hypothesis when in reality it is false.\n\t \t b.  \u0007Type I error: In reality, the mean BMI is equal to 20.16, but \nwe support the claim that the mean BMI is less than 20.16. \nType II error: In reality, the mean BMI is less than 20.16, but \nwe fail to support that claim.\nChapter 8: Cumulative Review Exercises\n\t 1.\t a.  37.1 deaths\t \t\nb.  36.0 deaths\n\t\n\t c.  9.8 deaths\t\n\t\nd.  96.8 deaths2\n\t\n\t e.  28.0 deaths\n\t \t f.  \u0007The pattern of the data over time is not revealed by the statis-\ntics. A time-series graph would be very helpful in understand-\ning the pattern over time.\n\t 2.\t a.  Ratio\t\n\t\nb.  Discrete\n\t\n\t c.  Quantitative\n\t \t d.  \u0007No. The data are from recent and consecutive years, so they \nare not randomly selected.\n\t 3.\t 29.1 deaths 6 m 6 45.0 deaths. We have 99% confidence that \nthe limits of 29.1 deaths and 45.0 deaths contain the value of the \npopulation mean.\n\t 4.\t H0: m = 72.6 deaths. H1: m 6 72.6 deaths. Test statistic: \nt = -13.509. P-value = 0.0000 (Table: 60.005). Critical value: \nt = -2.650. Reject H0. There is sufficient evidence to support \nthe claim that the mean number of annual lightning deaths is now \nless than the mean of 72.6 deaths from the 1980s. Possible fac-\ntors: Shift in population from rural to urban areas; better lightning \nclaim that the new process dispenses amounts with a standard \ndeviation less than the standard deviation of 4.25 g for the old \nprocess. The new process does not appear to be better in the sense \nof dispensing amounts that are more consistent.\n\t13.\t H0: s = 6.0 lb. H1: s ≠6.0 lb. Test statistic: x2 = 26.011.  \nP-value = 0.1101 (Table: 70.10). Critical values: x2 = 19.996, \n65.475 (Table: approximate critical values: 20.707, 66.766). Fail \nto reject H0. There is not sufficient evidence to warrant rejection \nof the claim that the amounts of weight loss have a standard  \ndeviation equal to 6.0 lb.\n\t15.\t H0: s = 109.3 sec. H1: s 6 109.3 sec. Test statistic: x2 = 0.616. \nP-value = 0.0001 (Table: 60.005). Critical value : x2 = 3.325. \nReject H0. There is sufficient evidence to support the claim that \nwith a single waiting line, the waiting times have a standard devia-\ntion less than 109.3 sec. Because the variation among waiting times \nappears to be reduced with the single waiting line, patients are \nhappier because their waiting times are closer to being the same. \nPatients are not annoyed by being stuck in an individual line that \ntakes much more time than other individual lines.\n\t17.\t Critical value: x2 = 81.540 (or 81.494 if using z = 2.326348 \nfound from technology), which is close to the value of 82.292 \nobtained from Statdisk and Minitab.\nChapter 8: Quick Quiz\n\t 1.\t a.  t distribution\t\n\t\nb.  Normal distribution\n\t \t c.  Chi-square distribution\n\t 2.\t a.  Two-tailed\t\n\t\nb.  Left-tailed\n\t \t c.  Right-tailed\n\t 3.\t a.  H0: p = 0.5. H1: p 7 0.5.\n\t\n\t b.  z = 1.39\n\t\n\t c.  Fail to reject H0.\n\t \t d.  \u0007There is not sufficient evidence to support the claim that the \nmajority of Internet users aged 18−29 use Instagram.\n\t 4.\t 0.0100\t\n5.  True\n\t 6.\t False\t\t\n7.  False\n\t 8.\t No. All critical values of x2 are always positive.\n\t 9.\t The t test requires that the sample is from a normally distributed \npopulation, and the test is robust in the sense that the test works \nreasonably well if the departure from normality is not too ex-\ntreme. The x2 (chi-square) test is not robust against a departure \nfrom normality, meaning that the test does not work well if the \npopulation has a distribution that is far from normal.\n\t10.\t The only true statement is the one given in part (a).\nChapter 8: Review Exercises\n\t 1.\t a.  False.\t\nb.  True.\n\t\n\t c.  False.\t\nd.  False.\n\t \t e.  False.\n\t 2.\t H0: p = 0.5. H1: p 7 0.5. Test statistic: z = 40.91 (using pn = 0.64) \nor z = 40.90 (using x =  13,661). P-value: 0.0000 (Table: 0.0001). \nCritical value: z = 2.33. Reject H0. There is sufficient evidence to \nsupport the claim that most people believe that the Loch Ness monster \nexists. Because the sample is a voluntary response sample, the con-\nclusion about the population might not be valid.\n\t 3.\t H0: m = 5.4 million cells per microliter. H1: m 6 5.4 million \ncells per microliter. Test statistic: t = -5.873. P-value: 0.0000 \n",
    "\t\nAppendix D\t\n667\nprotection and grounding in electric and cable and phone lines; \nbetter medical treatment of people struck by lightning; fewer \npeople use phones attached to cords; better weather predictions.\n\t 5.\t Because the vertical scale starts at 50 and not at 0, the difference \nbetween the number of males and the number of females is exag-\ngerated, so the graph is deceptive by creating the false impression \nthat males account for nearly all lightning strike deaths. A com-\nparison of the numbers of deaths shows that the number of male \ndeaths is roughly 4 times the number of female deaths, but the \ngraph makes it appear that the number of male deaths is around \n25 times the number of female deaths.\n\t 6.\t H0: p = 0.5. H1: p 7 0.5. Test statistic: z = 10.45.  \nP-value = 0.0000 (Table: 0.0001). Critical value: z = 2.33. \nReject H0. There is sufficient evidence to support the claim that \nthe proportion of male deaths is greater than 1>2. More males are \ninvolved in certain outdoor activities, such as construction, fish-\ning, and golf.\n\t 7.\t 0.763 6 p 6 0.854. Because the entire confidence interval is \ngreater than 0.5, it does not seem feasible that males and females \nhave equal chances of being killed by lightning.\n\t 8.\t a.  0.512\t\n\t\nb.  0.008\n\t\n\t c.  0.992\t\n\t\nd.  0.205\n\t\n\t e.  m = 40.0 males; s = 2.8 males\n\t \t f.  \u0007Yes. Using the range rule of thumb, significantly high values \nare m + 2s or greater. With m + 2s = 45.6, values above \n45.6 are significantly high, so 46 would be a significantly high \nnumber of male victims in a group of 50.\n\t 9.\t OR = 1.14. The odds in favor of experiencing migraine head-\naches is about 1.14 times higher for overweight people than for \npeople with normal weight.\nChapter 9 Answers\nSection 9-1 \n\t 1.\t The samples are simple random samples that are independent. \nFor each of the two groups, the number of successes is at least \n5 and the number of failures is at least 5. (Depending on what \nwe call a success, the four numbers are 33, 115, 201,196, and \n200,630 and all of those numbers are at least 5.) The require-\nments are satisfied.\n\t 3.\t a. H0: p1 = p2. H1: p1 6 p2.\n\t \t b. \u0007There is sufficient evidence to support the claim that the rate of \npolio is less for children given the Salk vaccine than for chil-\ndren given a placebo. The Salk vaccine appears to be effective.\n\t 5.\t H0: p1 = p2. H1: p1 7 p2. Test statistic: z = 12.82. ­ \nP-value: 0.0000. Critical value: z = 2.33. Reject H0. There is \nsufficient evidence to support the claim that vinyl gloves have a \ngreater virus leak rate than latex gloves.\n\t 7.\t a. \u0007H0: p1 = p2. H1: p1 6 p2. Test statistic: z = -1.66. \nP-value: 0.0484 (Table: 0.0485). Critical value: z = -2.33. \nFail to reject H0. There is not sufficient evidence to support the \nclaim that the rate of dementia among those who use ginkgo \nis less than the rate of dementia among those who use a pla-\ncebo. There is not sufficient evidence to support the claim that \nginkgo is effective in preventing dementia.\n\t\n\t b. \u000798% CI: -0.0541 6 p1 - p2 6 0.00904 (Table: -0.0542 6\np1 - p2 6 0.00909). Because the confidence interval limits \ninclude 0, there does not appear to be a significant difference \nbetween dementia rates for those treated with ginkgo and those \ngiven a placebo. There is not sufficient evidence to support the \nclaim that the rate of dementia among those who use ginkgo is \nless than the rate of dementia among those who use a placebo. \nThere is not sufficient evidence to support the claim that ginkgo \nis effective in preventing dementia.\n\t \t c. \u0007The sample results suggest that ginkgo is not effective in pre-\nventing dementia.\n\t 9.\t a. \u0007H0:p1 = p2. H1: p1 7 p2. Test statistic: z = 2.64. P-value: \n0.0041. Critical value: z = 2.33. Reject H0. There is sufficient \nevidence to support the claim that the rate of success for smok-\ning cessation is greater with the sustained care program.\n\t\n\t b. \u000798% CI: 0.0135 6 p1 - p2 6 0.200 (Table: 0.0134 6\np1 - p2 6 0.200). Because the confidence interval limits do \nnot contain 0, there is a significant difference between the two \nproportions. Because the interval consists of positive numbers \nonly, it appears that the success rate for the sustained care \nprogram is greater than the success rate for the standard care \nprogram.\n\t \t c. \u0007Based on the samples, the success rates of the programs are \n25.8% (sustained care) and 15.1% (standard care). That differ-\nence does appear to be substantial, so the difference between \nthe programs does appear to have practical significance.\n\t11.\t a. \u0007H0: p1 = p2. H1: p1 7 p2. Test statistic: z = 6.44. P-value \n= 0.0000 (Table: 0.0001). Critical value: z = 2.33. Reject \nH0. There is sufficient evidence to support the claim that the \nproportion of people over 55 who dream in black and white is \ngreater than the proportion of those under 25.\n\t\n\t b. \u000798% CI: 0.117 6 p1 - p2 6 0.240. Because the confidence \ninterval limits do not include 0, it appears that the two propor-\ntions are not equal. Because the confidence interval limits \ninclude only positive values, it appears that the proportion of \npeople over 55 who dream in black and white is greater than \nthe proportion of those under 25.\n\t \t c. \u0007The results suggest that the proportion of people over 55 who \ndream in black and white is greater than the proportion of \nthose under 25, but the results cannot be used to verify the \ncause of that difference.\n\t13.\t a. \u0007H0: p1 = p2. H1: p1 7 p2. Test statistic: z = 6.11. P-value =\n0.0000 (Table: 0.0001). Critical value: z = 1.645. Reject H0. \nThere is sufficient evidence to support the claim that the fatal-\nity rate is higher for those not wearing seat belts.\n\t\n\t b. \u000790% CI: 0.00559 6 p1 - p2 6 0.0123. Because the confi-\ndence interval limits do not include 0, it appears that the two \nfatality rates are not equal. Because the confidence interval \nlimits include only positive values, it appears that the fatality \nrate is higher for those not wearing seat belts.\n\t \t c. \u0007The results suggest that the use of seat belts is associated with \nfatality rates lower than those associated with not using seat \nbelts.\n\t15.\t a. \u0007H0: p1 = p2. H1: p1 ≠p2. Test statistic: z = 0.57.  \nP-value: 0.5720 (Table: 0.5686). Critical values: z = {1.96. \nFail to reject H0. There is not sufficient evidence to support the \nclaim that echinacea treatment has an effect.\n\t\n\t b. \u000795% CI: -0.0798 6 p1 - p2 6 0.149. Because the confi-\ndence interval limits do contain 0, there is not a significant \n",
    "668\t\nAppendix D\ndifference between the two proportions. There is not sufficient \nevidence to support the claim that echinacea treatment has an \neffect.\n\t \t c. \u0007Echinacea does not appear to have a significant effect on the \ninfection rate. Because it does not appear to have an effect, it \nshould not be recommended.\n\t17.\t a. \u0007H0: p1 = p2. H1: p1 6 p2. Test statistic: z = -7.94.  \nP-value: 0.0000 (Table: 0.0001). Critical value: z = -2.33. \nReject H0. There is sufficient evidence to support the claim that \nthe rate of right-handedness for those who prefer to use their \nleft ear for cell phones is less than the rate of right-handedness \nfor those who prefer to use their right ear for cell phones.\n\t \t b. \u000798% CI: -0.266 6 p 6 -0.126. Because the confidence \ninterval limits do not contain 0, there is a significant difference \nbetween the two proportions. Because the interval consists of \nnegative numbers only, it appears that the claim is supported.\n\t19.\t a. \u0007H0: p1 = p2. H1: p1 7 p2. Test statistic: z = 9.97.  \nP-value = 0.0000 (Table: 0.0001). Critical value: z = 2.33. \nReject H0. There is sufficient evidence to support the claim that \nthe cure rate with oxygen treatment is higher than the cure rate \nfor those given a placebo. It appears that the oxygen treatment \nis effective.\n\t\n\t b. \u000798% CI: 0.467 6 p1 - p2 6 0.687. Because the confidence \ninterval limits do not include 0, it appears that the two cure \nrates are not equal. Because the confidence interval limits \ninclude only positive values, it appears that the cure rate with \noxygen treatment is higher than the cure rate for those given a \nplacebo. It appears that the oxygen treatment is effective.\n\t \t c. \u0007The results suggest that the oxygen treatment is effective in \ncuring cluster headaches.\n\t21.\t a. \u0007H0: p1 = p2. H1: p1 6 p2. Test statistic: z = -1.17.  \nP-value = 0.1214 (Table: 0.1210). Critical value: z = -2.33.  \nFail to reject H0. There is not sufficient evidence to support the \nclaim that the rate of left-handedness among males is less than \nthat among females.\n\t\n\t b. \u000798% CI: -0.0848 6 p1 - p2 6 0.0264 (Table: -0.0849 6\np1 - p2 6 0.0265). Because the confidence interval limits \ninclude 0, there does not appear to be a significant difference \nbetween the rate of left-handedness among males and the rate \namong females. There is not sufficient evidence to support the \nclaim that the rate of left-handedness among males is less than \nthat among females.\n\t \t c. \u0007The rate of left-handedness among males does not appear to be \nless than the rate of left-handedness among females.\n\t23.\t The samples should include 2135 men and 2135 women.\n\t25.\t a. \u00070.0227 6 p1 - p2 6 0.217; because the confidence interval \nlimits do not contain 0, it appears that p1 = p2 can be rejected.\n\t\n\t b. \u00070.491 6 p1 6 0.629; 0.371 6 p2 6 0.509; because the con-\nfidence intervals do overlap, it appears that p1 = p2 cannot be \nrejected.\n\t\n\t c. \u0007H0: p1 = p2. H1: p1 ≠p2. Test statistic: z = 2.40.  \nP-value: 0.0164. Critical values: z = {1.96. Reject H0. There \nis sufficient evidence to reject p1 = p2.\n\t \t d. \u0007Reject p1 = p2. Least effective method: Using the overlap \n­between the individual confidence intervals.\nSection 9-2 \n\t 1.\t Only part (c) describes independent samples.\n\t 3.\t a. Yes    b. Yes    c. 98%\n\t 5.\t H0: m1 = m2. H1: m1 ≠m2. Test statistic: t = - 0.452. Criti-\ncal values: t = {1.987 (Table: t = {2.014). P-value: 0.6521 \n(Table: 70.20). Fail to reject H0. There is not sufficient evidence \nto warrant rejection of the claim that the two groups are from \npopulations with the same mean. This result suggests that the in-\ncreased humidity does not help in the treatment of croup.\n\t 7.\t a. \u0007H0: m1 = m2. H1: m1 6 m2. Test statistic: t = -2.908.  \nP-value = 0.0019 (Table: 60.005). Critical value: t = -1.649 \n(Table: -1.653 approximately). Reject H0. There is sufficient \nevidence to support the claim that the children exposed to co-\ncaine have a lower mean score.\n\t \t b. \u000790% CI: -1.4 6 m1 - m2 6 -0.4. Because the confidence \ninterval consists of negative numbers only, there is sufficient \nevidence to support the claim that the children exposed to co-\ncaine have a lower mean score.\n\t 9.\t a. \u0007H0: m1 = m2. H1: m1 7 m2. Test statistic: t = 8.075.  \nP-value = 0.0000 (Table: 60.005). Critical value: t = 1.678 \n(Table: t = 1.711). Reject H0. There is sufficient evidence \nto support the claim that unfiltered king-size cigarettes have \na mean tar content greater than that of filtered 100-mm ciga-\nrettes. The result suggests that the filters are effective in reduc-\ning the tar content, assuming that both types of cigarettes are \nabout the same size.\n\t \t b. \u000790% CI: 6.3 mg 6 m1 - m2 6 9.5 mg (Table: 6.2 mg 6\nm1 - m2 6 9.6 mg). The confidence interval limits include \npositive numbers only, which suggests that the mean tar con-\ntent of unfiltered king-size cigarettes is greater than the mean \nfor filtered 100-mm cigarettes.\n\t11.\t a. \u0007H0: m1 = m2. H1: m1 ≠m2. Test statistic: t = 5.045. P-value =\n0.0000 (Table: 60.01). Critical values: t = {2.058  \n(Table: {2.080). Reject H0. There is sufficient evidence to \nsupport the claim that there is a significant difference between \nthe treatment group and control group. We cannot conclude \nthat the cause is due to the treatment.\n\t \t b. \u000795% CI:1.47 6 m1 - m2 6 3.51 (Table: 1.46 6\nm1 - m2 6 3.52). Because the confidence interval does not \ncontain zero, there appears to be a significant difference be-\ntween the two population means. It does appear that there are \nsignificantly more errors made by those treated with alcohol.\n\t13.\t a. \u0007H0: m1 = m2. H1: m1 7 m2. Test statistic: t = 1.845.  \nP-value = 0.0352 (Table: 60.05). Critical value: t = 1.673 \n(Table 1.685). Reject H0. There is sufficient evidence to sup-\nport the claim that nonsmokers exposed to tobacco smoke have \na higher mean cotinine level than nonsmokers not exposed to \ntobacco smoke.\n\t\n\t b. \u000790% CI: 4.12 ng>mL 6 (m1 - m2) 6 84.34 ng>mL  \n(Table: 3.85 ng>mL 6 (m1 - m2) 6 84.61 ng>mL).\n\t \t c. \u0007Exposure to second-hand smoke appears to have the effect \nof being associated with greater amounts of nicotine than for \nthose not exposed to second-hand smoke.\n\t15.\t a. \u0007H0: m1 = m2. H1: m1 7 m2. Test statistic: t = 2.282.  \nP-value = 0.0132 (Table: 60.05). Critical value: t = 1.673 \n",
    "\t\nAppendix D\t\n669\n\t 7.\t a. \u0007H0: md = 0°F. H1: md ≠0°F. Test statistic: t = -7.499.  \nP-value = 0.0003 (Table: 60.01). Critical values: \nt = {2.447. Reject H0. There is sufficient evidence to warrant \nrejection of the claim that there is no difference between body \ntemperatures measured at 8 AM and at 12 AM. There appears \nto be a difference.\n\t \t b. \u000795% CI: -1.97°F 6 md 6 -1.00°F. The confidence interval \nconsists of negative numbers only and does not include 0.\n\t 9.\t H0: md = 0 in. H1: md ≠0 in. Test statistic: t = -1.379.  \nP-value = 0.2013 (Table: 70.20). Critical values: t = {2.262. \nFail to reject H0. There is not sufficient evidence to warrant rejec-\ntion of the claim that there is no difference in heights between \nmothers and their first daughters.\n\t11.\t -6.5 admissions 6 md 6 -0.2 admissions. Because the confi-\ndence interval does not include 0 admissions, it appears that there \nis sufficient evidence to warrant rejection of the claim that when \nthe 13th day of a month falls on a Friday, the numbers of hospital \nadmissions from motor vehicle crashes are not affected. Hospital \nadmissions do appear to be affected.\n\t13.\t -66.7 cm3 6 md 6 49.7 cm3 (Table: -66.8 cm3 6 md 6\n49.8 cm3). Because the confidence interval includes 0 cm3, the \nmean of the differences could be equal to 0 cm3, so there does not \nappear to be a significant difference.\n\t15.\t -4.16 in. 6 md 6 2.16 in. Because the confidence interval limits \ncontain 0, there is not sufficient evidence to support a claim that \nthere is a difference between self-reported heights and measured \nheights. We might believe that males would tend to exaggerate \ntheir heights, but the given data do not provide enough evidence \nto support that belief.\n\t17.\t a. \u0007H0: md = 0°F. H1: md ≠0°F. Test statistic: t = -8.485.  \nP-value = 0.0000 (Table: 60.01). Critical values: \nt = {1.996 (Table: {1.994). Reject H0. There is sufficient \nevidence to warrant rejection of the claim of no difference \nbetween body temperatures measured at 8 AM and at 12 AM. \nThere appears to be a difference.\n\t \t b. \u000795% CI: -1.05°F 6 md 6 -0.65°F. The confidence interval \nconsists of negative numbers only and does not include 0.\n\t19.\t H0: md = 0 in. H1: md ≠0 in. Test statistic: t = -6.347.  \nP-value = 0.0000 (Table: 60.01). Critical values: t = {1.978 \n(Table: {1.984 approximately). Reject H0. There is sufficient \nevidence to warrant rejection of the claim of no difference in \nheights between fathers and their first sons.\n\t21.\t For the temperatures in degrees Fahrenheit and the temperatures \nin degrees Celsius, the test statistic (t = 0.124) is the same, the \nP-value of 0.9023 is the same, the critical values (t = {2.028) \nare the same, and the conclusions are the same, so the hypothesis \ntest results are the same in both cases. The confidence intervals \nare -0.25°F 6 md 6 0.28°F and -0.14°C 6 md 6 0.16°C. The \nconfidence interval limits of -0.14°C and 0.16°C have numeri-\ncal values that are 5>9 of the numerical values of -0.25°F and \n0.28°F.\nSection 9-4 \n\t 1.\t a. \u0007No    b. No    c. The two samples have standard deviations \n(or variances) that are very close in value.    d. Skewed right\n(Table: 1.725). Reject H0. There is sufficient evidence to sup-\nport the claim that the mean IQ score of people with low blood \nlead levels is higher than the mean IQ score of people with \nhigh blood lead levels.\n\t\n\t b. \u000790% CI: 1.6 6 m1 - m2 6 10.4  \n(Table: 1.5 6 m1 - m2 6 10.5)\n\t \t c. \u0007Yes, it does appear that exposure to lead has an effect on \nIQ scores.\n\t17.\t a. \u0007H0: m1 = m2. H1: m1 ≠m2. Test statistic: t = 0.462.  \nP-value = 0.6465 (Table: 70.20). Critical values: \nt = {2.012 (Table: {2.120). Fail to reject H0. There is not \nsufficient evidence to warrant rejection of the claim that Dis-\nney animated children’s movies and other animated children’s \nmovies have the same mean time showing tobacco use.\n\t\n\t b. \u000795% CI: -41.3 sec 6 (m1 - m2) 6 65.9 sec  \n(Table: -44.2 sec 6 (m1 - m2) 6 68.8 sec)\n\t \t c. \u0007The times appear to be from a population with a distribution \nthat is not normal, but the methods in this section are robust \nagainst departures from normality. (Results obtained by using \nother methods confirm that the results obtained here are quite \ngood, even though the non-Disney times appear to violate the \nnormality requirement.)\n\t19.\t a. \u0007H0: m1 = m2. H1: m1 6 m2. Test statistic: t = -1.810. \nP-value = 0.0442 (Table: 70.025). Critical value: \nt = -2.574 (Table: -2.650). Fail to reject H0. There is not \nsufficient evidence to support the claim that the mean longev-\nity for popes is less than the mean for British monarchs after \ncoronation.\n\t \t b. \u000798% CI: -23.6 years 6 m1 - m2 6 4.0 years  \n(Table: -23.6 years 6 m1 - m2 6 4.4 years)\n\t21.\t H0: m1 = m2. H1: m1 ≠m2. Test statistic: t = -0.863.  \nP-value = 0.3887 (Table:70.20). Critical values are \nt = {1.968 (Table: {1.984). Fail to reject H0. There is not suf-\nficient evidence to warrant rejection of the claim that women and \nmen have the same mean diastolic blood pressure.\n\t23.\t With pooling, df increases dramatically to 97, but the test sta-\ntistic decreases from 2.282 to 1.705 (because the estimated \nstandard deviation increases from 2.620268 to 3.507614), the \nP-value increases to 0.0457, and the 90% confidence interval \nbecomes wider. With pooling, these results do not show greater \n­significance.\n\t25.\t H0: m1 = m2. H1: m1 ≠m2. Test statistic: t = 15.322.  \nP-value = 0.0000 (Table: 60.01). Critical values: t = {2.080. \nReject H0. There is sufficient evidence to warrant rejection of the \nclaim that the two populations have the same mean.\nSection 9-3 \n\t 1.\t Only parts (a) and (c) are true.\n\t 3.\t The results will be the same.\n\t 5.\t H0: md = 0. H1: md ≠0. Test statistic: t = -17.339.  \nP-value: 0.0001 (Table: 60.01). Critical values: t = {4.604. \nReject H0. There is sufficient evidence to support the claim of a \ndifference in measurements between the two arms. The right and \nleft arms should yield the same measurements, but the given data \nshow that this is not happening for this person.\n",
    "670\t\nAppendix D\n\t 5.\t Fail to reject H0. There is not sufficient evidence to warrant rejec-\ntion of the claim that for the people who were aware of the state-\nment, the proportion of women is equal to the proportion of men.\n\t 6.\t True\n\t 7.\t False\n\t 8.\t Because the data consist of matched pairs, they are dependent.\n\t 9.\t H0: md = 0. H1: md ≠0.\n\t10.\t a. t = d - md\nsd\n2n\n    b. t = (x1 - x2) - (m1 - m2)\nB\ns2\n1\nn1\n+ s2\n2\nn2\n\t\n\t c. z = (pn1 - pn2) - (p1 - p2)\nA\np q\nn1\n+ p q\nn2\n    d. F = s 2\n1\ns 2\n2\nChapter 9: Review Exercises\n\t 1.\t H0: p1 = p2. H1: p1 ≠p2. Test statistic: z = -4.20.  \nP-value: 0.0000 (Table: 0.0002). Critical values: z = {2.576 \n(Table: {2.575). Reject H0. There is sufficient evidence to war-\nrant rejection of the claim that the acceptance rate is the same \nwith or without blinding. Without blinding, reviewers know the \nnames and institutions of the abstract authors, and they might be \ninfluenced by that knowledge.\n\t 2.\t  -0.0372 6 p1 - p2 6 -0.00892. The confidence interval lim-\nits do not contain 0, so it appears that there is a significant differ-\nence between the two proportions.\n\t 3.\t  -25.33 cm 6 (m1 - m2) 6 -7.51 cm (Table: -25.70 cm 6 \n(m1 - m2) 6 -7.14 cm). With 95% confidence, we conclude \nthat the mean height of women is less than the mean height of \nmen by an amount that is between 7.51 cm and 25.33 cm  \n(Table: 7.14 cm and 25.70 cm).\n\t 4.\t H0: m1 = m2. H1: m1 6 m2. Test statistic: t = -4.001.  \nP-value: 0.0008 (Table: 60.005). Critical value: -2.666  \n(Table: -2.821). Reject H0. There is sufficient evidence to sup-\nport the claim that women have heights with a mean that is less \nthan the mean height of men.\n\t 5.\t a. \u0007H0: md = 0 kg. H1: md ≠0 kg. Test statistic: t = 2.301.  \nP-value: 0.0469. Critical values: t = {2.262 (assuming a 0.05 \nsignificance level). Reject H0 (assuming a 0.05 significance \nlevel). There is sufficient evidence to conclude that there is a \ndifference between pre-training and post-training weights.\n\t \t b. 0.0 kg 6 md 6 4.0 kg\n\t 6.\t H0: s1 = s2. H1: s1 ≠s2. Test statistic: F =  4.9933. P-value: \n0.0252. Upper critical F value: 4.0260. Reject H0. There is suf-\nficient evidence to warrant rejection of the claim that women and \nmen have heights with the same variation.\nChapter 9: Cumulative Review Exercises\n\t 1.\t a. \u0007Because the sample data are matched with each column con-\nsisting of heights from the same family, the data are dependent.\n\t\n\t b. \u0007x = 69.7 in.; median = 71.0 in.; range = 7.7 in.; s = 2.6 in.; \ns2 = 6.6 in2\n\t\n\t c. Ratio    d. Continuous\n\t 3.\t No. Unlike some other tests that have a requirement that samples \nmust be from normally distributed populations or the samples \nmust have more than 30 values, the F test has a requirement that \nthe samples must be from normally distributed populations, re-\ngardless of how large the samples are.\n\t 5.\t H0: s1 = s2. H1: s1 7 s2. Test statistic: F = 9.3364. P-value: \n0.0000. Critical F value: 2.0842 (Table: Critical F value is be-\ntween 2.0540 and 2.0960). Reject H0. There is sufficient evidence \nto support the claim that the treatment group has errors that vary \nmore than the errors of the placebo group.\n\t 7.\t H0: s1 = s2. H1: s1 ≠s2. Test statistic: F = 1.7778. P-value: \n0.0762. Upper critical F value: 1.8907 (Table: Critical F value is \nbetween 1.8752 and 2.0739). Fail to reject H0. There is not suffi-\ncient evidence to warrant rejection of the claim that subjects from \nboth treatment groups have ages with the same amount of varia-\ntion. If treatment groups have different characteristics, compari-\nsons of treatments become unclear, because differences might be \ndue to the treatments or they might be due to the different group \ncharacteristics.\n\t 9.\t H0: s1 = s2. H1: s1 7 s2. Test statistic: F = 2.1267.  \nP-value: 0.0543. Critical F value: 2.1682 (Table: Critical F value \nis between 2.1555 and 2.2341). Fail to reject H0. There is not \nsufficient evidence to support the claim that those given a sham \ntreatment have pain reductions that vary more than the pain \n­reductions for those treated with magnets.\n\t11.\t H0: s1 = s2. H1: s1 7 s2. Test statistic: F = 3.7539. P-value: \n0.0400. Critical F value: 3.4445. Reject H0. There is sufficient \nevidence to support the claim that king-size cigarettes with filters \nhave amounts of nicotine that vary more than the amounts of \nnicotine in non-filtered king-size cigarettes.\n\t13.\t H0: s1 = s2. H1: s1 7 s2. Test statistic: F = 1.8184.  \nP-value: 0.0774. Critical F value: 1.9983 (Table: Critical F value \nis ­between 1.9926 and 2.0772). Fail to reject H0. There is not \n­sufficient evidence to support the claim that men have body tem-\nperatures that vary more than the body temperatures of women.\n\t15.\t H0: s1 = s2. H1: s1 ≠s2. Test statistic: F = 4.3103.  \nP-value: 0.0023. Upper critical F value: 2.5308 (Table: Critical \nF value is between 2.4665 and 2.5699). Reject H0. There is suffi-\ncient evidence to warrant rejection of the claim that both popula-\ntions of longevity times have the same variation.\n\t17.\t c1 = 3, c2 = 0, critical value is 7.4569. Fail to reject H0. There \nis not sufficient evidence to support a claim that the two popula-\ntions of scores have different amounts of variation.\n\t19.\t FL = 0.4103; FR = 2.7006\nChapter 9: Quick Quiz\n\t 1.\t H0: p1 = p2. H1: p1 ≠p2.\n\t 2.\t x1 = 258, x2 = 282, pn1 = 258>1121 = 0.230, \npn2 = 282>1084 = 0.260, p = 0.245.\n\t 3.\t 0.1010\n\t 4.\t a. -0.0659 6 p1 - p2 6 0.00591\n\t \t b. \u0007The confidence interval includes the value of 0, so it is pos-\nsible that the two proportions are equal. There is not a signifi-\ncant difference.\n",
    "\t\nAppendix D\t\n671\n\t 9.\t H0: m1 = m2. H1: m1 ≠m2. Test statistic: t = -3.259.  \nP-value = 0.0019 (Table: 60.005). Critical values: t = {2.664 \n(Table: {2.724). Reject H0. There is sufficient evidence to war-\nrant rejection of the claim that males and females have the same \nmean braking reaction time. Males appear to have lower reaction \ntimes.\n\t10.\t a. \u0007Males: 40.1 6 m 6 48.7. Females: 47.2 6 m 6 61.4. The \nconfidence intervals overlap, so there does not appear to be a \nsignificant difference between the mean braking reaction times \nof males and females.\n\t\n\t b. \u0007-18.0 6 m1 - m2 6 -1.8  \n(Table: -18.2 6 m1 - m2 6 -1.6). Because the confidence \ninterval consists of negative numbers and does not include 0, \nthere appears to be a significant difference between the mean \nbraking reaction times of males and females.\n\t\n\t c. The results from part (b) are better.\nChapter 10 Answers\nSection 10-1\n\t 1.\t a. \u0007r is a statistic that represents the value of the linear correlation \ncoefficient computed from the paired sample data, and r is a \nparameter that represents the value of the linear correlation co-\nefficient that would be computed by using all of the paired data \nin the population of all statistics students.\n\t\n\t b. \u0007The value of r is estimated to be 0, because it is likely that \nthere is no correlation between body temperature and head \n­circumference.\n\t \t c. \u0007The value of r does not change if the body temperatures are \nconverted to Fahrenheit degrees.\n\t 3.\t No. A correlation between two variables indicates that they are \nsomehow associated, but that association does not necessarily \nimply that one of the variables has a direct effect on the other \nvariable. Correlation does not imply causality.\n\t 5.\t Yes. r = 0.963. P-value = 0.000. Critical values: {0.268 \n(Table: {0.279 approximately). There is sufficient evidence to \nsupport the claim that there is a linear correlation between the \nweights of bears and their chest sizes. It is easier to measure the \nchest size of a bear than the weight, which would require lifting \nthe bear onto a scale. It does appear that chest size could be used \nto predict weight.\n\t 7.\t Yes. r = 0.552. P-value 60.0001. Critical values are approxi-\nmately -0.196 and 0.196. There is sufficient evidence to support \nthe claim that there is a linear correlation between the heights of \nfathers and the heights of their sons.\n\t 9.\t a.\n\t 2.\t There does not appear to be a correlation or association between \nthe heights of fathers and the heights of their sons.\n\t 3.\t 67.6 in. 6 m 6 71.9 in. We have 95% confidence that the limits \nof 67.6 in. and 71.9 in. actually contain the true value of the mean \nheight of all adult sons.\n\t 4.\t H0: md = 0 in. H1: md ≠0 in. Test statistic: t = -1.712.  \nP-value = 0.1326 (Table: 70.10). Critical values: t = {2.365. \nFail to reject H0. There is not sufficient evidence to warrant rejec-\ntion of the claim that differences between heights of fathers and \ntheir sons have a mean of 0. There does not appear to be a differ-\nence between heights of fathers and their sons.\n\t 5.\t Because the points lie reasonably close to a straight-line pattern, \nand there is no other pattern that is not a straight-line pattern and \nthere are no outliers, the sample data appear to be from a popula-\ntion with a normal distribution.\n\t 6.\t The shape of the histogram indicates that the sample data appear \nto be from a population with a distribution that is approximately \nnormal.\n\t 7.\t Because the points are reasonably close to a straight-line pattern \nand there is no other pattern that is not a straight-line pattern, \nit appears that the braking reaction times of females are from a \npopulation with a normal distribution.\n\t 8.\t Because the boxplots overlap, there does not appear to be a sig-\nnificant difference between braking reaction times of males and \nfemales, but the braking reaction times for males appear to be \ngenerally lower than the braking reaction times of females.\n",
    "672\t\nAppendix D\n\t\n\t b. \u0007r = 0.816. P-value = 0.002 (Table: 60.01). Critical values: \nr = {0.602 assuming a 0.05 significance level. There is suf-\nficient evidence to support the claim of a linear correlation \nbetween the two variables.\n\t \t c. \u0007The scatterplot reveals a distinct pattern that is not a straight-\nline pattern.\n\t11.\t a. \u0007Answer varies. Because there appears to be an upward pattern, \nit is reasonable to think that there is a linear correlation.\n\t\n\t b. \u0007r = 0.906. P-value = 0.000 (Table: 60.01). Critical values: \nr = {0.632 (for a 0.05 significance level). There is sufficient \nevidence to support the claim of a linear correlation.\n\t\n\t c. \u0007r = 0. P-value = 1.000 (Table: 70.05). Critical values: \nr = {0.666 (for a 0.05 significance level). There is not suf-\nficient evidence to support the claim of a linear correlation.\n\t \t d. \u0007The effect from a single pair of values can be very substantial, \nand it can change the conclusion.\n\t13.\t r = 0.441. P-value = 0.174 (Table: 70.05). Critical values: \nr = {0.602. There is not sufficient evidence to support the \nclaim that there is a linear correlation between IQ scores and \nbrain volumes. It does not appear that people with larger brains \nhave higher IQ scores.\n\t15.\t r = 0.591. P-value = 0.294 (Table: 70.05). Critical values: \nr = {0.878. There is not sufficient evidence to support the \nclaim that there is a linear correlation between shoe print lengths \nand heights of males. The given results do not suggest that police \ncan use a shoe print length to estimate the height of a male.\n\t17.\t r = -0.959. P-value = 0.010. Critical values: r = {0.878. \nThere is sufficient evidence to support the claim that there is \na linear correlation between weights of lemon imports from \nMexico and U.S. car fatality rates. The results do not suggest any \ncause-effect relationship between the two variables.\n\t19.\t r = 0.028. P-value = 0.932 (Table: 70.05). Critical values: \nr = {0.576. There is not sufficient evidence to support the \nclaim that there is a linear correlation between pulse rates and \nsystolic blood pressures of adult females.\n\t21.\t r = 0.948. P-value = 0.004 (Table: 60.01). Critical values: \nr = {0.811. There is sufficient evidence to support the claim \nof a linear correlation between the overhead width of a seal in a \nphotograph and the weight of a seal.\n\t23.\t r = 0.113. P-value = 0.700 (Table: 70.05). Critical values: \nr = {0.532. There is not sufficient evidence to support the \nclaim that there is a linear correlation between heights of win-\nning presidential candidates and heights of their main opponents. \nIn an ideal world, voters would focus on important issues and not \nheight or physical appearance of candidates, so there should not \nbe a correlation.\n\t25.\t r = -0.063. P-value = 0.791 (Table: 70.05). Critical values: \nr = {0.444. There is not sufficient evidence to support the \nclaim that there is a linear correlation between IQ scores and \nbrain volumes.\n\t27.\t r = 0.594. P-value =  0.007 (Table: 60.01). Critical values: \nr = {0.456. There is sufficient evidence to support the claim \nthat there is a linear correlation between shoe print lengths and \nheights of males. The given results do suggest that police can use \na shoe print length to estimate the height of a male.\n\t29.\t r = -0.16217. (In this exercise, extra decimal places are needed \nfor r and the P-value. Table A-6  is not adequate to determine the \ncritical values and P-value for this exercise.) P-value = 0.0497. \nCritical values: r = {0.16197. There is sufficient evidence to \nsupport the claim that there is a linear correlation between pulse \nrates and systolic blood pressures of adult females.\n\t31.\t r = 0.748. (Table A-6 is not adequate to determine the critical \nvalues and P-value for this exercise.) P-value = 0.000. Critical \nvalues: {0.105. There is sufficient evidence to support the claim \nthat there is a linear correlation between right ear threshold mea-\nsurements and left ear threshold measurements.\n\t33.\t a. 0.911    b. 0.787    c. 0.9999 (largest)\n\t\n\t d. 0.976    e. -0.948 \nSection 10-2 \n\t 1.\t a. yn = 98.3 - 0.001x\n\t \t b. yn represents a predicted value of temperature.\n\t 3.\t a. \u0007A residual is a value of y - yn, which is the difference between \nan observed value of y and a predicted value of y.\n\t \t b. \u0007The regression line has the property that the sum of squares of \nthe residuals is the lowest possible sum.\n\t 5.\t With no significant linear correlation, the best predicted value is \ny = 161.69 cm.\n\t 7.\t With a significant linear correlation, the best predicted value is \n92.0 kg.\n\t 9.\t yn =  3.00 + 0.500x. The data have a pattern that is not a straight \nline.\n\t11.\t a. yn = 0.264 + 0.906x\n\t\n\t b. \u0007yn = 2 + 0x (or yn = 2)\n\t \t c. \u0007The results are very different, indicating that one point can dra-\nmatically affect the regression equation.\n\t13.\t yn = 44.9 + 0.0488x. Best predicted value: y = 99.0.\n\t15.\t yn = 125 + 1.73x. Best predicted value: y = 177.30 cm. \n­Because the best predicted value is the mean height, it would not \nbe helpful to police in trying to obtain a description of the male.\n\t17.\t yn = 16.5 - 0.00282x. Best predicted value: 15.1 fatalities per \n100,000 population. Common sense suggests that the prediction \ndoesn’t make much sense.\n\t19.\t yn = 117 + 0.0458x. Best predicted value: 121.0 mm Hg.\n\t21.\t yn = -157 + 40.2x. Best predicted value: -76.6 kg. The predic-\ntion is a negative weight that cannot be correct. The overhead \nwidth of 2 cm is well beyond the scope of the sample widths, so \nthe extrapolation might be off by a considerable amount. Clearly, \nthe predicted negative weight makes no sense.\n\t23.\t yn = 162 + 0.0975x. Best predicted height: y = 179.7 cm. \nHeights of opponents do not appear to be predicted well by using \nthe heights of the presidents.\n\t25.\t yn = 109 - 0.00670x. Best predicted value: y = 101.0.\n\t27.\t yn = 93.5 + 2.85x. Best predicted value: 182.7 cm. Although \nthere is a linear correlation, with r = 0.594, we see that it is not \nvery strong, so an estimate of the height of a male might be off \nby a considerable amount.\n\t29.\t yn = 138 - 0.223x. Best predicted value: 120 mm Hg.\n\t31.\t yn = 4.67 + 0.758x. Best predicted value: 19.8.\n\t33.\t a. 12.28\n\t \t b. \u0007The sum of squares of the residuals is 15.71, which is larger \nthan 12.28.\n",
    "\t\nAppendix D\t\n673\nmonoxide. It is best because it has the highest adjusted R2 value \nof 0.927 and the lowest P-value of 0.000. It is a good regression \nequation for predicting nicotine content because it has a high \nvalue of adjusted R2 and a low P-value.\n\t15.\t There are three possible regression equations corresponding to \npredictor variables of (1) brain volume; (2) body weight; (3) \nbrain volume and body weight. The best regression equation is \nyn = 109 - 0.00670x1, where x1 represents brain volume. It is \nbest because it has the highest adjusted R2 value of 0.0513 and \nthe lowest P-value of 0.791. The three regression equations all \nhave adjusted values of R2 that are very close to 0, so none of \nthem are good for predicting IQ. It does not appear that people \nwith larger brains have higher IQ scores.\n\t17.\t For H0: b1 = 0, the test statistic is t = 10.814, the P-value is \nless than 0.0001, so reject H0 and conclude that the regression \ncoefficient of b1 = 0.769 should be kept. For H0: b2 = 0, the \ntest statistic is t = 29.856, the P-value is less than 0.0001, so re-\nject H0 and conclude that the regression coefficient of b2 = 1.01 \nshould be kept. It appears that the regression equation should \ninclude both of the independent variables of height and waist cir-\ncumference.\nSection 10-5 \n\t 1.\t A dummy variable is a variable having only two values and those \nvalues (such as 0 and 1) are used to represent the different catego-\nries of a qualitative variable.\n\t 3.\t With simple logistic regression, there is only one predictor vari-\nable, but with multiple logistic regression, there are two or more \npredictor variables.\n\t 5.\t Length and weight are predictor variables. The response variable \nis sex, which is a dummy variable.\n\t 7.\t The probability that the bear is a male is 0.826. The probability \nthat the bear is a female is 0.174.\n\t 9.\t Weight = 3.06 + 82.4(Sex) + 2.91(AGE). Female: 61 lb; \nmale: 144 lb. The sex of the bear does appear to have an effect on \nits weight. The regression equation indicates that the predicted \nweight of a male bear is about 82 lb more than the predicted \nweight of a female bear with other characteristics being the same.\n\t11.\t ln a\np\n1 - pb = -41.2 + 0.2501Height2 - 0.008561Weight2.\n\t\n\t The probability of a male is 0.629.\n\t13.\t ln a\np\n1 - pb = -101.5 + 1.911Foot Length2 + 0.3011Height2.\n\t\n\t The probability of a male is 0.9999.\nChapter 10: Chapter Quick Quiz\n\t 1.\t Conclude that there is not sufficient evidence to support the claim \nof a linear correlation between the systolic blood pressure mea-\nsurements of the right and left arms.\n\t 2.\t None of the given values change when the variables are switched.\n\t 3.\t The value of r does not change if all values of one of the vari-\nables are multiplied by the same constant.\n\t 4.\t Because r must be between -1 and 1 inclusive, the value of \n1.500 is the result of an error in the calculations.\n\t 5.\t The best predicted value is 163.2 mm Hg, which is the mean of \nthe five measurements for the left arm.\nSection 10-3 \n\t 1.\t The value of se = 16.27555 cm is the standard error of estimate, \nwhich is a measure of the differences between the observed \nweights and the weights predicted from the regression equation. \nIt is a measure of the variation of the sample points about the re-\ngression line.\n\t 3.\t The coefficient of determination is r2 = 0.155. We know that \n15.5% of the variation in weight is explained by the linear cor-\nrelation between height and weight, and 84.5% of the variation in \nweight is explained by other factors and>or random variation.\n\t 5.\t r2 = 0.764. 76.4% of the variation in temperature is explained by \nthe linear correlation between chirps and temperature, and 23.6% \nof the variation in temperature is explained by other factors  \nand>or random variation.\n\t 7.\t r2 = 0.872. 87.2% of the variation in weights of bears is ex-\nplained by the linear correlation between neck size and weight, \nand 12.8% of the variation in weights is explained by other fac-\ntors and>or random variation.\n\t 9.\t r = 0.850. Critical values: r = {0.404 (Table: r = {0.396 \napproximately), assuming a 0.05 significance level. There is suf-\nficient evidence to support a claim of a linear correlation between \nregistered boats and manatee fatalities.\n\t11.\t 70.5 manatees\n\t13.\t 42.7 manatees 6 y 6 98.3 manatees\n\t15.\t 65.1 manatees 6 y 6 106.8 manatees\n\t17.\t a. 618.9541    b. 304.7126\n\t \t c. 56.0 mm Hg 6 y 6 81.6 mm Hg\n\t19.\t a. 352.7278    b. 109.3722    c. 71.09oF 6 y 6 88.71oF\n\t21.\t a. 6.5 6 y 6 7.2    b. 6.2 6 y 6 6.8\nSection 10-4 \n\t 1.\t The response variable is weight, and the predictor variables are \nlength and chest size.\n\t 3.\t The unadjusted R2 increases (or remains the same) as more vari-\nables are included, but the adjusted R2 is adjusted for the number \nof variables and sample size. The unadjusted R2 incorrectly sug-\ngests that the best multiple regression equation is obtained by \nincluding all of the available variables, but by taking into account \nthe sample size and number of predictor variables, the adjusted \nR2 is much more helpful in weeding out variables that should not \nbe included.\n\t 5.\t Son = 18.0 + 0.504 Father + 0.277 Mother\n\t 7.\t P-value less than 0.0001 is low, but the values of R2 (0.3649) and \nadjusted R2 (0.3552) are not high. Although the multiple regres-\nsion equation fits the sample data best, it is not a good fit, so it \nshould not be used for predicting the height of a son based on the \nheight of his father and the height of his mother.\n\t 9.\t Waist circumference, because it has the highest adjusted R2 value \nand the P-values are the same for the three individual variables.\n\t11.\t Some subjective judgment is involved here. A good choice \nwould be to use all three variables because the adjusted R2 value \nof 0.939 is considerably higher than any of the other values of \nadjusted R2. With this reasoning, the best regression equation is \nyn = -147 + 0.632 HT + 0.697 WAIST + 1.58 ARM.\n\t13.\t The best regression equation is yn = 0.127 + 0.0878x1 -\n0.0250x2, where x1 represents tar and x2 represents carbon  \n",
    "674\t\nAppendix D\n\t\n\t b. \u0007Three of the original pairs of sample data are the same  \n(20, 16), so those three points are at the same location and they \nappear to be one point.\n\t\n\t c. \u0007r = 0.437. P-value = 0.279 (Table: 70.05). Critical values: \nr = {0.707 (assuming a 0.05 significance level). There is not \nsufficient evidence to support the claim that there is a linear \ncorrelation between amounts of tar and carbon monoxide.\n\t\n\t d. \u0007yn = 12.0 + 0.181x\n\t \t e. \u0007The predicted value is y = 16.1 mg, which is close to the ac-\ntual amount of 15 mg.\n\t 4.\t a. \u0007NICOTINE = -0.443 + 0.0968 TAR - 0.0262 CO, or \nyn = -0.443 + 0.0968x1 - 0.0262x2.\n\t\n\t b. \u0007R2 = 0.936; adjusted R2 = 0.910; P-value = 0.001.\n\t\n\t c. \u0007With high values of R2 and adjusted R2 and a small P-value \nof 0.001, it appears that the regression equation can be used \nto predict the amount of nicotine given the amounts of tar and \ncarbon monoxide.\n\t \t d. \u0007The predicted value is 1.39 mg, or 1.4 mg rounded, which is \nclose to the actual value of 1.3 mg of nicotine.\n\t 5.\t r = 0.450. P-value = 0.192 (Table 70.05). Critical values: \nr = {0.632 (assuming a 0.05 significance level). There is not \nsufficient evidence to support the claim that there is a linear cor-\nrelation between time and population size. Although there is no \nlinear correlation between time and population size, the scatter-\nplot shows a very distinct pattern revealing that time and popula-\ntion size are associated by a function that is not linear.\n\t 6.\t ln a\np\n1 - pb = -44.4 + 0.5571Temp. at 8 AM2 -\n\t\n\t 0.0981Temp. at 12 AM2.\n\t\n\t The probability that the subject smokes is 0.667. Because the \nregression equation has the high overall P-value of 0.521, the \npredicted value is not likely to be very accurate.\nChapter 10: Cumulative Review Exercises\n\t 1.\t x = 3.3 lb, s = 5.7 lb\n\t 2.\t The highest weight before the diet is 212 lb, which converts to \nz = 1.55. The highest weight is not significantly high because its \nz score of 1.55 shows that it is within 2 standard deviations of the \nmean.\n\t 3.\t H0: md = 0. H1: md 7 0. Test statistic: t = 1.613. P-value =\n0.0754 (Table: 70.05). Critical value: t = 1.895. Fail to reject \nH0. There is not sufficient evidence to support the claim that the \ndiet is effective.\n\t 4.\t 161.8 lb 6 m 6 197.0 lb. We have 95% confidence that the in-\nterval limits of 161.8 lb and 197.0 lb contain the true value of the \nmean of the population of all subjects before the diet.\n\t 5.\t a. r = 0.965. P-value = 0.0001. Critical values: r = {0.707 \n(assuming a 0.05 significance level). There is sufficient evidence \nto support the claim that there is a linear correlation between be-\nfore and after weights.\n\t\n\t b.\tr = 1    c. r = 1\n\t \t d. \u0007The effectiveness of the diet is determined by the amounts of \nweight lost, but the linear correlation coefficient is not sensi-\ntive to different amounts of weight loss. Correlation is not a \nsuitable tool for testing the effectiveness of the diet.\n\t 6.\t The best predicted value is 174.6 mm Hg, which is found by sub-\nstituting 100 for x in the regression equation.\n\t 7.\t r2 = 0.752\n\t 8.\t False.\n\t 9.\t False.\n\t10.\t r = -1\nChapter 10: Review Exercises\n\t 1.\t a. r = 0.962. P-value = 0.000 (Table: 60.01). Critical values: \nr = {0.707 (assuming a 0.05 significance level). There is suf-\nficient evidence to support the claim that there is a linear correla-\ntion between the amount of tar and the amount of nicotine.\n\t\n\t b. 92.5%\n\t\n\t c. yn = -0.758 + 0.0920x\n\t \t d. \u0007The predicted value is 1.358 mg, or 1.4 mg rounded, which is \nclose to the actual amount of 1.3 mg.\n\t 2.\t a. \u0007The scatterplot shows a pattern with nicotine and CO both increas-\ning from left to right, but it is a very weak pattern and the points \nare not very close to a straight-line pattern, so it appears that there \nis not sufficient sample evidence to support the claim of a linear \ncorrelation between amounts of nicotine and carbon monoxide.\n\t\n\t b. \u0007r = 0.329. P-value = 0.427 (Table: 70.05). Critical values: \nr = {0.707 (assuming a 0.05 significance level). There is not \nsufficient evidence to support the claim that there is a linear \ncorrelation between amount of nicotine and amount of carbon \nmonoxide.\n\t\n\t c. yn = 14.2 + 1.42x\n\t \t d. \u0007The predicted value is y = 16.1 mg, which is close to the ac-\ntual amount of 15 mg.\n\t 3.\t a. \u0007The scatterplot shows a pattern with amounts of tar and carbon \nmonoxide both increasing from left to right, but it is a very \nweak pattern and the points are not very close to a straight-\nline pattern, so it appears that there is not sufficient sample \nevidence to support the claim of a linear correlation between \namounts of tar and carbon monoxide.\n",
    "\t\nAppendix D\t\n675\n\t 6.\t a. 43.58% (Table: 43.64%)    b. 2785.6 g (Table: 2786.4 g)\n\t \t c. 5.00%. Yes, many of the babies do require special treatment.\n\t 7.\t a. \u0007No. Correlation can be used to investigate an association be-\ntween the two variables, not whether differences between val-\nues of the two variables are significant.\n\t \t b. \u0007Test statistic: t = 1.185. P-value: 0.2663 (Table: 70.20). \nCritical values: t = {2.262. Fail to reject H0: md = 0. There \nis not sufficient evidence to warrant rejection of the claim \nthat position has no effect. Position does not appear to have a \n­significant effect.\n\t 8.\t There must be an error, because the rates of 13.7% and 10.6% are \nnot possible with sample sizes of 100.\nChapter 11 Answers\nSection 11-1 \n\t 1.\t a. \u0007Observed values are represented by O and expected values are \nrepresented by E.\n\t \t b. \u0007For the leading digit of 2, O = 62 and  \nE = (317) (0.176)= 55.792.\n\t \t c. For the leading digit of 2, (O-E)2>E = 0.691.\n\t 3.\t There is sufficient evidence to warrant rejection of the claim that the \nleading digits have a distribution that fits well with Benford’s law.\n\t 5.\t Test statistic: x2 = 0.523. P@value = 0.9712 (Table: 70.95). \nCritical value: x2 = 9.488. There is not sufficient evidence to \nwarrant rejection of the claim that injuries and illnesses occur \nwith equal frequency on the different days of the week.\n\t 7.\t Test statistic: x2 = 47.200. P@value = 0.0000. Critical value: \nx2 = 19.675. There is sufficient evidence to warrant rejection \nof the claim that motorcycle fatalities occur with equal frequen-\ncies in the different months. Fatalities might be lower in winter \nmonths when colder weather is associated with substantially  \nless use of motorcycles.\n\t 9.\t Test statistic: x2 = 93.072. P@value = 0.000 (Table: 60.005). \nCritical value: x2 = 19.675. There is sufficient evidence to  \nwarrant rejection of the claim that American-born Major League \nBaseball players are born in different months with the same  \nfrequency. The sample data appear to support Gladwell’s claim.\n\t11.\t Test statistic: x2 = 9.658. P@value = 0.0080. Critical value: \nx2 = 5.991. There is sufficient evidence to warrant rejection of \nthe claim that the actual frequencies correspond to the predicted \ndistribution.\n\t13.\t Test statistic: x2 = 524.713. P@value = 0.000 (Table: 60.005). \nCritical value: x2 = 13.277. There is sufficient evidence to war-\nrant rejection of the claim that the distribution of clinical trial \nparticipants fits well with the population distribution. Hispanics \nhave an observed frequency of 60 and an expected frequency \nof 391.027, so they are very underrepresented. Also, the Asian>\nPacific Islander subjects have an observed frequency of 54 and an \nexpected frequency of 163.286, so they are also underrepresented.\n\t15.\t Test statistic: x2 = 3650.251. P@value = 0.0000 (Table: 60.005). \nCritical value: x2 = 20.090. There is sufficient evidence to warrant \nrejection of the claim that the leading digits are from a population \nwith a distribution that conforms to Benford’s law. It does appear \nthat the image has been corrupted.\n\t17.\t Test statistic: x2 = 9.500. P@value = 0.147 (Table: 70.10). \nCritical value: x2 = 16.812. There is not sufficient evidence to \nsupport the claim that births do not occur on the seven different \ndays of the week with equal frequency.\n\t19.\t a. 26, 46, 49, 26\n\t \t b. \u00070.2023, 0.3171, 0.3046, 0.1761 (Table: 0.2033, 0.3166, \n0.3039, 0.1762)\n\t \t c. \u000729.7381, 46.6137, 44.7762, 25.8867 (Table: 29.8851, 46.5402, \n44.6733, 25.9014)\n\t \t d. \u0007Test statistic: x2 = 0.877 (Table: 0.931). P@value = 0.831 \n(Table: 70.10). Critical value: x2 = 11.345. There is not suf-\nficient evidence to warrant rejection of the claim that heights \nwere randomly selected from a normally distributed popula-\ntion. The test suggests that we cannot rule out the possibility \nthat the data are from a normally distributed population.\nSection 11-2 \n\t 1.\t a. E = 4.173\n\t \t b. \u0007Because the expected frequency of a cell is less than 5, the  \nrequirements for the hypothesis test are not satisfied.\n\t 3.\t Test statistic:x2 = 64.517. P-value: 0.000. Reject the null  \nhypothesis of independence between handedness and cell phone \near preference.\n\t 5.\t Test statistic: x2 = 9.750. P@value = 0.002 (Table: 60.005). \nCritical value: x2 = 6.635. There is sufficient evidence to war-\nrant rejection of the claim that success is independent of the type \nof treatment. The results suggest that the surgery treatment is  \nbetter.\n\t 7.\t Test statistic: x2 = 0.751. P@value = 0.3862 (Table: 70.10). \nCritical value: x2 = 3.841. There is not sufficient evidence to \nwarrant rejection of the claim of independence between the type \nof restoration and adverse health conditions. Amalgam restora-\ntions do not appear to affect health conditions.\n\t 9.\t Test statistic: x2 = 34.345. P@value = 0.0000. Critical value: \nx2 = 6.635. There is sufficient evidence to warrant rejection of \nthe claim that the source of the sample is independent of the dog’s \nselections. The results suggest that the dogs have some ability to \ndetect bladder cancer, but they did not do well enough for accurate \ndiagnoses.\n\t11.\t Test statistic: x2 = 9.854. P@value = 0.0017 (Table: 60.005). \nCritical value: x2 = 6.635. There is sufficient evidence to war-\nrant rejection of the claim that nausea is independent of whether \nthe subject took a placebo or Chantix. It appears that nausea is \nmore likely to occur among those who use Chantix, so nausea  \nis a concern. However, the rate of nausea among Chantix users  \nis only about 3.7%, so it is not much of a concern.\n\t13.\t Test statistic: x2 = 18.773. P@value = 0.000 (Table: 60.005). \nCritical value: x2 = 3.841. There is sufficient evidence to war-\nrant rejection of the claim of independence between texting \nwhile driving and irregular seat belt use. Those two risky behav-\niors appear to be somehow related.\n\t15.\t Test statistic: x2 = 42.568. P@value = 0.0000 (Table: 60.005). \nCritical value: x2 = 9.210. There is sufficient evidence to war-\nrant rejection of the claim that experiencing an adverse reaction \nin the digestive system is independent of the treatment group. \nTreatments with 1332 mg doses of Campral appear to be associ-\nated with an increase in adverse effects of the digestive system.\n",
    "676\t\nAppendix D\n\t17.\t Test statistic: x2 = 1.358. P@value = 0.715 (Table: 70.10). \nCritical value: x2 = 7.815 (assuming a 0.05 significance level). \nThere is not sufficient evidence to warrant rejection of the claim \nthat the amount of smoking is independent of seat belt use. The \ntheory is not supported by the given data.\n\t19.\t Test statistic: x2 = 9.971. P@value = 0.041 (Table: 60.05). \nCritical value: x2 = 9.488 (assuming a 0.05 significance level). \nThere is sufficient evidence to warrant rejection of the claim that \ninjuries are independent of helmet color. It appears that motor-\ncycle drivers should use yellow or orange helmets.\n\t21.\t Test statistics: x2 = 9.7504 and z = -3.122560496 so \nthat z 2 = x2. Critical values: x2 = 6.635 and z = 2.57583 \n(Table: {2.575) so z2 = x2.\nChapter 11: Quick Quiz\n\t 1.\t H0: p0 = p1 =  . . . = p9. H1: At least one of the probabilities is \ndifferent from the others.\n\t 2.\t O = 27 and E = 30\n\t 3.\t Right-tailed\n\t 4.\t df = 9\n\t 5.\t There is not sufficient evidence to warrant rejection of the claim \nthat the last digits are equally likely. Because reported heights \nwould likely include more last digits of 0 and 5, it appears that \nthe heights were measured instead of reported. (Also, most U.S. \nresidents would have difficulty reporting heights in centimeters, be-\ncause the United States, Liberia, and Myanmar are the only coun-\ntries that continue to use the Imperial system of measurement.)\n\t 6.\t H0: Surviving the sinking is independent of whether the person is \na man, woman, boy, or girl.\n\t\n\t H1: Surviving the sinking and whether the person is a man, \nwoman, boy, or girl are somehow related.\n\t 7.\t Chi-square distribution.\n\t 8.\t Right-tailed\n\t 9.\t df = 3\n\t10.\t There is sufficient evidence to warrant rejection of the claim that \nsurviving the sinking is independent of whether the person is a \nman, woman, boy, or girl. Most of the women survived, 45% of the \nboys survived, and most girls survived, but only about 20% of the \nmen survived, so it appears that the rule was followed quite well.\nChapter 11: Review Exercises\n\t 1.\t Test statistic: x2 = 269.147. P@value = 0.000 (Table: 60.005).  \nCritical value: x2 = 24.725. There is sufficient evidence to war-\nrant rejection of the claim that weather-related deaths occur in the \ndifferent months with the same frequency. The months of May, \nJune, and July appear to have disproportionately more weather-\nrelated deaths, and that is probably due to the fact that vacations \nand outdoor activities are much greater during those months.\n\t 2.\t Test statistic: x2 = 71.679. P@value = 0.0000 (Table: 60.005). \nCritical value: x2 = 3.841. There is sufficient evidence to war-\nrant rejection of the claim that getting norovirus infection is \nindependent of the ship. It appears that an outbreak of norovirus \ninfection has a different effect on different ships.\n\t 3.\t Test statistic: x2 = 10.375. P@value = 0.4970 (Table: 70.10). \nCritical value: x2 = 19.675. There is not sufficient evidence to \nwarrant rejection of the claim that homicides in New York City \nare equally likely for each of the 12 months. There is not suf-\nficient evidence to support the police commissioner’s claim that \nhomicides occur more often in the summer when the weather is \nwarmer.\n\t 4.\t Test statistic: x2 = 784.647. P@value = 0.0000 (Table: 60.005). \nCritical value: x2 = 11.345. There is sufficient evidence to war-\nrant rejection of the claim that left-handedness is independent of \nparental handedness. It appears that handedness of the parents \nhas an effect on handedness of the offspring, so left-handedness \nappears to be an inherited trait.\n\t 5.\t Test statistic: x2 = 53.051. P@value = 0.0000 (Table: 60.005). \nCritical value: x2 = 7.815. There is sufficient evidence to war-\nrant rejection of the claim that the distribution of crashes is the \nsame as the distribution of ages. Drivers under 25 appear to have \ndisproportionately more crashes.\nChapter 11: Cumulative Review Exercises\n\t 1.\t x = 53.7 years, median = 60.0 years, s = 16.1 years,  \ns2 = 258.9 years2. Because an age of 16 is more than 2 standard \ndeviations below the mean of 53.7 years, it is significantly low.\n\t 2.\t 42.2 years 6 m 6 65.2 years. Yes, the confidence interval limits \ndo contain the value of 65.0 years that was found from a sample \nof 9269 ICU patients.\n\t 3.\t Test statistic: x2 = 10.708. P@value = 0.0011 (Table: 60.005). \nCritical value: x2 = 3.841. There is sufficient evidence to war-\nrant rejection of the claim that wearing a helmet has no effect on \nwhether facial injuries are received. It does appear that a helmet \nis helpful in preventing facial injuries in a crash.\n\t 4.\t a. 349>531 or 0.657\n\t \t b. 0.0450\n\t \t c. 0.787\n\t 5.\t a. 630 mm\n\t \t b. \u000714.48 (Table: 14.46%). That percentage is too high, because \ntoo many women would not be accommodated.\n\t \t c. \u00070.7599 (Table: 0.7611). Groups of 16 women do not occupy a \ndriver’s seat or cockpit; because individual women occupy the \ndriver’s seat>cockpit, this result has no effect on the design.\n\t 6.\t Determine whether there is a linear correlation between diastolic \nblood pressure and height. r = -0.146. P@value = 0.7824 \n(Table: 70.05). Critical values: r = {0.811 (assuming a 0.05 \nsignificance level). There is not sufficient evidence to support the \nclaim that for males, there is a linear correlation between diastolic \nblood pressure and height.\nChapter 12 Answers\nSection 12-1\n\t 1.\t a. \u0007The chest deceleration measurements are categorized accord-\ning to the one characteristic of size.\n\t \t b. \u0007The terminology of analysis of variance refers to the method \nused to test for equality of the three population means. That \nmethod is based on two different estimates of a common popu-\nlation variance.\n\t 3.\t The test statistic is F = 3.288, and the F distribution applies.\n\t 5.\t Test statistic: F = 0.39. P-value: 0.677. Fail to reject  \nH0: m1 = m2 = m3. There is not sufficient evidence to warrant \nrejection of the claim that the three categories of blood lead level \n",
    "\t\nAppendix D\t\n677\nhave the same mean verbal IQ score. Exposure to lead does not \nappear to have an effect on verbal IQ scores.\n\t 7.\t Test statistic: F = 0.161. P-value: 0.852. Fail to reject  \nH0: m1 = m2 = m3. There is not sufficient evidence to warrant  \nrejection of the claim that the three size categories have the same \nmean head injury measurement. Based on the available data, the \nsize of a car does not appear to affect head injuries.\n\t 9.\t Test statistic: F = 1.304. P-value: 0.275. Fail to reject  \nH0: m1 = m2 = m3. There is not sufficient evidence to warrant \nrejection of the claim that males from the three age brackets have \nthe same mean pulse rate. It appears that pulse rates of males are \nnot affected by age bracket.\n\t11.\t Test statistic: F = 0.3476. P-value: 0.7111. Fail to reject  \nH0: m1 = m2 = m3. There is not sufficient evidence to warrant  \nrejection of the claim that the three size categories have the same \nmean pelvis injury measurement. The size of a car does not  \nappear to affect pelvis injuries.\n\t13.\t Test statistic: F = 6.1413. P-value: 0.0056. Reject H0: m1 =\nm2 = m3 = m4. There is sufficient evidence to warrant rejection \nof the claim that the four treatment categories yield poplar trees \nwith the same mean weight. Although not justified by the results \nfrom analysis of variance, the treatment of fertilizer and irriga-\ntion appears to be most effective.\n\t15.\t Test statistic: F = 18.9931. P-value: 0.0000. Reject H0: m1 = \nm2 = m3. There is sufficient evidence to warrant rejection of the \nclaim that the three different types of cigarettes have the same \nmean amount of nicotine. Given that the king-size cigarettes \nhave the largest mean of 1.26 mg per cigarette, compared to the \nother means of 0.87 mg per cigarette and 0.92 mg per cigarette, \nit appears that the filters do make a difference, although this con-\nclusion is not justified by the results from analysis of variance.\n\t17.\t The Tukey test results show different P-values, but they are not \ndramatically different. The Tukey test results suggest the same \nconclusions as the Bonferroni test.\nSection 12-2\n\t 1.\t The pulse rates are categorized using two different factors of  \n(1) age bracket and (2) gender.\n\t 3.\t a. \u0007An interaction between two factors or variables occurs if the  \neffect of one of the factors changes for different categories of \nthe other factor.\n\t\n\t b. \u0007If there is an interaction effect, we should not proceed with \nindividual tests for effects from the row factor and column \nfactor. If there is an interaction, we should not consider the ef-\nfects of one factor without considering the effects of the other \nfactor.\n\t \t c. \u0007Because the lines are far from parallel, the two genders have \nvery different effects for the different age brackets, so there does \nappear to be an interaction between gender and age bracket.\n\t 5.\t For interaction, the test statistic is F = 9.58 and the P-value is \n0.0003, so there is sufficient evidence to warrant rejection of the \nnull hypothesis of no interaction effect. Because there appears \nto be an interaction between age bracket and gender, we should \nnot proceed with a test for an effect from age bracket and a test \nfor an effect from gender. It appears an interaction between age \nbracket and gender has an effect on pulse rates. (Remember, \nthese results are based on fabricated data used in one of the cells, \nso this conclusion does not necessarily correspond to real data.)\n\t 7.\t For interaction, the test statistic is F = 1.7970 and the P-value is \n0.1756, so there is not sufficient evidence to conclude that there is an \ninteraction effect. For the row variable of age bracket, the test statis-\ntic is F = 2.0403 and the P-value is 0.1399, so there is not sufficient \nevidence to conclude that age bracket has an effect on height. For the \ncolumn variable of gender, the test statistic is F = 43.4607 and the \nP-value is less than 0.0001, so there is sufficient evidence to support \nthe claim that gender has an effect on height.\n\t 9.\t For interaction, the test statistic is F = 3.7332 and the P-value \nis 0.0291, so there is sufficient evidence to conclude that there is \nan interaction effect. The measures of self-esteem appear to be \naffected by an interaction between the self-esteem of the subject \nand the self-esteem of the target. Because there appears to be an \ninteraction effect, we should not proceed with individual tests of \nthe row factor (target’s self-esteem) and the column factor  \n(subject’s self-esteem).\n\t11.\t a. Test statistics and P-values do not change.\n\t\n\t b. Test statistics and P-values do not change.\n\t\n\t c. Test statistics and P-values do not change.\n\t \t d. \u0007An outlier can dramatically affect and change test statistics and \nP-values.\nChapter 12: Quick Quiz\n\t 1.\t The sample data are partitioned into the three different categories \naccording to the one factor of epoch.\n\t 2.\t H0: m1 = m2 = m3. H1: At least one of the three population \nmeans is different from the others.\n\t 3.\t Test statistic: F = 4.0497. Larger test statistics result in smaller \nP-values.\n\t 4.\t Reject H0. There is sufficient evidence to support the claim that \nthe different epochs have mean skull breadths that are not all  \nthe same.\n\t 5.\t Right-tailed. Yes, all one-way analysis of variance tests are right-tailed.\n\t 6.\t No. The method of analysis of variance does not justify a conclu-\nsion that any particular mean is different from the others.\n\t 7.\t With one-way analysis of variance, data from the different \nsamples are categorized using only one factor, but with two-way \nanalysis of variance, the sample data are categorized into differ-\nent cells determined by two different factors.\n\t 8.\t Test statistic: F = 1.41. P-value: 0.281. Fail to reject the null hy-\npothesis of no interaction effect. There is not sufficient evidence to \nwarrant rejection of the claim that head injury measurements are not \naffected by an interaction between the type of car (foreign, domes-\ntic) and size of the car (small, medium, large). There does not appear \nto be an effect from an interaction between the type of car (foreign or \ndomestic) and whether the car is small, medium, or large.\n\t 9.\t Test statistic: F = 2.25. P-value: 0.159. Fail to reject the null  \nhypothesis of no effect from the type of car. There is not suffi-\ncient evidence to support the claim that whether the car is foreign \nor domestic has an effect on head injury measurements.\n\t10.\t Test statistic: F = 0.44. P-value: 0.655. Fail to reject the null \nhypothesis of no effect from the size of the car. There is not suf-\nficient evidence to support the claim that whether the car is small, \nmedium, or large has an effect on head injury measurements.\n",
    "678\t\nAppendix D\nChapter 12: Review Exercises\n\t 1.\t a. One (type of diet)\n\t\n\t b. One-way analysis of variance\n\t\n\t c. \u0007Because the P-value is high, it appears that the four samples have \nmeans that do not differ by significant amounts. It appears that the \nmean ages of the four treatment groups are about the same.\n\t \t d. \u0007A small P-value would indicate that at least one of the treat-\nment groups has a mean age that is significantly different from \nthe others, so we would not know if differences from the diet \ntreatments are due to the diets or to differences in age. A small \nP-value would undermine the effectiveness of the experiment.\n\t 2.\t Test statistic: F = 42.9436. P-value: 0.000. Reject H0: m1 =\nm2 = m3. There is sufficient evidence to warrant rejection of the \nclaim that the three different types of cigarettes have the same \nmean amount of tar. Given that the king-size cigarettes have the \nlargest mean of 21.1 mg per cigarette, compared to the other \nmeans of 12.9 mg per cigarette and 13.2 mg per cigarette, it ap-\npears that the filters do make a difference, although this conclu-\nsion is not justified by the results from analysis of variance.\n\t 3.\t For interaction, the test statistic is F = 1.7171 and the P-value is \n0.1940, so there is not sufficient evidence to warrant rejection of \nno interaction effect. There does not appear to be an interaction \nbetween femur and car size. For the row variable of femur, the \ntest statistic is F = 1.3896 and the P-value is 0.2462, so there is \nnot sufficient evidence to conclude that whether the femur is right \nor left has an effect on load. For the column variable of car size, \nthe test statistic is F = 2.2296 and the P-value is 0.1222, so there \nis not sufficient evidence to warrant rejection of the claim of no \neffect from car size. It appears that the crash test loads are not af-\nfected by an interaction between femur and car size, they are not \naffected by femur, and they are not affected by car size.\n\t 4.\t For interaction, the test statistic is F = 0.8733 and the P-value is \n0.3685, so there does not appear to be an effect from an interac-\ntion between gender and whether the subject smokes. For gender, \nthe test statistic is F = 0.0178 and the P-value is 0.8960, so \ngender does not appear to have an effect on body temperature. \nFor smoking, the test statistic is F = 3.0119 and the P-value is \n0.1082, so there does not appear to be an effect from smoking on \nbody temperature.\nChapter 12: Cumulative Review Exercises\n\t 1.\t a. 15.5 years, 13.1 years, 22.7 years\n\t\n\t b. 9.7 years, 9.0 years, 18.6 years\n\t\n\t c. \u000794.5 years2, 80.3 years2, 346.1 years2\n\t \t d. Ratio\n\t 2.\t Test statistic: t = -1.383. P-value = 0.1860. Critical values as-\nsuming a 0.05 significance level: t = {2.123 (Table: {2.160). \nFail to reject H0: m1 = m2. There is not sufficient evidence to \nsupport the claim that there is a difference between the means for \nthe two groups.\n\t 3.\t Normal, because the histogram is approximately bell-shaped \nor the points in a normal quantile plot are reasonably close to a \nstraight-line pattern with no other pattern that is not a straight-\nline pattern.\n\t 4.\t 12.3 years 6 m 6 18.7 years. We have 95% confidence that the \nlimits of 12.3 years and 18.7 years contain the true value of the \npopulation mean.\n\t 5.\t a. H0: m1 = m2 = m3\n\t \t b. \u0007Because the P-value of 0.051 is greater than the significance \nlevel of 0.05, fail to reject the null hypothesis of equal means. \nThere is not sufficient evidence to warrant rejection of the \nclaim that the three means are equal. The three populations do \nnot appear to have means that are significantly different.\n\t 6.\t a. \u0007r = 0.918. Critical values: r = {0.707. P-value = 0.001.  \nThere is sufficient evidence to support the claim that there is a \nlinear correlation between September weights and the subse-\nquent April weights.\n\t\n\t b. yn = 9.28 + 0.823x\n\t \t c. \u000786.6 kg, which is not very close to the actual April weight of \n105 kg.\n\t 7.\t a. 0.1587\n\t\n\t b. 0.6827 (Table: 0.6826)\n\t\n\t c. 0.9987\n\t \t d. 334.7 (Table: 334.6)\n\t 8.\t a. 200\n\t\n\t b. 0.175 6 p 6 0.225\n\t \t c. \u0007Yes. The confidence interval shows us that we have 95% con-\nfidence that the true population proportion is contained within \nthe limits of 0.175 and 0.225, and 1>4 or 0.25 is not included \nwithin that range.\n\t 9.\t Using normal as approximation to binomial: 0.1020. (Exact result \nusing technology: 0.0995.) Assuming that one-quarter of all off-\nspring have blue eyes, the probability of getting 19 or fewer off-\nspring with blue eyes is high, so there is not sufficient evidence to \nconclude that the one-quarter rate is wrong.\n\t10.\t Test statistic: x2 = 2.909. P@value = 0.2335 (Table: 70.10). \nCritical value: x2 = 5.991. There is not sufficient evidence to \nwarrant rejection of the claim of independence between injury \ncategory and whether the firearm was a handgun or a rifle or \nshotgun. The type of injury doesn’t appear to be affected by \nwhether the firearm is a handgun or a rifle or shotgun.\nChapter 13 Answers\nSection 13-2\n\t 1.\t a. \u0007The only requirement for the matched pairs is that they consti-\ntute a simple random sample.\n\t \t b. \u0007There is no requirement of a normal distribution or any other \nspecific distribution.\n\t \t c. \u0007The sign test is “distribution free” in the sense that it does not \nrequire a normal distribution or any other specific distribution.\n\t 3.\t H0: There is no difference between the populations of body  \ntemperatures at 8 AM and at 12 AM. H1: There is a difference  \nbetween the populations of body temperatures at 8 AM and at  \n12 AM. The sample data do not contradict H1 because the numbers \nof positive signs (1) and negative signs (4) are not exactly the same.\n\t 5.\t The test statistic of x = 2 is not less than or equal to the criti-\ncal value of 0. There is not sufficient evidence to reject the \nclaim of no difference in heights between mothers and their \nfirst daughters.\n\t 7.\t The test statistic of x = 1 is not less than or equal to the criti-\ncal value of 0. There is not sufficient evidence to warrant rejec-\ntion of the claim that when the 13th day of a month falls on a \nFriday, the numbers of hospital admissions from motor vehicle \n",
    "\t\nAppendix D\t\n679\ncrashes are not affected. Hospital admissions do not appear to \nbe affected.\n\t 9.\t The test statistic of z = -2.66 results in a P-value of 0.0078 and \nit is in the critical region bounded by z = -2.575 and 2.575. \nThere is sufficient evidence to warrant rejection of the claim that \nthere is no difference between the proportions of those opposed \nand those in favor.\n\t11.\t The test statistic of z = -0.24 results in a P-value of 0.8103 and \nit is not in the critical region bounded by z = -1.96 and 1.96. \nThere is not sufficient evidence to reject the claim that boys and \ngirls are equally likely.\n\t13.\t The test statistic of x = 9 is not less than or equal to the critical \nvalue of 5. There is not sufficient evidence to warrant rejection of \nthe claim that the sample is from a population with a median  \nIQ score of 100.\n\t15.\t The test statistic of z = -2.30 results in a P-value of 0.0214 and \nit is in the critical region bounded by z = -1.96 and 1.96. There \nis sufficient evidence to warrant rejection of the claim that the \nsample is from a population with a median diastolic blood pres-\nsure level of 72.\n\t17.\t Second approach: The test statistic of z = -4.29 results in a \nP-value of 0.0000 and it is in the critical region bounded by \nz = -1.645, so the conclusions are the same as in Example 4.  \nThird approach: The test statistic of z = -2.82 results in a \nP-value of 0.0024 and it is in the critical region bounded by \nz = -1.645, so the conclusions are the same as in Example 4. \nThe different approaches can lead to very different results; see the \ntest statistics of -4.21, -4.29, and -2.82. The conclusions are \nthe same in this case, but they could be different in other cases.\nSection 13-3\n\t 1.\t a. \u0007The only requirements are that the matched pairs be a simple \nrandom sample and the population of differences be approxi-\nmately symmetric.\n\t\n\t b. \u0007There is no requirement of a normal distribution or any other \nspecific distribution.\n\t \t c. \u0007The Wilcoxon signed-ranks test is “distribution free” in the \nsense that it does not require a normal distribution or any other \nspecific distribution.\n\t 3.\t The sign test uses only the signs of the differences, but the  \nWilcoxon signed-ranks test uses ranks that are affected by the \nmagnitudes of the differences.\n\t 5.\t Test statistic: T = 8.5. Critical value: T = 4. Fail to reject the \nnull hypothesis that the population of differences has a median of \n0. There is not sufficient evidence to reject the claim of no differ-\nence in heights between mothers and their first daughters. There \ndoes not appear to be a difference in heights between mothers and \ntheir first daughters.\n\t 7.\t Test statistic: T = 1.5. Critical value: T = 1. Fail to reject the \nnull hypothesis that the population of differences has a median \nof 0. There is not sufficient evidence to warrant rejection of the \nclaim that when the 13th day of a month falls on a Friday, the \nnumbers of hospital admissions from motor vehicle crashes are \nnot affected. Hospital admissions do not appear to be affected.\n\t 9.\t Test statistic: T = 98. Critical value: T = 52. There is not suf-\nficient evidence to warrant rejection of the claim that the sample \nis from a population with a median IQ score of 100.\n\t11.\t Convert T = 16,236 to the test statistic z = -1.89.  \nP-value = 0.0588. Critical values: z = {1.96. There is not  \nsufficient evidence to warrant rejection of the claim that the  \nsample is from a population with a median diastolic blood  \npressure level of 72.\n\t13.\t a. 0 and 45,150\n\t \t b. 22,575\n\t \t c. 32,805\n\t \t d. n(n + 1)\n2\n- k\nSection 13-4\n\t 1.\t The two samples are from populations with the same median.\n\t 3.\t Yes. The samples are independent and both samples have more \nthan 10 values.\n\t 5.\t R1 = 172, R2 = 179, mR = 189, sR = 19.4422, test statistic: \nz = -0.87. P-value: 0.3843. Critical values: z = {1.96. Fail to \nreject the null hypothesis that the populations have the same me-\ndian. There is not sufficient evidence to warrant rejection of the \nclaim that girls and boys have the same median birth weight.\n\t 7.\t R1 = 253.5, R2 = 124.5, mR = 182, sR = 20.607, test statistic: \nz = 3.47. P-value = 0.001. Critical values: z = {1.96. Reject \nthe null hypothesis that the populations have the same median. \nThere is sufficient evidence to reject the claim that for those \ntreated with 20 mg of atorvastatin and those treated with 80 mg \nof atorvastatin, changes in LDL cholesterol have the same me-\ndian. It appears that the dosage amount does have an effect on the \nchange in LDL cholesterol.\n\t 9.\t R1 = 36,531.5, R2 = 43,668.5, mR = 41,102.5, sR = 1155.782, \ntest statistic: z = -3.95. P-value: 0.0001 (Table: 0.0002). \nCritical values: z = {1.96. Reject the null hypothesis that the \npopulations have the same median. There is sufficient evidence to \nwarrant rejection of the claim that girls and boys have the same \nmedian birth weight.\n\t11.\t R1 = 501, R2 = 445, mR =  484, sR =  41.158, test statistic: \nz = 0.41. P-value 0.3409. Critical value: z = 1.645. Fail to \nreject the null hypothesis that the populations have the same \nmedian. There is not sufficient evidence to support the claim that \nsubjects with medium lead levels have a higher median of the \nfull IQ scores than subjects with high lead levels. Based on these \ndata, it does not appear that lead level affects full IQ scores.\n\t13.\t Using U = 86.5, we get z = 1.26. The test statistic is the same \nvalue with opposite sign.\nSection 13-5\n\t 1.\t R1 = 36.5, R2 = 52.5, R3 = 47\n\t 3.\t n1 = 5, n2 = 6, n3 = 5, and N = 16.\n\t 5.\t Test statistic: H = 4.9054. Critical value: x2 = 5.991.  \n(Tech: P-value = 0.0861.) Fail to reject the null hypothesis of \nequal medians. The data do not suggest that larger cars are safer.\n\t 7.\t Test statistic: H = 22.8157. Critical value: x2 = 9.210.  \n(Tech: P-value = 0.000.) Reject the null hypothesis of equal \nmedians. It appears that the three states have median amounts of \narsenic that are not all the same.\n\t 9.\t Test statistic: H = 59.1546. Critical value: x2 = 9.210.  \n(Tech: P-value = 0.000.) Reject the null hypothesis of equal me-\ndians. The data suggest that the amounts of nicotine absorbed by  \n",
    "680\t\nAppendix D\nsmokers are different from the amounts absorbed by people who \ndon’t smoke.\n\t11.\t Test statistic: H = 27.9098. Critical value: x2 = 5.991.  \n(Tech: P-value: 0.000.) Reject the null hypothesis of equal medi-\nans. There is sufficient evidence to warrant rejection of the claim \nthat the three different types of cigarettes have the same median \namount of nicotine. It appears that the filters do make a difference.\n\t13.\t There are 10 zeros and 2 ones, so the values of t are 10 and 2. \nThe values of T are (103 - 10) = 990 and (23 - 2) = 6, so \nΣT = 990 + 6 = 996. Using ΣT = 996 and N = 18, the cor-\nrected value of H is 8.114, which is quite different from the value \nof 6.724 found in Example 1. In this case, the large numbers of \nties do appear to have a considerable effect on the test statistic H.\nSection 13-6\n\t 1.\t The methods of Section 10-2 should not be used for predictions. \nThe regression equation is based on a linear correlation between \nthe two variables, but the methods of this section do not require  \na linear relationship. The methods of this section could suggest  \nthat there is a correlation with paired data associated by some \nnonlinear relationship, so the regression equation would not be a \nsuitable model for making predictions.\n\t 3.\t r represents the linear correlation coefficient computed from \nsample paired data; r represents the parameter of the linear \ncorrelation coefficient computed from a population of paired \ndata; rs denotes the rank correlation coefficient computed \nfrom sample paired data; rs represents the rank correlation \ncoefficient computed from a population of paired data. The \nsubscript s is used so that the rank correlation coefficient can \nbe distinguished from the linear correlation coefficient r. The \nsubscript does not represent the standard deviation s. It is used \nin recognition of Charles Spearman, who introduced the rank \ncorrelation method.\n\t 5.\t rs = 1. Critical values are -0.648 and 0.648. Reject the null \nhypothesis of rs = 0. There is sufficient evidence to support a \nclaim of a correlation between ages and heights of trees.\n\t 7.\t rs = 0.857. Critical values: -0.738, 0.738. Reject the null  \nhypothesis of rs = 0. There is sufficient evidence to support \na conclusion that there is a correlation between the number of \nchirps in 1 min and the temperature.\n\t 9.\t rs = 0.624. Critical values: rs = {0.587. Reject the null  \nhypothesis of rs = 0. There is sufficient evidence to support a \nconclusion that there is a correlation between the number of  \ncigarettes smoked and the cotinine level.\n\t11.\t rs = 0.360. Critical values: -0.159, 0.159. Reject the null  \nhypothesis of rs = 0. There is sufficient evidence to support a \nconclusion that there is a correlation between the systolic and  \ndiastolic blood pressure levels in males.\n\t13.\t rs = 0.984. Critical values: -0.269, 0.269. Reject the null  \nhypothesis of rs = 0. There is sufficient evidence to support the \nclaim of a correlation between chest sizes and weights of bears.\n\t15.\t -0.159 and 0.159. (Use either t = 1.975799 from technology \nor use interpolation in Table A-3 with 151 degrees of freedom, \nso the critical value of t is approximately halfway between 1.984 \nand 1.972, which is 1.978.) The critical values are the same as \nthose found by using Formula 13-1.\nChapter 13: Quick Quiz\n\t 1.\t 5, 7, 11, 4, 9.5, 2, 3, 8, 9.5, 1, 6\n\t 2.\t The efficiency rating of 0.91 indicates that with all other factors \nbeing the same, rank correlation requires 100 pairs of sample ob-\nservations to achieve the same results as 91 pairs of observations \nwith the parametric test for linear correlation, assuming that the \nstricter requirements for using linear correlation are met.\n\t 3.\t a. Distribution-free test\n\t \t b. \u0007The term “distribution-free test” suggests correctly that the test \ndoes not require that a population must have a particular distri-\nbution, such as a normal distribution. The term “nonparametric \ntest” incorrectly suggests that the test is not based on a param-\neter, but some nonparametric tests are based on the median, \nwhich is a parameter; the term “distribution-free test” is better \nbecause it does not make that incorrect suggestion.\n\t 4.\t Rank correlation should be used. The rank correlation test is used \nto investigate whether there is a correlation between foot length \nand height.\n\t 5.\t No, the P-values are almost always different, and the conclusions \nmay or may not be the same.\n\t 6.\t Rank correlation can be used in a wider variety of circumstances \nthan linear correlation. Rank correlation does not require a nor-\nmal distribution for any population. Rank correlation can be used \nto detect some (not all) relationships that are not linear.\n\t 7.\t Because the sign test uses only signs of differences while the \nWilcoxon signed-ranks test uses ranks of the differences, the \nWilcoxon signed-ranks test uses more information about the data \nand tends to yield conclusions that better reflect the true nature \nof the data.\n\t 8.\t Kruskal-Wallis test\n\t 9.\t Two independent samples\n\t10.\t Matched pairs\nChapter 13: Review Exercises\n\t 1.\t Use the sign test. The test statistic of z = -4.46 results in a  \nP-value of 0.0000 (Table: 0.0001) and it is less than or equal to \nthe critical value of z = -1.645. Reject the null hypothesis of  \np = 0.5. There is sufficient evidence to support the claim that the \nmajority of adults obtain medical information more often from \nthe Internet than a doctor.\n\t 2.\t The test statistic of x = 3 is less than or equal to the critical \nvalue of 5 (from Table A-7). There is sufficient evidence to war-\nrant rejection of the claim that the sample is from a population \nwith a median equal to 5 min.\n\t 3.\t Test statistic T = 21 is less than or equal to the critical value of \n59. There is sufficient evidence to warrant rejection of the claim \nthat the sample is from a population with a median equal to 5 min.\n\t 4.\t Test statistic: H = 2.5288. P-value = 0.2824. Critical value: \nx2 = 5.991. Fail to reject the null hypothesis of equal medians. It \nappears that times of longevity after inauguration for presidents, \npopes, and British monarchs have the same median.\n\t 5.\t rs = 0.888. Critical values: -0.618, 0.618. Reject the null  \nhypothesis of rs = 0. There is sufficient evidence to support the \nclaim of a correlation between chocolate consumption and the \nrate of Nobel Laureates. It does not make sense to think that there \n",
    "\t\nAppendix D\t\n681\nis a cause>effect relationship, so the correlation could be the re-\nsult of a coincidence or other factors that affect the variables the \nsame way.\n\t 6.\t Test statistic: H = 6.6305. P-value = 0.0363. Critical value: \nx2 = 5.991. Reject the null hypothesis of equal medians.  \nInterbreeding of cultures is suggested by the data.\n\t 7.\t R1 = 60, R2 = 111, mR = 85.5, sR = 11.3248, test statistic: \nz = -2.25. P-value = 0.0244. Critical values: z = {1.96.  \nReject the null hypothesis that the populations have the same \nmedian. Skull breadths from 4000 B.C. appear to have a different \nmedian than those from A.D. 150.\n\t 8.\t rs = 0.714. Critical values: {0.738. Fail to reject the null  \nhypothesis of rs = 0. There is not sufficient evidence to support \nthe claim that there is a correlation between the student ranks \nand the magazine ranks. When ranking colleges, students and the \nmagazine do not appear to agree.\nChapter 13: Cumulative Review Exercises\n\t 1.\t x = 14.6 credit hours, median = 15.0 credit hours, s = 1.7 \ncredit hours, s2 = 2.9 (credit hours)2, range = 6.0 credit hours\n\t 2.\t a. Convenience sample\n\t \t b. \u0007Because the sample is from one class of statistics students, it is \nnot likely to be representative of the population of all full-time \ncollege students.\n\t \t c. Discrete\n\t \t d. Ratio\n\t 3.\t H0: m = 14 credit hours. H1: m 7 14 credit hours. Test statistic: \nt = 1.446. P-value = 0.0822 (Table: 70.05). Critical value: \nt = 1.729 (assuming a 0.05 significance level). Fail to reject \nH0. There is not sufficient evidence to support the claim that the \nmean is greater than 14 credit hours.\n\t 4.\t The test statistic of x = 5 is not less than or equal to the critical \nvalue of 4. There is not sufficient evidence to support the claim \nthat the sample is from a population with a median greater than \n14 credit hours.\n\t 5.\t 13.8 credit hours 6 m 6 15.3 credit hours. We have 95% con-\nfidence that the limits of 13.8 credit hours and 15.3 credit hours \ncontain the true value of the population mean.\n\t 6.\t 3.1% 6 p 6 4.7%. We have 95% confidence that the limits of \n3.1% and 4.7% actually contain the true percentage of the popu-\nlation of workers who test positive for drugs.\n\t 7.\t H0: p = 0.03. H1: p 7 0.03. Test statistic: z = 2.36.  \nP-value: 0.0091. Critical value: z = 1.645. Reject H0. There is \nsufficient evidence to support the claim that the rate of positive \ndrug test results among workers in the United States is greater \nthan 3.0%.\n\t 8.\t 2401\n\t 9.\t H0: p = 0.5. H1: p 7 0.5. Test statistic: z = 1.36. P-value: 0.0865 \n(Table: 0.0869). Critical value: z = 1.645. Fail to reject  \nH0. There is not sufficient evidence to support the claim that the \nmajority of the population is not afraid of heights in tall build-\nings. Because respondents themselves chose to reply, the sample \nis a voluntary response sample, not a random sample, so the  \nresults might not be valid.\n\t10.\t There must be an error, because the rates of 13.7% and 10.6% are \nnot possible with samples of size 100.\nChapter 14 Answers\nSection 14-1 \n\t 1. \tA cohort life table is a record of the actual observed mortality \nexperience for a particular group, whereas a period life table de-\nscribes mortality and longevity data for a hypothetical group that \nwould have lived with the same mortality conditions throughout \ntheir lives.\n\t 3. \tThe values in columns 3 through 6 would be halved, but the \nother values would remain the same.\n\t 5. \t0.000382\n\t 7. \t0.99491\n\t 9. \t0.999256; 4996.28 people (or 0.999252; 4996.26)\n\t11.\t 0.840024\n13.\t a.  0.006550    b. 0.000483\n\t\n\t The results are so different because of the exceptionally high \nmortality rate at or very near birth.\n15. \t2–4; 0.000483; 99,345; 48; 198,638; 7,667,195; 77.2\n17. \tUsing H1: p 7 0.000744, the test statistic is z = 1.87, the \nP-value is 0.0308 (Table: 0.0307), and the critical value is \nz = 1.645, so reject the null hypothesis of p = 0.000744 and \nconclude that there is sufficient evidence to support the claim \nthat the number of deaths is significantly high. [If the probability \nof dying is calculated from the third column of Table 14-1, use \nH1: p 7 0.00074815 to get a test statistic of z = 1.85, a P-value \nof 0.0323 (Table: 0.0322), and the same critical value and  \nconclusions.]\n19. \tUsing H1: p 7 0.011198 the test statistic is z = 4.95, the \nP-value is 0.0000 (Table: 0.0001), and the critical value is \nz = 1.645, so reject the null hypothesis of p = 0.011198 and \nconclude that there is sufficient evidence to support the claim \nthat the number of deaths is significantly high.\nSection 14-2 \n\t 1. \tA survivor is a subject that successfully lasted throughout a par-\nticular time period without reaching some terminating event. A \nsurvivor could be a person or an object or some other entity such \nas a marriage.\n\t 3. \tA life table is based on fixed intervals of time, but a table of sur-\nvival data and Kaplan-Meier calculations is based on times that \nvary according to the terminating event.\n\t 5. \tThe fast walkers are more likely to be healthier with greater lon-\ngevity, so they correspond to the top (green) curve. The moderate \ngroup corresponds to the middle (black) curve. The slow group \nof walkers is more likely to have health issues with lower longev-\nity, so they correspond to the bottom (red) curve.\n\t 7.\t a.  4 years    b.   1 year\n\t 9. \tThe five-year survival rates are 0.2 for the group of slow walkers, \n0.5 for the group with moderate walking speeds, and 0.9 for the \ngroup of fast walkers. The differences are substantial, and they \nsuggest that after five years, those with faster walking speeds \nhave much greater survival rates, and those with slow walking \nspeeds have much lower survival rates.\n\t\n\t \t\nThe data do not necessarily suggest that we can get older \npeople to live longer by somehow getting them to walk faster. It’s \nvery possible that walking speed is one manifestation of overall \n",
    "682\t\nAppendix D\n\t 7.\t\n\t 8. \tThe treatment group and the placebo group appear to have ap-\nproximately the same behavior. The treatment does not appear to \nbe effective.\nChapter 14: Cumulative Review Exercises\n\t 1. \tThe table shows that among 100,000 births, 99,492 sur-\nvived to the second birthday, so the probability of dying is \n1 - 0.99492 = 0.00508. Using H1: p 6 0.00508, the test statis-\ntic is z = -0.67, the P-value is 0.2501 (Table: 0.2514), and the \ncritical value is z = -1.645 (assuming a 0.05 significance level), \nso fail to reject the null hypothesis of p = 0.00508 and conclude \nthat there is not sufficient evidence to support the claim that the \nproportion of deaths is less than 0.00508. The program does not \nappear to be effective in reducing the mortality rate.\n\t 2.\t 0.99294 6 p 6 0.99953; the confidence interval limits contain \n0.99492, so it appears that the mortality rate has not been lowered \nby a significant amount.\n\t 3. \t0.986\n\t 4. \t0.0188; no, because being in the same family causes the events \nto be dependent, instead of being independent, as required by the \nmultiplication rule. It is reasonable to expect that four Hispanic \nfemales in the same family are more likely to experience similar \nenvironmental and hereditary characteristics.\n\t 5. \tThe graph is misleading. The vertical scale begins with a fre-\nquency of 800 instead of 0, so the difference between the “yes” \nand “no” responses is greatly exaggerated.\n\t 6.\t a.  99.89% (Table: 99.88%)\t\nb.  0.1587\nhealth status, so longevity and walking speed are likely both af-\nfected by one or more other extraneous variables.\n\t11.\t\n\t13.\t The graph does not show any information about the six censored \nsurvival times. The graph shows information about the two sur-\nvival times that were not censored.\nChapter 14: Quick Quiz\n\t 1.\t Life table\n\t 2.\t Survival table with Kaplan-Meier calculations\n\t 3.\t A period life table describes mortality and longevity data for a \nhypothetical group that would have lived with the same mortality \nconditions throughout their lives.\n\t 4.\t A cohort life table is a record of the actual observed mortality \nexperience for a particular group.\n\t 5.\t False\t\n\t 6.\tTrue\n\t 7.\t False\t\n\t 8.\tTrue\n\t 9.\t The entries are 1, 0, 0, and 0.\t\n10.\t0.999345\nChapter 14: Review Exercises\n\t 1.\t 0.000352\t\n2.\t 35\t\n3.\t 0.99492\n\t 4.\t 0–2; 0.00508; 100,000; 508; 199,098; 8,382,303; 83.8\n\t 5.\t 83.8 years; 83.2 years; the second value is less than the first \nvalue. As we age, our expected remaining lifetime steadily \n­decreases.\n6.\n \n \n \n \n \nDay\n \n \n \nStatus  \n0 = Censored \n1 = Failed\n \n \n \nNumber \nof  \nPatients\n \n \nPatients  \nNot  \nRequiring \nRetreatment\n \nProportion of \nPatients  \nNot  \nRequiring \nRetreatment\nCumulative \nProportion  \nof Patients  \nNot  \nRequiring \nRetreatment\n  3\n1\n4\n3\n3>4 = 0.75\n0.75\n12\n1\n3\n2\n2>3 = 0.667\n       0.5\n20\n1\n2\n1\n1>2 = 0.5\n0.25\n30\n0\n",
    "Credits\nPhotos\nChapter 1\nP1, Wavebreakmedia/Shutterstock;  P5, Gary Blakeley Shutterstock;  P6, USBFCO/Shutterstock;  P9, Wavebreakmedia/Shutterstock;  P15, Khamidulin \nSergey/Shutterstock;  P15, Suppakij1017/Shutterstock;  P18, Dotshock/Shutterstock;  P19, 18percentgrey/Shutterstock;  P21, Ollyy/Shutterstock;   \nP25, Andersen Ross/Stockbyte/Getty Images;  P26, Triff/Shutterstock;  P27, Fujji/Shutterstock\nChapter 2\nP40, Kodda/Shutterstock;  P43, Monkey Business Images/Shutterstock;  P53, Valua Vitaly/Shutterstock;  P58, Stockbyte/Getty Images;  P67, Dmitriy \n­Eremenkov. Shutterstock\nChapter 3\nP75, Toysf400/Shutterstock;  P79, Image Point Fr/Shutterstock;  P90, Kitch Bain/Shutterstock;  P91, Ariwasabi/Shutterstock;  P104, Sergey Nivens/ \nShutterstock\nChapter 4\nP118, Sculpies/Shutterstock;  P121, Photomatz/Shutterstock;  P123, Africa Studio/Shutterstock;  P123, Monkey Business Images/Shutterstock;   \nP123, Pakhnyushchy/Shutterstock;  P126, Bochkarev Photography/Shutterstock;  P132, Vitalinka/Shutterstock;  P145, Africa Studio/Shutterstock;   \nP148, Alexander Raths/Shutterstock;  P154, Eric Isselee/Shutterstock\nChapter 5\nP180, Katrina Elena Trninich/123RF;  P189, Kzenon/Shutterstock;  P195, JHDT Stock Images/Shutterstock;  P215, Alfred Eisenstaedt/The LIFE Picture \nCollection/Getty Images;  P215, Wikimedia Commons\nChapter 6\nP216, Mikael Damkier/Shutterstock;  P233, RGtimeline/Shutterstock;  P255, Ciurea Adrian/Shutterstock;  P263, Triff/Shutterstock\nChapter 7\nP282, Pearson Education, Inc.;  P285, Mama_mia/Shutterstock;  P287, Roland IJdema/Shutterstock;  P301, Eric Isselee/Fotolia;  P304, Robin W/Shutterstock;  \nP325, Andresr/Shutterstock\nChapter 8\nP336, Monkey Business Images/Shutterstock;  P339, Viktoria/Shutterstock;  P344, Azuzl/Shutterstock;  P346, Alexey Burmakin/123RF;   \nP355, David H.Seymour/Shutterstock;  P357, ­Suravid/Shutterstock;  P359, Elena Stepanova/Shutterstock;  P368, B Calkins/Shutterstock;   \nP369, Laborant/Shutterstock;  P371, Zentilia/Shutterstock\nChapter 9\nP392, Andresr/Shutterstock;  P409, Amy Walters/Shutterstock;  P412, Pressmaster/Shutterstock;  P421, D7INAMI7S/Shutterstock;  P423, Andrey Arkusha/\nShutterstock\nChapter 10\nP442, Lightwise/Shutterstock;  P448, Africa Studio/Shutterstock;  P464, Zffoto/Shutterstock;  P466, Leah-Anne Thompson/Shutterstock;   \nP477, Steve Snowden/Shutterstock\nChapter 11\nP502, Racorn/Shutterstock;  P505, Alex Kalashnikov/Shutterstock;  P508, Dundanim/Shutterstock;  P509, Serhiy Shullye/Shutterstock;   \nP517, Lenetstan/Shutterstock;  P520, Tatiana Popova/Shutterstock\nChapter 12\nP531, Bikeriderlondon/Shutterstock\nChapter 13\nP560, karen Roach/Shutterstock;  P595, Sinisa Botas/Shutterstock\nChapter 14\nAsianShow/Shutterstock\nCover\nRobert Essel NYC/Getty Images\nFM\niii, Marc Triola;  iii, Mario F. Triola;  iv, Jason Roy\n683\n",
    "684\t\nCredits\nText\nChapter 1\nP9, Dell Pub. Co\nChapter 4\nP154, Sir Arthur Stanley Eddington\nChapter 14\nP606–607, U.S. Department of Health and Human Services;  P610, U.S. Department of Health and Human Services;  P612, U.S. Department of Health  \nand Human Services;  P620, U.S. Department of Health and Human Services;  P622, U.S. Department of Health and Human Services\nAppendix B\nP639, Dr. Steven Wasserman, Dr. Philip Mackowiak, and Dr. Myron Levine;  P639, National Center for Health Statistics;  P640, National Center for  \nHealth Statistics;  P642, Hoffman, D. J., Policastro, P., Quick, V., and Lee, S. K., Changes in Body Weight and Fat Mass of Men and Women in the First  \nYear of College: A Study of the Freshman 15. Journal of American College Health, July 1, 2006, Vol. 55, No. 1, p. 41. Copyright © 2006. Reprinted by \nPermission;  P643, Federal Trade Commission;  P643, National Center for Health Statistics\nMulti: Statdisk screenshots, Triola Statdisk (c) Triola Stats. All rights reserved;  TI-83/84 Plus screenshots, Texas Instruments\nBarrelfold \nP4, Handbook of Statistical Tables, Addison-Wesley Pub. Co.\n",
    "685\nINDEX\nA\nAbnormal populations, 372–373\nAbridged life table, 609–611\nAbsolute risk reduction, 154\nAcceptance sampling, 204\nActive smoke, 643\nActual odds against, 157\nActual odds in favor, 157\nAddition rule, 140\ncomplementary events and, 134\ndisjoint events and, 133\nformal, 131–132\nintuitive, 131–132\nnotation for, 131–132\nAdjusted coefficient of determination, 483\nAdjusted rates, 164\nAlcohol, 643\na, 285–287, 342, 348–349\nAlternative hypothesis\ncontingency tables, 515\ndefinition, 341\ngoodness-of-fit test, 504\nAnalysis of variance (ANOVA). See ­One-way analysis of \n­variance, Two-way analysis of variance\nApproximations, 124\nArea\ncritical values, 228\ncumulative, 221\nwith nonstandard normal distribution, 232\nprobability and, 219, 220, 222\nsignificance and, 236–237\nbetween two boundaries, 221\nvalues from known, 235–237\nbetween z scores, 225\nz scores from known, 225–228\nArithmetic mean. See Mean\nAspirin, 339\nAssumptions, 398\n“At least one,” 144–145\nAttribute data, 14\nAudiometry data, 640\nAutomobile accidents, 67\nAverage, 79. See also Center\nB\nBar graphs, 58\nBayes’ theorem, 148–150\nBear measurements, 642\nBell-shaped distribution histogram, 53\nBenford’s law, 508–509\nb, 348–349\nBias\nin data, 21\nin internet surveys, 285\npublication, 7\nsurvivorship, 5\nBiased estimator, 91, 97, 247\nBig data, 15\napplications of, 19\ndefinition, 19\njobs in, 20\nBimodal, 80\nBinomial, Poisson as approximation to, 208–209\nBinomial probabilities, 625\nBinomial probability distributions\nbasics of, 193–198\nin claims testing, 354\ncontinuous, 269\ndefinition, 194\ndiscrete, 269\nmethods for finding, 195–197\nnormal distribution as approximation to, 270\nnotation for, 194, 269\nrationale for formula, 200–201\ntechnology, 197, 273–274\nBipolar depression, 415\nBirths, 639\ngender probabilities, 125\nBivariate data, 444\nBladder cancer, 523\nBlinding, 26\nBlocks, 29\nBlood pressure, 33, 177, 377, 460–461, 473–474,  \n480, 618\nBody data, 639\nBody mass index, 115, 278, 387, 416\nBody temperatures, 639\nBonferroni multiple comparison test, 540–541\nBootstrapping\nfor confidence interval estimate, 325–326\ndistribution-free method, 324–325\nnonparametric method, 324–325\nproportions, 326–327\nBootstrap resampling, 372–373\nBootstrap sample, 325\nBoundary, class, 42\nBox-and-whisker diagram, 108\nBoxplots, 102–111\nconstruction of, 109\ndefinition, 108–109\nskewness of, 109\nBrain size, 641\n",
    "686\t\nIndex\nC\nCar chases, 67\nCar safety, 505\nCase-control study, 28\nCategorical data, 14\nin frequency distributions, 44–45\nCausation\ncorrelation and, 8, 66\ninterpreting with, 453\nCause-specific death rate, 166\nCell phones, 352, 404, 499, 522\nCell phones and cancer, 131, 276\nCensored data, 614\nCensus, 4\nCenter\nof data, 51\nmeasures of, 77–84\nCentral limit theorem, 259–260\napplication of, 254–256\ndefinition, 252\nfinite population correction, 257–258\nfuzzy, 255\nkey elements of, 253\nsampling distribution and, 253\nChi-square distribution\nin claims testing, 378–379\ndefinition, 315\nin population standard deviation, 315–318\nin population variance, 315–318\nproperties of, 378–379\nvalues, 629\nChi-square test of homogeneity, 519\nCholesterol, 211–212, 322, 375, 553\nCigarette contents, 643. See also Smoking\nClaimed distribution, 505–506\nClaims testing\nwith abnormal populations, 372–373, 382\nalternative method, 382\nbinomial distribution in, 354\nchi-square distribution in, 378–379\nconfidence interval method for, ­357–359, 371,  \n381–382\ncritical value in, 354, 357, 359, 370, 380–381\nequivalent methods, 355, 366–367, 378\nexact method, 359–361\nabout means, 366–373\nnormal approximation method, ­354–359\nnormality in, 367\nnotation, 354, 367, 377\nabout population proportion, 354–361\nP-value in, 354, 355, 368–369\nrequirements, 354, 367, 378\nabout standard deviation, 377–382\nstudent t distribution in, 367–368\ntechnology in, 355–356\ntest statistic in, 354, 367, 378\nabout variance, 377–382\nXSORT method, 355\nClass boundaries, 42\nClassical approach to probability, 123\nClass limits, 42\nClass midpoints, 43\nClassroom length, 335, 390\nClass width, 43\nClinical trials, 25, 466\nalternatives to, 517\nCloning, 180, 297\nClopper-Pearson method, 294\nCluster sampling, 26\nCoefficient of determination\nadjusted, 483\ndefinition, 478\ninterpreting, 479\nmultiple, 483–484\nprediction interval and, 478\nCoefficient of variation\ndefinition, 96\nround-off rule for, 96\nCohort study, 28\nColumn factor, 549\nCombinations\ndefinition, 168\nmnemonics for, 168\npermutations compared with, 170\nrule, 170\nCommercial jet safety, 508\nComparisons, 318–319\nComplementary events\naddition rule and, 134\ndefinition, 127\nrule of, 134\nComplements, 144–145\nCompletely randomized design, 540\nComposite sampling, 204\nCompound event, 132\nConditional probability\nconfusion of inverse, 147\ndefinition, 145\nformal approach for, 145\nintuitive approach for, 145\nnotation, 145–146\nConfidence coefficient, 285\nConfidence interval, 347\nbetter-performing, 293–294\nbootstrapping for, 325–326\nfor comparisons, 318–319\nconstructing, 289, 295, 302, 318\ncritical values, 286–288\ndefinition, 275, 474\nfor dependent samples, 419–420\nexploration of data with, 305\nformats of, 295\n",
    "\t\nIndex\t\n687\nfor hypothesis tests, 291, 318–319\nindependent samples and, 407, 411\ninterpreting, 286, 304\nmargin of error in, 287–288, 304–305\nfor mean, 324\nmethod, 357–359, 371, 381–382\nnotation, 288, 300, 317\nplus four method, 294\npoint estimate from, 290, 304–305\nin population means, 300, 302, 304\nin population standard deviation, 315\nin population variance, 317–318\nfor proportion, 324, 394, 398–400\nrationale for, 320\nrequirements, 288\nround-off rule for, 288, 300, 318\nWald, 293\nWilson score, 294\nConfidence level, 285, 286\nConfounding, 28\nConfusion of inverse, 147\nContext, 4, 6\nContingency tables, 514–521\nalternative hypothesis, 515\ncritical values in, 515\ndefinition, 514\nexpected frequencies in, 516\nexpected value in, 516–518\nnotation, 515\nnull hypothesis, 515\nobserved frequencies in, 516\nP-values in, 515\nrequirements, 515\ntest statistic in, 515\nContinuity correction\ndefinition, 272\nto exact method of claims testing, 361\nnormal approximations, 270, 272–273\nContinuous binomial probability distributions, 269\nContinuous data, 15–16\nContinuous random variable\ndefinition, 183\nidentification of, 190–191\nContinuous uniform distribution, 229\nConvenience sampling, 26\nCorrelation\nbasic concepts of, 444–456\ncausation and, 8, 66\ncommon errors with, 453\ndefinition, 65, 444\nlinear, 65, 444\nscatterplot and, 65–66\nCorrelation coefficient\nlinear, 65–67, 446–450\nPearson, 634\nPearson product moment, 446\nCount five method, 431–432\nCounting, 167–171\nCounting rule, 167\nCoverage probability, 293\nCritical region\ndefinition, 343\nin hypothesis testing, 343\nWilcoxon signed-ranks test, 576\nCritical thinking, 4–9, 296–297\nmean for, 198–201\nmeasures of center and, 82–83\nrange rule of thumb and, 198\nstandard deviation for, 198–201\nCritical t value, 628\nCritical values\narea, 228\nfor claims testing, 354, 357, 359, 370,  \n380–381\nconfidence interval, 286–288\nin contingency tables, 515\ndecision criteria, 346\ndefinition, 228, 287, 345\nfor dependent samples, 419\nfinding, 295\nhypothesis testing, 340, 342–343, 345\nfor independent samples, 408, 410\nKruskal-Wallis test, 588\none-way analysis of variance, 539, 541\nof Pearson correlation coefficient, 634\nin population mean, 301\nin population standard deviation, 315\nin population variance, 315\nproportion, 398\nrank correlation, 593, 637\nsign test and, 566, 635\nWilcoxon rank-sum test, 582\nof Wilcoxon signed-ranks procedure, 636\nCross-sectional study, 28\nCrude rate, 164\nCuckoo egg lengths, 644\nCumulative area, 221\nCumulative frequency distribution, 45\nCurrent. See Period\nD\nData\nalcohol in movies, 643\nattribute, 14\naudiometry, 640\nbear measurements, 642\nbiased results, 21\nbig, 15, 19–20\nbirths, 639\nbivariate, 444\nbody, 639\nbody temperatures, 639\n",
    "688\t\nIndex\nData (Continued )\nbrain size, 641\ncategorical, 14, 44–45\ncensored, 614\ncenter of, 51\ncigarette contents, 643\nconfidence intervals in exploring, 305\ncontinuous, 15–16\ncuckoo egg lengths, 644\ndefinition, 4, 19\ndiscrete, 15–16\ndistribution of, 51\nfamily heights, 640\nfoot length, 641\nfrequency distributions and, 46–48\nfreshman 15, 642\nheight, 641\nIQ and, 641\niris measurements, 644\nmanatee deaths, 642\nmeasuring, 8–9\nmissing, 20–22\nmissing completely at random, 21\nmissing not at random, 21\nnominal, 568–570\nnormal distributions and, 46\nnumerical, 14, 15–16\npercentiles of, 104–105\nphony, 104\npitfalls in analysis of, 8–9\nPoplar tree weights, 644\nqualitative, 14\nquantitative, 14\nreporting, 8–9\nscience, 19\nset magnitudes, 19\nsignificantly high, 102\nsignificantly low, 102\nsmoking, 643\nsources of, 4, 6, 10\nspread of, 51\nstatistics in, 19\ntransformations, 266, 461\ntypes of, 13–19\nvision, 640\nDeath, 464\ncause-specific rate of, 166\nDegree of confidence, 285\nDegrees of freedom (df), 301\nindependent samples, 408\nin population standard deviation, 315\nin population variance, 315\nDelete cases, 21\nDensity curve, 219\nDependent events, 135\nindependent events and, 195\nDependent samples\nconfidence intervals for, 419–420\ncritical values for, 419\ndefinition, 407\nequivalent methods, 420–421\nexperiment design, 418–423\ninferences about, 419–420\nnotation, 419–420\nP-values for, 419\nrequirements, 419\ntest statistic for, 419–420\nDependent variable, 462\nDepression, 15, 415\nDescriptive statistics, 76\nDeterministic, 462\nDeviation. See also Population standard ­deviation; Standard \ndeviation; Variation\nexplained, 477\ntotal, 477\nunexplained, 477\ndf. See Degrees of freedom\nDiet pills, 409\nDisagreement, 505–506\nDiscordant pairs, 521\nDiscrete binomial probability distributions, 269\nDiscrete data, 15–16\nDiscrete random variable\ndefinition, 183\nidentification of, 190–191\nDisjoint events, 133\nDispersion. See Variation\nDistribution. See specific types \nDistribution-free method, 324–325\nDistribution-free tests. See Nonparametric tests\nDivision by n - 1, 96\nDotplots, 56–57\nDouble-blind experiments, 26\nDrug testing, 412\nDummy variables\ndefinition, 489\nas predictor variable, 489–490\nas response variable, 490–494\nE\nEfficiency rating, 564\nElectrical shock study, 33\nE-mail survey, 31, 330, 364\nEmpirical rule, 231\nEquivalent methods, 355\nErgonomics problems, 260–261\nErrors\nin correlation, 453\nmargin of, 287–288, 304–305\nmaximum error of the estimate, 288\nin multiple regression, 486\nnonrandom sampling, 30\n",
    "\t\nIndex\t\n689\nnonsampling, 30\nsampling, 29–31\nstandard error of estimate, 475\ntype I, 347–349\ntype II, 347–349\nEstimate\nmaximum error of, 288\nstandard error of, 475\nEstimating. See Confidence interval\nEstimators\nbiased, 91, 97, 247\ndefinition, 247\nunbiased, 95, 97, 247, 274–275\nEthics, 477\nEvents. See also Rare event rule\ncomplementary, 127, 134\ncompound, 132\ndefinition, 122\ndependent, 135, 195\ndisjoint, 133\nindependent, 135, 195\nmutually exclusive, 133\nprobability of, 122–126\nsequential, 149\nsimple, 122\nExact method of claims testing, 359–360\ncontinuity correction to, 361\nimproving, 361\nExpected frequencies\nin contingency tables, 516\nin goodness-of-fit test, 504–505\nrationale for, 519\nExpected value\nin contingency tables, 516–518\ndefinition, 186\nrationale for formulas, 189–190\nExperimental units, 25\nExperimenter effect, 26\nExperiments and experiment design\nblinding in, 26\ncompletely randomized, 540\ndefinition, 25\ndependent samples, 418–423\ndouble-blind, 26\ngold standard of, 24–25\nin hypothesis testing, 350–351\none-way analysis of variance, 540\nplacebo effect in, 26\npower and, 350–351\nrandomization and, 26\nreplication in, 25–26\nrigorously controlled, 540\nExplained deviation, 477\nExplained variation, 452–453\nprediction intervals and, 476–478\nExplanatory variable, 462\nF\nFacial variation, 91\nFactorial rule, 167–168\nFactorial symbol, 167\nFalse negative, 119, 149\nFalse positive, 119, 149, 240\nFamily heights, 640\nF distribution, 429–430\nin one-way analysis of variance, 533–534\nin right tail, 630–633\nFertility rates, 162\nFetal death, 162\nFinite populations, 257–258\nFischer, R. A., 536\nFisher’s exact test, 520\n5-number summary, 108\nFluoride, 421\nFoot length data, 641\nFormal addition rule, 131–132\nFormal hypothesis test\nalternative hypothesis in, 453\nnull hypothesis in, 453\none-tailed, 454\nrationale, 454–456\ntest statistic in, 453–454\nFormal multiplication rule, 135\nFractiles, 104\nFrequency. See Expected frequencies\nFrequency distributions, 42–50\ncalculation of means from, 83–84\ncategorical data in, 44–45\nconstructing, 43–45\ncumulative, 45\ndata and, 46–48\ndefinition, 42\npercentage, 45\nrelative, 45\nFrequency polygon, 60\nFrequency tables, one-way, 503\nFreshman 15, 642\nF test\nfor standard deviation, 428–431\nfor variance, 428–431\nFuzzy central limit theorem, 255\nG\nGalton, Francis, 462\nGaps, 47\nGender\nbirth probabilities, 125, 197\ndrug testing and, 412\nselection, 11, 121, 129, 180–181, 297, 335, 359–360,  \n363, 569\nsmoking and, 554, 556\nGenetics, 192–193, 199–200\nGenotypes, 512\n",
    "690\t\nIndex\nGeometric distribution, 206\nGoodness-of-fit test\nalternative hypothesis, 504\nclaimed distribution in, 505–506\ndefinition, 503\nexpected frequencies in, 504–505\nnotation, 504\nnull hypothesis, 504\nrequirements, 504\ntest statistic for, 504, 508\nGosset, William, 301\nGould, Stephen Jay, 78\nGraphs and graphing, 7\nbar, 58\ndeception and, 61–62\ndotplots, 56–57\nenlightenment and, 56–60\ninteraction, 547–552\nnonzero vertical axis, 61–62\nPareto charts, 58–59\npictographs, 62–63\npie charts, 59–60\npower of, 58\nstemplots, 57\ntime-series, 57–58\nGroup testing, 146\nGrowth charts, 43\nH\nHawthorne effect, 26\nHeart failure, 368\nHeight data, 641\nHistogram\nbasic concepts, 51–53\nbell-shaped distribution, 53\ndefinition, 51\ndistribution shapes, 52–53\nimportant uses of, 51\ninterpretation, 52\nnormal distributions, 52–53, 262\nfor normality determination, 263\nnormal quantile plots and, 262–263\noutliers and, 51\nprobability, 184–185\nrelative frequency, 51–52\nskewness of, 53\nuniform distribution, 53\nHomogeneity, test of, 519–520\nHomoscedasticity, 173\nHormone therapy, 25\nH test. See Kruskal-Wallis test\nHypergeometric distribution, 206\nHypothesis\nalternative, 341, 504, 515\ndefinition, 338\nnull, 341, 504, 515\nHypothesis test, 120\naccept or fail to reject, 346\nalternative methods, 431–432\nbasic concepts of, 338–347\nconfidence interval for, 291, 318–319, 347\ncount five method, 431–432\ncritical region in, 343\ncritical value in, 340, 342–343, 345\ndecision criteria, 346\ndefinition, 338\nequivalent methods, 347\nexperiment design in, 350–351\nfailures and successes in, 399–400\nfinal conclusions, 346–347\nformal, 453–456\nindependent samples and, 407\nintroduction to, 256–257\nLevene-Brown-Forsyth, 432\nmultiple negatives, 346–347\nnotation, 428\noriginal claim in, 341–342\npower of, 349–351\nprobability in, 256–257\nfor proportion, 394, 395–396\nP-value in, 340, 342–343, 343–345\nrare event rule in, 256–257\nrationale for, 400\nrequirements, 428\nsignificance in, 339\nsignificance level in, 342\nstandard deviation in, 428–429\ntechnology in, 339–340\ntest statistic in, 342–343, 429\ntype I and type II errors, 347–349\nvariance in, 428–429\nI\nImpute missing value, 21\nIncidence rates, 155, 156, 163\nIndependence, 135–138\ntest of, 514–515\nIndependent events, 135\ndependent events and, 195\nIndependent samples\nalternative methods, 411–413\nconfidence interval and, 407, 411\ncritical values for, 408, 410\ndefinition, 407\ndegrees of freedom for, 408\nhypothesis testing and, 407\nnotation, 408\nP-values for, 408, 409–410\nrequirements, 408\nsample variances and, 411–412\ntest statistic for, 408\nunknown and not assumed equal, 406–411\n",
    "\t\nIndex\t\n691\nIndependent variable, 462\nInfants, 162\nInferences\nfrom matched pairs, 418–424\nfrom mean, 406–413\nfrom proportions, 394–400\nfrom variance, 428–432\nInferential statistics, 127–128\nrare event rule for, 188–189, 256–257\nInfluential points, 468\nInteraction\ndefinition, 547\neffects, 548\ngraph, 547–552\nInternet surveys, bias in, 285\nInterquartile range, 108\nInterval estimate. See Confidence interval\nInterval level of measurement, 17\nIntuition, probability and, 121\nIntuitive addition rule, 131–132\nIntuitive multiplication rule, 135\nIQ, 641\nIris measurement, 644\nJ\nJet engines, 186\nJobs in big data, 20\nK\nKaplan-Meier survival analysis, 614–617\ndefinition, 614\nfor specific time period, 617\nKruskal-Wallis test\ncritical values, 588\ndefinition, 587\nnotation, 587\nprocedure for, 588–590\nrationale, 590\nrequirements, 587\nright-tailed, 587\ntest statistic, 588\nfor three or more samples, 586–590\nL\nLarge numbers, law of, 124\nLast digits, 46–47\nLaw of large numbers, 124\nLead pollution, 531\nLeast-squares property\ndefinition, 469\nin regression, 468–469\nLeft-handedness, 359\nLeftmost residual plots, 470\nLeft-tailed test, 343\nLevene-Brown-Forsyth test, 432\nLie detectors, 358\nLife insurance, 604–605\nLife tables\nabridged, 609–611\napplications of, 609–611\nperiod, 605–609\nprobability in, 611\nLimits. See also Central limit theorem\nlower class, 42\nupper class, 42\nLinear correlation\ndefinition, 65, 444\nfinding, 450–452\ninterpretation, 452–453\nstrength of, 446–448\ntesting for, 459–461\nLinear correlation coefficient, 65, 66\ncalculating, 448–450\ndefinition, 67, 446\ndetermining, 67–68\nformulas, 447\ninterpreting, 446–447\nnotation, 446\nproperties, 448\nrequirements, 446\nrounding, 447\nLinear regression, 65\nLinear relationships, 481\nLipitor, 161\nLogistic regression\ndefinition, 490\nmultiple, 492–493\nsimple, 490–491\nLognormal distribution, 266\nLongitudinal study, 28\nLower class limits, 42\nLung cancer, 159–160, 512–513, 603\nLurking variables, 25\nM\nMAD, 95–96\nManatee deaths, 479, 642\nMann-Whitney U test, 581\nMarginal change\ndefinition, 467\nin regression equation, 467\nMargin of error\nin confidence interval, 287–288, 304–305\ndefinition, 288\nMatched pairs\nclaims about, 567–568, 575–578\ndefinition, 407\ndesign, 29\ninferences from, 418–424\nMcNemar’s Test for, 520–521\nWilcoxon signed-ranks test and, 575–578\nMaximum error of the estimate, 288\n",
    "692\t\nIndex\nMcNemar’s test, 520–521\nMean. See also Population mean\nbootstrapping, 327–328\ncalculation of, 78–79\ncalculation of, from frequency distribution,  \n83–84\nclaims testing about, 366–373\nconfidence interval for, 324\nfor critical thinking, 198–201\ndefinition, 77\nimportant properties of, 77–78\ninferences about, 407–408\ninferences from, 406–413\nnotation of, 78–79\nfor probability distribution, 185\nresistant, 78\nsample, 243–245\ntest statistic and, 539\ntrimmed, 88\nweighted, 84\nMean absolute deviation (MAD), 95–96\nMeasurement\ninterval level of, 17\nlevels of, 16–19\nnominal level of, 16\nordinal level of, 16–17\nratio level of, 17\nunits of, 14–15\nMeasures of center. See also Mean; Median;  \nMode\nadvanced techniques, 83–84\nbasic concepts of, 77–84\ncritical thinking and, 82–83\nrounding, 81–82\nround-off rule for, 81\nMedian\ncalculation of, 79\nclaims about, of single population, 570–572, 579\ndefinition, 79\nimportant properties of, 79\nnotation of, 79\nMendel, Gregor, 270–271\nMeta-analysis, 369\nMiddle residual plots, 470\nMidpoints, class, 43\nMidquartile, 108\nMidrange\ndefinition, 81\nimportant properties of, 81\nMilgram, Stanley, 33\nMisleading conclusions, 8\nMissing completely at random, 21\nMissing data, 20–22\ncorrecting for, 21\nMissing not at random, 21\nMissing values, 21\nMode\ndefinition, 80\nfinding, 80\nimportant properties of, 80\nno, 80\ntwo, 80\nModified boxplots, 110–111\nMonkey typists, 154\nMorbidity rates, 163\nMortality rates, 162, 605\nMultimodal, 80\nMultinomial distribution, 206\nMultiple-choice questions, 150, 174\nMultiple coefficient of determination, 484\ndefinition, 483\nformula, 483\nMultiple comparison tests, 540\nMultiple logistic regression, 492–493\nMultiple regression, 481–488\ncommon errors involving, 486\nMultiple regression equation\ndefinition, 481\nfinding, 482\nguidelines, 484–486\nnotation, 482\nprocedure for, 482\nP-value, 484\nrequirements, 482\nMultiplication counting rule, 167\nMultiplication rule, 140\napplications of, 138–139\nformal, 135\nindependence and, 135–138\nintuitive, 135\nnotation for, 134–135\nrationale for, 139\nredundancy and, 138–139\nMultistage sampling, 27–28\nMutually exclusive events, 133\nN\nNegative predictive value, 119\nNegative terms, 346\nNegative z-scores, 626\nNeonatal death, 162\nNeonates, 162\nNewborn discharge, 157–158\nNicotine patch, 365\nNightingale, Florence, 60\nNNT. See Number needed to treat\nNominal data, 568–570\nNominal level of measurement, 16\nNonlinear pattern\ndetecting, 596–597\nin rank correlation, 596–597\nNonparametric method of bootstrapping, 324–325\n",
    "\t\nIndex\t\n693\nNonparametric tests, 571\nadvantages, 562\ndefinitions, 562\ndisadvantages, 562\nefficiency of, 563\nNonrandom sampling error, 30\nNonresponse, 9\nNonsampling error, 30\nNonstandard normal distribution, 232\nNonzero vertical axis, 61–62\nNormal approximations, 275–276\nbinomial distributions and, 270\ncontinuity correction, 270, 272–273\nrationale for, 269–270\nNormal distribution\nchoosing, 308\ndata and, 46\ndefinition, 218\nformulas for, 221\nhistogram, 52–53, 262\nnormal quantile plots in, 262\noutliers in, 262\npopulation mean and, 308\nrequirements, 270\nNormality\nadvanced methods of determining, 263\nassessment feature, 265\nassessment of, with normal quantile plots, 53–54\nbasic concepts in, 261–263\nin claims testing, 367\ndata transformations, 266\nhistograms for, 263\nnormal quantile plots for, 263\nin population mean, 301\nskewness and, 263\ntwo-way analysis of variance, 548\nNormal probability plot, 261\nNormal quantile plots, 261\nconstruction of, 268\ndefinition, 262\nhistograms and, 262–263\ninterpreting, 267–268\nmanual construction of, 263–265\nin normal distributions, 262\nnormality assessed with, 53–54\nfor normality determination, 263\nNotation\nfor addition rule, 131–132\nfor binomial probability distributions, 194, 269\nclaims testing, 354, 367, 377\nconditional probability, 145–146\nconfidence interval, 288, 300, 317\ncontingency tables, 515\ndependent samples, 419–420\ngoodness-of-fit test, 504\nindependent samples, 408\nKruskal-Wallis test, 587\nlinear correlation coefficient, 446\nof mean, 78–79\nof median, 79\nmultiple regression equation, 482\nfor multiplication rule, 134–135\nof percentiles, 105–106\nfor probability, 122\nrank correlation, 593\nof regression equation, 463\nfor sample proportion, 243\nin sample size, 291–292, 306\nfor sampling distribution, 254\nsign test, 566\nvariance, 95\nWilcoxon rank-sum test, 582\nin Wilcoxon signed-ranks test, 575\nNull hypothesis\ncontingency tables, 515\ndefinition, 341\ngoodness-of-fit test, 504\nNumber needed to treat (NNT)\ndefinition, 156\nround-off rule, 156\nNumerical data, 14\ndefinition, 15–16\nO\nObservational studies, 25\nObserved frequencies in contingency tables, 516\nOdds, 153–160\nactual, against, 157\nactual, in favor, 157\npayoff, 157\nratio, 158–159\nOne-tailed tests, 454–455\nOne-way analysis of variance, 533–542\nbasics of, 534–537\ncalculations, 537–542\ncritical values in, 539, 541\ndefinition, 534\ndifferent means in, 540–541\nexperiment design, 540\nF distribution in, 533–534\nP-values, 541\nrequirements, 534\ntesting procedure, 534\nOne-way frequency table, 503\nOrdinal level of measurement, 16–17\nOutliers\ndefinition, 468\nhistograms and, 51\nidentification of, 110\nmodified boxplots and, 110–111\nin normal distributions, 262\nin regression, 468\n",
    "694\t\nIndex\nP\nPalm reading, 448\nParameter, 13\nParametric tests, 571\ndefinitions, 562\nPareto charts, 58–59\nPassive smoke, 643\nPayoff odds, 157\nPearson correlation coefficient, 634\nPearson product moment correlation coefficient,  \n446\nPercentage frequency distribution, 45\nPercentages, 9\nprobabilities as, 124\nPercentiles, 107\nconversion of, 105–106\nof data values, 104–105\nfinding, 105\nnotation, 105–106\nPerinatal mortality, 162\nPeriod life table, 605–609\ncomponents of, 608–609\ndefinition, 605\nPermutations\ncombinations compared with, 170\ndefinition, 168\nmnemonics for, 168\nPermutations rule, 168–169\nPhony data, 104\nPictographs, 62–63\nPie charts, 59–60\nPlacebo effect, 263\nin experiments, 26\nPlus four method, 294\nPoint estimate\nfrom confidence interval, 290, 304–305\ndefinition, 274\nfor population mean, 300\nin population standard deviation, 315\nunbiased estimator in, 274–275\nPoisson probability distribution\nas approximation to binomial,  \n208–209\ndefinition, 207\nparameters of, 207\nproperties of, 207\nrequirements, 207\nPolice deaths, 67\nPolio vaccine, 153–157, 389, 529\nPoll conduction, 287, 510\nPolygon, frequency, 60\nPooled sample proportion, 394\nPoplar tree weights, 644\nPopulation\nabnormal, 372–373\nclaims about median of, 570–572, 579\nclaims testing with abnormal, 372–373, 382\ndefinition, 4\nfinite, 257–258\nlarge, 136\nin sample size, 306\nsampling from different, 519–520\nstandard deviation of, 94\ntotal, 605, 606\nvariance of, 94–95\nPopulation mean\nconfidence interval in, 300, 302, 304\ncritical values in, 301\nestimation of, 299–309\nnormal distributions and, 308\nnormality in, 301\npoint estimate for, 300\nsample size in, 305–307\nstudent t distribution and, 308\nPopulation proportion\nclaims testing about, 354–361\nestimation of, 284–294\nsample size for, 291–292\nPopulation standard deviation, 94–95\nchi-square distribution in, 315–318\nconfidence interval in, 315\ncritical values in, 315\ndegrees of freedom in, 315\npoint estimate in, 315\nsample size in, 320–321\nPopulation variance\nchi-square distribution in, 315–318\nconfidence interval in, 317–318\ncritical values in, 315\ndegrees of freedom in, 315\nsample size in, 320–321\nPositive predictive value, 119\nPositive z-scores, 627\nPosterior probability, 149\nPower, 349–351\nPractical significance, 7–8\nPrediction intervals\ndefinition, 474\nexplained variation and, 476–478\nformulas for, 475\nrequirements, 475\nunexplained variation and, 476–478\nPrediction models, 466\nPredictor variable\ndefinition, 462\ndummy variables as, 489–490\nPregnancy, 240\nPreparation, 4\nPrevalence rate, 119, 163\nPrior probability, 149\nPrisoners, 477\nProbabilistic models, 462\n",
    "\t\nIndex\t\n695\nProbability\narea and, 219, 220, 222\nbasics of, 121–122\nbinomial, 625\nclassical approach to, 123\nconditional, 145–147\ncoverage, 293\nof events, 122–126\nformula, 184\ngender, 125\nin hypothesis testing, 256–257\nidentification of significant results with, 127–128, 188\ninterpreting, 120\nintuition and, 121\nin life tables, 611\nnotation for, 122\nas percentages, 124\nposterior, 149\nprior, 149\nrelative frequency approximation of, 123\nrole of, 120–121\nrounding, 124\nsimulations, 124\nsubjective, 123\nz scores, 221–225\nProbability distribution, 182\nbasic concepts, 183\nbinomial, 193–198\ndefinition, 183\nidentification of, 191–192\nmean for, 185\nparameters of, 185–186\nrequirements, 183–184\nround-off rule for, 186\nstandard deviation for, 185\nvariance for, 185\nProbability histogram, 184–185\nProduct-limit method. See Kaplan-Meier  \nsurvival analysis\nProportion. See also Population proportion\nbad samples in, 399\nbootstrapping, 326–327\nconfidence interval for, 324, 394, 398–400\ncritical value method, 398\nhypothesis test for, 394, 395–396\ninferences about, 394–395\nnotation for two, 394\npooled sample, 394\nP-values and, 396–398\ntechnology and, 398\ntest statistics for, 395\nProportions, inferences from, 394–400\nProsecutor’s fallacy, 145\nProspective study, 28, 159\nPublication bias, 7\nPulse rates, 84\nP-values, 119\nclaims testing, 354–355, 368–369\nin contingency tables, 515\ndecision criteria, 346\ndefinition, 343\nfor dependent samples, 419\nfinding, 344\nhypothesis testing, 340, 342–345\nfor independent samples, 408–410\nin multiple regression equation, 484\none-way analysis of variance, 541\nfor proportion, 396–398\nrank correlation, 593\nsign test and, 566\ntechnology and, 370, 410\ntest statistic and, 536\nWilcoxon rank-sum test, 582\nWilcoxon signed-ranks test, 576\nQ\nQualitative data, 14\nQuantiles, 104\nQuantitative data, 14\nQuartiles\ncalculation of, 107–108, 111\ndefinition, 107\nfirst, 107\nsecond, 107\nthird, 107\nQuestions\nloaded, 8\norder of, 8–9\nR\nRandomization, 26\nRandomized block design, 29\nRandom number problems, 177\nRandom sample, 26\nRandom variable, 183\nRange\ndefinition, 90\nimportant properties of, 90\nRange rule of thumb, 203–204\ncritical thinking and, 198\nidentification of significant results with, 187–188\nfor standard deviation, 92–94\nRange tests, 540\nRank\ndefinition, 563\nhandling ties, 563–564\nRank correlation\nadvantages of, 595\ncritical values, 593, 637\ndefinition, 592\ndisadvantages of, 595\nefficiency of, 595–596\n",
    "696\t\nIndex\nRank correlation (Continued )\nnonlinear pattern in, 596–597\nnotation, 593\nprocedure, 594\nP-values, 593\nrequirements, 593\ntest statistic, 593\nRare event rule, 127–128\nin hypothesis testing, 256–257\nfor inferential statistics, 188–189, 256–257\nRate\nadjusted, 164\ndefinition, 162\nfertility, 162\nmorbidity, 163\nmortality, 162\nspecific, 164\nRatio level of measurement, 17\nRatio test, 18\nRedundancy, 138–139\nRegression, 68–69\nadvanced techniques, 467–471\nbasic concepts, 462–467\ninfluential points in, 468\nleast-squares property in, 468–469\nlogistic, 490–494\nmultiple, 481–488\noutliers in, 468\npredictions and, 472–473\nresidual plots, 469–470\nresiduals in, 468–469\nRegression coefficient, tests of, 486\nRegression equation, 69\ndefinition, 462\nmarginal change in, 467\nnotation of, 463\npredictions with, 466–467\nrequirements, 463\nrounding, 463\nslope of, 463\ntechnology for, 464\ny-intercept in, 463\nRegression line\ndefinition, 69, 462\nfinding equation of, 463\nrequirements, 463\nRelative frequency approximation of ­probability, 123\nRelative frequency distribution, 45\nRelative frequency histogram, 51–52\nRelative frequency polygon, 60\nRelative odds. See Odds\nRelative risk, 154–156\ndefinition, 155\ninterpreting, 155\nfor retrospective studies, 159–160\nRelative standing, 102–111\nReplication, 25–26\nResidual\ndefinition, 468\nin regression, 468–469\nResidual plot\ndefinition, 470\nleftmost, 470\nmiddle, 470\nregression, 469–470\nrightmost, 470\nResistant mean, 78\nResistant statistics, 78\nResponse variable\ndefinition, 462\ndummy variable as, 490–494\nRetrospective studies, 28\nrelative risk for, 159–160\nRightmost residual plots, 470\nRight-tailed test, 343\nRigorously controlled design, 29, 540\nRisk ratio. See Relative risk\nRisks, 153–160\nabsolute, reduction, 154\nrelative, 154–160\nRounding\nlinear correlation coefficient, 447\nmeasures of center, 81–82\nprobabilities, 124\nsample size, 306\nRound-off rule\nfor coefficient of variation, 96\nfor confidence interval, 288, 300, 318\nexceptions to, 186\nfor measures of center, 81\nNNT, 156\nfor probability distribution, 186\nfor sample size, 292, 306\nfor variation, 89\nfor z scores, 102\nRow factor, 549\nRules. See also Round-off rule\naddition, 131–134, 140\nof complementary events, 134\ncounting, 167\nfactorial, 167–168\nmultiplication, 135–140\nmultiplication counting, 167\npermutations, 168–169\nrare event, 127–128, 188–189, 256–257\nRyan-Joiner test, 265–266\nS\nSalk vaccine, 25, 153, 389, 529\nSample\nbad, in proportions, 399\nbootstrap, 325\n",
    "\t\nIndex\t\n697\ndefinition, 4\nKruskal-Wallis test for three or more, 586–590\nrandom, 26\nself-selected, 6\nsimple random, 26\nsmall, 136\nstandard deviation of, 90–92\nvariance between, 538\nvariance of, 94–95, 246\nvariance within, 538\nvoluntary response, 6\nWilcoxon rank-sum test for two ­independent, 581–584\nSample data, collection of, 24–33\nSample mean\nreal applications involving, 253\nsampling distributions of, 243–245\nSample proportion, 398\nbehavior of, 243\nnotation for, 243\nsampling distributions of, 242\nSample size, 78, 313–314\ndetermining, 291–293, 297–298, ­305–307, 323\nnotation in, 291–292, 306\npopulation in, 306\nin population means, 305–307\nfor population proportion, 291–292\nin population standard deviation, 320–321\nin population variance, 320–321\nrequirements, 291–292, 306\nrole of, 293\nrounding, 306\nround-off rule for, 292, 306\nunequal, 539–540\nunknowns, 306\nSample space, 122\nSample variance\nindependent samples and, 411–412\npooling, 411–412\nsampling distributions of, 246\nSampling\nacceptance, 204\ncluster, 26\ncomposite, 204\nconvenience, 26\nfrom different populations, 519–520\nmethod, 4, 6, 10\nmultistage, 27–28\nwith replacement, 136, 249\nwithout replacement, 136\nrequirements, 324\nstratified, 26\nsystematic, 26\nSampling distribution\ncentral limit theorem and, 253\ngeneral behavior of, 241\nnotation for, 254\nof sample mean, 243–245\nof sample proportion, 242\nof sample variance, 246\nof statistic, 242\nof test statistic, 342\nSampling errors, 29–31\ndefinition, 30\nScatter diagram, 65\nScatterplot, 455\ncorrelation and, 65–66\ndefinition, 65\ninterpreting, 445\nSeat belts, 161, 403, 416–417, 505\nSecond-hand smoke, 117, 305–306, 433, 560–561, 589\nSelf-selected sample, 6\nSemi-interquartile range, 108\nSequential events, 149\nSignificance. See also Hypothesis test\narea and, 236–237\nin hypothesis testing, 339\nSignificance level\ndefinition, 342\nin hypothesis testing, 342\nSignificant results\nidentification of, with probability, 127–128, 188\nidentification of, with range rule of thumb,  \n187–188\nSign test\nbasic concept, 564–567\ncritical values and, 566, 635\ndefinition, 564\nnotation, 566\nprocedure, 566\nP-value and, 566\nrequirements, 566\ntest statistic in, 566\nSimple event, 122\nSimple logistic regression, 490–491\nSimple random sample, 26\nSimulations, 124, 177\nSkewness\nof boxplots, 109\nof histograms, 53\nto left, 53\nnormality and, 263\nto right, 53\nSlope, 463\nSmoking, 589\ndata, 643\ngender and, 554, 556\nSocial security, 611\nSort, 57\nSpearmen’s rank correlation test. See Rank correlation\nSpecific rate, 164\nSpread of data, 51\nSquaring, 96\n",
    "698\t\nIndex\nStandard deviation. See also Population  \nstandard deviation\nclaims testing about, 377–382\nfor critical thinking, 198–201\ndefinition, 95\nF test for, 428–431\nin hypothesis test, 428–429\nimportant properties of, 91\nMAD and, 95–96\nfor probability distribution, 185\nrange rule of thumb for, 92–94\nsample, 90–92, 95\nStandard error of estimate, 475\nStandard normal distribution, 220, ­229–230\ndefinition, 221\nStatistical methods, 7\nStatistical significance, 7–8\nStatistical thinking, 4–9\nStatistics\nin data science, 20\ndefinition, 4, 13\ndescriptive, 76\ninferential, 127–128\nresistant, 78\nrole of probability in, 120–121\nsampling distributions of, 242\nvariation in, 200\nStemplots, 57\nStigler, Stephen, 536\nStratified sampling, 26\nStudent t distribution, 301–302\nchoosing, 308\nin claims testing, 367–368\nSubjective probability, 123\nSubjects, 25\nSuccesses, 127–128, 188, 357–358\nSugar, 302\nSurvey pitfalls, 32\nSurvival time, 614\nSurvivors, 614\nSurvivorship bias, 5\nSystematic patterns, 262, 263\nSystematic sampling, 26\nt distribution, 628. See also Student t ­distribution\nT\nTechnology\nbinomial probability distributions, 197\nin hypothesis testing, 339–340\nproportion and, 398\nP-values and, 370, 410\nfor regression equation, 464\nTest of homogeneity, chi-square, 519\nTest of independence\ndefinition, 514\ntest statistic for, 515\nTest of significance. See Hypothesis test\nTest power, 349–351\nTest sensitivity, 119\nTest specificity, 119\nTests of regression coefficients, 486\nTest statistic\ncalculating, 537–538\nin claims testing, 354, 367, 378\nin contingency tables, 515\ndefinition, 342\nfor dependent samples, 419–420\nin formal hypothesis test, 453–454\nfor goodness-of-fit test, 504, 508\nin hypothesis test, 342–343, 429\nfor independent samples, 408\ninterpreting, 430–431\nKruskal-Wallis test, 588\nmean and, 539\nfor proportion, 395\nP-value and, 536\nrank correlation, 593\nrationale for, 510, 573\nsampling distribution of, 342\nin sign test, 566\nfor test of independence, 515\nWilcoxon rank-sum test, 582–584\nWilcoxon signed-ranks test, 576\nThanksgiving Day, 126\nTime-series graphs, 57–58\nTobacco use. See Smoking\nToothpaste, 421\nTotal deviation, 477\nTotal population, 605, 606\nTouch therapy, 282, 285, 289, 364\nTreatment, 534\neffectiveness, 466, 499–500\ngroup, 25, 30\nTree height, 461, 473, 480, 598\nTrimmed mean, 88\nTrue negative, 119\nTrue positive, 119\nTrue zero, 18\nt test. See Student t distribution\nTufte, Edward, 63\nTukey test, 546\nTwins, 423\nTwo-tailed test, 343\nTwo-way analysis of variance, 547–552\ncolumn factor, 549\ninteraction graph and, 547–552\nmeans and, 547–552\nnormality, 548\nprocedure for, 549\nrequirements, 548\nrow factor, 549\nvariation in, 548\n",
    "\t\nIndex\t\n699\nType I errors, 347–349\ncontrolling, 349\nmemory hints for, 348\nType II errors, 347–349\ncontrolling, 349\nmemory hints for, 348\nU\nUltrasound images, 508–509\nUnbiased estimators, 95, 97\ndefinition, 247\nin point estimate, 274–275\nUnderestimation, 97\nUnequal sample sizes, 539–540\nUnexplained deviation, 477\nUnexplained variation, 476–478\nUniform distribution\ndefinition, 219\nhistogram, 53\nUpper class limits, 42\nV\nVaccine problems, 25, 153, 389, 529\nValue of statistical life (VSL), 27\nVariables\ncontinuous random, 183, 190–191\ndependent, 462\ndiscrete random, 183, 190–191\ndummy, 489–494\nexplanatory, 462\nindependent, 462\nlurking, 25\npredictor, 462, 489–490\nrandom, 183\nresponse, 462, 490–494\nVariance. See also Analysis of variance;  \nPopulation variance\nclaims testing about, 377–382\ndefinition, 94\nF test for, 428–431\nin hypothesis test, 428–429\nimportant properties of, 95\ninferences from, 428–432\nnotation, 95\nof population, 94–95\nfor probability distribution, 185\nsample, 94–95, 246\nbetween samples, 538\nwithin samples, 538\nVariation\nadvanced techniques, 95–97\nbasic concepts, 89–95\ncoefficient of, 96–97\ncomparing, 96–97\nexplained, 452–453, 476–478\nin faces, 91\nround-off rule for, 89\nin statistics, 200\nin two-way analysis of variance, 548\nunexplained, 476–478\nViagra, 160–161\nVision data, 640\nVoluntary response sample, 6\nVSL, 27\nW\nWald confidence interval, 293\nWeighted mean, 84\nWeighting, 195\nWeight problems, 8, 482, 487\nWidth, class, 43\nWilcoxon rank-sum test\ncritical values, 582\nnotation, 582\nP-value, 582\nrequirements, 582\ntest statistic, 582–584\nfor two independent samples, 581–584\nWilcoxon signed-ranks test\ncritical region, 576\ncritical values of, 636\ndefinition, 575\nmatched pairs and, 575–578\nnotation, 575\nP-values, 576\nrequirements, 576\ntest statistic, 576\nWildlife, 301\nWilson score confidence interval, 294\nWorld War II, 5, 146, 210\nX\nx. See Sample mean\nXSORT method, 355\nY\nYates’s correction for continuity, 526\ny-intercept, 463\nZ\nZero, true, 18\n0+, notation for, 184\nz scores\narea between, 225\ndefinition, 102\nfrom known areas, 225–228\nnegative, 626\npositive, 627\nprobability, 221–225\nproperties of, 102–103\nround-off rule for, 102\nsignificant values and, 103–104\n",
    "Table A-2  Standard Normal (z) Distribution: Cumulative Area from the LEFT\nz\n.00\n.01\n.02\n.03\n.04\n.05\n.06\n.07\n.08\n.09\n-3.50 and \nlower\n \n.0001\n \n \n \n \n-3.4\n.0003\n.0003\n.0003\n.0003\n.0003\n.0003\n.0003\n.0003\n.0003\n.0002\n-3.3\n.0005\n.0005\n.0005\n.0004\n.0004\n.0004\n.0004\n.0004\n.0004\n.0003\n-3.2\n.0007\n.0007\n.0006\n.0006\n.0006\n.0006\n.0006\n.0005\n.0005\n.0005\n-3.1\n.0010\n.0009\n.0009\n.0009\n.0008\n.0008\n.0008\n.0008\n.0007\n.0007\n-3.0\n.0013\n.0013\n.0013\n.0012\n.0012\n.0011\n.0011\n.0011\n.0010\n.0010\n-2.9\n.0019\n.0018\n.0018\n.0017\n.0016\n.0016\n.0015\n.0015\n.0014\n.0014\n-2.8\n.0026\n.0025\n.0024\n.0023\n.0023\n.0022\n.0021\n.0021\n.0020\n.0019\n-2.7\n.0035\n.0034\n.0033\n.0032\n.0031\n.0030\n.0029\n.0028\n.0027\n.0026\n-2.6\n.0047\n.0045\n.0044\n.0043\n.0041\n.0040\n.0039\n.0038\n.0037\n.0036\n-2.5\n.0062\n.0060\n.0059\n.0057\n.0055\n.0054\n.0052\n.0051\n.0049\n.0048\n-2.4\n.0082\n.0080\n.0078\n.0075\n.0073\n.0071\n.0069\n.0068\n.0066\n.0064\n-2.3\n.0107\n.0104\n.0102\n.0099\n.0096\n.0094\n.0091\n.0089\n.0087\n.0084\n-2.2\n.0139\n.0136\n.0132\n.0129\n.0125\n.0122\n.0119\n.0116\n.0113\n.0110\n-2.1\n.0179\n.0174\n.0170\n.0166\n.0162\n.0158\n.0154\n.0150\n.0146\n.0143\n-2.0\n.0228\n.0222\n.0217\n.0212\n.0207\n.0202\n.0197\n.0192\n.0188\n.0183\n-1.9\n.0287\n.0281\n.0274\n.0268\n.0262\n.0256\n.0250\n.0244\n.0239\n.0233\n-1.8\n.0359\n.0351\n.0344\n.0336\n.0329\n.0322\n.0314\n.0307\n.0301\n.0294\n-1.7\n.0446\n.0436\n.0427\n.0418\n.0409\n.0401\n.0392\n.0384\n.0375\n.0367\n-1.6\n.0548\n.0537\n.0526\n.0516\n.0505\n.0495\n.0485\n.0475\n.0465\n.0455\n-1.5\n.0668\n.0655\n.0643\n.0630\n.0618\n.0606\n.0594\n.0582\n.0571\n.0559\n-1.4\n.0808\n.0793\n.0778\n.0764\n.0749\n.0735\n.0721\n.0708\n.0694\n.0681\n-1.3\n.0968\n.0951\n.0934\n.0918\n.0901\n.0885\n.0869\n.0853\n.0838\n.0823\n-1.2\n.1151\n.1131\n.1112\n.1093\n.1075\n.1056\n.1038\n.1020\n.1003\n.0985\n-1.1\n.1357\n.1335\n.1314\n.1292\n.1271\n.1251\n.1230\n.1210\n.1190\n.1170\n-1.0\n.1587\n.1562\n.1539\n.1515\n.1492\n.1469\n.1446\n.1423\n.1401\n.1379\n-0.9\n.1841\n.1814\n.1788\n.1762\n.1736\n.1711\n.1685\n.1660\n.1635\n.1611\n-0.8\n.2119\n.2090\n.2061\n.2033\n.2005\n.1977\n.1949\n.1922\n.1894\n.1867\n-0.7\n.2420\n.2389\n.2358\n.2327\n.2296\n.2266\n.2236\n.2206\n.2177\n.2148\n-0.6\n.2743\n.2709\n.2676\n.2643\n.2611\n.2578\n.2546\n.2514\n.2483\n.2451\n-0.5\n.3085\n.3050\n.3015\n.2981\n.2946\n.2912\n.2877\n.2843\n.2810\n.2776\n-0.4\n.3446\n.3409\n.3372\n.3336\n.3300\n.3264\n.3228\n.3192\n.3156\n.3121\n-0.3\n.3821\n.3783\n.3745\n.3707\n.3669\n.3632\n.3594\n.3557\n.3520\n.3483\n-0.2\n.4207\n.4168\n.4129\n.4090\n.4052\n.4013\n.3974\n.3936\n.3897\n.3859\n-0.1\n.4602\n.4562\n.4522\n.4483\n.4443\n.4404\n.4364\n.4325\n.4286\n.4247\n-0.0\n.5000\n.4960\n.4920\n.4880\n.4840\n.4801\n.4761\n.4721\n.4681\n.4641\nNOTE: For values of z below -3.49, use 0.0001 for the area.\n*Use these common values that result from interpolation:\nNEGATIVE z Scores\n*\nz Score\nArea\n-1.645\n0.0500\n-2.575\n0.0050\n*\n0\nz\n(continued)\n",
    "POSITIVE z Scores\nTable A-2 (continued)  Cumulative Area from the LEFT\nz\n.00\n.01\n.02\n.03\n.04\n.05\n.06\n.07\n.08\n.09\n0.0\n.5000\n.5040\n.5080\n.5120\n.5160\n.5199\n.5239\n.5279\n.5319\n.5359\n0.1\n.5398\n.5438\n.5478\n.5517\n.5557\n.5596\n.5636\n.5675\n.5714\n.5753\n0.2\n.5793\n.5832\n.5871\n.5910\n.5948\n.5987\n.6026\n.6064\n.6103\n.6141\n0.3\n.6179\n.6217\n.6255\n.6293\n.6331\n.6368\n.6406\n.6443\n.6480\n.6517\n0.4\n.6554\n.6591\n.6628\n.6664\n.6700\n.6736\n.6772\n.6808\n.6844\n.6879\n0.5\n.6915\n.6950\n.6985\n.7019\n.7054\n.7088\n.7123\n.7157\n.7190\n.7224\n0.6\n.7257\n.7291\n.7324\n.7357\n.7389\n.7422\n.7454\n.7486\n.7517\n.7549\n0.7\n.7580\n.7611\n.7642\n.7673\n.7704\n.7734\n.7764\n.7794\n.7823\n.7852\n0.8\n.7881\n.7910\n.7939\n.7967\n.7995\n.8023\n.8051\n.8078\n.8106\n.8133\n0.9\n.8159\n.8186\n.8212\n.8238\n.8264\n.8289\n.8315\n.8340\n.8365\n.8389\n1.0\n.8413\n.8438\n.8461\n.8485\n.8508\n.8531\n.8554\n.8577\n.8599\n.8621\n1.1\n.8643\n.8665\n.8686\n.8708\n.8729\n.8749\n.8770\n.8790\n.8810\n.8830\n1.2\n.8849\n.8869\n.8888\n.8907\n.8925\n.8944\n.8962\n.8980\n.8997\n.9015\n1.3\n.9032\n.9049\n.9066\n.9082\n.9099\n.9115\n.9131\n.9147\n.9162\n.9177\n1.4\n.9192\n.9207\n.9222\n.9236\n.9251\n.9265\n.9279\n.9292\n.9306\n.9319\n1.5\n.9332\n.9345\n.9357\n.9370\n.9382\n.9394\n.9406\n.9418\n.9429\n.9441\n1.6\n.9452\n.9463\n.9474\n.9484\n.9495\n.9505\n.9515\n.9525\n.9535\n.9545\n1.7\n.9554\n.9564\n.9573\n.9582\n.9591\n.9599\n.9608\n.9616\n.9625\n.9633\n1.8\n.9641\n.9649\n.9656\n.9664\n.9671\n.9678\n.9686\n.9693\n.9699\n.9706\n1.9\n.9713\n.9719\n.9726\n.9732\n.9738\n.9744\n.9750\n.9756\n.9761\n.9767\n2.0\n.9772\n.9778\n.9783\n.9788\n.9793\n.9798\n.9803\n.9808\n.9812\n.9817\n2.1\n.9821\n.9826\n.9830\n.9834\n.9838\n.9842\n.9846\n.9850\n.9854\n.9857\n2.2\n.9861\n.9864\n.9868\n.9871\n.9875\n.9878\n.9881\n.9884\n.9887\n.9890\n2.3\n.9893\n.9896\n.9898\n.9901\n.9904\n.9906\n.9909\n.9911\n.9913\n.9916\n2.4\n.9918\n.9920\n.9922\n.9925\n.9927\n.9929\n.9931\n.9932\n.9934\n.9936\n2.5\n.9938\n.9940\n.9941\n.9943\n.9945\n.9946\n.9948\n.9949\n.9951\n.9952\n2.6\n.9953\n.9955\n.9956\n.9957\n.9959\n.9960\n.9961\n.9962\n.9963\n.9964\n2.7\n.9965\n.9966\n.9967\n.9968\n.9969\n.9970\n.9971\n.9972\n.9973\n.9974\n2.8\n.9974\n.9975\n.9976\n.9977\n.9977\n.9978\n.9979\n.9979\n.9980\n.9981\n2.9\n.9981\n.9982\n.9982\n.9983\n.9984\n.9984\n.9985\n.9985\n.9986\n.9986\n3.0\n.9987\n.9987\n.9987\n.9988\n.9988\n.9989\n.9989\n.9989\n.9990\n.9990\n3.1\n.9990\n.9991\n.9991\n.9991\n.9992\n.9992\n.9992\n.9992\n.9993\n.9993\n3.2\n.9993\n.9993\n.9994\n.9994\n.9994\n.9994\n.9994\n.9995\n.9995\n.9995\n3.3\n.9995\n.9995\n.9995\n.9996\n.9996\n.9996\n.9996\n.9996\n.9996\n.9997\n3.4\n.9997\n.9997\n.9997\n.9997\n.9997\n.9997\n.9997\n.9997\n.9997\n.9998\n3.50 and up\n.9999\nNOTE: For values of z above 3.49, use 0.9999 for the area.\n*Use these common values that result from interpolation:\nz score\nArea\n1.645\n0.9500\n2.575\n0.9950\n*\n*\n0\nz\nCommon Critical Values\nConfidence \nLevel\nCritical \nValue\n0.90\n1.645\n0.95\n1.96\n0.99\n2.575\n",
    "Table A-3  t Distribution: Critical t Values\n0.005\n0.01\nArea in One Tail  \n0.025\n0.05\n0.10\nDegrees of  \nFreedom\n0.01\n0.02\nArea in Two Tails \n0.05\n0.10\n0.20\n1\n63.657\n31.821\n12.706\n6.314\n3.078\n2\n9.925\n6.965\n4.303\n2.920\n1.886\n3\n5.841\n4.541\n3.182\n2.353\n1.638\n4\n4.604\n3.747\n2.776\n2.132\n1.533\n5\n4.032\n3.365\n2.571\n2.015\n1.476\n6\n3.707\n3.143\n2.447\n1.943\n1.440\n7\n3.499\n2.998\n2.365\n1.895\n1.415\n8\n3.355\n2.896\n2.306\n1.860\n1.397\n9\n3.250\n2.821\n2.262\n1.833\n1.383\n10\n3.169\n2.764\n2.228\n1.812\n1.372\n11\n3.106\n2.718\n2.201\n1.796\n1.363\n12\n3.055\n2.681\n2.179\n1.782\n1.356\n13\n3.012\n2.650\n2.160\n1.771\n1.350\n14\n2.977\n2.624\n2.145\n1.761\n1.345\n15\n2.947\n2.602\n2.131\n1.753\n1.341\n16\n2.921\n2.583\n2.120\n1.746\n1.337\n17\n2.898\n2.567\n2.110\n1.740\n1.333\n18\n2.878\n2.552\n2.101\n1.734\n1.330\n19\n2.861\n2.539\n2.093\n1.729\n1.328\n20\n2.845\n2.528\n2.086\n1.725\n1.325\n21\n2.831\n2.518\n2.080\n1.721\n1.323\n22\n2.819\n2.508\n2.074\n1.717\n1.321\n23\n2.807\n2.500\n2.069\n1.714\n1.319\n24\n2.797\n2.492\n2.064\n1.711\n1.318\n25\n2.787\n2.485\n2.060\n1.708\n1.316\n26\n2.779\n2.479\n2.056\n1.706\n1.315\n27\n2.771\n2.473\n2.052\n1.703\n1.314\n28\n2.763\n2.467\n2.048\n1.701\n1.313\n29\n2.756\n2.462\n2.045\n1.699\n1.311\n30\n2.750\n2.457\n2.042\n1.697\n1.310\n31\n2.744\n2.453\n2.040\n1.696\n1.309\n32\n2.738\n2.449\n2.037\n1.694\n1.309\n33\n2.733\n2.445\n2.035\n1.692\n1.308\n34\n2.728\n2.441\n2.032\n1.691\n1.307\n35\n2.724\n2.438\n2.030\n1.690\n1.306\n36\n2.719\n2.434\n2.028\n1.688\n1.306\n37\n2.715\n2.431\n2.026\n1.687\n1.305\n38\n2.712\n2.429\n2.024\n1.686\n1.304\n39\n2.708\n2.426\n2.023\n1.685\n1.304\n40\n2.704\n2.423\n2.021\n1.684\n1.303\n45\n2.690\n2.412\n2.014\n1.679\n1.301\n50\n2.678\n2.403\n2.009\n1.676\n1.299\n60\n2.660\n2.390\n2.000\n1.671\n1.296\n70\n2.648\n2.381\n1.994\n1.667\n1.294\n80\n2.639\n2.374\n1.990\n1.664\n1.292\n90\n2.632\n2.368\n1.987\n1.662\n1.291\n100\n2.626\n2.364\n1.984\n1.660\n1.290\n200\n2.601\n2.345\n1.972\n1.653\n1.286\n300\n2.592\n2.339\n1.968\n1.650\n1.284\n400\n2.588\n2.336\n1.966\n1.649\n1.284\n500\n2.586\n2.334\n1.965\n1.648\n1.283\n1000\n2.581\n2.330\n1.962\n1.646\n1.282\n2000\n2.578\n2.328\n1.961\n1.646\n1.282\nLarge\n2.576\n2.326\n1.960\n1.645\n1.282\n",
    "Formulas and Tables by Triola, Triola, and Roy\nCopyright 2018 Pearson Education, Inc.\nTable A-4  Chi-Square (x2) Distribution\nArea to the Right of the Critical Value\nDegrees of \nFreedom\n0.995\n0.99\n0.975\n0.95\n0.90\n0.10\n0.05\n0.025\n0.01\n0.005\n1\n—\n—\n0.001\n0.004\n0.016\n2.706\n3.841\n5.024\n6.635\n7.879\n2\n0.010\n0.020\n0.051\n0.103\n0.211\n4.605\n5.991\n7.378\n9.210\n10.597\n3\n0.072\n0.115\n0.216\n0.352\n0.584\n6.251\n7.815\n9.348\n11.345\n12.838\n4\n0.207\n0.297\n0.484\n0.711\n1.064\n7.779\n9.488\n11.143\n13.277\n14.860\n5\n0.412\n0.554\n0.831\n1.145\n1.610\n9.236\n11.071\n12.833\n15.086\n16.750\n6\n0.676\n0.872\n1.237\n1.635\n2.204\n10.645\n12.592\n14.449\n16.812\n18.548\n7\n0.989\n1.239\n1.690\n2.167\n2.833\n12.017\n14.067\n16.013\n18.475\n20.278\n8\n1.344\n1.646\n2.180\n2.733\n3.490\n13.362\n15.507\n17.535\n20.090\n21.955\n9\n1.735\n2.088\n2.700\n3.325\n4.168\n14.684\n16.919\n19.023\n21.666\n23.589\n10\n2.156\n2.558\n3.247\n3.940\n4.865\n15.987\n18.307\n20.483\n23.209\n25.188\n11\n2.603\n3.053\n3.816\n4.575\n5.578\n17.275\n19.675\n21.920\n24.725\n26.757\n12\n3.074\n3.571\n4.404\n5.226\n6.304\n18.549\n21.026\n23.337\n26.217\n28.299\n13\n3.565\n4.107\n5.009\n5.892\n7.042\n19.812\n22.362\n24.736\n27.688\n29.819\n14\n4.075\n4.660\n5.629\n6.571\n7.790\n21.064\n23.685\n26.119\n29.141\n31.319\n15\n4.601\n5.229\n6.262\n7.261\n8.547\n22.307\n24.996\n27.488\n30.578\n32.801\n16\n5.142\n5.812\n6.908\n7.962\n9.312\n23.542\n26.296\n28.845\n32.000\n34.267\n17\n5.697\n6.408\n7.564\n8.672\n10.085\n24.769\n27.587\n30.191\n33.409\n35.718\n18\n6.265\n7.015\n8.231\n9.390\n10.865\n25.989\n28.869\n31.526\n34.805\n37.156\n19\n6.844\n7.633\n8.907\n10.117\n11.651\n27.204\n30.144\n32.852\n36.191\n38.582\n20\n7.434\n8.260\n9.591\n10.851\n12.443\n28.412\n31.410\n34.170\n37.566\n39.997\n21\n8.034\n8.897\n10.283\n11.591\n13.240\n29.615\n32.671\n35.479\n38.932\n41.401\n22\n8.643\n9.542\n10.982\n12.338\n14.042\n30.813\n33.924\n36.781\n40.289\n42.796\n23\n9.260\n10.196\n11.689\n13.091\n14.848\n32.007\n35.172\n38.076\n41.638\n44.181\n24\n9.886\n10.856\n12.401\n13.848\n15.659\n33.196\n36.415\n39.364\n42.980\n45.559\n25\n10.520\n11.524\n13.120\n14.611\n16.473\n34.382\n37.652\n40.646\n44.314\n46.928\n26\n11.160\n12.198\n13.844\n15.379\n17.292\n35.563\n38.885\n41.923\n45.642\n48.290\n27\n11.808\n12.879\n14.573\n16.151\n18.114\n36.741\n40.113\n43.194\n46.963\n49.645\n28\n12.461\n13.565\n15.308\n16.928\n18.939\n37.916\n41.337\n44.461\n48.278\n50.993\n29\n13.121\n14.257\n16.047\n17.708\n19.768\n39.087\n42.557\n45.722\n49.588\n52.336\n30\n13.787\n14.954\n16.791\n18.493\n20.599\n40.256\n43.773\n46.979\n50.892\n53.672\n40\n20.707\n22.164\n24.433\n26.509\n29.051\n51.805\n55.758\n59.342\n63.691\n66.766\n50\n27.991\n29.707\n32.357\n34.764\n37.689\n63.167\n67.505\n71.420\n76.154\n79.490\n60\n35.534\n37.485\n40.482\n43.188\n46.459\n74.397\n79.082\n83.298\n88.379\n91.952\n70\n43.275\n45.442\n48.758\n51.739\n55.329\n85.527\n90.531\n95.023\n100.425\n104.215\n80\n51.172\n53.540\n57.153\n60.391\n64.278\n96.578\n101.879\n106.629\n112.329\n116.321\n90\n59.196\n61.754\n65.647\n69.126\n73.291\n107.565\n113.145\n118.136\n124.116\n128.299\n100\n67.328\n70.065\n74.222\n77.929\n82.358\n118.498\n124.342\n129.561\n135.807\n140.169\nSource: From Donald B. Owen, Handbook of Statistical Tables.\nDegrees of Freedom\nn - 1\nConfidence Interval or Hypothesis Test for a standard deviation or variance\nk - 1\nGoodness-of-fit test with k different categories\n(r - 1)(c - 1)\nContingency table test with r rows and c columns\nk - 1\nKruskal-Wallis test with k different samples\n",
    "Formulas and Tables by Triola, Triola, and Roy\nCopyright 2018 Pearson Education, Inc.\nCh. 3: Descriptive Statistics\nx = Σx\nn   Mean\nx =\nΣ1f # x2\nΣf\n  Mean (frequency table)\ns = B\nΣ1x - x2 2\nn - 1\n  Standard deviation\ns = B\nn 1Σx22 - 1Σx2 2\nn 1n - 12\n  Standard deviation (shortcut)\ns = B\nn 3Σ1f # x22 4 - 3Σ1f # x2 42\nn 1n - 12\n  Standard deviation  \n(frequency table)\nvariance = s2\nCh. 4: Probability\nP1A or B2 = P1A2 + P1B2  if A, B are mutually exclusive\nP1A or B2 = P1A2 + P1B2 - P1A and B2  \n    if A, B are not mutually exclusive\nP1A and B2 = P1A2 # P1B2  if A, B are independent\nP1A and B2 = P1A2 # P1B0 A2  if A, B are dependent\nP1A2 = 1 - P1A2  Rule of complements\nnPr =\nn!\n1n - r2!  Permutations (no elements alike)\nn!\nn1! n2! c nk!  Permutations (n1 alike, c)\nnCr =\nn!\n1n - r2! r!  Combinations\nCh. 5: Probability Distributions\nm = Σ 3x # P1x2 4  Mean (prob. dist.)\ns = 2Σ 3x2 # P1x2 4 - m2  Standard deviation (prob. dist.)\nP1x2 =\nn!\n1n - x2! x! # px # qn-x  Binomial probability\nm = n # p\t\nMean (binomial)\ns2 = n # p # q\t\nVariance (binomial)\ns = 1n # p # q\t\nStandard deviation (binomial)\nP1x2 = mx # e-m\nx!\nPoisson distribution where \ne = 2.71828\nCh. 6: Normal Distribution\nz = x - m\ns\n or  x - x\ns\n  Standard score\nmx = m  Central limit theorem\nsx =\ns\n2n\n  Central limit theorem (Standard error)\nCh. 7: Confidence Intervals (one population)\npn - E 6 p 6 pn + E  Proportion\n    where E = za>2B\npnqn\nn  \nx - E 6 m 6 x + E  Mean\n    where E = ta>2\ns\n1n  (s unknown)\n    or E = za>2\ns\n1n  (s known)\n1n - 12s2\nx2\nR\n6 s2 6\n1n - 12s2\nx2\nL\n  Variance\nCh. 7: Sample Size Determination\nn =\n3za>2420.25\nE2\n  Proportion\nn =\n3za>242pnqn\nE2\n  Proportion (pn and qn are known)\nn = J\nza>2s\nE\nR\n2\n  Mean\nCh. 8: Test Statistics (one population)\nz = pn - p\nB\npq\nn\n  Proportion—one population\nt = x - m\ns\n1n\n  Mean—one population (s unknown)\nz = x - m\ns\n1n\n  Mean—one population (s known)\nx2 =\n1n - 12s2\ns2\n \n\u0007Standard deviation or variance— \none population\n",
    "(df = smaller of\nn1 - 1, n2 - 1)\n(s1 and s2 unknown and not assumed equal)\nCh. 9: Confidence Intervals (two populations)\n1 pn1 - pn22 - E 6 1 p1 - p22 6 1 pn1 - pn22 + E\n    where E = za>2B\npn1qn1\nn1\n+ pn2qn2\nn2\n1x1 - x22 - E 6 1m1 - m22 6 1x1 - x22 + E  (Indep.)\nwhere E = ta>2B\ns2\n1\nn1\n+ s2\n2\nn2\n \n\t\nE = ta>2B\ns2p\nn1\n+\ns2p\nn2 1df = n1 + n2 - 22\n\t\ns2\np =\n1n1 - 12s2\n1 + 1n2 - 12s2\n2\n1n1 - 12 + 1n2 - 12\n(s1 and s2 unknown but assumed equal)\n\t\nE = za>2B\ns2\n1\nn1\n+ s2\n2\nn2\n\t\n(s1, s2 known)\nd - E 6 md 6 d + E  (Matched pairs)\n\t\nwhere E = ta>2\nsd\n1n \n1df = n - 12\nFormulas and Tables by Triola, Triola, and Roy\nCopyright 2018 Pearson Education, Inc.\nCh. 9: Test Statistics (two populations)\nz =\n1pn1 - pn22 - 1p1 - p22\nB\np q\nn1\n+ p q\nn2\n  Two proportions\np = x1 + x2\nn1 + n2\nt =\n1x1 - x22 - 1m1 - m22\nB\ns2\n1\nn1\n+ s2\n2\nn2\ndf = smaller of  \nn1 - 1, n2 - 1\n    \u0007Two means—independent; s1 and s2 unknown, and not  \nassumed equal.\nt =\n1x1 - x22 - 1m1 - m22\nB\ns2p\nn1\n+\ns2p\nn2\n \n1df = n1 +  n2 - 22\ns2\np =\n1n1 - 12s2\n1 + 1n2 - 12s2\n2\nn1 + n2 - 2\n    \u0007Two means—independent; s1 and s2 unknown, but  \nassumed equal.\nz =\n1x1 - x22 - 1m1 - m22\nB\ns2\n1\nn1\n+ s2\n2\nn2\n  \u0007Two means—independent;  \ns1, s2 known.\nt = d - md\nsd\n1n\n  Two means—matched pairs (df = n - 1)\nF = s2\n1\ns2\n2\n  \u0007Standard deviation or variance— \n\u0007two populations (where s2\n1 Ú s2\n2)\nCh. 10: Linear Correlation/Regression\nCorrelation r =\nnΣxy - 1Σx21Σy2\n2n1Σx22 - 1Σx2 22n1Σy22 - 1Σy2 2\n         or r =\ng1zx zy2\nn - 1   \u0007\nwhere \u0007zx = z score for x \nzy = z score for y\nSlope:  b1 =\nnΣxy - 1Σx21Σy2\nn 1Σx22 - 1Σx2 2  or b1 = r \nsy\nsx\ny-Intercept:\nb0 = y - b1x or  b0 =\n1Σy21Σx22 - 1Σx21Σxy2\nn 1Σx22 - 1Σx2 2\nyn = b0 + b1x  Estimated eq. of regression line\nr2 =\nexplained variation\ntotal variation\nse = B\nΣ1y - yn2 2\nn - 2\n or B\nΣy2 - b0Σy - b1Σxy\nn - 2\nyn - E 6 y 6 yn + E Prediction interval \nwhere E = ta>2se B1 + 1\nn +\nn1x0 - x2 2\nn1Σx22 - 1Σx2 2\nCh. 11: Goodness-of-Fit and Contingency Tables\nx2 = g\n1O - E2 2\nE\n  Goodness-of-fit (df = k - 1)\nx2 = g\n1O - E2 2\nE\n  Contingency table [df = (r - 1)(c - 1)]\n       where E =\n1row total21column total2\n1grand total2\nx2 =\n10 b - c0 - 12 2\nb + c\n  McNemar’s test for matched pairs 1df = 12\nCh. 12: One-Way Analysis of Variance\nProcedure for testing H0: m1 = m2 = m3 = c\n1.\t Use software or calculator to obtain results.\n2.\t Identify the P-value.\n3.\t Form conclusion:\nIf P-value … a, reject the null hypothesis  \n    of equal means.\nIf P-value 7 a, fail to reject the null hypothesis  \n    of equal means.\nCh. 12: Two-Way Analysis of Variance\nProcedure:\n1.\t Use software or a calculator to obtain results.\n2.\t Test H0: There is no interaction between the row factor and  \ncolumn factor.\n3.\t Stop if H0 from Step 2 is rejected.\nIf H0 from Step 2 is not rejected (so there does not appear to be an \ninteraction effect), proceed with these two tests:\n  Test for effects from the row factor.\n  Test for effects from the column factor.\n",
    "H =\n12\nN1N + 12\n aR2\n1\nn1\n+ R2\n2\nn2\n+ g + R2\nk\nnk\nb - 31N + 12\n    Kruskal-Wallis (chi-square df = k - 1)\nrs = 1 -\n6Σd2\nn1n2 - 12  Rank correlation\nacritical values for n 7 30: \n{ z\n1n - 1b\nFormulas and Tables by Triola, Triola, and Roy\nCopyright 2018 Pearson Education, Inc.\nCh. 13: Nonparametric Tests\nz =\n1x + 0.52 - 1n>22\n1n\n2\n  Sign test for n 7 25\nz =\nT - n 1n + 12>4\nB\nn 1n + 1212n + 12\n24\n \nTable A-6  \u0007Critical Values of the Pearson \nCorrelation Coefficient r\nn \na = .05\na = .01\n4\n.950\n.990\n5\n.878\n.959\n6\n.811\n.917\n7\n.754\n.875\n8\n.707\n.834\n9\n.666\n.798\n10\n.632\n.765\n11\n.602\n.735\n12\n.576\n.708\n13\n.553\n.684\n14\n.532\n.661\n15\n.514\n.641\n16\n.497\n.623\n17\n.482\n.606\n18\n.468\n.590\n19\n.456\n.575\n20\n.444\n.561\n25\n.396\n.505\n30\n.361\n.463\n35\n.335\n.430\n40\n.312\n.402\n45\n.294\n.378\n50\n.279\n.361\n60\n.254\n.330\n70\n.236\n.305\n80\n.220\n.286\n90\n.207\n.269\n100\n.196\n.256\nNOTE: To test H0: r = 0 (no correlation) against H1: r ≠0 (correlation), reject  \nH0 if the absolute value of r is greater than or equal to the critical value in the table.\nWilcoxon signed ranks  \n(matched pairs and n 7 30)\nz = R - mR\nsR\n=\nR -\nn11n1 + n2 + 12\n2\nB\nn1n21n1 + n2 + 12\n12\n \nWilcoxon rank-sum  \n(two independent  \nsamples)\nInferences about M: choosing between t and normal distributions\nt distribution:\ns not known and normally distributed population\nor\ns not known and n 7 30\nNormal distribution:\ns known and normally distributed population\nor\ns known and n 7 30\nNonparametric method or bootstrapping: Population not normally distributed and n … 30\n",
    "Procedure for \nHypothesis \nTests\nFinding P-Values\n8. Restate Decision in Nontechnical Terms\nRestate this previous decision in simple nontechnical terms, and \naddress the original claim.\n5. Identify the Test Statistic\nIdentify the test statistic that is relevant to the test and determine its \nsampling distribution (such as normal, t, chi-square).\n4. Select Signiﬁcance Level\nSelect the signiﬁcance level A based on the seriousness of a type I error. \nMake A small if the consequences of rejecting a true H0 are severe.\n \n• The values of 0.05 and 0.01 are very common.\n2. Give Symbolic Form\nGive the symbolic form that must be true when the original claim is false.\n1. Identify the Claim\nIdentify the claim to be tested and express it in symbolic form.\n3. Identify Null and Alternative Hypothesis\nConsider the two symbolic expressions obtained so far:\n \n• Alternative hypothesis H1 is the one NOT containing equality, so H1 uses \n \n the symbol . or , or Þ.\n \n• Null hypothesis H0 is the symbolic expression that the parameter equals\n \n the ﬁxed value being considered.\n7. Make a Decision\n• Reject H0 if P-value # a.\n• Fail to reject H0 if P-value . a.\n6. Find Values\nFind the value of the test statistic and \nthe P-value (see Figure 8-3). Draw a \ngraph and show the test statistic and \nP-value.\n7. Make a Decision\n• Reject H0 if the test statistic is in the\ncritical region.\n• Fail to reject H0 if the test statistic is \nnot in the critical region.\n6. Find Values\nP-Value Method\nCritical Value Method\nFind the value of the test statistic and \nthe critical values. Draw a graph \nshowing the test statistic, critical \nvalue(s) and critical region.\nIs the test\nstatistic to the\nright or left of\ncenter?\nLeft\nRight\nLeft-tailed\nRight-tailed\nP-value 5 twice the area to\nthe left of the test statistic\nP-value 5 area to the left\nof the test statistic\nP-value 5 twice the area to\nthe right of the test statistic\nP-value 5 area to the right\nof the test statistic\nWhat type\nof test?\nStart\n",
    "Table A-3  t Distribution: Critical t Values\n \n0.005\n \n0.01\nArea in One Tail \n0.025\n \n0.05\n \n0.10\nDegrees of \nFreedom\n \n0.01\n \n0.02\nArea in Two Tails \n0.05\n \n0.10\n \n0.20\n  1\n \n63.657\n    31.821\n    12.706\n6.314\n3.078\n  2\n9.925\n6.965\n4.303\n2.920\n1.886\n  3\n5.841\n4.541\n3.182\n2.353\n1.638\n  4\n4.604\n3.747\n2.776\n2.132\n1.533\n  5\n4.032\n3.365\n2.571\n2.015\n1.476\n  6\n3.707\n3.143\n2.447\n1.943\n1.440\n  7\n3.499\n2.998\n2.365\n1.895\n1.415\n  8\n3.355\n2.896\n2.306\n1.860\n1.397\n  9\n3.250\n2.821\n2.262\n1.833\n1.383\n10\n3.169\n2.764\n2.228\n1.812\n1.372\n11\n3.106\n2.718\n2.201\n1.796\n1.363\n12\n3.055\n2.681\n2.179\n1.782\n1.356\n13\n3.012\n2.650\n2.160\n1.771\n1.350\n14\n2.977\n2.624\n2.145\n1.761\n1.345\n15\n2.947\n2.602\n2.131\n1.753\n1.341\n16\n2.921\n2.583\n2.120\n1.746\n1.337\n17\n2.898\n2.567\n2.110\n1.740\n1.333\n18\n2.878\n2.552\n2.101\n1.734\n1.330\n19\n2.861\n2.539\n2.093\n1.729\n1.328\n20\n2.845\n2.528\n2.086\n1.725\n1.325\n21\n2.831\n2.518\n2.080\n1.721\n1.323\n22\n2.819\n2.508\n2.074\n1.717\n1.321\n23\n2.807\n2.500\n2.069\n1.714\n1.319\n24\n2.797\n2.492\n2.064\n1.711\n1.318\n25\n2.787\n2.485\n2.060\n1.708\n1.316\n26\n2.779\n2.479\n2.056\n1.706\n1.315\n27\n2.771\n2.473\n2.052\n1.703\n1.314\n28\n2.763\n2.467\n2.048\n1.701\n1.313\n29\n2.756\n2.462\n2.045\n1.699\n1.311\n30\n2.750\n2.457\n2.042\n1.697\n1.310\n31\n2.744\n2.453\n2.040\n1.696\n1.309\n32\n2.738\n2.449\n2.037\n1.694\n1.309\n33\n2.733\n2.445\n2.035\n1.692\n1.308\n34\n2.728\n2.441\n2.032\n1.691\n1.307\n35\n2.724\n2.438\n2.030\n1.690\n1.306\n36\n2.719\n2.434\n2.028\n1.688\n1.306\n37\n2.715\n2.431\n2.026\n1.687\n1.305\n38\n2.712\n2.429\n2.024\n1.686\n1.304\n39\n2.708\n2.426\n2.023\n1.685\n1.304\n40\n2.704\n2.423\n2.021\n1.684\n1.303\n45\n2.690\n2.412\n2.014\n1.679\n1.301\n50\n2.678\n2.403\n2.009\n1.676\n1.299\n60\n2.660\n2.390\n2.000\n1.671\n1.296\n70\n2.648\n2.381\n1.994\n1.667\n1.294\n80\n2.639\n2.374\n1.990\n1.664\n1.292\n90\n2.632\n2.368\n1.987\n1.662\n1.291\n100\n2.626\n2.364\n1.984\n1.660\n1.290\n200\n2.601\n2.345\n1.972\n1.653\n1.286\n300\n2.592\n2.339\n1.968\n1.650\n1.284\n400\n2.588\n2.336\n1.966\n1.649\n1.284\n500\n2.586\n2.334\n1.965\n1.648\n1.283\n1000\n2.581\n2.330\n1.962\n1.646\n1.282\n2000\n2.578\n2.328\n1.961\n1.646\n1.282\nLarge\n2.576\n2.326\n1.960\n1.645\n1.282\nCritical t value\n(negative)\na\nLeft tail\nCritical t value\n(positive)\na\nRight tail\nCritical t value\n(positive)\nCritical t value\n(negative)\na\u001f2\na\u001f2\nTwo tails\n",
    "Table A-2  Standard Normal (z) Distribution: Cumulative Area from the LEFT\nz\n.00\n.01\n.02\n.03\n.04\n.05\n.06\n.07\n.08\n.09\n-3.50 and \nlower\n \n.0001\n-3.4\n.0003\n.0003\n.0003\n.0003\n.0003\n.0003\n.0003\n.0003\n.0003\n.0002\n-3.3\n.0005\n.0005\n.0005\n.0004\n.0004\n.0004\n.0004\n.0004\n.0004\n.0003\n-3.2\n.0007\n.0007\n.0006\n.0006\n.0006\n.0006\n.0006\n.0005\n.0005\n.0005\n-3.1\n.0010\n.0009\n.0009\n.0009\n.0008\n.0008\n.0008\n.0008\n.0007\n.0007\n-3.0\n.0013\n.0013\n.0013\n.0012\n.0012\n.0011\n.0011\n.0011\n.0010\n.0010\n-2.9\n.0019\n.0018\n.0018\n.0017\n.0016\n.0016\n.0015\n.0015\n.0014\n.0014\n-2.8\n.0026\n.0025\n.0024\n.0023\n.0023\n.0022\n.0021\n.0021\n.0020\n.0019\n-2.7\n.0035\n.0034\n.0033\n.0032\n.0031\n.0030\n.0029\n.0028\n.0027\n.0026\n-2.6\n.0047\n.0045\n.0044\n.0043\n.0041\n.0040\n.0039\n.0038\n.0037\n.0036\n-2.5\n.0062\n.0060\n.0059\n.0057\n.0055\n.0054\n.0052\n.0051\n.0049\n.0048\n-2.4\n.0082\n.0080\n.0078\n.0075\n.0073\n.0071\n.0069\n.0068\n.0066\n.0064\n-2.3\n.0107\n.0104\n.0102\n.0099\n.0096\n.0094\n.0091\n.0089\n.0087\n.0084\n-2.2\n.0139\n.0136\n.0132\n.0129\n.0125\n.0122\n.0119\n.0116\n.0113\n.0110\n-2.1\n.0179\n.0174\n.0170\n.0166\n.0162\n.0158\n.0154\n.0150\n.0146\n.0143\n-2.0\n.0228\n.0222\n.0217\n.0212\n.0207\n.0202\n.0197\n.0192\n.0188\n.0183\n-1.9\n.0287\n.0281\n.0274\n.0268\n.0262\n.0256\n.0250\n.0244\n.0239\n.0233\n-1.8\n.0359\n.0351\n.0344\n.0336\n.0329\n.0322\n.0314\n.0307\n.0301\n.0294\n-1.7\n.0446\n.0436\n.0427\n.0418\n.0409\n.0401\n.0392\n.0384\n.0375\n.0367\n-1.6\n.0548\n.0537\n.0526\n.0516\n.0505\n.0495\n.0485\n.0475\n.0465\n.0455\n-1.5\n.0668\n.0655\n.0643\n.0630\n.0618\n.0606\n.0594\n.0582\n.0571\n.0559\n-1.4\n.0808\n.0793\n.0778\n.0764\n.0749\n.0735\n.0721\n.0708\n.0694\n.0681\n-1.3\n.0968\n.0951\n.0934\n.0918\n.0901\n.0885\n.0869\n.0853\n.0838\n.0823\n-1.2\n.1151\n.1131\n.1112\n.1093\n.1075\n.1056\n.1038\n.1020\n.1003\n.0985\n-1.1\n.1357\n.1335\n.1314\n.1292\n.1271\n.1251\n.1230\n.1210\n.1190\n.1170\n-1.0\n.1587\n.1562\n.1539\n.1515\n.1492\n.1469\n.1446\n.1423\n.1401\n.1379\n-0.9\n.1841\n.1814\n.1788\n.1762\n.1736\n.1711\n.1685\n.1660\n.1635\n.1611\n-0.8\n.2119\n.2090\n.2061\n.2033\n.2005\n.1977\n.1949\n.1922\n.1894\n.1867\n-0.7\n.2420\n.2389\n.2358\n.2327\n.2296\n.2266\n.2236\n.2206\n.2177\n.2148\n-0.6\n.2743\n.2709\n.2676\n.2643\n.2611\n.2578\n.2546\n.2514\n.2483\n.2451\n-0.5\n.3085\n.3050\n.3015\n.2981\n.2946\n.2912\n.2877\n.2843\n.2810\n.2776\n-0.4\n.3446\n.3409\n.3372\n.3336\n.3300\n.3264\n.3228\n.3192\n.3156\n.3121\n-0.3\n.3821\n.3783\n.3745\n.3707\n.3669\n.3632\n.3594\n.3557\n.3520\n.3483\n-0.2\n.4207\n.4168\n.4129\n.4090\n.4052\n.4013\n.3974\n.3936\n.3897\n.3859\n-0.1\n.4602\n.4562\n.4522\n.4483\n.4443\n.4404\n.4364\n.4325\n.4286\n.4247\n-0.0\n.5000\n.4960\n.4920\n.4880\n.4840\n.4801\n.4761\n.4721\n.4681\n.4641\nNOTE: For values of z below -3.49, use 0.0001 for the area.\n*Use these common values that result from interpolation:\nNEGATIVE z Scores\nz Score\nArea\n-1.645\n0.0500\n-2.575\n0.0050\n(continued )\n0\nz\n*\n*\n",
    "POSITIVE z Scores\nTable A-2 (continued)  Cumulative Area from the LEFT\nz\n.00\n.01\n.02\n.03\n.04\n.05\n.06\n.07\n.08\n.09\n0.0\n.5000\n.5040\n.5080\n.5120\n.5160\n.5199\n.5239\n.5279\n.5319\n.5359\n0.1\n.5398\n.5438\n.5478\n.5517\n.5557\n.5596\n.5636\n.5675\n.5714\n.5753\n0.2\n.5793\n.5832\n.5871\n.5910\n.5948\n.5987\n.6026\n.6064\n.6103\n.6141\n0.3\n.6179\n.6217\n.6255\n.6293\n.6331\n.6368\n.6406\n.6443\n.6480\n.6517\n0.4\n.6554\n.6591\n.6628\n.6664\n.6700\n.6736\n.6772\n.6808\n.6844\n.6879\n0.5\n.6915\n.6950\n.6985\n.7019\n.7054\n.7088\n.7123\n.7157\n.7190\n.7224\n0.6\n.7257\n.7291\n.7324\n.7357\n.7389\n.7422\n.7454\n.7486\n.7517\n.7549\n0.7\n.7580\n.7611\n.7642\n.7673\n.7704\n.7734\n.7764\n.7794\n.7823\n.7852\n0.8\n.7881\n.7910\n.7939\n.7967\n.7995\n.8023\n.8051\n.8078\n.8106\n.8133\n0.9\n.8159\n.8186\n.8212\n.8238\n.8264\n.8289\n.8315\n.8340\n.8365\n.8389\n1.0\n.8413\n.8438\n.8461\n.8485\n.8508\n.8531\n.8554\n.8577\n.8599\n.8621\n1.1\n.8643\n.8665\n.8686\n.8708\n.8729\n.8749\n.8770\n.8790\n.8810\n.8830\n1.2\n.8849\n.8869\n.8888\n.8907\n.8925\n.8944\n.8962\n.8980\n.8997\n.9015\n1.3\n.9032\n.9049\n.9066\n.9082\n.9099\n.9115\n.9131\n.9147\n.9162\n.9177\n1.4\n.9192\n.9207\n.9222\n.9236\n.9251\n.9265\n.9279\n.9292\n.9306\n.9319\n1.5\n.9332\n.9345\n.9357\n.9370\n.9382\n.9394\n.9406\n.9418\n.9429\n.9441\n1.6\n.9452\n.9463\n.9474\n.9484\n.9495\n.9505\n.9515\n.9525\n.9535\n.9545\n1.7\n.9554\n.9564\n.9573\n.9582\n.9591\n.9599\n.9608\n.9616\n.9625\n.9633\n1.8\n.9641\n.9649\n.9656\n.9664\n.9671\n.9678\n.9686\n.9693\n.9699\n.9706\n1.9\n.9713\n.9719\n.9726\n.9732\n.9738\n.9744\n.9750\n.9756\n.9761\n.9767\n2.0\n.9772\n.9778\n.9783\n.9788\n.9793\n.9798\n.9803\n.9808\n.9812\n.9817\n2.1\n.9821\n.9826\n.9830\n.9834\n.9838\n.9842\n.9846\n.9850\n.9854\n.9857\n2.2\n.9861\n.9864\n.9868\n.9871\n.9875\n.9878\n.9881\n.9884\n.9887\n.9890\n2.3\n.9893\n.9896\n.9898\n.9901\n.9904\n.9906\n.9909\n.9911\n.9913\n.9916\n2.4\n.9918\n.9920\n.9922\n.9925\n.9927\n.9929\n.9931\n.9932\n.9934\n.9936\n2.5\n.9938\n.9940\n.9941\n.9943\n.9945\n.9946\n.9948\n.9949\n.9951\n.9952\n2.6\n.9953\n.9955\n.9956\n.9957\n.9959\n.9960\n.9961\n.9962\n.9963\n.9964\n2.7\n.9965\n.9966\n.9967\n.9968\n.9969\n.9970\n.9971\n.9972\n.9973\n.9974\n2.8\n.9974\n.9975\n.9976\n.9977\n.9977\n.9978\n.9979\n.9979\n.9980\n.9981\n2.9\n.9981\n.9982\n.9982\n.9983\n.9984\n.9984\n.9985\n.9985\n.9986\n.9986\n3.0\n.9987\n.9987\n.9987\n.9988\n.9988\n.9989\n.9989\n.9989\n.9990\n.9990\n3.1\n.9990\n.9991\n.9991\n.9991\n.9992\n.9992\n.9992\n.9992\n.9993\n.9993\n3.2\n.9993\n.9993\n.9994\n.9994\n.9994\n.9994\n.9994\n.9995\n.9995\n.9995\n3.3\n.9995\n.9995\n.9995\n.9996\n.9996\n.9996\n.9996\n.9996\n.9996\n.9997\n3.4\n.9997\n.9997\n.9997\n.9997\n.9997\n.9997\n.9997\n.9997\n.9997\n.9998\n3.50 and up\n.9999\nNOTE: For values of z above 3.49, use 0.9999 for the area.\n*Use these common values that result from interpolation:\nCommon Critical Values\nConfidence\nLevel\nCritical\nValue\n0.90\n1.645\n0.95\n1.96\n0.99\n2.575\nz Score\nArea\n1.645\n0.9500\n2.575\n0.9950\n*\n*\n0\nz\n",
    ""
  ],
  "full_text": "\nConceptual Understanding \nStudents need to be equipped with both the methods and conceptual  \nunderstanding of statistics. MyStatLab offers a full question library of over \n1,000 conceptual-based questions to help tighten the comprehension of  \nstatistical concepts.\nReal-World Statistics\nMyStatLab video resources help foster conceptual understanding. StatTalk  \nVideos, hosted by fun-loving statistician, Andrew Vickers, demonstrate  \nimportant statistical concepts through interesting stories and real-life events. \nThis series of 24 videos includes assignable questions built in MyStatLab and  \nan instructor’s guide.\nVisit www.mystatlab.com and click Get Trained to make sure  \nyou’re getting the most out of MyStatLab.\n\nBIOSTATISTICS\nFOR THE BIOLOGICAL  \nAND HEALTH SCIENCES\nMARC M. TRIOLA, MD, FACP\nNew York University School of Medicine\nMARIO F. TRIOLA\nDutchess Community College \nJASON ROY, PHD\nUniversity of Pennsylvania \nPerelman School of Medicine\nSECOND EDITION\n\nTo Ginny\nDushana and Marisa\nTrevor and Mitchell\nDirector, Portfolio Management Deirdre Lynch\nSenior Portfolio Manager Suzy Bainbridge\nPortfolio Management Assistant Justin Billing\nContent Producer Peggy McMahon\nManaging Producer Karen Wernholm\nCourseware QA Manager Mary Durnwald\nSenior Producer Vicki Dreyfus\nProduct Marketing Manager Yvonne Vannatta\nField Marketing Manager Evan St. Cyr\nProduct Marketing Assistant Jennifer Myers\nField Marketing Assistant Erin Rush\nSenior Author Support/Technology Specialist Joe Vetere \nManager, Rights and Permissions Gina M. Cheselka\nText and Cover Design, Illustrations, Production  Coordination, \nComposition Cenveo Publisher Services\nCover Image Robert Essel NYC/Getty Images\nCopyright © 2018, 2006 by Pearson Education, Inc. All Rights Reserved. Printed in the United States of America. This publica-\ntion is protected by copyright, and permission should be obtained from the publisher prior to any prohibited reproduction, storage \nin a retrieval system, or transmission in any form or by any means, electronic, mechanical, photocopying, recording, or otherwise. \nFor information regarding permissions, request forms and the appropriate contacts within the Pearson Education Global Rights & \nPermissions department, please visit www.pearsoned.com/permissions/.\nAttributions of third party content appear on page 683–684, which constitutes an extension of this copyright page.\nPEARSON, ALWAYS LEARNING, and MYSTATLAB are exclusive trademarks owned by Pearson Education, Inc. or its affiliates \nin the U.S. and/or other countries.\nUnless otherwise indicated herein, any third-party trademarks that may appear in this work are the property of their respective own-\ners and any references to third-party trademarks, logos or other trade dress are for demonstrative or descriptive purposes only. Such \nreferences are not intended to imply any sponsorship, endorsement, authorization, or promotion of Pearson’s products by the owners \nof such marks, or any relationship between the owner and Pearson Education, Inc. or its affiliates, authors, licensees or distributors.\nMICROSOFT AND>OR ITS RESPECTIVE SUPPLIERS MAKE NO REPRESENTATIONS ABOUT THE SUITABILITY OF THE INFORMATION CONTAINED IN THE \nDOCUMENTS AND RELATED GRAPHICS PUBLISHED AS PART OF THE SERVICES FOR ANY PURPOSE. ALL SUCH DOCUMENTS AND RELATED GRAPHICS \nARE PROVIDED “AS IS” WITHOUT WARRANTY OF ANY KIND. MICROSOFT AND>OR ITS RESPECTIVE SUPPLIERS HEREBY DISCLAIM ALL WARRANTIES \nAND CONDITIONS WITH REGARD TO THIS INFORMATION, INCLUDING ALL WARRANTIES AND CONDITIONS OF MERCHANTABILITY, WHETHER EXPRESS, \nIMPLIED OR STATUTORY, FITNESS FOR A PARTICULAR PURPOSE, TITLE AND NON-INFRINGEMENT. IN NO EVENT SHALL MICROSOFTAND>OR ITS RESPEC-\nTIVE SUPPLIERS BE LIABLE FOR ANY SPECIAL, INDIRECT OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES WHATSOEVER RESULTING FROM LOSS OF \nUSE, DATA OR PROFITS, WHETHER IN AN ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT OF OR IN CONNECTION WITH \nTHE USE OR PERFORMANCE OF INFORMATION AVAILABLE FROM THE SERVICES.\nTHE DOCUMENTS AND RELATED GRAPHICS CONTAINED HEREIN COULD INCLUDE TECHNICAL INACCURACIES OR TYPOGRAPHICAL ERRORS. CHANGES \nARE PERIODICALLY ADDED TO THE INFORMATION HEREIN. MICROSOFT AND>OR ITS RESPECTIVE SUPPLIERS MAY MAKE IMPROVEMENTS AND>OR \nCHANGES IN THE PRODUCT(S) AND>OR THE PROGRAM(S) DESCRIBED HEREIN AT ANY TIME. PARTIAL SCREEN SHOTS MAY BE VIEWED IN FULL WITHIN \nTHE SOFTWARE VERSION SPECIFIED.\nLibrary of Congress Cataloging-in-Publication Data\nNames: Triola, Marc M. | Triola, Mario F. | Roy, Jason (Jason Allen)\nTitle: Biostatistics for the biological and health sciences.\nDescription: Second edition / Marc M. Triola, New York University, \nMario F. Triola, Dutchess Community College, Jason Roy, University of \nPennsylvania. | Boston : Pearson, [2018] | Includes bibliographical \nreferences and index.\nIdentifiers: LCCN 2016016759| ISBN 9780134039015 (hardcover) | ISBN\n0134039017 (hardcover)\nSubjects: LCSH: Biometry. | Medical statistics.\nClassification: LCC QH323.5 .T75 2018 | DDC 570.1/5195–dc23\nLC record available at https://lccn.loc.gov/2016016759\n1 16\nISBN 13: 978-0-13-403901-5\nISBN 10: 0-13-403901-7\n\niii\nMarc Triola, MD, FACP is the \nAssociate Dean for Educational \nInformatics at NYU School of \nMedicine, the founding director \nof the NYU Langone  Medical \nCenter Institute for Innovations \nin Medical Education (IIME), \nand an  Associate Professor of \nMedicine. Dr. Triola’s research \nexperience and expertise focus \non the disruptive effects of the \npresent revolution in educa-\ntion, driven by technological \nadvances, big data, and learn-\ning analytics. Dr. Triola has \nworked to create a “learning \necosystem” that includes interconnected computer-based e-learning tools and new \nways to effectively integrate growing amounts of electronic data in educational re-\nsearch. Dr. Triola and IIME have been funded by the National Institutes of Health, \nthe Integrated Advanced Information Management Systems program, the National \nScience Foundation Advanced Learning Technologies program, the Josiah Macy, \nJr. Foundation, the U.S. Department of Education, and the American Medical As-\nsociation Accelerating Change in Medical Education program. He chairs numer-\nous committees at the state and national levels focused on the future of health \nprofessions educational technology development and research.\nMario F. Triola is a Professor \nEmeritus of Mathematics at \nDutchess Community College, \nwhere he has taught statistics \nfor over 30 years. Marty is the \nauthor of Elementary Statistics, \n13th edition, Essentials of Sta-\ntistics, 5th edition, Elementary \nStatistics Using Excel, 6th edi-\ntion, and Elementary Statis-\ntics Using the TI-83>84 Plus \nCalculator, 4th edition, and \nhe is a co-author of Statistical \nReasoning for Everyday Life, \n5th edition. Elementary Statis-\ntics is currently available as an \nInternational Edition, and it has been translated into several foreign languages. \nMarty designed the original Statdisk statistical software, and he has  written \n several  manuals and workbooks for technology supporting statistics education. \nABOUT THE AUTHORS\n\niv \nAbout the Authors\nHe has been a speaker at many conferences and colleges. Marty’s consulting work \nincludes the design of casino slot machines and the design of fishing rods. He has \nworked with attorneys in determining probabilities in paternity lawsuits, analyz-\ning data in medical malpractice lawsuits, identifying salary inequities based on \ngender, and analyzing disputed election results. He has also used statistical meth-\nods in analyzing medical school surveys and in analyzing survey results for the \nNew York City Transit Authority. Marty has testified as an expert witness in the \nNew York State Supreme Court.\nJason Roy, PhD, is Associate \nProfessor of Biostatistics in \nthe Department of Biostatistics \nand Epidemiology, Perelman \nSchool of Medicine, Univer-\nsity of Pennsylvania. He re-\nceived his PhD in Biostatistics \nin 2000 from the University \nof Michigan. He was recipi-\nent of the 2002 David P. Byar \nYoung Investigator Award from \nthe American Statistical Asso-\nciation Biometrics Section. His \nstatistical research interests are \nin the areas of causal inference, \nmissing data, and prediction \nmodeling. He is especially interested in the statistical challenges with analyzing \ndata from large health care databases. He collaborates in many different disease \nareas, including chronic kidney disease, cardiovascular disease, and liver diseases. \nDr Roy is Associate Editor of Biometrics, Journal of the American Statistical \nAssociation, and Pharmacoepidemiology & Drug Safety, and has over 90 peer- \nreviewed publications.\n\nv\nCONTENTS\n1 \nINTRODUCTION TO STATISTICS \n1\n1-1  \nStatistical and Critical Thinking  4\n1-2  \nTypes of Data  13\n1-3  \nCollecting Sample Data  24\n2 \nEXPLORING DATA WITH TABLES AND GRAPHS \n40\n2-1  \nFrequency Distributions for Organizing and Summarizing Data  42\n2-2  Histograms  51\n2-3  Graphs That Enlighten and Graphs That Deceive  56\n2-4  Scatterplots, Correlation, and Regression  65\n3 \nDESCRIBING, EXPLORING, AND COMPARING DATA \n75\n3-1  \nMeasures of Center  77\n3-2  Measures of Variation  89\n3-3  Measures of Relative Standing and Boxplots  102\n4 \nPROBABILITY \n118\n4-1  \nBasic Concepts of Probability  120\n4-2  Addition Rule and Multiplication Rule  131\n4-3  Complements, Conditional Probability, and Bayes’ Theorem  144\n4-4  Risks and Odds  153\n4-5  Rates of Mortality, Fertility, and Morbidity  162\n4-6  Counting  167\n5 \nDISCRETE PROBABILITY DISTRIBUTIONS \n180\n5-1  \nProbability Distributions  182\n5-2  Binomial Probability Distributions  193\n5-3  Poisson Probability Distributions  206\n6 \nNORMAL PROBABILITY DISTRIBUTIONS \n216\n6-1  \nThe Standard Normal Distribution  218\n6-2  Real Applications of Normal Distributions  231\n6-3  Sampling Distributions and Estimators  241\n6-4  The Central Limit Theorem  252\n6-5  Assessing Normality  261\n6-6  Normal as Approximation to Binomial  269\n7 \nESTIMATING PARAMETERS AND DETERMINING SAMPLE SIZES \n282\n7-1 \nEstimating a Population Proportion  284\n7-2  Estimating a Population Mean  299\n7-3  Estimating a Population Standard Deviation or Variance  315\n7-4  Bootstrapping: Using Technology for Estimates  324\n8 \nHYPOTHESIS TESTING  \n336\n8-1  \nBasics of Hypothesis Testing  338\n8-2  Testing a Claim About a Proportion  354\n8-3  Testing a Claim About a Mean  366\n8-4  Testing a Claim About a Standard Deviation or Variance  377\n9 \nINFERENCES FROM TWO SAMPLES  \n392\n9-1  \nTwo Proportions  394\n9-2  Two Means: Independent Samples  406\n9-3  Two Dependent Samples (Matched Pairs)  418\n9-4  Two Variances or Standard Deviations  428\n\nvi \nContents\n10 \nCORRELATION AND REGRESSION  \n442\n10-1  Correlation  444\n10-2  Regression  462\n10-3  Prediction Intervals and Variation  474\n10-4  Multiple Regression  481\n10-5  Dummy Variables and Logistic Regression  489\n11 \nGOODNESS-OF-FIT AND CONTINGENCY TABLES  \n502\n11-1  Goodness-of-Fit  503\n11-2  Contingency Tables  514\n12 \nANALYSIS OF VARIANCE  \n531\n12-1  One-Way ANOVA  533\n12-2  Two-Way ANOVA  547\n13 \nNONPARAMETRIC TESTS  \n560\n13-1  Basics of Nonparametric Tests  562\n13-2  Sign Test  564\n13-3  Wilcoxon Signed-Ranks Test for Matched Pairs  575\n13-4  Wilcoxon Rank-Sum Test for Two Independent Samples  581\n13-5  Kruskal-Wallis Test for Three or More Samples  586\n13-6  Rank Correlation  592\n14 \nSURVIVAL ANALYSIS  \n603\n14-1  Life Tables  604\n14-2  Kaplan-Meier Survival Analysis  614\nAPPENDIX A TABLES  \n625\nAPPENDIX B DATA SETS  \n638\nAPPENDIX C WEBSITES AND BIBLIOGRAPHY OF BOOKS   \n645\nAPPENDIX D ANSWERS TO ODD-NUMBERED SECTION EXERCISES  \n646\n(and all Quick Quizzes, all Review Exercises, and all Cumulative Review Exercises)\nCredits  683\nIndex  685\n\nPREFACE\nStatistics permeates nearly every aspect of our lives, and its role has become partic-\nularly important in the biological, life, medical, and health sciences. From opinion \npolls to clinical trials in medicine and analysis of big data from health applications, \nstatistics influences and shapes the world around us. Biostatistics for the Health and \nBiological Sciences forges the relationship between statistics and our world through \nextensive use of a wide variety of real applications that bring life to theory and \nmethods.\nGoals of This Second Edition\n \n■Incorporate the latest and best methods used by professional statisticians.\n \n■Include features that address all of the recommendations included in the Guide-\nlines for Assessment and Instruction in Statistics Education (GAISE) as recom-\nmended by the American Statistical Association.\n \n■Provide an abundance of new and interesting data sets, examples, and exercises.\n \n■Foster personal growth of students through critical thinking, use of technology, \ncollaborative work, and development of communication skills.\n \n■Enhance teaching and learning with the most extensive and best set of supple-\nments and digital resources.\nAudience, Prerequisites\nBiostatistics for the Health and Biological Sciences is written for students major-\ning in the biological and health sciences, and it is designed for a wide variety of \nstudents taking their first statistics course. Algebra is used minimally, and calculus \nis not required. It is recommended that students have completed at least an elemen-\ntary algebra course or that students should learn the relevant algebra components \nthrough an integrated or co-requisite course. In many cases, underlying theory is \nincluded, but this book does not require the mathematical rigor more appropriate for \nmathematics majors.\nHallmark Features\nGreat care has been taken to ensure that each chapter of Biostatistics for the Health \nand Biological Sciences will help students understand the concepts presented. The \nfollowing features are designed to help meet that objective.\nReal Data\nHundreds of hours have been devoted to finding data that are real, meaningful, and \ninteresting to students. Fully 87% of the examples are based on real data, and 89% of \nthe exercises are based on real data. Some exercises refer to the 18 data sets listed in \nAppendix B, and 12 of those data sets are new to this edition. Exercises requiring use \nof the Appendix B data sets are located toward the end of each exercise set and are \nmarked with a special data set icon \n.\nReal data sets are included throughout the book to provide relevant and interesting \nreal-world statistical applications, including biometric security, body measurements, \nbrain sizes and IQ scores, and data from births. Appendix B includes descriptions of \nvii\n\nviii \nPreface\nthe 18 data sets that can be downloaded from the companion website www.pearson-\nhighered.com/triola, the author maintained www.TriolaStats.com and MyStatLab.\nTriolaStats.com includes downloadable data sets in formats for technologies \nincluding Excel, Minitab, JMP, SPSS, and TI@83>84 Plus calculators. The data \nsets are also included in the free Statdisk software, which is also available on the \nwebsite.\nReadability\nGreat care, enthusiasm, and passion have been devoted to creating a book that is readable, \nunderstandable, interesting, and relevant. Students pursuing any major in the biological, \nlife, medical, or health fields are sure to find applications related to their future work.\nWebsite\nThis textbook is supported by www.TriolaStats.com, and www.pearsonhighered.com/\ntriola which are continually updated to provide the latest digital resources, including:\n \n■Statdisk: A free, robust statistical software package designed for this book.\n \n■Downloadable Appendix B data sets in a variety of technology formats.\n \n■Downloadable textbook supplements including Glossary of Statistical Terms and \nFormulas and Tables.\n \n■Online instructional videos created specifically for this book that provide step-\nby-step technology instructions.\n \n■Triola Blog, which highlights current applications of statistics, statistics in the \nnews, and online resources.\nChapter Features\nChapter Opening Features\n \n■Chapters begin with a Chapter Problem that uses real data and motivates the \nchapter material.\n \n■Chapter Objectives provide a summary of key learning goals for each section in \nthe chapter.\nExercises\nMany exercises require the interpretation of results. Great care has been taken to \nensure their usefulness, relevance, and accuracy. Exercises are arranged in order of \nincreasing difficulty, and they begin with Basic Skills and Concepts. Most sections \ninclude additional Beyond the Basics exercises that address more difficult concepts or \nrequire a stronger mathematical background. In a few cases, these exercises introduce \na new concept.\nEnd-of-Chapter Features\n \n■Chapter Quick Quiz provides review questions that require brief answers.\n \n■Review Exercises offer practice on the chapter concepts and procedures.\n \n■Cumulative Review Exercises reinforce earlier material.\n \n■Technology Project provides an activity that can be used with a variety of \n technologies.\n \n■From Data to Decision is a capstone problem that requires critical thinking and \nwriting.\n \n■Cooperative Group Activities encourage active learning in groups.\n\nPreface \nix\nOther Features\nMargin Essays There are 57 margin essays designed to highlight real-world topics \nand foster student interest.\nFlowcharts The text includes flowcharts that simplify and clarify more complex con-\ncepts and procedures. Animated versions of the text’s flowcharts are available within \nMyStatLab and MathXL.\nQuick-Reference Endpapers Tables A-2 and A-3 (the normal and t distributions) are \nreproduced on the rear inside cover pages.\nDetachable Formula and Table Card This insert, organized by chapter, gives students \na quick reference for studying, or for use when taking tests (if allowed by the instruc-\ntor). It also includes the most commonly used tables. This is also available for download \nat www.TriolaStats.com, www.pearsonhighered.com/triola and in MyStatLab.\nTechnology Integration\nAs in the preceding edition, there are many displays of screens from technology through-\nout the book, and some exercises are based on displayed results from technology. Where \nappropriate, sections include a reference to an online Tech Center subsection that in-\ncludes detailed instructions for Statdisk, Minitab®, Excel®, StatCrunch, or a TI@83>84\nPlus® calculator. (Throughout this text, “TI-83>84 Plus” is used to identify a TI-83 Plus \nor TI-84 Plus calculator). The end-of-chapter features include a Technology Project.\nThe Statdisk statistical software package is designed specifically for this textbook \nand contains all Appendix B data sets. Statdisk is free to users of this book, and it can \nbe downloaded at www.statdisk.org.\nChanges in This Edition\nNew Features\nChapter Objectives provide a summary of key learning goals for each section in the \nchapter.\nLarger Data Sets: Some of the data sets in Appendix B are much larger than in the \nprevious edition. It is no longer practical to print all of the Appendix B data sets in this \nbook, so the data sets are described in Appendix B, and they can be downloaded at \nwww.TriolaStats.com, www.pearsonhighered.com/triola, and MyStatLab.\nNew Content: New examples, new exercises, and Chapter Problems provide relevant \nand interesting real-world statistical applications, including biometric security, drug \ntesting, gender selection, and analyzing ultrasound images.\nNumber\nNew to This Edition\nUse Real Data\nExercises\n1600\n85%\n89%\nExamples\n 200\n84%\n87%\nMajor Organization Changes\nAll Chapters\n \n■New Chapter Objectives: All chapters now begin with a list of key learning goals \nfor that chapter. Chapter Objectives replaces the former Overview numbered sec-\ntions. The first numbered section of each chapter now covers a major topic.\nChapter 1\n \n■New Section 1-1: Statistical and Critical Thinking\n \n■New Subsection 1-3, Part 2: Big Data and Missing Data: Too Much and Not Enough\n\nx \nPreface\nChapters 2 and 3\n \n■Chapter Partitioned: Chapter 2 (Describing, Exploring, and Comparing Data) \nfrom the first edition has been partitioned into Chapter 2 (Summarizing and Graph-\ning) and Chapter 3 (Statistics for Describing, Exploring, and Comparing Data).\n \n■New Section 2-4: Scatterplots, Correlation, and Regression This new section \nincludes scatterplots in Part 1, the linear correlation coefficient r in Part 2, and \nlinear regression in Part 3. These additions are intended to greatly facilitate cover-\nage for those professors who prefer some early coverage of correlation and regres-\nsion concepts. Chapter 10 includes these topics discussed with much greater detail.\nChapter 4\n \n■Combined Sections: Section 3-3 (Addition Rule) and Section 3-4 (Multiplication \nRule) from the first edition are now combined into one section: 4-2 (Addition \nRule and Multiplication Rule).\n \n■New Subsection 4-3, Part 3: Bayes’ Theorem\nChapter 5\n \n■Combined Sections: Section 4-3 (Binomial Probability Distributions) and \nSection 4-4 (Mean, Variance, and Standard Deviation for the Binomial Distribu-\ntion) from the first edition are now combined into one section: 5-2 (Binomial \nProbability Distributions).\nChapter 6\n \n■Switched Sections: Section 6-5 (Assessing Normality) now precedes Section 6-6 \n(Normal as Approximation to Binomial).\nChapter 7\n \n■Combined Sections: Sections 6-4 (Estimating a Population Mean: s Known) \nand 6-5 (Estimating a Population Mean: s Not Known) from the first edition \nhave been combined into one section: 7-2 (Estimating a Population Mean). The \ncoverage of the s known case has been substantially reduced and it is now lim-\nited to Part 2 of Section 7-2.\n \n■New Section 7-4: Bootstrapping: Using Technology for Estimates\nChapter 8\n \n■Combined Sections: Sections 7-4 (Testing a Claim About a Population Mean: s \nKnown) and 7-5 (Testing a Claim About a Population Mean: s Not Known) from \nthe first edition have been combined into one section: 8-3 (Testing a Claim About \na Mean). Coverage of the s known case has been substantially reduced and it is \nnow limited to Part 2 of Section 8-3.\nChapter 10\n \n■New Section: 10-5 Dummy Variables and Logistic Regression\nChapter 11\n \n■New Subsection: Section 11-2, Part 2 Test of Homogeneity, Fisher’s Exact Test, \nand McNemar’s Test for Matched Pairs\nChapter 14\n \n■Combined Sections: Section 13-2 (Elements of a Life Table) and Section 13-3 \n(Applications of Life Tables) from the first edition have been combined into \nSection 14-1 (Life Tables).\n \n■New Section: 14-2 Kaplan-Meier Survival Analysis\n\nPreface \nxi\nFlexible Syllabus\nThis book’s organization reflects the preferences of most statistics instructors, but \nthere are two common variations:\n \n■Early Coverage of Correlation and Regression: Some instructors prefer to \ncover the basics of correlation and regression early in the course. Section 2-4 \nnow includes basic concepts of scatterplots, correlation, and regression without \nthe use of formulas and greater depth found in Sections 10-1 (Correlation) and \n10-2 (Regression).\n \n■Minimum Probability: Some instructors prefer extensive coverage of probability, \nwhile others prefer to include only basic concepts. Instructors preferring mini-\nmum coverage can include Section 4-1 while skipping the remaining sections of \nChapter 4, as they are not essential for the chapters that follow. Many instructors \nprefer to cover the fundamentals of probability along with the basics of the addi-\ntion rule and multiplication rule (Section 4-2).\nGAISE\nThis book reflects recommendations from the American Statistical Association and \nits Guidelines for Assessment and Instruction in Statistics Education (GAISE). Those \nguidelines suggest the following objectives and strategies.\n1. Emphasize statistical literacy and develop statistical thinking: Each section \nexercise set begins with Statistical Literacy and Critical Thinking exercises. \nMany of the book’s exercises are designed to encourage statistical thinking \nrather than the blind use of mechanical procedures.\n2. Use real data: 87% of the examples and 89% of the exercises use real data.\n3. Stress conceptual understanding rather than mere knowledge of procedures: \nInstead of seeking simple numerical answers, most exercises and examples \ninvolve conceptual understanding through questions that encourage practical \ninterpretations of results. Also, each chapter includes a From Data to Decision \nproject.\n4. Foster active learning in the classroom: Each chapter ends with several \nCooperative Group Activities.\n5. Use technology for developing conceptual understanding and analyzing data: \nComputer software displays are included throughout the book. Special Tech \nCenter subsections are available online, and they include instruction for using \nthe software. Each chapter includes a Technology Project. When there are dis-\ncrepancies between answers based on tables and answers based on technology, \nAppendix D provides both answers. The websites www.TriolaStats.com and \nwww.pearsonhighered.com/triola as well as MyStatLab include free text-specific \nsoftware (Statdisk), data sets formatted for several different technologies, and \ninstructional videos for technologies.\n6. Use assessments to improve and evaluate student learning: Assessment tools \ninclude an abundance of section exercises, Chapter Quick Quizzes, Review \nExercises, Cumulative Review Exercises, Technology Projects, From Data to \nDecision projects, and Cooperative Group Activities.\n\nxii \nPreface\nAcknowledgments\nWe would like to thank the many statistics professors and students who have contrib-\nuted to the success of this book. We thank the reviewers for their suggestions for this \nsecond edition:\nJames Baldone, Virginia College\nNaomi Brownstein, Florida State University\nChristina Caruso, University of Guelph\nErica A. Corbett, Southeastern Oklahoma State University\nXiangming Fang, East Carolina University\nPhil Gona, UMASS Boston\nSharon Homan, University of North Texas\nJackie Milton, Boston University\nJoe Pick, Palm Beach State College\nSteve Rigdon, St. Louis University\nBrian Smith, Black Hills State University\nMahbobeh Vezvaei, Kent State University\nDavid Zeitler, Grand Valley State University\nWe also thank Paul Lorczak, Joseph Pick and Erica Corbett for their help in \nchecking the accuracy of the text and answers.\nMarc Triola\nMario Triola\nJason Roy\nSeptember 2016\n\nMyStatLab\n® Online Course for Biostatistics: For  \nthe Biological and Health Sciences, 2e by Marc M. Triola, \nMario F. Triola and Jason Roy (access code required)\nMyStatLab is available to accompany Pearson’s market leading text offerings. To give \nstudents a consistent tone, voice, and teaching method each text’s flavor and ap-\nproach is tightly integrated throughout the accompanying MyStatLab course, making \nlearning the material as seamless as possible.\nReal-World Data Examples - Help \nunderstand how statistics applies to \neveryday life through the extensive \ncurrent, real-world data examples and \nexercises provided throughout the text.\nMathXL coverage - MathXL is a market-leading \ntext-speciﬁc autograded homework system built \nto improve student learning outcomes.\nEnhanced video program to meet Introductory \nStatistics needs:\n•  New! Tech-Specific Video Tutorials - These \nshort, topical videos address how to use varying \ntechnologies to complete exercises.\n•  Updated! Section Lecture Videos - Watch author, \nMarty Triola, work through examples and elaborate \non key objectives of the chapter.\nResources for Success\nwww.mystatlab.com\nxiii\n\nxiv \nPreface\nSupplements\nFor the Student\nStudent’s Solutions Manual, by James Lapp (Colorado \nMesa University) provides detailed, worked-out solutions \nto all odd-numbered text exercises.\n(ISBN-13: 978-0-13-403909-1; ISBN-10: 0-13-403909-2)\nStudent Workbook for the Triola Statistics Series, by \nLaura lossi (Broward College) offers additional exam-\nples, concept exercises, and vocabulary exercises for each \nchapter.\n(ISBN-13: 978-0-13-446423-7; ISBN 10: 0-13-446423-0)\nThe following technology manuals, available in  MyStatLab, \ninclude instructions, examples from the main text, and \ninterpretations to complement those given in the text.\nExcel Student Laboratory Manual and Workbook \n(Download Only), by Laurel Chiappetta (University of \nPittsburgh).\n(ISBN-13: 978-0-13-446427-5; ISBN-10: 0-13-446427-3)\nMINITAB Student Laboratory Manual and Work-\nbook (Download Only), by Mario F. Triola.\n(ISBN-13: 978-0-13-446418-3; ISBN-10: 0-13-446418-4)\nGraphing Calculator Manual for the TI-83 Plus, \nTI-84 Plus, TI-84 Plus C and TI-84 Plus CE (Down-\nload Only), by Kathleen McLaughlin (University of \nConnecticut) & Dorothy Wakefield (University of Con-\nnecticut Health Center).\n(ISBN-13: 978-0-13-446414-5; ISBN 10: 0-13-446414-1)\nStatdisk Student Laboratory Manual and Workbook \n(Download Only), by Mario F. Triola. These files are \navailable to instructors and students through the Triola Sta-\ntistics Series website, www.pearsonhighered.com/triola, \nand MyStatLab.\nSPSS Student Laboratory Manual and Workbook \n(Download Only), by James J. Ball (Indiana State Uni-\nversity). These files are available to instructors and stu-\ndents through the Triola Statistics Series website, www.\npearsonhighered.com/triola, and MyStatLab.\nFor the Instructor\nInstructor’s Solutions Manual (Download Only), by \nJames Lapp (Colorado Mesa University) contains so-\nlutions to all the exercises. These files are available to \nqualified instructors through Pearson Education’s on-\nline catalog at www.pearsonhighered.com/irc or within \nMyStatLab.\nInsider’s Guide to Teaching with the Triola Statistics \nSeries, by Mario F. Triola, contains sample syllabi and \ntips for incorporating projects, as well as lesson overviews, \nextra examples, minimum outcome objectives, and recom-\nmended assignments for each chapter.\n(ISBN-13: 978-0-13-446425-1; ISBN-10: 0-13-446425-7)\nTestGen® Computerized Test Bank (www.pearsoned.\ncom/testgen) enables instructors to build, edit, print, and \nadminister tests using a computerized bank of questions \ndeveloped to cover all the objectives of the text. TestGen is \nalgorithmically based, allowing instructors to create mul-\ntiple but equivalent versions of the same question or test \nwith the click of a button. Instructors can also modify test \nbank questions or add new questions. The software and tes-\ntbank are available for download from Pearson Education’s \nonline catalog at www.pearsonhighered.com. A test bank \n(Download Only) is also available from the  online catalog.\nLearning Catalytics: Learning Catalytics is a web-based \nengagement and assessment tool. As a “bring-your-own-\ndevice” direct response system, Learning Catalytics offers \na diverse library of dynamic question types that allow stu-\ndents to interact with and think critically about statistical \nconcepts. As a real-time resource, instructors can take ad-\nvantage of critical teaching moments both in the classroom \nor through assignable and gradeable homework.\nTechnology Resources\nThe following resources can be found on the Triola Statistics \nSeries website (http://www.pearsonhighered.com/triola), the \nauthor maintained www.triolastats.com, and MyStatLab\n \n■Appendix B data sets formatted for Minitab, SPSS, \nSAS, Excel, JMP, and as text files. Additionally, these \ndata sets are available as an APP for the TI-83>84 \nPlus calculators, and supplemental programs for the \nTI-83>84 Plus calculator are also available.\n \n■Statdisk statistical software instructions for down-\nload. New features include the ability to directly use \nlists of data instead of requiring the use of their sum-\nmary statistics.\n \n■Extra data sets, an index of applications, and a sym-\nbols table.\nVideo resources have been expanded, updated and now \nsupplement most sections of the book, with many topics \npresented by the author.  The videos aim to support both \ninstructors and students through lecture, reinforcing sta-\ntistical basics through technology, and applying concepts:\n \n■Section Lecture Videos\n\nPreface \nxv\n \n■New! Technology Video Tutorials - These short, \ntopical videos address how to use Excel, Statdisk, \nand the TI graphing calculator to complete exercises.\n \n■StatTalk Videos: 24 Conceptual Videos to Help \nYou Actually Understand Statistics. Fun-loving \nstatistician Andrew Vickers takes to the streets of \nBrooklyn, NY, to demonstrate important statistical \nconcepts through interesting stories and real-life \nevents. These fun and engaging videos will help \nstudents actually understand statistical concepts. \nAvailable with an instructors user guide and assess-\nment questions.\nMyStatLab™ Online Course (access code required)\nMyStatLab is a course management system that delivers \nproven results in helping individual students succeed.\n \n■MyStatLab can be successfully implemented in \nany environment—lab-based, hybrid, fully online, \ntraditional—and demonstrates the quantifiable differ-\nence that integrated usage has on student retention, \nsubsequent success, and overall achievement.\n \n■MyStatLab’s comprehensive online gradebook au-\ntomatically tracks students’ results on tests, quizzes, \nhomework, and in the study plan. Instructors can use \nthe gradebook to provide positive feedback or inter-\nvene if students have trouble. Gradebook data can be \neasily exported to a variety of spreadsheet programs, \nsuch as Microsoft Excel. You can determine which \npoints of data you want to export, and then analyze \nthe results to determine success.\nMyStatLab provides engaging experiences that personal-\nize, stimulate, and measure learning for each student. In \naddition to the resources below, each course includes a full \ninteractive online version of the accompanying textbook.\n \n■Tutorial Exercises with Multimedia Learning Aids: \nThe homework and practice exercises in MyStatLab \nalign with the exercises in the textbook, and they \nregenerate algorithmically to give students unlim-\nited opportunity for practice and mastery. Exercises \noffer immediate helpful feedback, guided solutions, \nsample problems, animations, videos, and eText clips \nfor extra help at point-of-use.\n \n■Getting Ready for Statistics: A library of questions \nnow appears within each MyStatLab course to offer \nthe developmental math topics students need for the \ncourse. These can be assigned as a prerequisite to \nother assignments, if desired.\n \n■Conceptual Question Library: In addition to algo-\nrithmically regenerated questions that are aligned with \nyour textbook, there is a library of 1000 Conceptual \nQuestions available in the assessment manager that re-\nquire students to apply their statistical understanding.\n \n■StatCrunch™: MyStatLab integrates the web-based \nstatistical software, StatCrunch, within the online as-\nsessment platform so that students can easily analyze \ndata sets from exercises and the text. In addition, \nMyStatLab includes access to www.StatCrunch.com, \na website where users can access more than 15,000 \nshared data sets, conduct online surveys, perform \ncomplex analyses using the powerful statistical \nsoftware, and generate compelling reports.\n \n■Statistical Software Support: Knowing that  students \noften use external statistical software, we make it \neasy to copy our data sets, both from the ebook and \nthe MyStatLab questions, into software such as \nStatCrunch, Minitab, Excel, and more. Students have \naccess to a variety of support tools—Technology  \nTutorial Videos, Technology Study Cards, and Tech-\nnology Manuals for select titles—to learn how to \neffectively use statistical software.\nMathXL® for Statistics Online Course (access code \nrequired)\nMathXL® is the homework and assessment engine that \nruns MyStatLab. (MyStatLab is MathXL plus a learning \nmanagement system.)\nWith MathXL for Statistics, instructors can:\n \n■Create, edit, and assign online homework and tests \nusing algorithmically generated exercises correlated \nat the objective level to the textbook.\n \n■Create and assign their own online exercises and \nimport TestGen tests for added flexibility.\n \n■Maintain records of all student work, tracked in \nMathXL’s online gradebook.\nWith MathXL for Statistics, students can:\n \n■Take chapter tests in MathXL and receive personal-\nized study plans and>or personalized homework \nassignments based on their test results.\n \n■Use the study plan and>or the homework to link \ndirectly to tutorial exercises for the objectives they \nneed to study.\n \n■Students can also access supplemental animations \nand video clips directly from selected exercises.\n \n■Knowing that students often use external statistical \nsoftware, we make it easy to copy our data sets, both \nfrom the ebook and the MyStatLab questions, into \nsoftware like StatCrunch™, Minitab, Excel, and more.\n\nxvi\t\nPreface\nMathXL for Statistics is available to qualified adopters. \nFor more information, visit our website at www.mathxl \n.com, or contact your Pearson representative.\nStatCrunch™\nStatCrunch is powerful, web-based statistical software \nthat allows users to perform complex analyses, share data \nsets, and generate compelling reports. A vibrant online \ncommunity offers more than 15,000 data sets for students \nto analyze.\n■\n■Collect. Users can upload their own data to ­StatCrunch \nor search a large library of publicly shared data sets, \nspanning almost any topic of interest. Also, an online \nsurvey tool allows users to quickly collect data via \nweb-based surveys.\n■\n■Crunch. A full range of numerical and graphical \nmethods allow users to analyze and gain insights \nfrom any data set. Interactive graphics help users \nunderstand statistical concepts and are available for \nexport to enrich reports with visual representations \nof data.\n■\n■Communicate. Reporting options help users create a \nwide variety of visually appealing representations of \ntheir data.\nFull access to StatCrunch is available with ­MyStatLab \nand StatCrunch is available by itself to qualified adopt-\ners. StatCrunch Mobile is now available to access from \nyour mobile device. For more information, visit our web-\nsite at www.StatCrunch.com, or contact your Pearson \n­representative.\nMinitab® 17 and Minitab Express™ make learning sta-\ntistics easy and provide students with a skill-set that’s \nin demand in today’s data driven workforce. Bundling \nMinitab® software with educational materials ensures stu-\ndents have access to the software they need in the class-\nroom, around campus, and at home. And having 12 month \nversions of Minitab 17 and Minitab Express available \nensures students can use the software for the duration of \ntheir course.\nISBN 13: 978-0-13-445640-9\nISBN 10: 0-13-445640-8 (Access Card only; not sold as \nstand alone.)\nJMP Student Edition, Version 12 is an easy-to-use, stream-\nlined version of JMP desktop statistical discovery software \nfrom SAS Institute, Inc., and is available for bundling with \nthe text.\n(ISBN-13: 978-0-13-467979-2 ISBN-10: 0-13-467979-2)\n\nStatistical and Critical \nThinking\nTypes of Data\nCollecting Sample Data\n1-1\n1-2\n1-3\nSurvey Question: Do You Need Caffeine to Start Up Your Brain for the Day?\nCHAPTER \nPROBLEM\nIntroduction  \nto Statistics\n1\nSurveys provide data that enable us to improve products or \nservices. Surveys guide political candidates, shape business \npractices, identify effective medical treatments, and affect \nmany aspects of our lives. Surveys give us insight into the \nopinions and behaviors of others. As an example, the National \nHealth and Nutrition Examination Survey (NHANES) is part \n1\nof a research program that studies the health and nutrition of \nthousands of adults and children in the United States.\nLet’s consider one USA Today survey in which respondents \nwere asked if they need caffeine to start up their brain for the \nday. Among 2,006 respondents, 74% said that they did need the \ncaffeine. Figure 1-1 includes graphs that depict these results.\n\nThe survey results suggest that people overwhelmingly need caffeine to start up their brains \nfor the day. The graphs in Figure 1-1 visually depict the survey results. One of the most impor-\ntant objectives of this book is to encourage the use of critical thinking so that such results are \nnot blindly accepted. We might question whether the survey results are valid. Who conducted \nthe survey? How were respondents selected? Do the graphs in Figure 1-1 depict the results \nwell, or are those graphs somehow misleading?\nThe survey results presented here have major flaws that are among the most common, so \nthey are especially important to recognize. Here are brief descriptions of each of the major flaws:\nFlaw 1: Misleading Graphs The bar chart in Figure 1-1(a) is very deceptive. By using a \nvertical scale that does not start at zero, the difference between the two percentages is grossly \nexaggerated. Figure 1-1(a) makes it appear that approximately eight times as many people \nneed the caffeine. However, with 74% needing caffeine and 26% not needing caffeine, the \nratio is actually about 3:1, rather than the 8:1 ratio that is suggested by the graph.\nThe illustration in Figure 1-1(b) is also deceptive. Again, the difference between the actual \nresponse rates of 74% (needing caffeine) and 26% (not needing caffeine) is a difference that \nis grossly distorted. The picture graph (or “pictograph”) in Figure 1-1(b) makes it appear that \n2 \nCHAPTER 1 Introduction to Statistics\nFIGURE 1-1(a) Survey Results\nFIGURE 1-1(b) Survey Results\nPeople Needing Caﬀeine to Start\nUp Brain for the Day\nPeople Not Needing Caﬀeine to Start\nUp Brain for the Day\n\nthe ratio of people needing caffeine to people not needing caffeine is roughly 9:1 instead of \nthe correct ratio of about 3:1. (Objects with area or volume can distort perceptions because \nthey can be drawn to be disproportionately larger or smaller than the data indicate.) Decep-\ntive graphs are discussed in more detail in Section 2-3, but we see here that the illustrations in \nFigure 1-1 grossly exaggerate the number of people needing caffeine.\nFlaw 2: Bad Sampling Method The aforementioned survey responses are from a USA \nToday survey of Internet users. The survey question was posted on a website and Internet \nusers decided whether to respond. This is an example of a voluntary response sample—a \nsample in which respondents themselves decide whether to participate. With a voluntary \nresponse sample, it often happens that those with a strong interest in the topic are more likely \nto participate, so the results are very questionable. For example, people who strongly feel that \nthey cannot function without their morning cup(s) of coffee might be more likely to respond to \nthe caffeine survey than people who are more ambivalent about caffeine or coffee. When using \nsample data to learn something about a population, it is extremely important to obtain sample \ndata that are representative of the population from which the data are drawn. As we proceed \nthrough this chapter and discuss types of data and sampling methods, we should focus on \nthese key concepts:\n• Sample data must be collected in an appropriate way, such as through a process of \nrandom selection.\n• If sample data are not collected in an appropriate way, the data may be so completely \nuseless that no amount of statistical torturing can salvage them.\nIt would be easy to accept the preceding survey results and blindly proceed with calcula-\ntions and statistical analyses, but we would miss the critical two flaws described above. We \ncould then develop conclusions that are fundamentally wrong and misleading. Instead, we \nshould develop skills in statistical thinking and critical thinking so that we are better prepared \nto analyze such data.\nChapter Objectives \n3\nThe single most important concept presented in this chapter is this: When using meth-\nods of statistics with sample data to form conclusions about a population, it is absolutely \nessential to collect sample data in a way that is appropriate. Here are the main chapter \nobjectives:\nStatistical and Critical Thinking\n• Analyze sample data relative to context, source, and sampling method.\n• Understand the difference between statistical significance and practical significance.\n• Define and identify a voluntary response sample and know that statistical conclu-\nsions based on data from such a sample are generally not valid.\n1-1\nCHAPTER OBJECTIVES\n>>>\n\n4 \nCHAPTER 1 Introduction to Statistics\nBecause populations are often very large, a common objective of the use of statis-\ntics is to obtain data from a sample and then use those data to form a conclusion about \nthe population.\nTypes of Data\n• Distinguish between a parameter and a statistic.\n• Distinguish between quantitative data and categorical (or qualitative or attribute) data.\n• Distinguish between discrete data and continuous data.\n• Determine whether basic statistical calculations are appropriate for a particular data set.\nCollecting Sample Data\n• Define and identify a simple random sample.\n• Understand the importance of sound sampling methods and the importance of \ngood design of experiments.\n1-2\n1-3\nTypes of Data\n• Distinguish between a parameter and a\nr r\nstatistic.\n• Distinguish between quantitative data and categorical (or \nl l\nqualitative or attribute) data.\n• Distinguish between discrete data and continuous data.\n• Determine whether basic statistical calculations are appropriate for a particular data set.\nCollecting Sample Data\n• Define and identify a simple random sample.\n• Understand the importance of sound sampling methods and the importance of \ngood design of experiments.\nKey Concept In this section we begin with a few very basic definitions, and then we \nconsider an overview of the process involved in conducting a statistical study. This \nprocess consists of “prepare, analyze, and conclude.” “Preparation” involves consid-\neration of the context, the source of data, and sampling method. In future chapters we \nconstruct suitable graphs, explore the data, and execute computations required for the \nstatistical method being used. In future chapters we also form conclusions by deter-\nmining whether results have statistical significance and practical significance.\nStatistical thinking involves critical thinking and the ability to make sense of results. \nStatistical thinking demands so much more than the ability to execute complicated cal-\nculations. Through numerous examples, exercises, and discussions, this text will help \nyou develop the statistical thinking skills that are so important in today’s world.\nWe begin with some very basic definitions.\n1-1 \nStatistical and Critical Thinking\nDEFINITIONS\nData are collections of observations, such as measurements, or survey responses. \n(A single data value is called a datum, a term rarely used. The term “data” is plural, \nso it is correct to say “data are…” not “data is…”)\nStatistics is the science of planning studies and experiments; obtaining data; and \norganizing, summarizing, presenting, analyzing, and interpreting those data and \nthen drawing conclusions based on them.\nA population is the complete collection of all measurements or data that are be-\ning considered. Typically, the population is the complete collection of data that we \nwould like to make inferences about.\nA census is the collection of data from every member of the population.\nA sample is a subcollection of members selected from a population.\n\n1-1 Statistical and Critical Thinking \n5\nWe now proceed to consider the process involved in a statistical study. See Figure 1-2 \nfor a summary of this process and note that the focus is on critical thinking, not mathe-\nmatical calculations. Thanks to wonderful developments in technology, we have power-\nful tools that effectively do the number crunching so that we can focus on understanding \nand interpreting results.\nEXAMPLE 1  Residential Carbon Monoxide Detectors\nIn the journal article “Residential Carbon Monoxide Detector Failure Rates in the \nUnited States” (by Ryan and Arnold, American Journal of Public Health, Vol. 101, \nNo. 10), it was stated that there are 38 million carbon monoxide detectors installed \nin the United States. When 30 of them were randomly selected and tested, it was \nfound that 12 of them failed to provide an alarm in hazardous carbon monoxide \nconditions. In this case, the population and sample are as follows:\nPopulation: All 38 million carbon monoxide detectors in the United States \nSample: The 30 carbon monoxide detectors that were selected and tested \nThe objective is to use the sample data as a basis for drawing a conclusion about the \npopulation of all carbon monoxide detectors, and methods of statistics are helpful in \ndrawing such conclusions.\nConclude\n1. Signiﬁcance\n• Do the results have statistical signiﬁcance?\n• Do the results have practical signiﬁcance?\nAnalyze\n1. Graph the Data\n2. Explore the Data\n• Are there any outliers (numbers very far away from almost all of the other data)?\n• What important statistics summarize the data (such as the mean and standard deviation\n described in Chapter 3)?\n• How are the data distributed?\n• Are there missing data?\n• Did many selected subjects refuse to respond?\n3. Apply Statistical Methods\n• Use technology to obtain results.\nPrepare\n1. Context\n• What do the data represent?\n• What is the goal of study? \n2. Source of the Data\n• Are the data from a source with a special interest so that there is pressure to obtain \n results that are favorable to the source?\n3. Sampling Method\n \n• Were the data collected in a way that is unbiased, or were the data collected in a \n way that is biased (such as a procedure in which respondents volunteer to participate)?\nFIGURE 1-2 Statistical Thinking\nSurvivorship Bias\nIn World War \nII, statisti-\ncian Abraham \nWald saved \nmany lives \nwith his work \non the Applied \nMathematics Panel. Military \nleaders asked the panel how they \ncould improve the chances of \naircraft bombers returning after \nmissions. They wanted to add \nsome armor for protection, and \nthey recorded locations on the \nbombers where damaging holes \nwere found. They reasoned that \narmor should be placed in loca-\ntions with the most holes, but \nWald said that strategy would be \na big mistake. He said that armor \nshould be placed where returning \nbombers were not damaged. His \nreasoning was this: The bombers \nthat made it back with damage \nwere survivors, so the damage \nthey suffered could be survived. \nLocations on the aircraft that \nwere not damaged were the most \nvulnerable, and aircraft suffer-\ning damage in those vulnerable \nareas were the ones that did \nnot make it back. The military \nleaders would have made a big \nmistake with survivorship bias by \nstudying the planes that survived \ninstead of thinking about the \nplanes that did not survive.\n\n6 \nCHAPTER 1 Introduction to Statistics\nPrepare\nContext Figure 1-2 suggests that we begin our preparation by considering the context \nof the data, so let’s start with context by considering the data in Table 1-1. (The data \nare from Data Set 9 “IQ and Brain Size” in Appendix B.) The data in Table 1-1 consist \nof measured IQ scores and measured brain volumes from 10 different subjects. The \ndata are matched in the sense that each individual “IQ>brain volume” pair of values \nis from the same person. The first subject had a measured IQ score of 96 and a brain \nvolume of 1005 cm3. The format of Table 1-1 suggests the following goal: Determine \nwhether there is a relationship between IQ score and brain volume. This goal suggests \na possible hypothesis: People with larger brains tend to have higher IQ scores.\nSource of the Data The data in Table 1-1 were provided by M. J. Tramo, W. C. \nLoftus, T. A. Stukel, J. B. Weaver, and M. S. Gazziniga, who discuss the data in the \narticle “Brain Size, Head Size, and IQ in Monozygotic Twins,” Neurology, Vol. 50. \nThe researchers are from reputable medical schools and hospitals, and they would not \ngain by presenting the results in way that is misleading. In contrast, Kiwi Brands, a \nmaker of shoe polish, commissioned a study that resulted in this statement, which was \nprinted in some newspapers: “According to a nationwide survey of 250 hiring profes-\nsionals, scuffed shoes was the most common reason for a male job seeker’s failure to \nmake a good first impression.”\nWhen physicians who conduct clinical experiments on the efficacy of drugs re-\nceive funding from drug companies, they have an incentive to obtain favorable results. \nSome professional journals, such as the Journal of the American Medical Association, \nnow require that physicians report sources of funding in journal articles. We should be \nskeptical of studies from sources that may be biased.\nSampling Method Figure 1-2 suggests that we conclude our preparation by consid-\nering the sampling method. The data in Table 1-1 were obtained from subjects whose \nmedical histories were reviewed in an effort to ensure that no subjects had neurologic \nor psychiatric disease. In this case, the sampling method appears to be sound, but we \ncannot be sure of that without knowing how the subjects were recruited and whether \nany payments may have affected participation in the study.\nSampling methods and the use of randomization will be discussed in Section 1-3, \nbut for now, we stress that a sound sampling method is absolutely essential for good \nresults in a statistical study. It is generally a bad practice to use voluntary response (or \nself-selected) samples, even though their use is common.\nTABLE 1-1 IQ Scores and Brain Volumes (cm3)\nIQ\n96\n87\n101\n103\n127\n96\n88\n85\n97\n124\nBrain Volume (cm3)\n1005\n1035\n1281\n1051\n1034\n1079\n1104\n1439\n1029\n1160\nDEFINITION\nA voluntary response sample (or self-selected sample) is one in which the \nrespondents themselves decide whether to be included.\nThe following types of polls are common examples of voluntary response samples. \nBy their very nature, all are seriously flawed because we should not make conclusions \nabout a population on the basis of samples with a strong possibility of bias:\n \n■Internet polls, in which people online can decide whether to respond\n \n■Mail-in polls, in which people decide whether to reply\nOrigin of “Statistics”\nThe word \nstatistics is \nderived from \nthe Latin word \nstatus (mean-\ning “state”). \nEarly uses of \nstatistics involved compilations \nof data and graphs describing \nvarious aspects of a state or \ncountry. In 1662, John Graunt \npublished statistical information \nabout births and deaths. Graunt’s \nwork was followed by studies \nof mortality and disease rates, \npopulation sizes, incomes, and \nunemployment rates. House-\nholds, governments, and busi-\nnesses rely heavily on statistical \ndata for guidance. For example, \nunemployment rates, inflation \nrates, consumer indexes, and \nbirth and death rates are carefully \ncompiled on a regular basis, \nand the resulting data are used \nby business leaders to make \ndecisions affecting future hiring, \nproduction levels, and expansion \ninto new markets.\n\n1-1 Statistical and Critical Thinking \n7\n \n■Telephone call-in polls, in which newspaper, radio, or television announcements \nask that you voluntarily call a special number to register your opinion\nThe Chapter Problem involves a USA Today survey with a voluntary response sample. \nSee also the following Example 2.\nEXAMPLE 2  Voluntary Response Sample\nUSA Today posted this question on the electronic edition of their newspaper: “Have \nyou ever been bitten by an animal?” Internet users who saw that question then de-\ncided themselves whether to respond. Among the 2361 responses, 65% said “yes” \nand 35% said “no.” Because the 2361 subjects themselves chose to respond, they \nare a voluntary response sample and the results of the survey are highly question-\nable. It would be much better to get results through a poll in which the pollster ran-\ndomly selects the subjects, instead of allowing the subjects to volunteer themselves.\nAnalyze\nFigure 1-2 indicates that after completing our preparation by considering the context, \nsource, and sampling method, we begin to analyze the data.\nGraph and Explore An analysis should begin with appropriate graphs and explora-\ntions of the data. Graphs are discussed in Chapter 2, and important statistics are dis-\ncussed in Chapter 3.\nApply Statistical Methods Later chapters describe important statistical methods, \nbut application of these methods is often made easy with technology (calculators \nand>or statistical software packages). A good statistical analysis does not require \nstrong computational skills. A good statistical analysis does require using common \nsense and paying careful attention to sound statistical methods.\nConclude\nFigure 1-2 shows that the final step in our statistical process involves conclusions, and \nwe should develop an ability to distinguish between statistical significance and practi-\ncal significance.\nStatistical Significance Statistical significance is achieved in a study when we get \na result that is very unlikely to occur by chance. A common criterion is that we have \nstatistical significance if the likelihood of an event occurring by chance is 5% or less.\n \n■Getting 98 girls in 100 random births is statistically significant because such an \nextreme outcome is not likely to result from random chance.\n \n■Getting 52 girls in 100 births is not statistically significant because that event \ncould easily occur with random chance.\nPractical Significance It is possible that some treatment or finding is effective, but \ncommon sense might suggest that the treatment or finding does not make enough of a \ndifference to justify its use or to be practical, as illustrated in Example 3 which follows.\n\n8 \nCHAPTER 1 Introduction to Statistics\nAnalyzing Data: Potential Pitfalls\nHere are a few more items that could cause problems when analyzing data.\nMisleading Conclusions When forming a conclusion based on a statistical analy-\nsis, we should make statements that are clear even to those who have no understand-\ning of statistics and its terminology. We should carefully avoid making statements \nnot justified by the statistical analysis. For example, later in this book we introduce \nthe concept of a correlation, or association between two variables, such as smoking \nand pulse rate. A statistical analysis might justify the statement that there is a cor-\nrelation between the number of cigarettes smoked and pulse rate, but it would not \njustify a statement that the number of cigarettes smoked causes a person’s pulse rate \nto change. Such a statement about causality can be justified by physical evidence, not \nby statistical analysis.\nCorrelation does not imply causation.\nSample Data Reported Instead of Measured When collecting data from people, \nit is better to take measurements yourself instead of asking subjects to report results. \nAsk people what they weigh and you are likely to get their desired weights, not their \nactual weights. People tend to round, usually down, sometimes way down. When \nasked, someone with a weight of 187 lb might respond that he or she weighs 160 lb. \nAccurate weights are collected by using a scale to measure weights, not by asking \npeople what they weigh.\nLoaded Questions If survey questions are not worded carefully, the results of a \nstudy can be misleading. Survey questions can be “loaded” or intentionally worded to \nelicit a desired response. Here are the actual rates of “yes” responses for the two dif-\nferent wordings of a question:\n97% yes: “Should the President have the line item veto to eliminate waste?”\n57% yes: “Should the President have the line item veto, or not?”\nOrder of Questions Sometimes survey questions are unintentionally loaded \nby such factors as the order of the items being considered. See the following two \nEXAMPLE 3   Statistical Significance Versus  \nPractical Significance\nProCare Industries once supplied a product named Gender Choice that supposedly \nincreased the chance of a couple having a baby with the gender that they desired. \nIn the absence of any evidence of its effectiveness, the product was banned by the \nFood and Drug Administration (FDA) as a “gross deception of the consumer.” But \nsuppose that the product was tested with 10,000 couples who wanted to have baby \ngirls, and the results consist of 5200 baby girls born in the 10,000 births. This re-\nsult is statistically significant because the likelihood of it happening due to chance \nis only 0.003%, so chance doesn’t seem like a feasible explanation. That 52% rate \nof girls is statistically significant, but it lacks practical significance because 52% is \nonly slightly above 50%. Couples would not want to spend the time and money to \nincrease the likelihood of a girl from 50% to 52%. (Note: In reality, the likelihood \nof a baby being a girl is about 48.8%, not 50%.)\n\n1-1 Statistical and Critical Thinking \n9\nquestions from a poll conducted in Germany, along with the very different response \nrates:\n“Would you say that traﬃc contributes more or less to air pollution than indus-\ntry?” (45% blamed traﬃc; 27% blamed industry.)\n“Would you say that industry contributes more or less to air pollution than traf-\nﬁc?” (24% blamed traﬃc; 57% blamed industry.)\nIn addition to the order of items within a question, as illustrated above, the order of \nseparate questions could also affect responses.\nNonresponse A nonresponse occurs when someone either refuses to respond to \na survey question or is unavailable. When people are asked survey questions, some \nfirmly refuse to answer. The refusal rate has been growing in recent years, partly be-\ncause many persistent telemarketers try to sell goods or services by beginning with a \nsales pitch that initially sounds as though it is part of an opinion poll. (This “selling \nunder the guise” of a poll is called sugging.) In Lies, Damn Lies, and Statistics, author \nMichael Wheeler makes this very important observation:\nPeople who refuse to talk to pollsters are likely to be different from those \nwho do not. Some may be fearful of strangers and others jealous of their \nprivacy, but their refusal to talk demonstrates that their view of the \nworld around them is markedly different from that of those people who \nwill let poll-takers into their homes.\nPercentages Some studies cite misleading or unclear percentages. Note that 100% \nof some quantity is all of it, but if there are references made to percentages that exceed \n100%, such references are often not justified. If a medical researcher claims that she \nhas developed a treatment for migraine headaches and the treatment results in a 150% \nreduction in those headaches, that researcher cannot be correct, because totally elimi-\nnating all migraine headaches would be a 100% reduction. It is impossible to reduce \nthe number of migraine headaches by more than 100%.\nWhen working with percentages, we should know that % or “percent” really \nmeans “divided by 100.” Here is a principle used often in this book.\nPercentage of: To ﬁnd a percentage of an amount, replace the % symbol with \ndivision by 100, and then interpret “of” to be multiplication. The following \n calculation shows that 6% of 1200 is 72:\n6% of 1200 responses =\n6\n100 * 1200 = 72\nStatistical Literacy and Critical Thinking\n1. Online Medical Info USA Today posted this question on its website: “How often do you seek \nmedical information online?” Of 1072 Internet users who chose to respond, 38% of them responded \nwith “frequently.” What term is used to describe this type of survey in which the people surveyed \nconsist of those who decided to respond? What is wrong with this type of sampling method?\n2. Reported Versus Measured In a survey of 1046 adults conducted by Bradley Corpora-\ntion, subjects were asked how often they wash their hands when using a public restroom, and \n70% of the respondents said “always.”\na. Identify the sample and the population.\nb. Why would better results be obtained by observing the hand washing instead of asking about it?\n1-1 Basic Skills and Concepts\ne \nPublication Bias\nThere is a “pub-\nlication bias” \nin professional \njournals. It is \nthe tendency to \npublish positive \nresults (such \nas showing that some treatment \nis effective) much more often \nthan negative results (such as \nshowing that some treatment has \nno effect). In the article “Regis-\ntering Clinical Trials” (Journal of \nthe American Medical Asso-\nciation, Vol. 290, No. 4), authors \nKay Dickersin and Drummond \n Rennie state that “the result of \nnot knowing who has performed \nwhat (clinical trial) is loss and \ndistortion of the evidence, waste \nand duplication of trials, inability \nof funding agencies to plan, and \na chaotic system from which \nonly certain sponsors might \nbenefit, and is invariably against \nthe interest of those who offered \nto participate in trials and of \npatients in general.” They sup-\nport a process in which all clinical \ntrials are registered in one central \nsystem, so that future research-\ners have access to all previous \nstudies, not just the studies that \nwere published.\n\n10 \nCHAPTER 1 Introduction to Statistics\n3. Statistical Significance Versus Practical Significance When testing a new treatment, \nwhat is the difference between statistical significance and practical significance? Can a treat-\nment have statistical significance, but not practical significance?\n4. Correlation One study showed that for a recent period of 11 years, there was a strong cor-\nrelation (or association) between the numbers of people who drowned in swimming pools and \nthe amounts of power generated by nuclear power plants (based on data from the Centers for \nDisease Control and Prevention and the Department of Energy). Does this imply that increas-\ning power from nuclear power plants is the cause of more deaths in swimming pools? Why or \nwhy not?\nConsider the Source. In Exercises 5–8, determine whether the given source has the \n potential to create a bias in a statistical study.\n5. Physicians Committee for Responsible Medicine The Physicians Committee for Re-\nsponsible Medicine tends to oppose the use of meat and dairy products in our diets, and that \norganization has received hundreds of thousands of dollars in funding from the Foundation to \nSupport Animal Protection.\n6. Arsenic in Rice Amounts of arsenic in samples of rice grown in Texas were measured by \nthe Food and Drug Administration (FDA).\n7. Brain Size A data set in Appendix B includes brain volumes from 10 pairs of monozygotic \n(identical) twins. The data were collected by researchers at Harvard University, Massachusetts \nGeneral Hospital, Dartmouth College, and the University of California at Davis.\n8. Chocolate An article in Journal of Nutrition (Vol. 130, No. 8) noted that chocolate is rich \nin flavonoids. The article notes “regular consumption of foods rich in flavonoids may reduce \nthe risk of coronary heart disease.” The study received funding from Mars, Inc., the candy com-\npany, and the Chocolate Manufacturers Association.\nSampling Method. In Exercises 9–12, determine whether the sampling method appears \nto be sound or is flawed.\n9. Nuclear Power Plants In a survey of 1368 subjects, the following question was posted \non the USA Today website: “In your view, are nuclear plants safe?” The survey subjects \nwere Internet users who chose to respond to the question posted on the electronic edition of \nUSA Today.\n10. Clinical Trials Researchers at Yale University conduct a wide variety of clinical trials by \nusing subjects who volunteer after reading advertisements soliciting paid volunteers.\n11. NHANES Examinations In a recent year, the National Health and Nutrition Examina-\ntion Survey (NHANES), sponsored by the National Center for Health Statistics, selected \nmore than 9000 subjects who were given physical exams. Subjects were selected through \na somewhat complicated procedure designed to obtain results that are representative of the \npopulation.\n12. Health In a survey of 3014 randomly selected U.S. adults, 45% reported that they have \nat least one chronic health condition, such as diabetes or high blood pressure. The survey was \nconducted by Princeton Survey Research Associates International.\nStatistical Significance and Practical Significance. In Exercises 13–16, determine \nwhether the results appear to have statistical significance, and also determine whether the \nresults appear to have practical significance.\n13. Diet and Exercise Program In a study of the Kingman diet and exercise program, \n40  subjects lost an average of 22 pounds. There is about a 1% chance of getting such results \nwith a program that has no effect.\n\n1-1 Statistical and Critical Thinking \n11\n14. MCAT The Medical College Admissions Test (MCAT) is commonly used as part of the \n decision-making process for determining which students to accept into medical schools. To test \nthe effectiveness of the Siena MCAT preparation course, 16 students take the MCAT test, then \nthey complete the preparatory course, and then they retake the MCAT test, with the result that the \naverage (mean) score for this group rises from 25 to 30. There is a 0.3% chance of getting those \nresults by chance. Does the course appear to be effective?\n15. Gender Selection In a study of the Gender Aide method of gender selection used to \n increase the likelihood of a baby being born a girl, 2000 users of the method gave birth to \n980 boys and 1020 girls. There is about a 19% chance of getting that many girls if the method \nhad no effect.\n16. Systolic Blood Pressure High systolic blood pressure is 140 mm Hg or higher.  (Normal \nvalues are less than 120 mm Hg, and prehypertension levels are between 120 mm Hg and \n139 mm Hg.) Subjects with high blood pressure are encouraged to take action to lower it. A \npharmaceutical company develops a new medication designed to lower blood pressure, and \ntests on 25 subjects result in an average (mean) decrease of 2 mm Hg. Analysis of the results \nshows that there is a 15% chance of getting such results if the medication has no effect.\nIn Exercises 17–20, refer to the sample of body temperatures (degrees Fahrenheit) in the \ntable below. (The body temperatures are recorded on the same day from a sample of five \nrandomly selected males listed in a data set in Appendix B.)\nSubject\n1\n2\n3\n4\n5\n8 AM\n97.0\n98.5\n97.6\n97.7\n98.7\n12 AM\n97.6\n97.8\n98.0\n98.4\n98.4\n17. Context of the Data Refer to the table of body temperatures. Is there some meaning-\nful way in which each body temperature recorded at 8 AM is matched with the 12 AM \n temperature?\n18. Source The listed body temperatures were obtained from Dr. Steven Wasserman, Dr. \nPhilip Mackowiak, and Dr. Myron Levine, who were researchers at the University of Maryland. \nIs the source of the data likely to be biased?\n19. Conclusion Given the body temperatures in the table, what issue can be addressed by con-\nducting a statistical analysis of the data?\n20. Conclusion If we analyze the listed body temperatures with suitable methods of statistics, \nwe conclude that when the differences are found between the 8 AM body temperatures and \nthe 12 AM body temperatures, there is a 64% chance that the differences can be explained by \nrandom results obtained from populations that have the same 8 AM and 12 AM body tempera-\ntures. What should we conclude about the statistical significance of those differences?\nIn Exercises 21–24, refer to the data in the table below. The entries are white blood cell \ncounts (1000 cells,ML) and red blood cell counts (million cells,ML) from male subjects \n examined as part of a large health study conducted by the National Center for Health Statis-\ntics. The data are matched, so that the first subject has a white blood cell count of 8.7 and a \nred blood cell count of 4.91, and so on.\nSubject\n1\n2\n3\n4\n5\nWhite\n8.7\n5.9\n7.3\n6.2\n5.9\nRed\n4.91\n5.59\n4.44\n4.80\n5.17\ncontinued\n\n12 \nCHAPTER 1 Introduction to Statistics\n21. Context Given that the data (on the bottom of the preceding page) are matched and consid-\nering the units of the data, does it make sense to use the difference between each white blood \ncell count and the corresponding red blood cell count? Why or why not?\n22. Analysis Given the context of the data in the table (on the bottom of the preceding page), \nwhat issue can be addressed by conducting a statistical analysis of the measurements?\n23. Source of the Data Considering the source of the data (on the bottom of the preceding \npage), does that source appear to be biased in some way?\n24. Conclusion If we analyze the sample data (on the bottom of the preceding page) and \nconclude that there is a correlation between white and red blood cell counts, does it follow that \nhigher white are the cause of higher red blood cell counts?\nWhat’s Wrong? In Exercises 25–28, identify what is wrong.\n25. Potatoes In a poll sponsored by the Idaho Potato Commission, 1000 adults were asked to \nselect their favorite vegetables, and the favorite choice was potatoes, which were selected by \n26% of the respondents.\n26. Healthy Water In a USA Today online poll, 951 Internet users chose to respond, and 57% \nof them said that they prefer drinking bottled water instead of tap water.\n27. Cheese and Bedsheet Deaths In recent years, there has been a strong correlation be-\ntween per capita consumption of cheese in the United States and the numbers of people who \ndied from being tangled in their bedsheets. Really. Therefore, consumption of cheese causes \nbedsheet entanglement fatalities.\n28. Smokers The electronic cigarette maker V2 Cigs sponsored a poll showing that 55% of \nsmokers surveyed say that they feel ostracized “sometimes,” “often,” or “always.”\nPercentages. In Exercises 29 and 30, answer the given questions, which are related to \npercentages.\n29. Health It was noted in Exercise 12 “Health” that in a survey of 3014 randomly selected \nU.S. adults, 45% reported that they have at least one chronic health condition, such as diabetes \nor high blood pressure.\na. What is 45% of 3014 adults?\nb. Could the result from part (a) be the actual number of survey subjects who have at least one \nchronic condition?\nc. What is the actual number of survey subjects who have at least one chronic condition?\nd. Among those surveyed, 1808 were called by landline and 1206 were called by cell phone. \nWhat percentage of the survey subjects were called by cell phone?\n30. Chillax USA Today reported results from a Research Now for Keurig survey in which \n1458 men and 1543 women were asked this: “In a typical week, how often can you kick back \nand relax?”\na. Among the women, 19% responded with “rarely, if ever.” What is the exact value that is 19% \nof the number of women surveyed?\nb. Could the result from part (a) be the actual number of women who responded with “rarely, if \never”? Why or why not?\nc. What is the actual number of women who responded with “rarely, if ever”?\nd. Among the men who responded, 219 responded with “rarely, if ever.” What is the percentage \nof men who responded with “rarely, if ever”?\ne. Consider the question that the subjects were asked. Is that question clear and unambiguous so \nthat all respondents will interpret the question the same way? How might the survey be improved?\n\n1-2 Types of Data \n13\nIf we have more than one statistic, we have “statistics.” Another meaning of “statis-\ntics” was given in Section 1-1, where we defined statistics to be the science of plan-\nning studies and experiments; obtaining data; organizing, summarizing, presenting, \nanalyzing, and interpreting those data; and then drawing conclusions based on them. \nWe now have two different definitions of statistics, but we can determine which of \nthese two definitions applies by considering the context in which the term statistics is \nused, as in the following example.\n31. What’s Wrong with This Picture? The Newport Chronicle ran a survey by asking read-\ners to call in their response to this question: “Do you support a ban on electronic cigarettes, \nwhich foster smoking among our children?” It was reported that 20 readers responded and that \n87% said “no,” while 13% said “yes.” Identify four major flaws in this survey.\n32. Falsifying Data A researcher at the Sloan-Kettering Cancer Research Center was once \ncriticized for falsifying data. Among his data were figures obtained from 6 groups of mice, \nwith 20 individual mice in each group. The following values were given for the percentage of \nsuccesses in each group: 53%, 58%, 63%, 46%, 48%, 67%. What’s wrong with those values?\n1-1 Beyond the Basics\nDEFINITIONS\nA parameter is a numerical measurement describing some characteristic of a \npopulation.\nA statistic is a numerical measurement describing some characteristic of a sample.\nHINT The alliteration in “population parameter” and “sample statistic” helps us \nremember the meanings of these terms.\nEXAMPLE 1  Parameter, Statistic\nThere are 17,246,372 high school students in the United States. In a study of 8505 \nU.S. high school students 16 years of age or older, 44.5% of them said that they \ntexted while driving at least once during the previous 30 days (based on data in \nKey Concept A major use of statistics is to collect and use sample data to make con-\nclusions about populations. We should know and understand the meanings of the terms \nstatistic and parameter, as defined below. In this section we describe a few different \ntypes of data. The type of data is one of the key factors that determine the statistical \nmethods we use in our analysis.\nIn Part 1 of this section we describe the basics of different types of data, and then \nin Part 2 we consider “big data” and missing data.\nPART 1\n Basic Types of Data\nParameter, Statistic\n \n1-2 \nTypes of Data\ncontinued\n\n14 \nCHAPTER 1 Introduction to Statistics\nQuantitative, Categorical\nSome data are numbers representing counts or measurements (such as a systolic blood \npressure of 118 mm Hg), whereas others are attributes (such as eye color of green or \nbrown) that are not counts or measurements. The terms quantitative data and cat-\negorical data distinguish between these types.\n“Texting While Driving and Other Risky Motor Vehicle Behaviors Among U.S. \nHigh School Students,” by Olsen, Shults, Eaton, Pediatrics, Vol. 131, No. 6).\n \n1. Parameter: The population size of all 17,246,372 high school students is a \nparameter, because it is the size of the entire population of all high school \nstudents in the United States. If we somehow knew the percentage of all \n17,246,372 high school students who reported they had texted while driving, \nthat percentage would also be a parameter.\n \n2. Statistic: The value of 44.5% is a statistic, because it is based on the sample, \nnot on the entire population.\nDEFINITIONS\nQuantitative (or numerical) data consist of numbers representing counts or mea-\nsurements.\nCategorical (or qualitative or attribute) data consist of names or labels (not num-\nbers that represent counts or measurements).\nCAUTION Categorical data are sometimes coded with numbers, with those num-\nbers replacing names. Although such numbers might appear to be quantitative, \nthey are actually categorical data. See the third part of Example 2.\nInclude Units of Measurement With quantitative data, it is important to use the \nappropriate units of measurement, such as dollars, hours, feet, or meters. We should \ncarefully observe information given about the units of measurement, such as “all \namounts are in thousands of dollars,” or “all units are in kilograms.” Ignoring such \nunits of measurement can be very costly. The National Aeronautics and Space Admin-\nistration (NASA) lost its $125 million Mars Climate Orbiter when the orbiter crashed \nbecause the controlling software had acceleration data in English units, but they were \nincorrectly assumed to be in metric units.\nEXAMPLE 2  Quantitative, Categorical\n \n1. Quantitative Data: The ages (in years) of subjects enrolled in a clinical trial\n \n2. Categorical Data as Labels: The genders (male>female) of subjects enrolled \nin a clinical trial\n \n3. Categorical Data as Numbers: The identiﬁcation numbers 1, 2, 3, . . . , 25 \nare assigned randomly to the 25 subjects in a clinical trial. Those numbers \nare substitutes for names. They don’t measure or count anything, so they are \ncategorical data, not quantitative data.\n\n1-2 Types of Data \n15\nDiscrete, Continuous\nQuantitative data can be further described by distinguishing between discrete and con-\ntinuous types.\nDEFINITIONS\nDiscrete data result when the data values are quantitative and the number of \nvalues is finite or “countable.” (If there are infinitely many values, the collection of \nvalues is countable if it is possible to count them individually, such as the number \nof tosses of a coin before getting tails or the number of births in Houston before \ngetting a male.)\nContinuous (numerical) data result from infinitely many possible quantitative \nvalues, where the collection of values is not countable. (That is, it is impossible \nto count the individual items because at least some of them are on a continuous \nscale, such as the lengths of distances from 0 cm to 12 cm.)\nCAUTION The concept of countable data plays a key role in the preceding defini-\ntions, but it is not a particularly easy concept to understand. Continuous data can \nbe measured, but not counted. If you select a particular data value from continuous \ndata, there is no “next” data value. See Example 3.\n \n Continuous Data\n \n Discrete Data\nEXAMPLE 3  Discrete, Continuous\n \n1. Discrete Data of the Finite Type: Each of several physicians plans to count \nthe number of physical examinations given during the next full week. The \ndata are discrete data because they are ﬁnite numbers, such as 27 and 46 that \nresult from a counting process.\n \n2. Discrete Data of the Inﬁnite Type: Researchers plan to test the accuracy of a \nblood typing test by repeating the process of submitting a sample of the same \nblood (Type O+) until the test yields an error. It is possible that each research-\ner could repeat this test forever without ever getting an error, but they can \nstill count the number of tests as they proceed. The collection of the numbers \nof tests is countable, because you can count them, even though the counting \ncould go on forever.\n \n3. Continuous Data: When the typical patient has blood drawn as part of a \nroutine examination, the volume of blood drawn is between 0 mL and 50 mL. \nThere are inﬁnitely many values between 0 mL and 50 mL. Because it is im-\npossible to count the number of diﬀerent possible values on such a continuous \nscale, these amounts are continuous data.\n\n16 \nCHAPTER 1 Introduction to Statistics\nLevels of Measurement\nAnother common way of classifying data is to use four levels of measurement: nomi-\nnal, ordinal, interval, and ratio, all defined below. (Also see Table 1-2 for brief de-\nscriptions of the four levels of measurements.) When we are applying statistics to \nreal problems, the level of measurement of the data helps us decide which procedure \nto use. There will be references to these levels of measurement in this book, but the \nimportant point here is based on common sense: Don’t do computations and don’t use \nstatistical methods that are not appropriate for the data. For example, it would not \nmake sense to compute an average (mean) of Social Security numbers, because those \nnumbers are data used for identification, and they don’t represent measurements or \ncounts of anything.\nGRAMMAR: FEWER VERSUS LESS When describing smaller amounts, it is \ncorrect grammar to use “fewer” for discrete amounts and “less” for continuous \namounts. It is correct to say that we drank fewer cans of cola and that, in the pro-\ncess, we drank less cola. The numbers of cans of cola are discrete data, whereas \nthe volume amounts of cola are continuous data.\nDEFINITION\nThe nominal level of measurement is characterized by data that consist of \nnames, labels, or categories only. It is not possible to arrange the data in some \norder (such as low to high).\nEXAMPLE 4  Nominal Level\nHere are examples of sample data at the nominal level of measurement.\n1. Yes, No, Undecided: Survey responses of yes, no, and undecided\n \n2. Coded Survey Responses: For an item on a survey, respondents are given a \nchoice of possible answers, and they are coded as follows: “I agree” is coded \nas 1; “I disagree” is coded as 2; “I don’t care” is coded as 3; “I refuse to \nanswer” is coded as 4; “Go away and stop bothering me” is coded as 5. The \nnumbers 1, 2, 3, 4, 5 don’t measure or count anything.\nBecause nominal data lack any ordering or numerical significance, they should \nnot be used for calculations. Numbers such as 1, 2, 3, and 4 are sometimes assigned \nto the different categories (especially when data are coded for computers), but these \nnumbers have no real computational significance and any average (mean) calculated \nfrom them is meaningless and possibly misleading.\nDEFINITION\nData are at the ordinal level of measurement if they can be arranged in some \norder, but differences (obtained by subtraction) between data values either cannot \nbe determined or are meaningless.\n\n1-2 Types of Data \n17\nOrdinal data provide information about relative comparisons, but not the magni-\ntudes of the differences. Usually, ordinal data should not be used for calculations such \nas an average (mean), but this guideline is sometimes disregarded (such as when we \nuse letter grades to calculate a grade-point average).\nEXAMPLE 5  Ordinal Level\nHere is an example of sample data at the ordinal level of measurement.\nCourse Grades: A biostatistics professor assigns grades of A, B, C, D, or F. These \ngrades can be arranged in order, but we can’t determine differences between the \ngrades. For example, we know that A is higher than B (so there is an ordering), but \nwe cannot subtract B from A (so the difference cannot be found).\nDEFINITION\nData are at the interval level of measurement if they can be arranged in order, and \ndifferences between data values can be found and are meaningful; but data at this \nlevel do not have a natural zero starting point at which none of the quantity is present.\nEXAMPLE 6  Interval Level\nThese examples illustrate the interval level of measurement.\n \n1. Temperatures: Body temperatures of 98.2°F and 98.8°F are examples of data \nat this interval level of measurement. Those values are ordered, and we can \ndetermine their diﬀerence of 0.6°F. However, there is no natural starting point. \nThe value of 0°F might seem like a starting point, but it is arbitrary and does \nnot represent the total absence of heat.\n \n2. Years: The years 1492 and 1776 can be arranged in order, and the diﬀerence \nof 284 years can be found and is meaningful. However, time did not begin in \nthe year 0, so the year 0 is arbitrary instead of being a natural zero starting \npoint representing “no time.”\nDEFINITION\nData are at the ratio level of measurement if they can be arranged in order, differ-\nences can be found and are meaningful, and there is a natural zero starting point \n(where zero indicates that none of the quantity is present). For data at this level, dif-\nferences and ratios are both meaningful.\nEXAMPLE 7  Ratio Level\nThe following are examples of data at the ratio level of measurement. Note the pres-\nence of the natural zero value, and also note the use of meaningful ratios of “twice” \nand “three times.”\n \n1. Heights of Students: Heights of 180 cm and 90 cm for a high school student and a \npreschool student (0 cm represents no height, and 180 cm is twice as tall as 90 cm.)\n \n2. Class Times: The times of 50 min and 100 min for a statistics class (0 min \nrepresents no class time, and 100 min is twice as long as 50 min.)\n\n18 \nCHAPTER 1 Introduction to Statistics\nSee Table 1-2 for brief descriptions of the four levels of measurements.\nTABLE 1-2 Levels of Measurement\nLevel of \nMeasurement\n \nBrief Description\n \nExample\nRatio\nThere is a natural zero starting point and \nratios make sense.\nHeights, lengths, distances, \nvolumes\nInterval\nDifferences are meaningful, but there is \nno natural zero starting point and ratios \nare meaningless.\nBody temperatures in degrees \nFahrenheit or Celsius\nOrdinal\nData can be arranged in order, but dif-\nferences either can’t be found or are \nmeaningless.\nRanks of colleges in U.S. News & \nWorld Report\nNominal\nCategories only. Data cannot be arranged \nin order.\nEye colors\nHINT The distinction between the interval and ratio levels of measurement can \nbe a bit tricky. Here are two tools for help with that distinction:\n \n1.  Ratio Test Focus on the term “ratio” and know that the term “twice” describes the \nratio of one value to be double the other value. To distinguish between the interval \nand ratio levels of measurement, use a “ratio test” by asking this question: Does \nuse of the term “twice” make sense? “Twice” makes sense for data at the ratio level \nof measurement, but it does not make sense for data at the interval level of mea-\nsurement.\n \n2.  True Zero For ratios to make sense, there must be a value of “true zero,” where \nthe value of zero indicates that none of the quantity is present, and zero is not \nsimply an arbitrary value on a scale. The temperature of 0°F is arbitrary and \ndoes not indicate that there is no heat, so temperatures on the Fahrenheit scale \nare at the interval level of measurement, not the ratio level.\nEXAMPLE 8   Distinguishing Between the Ratio Level and  \nInterval Level\nFor each of the following, determine whether the data are at the ratio level of mea-\nsurement or the interval level of measurement:\n \na. Times (minutes) it takes to complete a statistics test.\n \nb. Body temperatures (Celsius) of statistics students.\nSOLUTION\n \na. Apply the “ratio test” described in the preceding hint. If one student completes \nthe test in 40 minutes and another student completes the test in 20 min, does it \nmake sense to say that the ﬁrst student used twice as much time? Yes! So the \ntimes are at the ratio level of measurement. Also, a time of 0 minutes does repre-\nsent “no time,” so the value of 0 is a true zero indicating that no time was used.\n \nb. Apply the “ratio test” described in the preceding hint. If one student has a \nbody temperature of 40°C and another student has a body temperature of \n20°C, does it make sense to say that the ﬁrst student is twice as hot as the \nT\nSurvey Pitfalls\nSurveys con-\nstitute a huge \nand growing \nbusiness in the \nUnited States, \nbut survey \nresults can be \ncompromised by many factors. \nA growing number of people \nrefuse to respond; the average \nresponse rate is now about 22%, \ncompared to 36% around the \nyear 2000. A growing number of \npeople are more difficult to reach \nbecause they use cell phones \n(no directories); about 15% of \nadults now have cell phones and \nno landlines, and they tend to \nbe younger than average. There \nare obvious problems associated \nwith surveys that ask respon-\ndents about drug use, theft, or \nsexual behavior, and a social \ndesirability bias occurs when sur-\nvey respondents are not honest \nbecause they don’t want to be \nviewed negatively by the person \nconducting the interview.\n\n1-2 Types of Data \n19\nPART 2\n  Big Data and Missing Data:  \nToo Much and Not Enough\nWhen working with data, we might encounter some data sets that are excessively \nlarge, and we might also encounter some data sets with individual elements missing. \nHere in Part 2 we briefly discuss both cases.\nBig Data\nEdward Snowden used his employment at the NSA (National Security Agency) to re-\nveal substantial top secret documents that led to the realization that the NSA was con-\nducting telephone and Internet surveillance of U.S. citizens as well as world leaders. \nThe NSA was collecting massive amounts of data that were analyzed in an attempt to \nprevent terrorism. Monitoring telephone calls and Internet communications is made \npossible with modern technology. The NSA can compile big data, and such ginormous \ndata sets have led to the birth of data science. There is not universal agreement on the \nfollowing definitions, and various other definitions can be easily found elsewhere.\n second student? (Ignore subjective amounts of attractiveness and consider \nonly science.) No! So the body temperatures are not at the ratio level of \nmeasurement. Because the diﬀerence between 40°C and 20°C is the same as \nthe diﬀerence between 90°C and 70°C, the diﬀerences are meaningful, but be-\ncause ratios do not make sense, the body temperatures are at the interval level \nof measurement. Also, the temperature of 0°C does not represent “no heat” so \nthe value of 0 is not a true zero indicating that no heat is present.\nDEFINITIONS\nBig data refers to data sets so large and so complex that their analysis is beyond \nthe capabilities of traditional software tools. Analysis of big data may require soft-\nware simultaneously running in parallel on many different computers.\nData science involves applications of statistics, computer science, and software en-\ngineering, along with some other relevant fields (such as biology and epidemiology).\nExamples of Data Set Magnitudes We can see from the above definition of big \ndata that there isn’t a fixed number that serves as an exact boundary for determining \nwhether a data set qualifies as being big data, but big data typically involves amounts \nof data such as the following.\n \n■Terabytes (1012 or 1,000,000,000,000 bytes) of data\n \n■Petabytes (1015 bytes) of data\n \n■Exabytes (1018 bytes) of data\n \n■Zettabytes (1021 bytes) of data\n \n■Yottabytes (1024 bytes) of data\nExamples of Applications of Big Data The following are a few examples involv-\ning big data:\n \n■Attempt to forecast flu epidemics by analyzing Internet searches of flu symptoms.\n \n■The Spatio Temporal Epidemiological Modeler developed by IBM is providing a \nmeans for using a variety of data that are correlated with disease data.\ne-\nl \no\nBig Data Instead  \nof a Clinical Trial\nNicholas \nTatonetti of \nColumbia \nUniversity \nsearched Food \nand Drug \nAdministration \ndatabases for \nadverse reactions in patients that \nresulted from different pairings \nof drugs. He discovered that \nthe paroxetine drug for depres-\nsion and the pravastatin drug \nfor high cholesterol interacted \nto create increases in glucose \n(blood sugar) levels. When taken \nseparately by patients, neither \ndrug raised glucose levels, but \nthe increase in glucose levels \noccurred when the two drugs \nwere taken together. This finding \nresulted from a general database \nsearch of interactions from many \npairings of drugs, not from a \nclinical trial involving patients \nusing Paxil and pravastatin.\ncontinued\n\n20 \nCHAPTER 1 Introduction to Statistics\n \n■A National Electronic Disease Surveillance System is used to monitor disease \ntrends and identify outbreaks of infectious disease.\n \n■Google provides live traffic maps by recording and analyzing GPS (global posi-\ntioning system) data collected from the smartphones of people traveling in their \nvehicles.\n \n■Amazon monitors and tracks 1.4 billion items in its store that are distributed \nacross hundreds of fulfillment centers around the world.\nExamples of Jobs According to Analytic Talent, there are 6000 companies hiring \ndata scientists, and here are some job posting examples:\n \n■Facebook: Data Scientist\n \n■IBM: Data Scientist\n \n■PayPal: Data Scientist\n \n■The College Board: SAS Programmer>Data Scientist\n \n■Netflix: Senior Data Engineer>Scientist\nStatistics in Data Science The modern data scientist has a solid background in \nstatistics and computer systems as well as expertise in fields that extend beyond sta-\ntistics. The modern data scientist might be skilled with Hadoop software, which uses \nparallel processing on many computers for the analysis of big data. The modern data \nscientist might also have a strong background in some other field, such as psychology, \nbiology, medicine, chemistry, or economics. Because of the wide range of disciplines \nrequired, a data science project might typically involve a team of collaborating indi-\nviduals with expertise in different fields. An introductory statistics course is a great \nfirst step in becoming a data scientist.\nMissing Data\nWhen collecting sample data, it is quite common to find that some values are miss-\ning. Ignoring missing data can sometimes create misleading results. If you make the \nmistake of skipping over a few different sample values when you are manually typ-\ning them into a statistics software program, the missing values are not likely to have \na serious effect on the results. However, if a survey includes many missing salary en-\ntries because those with very low incomes are reluctant to reveal their salaries, those \nmissing low values will have the serious effect of making salaries appear higher than \nthey really are.\nFor an example of missing data, see the following table. The body temperature for \nSubject 2 at 12 AM on day 2 is missing. (The table below includes the first three rows \nof data from Data Set 2 “Body Temperatures” in Appendix B.)\n Body Temperatures (in degrees Fahrenheit) of Healthy Adults\nTemperature  \nDay 1\nTemperature  \nDay 2\nSubject\nAge\nSex\nSmoke\n8 AM\n12 AM\n8 AM\n12 AM\n1\n22\nM\nY\n98.0\n98.0\n98.0\n98.6\n2\n23\nM\nY\n97.0\n97.6\n97.4\n----\n3\n22\nM\nY\n98.6\n98.8\n97.8\n98.6\n\n1-2 Types of Data \n21\nThere are different categories of missing data. See the following definitions.\nDEFINITION\nA data value is missing completely at random if the likelihood of its being miss-\ning is independent of its value or any of the other values in the data set. That is, any \ndata value is just as likely to be missing as any other data value.\n(Note: More complete discussions of missing data will distinguish between missing \ncompletely at random and missing at random, which means that the likelihood of a \nvalue being missing is independent of its value after controlling for another variable. \nThere is no need to know this distinction in this book.)\nExample of Missing Data—Random When using a keyboard to manually enter \nages of survey respondents, the operator is distracted by a colleague singing “Day-\ndream Believer” and makes the mistake of failing to enter the age of 37 years. This \ndata value is missing completely at random.\nDEFINITION\nA data value is missing not at random if the missing value is related to the reason \nthat it is missing.\nExample of Missing Data—Not at Random A survey question asks each respon-\ndent to enter his or her annual income, but respondents with very low incomes skip \nthis question because they find it embarrassing.\nBiased Results? Based on the above two definitions and examples, it makes sense \nto conclude that if we ignore data missing completely at random, the remaining values \nare not likely to be biased and good results should be obtained. However, if we ignore \ndata that are missing not at random, it is very possible that the remaining values are \nbiased and results will be misleading.\nCorrecting for Missing Data There are different methods for dealing with missing \ndata.\n1. Delete Cases: One very common method for dealing with missing data is to \ndelete all subjects having any missing values.\n \n■If the data are missing completely at random, the remaining values are not \nlikely to be biased and good results can be obtained, but with a smaller sam-\nple size.\n \n■If the data are missing not at random, deleting subjects having any missing \nvalues can easily result in a bias among the remaining values, so results can \nbe misleading.\n2. Impute Missing Values: We impute missing data values when we substitute \nvalues for them. There are different methods of determining the replacement \nvalues, such as using the mean of the other values, or using a randomly selected \nvalue from other similar cases, or using a method based on regression analysis \n(which will make more sense after studying Chapter 10).\nMeasuring  \nDisobedience\nHow are data \ncollected about \nsomething that \ndoesn’t seem \nto be measur-\nable, such as \npeople’s level of \ndisobedience? \nPsychologist Stanley Milgram \ndevised the following experi-\nment: A researcher instructed a \nvolunteer subject to operate a \ncontrol board that gave increas-\ningly painful “electrical shocks” \nto a third person. Actually, no real \nshocks were given, and the third \nperson was an actor. The volun-\nteer began with 15 volts and was \ninstructed to increase the shocks \nby increments of 15 volts. The \ndisobedience level was the point \nat which the subject refused to \nincrease the voltage. Surpris-\ningly, two-thirds of the subjects \nobeyed orders even when the \nactor screamed and faked a \nheart attack.\n\n22 \nCHAPTER 1 Introduction to Statistics\nIn this book we do not work much with missing data, but it is important to under-\nstand this:\nWhen analyzing sample data with missing values, try to determine why \nthey are missing, and then decide whether it makes sense to treat the \nremaining values as being representative of the population. If it appears \nthat there are missing values that are missing not at random (that is, \ntheir values are related to the reasons why they are missing), know that \nthe remaining data may well be biased and any conclusions based on \nthose remaining values may well be misleading.\nStatistical Literacy and Critical Thinking\n1. Health Survey In a survey of 1020 adults in the United States, 44% said that they wash \ntheir hands after riding public transportation (based on data from KRC Research).\na. Identify the sample and the population.\nb. Is the value of 44% a statistic or a parameter?\n2. Health Survey For the same survey from Exercise 1, answer the following.\na. What is the level of measurement of the value of 44%? (nominal, ordinal, interval, ratio)\nb. Are the numbers of subjects in such surveys discrete or continuous?\nc. The responses are “yes,” “no,” “not sure,” or “refused to answer.” Are these responses quan-\ntitative data or categorical data?\n3. Quantitative, Categorical Data Identify each of the following as quantitative data or cat-\negorical data.\na. The platelet counts of exam subjects in Data Set 1 “Body Data” in Appendix B\nb. The names of the pharmaceutical companies that manufacture aspirin tablets\nc. The colors of pills\nd. The weights of aspirin tablets\n4. Discrete, Continuous Data Which of the following describe discrete data?\na. The numbers of people surveyed in each of the next several National Health and Nutrition \n Examination Surveys\nb. The exact foot lengths (cm) of a random sample of statistics students\nc. The exact times that randomly selected drivers spend texting while driving during the past 7 days\nIn Exercises 5–12, identify whether the given value is a statistic or a parameter.\n5. Brain Volume The average (mean) volume of the brains included in Data Set 9 “IQ and \nBrain Size” in Appendix B is 1126.0 cm3.\n6. CHIS A recent California Health Interview Survey (CHIS) included 2799 adolescent resi-\ndents of California.\n7. Cigarettes A data set in Appendix B includes measurements from 25 king-size cigarettes, \nand the average (mean) amount of nicotine in those 25 cigarettes is 1.26 mg.\n8. Triangle Fire Fatalities A deadly disaster in the United States was the Triangle Shirtwaist \nFactory Fire in New York City. A population of 146 garment workers died in that fire.\n1-2 Basic Skills and Concepts\n\n1-2 Types of Data \n23\n9. Birth Weight In a study of 400 babies born at four different hospitals in New York State, it \nwas found that the average (mean) weight at birth was 3152.0 grams.\n10. Birth Genders In the same study cited in the preceding exercise, 51% of the babies were girls.\n11. Titanic A study was conducted of all 2223 passengers aboard the Titanic when it sank.\n12. Periodic Table The average (mean) atomic weight of all elements in the periodic table is \n134.355 unified atomic mass units.\nIn Exercises 13–20, determine whether the data are from a discrete or continuous  \ndata set.\n13. Freshman 15 In a study of weight gains by college students in their freshman year, re-\nsearchers record the amounts of weight gained by randomly selected students (as in Data Set \n10 “Freshman 15” in Appendix B).\n14. Births Data Set 3 “Births” in Appendix B includes the length of stay (in days) for each \nbaby in a sample of babies born in New York State. The first few values are 2, 2, 36, 5, and 2.\n15. CHIS Among the subjects surveyed as part of the California Health Interview Survey \n(CHIS), several subjects are randomly selected and their heights are recorded.\n16. Arm Circumference From Data Set 1 “Body Data” in Appendix B we see that a female \nhad an arm circumference of 32.49 cm.\n17. Families A sample of married couples is randomly selected and the number of children in \neach family is recorded.\n18. Criminal Forensics When studying the relationship between lengths of feet and heights \nso that footprint evidence at a crime scene can be used to estimate the height of the suspect, a \nresearcher records the exact lengths of feet from a large sample of random subjects.\n19. Stitch In Time The Emergency Room of the Albany Medical Center records the numbers \nof stitches used for patients in a week.\n20. Texting Fatalities The Insurance Institute for Highway Safety collects data consisting of \nthe numbers of motor vehicle fatalities caused by driving while texting.\nIn Exercises 21–28, determine which of the four levels of measurement (nominal, ordinal, \ninterval, ratio) is most appropriate.\n21. Brain Volumes Volumes (cm3) of brains listed in Data Set 9 “IQ and Brain Size” in \n Appendix B\n22. Blood Lead Level Blood lead levels of low, medium, and high used to describe the sub-\njects in Data Set 8 “IQ and Lead” in Appendix B\n23. Body Temperatures Body temperatures (in degrees Fahrenheit) listed in Data Set 2 \n“Body Temperatures” in Appendix B.\n24. Privacy Codes Instead of using actual names, subjects included in the National Health \nand Nutrition Examination Survey are coded with consecutive numbers.\n25. Hospitals A research project on the effectiveness of heart transplants begins with a compi-\nlation of the U.S. hospitals that provide heart transplants.\n26. Hospital Charges A research project on the effectiveness of heart transplants begins \nwith a compilation of the charges (dollars) for heart transplant procedures that were conducted \nwithin the past year.\n27. Physician Ranks A research project on the effectiveness of heart transplants includes \nrankings (scale of 1, 2, 3, 4, 5) of physicians who perform those procedures.\n28. Pharmaceuticals Pfizer records the years in which new products were launched, \n beginning with 1849.\n\n24 \nCHAPTER 1 Introduction to Statistics\nIn Exercises 29–32, identify the level of measurement of the data as nominal, ordinal, inter-\nval, or ratio. Also, explain what is wrong with the given calculation.\n29. Hospital ID The four hospitals included in Data Set 3 “Births” in Appendix B are coded as \nfollows: Albany Medical Center (1); Bellevue Hospital Center (1438); Olean General Hospital \n(66); Strong Memorial Hospital (413). The average (mean) of those numbers is 479.5.\n30. Social Security Numbers As part of a clinical study, the Social Security number of each \nsubject is recorded and the average (mean) of the individual digits is computed to be 4.7.\n31. Temperatures A person has a body temperature of 98.0°F during the time when the out-\nside air temperature is 49.0°F, so the person is twice as warm as the outside air.\n32. Medical School Ranks As of this writing, U.S. News & World Report ranked medical \nschools, including these results: Harvard (1), Stanford (2), Johns Hopkins (3), University of \nCalifornia at San Francisco (4), and University of Pennsylvania (5). The difference between \nHarvard and Stanford is the same as the difference between Johns Hopkins and University of \nCalifornia at San Francisco.\n33. Countable For each of the following, categorize the nature of the data using one of these \nthree descriptions: (1) discrete because the number of possible values is finite; (2) discrete \nbecause the number of possible values is infinite but countable; (3) continuous because the \nnumber of possible values is infinite and not countable.\na. Exact lengths of the feet of members of the band the Monkees\nb. Shoe sizes of members of the band the Monkees (such as 9, 9½, and so on)\nc. The number of albums sold by the Monkees band\nd. The numbers of monkeys sitting at keyboards before one of them randomly types the lyrics \nfor the song “Daydream Believer”\n1-2 Beyond the Basics\nKey Concept When using statistics in a study, planning is very important, and it is \nessential to use an appropriate method for collecting the sample data. This section \nincludes comments about various methods and sampling procedures. Of particular im-\nportance is the method of using a simple random sample. We will make frequent use \nof this sampling method throughout the remainder of this book.\nAs you read this section, remember this:\nIf sample data are not collected in an appropriate way, the data may be \nso utterly useless that no amount of statistical torturing can salvage them.\nPART 1\n  Basics of Design of Experiments and \nCollecting Sample Data\nThe Gold Standard Randomization with placebo>treatment groups is sometimes \ncalled the “gold standard” because it is so effective. (A placebo such as a sugar pill \nhas no medicinal effect.) The following example describes how the gold standard was \nused in the largest health experiment ever conducted.\n \n1-3 \nCollecting Sample Data\n\n1-3 Collecting Sample Data \n25\nExample 1 describes an experiment because subjects were given a treatment, but ethi-\ncal, cost, time, and other considerations sometimes prohibit the use of an experiment. \nWe would never want to conduct a driving/texting experiment in which we ask sub-\njects to text while driving—some of them could die. It would be far better to observe \npast crash results to understand the effects of driving while texting. See the following \ndefinitions.\nEXAMPLE 1  The Salk Vaccine Experiment\nIn 1954, an experiment was designed to test the effectiveness of the Salk vaccine in \npreventing polio, which had killed or paralyzed thousands of children. By random \nselection, 401,974 children were randomly assigned to two groups: (1) 200,745 \nchildren were given a treatment consisting of Salk vaccine injections; (2) 201,229 \nchildren were injected with a placebo that contained no drug. Children were as-\nsigned to the treatment or placebo group through a process of random selection, \nequivalent to flipping a coin. Among the children given the Salk vaccine, 33 later \ndeveloped paralytic polio, and among the children given a placebo, 115 later devel-\noped paralytic polio.\nDEFINITIONS\nIn an experiment, we apply some treatment and then proceed to observe its \n effects on the individuals. (The individuals in experiments are called experimental \nunits, and they are often called subjects when they are people.)\nIn an observational study, we observe and measure specific characteristics, but \nwe don’t attempt to modify the individuals being studied.\nExperiments are often better than observational studies because well-planned experi-\nments typically reduce the chance of having the results affected by some variable that \nis not part of a study. A lurking variable is one that affects the variables included in \nthe study, but it is not included in the study.\nEXAMPLE 2  Ice Cream and Drownings\nObservational Study: Observe past data to conclude that ice cream causes drown-\nings (based on data showing that increases in ice cream sales are associated with \nincreases in drownings). The mistake is to miss the lurking variable of temperature \nand the failure to see that as the temperature increases, ice cream sales increase and \ndrownings increase because more people swim.\nExperiment: Conduct an experiment with one group treated with ice cream while \nanother group gets no ice cream. We would see that the rate of drowning victims \nis about the same in both groups, so ice cream consumption has no effect on \ndrownings.\nHere, the experiment is clearly better than the observational study.\nDesign of Experiments\nGood design of experiments includes replication, blinding, and randomization.\n \n■Replication is the repetition of an experiment on more than one individual. Good \nuse of replication requires sample sizes that are large enough so that we can see \nn \nClinical Trials vs. \nObservational Studies\nIn a New York \nTimes article \nabout hormone \ntherapy for \nwomen, reporter \nDenise Grady \nwrote about \nrandomized \nclinical trials that involve subjects \nwho were randomly assigned to \na treatment group and another \ngroup not given the treatment. \nSuch randomized clinical trials \nare often referred to as the “gold \nstandard” for medical research. \nIn contrast, observational studies \ncan involve patients who decide \nthemselves to undergo some \ntreatment. Subjects who decide \nthemselves to undergo treat-\nments are often healthier than \nother subjects, so the treatment \ngroup might appear to be more \nsuccessful simply because it \ninvolves healthier subjects, not \nnecessarily because the treat-\nment is effective. Researchers \ncriticized observational studies of \nhormone therapy for women by \nsaying that results might appear \nto make the treatment more ef-\nfective than it really is.\n\n26 \nCHAPTER 1 Introduction to Statistics\neffects of treatments. In the Salk experiment in Example 1, the experiment used \nsufficiently large sample sizes, so the researchers could see that the Salk vaccine \nwas effective.\n \n■Blinding is used when the subject doesn’t know whether he or she is receiving a \ntreatment or a placebo. Blinding is a way to get around the placebo effect, which \noccurs when an untreated subject reports an improvement in symptoms. (The \nreported improvement in the placebo group may be real or imagined.) The Salk \nexperiment in Example 1 was double-blind, which means that blinding occurred \nat two levels: (1) The children being injected didn’t know whether they were \ngetting the Salk vaccine or a placebo, and (2) the doctors who gave the injec-\ntions and evaluated the results did not know either. Codes were used so that the \nresearchers could objectively evaluate the effectiveness of the Salk vaccine.\n \n■Randomization is used when individuals are assigned to different groups \nthrough a process of random selection, as in the Salk vaccine experiment in \nExample 1. The logic behind randomization is to use chance as a way to create \ntwo groups that are similar. The following definition refers to one common and \neffective way to collect sample data in a way that uses randomization.\nDEFINITION\nA simple random sample of n subjects is selected in such a way that every pos-\nsible sample of  the same size n has the same chance of being chosen. (A simple \nrandom sample is often called a random sample, but strictly speaking, a random \nsample has the weaker requirement that all members of the population have the \nsame chance of being selected. That distinction is not so important in this text. \n(See Exercise 38 “Simple Random Sample vs. Random Sample.”)\nThroughout, we will use various statistical procedures, and we often have \na requirement that we have collected a simple random sample, as defined \nabove.\nUnlike careless or haphazard sampling, random sampling usually requires very \ncareful planning and execution.\nOther Sampling Methods In addition to simple random sampling, here are some \nother sampling methods commonly used for surveys. Figure 1-3 illustrates these dif-\nferent sampling methods.\nDEFINITIONS\nIn systematic sampling, we select some starting point and then select every kth \n(such as every 50th) element in the population.\nWith convenience sampling, we simply use data that are very easy to get.\nIn stratified sampling, we subdivide the population into at least two different \nsubgroups (or strata) so that subjects within the same subgroup share the same \ncharacteristics (such as gender). Then we draw a sample from each subgroup (or \nstratum).\nIn cluster sampling, we first divide the population area into sections (or clusters). \nThen we randomly select some of those clusters and choose all the members from \nthose selected clusters.\nHawthorne and \nExperimenter Effects\nThe well-\nknown \nplacebo effect \noccurs when \nan untreated \nsubject incor-\nrectly believes \nthat he or she is receiving a \nreal treatment and reports an \nimprovement in symptoms. The \nHawthorne effect occurs when \ntreated subjects somehow re-\nspond differently, simply because \nthey are part of an experiment. \n(This phenomenon was called \nthe “Hawthorne effect” because \nit was first observed in a study \nof factory workers at Western \nElectric’s Hawthorne plant.) An \nexperimenter effect (sometimes \ncalled a Rosenthal effect) occurs \nwhen the researcher or experi-\nmenter unintentionally influences \nsubjects through such factors as \nfacial expression, tone of voice, \nor attitude.\n\n1-3 Collecting Sample Data \n27\nMultistage Sampling Professional pollsters and government researchers often  collect \ndata by using some combination of the preceding sampling methods. In a  multistage \nsample design, pollsters select a sample in different stages, and each stage might use \ndifferent methods of sampling, as in the following example.\nMAIN\nCENTER\nHeritage\nSchool\nPark St.\nNorth St.\n1st St.\n2nd St.\n3rd St.\n82nd St.\n52nd St.\n36th St.\n43rd St.\nA St.\nB St.\nC St.\nD St.\nE St.\nF St.\nWay St.\n4th St.\n5th St.\nMLK PKWY\n555-867-5309\n555-606-0842\n555-777-9311\nSimple Random Sample\nA sample of n subjects is selected \nso that every sample of the same \nsize n has the same chance of \nbeing selected.\nStratiﬁed Sample\nSubdivide population into strata \n(groups) with the same \ncharacteristics, then randomly \nsample within those strata.\nCluster Sample\nPartition the population in clusters \n(groups), then randomly select \nsome clusters, then select all \nmembers of the selected clusters.\nSystematic Sample\nSelect every kth subject.\nConvenience Sample\nUse data that are very easy to get.\nMen\nWomen\n3rd\n6th\nFIGURE 1-3 Common Sampling Methods\nEXAMPLE 3  Multistage Sample Design\nThe U.S. government’s unemployment statistics are based on surveys of house-\nholds. It is impractical to personally survey each household in a simple random \nsample, because they would be scattered all over the country. Instead, the U.S. \n Census Bureau and the Bureau of Labor Statistics collaborate to conduct a survey \ncalled the Current Population Survey. A recent survey incorporates a multistage \nsample design, roughly following these steps:\n \n1. The entire United States is partitioned into 2,007 diﬀerent regions called \nprimary sampling units (PSUs). The primary sampling units are metropolitan \nareas, large counties, or combinations of smaller counties. The 2,007 primary \nsampling units are then grouped into 824 diﬀerent strata.\nValue of a  \nStatistical Life\nThe value of a \nstatistical life \n(VSL) is a mea-\nsure routinely \ncalculated and \nused for making \ndecisions in \nfields such as \nmedicine, insurance, environ-\nmental health, and transportation \nsafety. As of this writing, the \nvalue of a statistical life is  \n$6.9 million.\nMany people oppose the con-\ncept of putting a value on a hu-\nman life, but the word statistical \nin the “value of a statistical life” \nis used to ensure that we don’t \nequate it with the true worth \nof a human life. Some people \nlegitimately argue that every life \nis priceless, but others argue that \nthere are conditions in which it \nis impossible or impractical to \nsave every life, so a value must \nbe somehow assigned to a hu-\nman life in order that sound and \nrational decisions can be made. \nNot far from the author’s home, a \nparkway was modified at a cost \nof about $3 million to improve \nsafety at a location where car \noccupants had previously died \nin traffic crashes. In the cost-\nbenefit analysis that led to this \nimprovement in safety, the value \nof a statistical life was surely \nconsidered.\ncontinued\n\n28 \nCHAPTER 1 Introduction to Statistics\nPART 2\n  Beyond the Basics of Design of \nExperiments and Collecting Sample Data\nObservational Studies In Part 2 of this section, we discuss different types of ob-\nservational studies and different ways of designing experiments. The following defi-\nnitions identify the standard terminology used in professional journals for different \ntypes of observational studies. These definitions are illustrated in Figure 1-4.\n \n2. In each of the 824 diﬀerent strata, one of the primary sampling units is \nselected so that the probability of selection is proportional to the size of the \npopulation in each primary sampling unit.\n \n3. In each of the 824 selected primary sampling units, census data are used to \nidentify a census enumeration district, with each containing about 300 house-\nholds. Enumeration districts are then randomly selected.\n \n4. In each of the selected enumeration districts, clusters of about four addresses \n(contiguous whenever possible) are randomly selected.\n \n5. A responsible person in each of the 60,000 selected households is interviewed \nabout the employment status of each household member of age 16 or older.\nThis multistage sample design includes a combination of random, stratified, and \ncluster sampling at different stages. The end result is a very complicated sampling \ndesign, but it is much more practical, less expensive, and faster than using a simpler \ndesign, such as a simple random sample.\nWhen\nare the\nobservations\nmade?\nObservational Study:\nObserve and measure,\nbut do not modify.\nOne point in time\nRetrospective\n(or case-control) study:\nGo back in time to \ncollect data over some \npast period.\nCross-sectional \nstudy:\nData are\nmeasured at one \npoint in time.\nProspective\n(or longitudinal or cohort) study:\nGo forward in time and observe\ngroups sharing common factors,\nsuch as smokers and nonsmokers.\nForward in time\nPast period of time\nFIGURE 1-4 Types of Observational Studies\nDEFINITIONS\nIn a cross-sectional study, data are observed, measured, and collected at one \npoint in time, not over a period of time.\nIn a retrospective (or case-control) study, data are collected from a past time pe-\nriod by going back in time (through examination of records, interviews, and so on).\nIn a prospective (or longitudinal or cohort) study, data are collected in the future \nfrom groups that share common factors (such groups are called cohorts).\n\n1-3 Collecting Sample Data \n29\nExperiments In a study, confounding occurs when we can see some effect, but \nwe can’t identify the specific factor that caused it, as in the ice cream and drowning \nobservational study in Example 2. See also the bad experimental design illustrated \nin  Figure 1-5(a), where confounding can occur when the treatment group of women \nshows strong positive results. Because the treatment group consists of women and the \nplacebo group consists of men, confounding has occurred because we cannot deter-\nmine whether the treatment or the gender of the subjects caused the positive results. \nThe Salk vaccine experiment in Example 1 illustrates one method for controlling the \neffect of the treatment variable: Use a completely randomized experimental design, \nwhereby randomness is used to assign subjects to the treatment group and the placebo \ngroup. A completely randomized experimental design is one of the following methods \nthat are used to control effects of variables.\nCompletely Randomized Experimental Design: Assign subjects to different treat-\nment groups through a process of random selection, as illustrated in Figure 1-5(b).\nTreatment Group: Women\nBad experimental design:\nTreat all women subjects\nand give the men a placebo.\n(Problem: We don’t know if\neﬀects are due to sex or\nto treatment.)\nCompletely randomized\nexperimental design:\nUse randomness to\ndetermine who gets the\ntreatment and who gets\nthe placebo.\n  \nTreat all women subjects.\nPlacebo Group: Men\n  \nGive all men a placebo\nTreat these  randomly\nselected subjects and give\nthe others a placebo.\n(a)\n(b)\nBefore\nAfter\nAlex\nBob\nChris\nBlock of Women\nRandomized block design:\n1. Form a block of women\n \nand a block of men.\n2. Within each block,\n \nrandomly select subjects\n \nto be treated.\nMatched pairs design:\nGet measurements from the\nsame subjects before and after\nsome treatment.\n  \nTreat randomly selected\nwomen.\nBlock of Men\n  \nTreat randomly selected men.\n(c)\n(d)\nFIGURE 1-5 Designs of Experiments\n\n30 \nCHAPTER 1 Introduction to Statistics\nExperimental design requires much more thought and care than we can describe \nin this relatively brief section. Taking a complete course in the design of experiments \nis a good start in learning so much more about this important topic.\nRandomized Block Design: See Figure 1-5c. A block is a group of subjects that are \nsimilar, but blocks differ in ways that might affect the outcome of the experiment. Use \nthe following procedure, as illustrated in Figure 1-5(c):\n1. Form blocks (or groups) of subjects with similar characteristics.\n2. Randomly assign treatments to the subjects within each block.\nFor example, in designing an experiment to test the effectiveness of aspirin treatments \non heart disease, we might form a block of men and a block of women, because it is \nknown that the hearts of men and women can behave differently. By controlling for \ngender, this randomized block design eliminates gender as a possible source of con-\nfounding.\nA randomized block design uses the same basic idea as stratified sampling, but \nrandomized block designs are used when designing experiments, whereas stratified \nsampling is used for surveys.\nMatched Pairs Design: Compare two treatment groups (such as treatment and pla-\ncebo) by using subjects matched in pairs that are somehow related or have similar \ncharacteristics, as in the following cases.\n \n■Before/After: Matched pairs might consist of measurements from subjects before \nand after some treatment, as illustrated in Figure 1-5(d) on the preceding page. \nEach subject yields a “before” measurement and an “after” measurement, and \neach before/after pair of measurements is a matched pair.\n \n■Twins: A test of Crest toothpaste used matched pairs of twins, where one twin \nused Crest and the other used another toothpaste.\nRigorously Controlled Design: Carefully assign subjects to different treatment \ngroups, so that those given each treatment are similar in the ways that are important to \nthe experiment. This can be extremely difficult to implement, and often we can never \nbe sure that we have accounted for all of the relevant factors.\nSampling Errors\nIn statistics, you could use a good sampling method and do everything correctly, and \nyet it is possible to get wrong results. No matter how well you plan and execute the \nsample collection process, there is likely to be some error in the results. The different \ntypes of sampling errors are described here.\nDEFINITIONS\nA sampling error (or random sampling error) occurs when the sample has been \nselected with a random method, but there is a discrepancy between a sample \nresult and the true population result; such an error results from chance sample \nfluctuations.\nA nonsampling error is the result of human error, including such factors as wrong \ndata entries, computing errors, questions with biased wording, false data provided \nby respondents, forming biased conclusions, or applying statistical methods that \nare not appropriate for the circumstances.\nA nonrandom sampling error is the result of using a sampling method that is not \nrandom, such as using a convenience sample or a voluntary response sample.\n\n1-3 Collecting Sample Data \n31\nStatistical Literacy and Critical Thinking\n1. Back Pain Treatment In a study designed to test the effectiveness of paracetamol (also \nknown as acetaminophen) as a treatment for lower back pain, 1643 patients were randomly \nassigned to one of three groups: (1) the 547 subjects in the placebo group were given pills \ncontaining no medication; (2) 550 subjects were in a group given pills with paracetamol taken \nat regular intervals; (3) 546 subjects were in a group given pills with paracetamol to be taken \nwhen needed for pain relief. (See “Efficacy of Paracetamol for Acute Low-Back Pain,” by \n Williams et al., Lancet.) Is this study an experiment or an observational study? Explain.\n2. Blinding What does it mean when we say that the study cited in Exercise 1 was “double-blind”?\n3. Replication In what specific way was replication applied in the study cited in Exercise 1?\n4. Sampling Method The patients included in the study cited in Exercise 1 were those “who \nsought care for low-back pain directly or in response to a community advertisement.” What \ntype of sampling best describes the way in which the 1634 subjects were chosen: simple ran-\ndom sample, systematic sample, convenience sample, stratified sample, cluster sample? Does \nthe method of sampling appear to adversely affect the quality of the results?\nExercises 5–8 refer to the study of an association between which ear is used for cell phone \ncalls and whether the subject is left-handed or right-handed. The study is reported in “Hemi-\nspheric Dominance and Cell Phone Use,” by Seidman et al., JAMA Otolaryngology—Head \n& Neck Surgery, Vol. 139, No. 5. The study began with a survey e-mailed to 5000 people \nbelonging to an otology online group, and 717 surveys were returned. (Otology relates to the \near and hearing.)\n5. Sampling Method What type of sampling best describes the way in which the 717 subjects \nwere chosen: simple random sample, systematic sample, convenience sample, stratified sample, \ncluster sample? Does the method of sampling appear to adversely affect the quality of the results?\n6. Experiment or Observational Study Is the study an experiment or an observational \nstudy? Explain.\n7. Response Rate What percent of the 5000 surveys were returned? Does that response rate \nappear to be low? In general, what is a problem with a very low response rate?\n8. Sampling Method Assume that the population consists of all students currently in your \nstatistics class. Describe how to obtain a sample of six students so that the result is a sample of \nthe given type.\na. Simple random sample\nb. Systematic sample\nc. Stratified sample\nd. Cluster sample\nIn Exercises 9–20, identify which of these types of sampling is used: random, systematic, \nconvenience, stratified, or cluster.\n9. Cormorant Density Cormorant bird population densities were studied by using the “line \ntransect method” with aircraft observers flying along the shoreline of Lake Huron and collecting \nsample data at intervals of every 20 km (based on data from Journal of Great Lakes Research).\n1-3 Basic Skills and Concepts\n\n32 \nCHAPTER 1 Introduction to Statistics\n10. Sexuality of Women The sexuality of women was discussed in Shere Hite’s book Women \nand Love: A Cultural Revolution. Her conclusions were based on sample data that consisted of \n4500 mailed responses from 100,000 questionnaires that were sent to women.\n11. Acupuncture Study In a study of treatments for back pain, 641 subjects were randomly \nassigned to the four different treatment groups of individualized acupuncture, standardized \nacupuncture, simulated acupuncture, and usual care (based on data from “A Randomized Trial \nComparing Acupuncture, Simulated Acupuncture, and Usual Care for Chronic Low Back \nPain,” by Cherkin et al., Archives of Internal Medicine, Vol. 169, No. 9).\n12. Class Survey A professor surveys her statistics class by identifying groups of males and \nfemales, then randomly selecting five students from each of those two groups.\n13. Class Survey A professor conducts a survey by randomly selecting three different classes \nand surveying all of the students as they left those classes.\n14. Exercise Program In a study designed to test the effectiveness of exercise in lowering \nblood pressure, 532 subjects were randomly assigned to these two different groups: (1) group \ngiven regular exercise programs; (2) group given no exercise programs.\n15. Hospital Survey A researcher collects sample data by randomly selecting 20 hospital \n employees from each of the categories of physician, nurse, and administrator.\n16. Deforestation Rates Satellites are used to collect sample data for estimating deforesta-\ntion rates. The Forest Resources Assessment of the United Nations (UN) Food and Agriculture \nOrganization uses a method of selecting a sample of a 10-km-wide square at every 1° intersec-\ntion of latitude and longitude.\n17. Testing Lipitor In a clinical trial of the cholesterol drug Lipitor (atorvastatin), subjects \nwere partitioned into groups given a placebo or Lipitor doses of 10 mg, 20 mg, 40 mg, or \n80 mg. The subjects were randomly assigned to the different treatment groups (based on data \nfrom Pfizer, Inc.).\n18. Blood Drives A researcher for the American Red Cross randomly selected five different \nblood donor sites and then interviewed all blood donors as they left the sites.\n19. Smoking Prevalence A medical student collects sample data on the prevalence of smok-\ning among adults by surveying all of the patients she encounters in the clinic where she is doing \nher residency.\n20. Health Survey The Texas Health and Human Services Commission obtains an alphabeti-\ncal listing of all 20,126,759 adults and constructs a sample by selecting every 10,000th name \non that list.\nCritical Thinking: What’s Wrong? In Exercises 21–28, determine whether the study is \nan experiment or an observational study, and then identify a major problem with the study.\n21. Online Medical Information In a survey conducted by USA Today, 1072 Internet users \nchose to respond to this question posted on the USA Today electronic edition: “How often do \nyou seek medical information online?” 38% of the respondents said “frequently.”\n22. Physicians’ Health Study The Physicians’ Health Study involved 22,071 male physi-\ncians. Based on random selections, 11,037 of them were treated with aspirin and the other \n11,034 were given placebos. The study was stopped early because it became clear that aspirin \nreduced the risk of myocardial infarctions by a substantial amount.\n23. Drinking and Driving A researcher for a consortium of insurance companies plans to \ntest for the effects of drinking on driving ability by randomly selecting 1000 drivers and then \nrandomly assigning them to two groups: One group of 500 will drive in New York City after no \nalcohol consumption, and the second group will drive in New York City after consuming three \nshots of Jim Beam bourbon whiskey.\n\n1-3 Collecting Sample Data \n33\n24. Blood Pressure A medical researcher tested for a difference in systolic blood pressure \nlevels between male and female students who are 20 years of age. She randomly selected four \nmales and four females for her study.\n25. Salt Deprivation In a program designed to investigate the effects of salt deprivation in \ndiets, the original plan was to use a sample of 500 adults randomly selected throughout the \ncountry. The program managers know that they would get a biased sample if they limit their \nstudy to adults in New York City, so they planned to compensate for that bias by using a larger \nsample of 2000 adults in New York City.\n26. Atkins Weight Loss Program An independent researcher tested the effectiveness of the \nAtkins weight loss program by randomly selecting 1000 subjects using that program. Each of \nthe subjects was called to report his or her weight before the diet and after the diet.\n27. Crime Research A researcher has created a brief survey to be given to 2000 adults ran-\ndomly selected from the U.S. population. Here are her first two questions: (1) Have you ever \nbeen the victim of a felony crime? (2) Have you ever been convicted of a felony?\n28. Medications The Pharmaceutical Research and Manufacturers of America wants infor-\nmation about the consumption of various medications. An independent researcher conducts a \nsurvey by mailing 10,000 questionnaires to randomly selected adults in the United States, and \nshe receives 152 responses.\nIn Exercises 29–32, indicate whether the observational study used is cross-sectional, \n retrospective, or prospective.\n29. Nurses’ Health Study II Phase II of the Nurses’ Health Study was started in 1989 with \n116,000 female registered nurses. The study is ongoing.\n30. Heart Health Study Samples of subjects with and without heart disease were selected, \nthen researchers looked back in time to determine whether they took aspirin on a regular basis.\n31. Marijuana Study Researchers from the National Institutes of Health want to determine the \ncurrent rates of marijuana consumption among adults living in states that have legalized the use \nof marijuana. They conduct a survey of 500 adults in those states.\n32. Framingham Heart Study The Framingham Heart Study was started in 1948 and is ongo-\ning. Its focus is on heart disease.\nIn Exercises 33–36, identify which of these designs is most appropriate for the given \nexperiment: completely randomized design, randomized block design, or matched pairs \ndesign.\n33. Lunesta Lunesta (eszopiclone) is a drug designed to treat insomnia. In a clinical trial of \nLunesta, amounts of sleep each night are measured before and after subjects have been treated \nwith the drug.\n34. Lipitor A clinical trial of Lipitor treatments is being planned to determine whether its \neffects on diastolic blood pressure are different for men and women.\n35. West Nile Vaccine Currently, there is no approved vaccine for the prevention of West Nile \nvirus infection. A clinical trial of a possible vaccine is being planned to include subjects treated \nwith the vaccine while other subjects are given a placebo.\n36. HIV Vaccine The HIV Trials Network is conducting a study to test the effectiveness of two \ndifferent experimental HIV vaccines. Subjects will consist of 80 pairs of twins. For each pair \nof twins, one of the subjects will be treated with the DNA vaccine and the other twin will be \ntreated with the adenoviral vector vaccine.\n1-3 Beyond the Basics\n\n34 \nCHAPTER 1 Introduction to Statistics\n37. Sample Design Literacy In “Cardiovascular Effects of Intravenous Triiodothyronine in \nPatients Undergoing Coronary Artery Bypass Graft Surgery” (Journal of the American Medi-\ncal Association, Vol. 275, No. 9), the authors explain that patients were assigned to one of \nthree groups: (1) a group treated with triiodothyronine, (2) a group treated with normal saline \nbolus and dopamine, and (3) a placebo group given normal saline. The authors summarize the \nsample design as a “prospective, randomized, double-blind, placebo-controlled trial.” Describe \nthe meaning of each of those terms in the context of this study.\n38. Simple Random Sample vs. Random Sample Refer to the definition of simple random \nsample in this section and the accompanying definition of random sample enclosed within pa-\nrentheses. Determine whether each of the following is a simple random sample and a random \nsample.\na. A statistics class with 36 students is arranged so that there are 6 rows with 6 students in each \nrow, and the rows are numbered from 1 through 6. A die is rolled and a sample consists of all \nstudents in the row corresponding to the outcome of the die.\nb. For the same class described in part (a), the 36 student names are written on 36 individual \nindex cards. The cards are shuffled and six names are drawn from the top.\nc. For the same class described in part (a), the six youngest students are selected.\n1. Clinical Study When conducting a clinical study, it is common to maintain the privacy of \nsubjects by assigning them number codes that will be used instead of their actual names. Sev-\neral subjects are assigned these codes: 1, 2, 3, 5, 6, 9, 11, 13, 16, 20, 22, 26, 32, and 40. Does it \nmake sense to calculate the average (mean) of these numbers?\n2. Clinical Study Which of the following best describes the level of measurement of the data \nlisted in Exercise 1: nominal, ordinal, interval, ratio?\n3. Waist Data Set 1 “Body Data” includes measurements of waist circumferences. Are waist \ncircumferences values that are discrete or continuous?\n4. Waist Are the waist circumferences described in Exercise 3 quantitative data or categorical \ndata?\n5. Waist Which of the following best describes the level of measurement of the waist \n circumferences described in Exercise 3: nominal, ordinal, interval, ratio?\n6. Waist If you construct a sample by selecting every sixth waist circumference from those \nlisted in Data Set 1 “Body Data,” is the result a simple random sample of the listed waist \n circumferences?\n7. Gallup Poll In a recent Gallup poll, pollsters randomly selected adults and asked them \nwhether they smoke. Because the subjects agreed to respond, is the sample a voluntary re-\nsponse sample?\n8. Parameter and Statistic In a recent Gallup poll, pollsters randomly selected adults and \nasked them whether they smoke. Among the adults who responded to the survey question, 21% \nsaid that they did smoke. Is that value of 21% an example of a statistic or a parameter?\n9. Observational Study or Experiment Are the data described in Exercise 8 the result of an \nobservational study or an experiment?\n10. Statistical Significance and Practical Significance True or false: If data lead to a con-\nclusion with statistical significance, then the results also have practical significance.\nChapter Quick Quiz\n\n1. Hospitals Currently, there are 5723 registered hospitals in the United States.\na. Are the numbers of hospitals in different states discrete or continuous?\nb. What is the level of measurement for the numbers of hospitals in different years? (nominal, \nordinal, interval, ratio)\nc. If a survey is conducted by randomly selecting 10 patients in every hospital, what type of \nsampling is used? (random, systematic, convenience, stratified, cluster)\nd. If a survey is conducted by randomly selecting 20 hospitals and interviewing all of the mem-\nbers of each board of directors, what type of sampling is used? (random, systematic, conve-\nnience, stratified, cluster)\ne. What is wrong with surveying patient satisfaction by mailing questionnaires to 10,000 ran-\ndomly selected patients?\n2. What’s Wrong? A survey sponsored by the American Laser Centers included responses \nfrom 575 adults, and 24% of the respondents said that the face is their favorite body part (based \non data from USA Today). What is wrong with this survey?\n3. What’s Wrong? A survey included 2028 responses from Internet users who decided to \nrespond to a question posted by AOL. Here is the question: “How often do you drink soda?” \nAmong the respondents, 33% said that they drink soda almost every day. What is wrong with \nthis survey?\n4. Sampling Seventy-two percent of Americans squeeze their toothpaste tube from the top. \nThis and other not-so-serious findings are included in The First Really Important Survey of \nAmerican Habits. Those results are based on 7000 responses from the 25,000 questionnaires \nthat were mailed.\na. What is wrong with this survey?\nb. As stated, the value of 72% refers to all Americans, so is that 72% a statistic or a parameter? \nExplain.\nc. Does the survey constitute an observational study or an experiment?\n5. Percentages\na. The labels on U-Turn protein energy bars include the statement that these bars contain \n“125% less fat than the leading chocolate candy brands” (based on data from Consumer \nReports magazine). What is wrong with that claim?\nb. In a Pew Research Center poll on driving, 58% of the 1182 respondents said that they like to \ndrive. What is the actual number of respondents who said that they like to drive?\nc. In a Pew Research Center poll on driving, 331 of the 1182 respondents said that driving is a \nchore. What percentage of respondents said that driving is a chore?\n6. Simple Random Sample Which of the following is>are simple random samples?\na. As Lipitor pills are being manufactured, a quality control plan is to select every 500th pill \nand test it to confirm that it contains 80 mg of atorvastatin.\nb. To test for a gender difference in the way that men and women make online purchases, \n Gallup surveys 500 randomly selected men and 500 randomly selected women.\nc. A list of all 10,877 adults in Trinity County, California, is obtained; the list is numbered from \n1 to 10,877; and then a computer is used to randomly generate 250 different numbers between \n1 and 10,877. The sample consists of the adults corresponding to the selected numbers.\nReview Exercises\nCHAPTER 1 Review Exercises \n35\n\n36 \nCHAPTER 1 Introduction to Statistics\n7. Statistical Significance and Practical Significance The Gengene Research Group has \ndeveloped a procedure designed to increase the likelihood that a baby will be born a girl. In a \nclinical trial of their procedure, 112 girls were born to 200 different couples. If the method has \nno effect, there is about a 4% chance that such extreme results would occur. Does the procedure \nappear to have statistical significance? Does the procedure appear to have practical signifi-\ncance?\n8. Marijuana Survey In a recent Pew poll of 1500 adults, 52% of the respondents said that the \nuse of marijuana should not be made legal. In the same poll, 23% of the respondents said that \nthe use of marijuana for medical purposes should not be legal.\na. The sample of 1500 adults was selected from the population of all adults in the United \nStates. The method used to select the sample was equivalent to placing the names of all adults \nin a giant bowl, mixing the names, and then drawing 1500 names. What type of sampling is \nthis? (random, systematic, convenience, stratified, cluster)\nb. If the sampling method consisted of a random selection of 30 adults from each of the 50 states, \nwhat type of sampling would this be? (random, systematic, convenience, stratified, cluster)\nc. What is the level of measurement of the responses of yes, no, don’t know, and refused to \nrespond?\nd. Is the given value of 52% a statistic or a parameter? Why?\ne. What would be wrong with conducting the survey by mailing a questionnaire that respon-\ndents could complete and mail back?\n9. Marijuana Survey Identify the type of sampling (random, systematic, convenience, strati-\nfied, cluster) used when a sample of the 1500 survey responses is obtained as described. Then \ndetermine whether the sampling scheme is likely to result in a sample that is representative of \nthe population of all adults.\na. A complete list of all 241,472,385 adults in the United States is compiled, and every \n150,000th name is selected until the sample size of 1500 is reached.\nb. A complete list of all 241,472,385 adults in the United States is compiled, and 1500 adults \nare randomly selected from that list.\nc. The United States is partitioned into regions with 100 adults in each region. Then 15 of those \nregions are randomly selected, and all 100 people in each of those regions are surveyed.\nd. The United States is partitioned into 150 regions with approximately the same number of \nadults in each region; then 10 people are randomly selected from each of the 150 regions.\ne. A survey is mailed to 10,000 randomly selected adults, and the 1500 responses are used.\n10. Marijuana Survey Exercise 8 referred to a Pew poll of 1500 adults, and 52% of the \n respondents said that the use of marijuana should not be made legal.\na. Among the 1500 adults who responded, what is the number of respondents who said that the \nuse of marijuana should not be made legal?\nb. In the same poll of 1500 adults, 345 of the respondents said that the use of marijuana for \nmedical purposes should not be legal. What is the percentage of respondents who said that the \nuse of marijuana for medical purposes should not be legal?\nc. In this survey of 1500 adults, 727 are men and 773 are women. Find the percentage of \n respondents who are men, and then find the percentage of respondents who are women.\nd. Does the difference between the two percentages from part (c) appear to have statistical \nsignificance?\ne. Does the difference between the two percentages from part (c) appear to have practical \n significance?\n\nFor Chapter 2 through Chapter 14, the Cumulative Review Exercises include topics from \npreceding chapters. For this chapter, we present a few calculator warm-up exercises, with \nexpressions similar to those found throughout this book. Use your calculator to find the \nindicated values.\n1. Birth Weights Listed below are the weights (grams) of newborn babies from Albany Medi-\ncal Center Hospital. What value is obtained when those weights are added and the total is di-\nvided by the number of weights? (This result, called the mean, is discussed in Chapter 3.) What \nis notable about these values, and what does it tell us about how the weights were measured?\n3600 1700 4000 3900 3100 3800\n2200 3000\n2. Six Children Jule Cole is a founder of Mabel’s Labels, and she is the mother of six chil-\ndren. The probability that six randomly selected children are all girls is found by evaluating \n0.56. Find that value.\n3. Tallest Person Robert Wadlow (1918–1940) is the tallest known person to have lived. The \nexpression below converts his height of 272 cm to a standardized score. Find this value and \nround the result to two decimal places. Such standardized scores are considered to be signifi-\ncantly high if they are greater than 2 or 3. Is the result significantly high?\n272 - 176\n6\n4. Body Temperature The given expression is used for determining the likelihood that the av-\nerage (mean) human body temperature is different from the value of 98.6°F that is commonly \nused. Find the given value and round the result to two decimal places.\n98.2 - 98.6\n0.62\n2106\n5. Determining Sample Size The given expression is used to determine the size of the sam-\nple necessary to estimate the proportion of college students who have the profound wisdom to \ntake a statistics course. Find the value and round the result to the nearest whole number.\n1.962 # 0.25\n0.032\n6. Standard Deviation One way to get a very rough approximation of the value of a standard \ndeviation of sample data is to find the range, then divide it by 4. The range is the difference be-\ntween the highest sample value and the lowest sample value. In using this approach, what value \nis obtained from the sample data listed in Exercise 1 “Birth Weights”?\n7. Standard Deviation The standard deviation is an extremely important concept introduced \nin Chapter 3. Using the sample data from Exercise 1 “Birth Weights,” part of the calculation of \nthe standard deviation is shown in the expression below. Evaluate this expression. (Fortunately, \ncalculators and software are designed to automatically execute such expressions, so our future \nwork with standard deviations will not be burdened with cumbersome calculations.)\n13600 - 3162.52 2\n7\n8. Standard Deviation The given expression is used to compute the standard deviation of \nthree randomly selected body temperatures. Perform the calculation and round the result to two \ndecimal places.\nB\n198.4 - 98.62 2 + 198.6 - 98.62 2 + 198.8 - 98.62 2\n3 - 1\nCumulative Review Exercises\nCHAPTER 1 Cumulative Review Exercises \n37\n\n38 \nCHAPTER 1 Introduction to Statistics\nScientific Notation. In Exercises 9–12, the given expressions are designed to yield re-\nsults expressed in a form of scientific notation. For example, the calculator-displayed re-\nsult of 1.23E5 can be expressed as 123,000, and the result of 1.23E-4 can be expressed as \n0.000123. Perform the indicated operation and express the result as an ordinary number \nthat is not in scientific notation.\n9. 0.48  10. 911  11. 614  12. 0.312\nTechnology Project\nMissing Data The focus of this project is to download a data set and manipulate it to work \naround missing data.\na. First, download Data Set 2 “Body Temperatures” in Appendix B from www.TriolaStats.com. \nChoose the download format that matches your technology. (If you have no preferred technol-\nogy, you can download a free copy of Statdisk (from www.statdisk.org), which is designed for \nthis book and contains all Appendix B data sets.)\nb. Some statistical procedures, such as those involved with correlation and regression (dis-\ncussed in later chapters) require data that consist of matched pairs of values, and those proce-\ndures ignore pairs in which at least one of the data values in a matched pair is missing. Assume \nthat we want to conduct analyses for correlation and regression on the last two columns of \ndata in Data Set 2: body temperatures measured at 8 AM on day 2 and again at 12 AM on day \n2. For those last two columns, identify the rows with at least one missing value. Note that in \nsome technologies, such as TI-83>84 Plus calculators, missing data must be represented by a \nconstant such as -9 or 999.\nc. Here are two different strategies for reconfiguring the data set to work around the missing \ndata in the last two columns (assuming that we need matched pairs of data with no missing \nvalues):\ni. Manual Deletion Highlight rows with at least one missing value in the last two columns, \nthen delete those rows. This can be tedious if there are many rows with missing data and those \nrows are interspersed throughout instead of being adjacent rows.\nii. Sort Most technologies have a Sort feature that allows you to rearrange all rows using one \nparticular column as the basis for sorting (TI-83>84 Plus calculators do not have this type of sort \nfeature). The result is that all rows remain the same but they are in a different order. First use \nthe technology’s Sort feature to rearrange all rows using the “8 AM day 2” column as the basis \nfor sorting (so that all missing values in the “8 AM day 2” column are at the beginning); then \nhighlight and delete all of those rows with missing values in the “8 AM day 2” column. Next, \nuse the technology’s Sort feature to rearrange all rows using the “12 AM day 2” column as the \nbasis for sorting (so that all missing values in the “12 AM day 2” column are at the beginning); \nthen highlight and delete all of those rows with missing values in the “12 AM day 2” column. \nThe remaining rows will include matched pairs of body temperatures, and those rows will be \nsuitable for analyses such as correlation and regression. Print the resulting reconfigured data set.\n\nCooperative Group Activities\n1. In-class activity Working in groups of three or four, design an experiment to determine \nwhether pulse rates of college students are the same while the students are standing and sitting. \nConduct the experiment and collect the data. Save the data so that they can be analyzed with \nmethods presented in the following chapters.\n2. In-class activity Working in groups of three or four, construct a brief survey that includes \nonly a few questions that can be quickly asked. Include some objective questions along with \nsome that are biased, such as the first question below.\n•  Should your college force all students to pay a $100 activity fee?\n•  Should your college fund activities by collecting a $100 fee?\n Conduct the survey and try to detect the effect that the biased wording has on the  responses.\n3. In-class activity Identify problems with a mailing from Consumer Reports magazine that \nincluded an annual questionnaire about cars and other consumer products. Also included were \na request for a voluntary contribution of money and a voting ballot for the board of directors. \nResponses were to be mailed back in envelopes that required postage stamps.\n4. Out-of-class activity Find a report of a survey that used a voluntary response sample. De-\nscribe how it is quite possible that the results do not accurately reflect the population.\n5. Out-of-class activity Find a professional journal with an article that includes a statistical \nanalysis of an experiment. Describe and comment on the design of the experiment. Identify \none particular issue addressed by the study, and determine whether the results were found to \nbe statistically significant. Determine whether those same results have practical significance.\nFROM DATA TO DECISION\nCritical Thinking:  \nDo Male Symphony Conductors Really Live Longer?\nSeveral media reports made the interesting observation that \nmale symphony conductors live longer than other males. \nJohn Amaral wrote in Awaken that orchestra conductors \n“live longer than almost any other group of people by three \nto seven years.” Robert Levine wrote in Polyphonic.org that \nthey live longer “because they stand up while working.” \nSome provided other explanations for this phenomenon, \noften referring to cardiovascular activity. But do male sym-\nphony conductors really live longer than other groups of \nmales? The Internet can be researched for possible answers. \nLet’s also consider the following.\nAnalysis\n1. Consider the statement that “male symphony conductors \nlive longer.” Identify the specific group that they supposedly \nlive longer than. Does that other group consist of males ran-\ndomly selected from the general population?\n2. It is reasonable to assume that males do not become sym-\nphony conductors until they have reached at least the age \nof 40 years. When comparing life spans of male conduc-\ntors, should we compare them to other males in the general \n population, or should we compare them to other males who \nlived until at least 40 years of age? Explain.\n3. Without any disabilities, males qualify for Medicare if \nthey are 65 or older and meet a few other requirements. If \nwe compare life spans of males on Medicare to life spans \nof males randomly selected from the general population, \nwhy would we find that males on Medicare have longer life \nspans?\n4. Explain in detail how to design a study for collecting data \nto determine whether it is misleading to state that male sym-\nphony conductors live longer. Should the study be an experi-\nment or an observational study?\nCHAPTER 1 Cooperative Group Activities \n39\n\n40\nFrequency Distributions \nfor Organizing and \nSummarizing Data\nHistograms\nGraphs That Enlighten \nand Graphs That \nDeceive\nScatterplots, \nCorrelation, and \nRegression\n2-1\n2-2\n2-3\n2-4\nDoes Exposure to Lead Affect IQ Scores?\nCHAPTER \nPROBLEM\nExploring Data with \nTables and Graphs\nData Set 8 “IQ and Lead” in Appendix B includes full IQ scores \nfrom three groups of children who lived near a lead smelter. \nThe children in Group 1 had low levels of measured lead in \ntheir blood (with blood levels less than 40 micrograms>100 mL \nin each of two years). Group 2 had medium levels of measured \nlead in their blood (with blood levels of at least  \n40 micrograms/100 mL in exactly one of two years). Group 3 \nhad high levels of measured lead in their blood (with blood lev-\nels of at least 40 micrograms>100 mL in each of two years).\nLet’s consider the measured full IQ scores from Group 1  \n(low lead level) and Group 3 (high lead level), as listed in \nTable 2-1. It is an exceptionally rare person who can look \nat both lists of IQ scores and form meaningful conclusions. \nAlmost all of us must work at describing, exploring, and \n2\n\ncomparing the two sets of data. In this chapter we pres-\nent methods that focus on summarizing the data and using \ngraphs that enable us to understand important characteris-\ntics of the data, especially the distribution of the data. These \nmethods will help us compare the two sets of data so that we \ncan determine whether the IQ scores of the low lead group \nare somehow different from the IQ scores of the high lead \ngroup. Such comparisons will be helpful as we try to address \nthis important and key issue: Does exposure to lead have an \neffect on IQ score?\nThis chapter and the following chapter focus on important characteristics of data, \nincluding the following:\nCharacteristics of Data\n1. Center: A representative value that shows us where the middle of the data set is \nlocated.\n2. Variation: A measure of the amount that the data values vary.\n3. Distribution: The nature or shape of the spread of the data over the range of values \n(such as bell-shaped).\n4. Outliers: Sample values that lie very far away from the vast majority of the other \nsample values. (Later, a more objective definition of “outlier” will be given.)\n5. Time: Any change in the characteristics of the data over time.\nThis chapter provides tools that enable us to gain insight into data by organizing, sum-\nmarizing, and representing them in ways that enable us to see important characteristics \nof the data. Here are the chapter objectives:\nFrequency Distributions for Organizing and Summarizing Data\n• Develop an ability to summarize data in the format of a frequency distribution and a \nrelative frequency distribution.\n• For a frequency distribution, identify values of class width, class midpoint, class lim-\nits, and class boundaries.\n2-1\nChapter Objectives \n41\nCHAPTER OBJECTIVES\n>>>\nTABLE 2-1 Full IQ Scores of the Low Lead Group and the High Lead Group\nLow Lead Level (Group 1)\n70\n85\n86\n76\n84\n96\n94\n56\n115\n97\n77\n128\n99\n80\n118\n86\n141\n88\n96\n96\n107\n86\n80\n107\n101\n91\n125\n96\n99\n99\n115\n106\n105\n96\n50\n99\n85\n88\n120\n93\n87\n98\n78\n100\n105\n87\n94\n89\n80\n111\n104\n85\n94\n75\n73\n76\n107\n88\n89\n96\n72\n97\n76\n107\n104\n85\n76\n95\n86\n89\n76\n96\n101\n108\n102\n77\n74\n92\nHigh Lead Level (Group 3)\n82\n93\n85\n75\n85\n80\n101\n89\n80\n94\n88\n104\n88\n88\n83\n104\n96\n76\n80\n79\n75\n\n42 \nCHAPTER 2 Exploring Data with Tables and Graphs\nHistograms\n• Develop the ability to picture the distribution of data in the format of a histogram or \nrelative frequency histogram.\n• Examine a histogram and identify common distributions, including a uniform distribu-\ntion and a normal distribution.\nGraphs That Enlighten and Graphs That Deceive\n• Develop an ability to graph data using a dotplot, stemplot, time-series graph, Pareto \nchart, pie chart, and frequency polygon.\n• Determine when a graph is deceptive through the use of a nonzero axis or a \n pictograph that uses an object of area or volume for one-dimensional data.\nScatterplots, Correlation, and Regression\n• Develop an ability to construct a scatterplot of paired data.\n• Analyze a scatterplot to determine whether there appears to be a correlation \n between two variables.\n2-2\n2-3\n2-4\nHistograms\n• Develop the ability to picture the distribution of data in the format of a histogram or \nrelative frequency histogram.\n• Examine a histogram and identify common distributions, including a uniform distribu-\ntion and a normal distribution.\nGraphs That Enlighten and Graphs That Deceive\n• Develop an ability to graph data using a dotplot, stemplot, time-series graph, Pareto\nchart, pie chart, and frequency polygon.\n• Determine when a graph is deceptive through the use of a nonzero axis or a\npictograph that uses an object of area or volume for one-dimensional data.\nScatterplots, Correlation, and Regression\n• Develop an ability to construct a scatterplot of paired data.\n• Analyze a scatterplot to determine whether there appears to be a correlation \nbetween two variables.\nKey Concept When working with large data sets, a frequency distribution (or frequency \ntable) is often helpful in organizing and summarizing data. A frequency distribution \nhelps us to understand the nature of the distribution of a data set.\n \n2-1\n \n Frequency Distributions for Organizing  \nand Summarizing Data\nDEFINITION\nA frequency distribution (or frequency table) shows how data are partitioned \namong several categories (or classes) by listing the categories along with the num-\nber (frequency) of data values in each of them.\nConsider the IQ scores of the low lead group listed in Table 2-1. Table 2-2 is a fre-\nquency distribution summarizing those IQ scores. The frequency for a particular class \nis the number of original values that fall into that class. For example, the first class in \nTable 2-2 has a frequency of 2, so 2 of the IQ scores are between 50 and 69 inclusive.\nThe following standard terms are often used in constructing frequency distributions \nand graphs.\nTABLE 2-2 IQ Scores of the \nLow Lead Group\nIQ Score\nFrequency\n50–69\n 2\n70–89\n33\n 90–109\n35\n110–129\n 7\n130–149\n 1\nDEFINITIONS\nLower class limits are the smallest numbers that can belong to each of the differ-\nent classes. (Table 2-2 has lower class limits of 50, 70, 90, 110, and 130.)\nUpper class limits are the largest numbers that can belong to each of the different \nclasses. (Table 2-2 has upper class limits of 69, 89, 109, 129, and 149.)\nClass boundaries are the numbers used to separate the classes, but without the \ngaps created by class limits. In Figure 2-1 we see that the values of 69.5, 89.5, \n109.5, and 129.5 are in the centers of those gaps, and following the pattern of \nthose class boundaries, we see that the lowest class boundary is 49.5 and the \n\n2-1 Frequency Distributions for Organizing and Summarizing Data  \n43\nProcedure for Constructing a Frequency Distribution\nWe construct frequency distributions to (1) summarize large data sets, (2) see the dis-\ntribution and identify outliers, and (3) have a basis for constructing graphs (such as \nhistograms, introduced in Section 2-2). Technology can generate frequency distribu-\ntions, but here are the steps for manually constructing them:\n1. Select the number of classes, usually between 5 and 20. The number of classes \nmight be affected by the convenience of using round numbers.\n2. Calculate the class width.\nClass width ≈1maximum data value2 - 1minimum data value2\nnumber of classes\nRound this result to get a convenient number. (It’s usually best to round up.) \nUsing a specific number of classes is not too important, and it’s usually wise to \nchange the number of classes so that they use convenient values for the class \nlimits.\n3. Choose the value for the first lower class limit by using either the minimum \nvalue or a convenient value below the minimum.\nhighest class boundary is 149.5. Thus the complete list of class boundaries is 49.5, \n69.5, 89.5, 109.5, 129.5, and 149.5.\nClass midpoints are the values in the middle of the classes. Table 2-2 has class \nmidpoints of 59.5, 79.5, 99.5, 119.5, and 139.5. Each class midpoint is computed \nby adding the lower class limit to the upper class limit and dividing the sum by 2.\nClass width is the difference between two consecutive lower class limits (or two \nconsecutive lower class boundaries) in a frequency distribution. Table 2-2 uses a \nclass width of 20. (The first two lower class boundaries are 50 and 70, and their dif-\nference is 20.)\nCAUTION Finding the correct class width can be tricky. For class width, don’t \nmake the most common mistake of using the difference between a lower class limit \nand an upper class limit. See Table 2-2 and note that the class width is 20, not 19.\n69.5\n49.5\n50\n69\n149.5\nSTEP 1:\nList the class limits\nfrom Table 2-2.\nSTEP 2:\nSplit the diﬀerence\nas shown.\nSTEP 3:\nFind the ﬁrst and\nlast values of 49.5\nand 149.5 by\nprojecting the\nsame pattern.\n70\n89\n89.5\n90\n109\n109.5\n110\n129\n129.5\n130\n149\nFIGURE 2-1 Finding Class Boundaries from Class Limits in Table 2-2\nGrowth Charts Updated\nPediatricians \ntypically use \nstandardized \ngrowth charts to \ncompare their \npatient’s weight \nand height \nto a sample of other children. \nChildren are considered to be in \nthe normal range if their weight \nand height fall between the 5th \nand 95th percentiles. If they fall \noutside that range, they are often \ngiven tests to ensure that there \nare no serious medical problems. \nPediatricians became increas-\ningly aware of a major problem \nwith the charts: Because they \nwere based on children living be-\ntween 1929 and 1975, the growth \ncharts had become inaccurate. \nTo rectify this problem, the charts \nwere updated in 2000 to reflect \nthe current measurements of \nmillions of children. The weights \nand heights of children are good \nexamples of populations that \nchange over time. This is the \nreason for including changing \ncharacteristics of data over time \nas an important consideration for \na population.\nh\nhild\nCAUTION For class boundaries, remember that they split the difference between \nthe end of one class and the beginning of the next class, as shown in Figure 2-1.\ncontinued\n\n44 \nCHAPTER 2 Exploring Data with Tables and Graphs\n4. Using the first lower class limit and the class width, list the other lower class \nlimits. (Do this by adding the class width to the first lower class limit to get the \nsecond lower class limit. Add the class width to the second lower class limit to \nget the third lower class limit, and so on.)\n5. List the lower class limits in a vertical column and then determine and enter the \nupper class limits.\n6. Take each individual data value and put a tally mark in the appropriate \nclass. Add the tally marks to find the total frequency for each class.\nWhen constructing a frequency distribution, be sure the classes do not overlap. \nEach of the original values must belong to exactly one class. Include all classes, even \nthose with a frequency of zero. Try to use the same width for all classes, although it is \nsometimes impossible to avoid open-ended intervals, such as “65 years or older.”\nEXAMPLE 1  IQ Scores of Low Lead Group\nUsing the IQ scores of the low lead group in Table 2-1, follow the above procedure \nto construct the frequency distribution shown in Table 2-2. Use five classes.\nSOLUTION\nStep 1: Select 5 as the number of desired classes.\nStep 2: Calculate the class width as shown below. Note that we round 18.2 up to 20, \nwhich is a much more convenient number.\n Class width ≈1maximum data value2 - 1minimum data value2\nnumber of classes\n = 141 - 50\n5\n= 18.2 ≈20 1rounded up to a convenient number2\nStep 3: The minimum data value is 50 and it is a convenient starting point, so use \n50 as the first lower class limit. (If the minimum value had been 52 or 53, we would \nhave rounded down to the more convenient starting point of 50.)\nStep 4: Add the class width of 20 to 50 to get the second lower class limit of 70. \nContinue to add the class width of 20 until we have five lower class limits. The \nlower class limits are therefore 50, 70, 90, 110, and 130.\nStep 5: List the lower class limits vertically, as shown in the margin. From this list, \nwe identify the corresponding upper class limits as 69, 89, 109, 129, and 149.\nStep 6: Enter a tally mark for each data value in the appropriate class. Then add the \ntally marks to find the frequencies shown in Table 2-2.\n 50–\n 70–\n 90–\n110–\n130–\nCategorical Data So far we have discussed frequency distributions using only quan-\ntitative data sets, but frequency distributions can also be used to summarize categori-\ncal (or qualitative or attribute) data, as illustrated in Example 2.\nEXAMPLE 2   Emergency Room Visits for Injuries from Sports \nand Recreation \nTable 2-3 lists data for the highest seven sources of injuries resulting in a visit to \na hospital emergency room (ER) in a recent year (based on data from the Centers \nfor Disease Control and Prevention). The activity names are categorical data at \n\n2-1 Frequency Distributions for Organizing and Summarizing Data  \n45\nRelative Frequency Distribution\nA variation of the basic frequency distribution is a relative frequency distribution or \npercentage frequency distribution, in which each class frequency is replaced by a \nrelative frequency (or proportion) or a percentage. In this text we use the term “rela-\ntive frequency distribution” whether we use relative frequencies or percentages. Rela-\ntive frequencies and percentages are calculated as follows.\n Relative frequency for a class = frequency for a class\nsum of all frequencies\n Percentage for a class = frequency for a class\nsum of all frequencies * 100%\nTable 2-4 is an example of a relative frequency distribution. It is a variation of \nTable 2-2 in which each class frequency is replaced by the corresponding percent-\nage value. Because there are 78 data values, divide each class frequency by 78, and \nthen multiply by 100%. The first class of Table 2-2 has a frequency of 2, so divide \n2 by 78 to get 0.0256, and then multiply by 100% to get 2.56%, which we rounded \nto 2.6%. The sum of the percentages should be 100%, with a small discrepancy al-\nlowed for rounding errors, so a sum such as 99% or 101% is acceptable. The sum \nof the percentages in Table 2-4 is 100.1%.\nThe sum of the percentages in a relative frequency distribution must be \nvery close to 100%.\nCumulative Frequency Distribution\nAnother variation of a frequency distribution is a cumulative frequency distribu-\ntion in which the frequency for each class is the sum of the frequencies for that class \nand all previous classes. Table 2-5 is a cumulative frequency distribution based on \nTable 2-2. Using the original frequencies of 2, 33, 35, 7, and 1, we add 2 + 33 to get \nthe second cumulative frequency of 35; then we add 2 + 33 + 35 to get the third; \nand so on. See Table 2-5, and note that in addition to the use of cumulative frequen-\ncies, the class limits are replaced by “less than” expressions that describe the new \nranges of values.\nTABLE 2-3 Annual ER Visits for Injuries from Sports and Recreation\nActivity\nFrequency\nBicycling\n26,212\nFootball\n25,376\nPlayground\n16,706\nBasketball\n13,987\nSoccer\n10,436\nBaseball\n 9,634\nAll-terrain vehicle\n 6,337\nthe nominal level of measurement, but we can create the frequency distribution as \nshown. It might be surprising to see that bicycling is at the top of this list, but this \ndoesn’t mean that bicycling is the most dangerous of these activities; many more \npeople bicycle than play football or ride an all-terrain vehicle or do any of the other \nlisted activities.\nTABLE 2-4 Relative  \nFrequency Distribution of IQ \nScores of Low Lead Group\nIQ Score\nFrequency\n50–69\n2.6%\n70–89\n42.3%\n 90–109\n44.9%\n110–129\n 9.0%\n130–149\n 1.3%\nTABLE 2-5 Cumulative  \nFrequency Distribution of IQ \nScores of Low Lead Group\n \nIQ Score\nCumulative \nFrequency\nLess than 70\n 2\nLess than 90\n35\nLess than 110\n70\nLess than 130\n77\nLess than 150\n78\n\n46 \nCHAPTER 2 Exploring Data with Tables and Graphs\nCritical Thinking: Using Frequency Distributions  \nto Understand Data\nAt the beginning of this section we noted that a frequency distribution can help us un-\nderstand the distribution of a data set, which is the nature or shape of the spread of the \ndata over the range of values (such as bell-shaped). In statistics we are often interested \nin determining whether the data have a normal distribution. (Normal distributions are \ndiscussed extensively in Chapter 6.) Data that have an approximately normal distribu-\ntion are characterized by a frequency distribution with the following features:\nNormal Distribution\n1. The frequencies start low, then increase to one or two high frequencies, and \nthen decrease to a low frequency.\n2. The distribution is approximately symmetric: Frequencies preceding the \nmaximum frequency should be roughly a mirror image of those that follow \nthe maximum frequency.\nTable 2-6 satisfies these two conditions. The frequencies start low, increase to the max-\nimum of 56, and then decrease to a low frequency. Also, the frequencies of 1 and 10 \nthat precede the maximum are a mirror image of the frequencies 10 and 1 that follow \nthe maximum. Real data sets are usually not so perfect as Table 2-6, and judgment \nmust be used to determine whether the distribution comes “close enough” to satisfying \nthe above two conditions. (There are more objective procedures included later.)\nTABLE 2-6 Frequency Distribution Showing a Normal Distribution\nScore\nFrequency\nNormal Distribution\n50–69\n 1\nd Frequencies start low, . . .\n70–89\n10\n 90–109\n56\nd  Increase to a maximum, . . .\n110–129\n10\n130–149\n 1\nd  Decrease to become low again.\nAnalysis of Last Digits Example 3 illustrates this principle:\nFrequencies of last digits sometimes reveal how the data were collected \nor measured.\nEXAMPLE 3   Exploring Data: How Were the Weights Obtained in \nCalifornia? \nWhen collecting weights of people, it’s better to actually weigh people than to \nask them what they weigh. People often tend to round way down, so that a weight \nof 196 lb might be reported as 170 lb. Table 2-7 summarizes the last digits of the \nweights of 100 people used in the California Health Interview Survey. If people are \nactually weighed on a scale, the last digits of weights tend to have frequencies that \nare approximately the same, but Table 2-6 shows that the vast majority of weights \nhave last digits of 0 or 5, and this is strong evidence that people reported their \nweights and were not physically weighed. (Also, the word “interview” in the title \nof the California Health Interview Survey reveals that people were interviewed and \nwere not physically measured.)\n\n2-1 Frequency Distributions for Organizing and Summarizing Data  \n47\nGaps Example 4 illustrates this principle:\nThe presence of gaps can suggest that the data are from two or more \ndiﬀerent populations.\nThe converse of this principle is not true, because data from different populations do \nnot necessarily result in gaps.\nTABLE 2-7  Last Digits of Weights from the \nCalifornia Health Interview Survey\nLast Digit of Weight\nFrequency\n0\n46\n1\n 1\n2\n 2\n3\n 3\n4\n 3\n5\n30\n6\n 4\n7\n 0\n8\n 8\n9\n 3\nEXAMPLE 4  Exploring Data: What Does a Gap Tell Us?\nTable 2-8 is a frequency distribution of the heights (in.) of males. Examination of \nthe frequencies reveals a large gap between the shortest males and the tallest males. \nThis can be explained by the fact that half of the males are 7 years old and the other \nhalf are adults, so we really have samples from two different populations.\nTABLE 2-8 Heights of Males\nHeight (in.)\nFrequency\n40–44\n 3\n45–49\n17\n50–54\n29\n55–59\n 1\n60–64\n 0\n65–69\n24\n70–74\n23\n75–79\n 3\n\n48 \nCHAPTER 2 Exploring Data with Tables and Graphs\nTABLE 2-9 IQ Scores from the Low Lead Group and the High Lead Group\nIQ Score\nLow Lead Group\nHigh Lead Group\n50–69\n 2.6%\n70–89\n42.3%\n71.4%\n 90–109\n44.9%\n28.6%\n110–129\n 9.0%\n130–149\n 1.3%\nEXAMPLE 5   Comparing IQ Scores of the Low Lead Group and \nthe High Lead Group \nTable 2-1, which is given with the Chapter Problem at the beginning of this chapter, \nlists IQ scores from the low lead group and the high lead group. Because the sample \nsizes of 78 and 21 are so different, a comparison of frequency distributions is not \neasy, but Table 2-9 shows the relative frequency distributions for those two groups. \nBy comparing those relative frequencies, we see that the majority of children in the \nlow lead group had IQ scores of 90 or higher, but the majority of children in the \nhigh lead group had IQ scores below 90. This suggests that perhaps high lead expo-\nsure has a detrimental effect on IQ scores.\nFrequency Distributions\nAccess tech instructions, videos, and data sets at www.TriolaStats.com\nTECH CENTER \nStatistical Literacy and Critical Thinking\n1. Cotinine in Smokers Refer to the accompanying table summarizing measured amounts \nof serum cotinine (ng/mL) from a sample of smokers (from Data Set 14 “Passive and Active \nSmoke” in Appendix B). When nicotine is absorbed by the body, cotinine is produced. How \nmany subjects are included in the summary? Is it possible to identify the exact values of all of \nthe original cotinine measurements?\n2-1 Basic Skills and Concepts \nCotinine (ng, mL)\nFrequency\n 0–99\n11\n100–199\n12\n200–299\n14\n300–399\n 1\n400-499\n 2\n2. Cotinine in Smokers Refer to the accompanying frequency distribution. What problem is \ncreated by using classes of 0–100, 100–200, . . . ?\n3. Relative Frequency Distribution Use percentages to construct the relative frequency dis-\ntribution corresponding to the accompanying frequency distribution for cotinine amounts.\n4. What’s Wrong? Heights of adult males are known to have a normal distribution, as de-\nscribed in this section. A researcher claims to have randomly selected adult males and mea-\nsured their heights with the resulting relative frequency distribution as shown here. Identify two \nmajor flaws with theses results.\nHeight \n(cm)\nRelative  \nFrequency\n130–144\n23%\n145–159\n25%\n160–174\n22%\n175–189\n27%\n190–204\n28%\nComparisons Example 5 illustrates this principle:\nCombining two or more relative frequency distributions in one table \nmakes comparisons of data much easier.\n\n2-1 Frequency Distributions for Organizing and Summarizing Data  \n49\nIn Exercises 5–8, identify the class width, class midpoints, and class boundaries for the \ngiven frequency distribution. The frequency distributions are based on real data from \nAppendix B.\n5. \nCotinine (NonSmokers  \nExposed to Smoke  \nin ng, mL)\n \n \nFrequency\n0–99\n34\n100–199\n 2\n200–299\n 1\n300–399\n 1\n400–499\n 0\n500–599\n 2\n6. \nBrain Volume (cm3)\nFrequency\n960–1049\n6\n1050–1139\n7\n1140–1229\n3\n1230–1319\n2\n1320–1409\n1\n1410–1499\n1\n7. \nBlood Platelet \nCount of Males\n \nFrequency\n 0–99\n 1\n100–199\n51\n200–299\n90\n300–399\n10\n400–499\n 0\n500–599\n 0\n600–699\n 1\n8. \nBlood Platelet \nCount of Females\n \nFrequency\n100–199\n25\n200–299\n92\n300–399\n28\n400–499\n 0\n500–599\n 2\nNormal Distributions. In Exercises 9–12, answer the given questions, which are related \nto normal distributions.\n9. Cotinine Determine whether the frequency distribution given in Exercise 5 is approximately \na normal distribution. Explain.\n10. Brain Volume Refer to the frequency distribution given in Exercise 6 and ignore the given fre-\nquencies. Assume that the first three frequencies are 1, 3, and 6, respectively. Assuming that the dis-\ntribution of the 20 sample values is a normal distribution, identify the remaining three frequencies.\n11. Normal Distribution Refer to the frequency distribution given in Exercise 7 and ignore \nthe given frequencies. Assume that the first three frequencies are 2, 12, and 18, respectively. \nAssuming that the distribution of the 153 sample values is a normal distribution, identify the \nremaining four frequencies.\n12. Normal Distribution Refer to the frequency distribution given in Exercise 8 and deter-\nmine whether it appears to be a normal distribution. Explain.\nConstructing Frequency Distributions. In Exercises 13–22, use the indicated data and \nconstruct the frequency distribution. (The data for Exercises 13–22 can be downloaded at \nTriolaStats.com.)\n13. Pulse Rates of Males Refer to Data Set 1 “Body Data” in Appendix B and use the pulse \nrates (beats per minute) of males. Begin with a lower class limit of 40 and use a class width of \n10. Do the pulse rates of males appear to have a normal distribution?\n14. Pulse Rates of Females Refer to Data Set 1 “Body Data” in Appendix B and use the \npulse rates (beats per minute) of females. Begin with a lower class limit of 30 and use a class \nwidth of 10. Do the pulse rates of females appear to have a normal distribution?\n15. Lead and IQ Refer to Data Set 8 “IQ and Lead” in Appendix B and use the verbal IQ \nscores of the low lead group. Begin with a lower class limit of 50 and use a class width of 10. \nDo these IQ scores appear to be normally distributed?\n\n50 \nCHAPTER 2 Exploring Data with Tables and Graphs\n16. Lead and IQ Refer to Data Set 8 “IQ and Lead” in Appendix B and use the verbal IQ \nscores of the high lead group. Begin with a lower class limit of 60 and use a class width of 10. \nDo these IQ scores appear to be normally distributed?\n17. Male Red Blood Cell Counts Refer to Data Set 1 “Body Data” in Appendix B and use \nthe red blood cell counts (million cells>mL) for males. Begin with a lower class limit of 3.00 \nand use a class width of 0.50. Using a very loose interpretation of the requirements for a nor-\nmal distribution, do the red blood cell counts appear to be normally distributed?\n18. Female Red Blood Cell Counts Repeat the preceding exercise using the red blood cell \ncounts for females.\n19. Freshman 15 Refer to Data Set 10 “Freshman 15” in Appendix B and use the weights (kg) \nof males in September of their freshman year. Begin with a lower class limit of 50 kg and use a \nclass width of 10 kg.\n20.  Freshman 15 Repeat the preceding exercise using the weights (kg) of males in April. \nCompare the result to the frequency distribution from the preceding exercise. Does it appear \nthat males gain 15 lb (or 6.8 kg) during their freshman year?\n21. Analysis of Last Digits Heights of statistics students were obtained by one of the authors \nas part of an experiment conducted for class. The last digits of those heights are listed below. \nConstruct a frequency distribution with 10 classes. Based on the distribution, do the heights ap-\npear to be reported or actually measured? What do you know about the accuracy of the results?\n0 0 0 0 0 0 0 0 0 1 1 2 3 3 3 4 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 6 6 8 8 8 9\n22. Analysis of Last Digits Listed below are the last digits of weights of subjects. After con-\nstructing the frequency distribution, does it appear that the weights were reported or physically \nmeasured? Explain.\n2 7 7 3 2 8 5 9 7 2 8 6 9 2 7 5 6 4 0 7 6 8 4 0 4\n7 5 5 4 8 6 3 8 9 3 9 2 6 0 1 1 1 7 2 0 3 5 6 6 8\nRelative Frequencies for Comparisons. In Exercises 23 and 24, find the relative fre-\nquencies and answer the given questions.\n23. Cotinine Construct one table (similar to Table 2-9 on page 48) that includes relative fre-\nquencies based on the frequency distributions from Exercise 1 (smokers) and Exercise 5 (non-\nsmokers exposed to smoke), and then compare them. Are there notable differences?\n24. Blood Platelet Counts Construct one table (similar to Table 2-9 on page 48) that includes \nrelative frequencies based on the frequency distributions from Exercises 7 and 8, and then com-\npare them. Are there notable differences?\nCumulative Frequency Distributions. In Exercises 25 and 26, construct the cumulative \nfrequency distribution that corresponds to the frequency distribution in the exercise indicated.\n25. Exercise 5\n26. Exercise 6\n27. Interpreting Effects of Outliers Exercise 5 in this section involved cotinine levels of \nnonsmokers who were exposed to tobacco smoke. (See the middle column in Data Set 14 \n “Passive and Active Smoke” in Appendix B.)\na. Identify any outliers.\nb. After adding another value of 999 to the cotinine levels of nonsmokers exposed to smoke, construct \nthe frequency distribution as in Exercise 5. How is the frequency distribution affected by the addition \nof the outlier 999? State a generalization about the effect of an outlier on a frequency distribution.\n2-1 Beyond the Basics \n\n2-2 Histograms \n51\nImportant Uses of a Histogram\n \n■Visually displays the shape of the distribution of the data\n \n■Shows the location of the center of the data\n \n■Shows the spread of the data\n \n■Identifies outliers\nA histogram is basically a graph of a frequency distribution. For example, \n Figure 2-2 shows the histogram corresponding to the frequency distribution given in \nTable 2-2 on page 42.\nClass frequencies should be used for the vertical scale and that scale should be la-\nbeled as in Figure 2-2. There is no universal agreement on the procedure for selecting \nwhich values are used for the bar locations along the horizontal scale, but it is com-\nmon to use class boundaries (as shown in Figure 2-2) or class midpoints or class limits \nor something else. It is often easier for us mere mortals to use class midpoints for the \nhorizontal scale. Histograms can usually be generated using technology.\nRelative Frequency Histogram\nA relative frequency histogram has the same shape and horizontal scale as a histo-\ngram, but the vertical scale uses relative frequencies (as percentages or proportions) \ninstead of actual frequencies. Figure 2-3 is the relative frequency histogram corre-\nsponding to Figure 2-2.\nPART 1\nBasic Concepts of Histograms\nKey Concept While a frequency distribution is a useful tool for summarizing data \nand investigating the distribution of data, an even better tool is a histogram, which is a \ngraph that is easier to interpret than a table of numbers.\n2-2 \nHistograms\nDEFINITION\nA histogram is a graph consisting of bars of equal width drawn adjacent to each \nother (unless there are gaps in the data). The horizontal scale represents classes of \nquantitative data values, and the vertical scale represents frequencies. The heights \nof the bars correspond to frequency values.\nFIGURE 2-2 Histogram\nFIGURE 2-3 Relative Frequency Histogram\n\n52 \nCHAPTER 2 Exploring Data with Tables and Graphs\nCritical Thinking: Interpreting Histograms\nThe ultimate objective of a histogram is to understand characteristics of the data. Ex-\nplore the data by analyzing the histogram to see what can be learned about “CVDOT”: \nthe center of the data, the variation (which will be discussed at length in Section 3-2), \nthe shape of the distribution, whether there are any outliers (values far away from the \nother values), and time (whether there is any change in the characteristics of the data \nover time). Examining Figure 2-2, we see that the histogram is centered close to 90, \nthe values vary from around 50 to 150, and the distribution is roughly bell-shaped. \nThere aren’t any outliers and any changes in time are irrelevant for these data.\nCommon Distribution Shapes\nThe histograms shown in Figure 2-4 depict four common distribution shapes.\nNormal Distribution\nWhen graphed as a histogram, data with a normal distribution have a “bell” shape \nsimilar to the one superimposed in Figure 2-5. Many collections of data have a dis-\ntribution that is approximately normal. Many statistical methods require that sample \ndata come from a population having a distribution that is approximately a normal dis-\ntribution, and we can often use a histogram to judge whether this requirement is satis-\nfied. There are more advanced and less subjective methods for determining whether \nthe distribution is a normal distribution. Normal quantile plots are very helpful for \nassessing normality: see Part 2 of this section.\n   \n   \nFIGURE 2-4 Common Distributions\n(a)\n(b)\n(c)\n(d)\n\n2-2 Histograms \n53\nUniform Distribution\nThe different possible values occur with approximately the same frequency, so the \nheights of the bars in the histogram are approximately uniform, as in Figure 2-4(b). \nFigure 2-4(b) depicts outcomes of last digits of weights from a large sample of ran-\ndomly selected subjects, and such a graph is helpful in determining whether the sub-\njects were actually weighed or whether they reported their weights.\nPopulation sizes of an organism are often uniformly distributed when they are \nfound in equally sized areas of a region where they must compete for a limited re-\nsource. For example, redwood trees must compete for light, and numbers of redwood \ntrees in equally sized areas of a region tend to be uniformly distributed.\nSkewness\nA distribution of data is skewed if it is not symmetric and extends more to one side \nthan to the other. Data skewed to the right (also called positively skewed) have a \nlonger right tail, as in Figure 2-4(c). Annual incomes of adult Americans are skewed \nto the right; death rates of nations are skewed to the right. Data skewed to the left \n(also called negatively skewed) have a longer left tail, as in Figure 2-4(d). Life span \ndata in humans are skewed to the left. (Here’s a mnemonic for remembering skew-\nness: A distribution skewed to the right resembles the toes on your right foot, and \none skewed to the left resembles the toes on your left foot.) Distributions skewed to \nthe right are more common than those skewed to the left because it’s often easier to \nget exceptionally large values than values that are exceptionally small. With annual \nincomes, for example, it’s impossible to get values below zero, but there are a few \npeople who earn millions or billions of dollars in a year. Annual incomes therefore \ntend to be skewed to the right.\nPART 2\n  Assessing Normality with  \nNormal Quantile Plots\nSome methods presented in later chapters have a requirement that sample data must \nbe from a population having a normal distribution. Histograms can be helpful in de-\ntermining whether the normality requirement is satisfied, but they are not very help-\nful with small data sets. Section 6-5 discusses methods for assessing normality—that \nis, determining whether the sample data are from a normally distributed population. \nSection 6-5 includes a procedure for constructing normal quantile plots, which are \nFIGURE 2-5  Bell-Shaped Distribution\nBecause this histogram is roughly bell-shaped, we say that the \ndata have a normal distribution. (A more rigorous deﬁnition will be \ngiven in Chapter 6.)\nRemembering Skewness:\nSkewed Left:   Resembles \ntoes on left \nfoot\nSkewed Right:  Resembles \ntoes on right \nfoot\n\n54 \nCHAPTER 2 Exploring Data with Tables and Graphs\neasy to generate using technology such as Statdisk, SPSS, JMP, Minitab, XLSTAT, \nStatCrunch, or a TI-83>84 Plus calculator. Interpretation of a normal quantile plot is \nbased on the following criteria:\nCriteria for Assessing Normality with a Normal Quantile Plot\nNormal Distribution: The population distribution is normal if the pattern of the \npoints in the normal quantile plot is reasonably close to a straight line, and the \npoints do not show some systematic pattern that is not a straight-line pattern.\nNot a Normal Distribution: The population distribution is not normal if the \nnormal quantile plot has either or both of these two conditions:\n•  The points do not lie reasonably close to a straight-line pattern.\n•  The points show some systematic pattern that is not a straight-line pattern.\nThe following are examples of normal quantile plots. Procedures for creating such \nplots are described in Section 6-5.\nNormal Distribution: The points are  \nreasonably close to a straight-line pattern, \nand there is no other systematic pattern \nthat is not a straight-line pattern.\nNot a Normal Distribution: The \npoints do not lie reasonably close to a \nstraight line.\nNot a Normal Distribution: The \npoints show a systematic pattern that \nis not a straight-line pattern.\nHistograms\nAccess tech instructions, videos, and data sets at www.TriolaStats.com\nTECH CENTER \nStatistical Literacy and Critical Thinking\n1. Histogram Table 2-2 is a frequency distribution summarizing the IQ scores of the low lead \ngroup listed in Table 2-1 on page 41, and Figure 2-2 on page 51 is a histogram depicting that \nsame data set. When trying to better understand the IQ data, what is the advantage of examin-\ning the histogram instead of the frequency distribution?\n2. Voluntary Response Sample The histogram in Figure 2-2 on page 51 is constructed from \na simple random sample of children. If you construct a histogram with data collected from a \nvoluntary response sample, will the distribution depicted in the histogram reflect the true dis-\ntribution of the population? Why or why not?\n3. Blood Platelet Counts Listed below are blood platelet counts (1000 cells>mL) randomly \nselected from adults in the United States. Why does it not make sense to construct a histogram \nfor this data set?\n191 286 263 193 193 215 162 646 250 386\n2-2 Basic Skills and Concepts\n\n2-2 Histograms \n55\n4. Normal Distribution When it refers to a normal distribution, does the term “normal” have \nthe same meaning as in ordinary language? What criterion can be used to determine whether \nthe data depicted in a histogram have a distribution that is approximately a normal distribution? \nIs this criterion totally objective, or does it involve subjective judgment?\nInterpreting a Histogram. In Exercises 5–8, answer the questions by referring to the fol-\nlowing histogram, which represents the sepal widths (mm) of a sample of irises. (See Data \nSet 16 “Iris Measurements” in Appendix B.)\n5. Sample Size Based on the histogram, what is the approximate number of irises in \nthe sample?\n6. Class Width and Class Limits What is the class width? What are the approximate lower \nand upper class limits of the first class?\n7. Outlier? What is the largest possible value? Would that value be an outlier?\n8. Normal Distribution Does it appear that the sample is from a population having a normal \ndistribution?\nConstructing Histograms. In Exercises 9–18, construct the histograms and answer the \ngiven questions. Use class midpoint values for the horizontal scale.\n9. Pulse Rates of Males Use the frequency distribution from Exercise 13 in Section 2-1 on \npage 49 to construct a histogram. Do the pulse rates of males appear to have a normal distribution?\n10. Pulse Rates of Females Use the frequency distribution from Exercise 14 in Section 2-1  \non page 49 to construct a histogram. Do the pulse rates of females appear to have a normal \ndistribution?\n11. Lead and IQ Use the frequency distribution from Exercise 15 in Section 2-1 on page 49 to \nconstruct a histogram. Do the IQ scores appear to have a normal distribution?\n12. Lead and IQ Use the frequency distribution from Exercise 16 in Section 2-1 on page 50 to \nconstruct a histogram. Do the IQ scores appear to have a normal distribution?\n13.  Male Red Blood Cell Counts Use the frequency distribution from Exercise 17 in \nSection 2-1 on page 50 to construct a histogram. Do the red blood cell counts appear to have a \nnormal distribution?\n14. Female Red Blood Cell Counts Use the frequency distribution from Exercise 18 in \nSection 2-1 on page 50 to construct a histogram. Do the red blood cell counts appear to have \na normal distribution?\n15. Freshman 15 Use the frequency distribution from Exercise 19 in Section 2-1 on page 50 \nto construct a histogram.\n16. Freshman 15 Use the frequency distribution from Exercise 20 in Section 2-1 on page 50 \nto construct a histogram.\n\n56 \nCHAPTER 2 Exploring Data with Tables and Graphs\n17. Last Digit Analysis Use the frequency distribution from Exercise 21 in Section 2-1 on \npage 50 to construct a histogram. What does the histogram suggest about the method used to \ncollect the heights?\n18. Last Digit Analysis Use the frequency distribution from Exercise 22 in Section 2-1 on \npage 50 to construct a histogram. What does the histogram suggest about the method used to \ncollect the weights?\n2-2 Beyond the Basics\nKey Concept Section 2-2 introduced the histogram, and this section introduces other \ncommon graphs that foster understanding of data. We also discuss some graphs that \nare deceptive because they create impressions about data that are somehow mislead-\ning or wrong.\nThe era of charming and primitive hand-drawn graphs has passed, and technol-\nogy now provides us with powerful tools for generating a wide variety of graphs. \nHere we go.\nGraphs That Enlighten\nDotplots\nA dotplot consists of a graph of quantitative data in which each data value is plotted \nas a point (or dot) above a horizontal scale of values. Dots representing equal values \nare stacked.\nFeatures of a Dotplot\n \n■Displays the shape of the distribution of data.\n \n■It is usually possible to recreate the original list of data values.\n2-3 \nGraphs That Enlighten and Graphs That Deceive\n19. Interpreting Normal Quantile Plots Which of the following normal quantile plots  appear \nto represent data from a population having a normal distribution? Explain.\n(a)\n(b)\n(c)\n(d)\n\n2-3 Graphs That Enlighten and Graphs That Deceive \n57\nStemplots\nA stemplot (or stem-and-leaf plot) represents quantitative data by separating each \nvalue into two parts: the stem (such as the leftmost digit) and the leaf (such as the \nrightmost digit). Better stemplots are often obtained by first rounding the original data \nvalues. Also, stemplots can be expanded to include more rows and can be condensed \nto include fewer rows.\nFeatures of a Stemplot\n \n■Shows the shape of the distribution of the data.\n \n■Retains the original data values.\n \n■The sample data are sorted (arranged in order).\nFIGURE 2-6 Dotplot of Pulse Rates of Males\nEXAMPLE 1  Dotplot of Pulse Rates of Males\nFigure 2-6 shows a dotplot of the pulse rates (beats per minute) of males from Data \nSet 1 “Body Data” in Appendix B. The two stacked dots above the position at 50 in-\ndicate that two of the pulse rates are 50. (In this dotplot, the horizontal scale allows \neven numbers only, but the original pulse rates are all even numbers.)\nEXAMPLE 2  Stemplot of Male Pulse Rates\nThe following stemplot displays the pulse rates of the males in Data Set 1 “Body \nData” in Appendix B. The lowest pulse rate of 40 is separated into the stem of 4 and \nthe leaf of 0. The stems and leaves are arranged in increasing order, not the order in \nwhich they occur in the original list. If you turn the stemplot on its side, you can see \nthe distribution of the IQ scores in the same way you would see it in a histogram or \ndotplot.\nPulse rates are 40 and 42\nPulse rates are 90, 92, 94, 96, 96\nTime-Series Graph\nA time-series graph is a graph of time-series data, which are quantitative data that \nhave been collected at different points in time, such as monthly or yearly. An advan-\ntage of a time-series graph is that it reveals information about trends over time.\nFeatures of a Time-series Graph\n \n■Reveals information about trends over time\n\n58 \nCHAPTER 2 Exploring Data with Tables and Graphs\nBar Graphs\nA bar graph uses bars of equal width to show frequencies of categories of categori-\ncal (or qualitative) data. The bars may or may not be separated by small gaps.\nFeature of a Bar Graph\n \n■Shows the relative distribution of categorical data so that it is easier to compare \nthe different categories\nPareto Charts\nA Pareto chart is a bar graph for categorical data, with the added stipulation that the \nbars are arranged in descending order according to frequencies, so the bars decrease \nin height from left to right.\nFeatures of a Pareto Chart\n \n■Shows the relative distribution of categorical data so that it is easier to compare \nthe different categories\n \n■Draws attention to the more important categories\nFIGURE 2-7  Time-Series Graph of Law  \nEnforcement Fatalities\nEXAMPLE 3   Time-Series Graph of Fatalities of Law  \nEnforcement Officers\nThe time-series graph shown in Figure 2-7 depicts the yearly number of fatalities \nof law enforcement officers in the United States. See that a spike occurred in 2001, \nthe year of the September 11, 2001 terrorist attacks. Except for the data from 2001, \nthere appears to be a slight downward trend.\nEXAMPLE 4  Pareto Chart of Causes of Accidental Deaths\nFor the accidental deaths in a recent year, Figure 2-8 shows the most common \ncauses. We can see that deaths from poison represent the most serious problem. \n(Deaths from poison include deaths from drug overdoses.)\nThe Power of a Graph\nWith annual \nsales around \n$13 billion and \nwith roughly \n50 million \npeople using \nit, Pfizer’s \nprescription drug Lipitor (ator-\nvastatin) has become the most \nprofitable and most widely used \nprescription drug ever marketed. \nIn the early stages of its develop-\nment, Lipitor was compared to \nother drugs (Zocor [simvastatin], \nMevacor [lovastatin], Lescol \n[fluvastatin], and Pravachol \npravastatin) in a process that \ninvolved controlled trials. The \nsummary report included a graph \nshowing a Lipitor curve that had \na steeper rise than the curves for \nthe other drugs, visually showing \nthat Lipitor was more effective \nin reducing cholesterol than the \nother drugs. Pat Kelly, who was \nthen a senior marketing execu-\ntive for Pfizer, said, “I will never \nforget seeing that chart…. It was \nlike ‘Aha!’ Now I know what this \nis about. We can communicate \nthis!” The Food and Drug Admin-\nistration approved Lipitor and al-\nlowed Pfizer to include the graph \nwith each prescription. Pfizer \nsales personnel also distributed \nthe graph to physicians.\n\n2-3 Graphs That Enlighten and Graphs That Deceive \n59\nPie Charts\nA pie chart is a very common graph that depicts categorical data as slices of a circle, \nin which the size of each slice is proportional to the frequency count for the category. \nAlthough pie charts are very common, they are not as effective as Pareto charts.\nFeature of a Pie Chart\n \n■Shows the distribution of categorical data in a commonly used format\nFIGURE 2-8  Pareto Chart of Causes of \n Accidental Deaths\nEXAMPLE 5  Pie Chart of Causes of Accidental Deaths\nFigure 2-9 is a pie chart of the same cause of death data from Example 4. Construc-\ntion of a pie chart involves slicing up the circle into the proper proportions that rep-\nresent relative frequencies. For example, the category poison accounts for 34% of \nthe total, so the slice representing poison should be 34% of the total (with a central \nangle of 0.34 * 360° = 122°).\nFIGURE 2-9  Pie Chart of Causes of \nAccidental Deaths\nThe Pareto chart in Figure 2-8 and the pie chart in Figure 2-9 depict the same data in \ndifferent ways, but the Pareto chart does a better job of showing the relative sizes of the \ndifferent components. Graphics expert Edwin Tufte makes the following suggestion:\nNever use pie charts because they waste ink on components that are not \ndata, and they lack an appropriate scale.\n\n60 \nCHAPTER 2 Exploring Data with Tables and Graphs\nFrequency Polygon\nA frequency polygon uses line segments connected to points located directly above \nclass midpoint values. A frequency polygon is very similar to a histogram, but a fre-\nquency polygon uses line segments instead of bars.\nA variation of the basic frequency polygon is the relative frequency polygon, \nwhich uses relative frequencies (proportions or percentages) for the vertical scale. An \nadvantage of relative frequency polygons is that two or more of them can be combined \non a single graph for easy comparison, as in Figure 2-11.\nFIGURE 2-10  Frequency Polygon of Full IQ \nScores of Low Lead Group\nEXAMPLE 6   Frequency Polygon of Full IQ Scores of  \nLow Lead Group\nSee Figure 2-10 for the frequency polygon corresponding to the full IQ scores of the \nlow lead group summarized in the frequency distribution of Table 2-2 on page 42 \n(from Data Set 8 in Appendix B). The heights of the points correspond to the class \nfrequencies, and the line segments are extended to the right and left so that the graph \nbegins and ends on the horizontal axis. The points are plotted directly above class \nmidpoint values.\nEXAMPLE 7   Relative Frequency Polygon: IQ Scores  \nof Lead Groups\nFigure 2-11 shows the relative frequency polygons for the full IQ scores of two \ngroups: (1) group with low blood lead levels; (2) group with high blood lead levels. \nHere, relative frequency polygons are much better than frequency polygons because \nthe different sample sizes of 21 and 78 would have made a comparison difficult, but \nthat difficulty is removed by using relative percentages.\nFigure 2-11 shows that the group with high blood lead levels has full IQ scores \nthat are somewhat lower than those in the low blood level group. This suggests that \nexposure to lead has an effect on IQ scores. Later chapters will provide us with \nmore tools that allow us to examine this issue beyond the subjective interpretation \nof a graph.\nF\nA\nc\nq\nFlorence Nightingale\nFlorence \nNightingale \n(1820–1910) \nis known to \nmany as the \nfounder of \nthe nursing \nprofession, but she also saved \nthousands of lives by using \nstatistics. When she encountered \nan unsanitary and undersup-\nplied hospital, she improved \nthose conditions and then used \nstatistics to convince others of \nthe need for more widespread \nmedical reform. She developed \noriginal graphs to illustrate that \nduring the Crimean War, more \nsoldiers died as a result of \nunsanitary conditions than were \nkilled in combat. Florence Night-\ningale pioneered the use of social \nstatistics as well as graphics \ntechniques.\n\n2-3 Graphs That Enlighten and Graphs That Deceive \n61\nGraphs That Deceive\nDeceptive graphs are commonly used to mislead people, and we really don’t want \nstatistics students to be among those susceptible to such deceptions. Graphs should be \nconstructed in a way that is fair and objective. The readers should be allowed to make \ntheir own judgments, instead of being manipulated by misleading graphs. We present \ntwo of the ways in which graphs are commonly used to misrepresent data.\nNonzero Vertical Axis\nA common deceptive graph involves using a vertical scale that starts at some value \ngreater than zero to exaggerate differences between groups.\nFIGURE 2-11  Relative Frequency Polygons for Full IQ \nScores of High and Low Lead Groups\nNONZERO AXIS: Always examine a graph carefully to see whether a vertical axis \nbegins at some point other than zero so that differences are exaggerated.\nEXAMPLE 8  Nonzero Axis\nFigure 2-12(a) and Figure 2-12(b) are based on the same data from a clinical trial of \nOxyContin (oxycodone), a drug used to treat moderate to severe pain. The results of \nthat clinical trial included the percentage of subjects who experienced nausea in an \nOxyContin treatment group and the percentage in a group given a placebo.\n \nFIGURE 2-12 Nausea in a Clinical Trial\n(a)\n(b)\ncontinued\n\n62 \nCHAPTER 2 Exploring Data with Tables and Graphs\nPictographs\nDrawings of objects, called pictographs, are often misleading. Data that are one-\ndimensional in nature (such as budget amounts) are often depicted with two-dimensional \nobjects (such as dollar bills) or three-dimensional objects (such as stacks of coins, \nhomes, or barrels). With pictographs, artists can create false impressions that grossly \ndistort differences by using these simple principles of basic geometry: (1) When you \ndouble each side of a square, its area doesn’t merely double; it increases by a factor \nof four. (2) When you double each side of a cube, its volume doesn’t merely double; \nit increases by a factor of eight.\nBy using a vertical scale that starts at 10% instead of 0%, Figure 2-12(a) \ngrossly exaggerates the difference between the two groups. Figure 2-12(a) makes it \nappear that those using OxyContin experience nausea at a rate that is about 12 times \nhigher than the rate for those using a placebo, but Figure 2-12(b) shows that the true \nratio is about 2:1, not 12:1. Perhaps someone wants to discourage recreational use \nof OxyContin by misleading people into thinking that the problem with nausea is \nmuch greater than it really is. The objective might be sincere, but the use of a mis-\nleading graph is not the way to achieve that objective.\nPICTOGRAPHS: When examining data depicted with a pictograph, determine \nwhether the graph is misleading because objects of area or volume are used to \ndepict amounts that are actually one-dimensional. (Histograms and bar charts \nrepresent one-dimensional data with two-dimensional bars, but they use bars with \nthe same width so that the graph is not misleading.)\nEXAMPLE 9  Pictograph of Cigarette Smokers\nRefer to Figure 2-13 and see that the larger cigarette is about twice as long, twice as \ntall, and twice as deep as the smaller cigarette, so the volume of the larger cigarette \nis about eight times the volume of the smaller cigarette. (The data are from the Cen-\nters for Disease Control and Prevention.) The larger cigarette appears to be eight \ntimes as large as the smaller cigarette, but the actual percentages show that the 37% \nsmoking rate in 1970 is about twice that of the 18% rate in 2013.\n \nFIGURE 2-13 Smoking by U.S. Adults\n1970: 37% of U.S. adults smoked.       2013: 18% of U.S. adults smoked.\n\n2-3 Graphs That Enlighten and Graphs That Deceive \n63\nConcluding Thoughts\nIn addition to the graphs we have discussed in this section, there are many other useful \ngraphs—some of which have not yet been created. The world desperately needs more \npeople who can create original graphs that enlighten us about the nature of data. In \nThe Visual Display of Quantitative Information, Edward Tufte offers these principles:\n \n■For small data sets of 20 values or fewer, use a table instead of a graph.\n \n■A graph of data should make us focus on the true nature of the data, not on other \nelements, such as eye-catching but distracting design features.\n \n■Do not distort data; construct a graph to reveal the true nature of the data.\n \n■Almost all of the ink in a graph should be used for the data, not for other design \nelements.\nGraphing Capabilities\nAccess tech instructions, videos, and data sets at www.TriolaStats.com\nTECH CENTER \nStatistical Literacy and Critical Thinking\n1. Body Temperatures Listed below are body temperatures (°F) of healthy adults. Why is it \nthat a graph of these data would not be very effective in helping us understand the data?\n98.6 98.6 98.0 98.0 99.0 98.4 98.4 98.4 98.4 98.6\n2. Voluntary Response Data If we have a large voluntary response sample consisting of \nweights of subjects who chose to respond to a survey posted on the Internet, can a graph help to \novercome the deficiency of having a voluntary response sample?\n3. Ethics There are data showing that smoking is detrimental to good health. Given that people \ncould be helped and lives could be saved by reducing smoking, is it ethical to graph the data in \na way that is misleading by exaggerating the health risks of smoking?\n4. CVDOT Section 2-1 introduced important characteristics of data summarized by the acro-\nnym CVDOT. What characteristics do those letters represent, and which graph does the best \njob of giving us insight into the last of those characteristics?\nDotplots. In Exercises 5 and 6, construct the dotplot.\n5. Pulse Rates Listed below are pulse rates (beats per minute) of females selected from Data \nSet 1 “Body Data” in Appendix B. All of those pulse rates are even numbers. Is there a pulse \nrate that appears to be an outlier? What is its value?\n80  94  58  66  56  82  78  86  88  56  36  66  84  76  78  64  66  78  60  64\n6. Diastolic Blood Pressure Listed below are diastolic blood pressure measurements \n(mm Hg) of females selected from Data Set 1 “Body Data” in Appendix B. All of the values are \neven numbers. Are there any outliers? If so, identify their values.\n62 70 72 88 70 66 68 70 82 74 90 62 70 76 90 86 60 78 82 78 84 76 60 64\nStemplots. In Exercises 7 and 8, construct the stemplot.\n7. Pulse Rates Refer to the data listed in Exercise 5. How are the data sorted in the stemplot?\n8. Diastolic Blood Pressure Refer to the data listed in Exercise 6. Identify the two values \nthat are closest to the middle when the data are sorted in order from lowest to highest. (These \nvalues are often used to find the median, which is defined in Section 3-1.)\n2-3 Basic Skills and Concepts\n\n64 \nCHAPTER 2 Exploring Data with Tables and Graphs\nTime-Series Graphs. In Exercises 9 and 10, construct the time-series graph.\n9. Triplets Listed below are the numbers of triplets born in the United States each year beginning \nwith 1995. Is there a trend?\n4551 5298 6148 6919 6742 6742 6885 6898 7110\n6750 6208 6118 5967 5877 5905 5153 5137 4598\n10. Drunk Driving Fatalities Listed below are annual fatality rates (per 100,000 population) \nfrom drunk driving. The first entry represents the year 1991. Is there a trend? Any explanation?\n6.3 5.5 5.3 5.1 5.1 5.1 4.8 4.6 4.6 4.7 4.7\n4.7 4.5 4.5 4.6 4.5 4.3 3.9 3.5 3.3 3.2 3.3\nPareto Charts. In Exercises 11 and 12 construct the Pareto chart.\n11. Journal Retractions In a study of retractions in biomedical journals, 436 were due to \nerror, 201 were due to plagiarism, 888 were due to fraud, 291 were duplications of publica-\ntions, and 287 had other causes (based on data from “Misconduct Accounts for the Majority \nof Retracted Scientific Publications,” by Fang, Steen, Casadevall, Proceedings of the National \nAcademy of Sciences of the United States of America, Vol. 110, No. 3). Among such retrac-\ntions, does misconduct (fraud, duplication, plagiarism) appear to be a major factor?\n12. Getting a Job In a survey, subjects seeking a job were asked to whom they send a thank-\nyou note after having a job interview. Results were as follows: 40 said only the person they \nspent the most time with, 40 said only the most senior-level person, 396 said everyone that they \nmet, 15 said the person that they had the best conversation with, and 10 said that they don’t \nsend thank-you notes (based on data from TheLadders.com). Comment on the results.\nPie Charts. In Exercises 13 and 14, construct the pie chart.\n13. Journal Retractions Use the data from Exercise 11 “Journal Retractions.”\n14. Getting a Job Use the data from Exercise 12 “Getting a Job.”\nFrequency Polygon. In Exercises 15 and 16, construct the frequency polygons.\n15. Pulse Rates of Males Use the frequency distribution for the pulse rates of males from \nExercise 13 in Section 2-1 on page 49 to construct a frequency polygon. Comment on the \nshape of the distribution.\n16. Pulse Rates of Females Use the frequency distribution for the pulse rates of females \nfrom Exercise 14 in Section 2-1 on page 49 to construct a frequency polygon. Comment on the \nshape of the distribution.\nDeceptive Graphs. In Exercises 17–18, identify how the graph is deceptive.\n17. Self-Driving Vehicles In a survey of adults, subjects were asked if they felt comfortable \nbeing in a self-driving vehicle. The accompanying graph depicts the results (based on data from \nTE Connectivity).\n\n2-4 Scatterplots, Correlation, and Regression \n65\n18. Cost of Giving Birth According to the Agency for Healthcare Research and Quality \nHealthcare Cost and Utilization Project, the typical cost of a C-section baby delivery is $4500, \nand the typical cost of a vaginal delivery is $2600. See the accompanying illustration.\nCost of C-Section Delivery: $4500\nCost of Vaginal Delivery: $2600\nKey Concept This section introduces the analysis of paired (or “bivariate”) sample \ndata, which are data from two different variables that are paired in some way, such \nas the variables of heights and weights from subjects. In Part 1 of this section we dis-\ncuss correlation and the role of a graph called a scatterplot. In Part 2 we provide an \nintroduction to the use of the linear correlation coefficient. In Part 3 we provide a very \nbrief discussion of linear regression, which involves the equation and graph of the \nstraight line that best fits the sample paired data.\nAll of the principles discussed in this section are discussed more fully in Chapter 10, \nbut this section serves as a quick introduction to some important concepts of correlation \nand regression. This section does not include details for executing manual calculations, \nand those calculations are rarely done. Instructions for using technology to obtain results \ncan be found at www.TriolaStats.com; refer to the instructions for Chapter 10.\nPART 1\n Scatterplot and Correlation \nOur objective in this section is to explore whether there is a correlation, or associa-\ntion, between two variables. We begin with basic definitions.\n2-4 \nScatterplots, Correlation, and Regression\nDEFINITIONS\nA correlation exists between two variables when the values of one variable are \nsomehow associated with the values of the other variable.\nA linear correlation exists between two variables when there is a correlation and \nthe plotted points of paired data result in a pattern that can be approximated by a \nstraight line.\nA scatterplot or scatter diagram is a plot of paired (x, y) quantitative data with a \nhorizontal x-axis and a vertical y-axis. The horizontal axis is used for the first vari-\nable (x), and the vertical axis is used for the second variable (y).\n\n66 \nCHAPTER 2 Exploring Data with Tables and Graphs\nA scatterplot can be used as a visual aid in determining whether there is a correlation \n(or relationship) between the two variables. (This issue is discussed at length when the \ntopic of correlation is considered in Section 10-1.)\nCAUTION: The presence of a correlation between two variables is not evidence \nthat one of the variables causes the other. We might find a correlation between beer \nconsumption and weight, but we cannot conclude from the statistical evidence that \ndrinking beer has a direct effect on weight.\nCorrelation does not imply causality!\nEXAMPLE 1  Correlation: Waist and Arm Circumference\nData Set 1 “Body Data” in Appendix B includes waist circumferences (cm) and arm \ncircumferences (cm) of randomly selected adult subjects. Figure 2-14 is a scatter-\nplot of the paired waist>arm measurements. The points show a pattern of increasing \nvalues from left to right. This pattern suggests that there is a correlation or relation-\nship between waist circumferences and arm circumferences.\nEXAMPLE 2  No Correlation: Weight and Pulse Rate\nData Set 1 “Body Data” in Appendix B includes weights (kg) and pulse rates (beats \nper minute) of randomly selected adult subjects. Figure 2-15 is a scatterplot of the \npaired weight>pulse rate measurements. The points in Figure 2-15 do not show any \nobvious pattern, and this lack of a pattern suggests that there is no correlation or re-\nlationship between weights and pulse rates.\nFIGURE 2-14  Waist and Arm Circumferences\nCorrelation: The distinct straight-line pattern of the plotted \npoints suggests that there is a correlation between waist \ncircumferences and arm circumference.\nFIGURE 2-15 Weights and Pulse Rates\nNo Correlation: The plotted points do not show a distinct \npattern, so it appears that there is no correlation between \nweights and pulse rates.\nThe preceding two examples involve making decisions about a correlation \nbased on subjective judgments of scatterplots, but Part 2 introduces the linear corre-\nlation coefficient as a numerical measure that can help us make such decisions more \nobjectively. Using paired data, we can calculate the value of the linear correlation \ncoefficient r.\n\n2-4 Scatterplots, Correlation, and Regression \n67\nPART 2\nLinear Correlation Coefficient r\nUsing paired data, we can calculate the value of the linear correlation coefficient r.\nDEFINITION\nThe linear correlation coefficient is denoted by r, and it measures the strength of \nthe linear association between two variables.\nThe value of a linear correlation coefficient r can be manually computed by applying \nFormula 10-1 or Formula 10-2 found in Section 10-1 on page 447, but in practice, r is \nalmost always found by using technology.\nUsing r for Determining Correlation\nThe computed value of the linear correlation coefficient is always between -1 and \n1. A value of exactly -1 or 1 implies that all of the data fall exactly on a line, which \nreflects a perfect correlation. If r is close to -1 or close to 1, there appears to be a \nstrong correlation, but if r is close to 0, there appears to be a weak or no linear cor-\nrelation. For the data depicted in the scatterplot of Figure 2-14, r = 0.802 (somewhat \nclose to 1), and the data in the scatterplot of Figure 2-15 result in r = 0.082 (pretty \nclose to 0). These descriptions of “close to” -1 or 1 or 0 are vague, but there are other \nobjective criteria discussed in Chapter 10. See the following example illustrating the \ninterpretation of the linear correlation coefficient r.\nTABLE 2-10 Shoe Print Lengths and Heights of Males\nShoe Print Length (cm)\n29.7\n29.7\n31.4\n31.8\n27.6\nHeight (cm)\n175.3\n177.8\n185.4\n175.3\n172.7\nEXAMPLE 3   Correlation Between Shoe Print  \nLengths and Heights?\nConsider the data in Table 2-10 (using data from Data Set 7 “Foot and Height” in \nAppendix B). From the accompanying scatterplot of the paired data in Table 2-10, it \nisn’t very clear whether there is a linear correlation. The Statdisk display of the results \nshows that the linear correlation coefficient has the value of r = 0.591 (rounded).\nPolice Deaths in Car \nChases\nUSA Today \ninvestigated \nthe annual \nreporting of \nthe numbers of \npolice who were \nkilled during \ncar chases. It was found that the \nFederal Bureau of Investigation \n(FBI) counted 24 deaths in the \npast 35 years, but other records \nshow that there were 371 deaths \nduring that time period. USA \nToday reporter Thomas Frank \nwrote that “the undercount is one \nof the most extreme examples of \nthe federal government’s inability \nto accurately track violent deaths \nand has led the FBI to minimize \nthe danger of police chasing \nmotorists.” Apparently, the FBI \nwas categorizing these deaths \nas automobile accidents instead \nof designating them as police \ndeaths that occurred during a car \nchase.\nStatdisk\n\n68 \nCHAPTER 2 Exploring Data with Tables and Graphs\nIn Example 3, we know from the Statdisk display that using the five pairs of data from \nTable 2-10, the linear correlation coefficient is computed to be r = 0.591. The value \nof r = 0.591 is not very close to 0 or 1, so based on that value and the displayed scat-\nterplot, it does not appear that there is a strong correlation between shoeprint lengths \nand heights of males.\nEXAMPLE 4   Correlation Between Shoe Print Lengths  \nand Heights?\nExample 3 used only five pairs of data from Data Set 7 “Foot and Height” in Appendix B. \nIf we use the shoe print lengths and heights from all of the 40 subjects listed in Data Set 7 \nin Appendix B, we get the scatterplot shown in Figure 2-16 and we get the Minitab results \nshown in the accompanying display. The scatterplot does show a distinct pattern instead of \nhaving points scattered about willy-nilly. Also, we see that the value of the linear correla-\ntion coefficient is r = 0.813. Because r = 0.813 is reasonably close to 1 and because of \nthe pattern of points in the scatterplot, it appears that there is a linear  correlation between \nshoe print lengths and heights.\nIn Example 3 with only five pairs of data, we did not have enough evidence to \nconclude that there is a linear correlation, but in this example with 40 pairs of data, it \ndoes appear that there is a linear correlation between shoe print lengths and heights.\nPART 3\n Regression \nWhen we do conclude that there appears to be a linear correlation between two vari-\nables (as in Example 4), we can find the equation of the straight line that best fits the \nsample data, and that equation can be used to predict the value of one variable when \ngiven a specific value of the other variable. Based on the results from Example 4, we \ncan predict someone’s height given the length of their shoe print (which may have \nbeen found at a crime scene).\nInstead of using the straight-line equation format of y = mx + b that we have all \nlearned in prior math courses, we use the format that follows.\nFIGURE 2-16 Scatterplot of 40 Pairs of Data\nMinitab\n\n2-4 Scatterplots, Correlation, and Regression \n69\nThe regression equation\nyn = b0 + b1x\nalgebraically describes the regression line.\nSection 10-2 gives a good reason for using the format of yn = b0 + b1x instead of \nthe format of y = mx + b. Section 10-2 also provides formulas that could be used to \nidentify the values of the y-intercept b0 and the slope b1, but those values are usually \nfound by using technology.\nDEFINITION\nGiven a collection of paired sample data, the regression line (or line of  best fit or \nleast-squares line) is the straight line that “best” fits the scatterplot of the data. (The \nspecific criterion for the “best”-fitting straight line is the “least squares” property \ndescribed in Section 10-2.)\nFIGURE 2-17 Regression Line\nEXAMPLE 5  Regression Line\nExample 4 included a scatterplot of the 40 pairs of shoe print lengths and heights \nfrom Data Set 7 “Foot and Height” in Appendix B. Figure 2-17 shown here is that \nsame scatterplot with the graph of the regression line included. Also shown is the \nStatdisk display from the 40 pairs of data.\nFrom the Statdisk display, we see that the general form of the regression equa-\ntion has a y-intercept of b0 = 80.9 (rounded) and slope b1 = 3.22 (rounded), so the \nequation of the regression line shown in Figure 2-17 is yn = 80.9 + 3.22x. It might \nbe helpful to express that equation more clearly by using the names of the variables:\nHeight = 80.9 + 3.22 1Shoe Print Length2\nNote that the equation shows the y-intercept of 80.9 that does not appear on the ver-\ntical scale in the graph. The leftmost vertical scale in Figure 2-19 is not the actual \ny-axis that passes through 0 on the x-axis. If the graph were extended to the left, the \nregression line would intercept the actual y-axis at the height of y = 80.9 cm.\nStatdisk\n\n70 \nCHAPTER 2 Exploring Data with Tables and Graphs\nStatistical Literacy and Critical Thinking\n1. Linear Correlation In this section we use r to denote the value of the linear correlation co-\nefficient. Why do we refer to this correlation coefficient as being linear?\n2. Causation A study has shown that there is a correlation between body weight and blood \npressure. Higher body weights are associated with higher blood pressure levels. Can we con-\nclude that gaining weight is a cause of increased blood pressure?\n3. Scatterplot What is a scatterplot and how does it help us?\n4. Estimating r For each of the following, estimate the value of the linear correlation coeffi-\ncient r for the given paired data obtained from 50 randomly selected adults.\na. Their heights are measured in inches (x) and those same heights are recorded in centimeters (y).\nb. Their IQ scores (x) are measured and their heights (y) are measured in centimeters.\nc. Their pulse rates (x) are measured and their IQ scores are measured (y).\nd. Their heights (x) are measured in centimeters and those same heights are listed again, but \nwith negative signs (y) preceding each of these second listings.\nScatterplot. In Exercises 5–8, use the sample data to construct a scatterplot. Use the first vari-\nable for the x-axis. Based on the scatterplot, what do you conclude about a linear correlation?\n5. Brain Volume and IQ The table lists brain volumes (cm3) and IQ scores of five males (from \nData Set 9 “IQ and Brain Size” in Appendix B).\nBrain volume (cm3)\n1173\n1067\n1347\n1029\n1204\nIQ\n 101\n  93\n  94\n  97\n 113\n6. Bear Measurements The table lists chest sizes (distance around chest in inches) and \nweights (pounds) of anesthetized bears that were measured (from Data Set 11 in Appendix B).\nChest (in.)\n26\n 45\n 54\n 49\n 35\n 41\n 41\nWeight (lb)\n80\n344\n416\n348\n166\n220\n262\n7. Body Temperatures The table lists body temperatures (°F) of seven healthy adults at 8 AM on \none day and at 8 AM  on the following day (from Data Set 2 “Body Temperatures” in Appendix B).\nDay 1  98.6  97.4  98.2  98.2  98.2  96.6  97.4\nDay 2  97.8  97.0  97.0  96.6  97.0  96.8  96.6\n8. Heights of Fathers and Sons The table lists heights (in.) of fathers and the heights (in.) of \ntheir first sons (from Francis Galton).\nHeight of father (in.)\n73.0\n75.5\n75.0\n75.0\n75.0\n74.0\n74.0\n73.0\n73.0\n78.5\nHeight of first son (in.)\n74.0\n73.5\n71.0\n70.5\n72.0\n76.5\n74.0\n71.0\n72.0\n73.2\nLinear Correlation Coefficient. In Exercises 9–12, the linear correlation coefficient r is \nprovided. What do you conclude about a linear correlation?\n9. Using the data from Exercise 5 “Brain Volume and IQ,” the linear correlation coefficient is \nr = 0.127.\n10. Using the data from Exercise 6 “Bear Measurements,” the linear correlation coefficient is \nr = 0.980.\n2-4 Basic Skills and Concepts\n\n11. Using the data from Exercise 7 “Body Temperatures,” the linear correlation coefficient is \nr = 0.520.\n12. Using the data from Exercise 8 “Heights of Fathers and Sons,” the linear correlation coef-\nficient is r = -0.017.\nChapter Quick Quiz\n1. BAC When constructing a table representing the frequency distribution of blood alcohol \ncontent (g>dL) of drunk drivers involved in fatal car crashes, the first two classes of a fre-\nquency distribution are 0.08 – 0.11 and 0.12 – 0.15. What is the class width?\n2. BAC Using the same first two classes from Exercise 1, identify the class boundaries of the \nfirst class.\n3. BAC The first class described in Exercise 1 has a frequency of 36. If you know only the class \nlimits given in Exercise 1 and the frequency of 36, can you identify the original 36 data values?\n4. BAC A stemplot is created from the ages of drunk drivers involved in fatal car crashes and \nthe first row is 1 | 67889. Identify the values represented by that row.\n5. Reaction Times A large sample is randomly selected from a normally distributed popula-\ntion of reaction times, and a histogram is constructed from a frequency distribution. What is the \nshape of the histogram?\n6. Tylenol In testing samples of regular Tylenol pills to verify that they have close to the de-\nsired amount of 325 mg of acetaminophen, which important characteristic of data is missing \nfrom this list: center, distribution, outliers, changes over time?\n7. Tylenol A quality control manager wants to monitor the production of regular Tylenol pills \nto be sure that the mean amount of acetaminophen does not change over time. Which of the fol-\nlowing graphs is most helpful for that purpose: histogram, Pareto chart, pie chart, scatterplot, \ntime-series graph, dotplot?\n8. Blood Pressure In an investigation of the relationship between systolic blood pressure and \ndiastolic blood pressure, which of the following graphs is most helpful: histogram; pie chart; \nscatterplot; stemplot; dotplot?\n9. Blood Pressure Thing The W. A. Baum Company manufactures sphygmomanometers \nused to measure blood pressure. Quality control managers at such companies monitor defects \nand identify various causes, including worn machinery, human error, bad supplies, and packag-\ning mistreatment. Which of the following graphs would be best for describing the causes of \ndefects: histogram, scatterplot, Pareto chart, dotplot, stemplot?\n10. Frequency Distribution and Histogram What is the basic difference between a fre-\nquency distribution and a histogram?\n1. Frequency Distribution of Body Temperatures Construct a frequency distribution of the \n20 body temperatures 1°F2 listed below. (These data are from Data Set 2 “Body Temperatures” \nin Appendix B.) Use a class width of 0.5°F and a starting value of 97.0°F.\n97.1 97.2 97.5 97.6 97.6 97.8 98.0 98.0 98.2 98.2\n98.2 98.3 98.4 98.6 98.6 98.7 98.7 98.9 99.1 99.4\nReview Exercises\nCHAPTER 2 Review Exercises \n71\n\n72 \nCHAPTER 2 Exploring Data with Tables and Graphs\n2. Histogram of Body Temperatures Construct the histogram that corresponds to the fre-\nquency distribution from Exercise 1. Use class midpoint values for the horizontal scale. Does \nthe histogram suggest that the data are from a population having a normal distribution? Why or \nwhy not?\n3. Dotplot of Body Temperatures Construct a dotplot of the body temperatures listed in \n Exercise 1. Which does a better job of illustrating the distribution of the data: the histogram \nfrom Exercise 2 or the dotplot?\n4. Stemplot of Body Temperatures Construct a stemplot of the body temperatures listed in \nExercise 1. Are there any outliers?\n5. Bears Listed below are the neck sizes (in.) and weights (lb) of bears (from Data Set 11 \n“Bear Measurements” in Appendix B). Construct a scatterplot. Based on the graph, does there \nappear to be a relationship between neck sizes and weights of bears?\nNeck Size (in.)   16   28   31   31.5   22   21   26.5    27   20   18\nWeight (lb)     80  344  416  348.0  166  220  262.0  360  204  144\n6. Monitoring Weight\na. After collecting the average (mean) weight of adult males in the United States for each of the \nmost recent 100 years, we want to construct the graph that is most appropriate for these data. \nWhich graph is best?\nb. After collecting the average (mean) weight and height of males for the most recent 100 years, \nwe want to construct a graph to investigate the association between those two variables. Which \ngraph is best?\nc. An investigation of health problems associated with overweight males includes heart dis-\nease, stroke, high blood pressure, diabetes, and breathing problems. If we want to construct a \ngraph that illustrates the relative importance of these adverse effects, which graph is best?\n7. Medical School Enrollees The accompanying graph illustrates male and female enrollees \nin U.S. medical schools in a recent year. What is wrong with the graph?\nCumulative Review Exercises\n1. Hygiene Listed below are times (minutes) spent on hygiene and grooming in the morning \nby randomly selected subjects (based on data from a Svenska Cellulosa Aktiebolaget survey). \nConstruct a table representing the frequency distribution. Use the classes 0–9, 10–19, and so on.\n0  5  12  15  15  20  22  24  25  25  25  27  27  28  30  30  35  35  40  45\n2. Hygiene Histogram Use the frequency distribution from Exercise 1 to construct a histo-\ngram. Use class midpoint values for the horizontal scale. Based on the result, do the data ap-\npear to be from a population with a normal distribution? Explain.\n3. Hygiene Stemplot Use the data from Exercise 1 to construct a stemplot.\n4. Analysis of Last Digits Use the data from Exercise 1 and construct a frequency distribution \nof the last digits of the grooming times. What does the result suggest about the grooming times?\n5. Hygiene Refer to the grooming times given in Exercise 1.\na. What is the level of measurement of those times? (nominal, ordinal, interval, ratio)\nb. Are the exact unrounded grooming times discrete data or continuous data?\nc. Are the grooming times categorical data?\nd. The average (mean) of the grooming times is 24.3 minutes. Is that value a statistic or a \n parameter?\n\n6. Mother, Daughter Heights Refer to the following list of heights of mothers and the heights \nof their first daughters (from Data Set 6 “Family Heights” in Appendix B). What issue would \nbe investigated with these data? Construct the best graph for investigating that issue. What does \nthat graph suggest?\nMother’s Height (in.)    67.0  66.5  64  64  58.5  68.0  62  66.5  65.0  64.5\nDaughter’s Height (in.)  69.2  65.5  68  67  66.5  70.5  68  66.7  68.7  66.5\nTechnology Project\nIt was stated in this chapter that the days of charming and primitive hand-drawn graphs are well \nbehind us, and technology now provides us with powerful tools for generating a wide variety of \ndifferent graphs. This project therefore serves as a good preparation for professional presenta-\ntions that will be inevitably made in the future.\nThe complete data sets in Appendix B can be downloaded from www.TriolaStats.com. \nThey can be opened by statistical software packages, such as Minitab, Excel, SPSS, and JMP. \nStatdisk already includes the data sets. Use a statistical software package to open Data Set 1 \n“Body Data.” Use this statistical software with the methods of this chapter to describe, explore, \nand compare the ages of males and females. Does there appear to be a difference? Reports \nof randomized clinical trials typically include “baseline characteristics” of the subjects in the \ndifferent groups so that we can see whether the groups are similar in ways that are important. \nBased on ages, do the males and females in Data Set 1 appear to be similar? (Later chapters \nwill present more formal methods for making such comparisons.)\nFROM DATA TO DECISION\nCar crash fatalities are tragic losses of lives and they are \ndevastating to the families involved. Listed below are the \nages of 100 randomly selected drivers who were killed in car \ncrashes. Also given is a frequency distribution of licensed \ndrivers by age (based on recent data from the Insurance Insti-\ntute for Highway Safety).\nAges (in years) of Drivers Killed in Car Crashes\n \nAge\nLicensed Drivers  \n(millions)\n41 43 38 31 57 29 65 18 42 47\n16–19\n 9.7\n69 50 22 60 30 30 34 18 18 42\n20–29\n33.6\n18 16 74 25 41 43 50 34 54 45\n30–39\n40.2\n32 20 50 36 27 59 19 23 57 74\n40–49\n40.3\n27 38 29 24 56 72 21 22 74 20\n50–59\n29.6\n43 34 38 62 39 45 56 70 68 75\n60–69\n18.3\n37 49 25 24 21 25 31 21 76 69\n70–79\n13.4\n28 62 69 26 22 62 64 24 56 70\n80–89\n 5.4\n21 52 32 30 38 73 35 52 38 29\n23 17 44 25 24 70 16 49 45 34\nAnalysis\nConvert the given frequency distribution to a relative fre-\nquency distribution, then create a relative frequency distri-\nbution using the 100 ages of drivers killed in car crashes. \nCompare the two relative frequency distributions. Which age \ncategories appear to have substantially greater proportions \nof fatalities than the proportions of licensed drivers? If you \nwere responsible for establishing the rates for auto insurance, \nwhich age categories would you select for higher rates? Con-\nstruct a graph that is effective in identifying age categories \nthat are more prone to fatal car crashes.\nCHAPTER 2 Technology Project \n73\n\n74 \nCHAPTER 2 Exploring Data with Tables and Graphs\nCooperative Group Activities\n1. In-class activity In class, each student should record two pulse rates by counting the \nnumber of heartbeats in 1 minute. The first pulse rate should be measured while the student \nis seated, and the second pulse rate should be measured while the student is standing. Us-\ning the pulse rates measured while seated, construct a frequency distribution and histogram \nfor the pulse rates of males, and then construct another frequency distribution and histo-\ngram for the pulse rates of females. Using the pulse rates measured while standing, construct \na frequency distribution and histogram for the pulse rates of males, and then construct another \nfrequency distribution and histogram for the pulse rates of females. Compare the results. Do \nmales and females appear to have different pulse rates? Do pulse rates measured while seated \nappear to be different from pulse rates measured while standing? Use an appropriate graph to \ndetermine whether there is a relationship between sitting pulse rate and standing pulse rate.\n2. In-class activity Given below are the ages of motorcyclists at the time they were fatally \ninjured in traffic accidents (based on data from the U.S. Department of Transportation). If your \nobjective is to dramatize the dangers of motorcycles for young people, which graph would be \nmost effective: histogram, Pareto chart, pie chart, dotplot, stemplot, frequency polygon, time-\nseries graph? Construct the graph that best meets that objective. Is it okay to deliberately distort \ndata if the objective is one such as saving lives of motorcyclists?\n17 38 27 14 18 34 16 42 28 24 40 20 23 31\n37 21 30 25 17 28 33 25 23 19 51 18 29\n3. Out-of-class activity In each group of three or four students, select one of the following \nitems and construct a graph that is effective in addressing the question:\na. Is there a difference between the body mass index (BMI) values for men and for women? \n(See Data Set 1 “Body Data” in Appendix B.)\nb. Is there a relationship between the heights of sons (or daughters) and the heights of their \nfathers (or mothers)? (See Data Set 6 “Family Heights” in Appendix B.)\n4. Out-of-class activity Search the Internet to find an example of a graph that is misleading. \nDescribe how the graph is misleading. Redraw the graph so that it depicts the information cor-\nrectly. If possible, please submit your graph to www.TriolaStats.com.\n5. Out-of-class activity Find Charles Joseph Minard’s graph describing Napoleon’s march to \nMoscow and back, and explain why Edward Tufte says that “it may well be the best graphic \never drawn.” (See The Visual Display of Quantitative Information by Edward Tufte, Graphics \nPress). Minard’s graph can be seen at www.TriolaStats.com under “Textbook Supplements.”\n6. Out-of-class activity In The Visual Display of Quantitative Information by Edward Tufte \n(Graphics Press), find the graph that appeared in American Education, and explain why Tufte \nsays that “this may well be the worst graphic ever to find its way into print.” The graph can be \nseen at www.TriolaStats.com under “Textbook Supplements.” Construct a graph that is effec-\ntive in depicting the same data.\n\n75\nCHAPTER \nPROBLEM\nData Set 1 “Body Data” in Appendix B includes pulse rates \nof men and women. The full data set contains measurements \nfrom 300 adults, and the first 5 cases are printed in Appendix B. \nFigure 3-1 shows dotplots of the pulse rates categorized ac-\ncording to gender. Close examination of Figure 3-1 reveals \nthat the pulse rates consist of even numbers only. This sug-\ngests that the pulse rates were measured for 30 seconds, \nand the result was doubled to provide a pulse rate in beats \nper minute. Examine Figure 3-1 closely to see that the pulse \nrates of males tend to be generally a little lower (farther to \nthe left) than the pulse rates of females. This observation \nsuggests a hypothesis: Males have lower pulse rates than \nfemales. A conclusion about such a hypothesis should not \nbe made on the basis of a graph alone. We should consider \nDo men and women have the same pulse rates?\nMeasures of Center\nMeasures of Variation\nMeasures of Relative \nStanding and Boxplots\n3-1\n3-2\n3-3\nDescribing, Exploring, \nand Comparing Data\n3 \n\n>>>\nwhether the sample data were collected with an appropriate \nmethod. We should also consider whether the apparent dif-\nference between male pulse rates and female pulse rates is \nactually a significant difference and not just a random chance \nanomaly.\nInstead of relying solely on subjective interpretations of a \ngraph like Figure 3-1, this chapter introduces measures that \nare essential to any study of statistics. This chapter introduces \nthe mean, median, standard deviation, and variance, which \nare among the most important statistics presented in this book, \nand they are among the most important statistics in the study \nof statistics. We will use these statistics for describing, explor-\ning, and comparing the measured pulse rates for males and \nfemales in Data Set 1 “Body Data.”\nCHAPTER OBJECTIVES\nCritical Thinking and Interpretation: Going Beyond Formulas and Arithmetic\nIn this modern biostatistics course, it isn’t so important to memorize formulas or manu-\nally do messy arithmetic. We can get results with a calculator or software so that we \ncan focus on making practical sense of results through critical thinking. Although this \nchapter includes detailed steps for important procedures, it isn’t always necessary to \nmaster those steps. It is, however, generally helpful to perform a few manual calcula-\ntions before using technology, so that understanding is enhanced.\nThe methods and tools presented in this chapter are often called methods of \ndescriptive statistics, because they summarize or describe relevant characteristics of \ndata. In later chapters we use inferential statistics to make inferences, or generaliza-\ntions, about populations. Here are the chapter objectives:\nMeasures of Center\n• Develop the ability to measure the center of data by finding the mean, median, \nmode, and midrange.\n• Determine whether an outlier has a substantial effect on the mean and median.\nMeasures of Variation\n• Develop the ability to measure variation in a set of sample data by finding values of \nthe range, variance, and standard deviation.\n3-1\n3-2\nFIGURE 3-1 Dotplot of Pulse Rates of Males and Females\n76 \nCHAPTER 3 Describing, Exploring, and Comparing Data\n\n3-1 Measures of Center \n77\nThere are different approaches for measuring the center, so we have different defi-\nnitions for those different approaches. We begin with the mean.\nMean\nThe mean (or arithmetic mean) is generally the most important of all numerical mea-\nsurements used to describe data, and it is what many people call an average.\nKey Concept The focus of this section is to obtain a value that measures the center of \na data set. We present measures of center, including mean and median. Our objective \nhere is not only to find the value of each measure of center, but also to interpret and \nmake sense of those values. Part 1 of this section includes core concepts that should \nbe understood before considering Part 2.\nPART 1\n Basic Concepts of Measures of Center \nIn Part 1 of this section, we introduce the mean, median, mode, and midrange as dif-\nferent measures of center. Measures of center are widely used to provide representa-\ntive values that “summarize” data sets.\n3-1 \nMeasures of Center\nDEFINITION\nA measure of center is a value at the center or middle of a data set.\nDEFINITION\nThe mean (or arithmetic mean) of a set of data is the measure of center found by \nadding all of the data values and dividing the total by the number of data values.\nImportant Properties of the Mean\n \n■Sample means drawn from the same population tend to vary less than other mea-\nsures of center.\n \n■The mean of a data set uses every data value.\n• Develop the ability to interpret values of the standard deviation by applying the \nrange rule of  thumb to determine whether a particular value is significantly low or \nsignificantly high.\nMeasures of Relative Standing and Boxplots\n• Develop the ability to compute a z score and use the result to determine whether a \ngiven value x is significantly low or significantly high.\n• Identify percentile values and quartile values from a set of data.\n• Develop the ability to construct a boxplot from a set of data.\n3-3\n• Develop the ability to interpret values of the standard deviation by applying the\nrange rule of  thumb to determine whether a particular value is significantly low or \nw\nsignificantly high.\nMeasures of Relative Standing and Boxplots\n• Develop the ability to compute a z score and use the result to determine whether a\nz z\ngiven value x is \nx\nsignificantly low or \nw\nsignificantly high.\n• Identify percentile\nrc\nr\nvalues and quartile values from a set of data.\n• Develop the ability to construct a boxplot from a set of data.\ncontinued\n\n78 \nCHAPTER 3 Describing, Exploring, and Comparing Data\nCalculation and Notation of the Mean\nThe definition of the mean can be expressed as Formula 3-1, in which the Greek letter \nΣ (uppercase sigma) indicates that the data values should be added, so Σ  x represents \nthe sum of all data values. The symbol n denotes the sample size, which is the number \nof data values.\nFORMULA 3-1\nMean = Σ  x\nn  d sum of all data values\nd number of data values\nIf the data are a sample from a population, the mean is denoted by x (pronounced \n“x-bar”); if the data are the entire population, the mean is denoted by m (lowercase \nGreek mu).\nDEFINITION\nA statistic is resistant if the presence of extreme values (outliers) does not cause it \nto change very much.\n \n■A disadvantage of the mean is that just one extreme value (outlier) can change \nthe value of the mean substantially. (Using the following definition, we say that \nthe mean is not resistant.)\nNOTATION Hint: Sample statistics are usually represented by English letters, \nsuch as x, and population parameters are usually represented by Greek letters, \nsuch as m.\nΣ \ndenotes the sum of a set of data values.\nx \nis the variable usually used to represent the individual data values.\nn \nrepresents the number of data values in a sample.\nN \nrepresents the number of data values in a population.\nx = Σ  x\nn  \nis the mean of a set of sample values.\nm = Σ  x\nN  \nis the mean of all values in a population.\nEXAMPLE 1  Mean\nData Set 1 “Body Data” in Appendix B includes measures of pulse rates. Find the \nmean of the first five pulse rates for males: 84, 74, 50, 60, 52 (all in beats per minute, \nor BPM).\nSOLUTION\nThe mean is computed by using Formula 3-1. First add the data values, then divide \nby the number of data values:\n x = Σx\nn\n= 84 + 74 + 50 + 60 + 52\n5\n= 320\n5\n = 64.0 BPM\nThe mean of the first five male pulse rates is 64.0 BPM.\n\n3-1 Measures of Center \n79\nMedian\nThe median can be thought of loosely as a “middle value” in the sense that about half \nof the values in a data set are less than the median and half are greater than the me-\ndian. The following definition is more precise.\nCAUTION Never use the term average when referring to a measure of center. \nThe word average is often used for the mean, but it is sometimes used for other \nmeasures of center. The term average is not used by statisticians, it is not used in \nprofessional journals, and it will not be used throughout the remainder of this book \nwhen referring to a specific measure of center.\nDEFINITION\nThe median of a data set is the measure of center that is the middle value when the \noriginal data values are arranged in order of increasing (or decreasing) magnitude.\nImportant Properties of the Median\n \n■The median does not change by large amounts when we include just a few ex-\ntreme values, so the median is a resistant measure of center.\n \n■The median does not directly use every data value. (For example, if the largest \nvalue is changed to a much larger value, the median does not change.)\nCalculation and Notation of the Median\nThe median of a sample is sometimes denoted by x∼ (pronounced “x-tilde”) or M or \nMed; there isn’t a commonly accepted notation and there isn’t a special symbol for \nthe median of a population. To find the median, first sort the values (arrange them in \norder), and then follow one of these two procedures:\n1. If the number of data values is odd, the median is the number located in the ex-\nact middle of the sorted list.\n2. If the number of data values is even, the median is found by computing the \nmean of the two middle numbers in the sorted list.\nEXAMPLE 2  Median with an Odd Number of Data Values\nFind the median of the first five pulse rates for males: 84, 74, 50, 60, 52 (all in \nBPM).\nSOLUTION\nFirst sort the data values by arranging them in ascending order, as shown below:\n50 52 60 74 84\nBecause there are 5 data values, the number of data values is an odd number (5), \nso the median is the number located in the exact middle of the sorted list, which is \n60.0 BPM. The median is therefore 60.0 BPM. Note that the median of 60.0 BPM \nis different from the mean of 64.0 BPM found in Example 1.\nWhat the Median Is Not\nHarvard  \nbiologist Ste-\nphen Jay Gould \nwrote, “The \nMedian Isn’t the \nMessage.” In \nit, he describes \nhow he learned that he had ab-\ndominal mesothelioma, a form of \ncancer. He went to the library to \nlearn more, and he was shocked \nto find that mesothelioma was \nincurable, with a median survival \ntime of only eight months after \nit was discovered. Gould wrote \nthis: “I suspect that most people, \nwithout training in statistics, \nwould read such a statement as \n‘I will probably be dead in eight \nmonths’ the very conclusion that \nmust be avoided, since it isn’t \nso, and since attitude (in fighting \nthe cancer) matters so much.” \nGould went on to carefully \ninterpret the value of the median. \nHe knew that his chance of liv-\ning longer than the median was \ngood because he was young, his \ncancer was diagnosed early, and \nhe would get the best medical \ntreatment. He also reasoned that \nsome could live much longer \nthan eight months, and he saw \nno reason why he could not be \nin that group. Armed with this \nthoughtful interpretation of the \nmedian and a strong positive \nattitude, Gould lived for 20 years \nafter his diagnosis. He died of \nanother cancer not related to the \nmesothelioma.\n\n80 \nCHAPTER 3 Describing, Exploring, and Comparing Data\nMode\nThe mode isn’t used much with quantitative data, but it’s the only measure of center \nthat can be used with qualitative data (consisting of names, labels, or categories only).\nEXAMPLE 3  Median with an Even Number of Data Values\nRepeat Example 2 after including the sixth pulse rate of 62 BPM. That is, find the \nmedian of these pulse rates: 84, 74, 50, 60, 52, 62 (all in BPM).\nSOLUTION\nFirst arrange the values in ascending order: 50, 52, 60, 62, 74, 84.\nBecause the number of data values is an even number (6), the median is found by \ncomputing the mean of the two middle numbers, which are 60 and 62.\nMedian = 60 + 62\n2\n= 122\n2\n= 61.0 BPM\nThe median is 61.0 BPM.\nDEFINITION\nThe mode of a data set is the value(s) that occurs with the greatest frequency.\nImportant Properties of the Mode\n \n■The mode can be found with qualitative data.\n \n■A data set can have no mode or one mode or multiple modes.\nFinding the Mode: A data set can have one mode, more than one mode, or no mode.\n \n■When two data values occur with the same greatest frequency, each one is a \nmode and the data set is said to be bimodal.\n \n■When more than two data values occur with the same greatest frequency, each is \na mode and the data set is said to be multimodal.\n \n■When no data value is repeated, we say that there is no mode.\nEXAMPLE 4  Mode\nFind the mode of these pulse rates (in BPM):\n58 58 58 58 60 60 62 64\nSOLUTION\nThe mode is 58 BPM, because it is the pulse rate occurring most often (four times).\nIn Example 4, the mode is a single value. Here are other possible circumstances:\nTwo modes:  The pulse rates (BPM) of 58, 58, 58, 60, 60, 60, 62, 64 have two \nmodes: 58 BPM and 60 BPM.\nNo mode: \n The pulse rates of 58, 60, 64, 68, 72 have no mode because no \nvalue is repeated.\n\n3-1 Measures of Center \n81\nMidrange\nAnother measure of center is the midrange.\nDEFINITION\nThe midrange of a data set is the measure of center that is the value midway be-\ntween the maximum and minimum values in the original data set. It is found by add-\ning the maximum data value to the minimum data value and then dividing the sum \nby 2, as in the following formula:\nMidrange = maximum data value + minimum data value\n2\nImportant Properties of the Midrange\n \n■Because the midrange uses only the maximum and minimum values, it is very \nsensitive to those extremes so the midrange is not resistant.\n \n■In practice, the midrange is rarely used, but it has three redeeming features:\n1. The midrange is very easy to compute.\n2. The midrange helps reinforce the very important point that there are several \ndifferent ways to define the center of a data set.\n3. The value of the midrange is sometimes used incorrectly for the median, so con-\nfusion can be reduced by clearly defining the midrange along with the median.\nEXAMPLE 5  Midrange\nFind the midrange of these five pulse rates for males used in Example 1: 84, 74, 50, \n60, 52 (BPM).\nSOLUTION\nThe midrange is found as follows:\n Midrange = maximum data value + minimum data value\n2\n = 84 + 50\n2\n= 67.0 BPM\nThe midrange is 67.0 BPM.\nRounding Measures of Center\nWhen calculating measures of center, we often need to round the result. We use the \nfollowing rule.\nROUND-OFF RULES FOR MEASURES OF CENTER:\n \n■For the mean, median, and midrange, carry one more decimal place than is \npresent in the original set of values.\n \n■For the mode, leave the value as is without rounding (because values of the \nmode are the same as some of the original data values).\n\n82 \nCHAPTER 3 Describing, Exploring, and Comparing Data\nWhen applying any rounding rules, round only the final answer, not intermedi-\nate values that occur during calculations. For example, the mean of 2, 3, and 5 is \n3.333333. . . , which is rounded to 3.3, which has one more decimal place than the origi-\nnal values of 2, 3, and 5. As another example, the mean of 80.4 and 80.6 is 80.50 (one \nmore decimal place than was used for the original values). Because the mode is one or \nmore of the original data values, we do not round values of the mode; we simply use \nthe same original values that are modes.\nCritical Thinking\nWe can always calculate measures of center from a sample of numbers, but we should \nalways think about whether it makes sense to do that. In Section 1-2 we noted that it \nmakes no sense to do numerical calculations with data at the nominal level of mea-\nsurement, because those data consist of names, labels, or categories only, so statistics \nsuch as the mean and median are meaningless for such data. We should also think \nabout the sampling method used to collect the data. If the sampling method is not \nsound, the statistics we obtain may be very misleading.\nEXAMPLE 6  Critical Thinking and Measures of Center\nEach of the following illustrates data for which the mean and median are not mean-\ningful statistics.\na. Zip codes of the hospitals in the United States. (The zip codes don’t measure \nor count anything. The numbers are just labels for geographic locations.)\n \nb. Ranks of selected medical schools: 2, 3, 7, 10, 14. (The ranks reﬂect an order-\ning, but they don’t measure or count anything.)\n \nc. Numbers on the jerseys of the starting defense for the Seattle Seahawks when \nthey won Super Bowl XLVIII: 31, 28, 41, 56, 25, 54, 69, 50, 91, 72, 29. (The \nnumbers on the football jerseys don’t measure or count anything; they are just \nsubstitutes for names.)\n \nd. Top 5 incomes of hospital chief executive oﬃcers. (Such “top 5” or “top 10” \nlists include data that are not at all representative of the larger population.)\n \ne. The 50 mean ages computed from the means in each of the 50 states. (If you \ncalculate the mean of those 50 values, the result is not the mean age of people \nin the entire United States. The population sizes of the 50 diﬀerent states must \nbe taken into account, as described in the weighted mean introduced in Part 2 \nof this section.)\nIn the spirit of describing, exploring, and comparing data, we provide Table 3-1, \nwhich summarizes the different measures of center for the 300 pulse rates referenced \nin the Chapter Problem. Figure 3-1 on page 76 suggests that males have lower pulse \nrates, and comparison of the means and medians in Table 3-1 also suggests that males \nhave lower pulse rates. The following chapters will describe other tools that can be \nused for an effective comparison.\n\n3-1 Measures of Center \n83\nPART 2\n Beyond the Basics of Measures of Center\nCalculating the Mean from a Frequency Distribution\nFormula 3-2 is the same calculation for the mean that was presented in Part 1, but it \nincorporates this approach: When working with data summarized in a frequency dis-\ntribution, we make calculations possible by pretending that all sample values in each \nclass are equal to the class midpoint. Formula 3-2 is not really a new concept; it is \nsimply a variation of Formula 3-1 for the mean.\nFORMULA 3-2 MEAN FROM A FREQUENCY DISTRIBUTION\nFirst multiply each frequency and\nclass midpoint; then add the products. \n T \nx = Σ 1f ·x2\nΣ f   1Result is an approximation2\n c \nSum of frequencies\n(equal to n)\nExample 7 illustrates the procedure for finding the mean from a frequency distribution.\nTABLE 3-1 Male and Female Pulse Rates\nMale\nFemale\nMean\n69.6\n  74.0\nMedian\n68.0\n  74.0\nMode\n    66\n72, 74, 82\nMidrange\n72.0\n  70.0\nEXAMPLE 7  Computing the Mean from a Frequency Distribution\nThe first two columns of Table 3-2 on the next page constitute a frequency distribution \nsummarizing the pulse rates from males in Data Set 1 “Body Data” from Appendix B. \nUse the frequency distribution in the first two columns to find the mean.\nSOLUTION\nRemember, when working with data summarized in a frequency distribution, we \nmake calculations possible by pretending that all sample values in each class are \nequal to the class midpoint. For example, see Table 3-2 and consider the first class \ninterval of 40–54 with a frequency of 15. We pretend that each of the 15 pulse rates \nis 47 (the class midpoint). With the pulse rate of 47 repeated 15 times, we have a \ntotal of 47 # 15 = 705, as shown in the last column of Table 3-2. We can then add \nthose results to find the sum of all sample values.\nThe bottom row of Table 3-2 shows the two components we need for the cal-\nculation of the mean (as in Formula 3-2): Σf = 153 and Σ1f # x2 =  10,611. We \ncalculate the mean using Formula 3-2 as follows:\nx = Σ1 f # x2\nΣf\n= 10,611\n153\n= 69.4 BPM\ncontinued\n\n84 \nCHAPTER 3 Describing, Exploring, and Comparing Data\nCalculating a Weighted Mean\nWhen different x data values are assigned different weights w, we can compute a \nweighted mean. Formula 3-3 can be used to compute the weighted mean.\nFORMULA 3-3\nWeighted mean: x = Σ(w # x)\nΣw\nFormula 3-3 tells us to first multiply each weight w by the corresponding value \nx, then to add the products, and then finally to divide that total by the sum of the \nweights, Σw.\nThe result of x = 69.4 BPM is an approximation because it is based on the use  \nof class midpoint values instead of the original list of pulse rates. The mean of \n69.6 BPM found by using all of the original pulse rates for males is a more accu-\nrate result.\nTABLE 3-2 Pulse Rates (BPM) of Males\nPulse Rate\nFrequency f\nClass Midpoint x\nf ~ x\n40–54\n15\n 47\n 705\n55–69\n63\n 62\n3906\n70–84\n62\n 77\n4774\n85–99\n11\n 92\n1012\n100–114\n 2\n107\n 214\nTotals:\n횺f =  153\n횺1f ~ x2 = 10,611\nEXAMPLE 8  Computing Grade-Point Average\nIn her first semester of college, a student of one of the authors took five courses. \nHer final grades along with the number of credits for each course were A (3 cred-\nits), A (4 credits), B (3 credits), C (3 credits), and F (1 credit). The grading system \nassigns quality points to letter grades as follows: A = 4; B = 3; C = 2; D = 1; \nF = 0. Compute her grade-point average.\nSOLUTION\nUse the numbers of credits as weights: w = 3, 4, 3, 3, 1. Replace the letter grades \nof A, A, B, C, and F with the corresponding quality points: x = 4, 4, 3, 2, and 0. \nWe now use Formula 3-3 as shown below. The result is a first-semester grade-point \naverage of 3.07. (In using the preceding round-off rule, the result should be rounded \nto 3.1, but it is common to round grade-point averages to two decimal places.)\n x = Σ1w # x2\nΣw\n = 13 * 42 + 14 * 42 + 13 * 32 + 13 * 22 + 11 * 02\n3 + 4 + 3 + 3 + 1\n = 43\n14 = 3.07\n\n3-1 Measures of Center \n85\nDescriptive Statistics\nAccess tech instructions, videos, and data sets at www.TriolaStats.com\nTECH CENTER \nStatistical Literacy and Critical Thinking \n1. Average A report includes a statement that the “average” Medical College Admission Test \n(MCAT) score of applicants to medical schools is 28.4. What is the role of the term average in \nstatistics? Should another term be used in place of average?\n2. What’s Wrong? The Centers for Disease Control and Prevention (CDC) publishes a list of \nsmoking rates in each state. If we add the 50 percentages and then divide by 50, we get 19.67%. \nIs the value of 19.67% the mean smoking rate for all of the United States? Why or why not?\n3. Measures of Center In what sense are the mean, median, mode, and midrange measures \nof “center”?\n4. Resistant Measures Here are five pulse rates (BPM) of females: 80, 94, 58, 66, 56. Find \nthe mean and median of these five values. Then find the mean and median after including a \nsixth value of 740, which is an outlier. (One of the female pulse rates is 74, but 740 is used here \nas an error resulting from an incorrect data entry.) Compare the two sets of results. How much \nwas the mean affected by the inclusion of the outlier? How much is the median affected by the \ninclusion of the outlier?\nCritical Thinking. Each of Exercises 5–16 involves some feature that is somewhat tricky. \nFind the (a) mean, (b) median, (c) mode, and (d) midrange, and then answer the given \nquestion.\n5. Charges for Births Data Set 3 “Births” in Appendix B includes total charges for births at \nfour hospitals in New York State, and the top 10 highest amounts (in dollars) are listed below. \nWhat do the results tell us about the population of all such charges?\n471,062 359,091 290,837 271,863 255,788\n247,477 232,782 197,912 183,271 155,857\n6. MCAT Score Listed below are mean MCAT scores listed in order by year, starting with the \nyear 2002. What important feature of the data is not revealed by any of the measures of center?\n27.0 26.8 27.1 27.3 27.4 27.7 28.1 27.9 28.3 28.2 28.3 28.4\n7. Football Player Numbers Listed below are the jersey numbers of 11 players randomly \nselected from the roster of the Seattle Seahawks when they won Super Bowl XLVIII. What do \nthe results tell us?\n89 91 55 7 20 99 25 81 19 82 60\n8. Football Player Weights Listed below are the weights in pounds of 11 players randomly \nselected from the roster of the Seattle Seahawks when they won Super Bowl XLVIII (the same \nplayers from the preceding exercise). Are the results likely to be representative of all National \nFootball League (NFL) players?\n189 254 235 225 190 305 195 202 190 252 305\n9.  Peas in a Pod Biologists conducted experiments to determine whether a deficiency \nof carbon dioxide in the soil affects the phenotypes of peas. Listed below are the pheno-\ntype codes, where 1 = smooth@yellow, 2 = smooth@green, 3 = wrinkled@yellow, and \n3-1 Basic Skills and Concepts\ncontinued\n\n86 \nCHAPTER 3 Describing, Exploring, and Comparing Data\n4 = wrinkled@green. Can the measures of center be obtained for these values? Do the results \nmake sense?\n2 1 1 1 1 1 1 4 1 2 2 1 2 3 3 2 3 1 3 1 3 1 3 2 2\n10. TV Prices A physician plans to buy a television for her large waiting room. Listed below \nare selling prices in dollars of TVs that are 60 inches or larger and rated as a “best buy” by \nConsumer Reports magazine. Are the resulting statistics representative of the population of all \nTVs that are 60 inches and larger? If you decide to buy one of these TVs, what statistic is most \nrelevant, other than the measures of central tendency?\n1800 1500 1200 1500 1400 1600 1500 950 1600 1150 1500 1750\n11. Cell Phone Radiation Listed below are the measured radiation absorption rates (in W>kg) \ncorresponding to these cell phones: iPhone 5S, BlackBerry Z30, Sanyo Vero, Optimus V, Droid \nRazr, Nokia N97, Samsung Vibrant, Sony Z750a, Kyocera Kona, LG G2, and Virgin Mobile \nSupreme. The data are from the Federal Communications Commission (FCC). The media often \nreport about the dangers of cell phone radiation as a cause of cancer. The FCC has a standard \nthat a cell phone absorption rate must be 1.6 W>kg or less. If you are planning to purchase a cell \nphone, are any of the measures of center the most important statistic? Is there another statistic \nthat is most relevant? If so, which one?\n1.18 1.41 1.49 1.04 1.45 0.74 0.89 1.42 1.45 0.51 1.38\n12. Caffeine in Soft Drinks Listed below are measured amounts of caffeine (mg per 12 oz \nof drink) obtained in one can from each of 20 brands (7-UP, A&W Root Beer, Cherry Coke, \n. . . , Tab). Are the statistics representative of the population of all cans of the same 20 brands \nconsumed by Americans?\n0 0 34 34 34 45 41 51 55 36 47 41 0 0 53 54 38 0 41 47\n13. Firefighter Fatalities Listed below are the numbers of heroic firefighters who lost their \nlives in the United States each year while fighting forest fires. The numbers are listed in order \nby year, starting with the year 2000. What important feature of the data is not revealed by any \nof the measures of center?\n20 18 23 30 20 12 24 9 25 15 8 11 15 34\n14. Foot Lengths Listed below are foot lengths in inches of randomly selected Army women \nmeasured in the 1988 Anthropometric Survey (ANSUR). Are the statistics representative of the \ncurrent population of all Army women?\n10.4 9.3 9.1 9.3 10.0 9.4 8.6 9.8 9.9 9.1 9.1\n15. Medical School Tuition Listed below in dollars are the annual costs of tuition at the 10 \nmost expensive private medical schools in the United States for a recent year (based on data \nfrom U.S. News & World Report). What does this “top 10” list tell us about those costs for the \npopulation of all U.S. private medical school tuitions?\n57,261 56,784 55,196 54,976 54,653 54,528 54,268 54,050 53,581 53,323\n16. California Smokers In the California Health Interview Survey, randomly selected adults \nare interviewed. One of the questions asks how many cigarettes are smoked per day, and results \nare listed below for 50 randomly selected respondents. How well do the results reflect the \nsmoking behavior of California adults?\n9\n10\n10\n20\n40\n50\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n3-1 Measures of Center \n87\nIn Exercises 17–20, find the mean and median for each of the two samples, then compare \nthe two sets of results.\n17.  Blood Pressure A sample of blood pressure measurements is taken from Data Set \n1 “Body Data” in Appendix B, and those values (mm Hg) are listed below. The values are \nmatched so that 10 subjects each have systolic and diastolic measurements. (Systolic is a mea-\nsure of the force of blood being pushed through arteries, but diastolic is a measure of blood \npressure when the heart is at rest between beats.) Are the measures of center the best statistics \nto use with these data? What else might be better?\nSystolic:\n118\n128\n158\n96\n156\n122\n116\n136\n126\n120\nDiastolic:\n 80\n 76\n 74\n52\n 90\n 88\n 58\n 64\n 72\n 82\n18. White>Red Blood Counts Listed below are white blood cell counts (1000 cells>mL) \nand red blood cell counts (million cells>mL) from different subjects (from Data Set 1 “Body \nData” in Appendix B). The values are matched so that each of the 12 subjects has a white blood \ncell count and a red blood cell count. Are the measures of center the best statistics to use with \nthese data? What else might be better?\nWhite:\n8.7\n4.9\n6.9\n7.5\n6.1\n5.7\n4.1\n8.1\n8.0\n5.6\n8.3\n6.9\nRed:\n4.8\n4.7\n4.5\n4.3\n5.0\n4.0\n4.7\n4.6\n4.1\n5.5\n4.4\n4.2\n19. White Blood Counts Listed below are white blood cell counts (1000 cells>mL) from \nmales and females (from Data Set 1 “Body Data” in Appendix B). Do they appear to be  different?\nFemale:\n8.7\n6.9\n8.1\n8.0\n6.9\n8.1\n6.4\n6.3\n10.9\n4.8\n5.9\n7.2\nMale:\n4.9\n7.5\n6.1\n5.7\n4.1\n5.6\n8.3\n5.1\n 9.5\n6.1\n5.7\n5.4\n20. Queues A Providence Hospital experiment involves two different waiting line configura-\ntions for patients arriving for admission. The waiting times (in seconds) are recorded with a \nsingle line configuration that feeds four stations and another configuration with individual lines \nat the four stations. Determine whether there is a difference between the two data sets that is \nnot apparent from a comparison of the measures of center. If so, what is it?\nSingle Line\n390\n396\n402\n408\n426\n438\n444\n462\n462\n462\nIndividual Lines\n252\n324\n348\n372\n402\n462\n462\n510\n558\n600\nLarge Data Sets from Appendix B. In Exercises 21–24, refer to the indicated data set in \nAppendix B. Use software or a calculator to find the means and medians.\n21. HDL Use the high-density lipoprotein (HDL) cholesterol measurements (mg>dL) from the \n300 subjects included in Data Set 1 “Body Data” in Appendix B. Identify the highest value. \nDoes it appear to be an outlier? Do the mean and median change much when that highest value \nis deleted?\n22. LDL Repeat the preceding exercise using the low-density lipoprotein (LDL) measurements \n(mg>dL).\n23. Body Temperatures Refer to Data Set 2 “Body Temperatures” in Appendix B and use \nthe body temperatures for 12:00 AM on day 2. Do the results support or contradict the common \nbelief that the mean body temperature is 98.6oF?\n24. Births Use the birth weights (grams) of the 400 babies listed in Data Set 3 “Births” in \n Appendix B. Examine the list of birth weights to make an observation about those numbers. \nHow does that observation affect the way that the results should be rounded?\n\n88 \nCHAPTER 3 Describing, Exploring, and Comparing Data\nIn Exercises 25 and 26, find the mean of the data summarized in the frequency distribution. \nAlso, compare the computed means to the actual means obtained by using the original list \nof data values, which are as follows: (Exercise 25) 224.3; (Exercise 26) 255.1.\n25. \nBlood Platelet \nCount of Males\n \nFrequency\n 0–99\n 1\n100–199\n51\n200–299\n90\n300–399\n10\n400–499\n 0\n500–599\n 0\n600–699\n 1\n26. \nBlood Platelet Count \nof Females\n \nFrequency\n100–199\n25\n200–299\n92\n300–399\n28\n400–499\n 0\n500–599\n 2\n27. Weighted Mean A student of one of the authors earned grades of A, C, B, A, and D. \nThose courses had these corresponding numbers of credit hours: 3, 3, 3, 4, and 1. The grad-\ning system assigns quality points to letter grades as follows: A = 4; B = 3; C = 2; D = 1;\nF = 0. Compute the grade-point average (GPA) and round the result with two decimal places. \nIf the dean’s list requires a GPA of 3.00 or greater, did this student make the dean’s list?\n28. Weighted Mean A student of one of the authors earned grades of 63, 91, 88, 84, and 79 \non her five regular statistics tests. She earned a grade of 86 on the final exam and 90 on her \nclass projects. Her combined homework grade was 70. The five regular tests count for 60% \nof the final grade, the final exam counts for 10%, the project counts for 15%, and homework \ncounts for 15%. What is her weighted mean grade? What letter grade did she earn (A, B, C, D, \nor F)? Assume that a mean of 90 or above is an A, a mean of 80 to 89 is a B, and so on.\n29. Degrees of Freedom Five pulse rates randomly selected from Data Set 1 “Body Data” in \nAppendix B have a mean of 78.0 beats per minute. Four of the pulse rates are 82, 78, 56, and 84.\na. Find the missing value.\nb. We need to create a list of n values that have a specific known mean. We are free to select \nany values we desire for some of the n values. How many of the n values can be freely assigned \nbefore the remaining values are determined? (The result is referred to as the number of degrees \nof freedom.)\n30. Censored Data Recently, five U.S. presidents were still alive and after their first inaugura-\ntion, they have lived 37 years, 25 years, 21 years, 13 years, and 5 years so far. We might use the \nvalues of 37+, 25+, 21+, 13+, and 5+, where the positive signs indicate that the actual value \nis equal to or greater than the current value. (These values are said to be censored at the current \ntime that this list was compiled.) If we ignore the presidents who took office because of an as-\nsassination or resignation and if we ignore the five presidents who are still alive, the mean of \nthe 33 remaining presidents is 15.0 years. What do we know about the mean if we include the \ncensored values of 37+, 25+, 21+, 13+, and 5+? Do the two results differ by much?\n31. Trimmed Mean Because the mean is very sensitive to extreme values, we say that it is \nnot a resistant measure of center. By deleting some low values and high values, the trimmed \nmean (or truncated mean) is more resistant. To find the 10% trimmed mean for a data set, first \narrange the data in order, next delete the bottom 10% of the values and delete the top 10% of \nthe values, and then calculate the mean of the remaining values. Use the LDL measurements \nof the 300 subjects from Data Set 1 “Body Data” in Appendix B. Compare the mean, the 10% \ntrimmed mean, and the 20% trimmed mean.\n3-1 Beyond the Basics\n\n3-2 Measures of Variation \n89\nPART 1\nBasic Concepts of Variation \nTo visualize the property of variation, see Figure 3-2, which illustrates pulse rates \n(beats per minute or BPM) for subjects given a treatment and subjects given a pla-\ncebo. (A high priority is placed on using real data, but these pulse rates are fabricated \nfor the purposes of making an important point here.) Verify this important observa-\ntion: The pulse rates in the treatment group (top dotplot) have more variation than \nthose in the placebo group (bottom dotplot). Both sets of pulse rates have the same \nmean of 70.2 BPM, they have the same median of 70.0 BPM, and they have the same \nmode of 70 BPM. Those measures of center do not “see” the difference in variation.\nTo keep our round-off rules as consistent and as simple as possible, we will round \nthe measures of variation using this rule:\nKey Concept Variation is the single most important topic in statistics, so this is the \nsingle most important section in this book. This section presents three important \nmeasures of variation: range, standard deviation, and variance. These statistics are \nnumbers, but our focus is not just computing those numbers but developing the abil-\nity to interpret and understand them. This section is not a study of arithmetic; it is \nabout understanding and interpreting measures of variation, especially the standard \ndeviation.\n3-2 \nMeasures of Variation\nSTUDY HINT: Part 1 of this section presents basic concepts of variation, and \nPart 2 presents additional concepts related to the standard deviation. Part 1 \nand Part 2 both include formulas for computation, but do not spend too much \ntime memorizing formulas or doing arithmetic calculations. Instead, focus on \nunderstanding and interpreting values of standard deviation.\nROUND-OFF RULE FOR MEASURES OF VARIATION When rounding the value \nof a measure of variation, carry one more decimal place than is present in the \noriginal set of data.\nFIGURE 3-2 Dotplots of Pulse Rates\n\n90 \nCHAPTER 3 Describing, Exploring, and Comparing Data\nRange\nLet’s begin with the range because it is quick and easy to compute, but it is not as im-\nportant as other measures of variation.\nDEFINITION\nThe range of a set of data values is the difference between the maximum data \nvalue and the minimum data value.\nRange =  1maximum data value2 − 1minimum data value2\nImportant Properties of the Range\n \n■The range uses only the maximum and the minimum data values, so it is very \nsensitive to extreme values. The range is not resistant.\n \n■Because the range uses only the maximum and minimum values, it does not take \nevery value into account and therefore does not truly reflect the variation among \nall of the data values.\nEXAMPLE 1  Range\nFind the range of the first five pulse rates for males from Data Set 1 “Body Data” in \nAppendix B: 84, 74, 50, 60, 52 (all in BPM).\nSOLUTION\nThe range is found by subtracting the lowest value from the largest value, so we get\nRange = 1maximum value2 - 1minimum value2 = 84 - 50 = 34.0 BPM\nThe range of 34.0 BPM is shown with one more decimal place than is present in the \noriginal data values.\nStandard Deviation of a Sample\nThe standard deviation is the measure of variation most commonly used in statistics.\nDEFINITION\nThe standard deviation of a set of sample values, denoted by s, is a measure  \nof how much data values deviate away from the mean. It is calculated by using  \nFormula 3-4 or 3-5. Formula 3-5 is just a different version of Formula 3-4; both for-\nmulas are algebraically the same.\nThe standard deviation found from sample data is a statistic denoted by s, but the stan-\ndard deviation found from population data is a parameter denoted by s. The formula \nfor s is slightly different with division by the population size N used instead of divi-\nsion by n - 1. The population standard deviation s will be discussed later.\nNotation\ns = sample standard deviation\ns = population standard deviation\nR\nL\np\nGot a Second?\nThe time unit \nof 1 second \nis defined \nto be “the \nduration of \n9,192,631,770 \nperiods of the \nradiation corresponding to the \ntransition between the two hy-\nperfine levels of the ground state \nof the cesium-133 atom.” That \ndefinition redefines time to be \nbased on the behavior of atoms \ninstead of the earth’s motion. It \nresults in accuracy of ±1 second \nin 10,000,000 years, which is the \nmost accurate measurement we \nuse. Because it is so accurate, the \nsecond is being used to define \nother quantities, such as the me-\nter. The meter was once defined \nas 1>10,000,000 of the distance \nalong the surface of the earth \nbetween the North Pole and the \nequator (passing through Paris). \nThe meter is now defined as the \nlength of the distance traveled by \nlight in a vacuum during a time \ninterval of 1>299,792,458 sec.\nWhen dealing with time mea-\nsurement devices, the traditional \nstandard deviation has been \nfound to be poor because of a \ntrend in which the mean changes \nover time. Instead, other special \nmeasures of variation are used, \nsuch as Allan variance, total vari-\nance, and TheoH.\nUnrelated to statistics but \nnonetheless interesting is the \nfact that ads for watches usually \nshow a watch with a time close \nto 10:10. That time allows the \nbrand name to be visible, and it \ncreates a subliminal image of a \nhappy face. The time of 10:10 \nhas been the industry standard \nsince the 1940s.\n\n3-2 Measures of Variation \n91\nFORMULA 3-4\ns = B\nΣ1x - x2 2\nn - 1\n sample standard deviation\nFORMULA 3-5\ns = B\nn1Σ  x22 - 1Σ  x2 2\nn1n - 12\n shortcut formula for sample standard\n  deviation (used by calculators and software)\nLater we give the reasoning behind these formulas, but for now we recommend \nthat you use Formula 3-4 for an example or two, and then learn how to find standard \ndeviation values using a calculator or software.\nImportant Properties of Standard Deviation\n \n■The standard deviation is a measure of how much data values deviate away from \nthe mean.\n \n■The value of the standard deviation s is never negative. It is zero only when all of \nthe data values are exactly the same.\n \n■Larger values of s indicate greater amounts of variation.\n \n■The standard deviation s can increase dramatically with one or more outliers.\n \n■The units of the standard deviation s (such as minutes, feet, pounds) are the same \nas the units of the original data values.\n \n■The sample standard deviation s is a biased estimator of the population standard \ndeviation s, which means that values of the sample standard deviation s do not \ncenter around the value of s. (This is explained in Part 2.)\nExample 2 illustrates a calculation using Formula 3-4 because that formula better \nillustrates that the standard deviation is based on deviations of sample values away \nfrom the mean.\nEXAMPLE 2  Calculating Standard Deviation with Formula 3-4\nUse Formula 3-4 to find the standard deviation of the first five pulse rates for males \nfrom Data Set 1 “Body Data” in Appendix B: 84, 74, 50, 60, 52 (all in BPM).\nSOLUTION\nThe left column of Table 3-3 on the next page summarizes the general procedure \nfor finding the standard deviation using Formula 3-4, and the right column illus-\ntrates that procedure using the sample values 84, 74, 50, 60, 52. The result shown \nin Table 3-3 is 14.6 BPM, which is rounded to one more decimal place than is \npresent in the original list of sample values. Also, the units for the standard devia-\ntion are the same as the units of the original data. Because the original data values \nare all in units of BPM, the standard deviation is 14.6 BPM.\nVariation in Faces\nResearchers \ncommented \nthat “if everyone \nlooked more or \nless the same, \nthere would be \ntotal chaos.” \nThey studied \nhuman body measurements and \nfound that facial traits varied \nmore than other body traits, \nand the greatest variation oc-\ncurred within the triangle formed \nby the eyes and mouth. They \nlearned that facial traits vary \nindependently of each other. For \nexample, there is no relationship \nbetween the distance between \nyour eyes and how big your \nmouth is. The researchers stated \nthat our facial variation played an \nimportant role in human evolu-\ntion. (See “Morphological and \nPopulation Genomic Evidence \nThat Human Faces Have Evolved \nto Signal Individual Identity,” by \nSheehan and Nachman, Nature \nCommunications, Vol. 5,  \nNo. 4800.)\n\n92 \nCHAPTER 3 Describing, Exploring, and Comparing Data\nTABLE 3-3\nGeneral Procedure for Finding Standard  \nDeviation with Formula 3-4\nSpecific Example Using These Sample  \nValues: 84, 74, 50, 60, 52\nStep 1: Compute the mean x.\nThe sum of 84, 74, 50, 60, 52 is 320; therefore:\n x = Σ  x\nn\n= 84 + 74 + 50 + 60 + 52\n5\n = 320\n5\n= 64.0\nStep 2: Subtract the mean from each individual \nsample value. [The result is a list of deviations \nof the form 1x - x2.]\nSubtract the mean of 64.0 from each sample \nvalue to get these deviations away from the \nmean: 20, 10, −14, −4, −12.\nStep 3: Square each of the deviations obtained \nfrom Step 2. [This produces numbers of the \nform 1x - x2 2.]\nThe squares of the deviations from Step 2 are: \n400, 100, 196, 16, 144.\nStep 4: Add all of the squares obtained from \nStep 3. The result is Σ1x - x2 2.\nThe sum of the squares from Step 3 is 856.\nStep 5: Divide the total from Step 4 by the num-\nber n - 1, which is 1 less than the total number \nof sample values present.\nWith n = 5 data values, n - 1 = 4, so we \ndivide 856 by 4 to get this result:\n856\n4\n= 214\nStep 6: Find the square root of the result of \nStep 5. The result is the standard deviation, \ndenoted by s.\nThe standard deviation is 2214 = 14.6287. \nRounding the result, we get s = 14.6 BPM.\nEXAMPLE 3  Calculating Standard Deviation with Formula 3-5\nUse Formula 3-5 to find the standard deviation of the first five pulse rates of males \nfrom Data Set 1 “Body Data”: 84, 74, 50, 60, 52.\nSOLUTION\nHere are the components needed in Formula 3-5.\nn = 5 (because there are 5 values in the sample)\nΣ  x = 320 (found by adding the original sample values)\nΣ  x2 = 21,336 (found by adding the squares of the sample values, as in\n842 + 742 + 502 + 602 + 522 = 21,336)\nUsing Formula 3-5, we get\ns = B\nn1Σ  x22 - 1Σ  x2 2\nn1n - 12\n= B\n5121,3362 - 13202 2\n515 - 12\n= B\n4280\n20\n= 14.6 BPM\nThe result of s = 14.6 BPM is the same as the result in Example 2.\nRange Rule of Thumb for Understanding Standard Deviation\nThe range rule of thumb is a crude but simple tool for understanding and interpreting \nstandard deviation. It is based on the principle that for many data sets, the vast major-\nity (such as 95%) of sample values lie within 2 standard deviations of the mean. We \ncould improve the accuracy of this rule by taking into account such factors as the size \nof the sample and the distribution, but here we sacrifice accuracy for the sake of sim-\nplicity. The concept of significance as given below will be enhanced in later chapters, \nespecially those that include the topic of hypothesis tests, which are also called tests \n\n3-2 Measures of Variation \n93\nof significance. The following range rule of thumb is based on the population mean m\nand the population standard deviation s, but for large and representative samples, we \ncould use x and s instead.\nRange Rule of Thumb for Identifying Significant Values\nSigniﬁcantly low values are m - 2s or lower.\nSignificantly high values are m + 2s or higher.\nValues not signiﬁcant: Between 1m - 2s2 and 1m + 2s2\nSee Figure 3-3, which illustrates the above criteria.\nValues not signiﬁcant\nSigniﬁcantly\nlow values\nSigniﬁcantly\nhigh values\nm\nm − 2s\nm + 2s\nFIGURE 3-3  Range Rule of Thumb for Identifying \nSignificant Values\nRange Rule of Thumb for Estimating a Value of the Standard Deviation s\nTo roughly estimate the standard deviation from a collection of known sample \ndata, use\ns ≈range\n4\nEXAMPLE 4  Range Rule of Thumb for Interpreting s\nUsing the 153 pulse rates of males listed in Data Set 1 “Body Data” in Appendix B, \nthe mean is x = 69.6 BPM and the standard deviation is s = 11.3 BPM. Use x and \ns as estimates of m and s, and use the range rule of thumb to find the limits separat-\ning values that are significantly low or significantly high. Then determine whether a \nmale pulse rate of 100 BPM is significantly high.\nSOLUTION\nWith a mean of 69.6 and a standard deviation of 11.3, we use the range rule of \nthumb to find values that are significantly low or significantly high as follows:\nSignificantly low values are 169.6 - 2 * 11.32 or lower, \nso significantly low values are 47.0 BPM or lower.\nSignificantly high values are 169.6 + 2 * 11.32 or higher, \nso significantly high values are 92.2 BPM or higher.\nValues not significant: Between 47.0 and 92.2 BPM\nINTERPRETATION\nBased on these results, we expect that typical pulse rates of males are between \n47.0 BPM and 92.2 BPM. Because the given value of 100 BPM falls above \n92.2 BPM, we consider it to be a significantly high pulse rate for a male.\n\n94 \nCHAPTER 3 Describing, Exploring, and Comparing Data\nStandard Deviation of a Population\nThe definition of standard deviation and Formulas 3-4 and 3-5 apply to the standard \ndeviation of sample data. A slightly different formula is used to calculate the standard \ndeviation s (lowercase sigma) of a population: Instead of dividing by n - 1, we di-\nvide by the population size N, as shown here:\nPopulation standard deviation s = B\nΣ1x - m2 2\nN\nBecause we generally deal with sample data, we will usually use Formula 3-4, in \nwhich we divide by n - 1. Many calculators give both the sample standard deviation \nand the population standard deviation, but they use a variety of different notations.\nEXAMPLE 5  Range Rule of Thumb for Estimating s\nUse the range rule of thumb to estimate the standard deviation of the sample of \n153 pulse rates of males listed in Data Set 1 “Body Data” in Appendix B. Those \n153 values have a minimum of 40 BPM and a maximum of 104 BPM.\nSOLUTION\nThe range rule of thumb indicates that we can estimate the standard deviation by \nfinding the range and dividing it by 4. With a minimum of 40 BPM and a maximum \nof 104 BPM, the range rule of thumb can be used to estimate the standard deviation \ns as follows:\ns ≈range\n4\n= 104 - 40\n4\n= 16.0 BPM\nINTERPRETATION\nThe actual value of the standard deviation is s = 11.3 BPM, so the estimate of \n16.0 BPM is very roughly in the general neighborhood of the exact result. Because \nthis estimate is based on only the minimum and maximum values, it might be off by \na considerable amount.\nCAUTION When using a calculator to find standard deviation, identify the notation \nused by your particular calculator so that you get the sample standard deviation, \nnot the population standard deviation.\nVariance of a Sample and a Population\nSo far, we have used the term variation as a general description of the amount that val-\nues vary among themselves. (The terms dispersion and spread are sometimes used in-\nstead of variation.) Unlike the term variation, the term variance has a specific meaning.\nDEFINITION\nThe variance of a set of values is a measure of variation equal to the square of the \nstandard deviation.\n•  Sample variance: s2 =  square of the standard deviation s.\n•  Population variance: s2 =  square of the population standard deviation s.\n\n3-2 Measures of Variation \n95\nNotation Here is a summary of notation for the standard deviation and variance:\ns = sample standard deviation\ns2 = sample variance\ns = population standard deviation\ns2 = population variance\nNote: Articles in professional journals and reports often use SD for standard deviation \nand VAR for variance.\nImportant Properties of Variance\n \n■The units of the variance are the squares of the units of the original data values. \n(If the original data values are in feet, the variance will have units of ft2; if the \noriginal data values are in seconds, the variance will have units of  sec2.)\n \n■The value of the variance can increase dramatically with the inclusion of outliers. \n(The variance is not resistant.)\n \n■The value of the variance is never negative. It is zero only when all of the data \nvalues are the same number.\n \n■The sample variance s2 is an unbiased estimator of the population variance s2, \nas described in Part 2 of this section. (The sample standard deviation s is a biased \nestimator of the population standard deviation s.)\nThe variance is a statistic used in some statistical methods, but for our present pur-\nposes, the variance has the serious disadvantage of using units that are different than \nthe units of the original data set. This makes it difficult to understand variance as it \nrelates to the original data set. Because of this property, it is better to first focus on the \nstandard deviation when trying to develop an understanding of variation.\nPART 2\nBeyond the Basics of Variation\nIn Part 2, we focus on making sense of the standard deviation so that it is not some \nmysterious number devoid of any practical significance. We begin by addressing com-\nmon questions that relate to the standard deviation.\nWhy Is Standard Deviation Defined as in Formula 3-4?\nIn measuring variation in a set of sample data, it makes sense to begin with the indi-\nvidual amounts by which values deviate from the mean. For a particular data value x, \nthe amount of deviation is x - x. It makes sense to somehow combine those devia-\ntions into one number that can serve as a measure of the variation. Adding the devia-\ntions isn’t good, because the sum will always be zero. To get a statistic that measures \nvariation, it’s necessary to avoid the canceling out of negative and positive numbers. \nOne approach is to add absolute values, as in Σ\u001ax - x \u001a. If we find the mean of that \nsum, we get the mean absolute deviation (or MAD), which is the mean distance of \nthe data from the mean:\nMean absolute deviation = Σ\u001ax - x \u001a\nn\nWhy Not Use the Mean Absolute Deviation Instead of the Standard \nDeviation? Computation of the mean absolute deviation uses absolute values, \nso it uses an operation that is not “algebraic.” (The algebraic operations include \n\n96 \nCHAPTER 3 Describing, Exploring, and Comparing Data\naddition, multiplication, extracting roots, and raising to powers that are integers \nor fractions.) The use of absolute values would be simple, but it would create \nalgebraic difficulties in inferential methods of statistics discussed in later chap-\nters. The standard deviation has the advantage of using only algebraic opera-\ntions. Because it is based on the square root of a sum of squares, the standard \ndeviation closely parallels distance formulas found in algebra. There are many \ninstances where a statistical procedure is based on a similar sum of squares. \nConsequently, instead of using absolute values, we square all deviations 1x - x2\nso that they are nonnegative, and those squares are used to calculate the standard \ndeviation.\nWhy Divide by n −1? After finding all of the individual values of 1x - x2 2 we \ncombine them by finding their sum. We then divide by n - 1 because there are only \nn - 1 values that can assigned without constraint. With a given mean, we can use any \nnumbers for the first n - 1 values, but the last value will then be automatically deter-\nmined. With division by n - 1, sample variances s2 tend to center around the value of \nthe population variance s2; with division by n, sample variances s2 tend to underesti-\nmate the value of the population variance s2.\nComparing Variation in Different Samples or Populations\nIt’s a good practice to compare two sample standard deviations only when the sample \nmeans are approximately the same. When comparing variation in samples or popula-\ntions with very different means, it is better to use the coefficient of variation. Also use \nthe coefficient of variation to compare variation from two samples or populations with \ndifferent scales or units of values, such as the comparison of variation of pulse rates of \nmen and heights of men. (See Example 6.)\nDEFINITION\nThe coefficient of variation (or CV) for a set of nonnegative sample or popula-\ntion data, expressed as a percent, describes the standard deviation relative to the \nmean, and is given by the following:\n \nSample \nPopulation\n \nCV = s\nx # 100% \nCV = s\nm # 100%\nROUND-OFF RULE FOR THE COEFFICIENT OF VARIATION Round the \ncoefficient of variation to one decimal place (such as 25.3%).\nEXAMPLE 6  Pulse Rates and Heights\nCompare the variation of the 153 male pulse rates listed in Data Set 1 “Body \nData” in Appendix B and the heights of the same males. For the male pulse \nrates, x = 69.6 BPM and s = 11.3 BPM; for their heights, x = 174.12 cm and \ns = 7.10 cm. Note that we want to compare variation among pulse rates to varia-\ntion among heights.\n\n3-2 Measures of Variation \n97\nBiased and Unbiased Estimators\nThe sample standard deviation s is a biased estimator of the population standard de-\nviation s, which means that values of the sample standard deviation s do not tend \nto center around the value of the population standard deviation s. While individual \nvalues of s could equal or exceed s, values of s generally tend to underestimate the \nvalue of s. For example, consider an IQ test designed so that the population standard \ndeviation is 15. If you repeat the process of randomly selecting 100 subjects, giving \nthem IQ tests, and calculating the sample standard deviation s in each case, the sample \nstandard deviations that you get will tend to be less than 15, which is the population \nstandard deviation. There is no correction that allows us to fix the bias for all distribu-\ntions of data. There is a correction that allows us to fix the bias for normally distrib-\nuted populations, but it is rarely used because it is too complex and makes relatively \nminor corrections.\nThe sample variance s2 is an unbiased estimator of the population variance s2,\nwhich means that values of s2 tend to center around the value of s2 instead of system-\natically tending to overestimate or underestimate s2. Consider an IQ test designed so \nthat the population variance is 225. If you repeat the process of randomly selecting \n100 subjects, giving them IQ tests, and calculating the sample variance s2 in each \ncase, the sample variances that you obtain will tend to center around 225, which is the \npopulation variance.\nBiased estimators and unbiased estimators will be discussed more in Section 6-3.\nSOLUTION\nWe can compare the standard deviations if the same scales and units are used and \nthe two means are approximately equal, but here we have different scales and differ-\nent units of measurement, so we use the coefficients of variation:\n Male Pulse Rates:   CV = s\nx # 100% = 11.3 BPM\n69.6 BPM # 100% = 16.2%\n Male Heights:  \n CV = s\nx # 100% =\n7.10 cm\n174.12 cm # 100% = 4.1%\nWe can now see that the male pulse rates (with CV = 16.2%) vary more than male \nheights (with CV = 4.1%).\nMeasures of Variation\nAccess tech instructions, videos, and data sets at www.TriolaStats.com\nTECH CENTER \nStatistical Literacy and Critical Thinking \n1. Range Rule of Thumb for Estimating s The 20 brain volumes (cm3) from Data Set 9 \n“IQ and Brain Size” in Appendix B vary from a low of 963 cm3 to a high of 1439 cm3. Use \nthe range rule of thumb to estimate the standard deviation s and compare the result to the exact \nstandard deviation of 124.9 cm3.\n3-2 Basic Skills and Concepts\n\n98 \nCHAPTER 3 Describing, Exploring, and Comparing Data\n2. Range Rule of Thumb for Interpreting s The 20 brain volumes (cm3) from Data Set 9 \n“IQ and Brain Size” in Appendix B have a mean of 1126.0 cm3 and a standard deviation of \n124.9 cm3. Use the range rule of thumb to identify the limits separating values that are signifi-\ncantly low or significantly high. For such data, would a brain volume of 1440 cm3 be signifi-\ncantly high?\n3.  Variance The 20 subjects used in Data Set 9 “IQ and Brain Size” in Appendix B have \nweights with a standard deviation of 20.0414 kg. What is the variance of their weights? Include \nthe appropriate units with the result.\n4. Symbols Identify the symbols used for each of the following: (a) sample standard devia-\ntion; (b) population standard deviation; (c) sample variance; (d) population variance.\nIn Exercises 5–20, find the range, variance, and standard deviation for the given sample \ndata. Include appropriate units (such as “minutes”) in your results. (The same data were \nused in Section 3-1 where we found measures of center. Here we find measures of varia-\ntion.) Then answer the given questions.\n5. Charges for Births Data Set 3 “Births” in Appendix B includes total charges for births at \nfour hospitals in New York State, and the top 10 highest amounts (in dollars) are listed below. \nWhat do the results tell us about the population of all such charges?\n471,062 359,091 290,837 271,863 255,788\n247,477 232,782 197,912 183,271 155,857\n6. MCAT Score Listed below are mean MCAT scores listed in order by year, starting with the \nyear 2002. What important feature of the data is not revealed by any of the measures of center?\n27.0 26.8 27.1 27.3 27.4 27.7 28.1 27.9 28.3 28.2 28.3 28.4\n7. Football Player Numbers Listed below are the jersey numbers of 11 players randomly \nselected from the roster of the Seattle Seahawks when they won Super Bowl XLVIII. What do \nthe results tell us?\n89 91 55 7 20 99 25 81 19 82 60\n8. Football Player Weights Listed below are the weights (lb) of 11 players randomly selected \nfrom the roster of the Seattle Seahawks when they won Super Bowl XLVIII (the same players \nfrom the preceding exercise). Are the results likely to be representative of all NFL players?\n189 254 235 225 190 305 195 202 190 252 305\n9.  Peas in a Pod Biologists conducted experiments to determine whether a deficiency \nof carbon dioxide in the soil affects the phenotypes of peas. Listed below are the pheno-\ntype codes, where 1 = smooth @ yellow, 2 = smooth @ green, 3 = wrinkled @yellow, and \n4 = wrinkled @ green. Do the results make sense?\n2  1  1  1  1  1  1  4  1  2  2  1  2  3  3  2  3  1  3  1  3  1  3  2  2\n10. TV Prices A physician plans to buy a television for her large waiting room. Listed below \nare selling prices (in dollars) of TVs that are 60 inches or larger and rated as a “best buy” by \nConsumer Reports magazine. Are the resulting statistics representative of the population of all \nTVs that are 60 inches and larger?\n1800 1500 1200 1500 1400 1600 1500 950 1600 1150 1500 1750\n11. Cell Phone Radiation Listed below are the measured radiation absorption rates (in W>kg) \ncorresponding to these cell phones: iPhone 5S, BlackBerry Z30, Sanyo Vero, Optimus V, Droid \nRazr, Nokia N97, Samsung Vibrant, Sony Z750a, Kyocera Kona, LG G2, and Virgin Mobile \nSupreme. The data are from the Federal Communications Commission. If one of each model of \ncell phone is measured for radiation and the results are used to find the measures of variation, \nare the results typical of the population of cell phones that are in use?\n1.18 1.41 1.49 1.04 1.45 0.74 0.89 1.42 1.45 0.51 1.38\n\n3-2 Measures of Variation \n99\n12. Caffeine in Soft Drinks Listed below are measured amounts of caffeine (mg per 12 oz of \ndrink) obtained in one can from each of 20 brands (7-UP, A&W Root Beer, Cherry Coke, . . . , \nTab). Are the statistics representative of the population of all cans of the same 20 brands consumed \nby Americans?\n0  0  34  34  34  45  41  51  55  36  47  41 0  0  53  54  38  0  41  47\n13. Firefighter Fatalities Listed below are the numbers of heroic firefighters who lost their \nlives in the United States each year while fighting forest fires. The numbers are listed in order \nby year, starting with the year 2000. What important feature of the data is not revealed by any \nof the measures of variation?\n20 18 23 30 20 12 24 9 25 15 8 11 15 34\n14. Foot Lengths Listed below are foot lengths in inches of randomly selected Army women \nmeasured in the 1988 Anthropometric Survey (ANSUR). Are the statistics representative of the \ncurrent population of all Army women?\n10.4 9.3 9.1 9.3 10.0 9.4 8.6 9.8 9.9 9.1 9.1\n15. Medical School Tuition Listed below in dollars are the annual costs of tuition at the 10 \nmost expensive private medical schools in the United States for a recent year (based on data \nfrom U.S. News & World Report). What does this “top 10” list tell us about those costs for the \npopulation of all U.S. private medical school tuitions?\n57,261 56,784 55,196 54,976 54,653 54,528 54,268 54,050 53,581 53,323\n16. California Smokers In the California Health Interview Survey, randomly selected adults \nare interviewed. One of the questions asks how many cigarettes are smoked per day, and results \nare listed below for 50 randomly selected respondents. How well do the results reflect the \nsmoking behavior of California adults?\n9 10 10 20 40 50 1Plus 44 other values that are all 02\nIn Exercises 17–20, find the coefficient of variation for each of the two samples; then com-\npare the variation. (The same data were used in Section 3-1.)\n17.  Blood Pressure A sample of blood pressure measurements is taken from Data Set \n1 “Body Data” in Appendix B, and those values (mm Hg) are listed below. The values are \nmatched so that 10 subjects each have systolic and diastolic measurements.\nSubject:\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\nSystolic:\n118\n128\n158\n96\n156\n122\n116\n136\n126\n120\nDiastolic:\n 80\n 76\n 74\n52\n 90\n 88\n 58\n 64\n 72\n 82\n18. White , Red Blood Counts Listed below are white blood cell counts (1000 cells>mL) \nand red blood cell counts (million cells>mL) from different subjects (from Data Set 1 “Body \nData” in Appendix B). The values are matched so that each of the 12 subjects has a white blood \ncell count and a red blood cell count.\nWhite:\n8.7\n4.9\n6.9\n7.5\n6.1\n5.7\n4.1\n8.1\n8.0\n5.6\n8.3\n6.9\nRed:\n4.8\n4.7\n4.5\n4.3\n5.0\n4.0\n4.7\n4.6\n4.1\n5.5\n4.4\n4.2\n19.  White Blood Counts Listed below are white blood cell counts (1000 cells>mL) from \nmales and females (from Data Set 1 “Body Data” in Appendix B). Do they appear to be different?\nFemale:\n8.7\n6.9\n8.1\n8.0\n6.9\n8.1\n6.4\n6.3\n10.9\n4.8\n5.9\n7.2\nMale:\n4.9\n7.5\n6.1\n5.7\n4.1\n5.6\n8.3\n5.1\n 9.5\n6.1\n5.7\n5.4\n\n100 \nCHAPTER 3 Describing, Exploring, and Comparing Data\n20. Queues A Providence Hospital experiment involves two different waiting line configura-\ntions for patients arriving for admission. The waiting times (in seconds) are recorded with a \nsingle line configuration that feeds four stations and another configuration with individual lines \nat the four stations.\nSingle Line\n390\n396\n402\n408\n426\n438\n444\n462\n462\n462\nIndividual Lines\n252\n324\n348\n372\n402\n462\n462\n510\n558\n600\nLarge Data Sets from Appendix B. In Exercises 21–24, refer to the indicated data set in \nAppendix B. Use software or a calculator to find the range, variance, and standard devia-\ntion. Express answers using appropriate units, such as “minutes.”\n21. HDL Use the HDL cholesterol measurements (mg>dL) from the 300 subjects included in \nData Set 1 “Body Data” in Appendix B. Identify the highest value. Does it appear to be an out-\nlier? Do the measures of variation change much when that highest value is deleted?\n22. LDL Repeat the preceding exercise using the LDL measurements (mg>dL).\n23. Body Temperatures Refer to Data Set 2 “Body Temperatures” in Appendix B and use \nthe body temperatures for 12:00 AM on day 2.\n24. Births Use the birth weights (grams) of the 400 babies listed in Data Set 3 “Births” in \n Appendix B. Examine the list of birth weights to make an observation about those numbers. \nHow does that observation affect the way that the results should be rounded?\nEstimating Standard Deviation with the Range Rule of Thumb. In Exercises 25–28, \nrefer to the data in the indicated exercise. After finding the range of the data, use the range \nrule of thumb to estimate the value of the standard deviation. Compare the result to the \nstandard deviation computed with all of the data.\n25. HDL Exercise 21\n26. LDL Exercise 22\n27. Body Temperatures Exercise 23\n28. Births Exercise 24\nIdentifying Significant Values with the Range Rule of Thumb. In Exercises 29–32, \nuse the range rule of thumb to identify the limits separating values that are significantly low \nor significantly high.\n29. Pulse Rates of Females Based on Data Set 1 “Body Data” in Appendix B, females \nhave pulse rates with a mean of 74.0 beats per minute and a standard deviation of 12.5 beats \nper minute. Is a female pulse rate of 44 beats per minute significantly low or significantly high? \n(All of these pulse rates are measured at rest.)\n30. Pulse Rates of Males Based on Data Set 1 “Body Data” in Appendix B, males have \npulse rates with a mean of 69.6 beats per minute and a standard deviation of 11.3 beats per \nminute. Is a male pulse rate of 50 beats per minute significantly low or significantly high? (All \nof these pulse rates are measured at rest.) Explain.\n31. Foot Lengths Based on Data Set 7 “Foot and Height” in Appendix B, adult males have \nfoot lengths with a mean of 27.32 cm and a standard deviation of 1.29 cm. Is the adult male \nfoot length of 30 cm significantly low or significantly high? Explain.\n32. Body Temperatures Based on Data Set 2 “Body Temperatures” in Appendix B, body \ntemperatures of adults have a mean of 98.20oF and a standard deviation of 0.62oF. Is an adult \nbody temperature of 100oF significantly low or significantly high?\n\n3-2 Measures of Variation \n101\nFinding Standard Deviation from a Frequency Distribution. In Exercises 33 and 34, \nrefer to the frequency distribution in the given exercise and find the standard deviation by \nusing the formula below, where x represents the class midpoint, f represents the class fre-\nquency, and n represents the total number of sample values. Also, compare the computed \nstandard deviations to these standard deviations obtained by using Formula 3-4 with the \noriginal list of data values: (Exercise 33) 59.5; (Exercise 34) 65.4.\ns = B\nn3Σ1f # x22 4 - 3Σ1f # x2 42\nn1n - 12\n33. \nBlood Platelet \nCount of Males\n \nFrequency\n 0–99\n 1\n100–199\n51\n200–299\n90\n300–399\n10\n400–499\n 0\n500–599\n 0\n600–699\n 1\n34. \nBlood Platelet \nCount of Females\n \nFrequency\n100–199\n25\n200–299\n92\n300–399\n28\n400–499\n 0\n500–599\n 2\n35. Why Divide by n −1? Let a population consist of these values: 9 cigarettes, 10 \ncigarettes, and 20 cigarettes smoked in a day (based on data from the California Health \nInterview Survey). Assume that samples of two values are randomly selected with replace-\nment from this population. (That is, a selected value is replaced before the second selection \nis made.)\na. Find the variance s2 of the population {9 cigarettes, 10 cigarettes, 20 cigarettes}.\nb. After listing the nine different possible samples of two values selected with replacement, \nfind the sample variance s2 (which includes division by n - 1) for each of them; then find the \nmean of the nine sample variances s2.\nc. For each of the nine different possible samples of two values selected with replacement, find \nthe variance by treating each sample as if it is a population (using the formula for population \nvariance, which includes division by n); then find the mean of those nine population variances.\nd. Which approach results in values that are better estimates of s2: part (b) or part (c)? Why? \nWhen computing variances of samples, should you use division by n or n - 1?\ne. The preceding parts show that s2 is an unbiased estimator of s2. Is s an unbiased estimator \nof s? Explain.\n36. Mean Absolute Deviation Use the same population of {9 cigarettes, 10 cigarettes, \n20 cigarettes} from Exercise 35. Show that when samples of size 2 are randomly selected \nwith replacement, the samples have mean absolute deviations that do not center about the \nvalue of the mean absolute deviation of the population. What does this indicate about a \nsample mean absolute deviation being used as an estimator of the mean absolute deviation \nof a population?\n3-2  Beyond the Basics\n\n102 \nCHAPTER 3 Describing, Exploring, and Comparing Data\nKey Concept This section introduces measures of relative standing, which are num-\nbers showing the location of data values relative to the other values within the same \ndata set. The most important concept in this section is the z score, which will be used \noften in following chapters. We also discuss percentiles and quartiles, which are com-\nmon statistics, as well as another statistical graph called a boxplot.\nPART 1\n  Basics of z Scores, Percentiles, Quartiles, \nand Boxplots \nz Scores\nA z score is found by converting a value to a standardized scale, as given in the fol-\nlowing definition. This definition shows that a z score is the number of standard devia-\ntions that a data value is away from the mean. The z score is used often in Chapter 6 \nand later chapters.\n3-3 \nMeasures of Relative Standing and Boxplots\nDEFINITION\nA z score (or standard score or standardized value) is the number of standard \ndeviations that a given value x is above or below the mean. The z score is calcu-\nlated by using one of the following:\nSample\nPopulation\nz = x - x\ns\nor\nz = x - m\ns\nROUND-OFF RULE FOR z SCORES Round z scores to two decimal places  \n(such as 2.31).\nThis round-off rule is motivated by the format of standard tables in which z scores \nare expressed with two decimal places, as in Table A-2 in Appendix A. Example 1 il-\nlustrates how z scores can be used to compare values, even if they come from different \npopulations.\nImportant Properties of z Scores\n1. A z score is the number of standard deviations that a given value x is above or \nbelow the mean.\n2. z Scores are expressed as numbers with no units of measurement.\n3. A data value is significantly low if its z score is less than or equal to -2 or the \nvalue is significantly high if its z score is greater than or equal to +2.\n4. If an individual data value is less than the mean, its corresponding z score \nis a negative number.\n\n3-3 Measures of Relative Standing and Boxplots \n103\nUsing z Scores to Identify Significant Values In Section 3-2 we used the range \nrule of thumb to conclude that a value is significantly low or significantly high if it is \nat least 2 standard deviations away from the mean. It follows that significantly low \nvalues have z scores less than or equal to -2 and significantly high values have z \nscores greater than or equal to +2, as illustrated in Figure 3-4. Using this criterion \nwith the two individual values used in Example 1 above, we see that neither value is \nsignificant because both z scores are between -2 and +2.\nEXAMPLE 1   Comparing a Baby’s Weight and  \nAdult Body Temperature\nWhich of the following two data values is more extreme relative to the data set from \nwhich it came?\n \n■The 4000 g weight of a newborn baby (among 400 weights with sample mean \nx = 3152.0 g and sample standard deviation s = 693.4 g)\n \n■The 99°F temperature of an adult (among 106 adults with sample mean \nx = 98.20°F and sample standard deviation s = 0.62°F)\nSOLUTION\nThe 4000 g weight and the 99°F body temperature can be standardized by convert-\ning each of them to z scores as shown below.\n4000 g birth weight:\nz = x - x\ns\n= 4000 g - 3152.0 g\n693.4 g\n= 1.22\n99°F body temperature:\nz = x - x\ns\n= 99°F - 98.20°F\n0.62°F\n= 1.29\nINTERPRETATION\nThe z scores show that the 4000 g birth weight is 1.22 standard deviations above the \nmean, and the 99°F body temperature is 1.29 standard deviations above the mean. \nBecause the body temperature is farther above the mean, it is the more extreme \nvalue, but not by much. A 99°F body temperature is slightly more extreme than a \nbirth weight of 4000 g.\nValues not signiﬁcant\nSigniﬁcantly\nlow values\nSigniﬁcantly\nhigh values\nz\n−2\n−1\n2\n−3\n3\n0\n1\nFIGURE 3-4  Interpreting z Scores \nSignificant values are those with z scores …  -2.00 or Ú 2.00.\n\n104 \nCHAPTER 3 Describing, Exploring, and Comparing Data\nA z score is a measure of position, in the sense that it describes the location of a \nvalue (in terms of standard deviations) relative to the mean. Percentiles and quartiles \nare other measures of position useful for comparing values within the same data set or \nbetween different sets of data.\nPercentiles\nPercentiles are one type of quantiles—or fractiles—which partition data into groups \nwith roughly the same number of values in each group.\nEXAMPLE 2  Is a Platelet Count of 75 Significantly Low?\nThe lowest platelet count in Data Set 1 “Body Data” in Appendix B is 75. (The \nplatelet counts are measured in 1000 cells>mL). Is that value significantly low? \nBased on the platelet counts from Data Set 1 in Appendix B, assume that platelet \ncounts have a mean of x = 239.4 and a standard deviation of s = 64.2.\nSOLUTION\nThe platelet count of 75 is converted to a z score as shown below:\nz = x - x\ns\n= 75 - 239.4\n64.2\n= -2.56\nINTERPRETATION\nThe platelet count of 75 converts to the z score of -2.56. Refer to Figure 3-4 to \nsee that z = -2.56 is less than -2, so the platelet count of 75 is significantly low. \n(Low platelet counts are called thrombocytopenia. What a wonderful name.)\nDEFINITION\nPercentiles are measures of location, denoted P1, P2, . . . , P99, which divide a set of \ndata into 100 groups with about 1% of the values in each group.\nThe 50th percentile, denoted P50, has about 50% of the data values below it and about \n50% of the data values above it, so the 50th percentile is the same as the median. \nThere is not universal agreement on a single procedure for calculating percentiles, but \nwe will describe relatively simple procedures for (1) finding the percentile of a data \nvalue and (2) converting a percentile to its corresponding data value. We begin with \nthe first procedure.\nFinding the Percentile of a Data Value\nThe process of finding the percentile that corresponds to a particular data value x \nis given by the following (round the result to the nearest whole number):\nPercentile of value x = number of values less than x\ntotal number of values\n# 100\nDetecting Phony Data\nA class is \ngiven the \nhomework \nassignment of \nrecording the \nresults when a \ncoin is tossed \n500 times. One dishonest stu-\ndent decides to save time by just \nmaking up the results instead of \nactually flipping a coin. Because \npeople generally cannot make \nup results that are really random, \nwe can often identify such phony \ndata. With 500 tosses of an ac-\ntual coin, it is extremely likely that \nyou will get a run of six heads or \nsix tails, but people almost never \ninclude such a run when they \nmake up results.\nAnother way to detect fab-\nricated data is to establish that \nthe results violate Benford’s law: \nFor many collections of data, the \nleading digits are not uniformly \ndistributed. Instead, the leading \ndigits of 1, 2,…, 9 occur with \nrates of 30%, 18%, 12%, 10%, \n8%, 7%, 6%, 5%, and 5%, re-\nspectively. (See “The Difficulty of \nFaking Data,” by Theodore Hill, \nChance, Vol. 12, No. 3.)\n\n3-3 Measures of Relative Standing and Boxplots \n105\nExample 3 shows how to convert from a given sample value to the corresponding \npercentile. There are several different methods for the reverse procedure of converting \na given percentile to the corresponding value in the data set. The procedure we will \nuse is summarized in Figure 3-5 on the next page, which uses the following notation.\nNotation\nn \ntotal number of values in the data set\nk \npercentile being used (Example: For the 25th percentile, k = 25.)\nL \n locator that gives the position of a value (Example: For the 12th value in \nthe sorted list, L = 12.)\nPk \nkth percentile (Example: P25 is the 25th percentile.)\nTABLE 3-4 Sorted Cotinine Measures of Smokers\n  0\n  1\n  1\n  3\n 17\n 32\n 35\n 44\n 48\n 86\n 87\n103\n112\n121\n123\n130\n131\n149\n164\n167\n173\n173\n198\n208\n210\n222\n227\n234\n245\n250\n253\n265\n266\n277\n284\n289\n290\n313\n477\n491\nEXAMPLE 3  Finding a Percentile\nTable 3-4 lists the 40 cotinine measures (ng>mL) of smokers from Data Set 14 \n“Passive and Active Smoke” in Appendix B, and they are listed in order. Find the \npercentile for the cotinine level of 198 ng>mL.\nSOLUTION\nFrom the sorted list of cotinine levels in Table 3-4, we see that there are 22 values \nless than 198 ng>mL, so\nPercentile of 198 ng>mL = 22\n40 # 100 = 55\nINTERPRETATION\nA cotinine level of 198 ng>mL is in the 55th percentile. This can be interpreted \nloosely as this: A cotinine level of 198 ng>mL separates the lowest 55% of values \nfrom the highest 45% of values. We have P55 = 198 ng>mL.\nEXAMPLE 4  Converting a Percentile to a Data Value\nRefer to the sorted cotinine levels of smokers in Table 3-4 and use the procedure in \nFigure 3-5 to find the value of the 33rd percentile, P33.\ncontinued\n\n106 \nCHAPTER 3 Describing, Exploring, and Comparing Data\nThe value of Pk is the Lth\nvalue, counting from\nthe lowest.\nIs L a whole\nnumber?\nYes\nNo\nChange L by rounding it\nup to the next larger\nwhole number.\nCompute\nn 5 number of values\nk 5 percentile in question\nSort the data.\n(Arrange the data in order\nof lowest to highest.)\nStart\nL 5\nn   where\nk\n100\nThe value of the kth percentile is \nmidway between the Lth value \nand the next value in the sorted \nset of data. Find Pk by adding \nthe Lth value and the next value \nand dividing the total by 2. \nFIGURE 3-5  Converting from the kth percentile to the \ncorresponding data value\nSOLUTION\nFrom Figure 3-5, we see that the sample data are already sorted, so we can proceed \nto find the value of the locator L. In this computation we use k = 33 because we are \ntrying to find the value of the 33rd percentile. We use n = 40 because there are 40 \ndata values.\nL =\nk\n100 # n = 33\n100 # 40 = 13.2\nSince L = 13.2 is not a whole number, we proceed to the next lower box in Figure 3-5 \nwhere we change L by rounding it up from 13.2 to the next larger whole number: 14. \n(In this book we typically round off the usual way, but this is one of two cases where \nwe round up instead of rounding off.) From the bottom box we see that the value of P33 \nis the 14th value, counting from the lowest. In Table 3-4, the 14th value is 121. That is, \nP33 = 121 ng>mL. Roughly speaking, about 33% of the cotinine levels in Table 3-4 \nare less than 121 ng>mL and 67% of them are more than 121 ng>mL.\n\n3-3 Measures of Relative Standing and Boxplots \n107\nQuartiles\nJust as there are 99 percentiles that divide the data into 100 groups, there are three \nquartiles that divide the data into four groups.\nEXAMPLE 5  Converting a Percentile to a Data Value\nRefer to the sorted pulse rates in Table 3-4. Use Figure 3-5 to find the 25th percen-\ntile, denoted by P25.\nSOLUTION\nReferring to Figure 3-5, we see that the sample data are already sorted, so we can \nproceed to compute the value of the locator L. In this case, we use k = 25 because \nwe are attempting to find the value of the 25th percentile, and we use n = 40 be-\ncause there are 40 data values.\nL =\nk\n100 # n = 25\n100 # 40 = 10\nSince L = 10 is a whole number, we proceed to the box in Figure 3-5 located at the \nright. We now see that the value of the 25th percentile is midway between the Lth \n(10th) value and the next higher value in the original set of data. That is, the value \nof the 25th percentile is midway between the 10th value and the 11th value. The \n10th value in Table 3-4 is 86 and the 11th value is 87, so the value midway between \nthem is 86.5 ng>mL. We conclude that the 25th percentile is P25 = 86.5 ng>mL.\nDEFINITION\nQuartiles are measures of location, denoted Q1, Q2, and Q3,which divide a set of \ndata into four groups with about 25% of the values in each group.\nHere are descriptions of quartiles that are more accurate than those given in the \npreceding definition:\nQ1 (First quartile): \n Same value as P25. It separates the bottom 25% of the \nsorted values from the top 75%. (To be more precise, \nat least 25% of the sorted values are less than or equal \nto Q1, and at least 75% of the values are greater than or \nequal to Q1.)\nQ2 (Second quartile):  Same as P50 and same as the median. It separates the \nbottom 50% of the sorted values from the top 50%.\nQ3 (Third quartile): \n Same as P75. It separates the bottom 75% of the sorted val-\nues from the top 25%. (To be more precise, at least 75% of \nthe sorted values are less than or equal to Q3, and at least \n25% of the values are greater than or equal to Q3.)\nFinding values of quartiles can be accomplished with the same procedure used for \nfinding percentiles. Simply use the relationships shown in the margin. In Example 4 \nwe found that P25 = 86.5 ng>mL, so it follows that Q1 = 86.5 ng>mL.\nQ1 = P25\nQ2 = P50\nQ3 = P75\n\n108 \nCHAPTER 3 Describing, Exploring, and Comparing Data\nIn earlier sections of this chapter we described several statistics, including the \nmean, median, mode, range, and standard deviation. Some other statistics are defined \nusing quartiles and percentiles, as in the following:\nInterquartile range (or IQR) \n= Q3 - Q1\nSemi-interquartile range \n= Q3 - Q1\n2\nMidquartile \n= Q3 + Q1\n2\n10–90 percentile range \n= P90 - P10\n5-Number Summary and Boxplot\nThe values of the minimum, maximum and three quartiles 1Q1, Q2, Q32 are used for \nthe 5-number summary and the construction of boxplot graphs.\nCAUTION Just as there is not universal agreement on a procedure for finding \npercentiles, there is not universal agreement on a single procedure for calculating \nquartiles, and different technologies often yield different results. If you use a \ncalculator or software for exercises involving quartiles, you may get results that differ \nsomewhat from the answers obtained by using the procedures described here.\nDEFINITION\nFor a set of data, the 5-number summary consists of these five values:\n1. Minimum\n2. First quartile, Q1\n3. Second quartile, Q2 (same as the median)\n4. Third quartile, Q3\n5. Maximum\nEXAMPLE 6  Finding a 5-Number Summary\nUse the cotinine measurements in Table 3-4 to find the 5-number summary.\nSOLUTION\nBecause the cotinine measurements in Table 3-4 are sorted, it is easy to see that \nthe minimum is 0 ng>mL and the maximum is 491 ng>mL. The value of the first \nquartile is Q1 = 86.5 ng>mL (from Example 5). The median is equal to Q2, and it \nis 170.0 ng>mL. Also, we can find that Q3 = 251.5 ng>mL by using the procedure \nfor finding P75 (as summarized in Figure 3-5). The 5-number summary is therefore \n0, 86.5, 170.0, 251.5, and 491 (all in units of ng>mL).\nDEFINITION\nA boxplot (or box-and-whisker diagram) is a graph of a data set that consists of a \nline extending from the minimum value to the maximum value, and a box with lines \ndrawn at the first quartile Q1, the median, and the third quartile Q3. (See Figure 3-6.)\n\n3-3 Measures of Relative Standing and Boxplots \n109\nProcedure for Constructing a Boxplot\n1. Find the 5-number summary (minimum value, Q1, Q2, Q3, maximum value).\n2. Construct a line segment extending from the minimum data value to the maxi-\nmum data value.\n3. Construct a box (rectangle) extending from Q1 to Q3, and draw a line in the \nbox at the value of Q2 (median).\nCAUTION Because there is not universal agreement on procedures for finding \nquartiles, and because boxplots are based on quartiles, different technologies may \nyield different boxplots.\nEXAMPLE 7  Constructing a Boxplot\nUse the cotinine measurements listed in Table 3-4 to construct a boxplot.\nSOLUTION\nThe boxplot uses the 5-number summary found in Example 6: 0, 86.5, 170.0, 251.5, \nand 491 (all in units of ng>mL). Figure 3-6 is the boxplot representing the cotinine \nmeasurements listed in Table 3-4.\nFIGURE 3-6 Boxplot of Cotinine Measurements (ng, mL)\nSkewness A boxplot can often be used to identify skewness (discussed in \n Section 2-2). The boxplot in Figure 3-6 isn’t exactly symmetric; it shows that the \ndata are slightly skewed to the right.\nBecause the shape of a boxplot is determined by the five values from the 5-number \nsummary, a boxplot is not a graph of the distribution of the data, and it doesn’t show \nas much detailed information as a histogram or stemplot. However, boxplots are often \ngreat for comparing two or more data sets. When using two or more boxplots for com-\nparing different data sets, graph the boxplots on the same scale so that comparisons \ncan be easily made. Methods discussed later in this book allow us to analyze com-\nparisons of data sets more formally than subjective conclusions based on a graph. It is \nalways wise to construct suitable graphs, such as histograms, dotplots, and boxplots, \nbut we should not rely solely on subjective judgments based on graphs.\nEXAMPLE 8  Comparing the Pulse Rates of Men and Women\nThe Chapter Problem involves pulse rates of men and women, and the data are \nfound in Data Set 1 “Body Data” in Appendix B. Construct boxplots of those two \ndifferent sets of pulse rates.\ncontinued\n\n110 \nCHAPTER 3 Describing, Exploring, and Comparing Data\nOutliers\nWhen analyzing data, it is important to identify and consider outliers because they \ncan strongly affect values of some important statistics (such as the mean and standard \ndeviation), and they can also strongly affect important methods discussed later in this \nbook. In Chapter 2 we described outliers as sample values that lie very far away from \nthe vast majority of the other values in a set of data, but that description is vague and \nit does not provide specific objective criteria. Part 2 of this section includes a descrip-\ntion of modified boxplots along with a more precise definition of outliers used in the \ncontext of creating modified boxplots.\nSOLUTION\nThe Statdisk-generated boxplots are shown in Figure 3-7. The three quartiles for \nmales are all lower than the corresponding three quartiles for females, which sug-\ngests that males generally have lower pulse rates than females. The minimums and \nmaximums are not very different in the two boxplots, and we shouldn’t place too \nmuch importance on those differences because they are not very reliable measures.\nFIGURE 3-7 Boxplots of Pulse Rates of Men and Women\nCAUTION When analyzing data, always identify outliers and consider their effects, \nwhich can be substantial.\nPART 2\n Outliers and Modified Boxplots \nWe noted that the description of outliers is somewhat vague, but for the purposes of \nconstructing modified boxplots, we can consider outliers to be data values meeting \nspecific criteria based on quartiles and the interquartile range. (The interquartile range \nis often denoted by IQR, and IQR = Q3 - Q1.)\nIdentifying Outliers for Modified Boxplots\n1. Find the quartiles Q1, Q2, and Q3.\n2. Find the interquartile range (IQR), where IQR = Q3 - Q1.\n3. Evaluate 1.5 * IQR.\n4. In a modified boxplot, a data value is an outlier if it is\nabove Q3, by an amount greater than 1.5 : IQR\nor below Q1, by an amount greater than 1.5 : IQR\nModified Boxplots\nThe boxplots described earlier in Part 1 are called skeletal (or regular) boxplots, but \nsome statistical software packages provide modified boxplots, which represent outliers as \n\n3-3 Measures of Relative Standing and Boxplots \n111\nspecial points. A modified boxplot is a regular boxplot constructed with these modifi-\ncations: (1) A special symbol (such as an asterisk or point) is used to identify outliers \nas defined above, and (2) the solid horizontal line extends only as far as the minimum \ndata value that is not an outlier and the maximum data value that is not an outlier. \n(Note: Exercises involving modified boxplots are found in the “Beyond the Basics” \nexercises only.)\nEXAMPLE 9  Constructing Modified Boxplots\nUse the pulse rates of males in Data Set 1 “Body Data” from Appendix B to con-\nstruct a modified boxplot. The five-number summary is 40, 62.0, 68.0, 76.0, 104 (all \nin BPM).\nSOLUTION\nLet’s begin with the four steps for identifying outliers in a modified boxplot.\n1. Using the pulse rates of males, the three quartiles are Q1 = 62.0, the median \nis Q2 = 68.0, and Q3 = 76.0.\n2. The interquartile range is IQR = Q3 - Q1 = 76.0 - 62.0 = 14.0.\n3. 1.5 * IQR = 1.5 * 14.0 = 21.0.\n \n4. Any outliers are\n \n■Greater than Q3 = 76.0 by more than 21.0 or\n \n■Less than Q1 = 62.0 by more than 21.0.\nThis means that any outliers are greater than 97.0 or less than 41.0. We can now \nexamine the original pulse rates of males to identify any that are greater than 97.0 or \nless than 41.0. We find that the pulse rates of 102 and 104 are greater than 97.0, and \nthe pulse rate of 40 is less than 41.0. The outliers are 102, 104, and 40.\nWe can now construct the modified boxplot shown in Figure 3-8. In Figure 3-8, \nthe three outliers (40, 102, 104) are identified as special points, the three quartiles \n(62.0, 68.0, 76.0) are shown as in a regular boxplot, and the horizontal line extends \nfrom the lowest data value that is not an outlier (42) to the highest data value that is \nnot an outlier (96).\nFIGURE 3-8 Modified Boxplot of Male Pulse Rates (BPM)\nCAUTION Because there is not universal agreement on procedures for finding \nquartiles, and because modified boxplots are based on quartiles, different \ntechnologies may yield different modified boxplots.\n\n112 \nCHAPTER 3 Describing, Exploring, and Comparing Data\nBoxplots, 5-Number Summary, Outliers\nAccess tech instructions, videos, and data sets at www.TriolaStats.com\nTECH CENTER \nStatistical Literacy and Critical Thinking \n1.  z Scores LeBron James, one of the most successful basketball players of all time, has \na height of 6 feet 8 inches, or 203 cm. Based on statistics from Data Set 1 “Body Data” in \n Appendix B, his height converts to the z score of 4.07. How many standard deviations is his \nheight above the mean?\n2. Heights The boxplot shown below results from the heights (cm) of males listed in Data Set \n1 “Body Data” in Appendix B. What do the numbers in that boxplot tell us?\n3. Boxplot Comparison Refer to the boxplots shown below that are drawn on the same scale. \nOne boxplot represents weights of men and the other boxplot represents weights of women. \nWhich boxplot represents weights of women? Explain.\n4. z Scores If your score on your next statistics test is converted to a z score, which of these z \nscores would you prefer: -2.00,-1.00, 0, 1.00, 2.00? Why?\nz Scores. In Exercises 5–8, express all z scores with two decimal places.\n5. Female Pulse Rates For the pulse rates of females listed in Data Set 1 “Body Data” in \nAppendix B, the mean is 74.0 BPM, the standard deviation is 12.5 BPM, and the maximum is \n104 BPM.\na. What is the difference between the maximum and the mean?\nb. How many standard deviations is that [the difference found in part (a)]?\nc. Convert the maximum pulse rate to a z score.\nd. If we consider pulse rates that convert to z scores between -2 and 2 to be neither signifi-\ncantly low nor significantly high, is the maximum pulse rate significant?\n6. Female Pulse Rates For the pulse rates of females listed in Data Set 1 “Body Data” in \nAppendix B, the mean is 74.0 BPM, the standard deviation is 12.5 BPM, and the minimum is \n36 BPM.\na. What is the difference between the minimum and the mean?\nb. How many standard deviations is that [the difference found in part (a)]?\n3-3 Basic Skills and Concepts\n\n3-3 Measures of Relative Standing and Boxplots \n113\nc. Convert the minimum pulse rate to a z score.\nd. If we consider pulse rates that convert to z scores between -2 and 2 to be neither significantly \nlow nor significantly high, is the minimum pulse rate significantly low or significantly high?\n7. Body Temperatures For the body temperatures at 12 AM on day 2 (listed in Data Set 2 \n“Body Temperatures” in Appendix B), the mean is 98.20oF, the standard deviation is 0.62oF, \nand the minimum is 96.5oF.\na. What is the difference between the minimum and the mean?\nb. How many standard deviations is that [the difference found in part (a)]?\nc. Convert the minimum temperature to a z score.\nd. If we consider body temperatures that convert to z scores between -2 and 2 to be neither \nsignificantly low nor significantly high, is the minimum body temperature significant?\n8. Body Temperatures For the body temperatures at 12 AM on day 2 (listed in Data Set 2 \n“Body Temperatures” in Appendix B), the mean is 98.20°F, the standard deviation is 0.62°F,\nand Q3 = 98.60°F.\na. What is the difference between Q3 and the mean?\nb. How many standard deviations is that [the difference found in part (a)]?\nc. Convert Q3 to a z score.\nd. If we consider temperatures that convert to z scores between -2 and 2 to be neither signifi-\ncantly low nor significantly high, is Q3 significant?\nSignificant Values. In Exercises 9–12, consider a value to be significantly low if its z \nscore is less than or equal to −2 or consider the value to be significantly high if its z score \nis greater than or equal to 2.\n9. ACT The ACT test is used to assess readiness for college. In a recent year, the mean ACT \nscore was 21.1 and the standard deviation was 5.1. Identify the ACT scores that are signifi-\ncantly low or significantly high.\n10. MCAT In a recent year, scores on the MCAT had a mean of 25.2 and a standard deviation \nof 6.4. Identify the MCAT scores that are significantly low or significantly high.\n11. Birth Weights Data Set 3 “Births” lists birth weights (g) of 400 babies. Those weights \nhave a mean of 3152.0 g and a standard deviation of 693.4 g. Identify birth weights that are \nsignificantly low or significantly high.\n12. Ergonomics in Aircraft Seats In the process of designing aircraft seats, it was found \nthat men have hip breadths with a mean of 36.6 cm and a standard deviation of 2.5 cm (based \non anthropometric survey data from Gordon, Clauser, et al.). Identify the hip breadths of men \nthat are significantly low or significantly high.\nComparing Values. In Exercises 13–16, use z scores to compare the given values.\n13. Tallest and Shortest Men The tallest living man at the time of this writing is Sultan \nKosen, who has a height of 251 cm. The shortest living man is Chandra Bahadur Dangi, who \nhas a height of 54.6 cm. Heights of men have a mean of 174.12 cm and a standard deviation of \n7.10 cm. Which of these two men has the height that is more extreme?\n14. Red Blood Cell Counts Based on Data Set 1 “Body Data” in Appendix B, males have \nred blood cell counts with a mean of 4.719 and a standard deviation of 0.490, while females \nhave red blood cell counts with a mean of 4.349 and a standard deviation of 0.402. Who has the \nhigher count relative to the sample from which it came: a male with a count of 5.58 or a female \nwith a count of 5.23? Explain.\n15. Birth Weights Based on Data Set 3 “Births” in Appendix B, newborn males have weights \nwith a mean of 3272.8 g and a standard deviation of 660.2 g. Newborn females have weights \nwith a mean of 3037.1 g and a standard deviation of 706.3 g. Who has the weight that is more \ncontinued\n\n114 \nCHAPTER 3 Describing, Exploring, and Comparing Data\nextreme relative to the group from which they came: a male who weighs 1500 g or a female \nwho weighs 1500 g? Who has the larger weight relative to the group from which they came?\n16. Oscars In the 87th Academy Awards, Eddie Redmayne won for best actor at the age of \n33 and Julianne Moore won for best actress at the age of 54. For all best actors, the mean age \nis 44.1 years and the standard deviation is 8.9 years. For all best actresses, the mean age is \n36.2 years and the standard deviation is 11.5 years. (All ages are determined at the time of the \nawards ceremony.) Relative to their genders, who had the more extreme age when winning the \nOscar: Eddie Redmayne or Julianne Moore? Explain.\nPercentiles. In Exercises 17–20, use the following lengths (inches) of bears (from Data \nSet 11 “Bear Measurements” in Appendix B). Find the percentile corresponding to the \ngiven length.\n36.0 37.0 40.0 40.0 41.0 43.0 43.5 46.0 46.0 47.0 48.0 48.0\n49.0 50.0 52.0 52.5 53.0 53.0 54.0 57.3 57.5 58.0 59.0 59.0\n59.0 60.0 60.5 61.0 61.0 61.5 62.0 63.0 63.0 63.0 63.5 64.0\n64.0 64.0 65.0 65.0 66.5 67.0 67.5 68.5 70.0 70.5 72.0 72.0\n72.0 72.0 73.0 73.5 75.0 76.5\n17. 61.0 in.  18. 47.0 in.  19. 70.0 in.  20. 58.0 in.\nIn Exercises 21–28, use the same list of bear lengths (in.) given for Exercises 17–20. Find \nthe indicated percentile or quartile.\n21. P60   22. Q1\n23. Q3   24. P40\n25. P50   26. P75\n27. P25   28. P85\nBoxplots. In Exercises 29–32, use the given data to construct a boxplot and identify the \n5-number summary.\n29. Foot Lengths The following are the foot lengths (cm) of 19 males (from Data Set 7 “Foot \nand Height” in Appendix B).\n 25.1 25.4 25.7 25.9 26.4 26.7 26.7 26.7 26.8 27.5\n 27.8 27.9 27.9 28.1 28.6 28.7 28.8 29.2 29.2\n30.  Cell Phone Radiation Listed below are the measured radiation absorption rates (in \nW>kg) corresponding to these cell phones: iPhone 5S, BlackBerry Z30, Sanyo Vero, Optimus \nV, Droid Razr, Nokia N97, Samsung Vibrant, Sony Z750a, Kyocera Kona, LG G2, and Virgin \nMobile Supreme. The data are from the Federal Communications Commission.\n1.18 1.41 1.49 1.04 1.45 0.74 0.89 1.42 1.45 0.51 1.38\n31. Radiation in Baby Teeth Listed below are amounts of strontium-90 (in millibecquerels, \nor mBq) in a simple random sample of baby teeth obtained from Pennsylvania residents born \nafter 1979 (based on data from “An Unexpected Rise in Strontium-90 in U.S. Deciduous Teeth \nin the 1990s,” by Mangano et. al., Science of the Total Environment).\n 128 130 133 137 138 142 142 144 147 149 151 151 151 155\n 156 161 163 163 166 172\n32. Blood Pressure Measurements Fourteen different second-year medical students \nat  Bellevue Hospital measured the blood pressure of the same person. The systolic readings \n(mm Hg) are listed below.\n138 130 135 140 120 125 120 130 130 144 143 140 130 150\n\nBoxplots from Large Data Sets in Appendix B. In Exercises 33 and 34, use the given \ndata sets from Appendix B. Use the boxplots to compare the two data sets.\n33. BMI Use the body mass indexes (BMI) for males and use the BMI measures for females \nlisted in Data Set 1 “Body Data.”\n34. Lead and IQ Use the same scale to construct boxplots for the full IQ scores (IQF) for the \nlow lead level group and the high lead level group in Data Set 8 “IQ and Lead” in Appendix B.\n35. Outliers and Modified Boxplots Repeat Exercise 33 “BMI” using modified boxplots. \nIdentify any outliers as defined in Part 2 of this section.\n3-3 Beyond the Basics\nChapter Quick Quiz\n1. Sleep Mean As part of the National Health and Nutrition Examination Survey, subjects \nwere asked how long they slept the preceding night and the following times (hours) were re-\nported: 8, 7, 5, 7, 4, 7, 6, 7, 8, 8, 8, 6. Find the mean.\n2. Sleep Median What is the median of the sample values listed in Exercise 1?\n3. Sleep Mode What is the mode of the sample values listed in Exercise 1?\n4. Sleep Variance The standard deviation of the sample values in Exercise 1 is 1.3 hours. \nWhat is the variance (including units)?\n5. Sleep Outlier If the sleep time of 0 hours is included with the sample data given in Exercise 1, \nis it an outlier? Why or why not?\n6. Sleep z Score A larger sample of 50 sleep times (hours) has a mean of 6.3 hours and a stan-\ndard deviation of 1.4 hours. What is the z score for a sleep time of 5 hours?\n7. Sleep Q3 For a sample of 80 sleep times, approximately how many of those times are less \nthan Q3?\n8. Sleep 5-Number Summary For a sample of 100 sleep times, give the names of the val-\nues that constitute the 5-number summary. (The actual values can’t be identified; just give the \nnames of those values.)\n9. Estimating s A large sample of sleep times includes values ranging from a low of 4 hours \nto a high of 10 hours. Use the range rule of thumb to estimate the standard deviation.\n10. Sleep Notation Consider a sample of sleep times taken from the population of all adults \nliving in Alaska. Identify the symbols used for the sample mean, population mean, sample stan-\ndard deviation, population standard deviation, sample variance, and the population variance.\nReview Exercises\n1. Ergonomics When designing an eye-recognition security device, engineers must consider \nthe eye heights of standing women. (It’s easy for men to bend lower, but it’s more difficult for \nwomen to rise higher.) Listed below are the eye heights (in millimeters) obtained from a simple \nrandom sample of standing adult women (based on anthropometric survey data from Gordon, \nChurchill, et al.). Use the given eye heights to find the (a) mean; (b) median; (c) mode; (d) mid-\nrange; (e) range; (f) standard deviation; (g) variance.\n1550 1642 1538 1497 1571\nCHAPTER 3 Review Exercises \n115\n\n116 \nCHAPTER 3 Describing, Exploring, and Comparing Data\n2. z Score Using the sample data from Exercise 1, find the z score corresponding to the eye \nheight of 1642 mm. Is that eye height significantly low or significantly high? Why or why not?\n3. ER Codes In an analysis of activities that resulted in brain injuries presenting at hospital \nemergency rooms (ERs), the following activities were identified by the code shown in paren-\ntheses: bicycling (12); football (14); playground (22); basketball (27); swimming (40). Find the \nmean of 12, 14, 22, 27, and 40. What is wrong with this result?\n4. Comparing Birth Weights The birth weights of a sample of males have a mean of 3273 g and \na standard deviation of 660 g. The birth weights of a sample of females have a mean of 3037 g \nand a standard deviation of 706 g (based on Data Set 3 “Births” in Appendix B). When consid-\nered among members of the same gender, which baby has the relatively larger birth weight: a \nboy with a birth weight of 3400 g or a girl with a birth weight of 3200 g? Why?\n5. Effects of an Outlier Listed below are platelet counts (1000 cells>mL) from subjects in-\ncluded in Data Set 1 “Body Data.” Identify the outlier and then comment on the effect it has \non the mean and standard deviation by finding the values of those statistics with the outlier \nincluded and then with the outlier excluded.\n263 206 185 246 188 191 308 262 198 253 646\n6. Interpreting a Boxplot Shown below is a boxplot of a sample of 30 maximal skull breadths \n(mm) measured from Egyptian skulls from around 4000 B.C. What do the numbers in the box-\nplot represent?\n7. Interpreting Standard Deviation A physician routinely makes physical examinations of \nchildren. She is concerned that a three-year-old girl has a height of only 87.8 cm. Heights of \nthree-year-old girls have a mean of 97.5 cm and a standard deviation of 6.9 cm (based on data \nfrom the National Health and Nutrition Examination Survey). Use the range rule of thumb to \nfind the limits separating heights of three-year-old girls that are significantly low or signifi-\ncantly high. Based on the result, is the height of 87.8 cm significant? Should the physician be \nconcerned?\n8. Mean or Median? A biostatistics class consists of 30 students with no income, 10 students \nwith small incomes from part-time jobs, plus a professor with a very large income that is well \ndeserved. Which is better for describing the income of a typical person in this class: mean or \nmedian? Explain.\nCumulative Review Exercises\n1. Arsenic in Rice Listed below are measured amounts (mg per serving) of arsenic in a sample \nof servings of brown rice [data from the Food and Drug Administration (FDA)]. Construct a \nfrequency distribution. Use a class width of 2 mg, and use 0 mg as the lower class limit of the \nfirst class.\n6.1 5.4 6.9 4.9 6.6 6.3 6.7 8.2 7.8 1.5 5.4 7.3\n2. Histogram Use the frequency distribution from Exercise 1 to construct a histogram. Use \nclass midpoint values for the horizontal scale.\n3. Stemplot Use the amounts of arsenic from Exercise 1 to construct a stemplot.\n4. Descriptive Statistics Use amounts of arsenic in Exercise 1 and find the following: (a) \nmean; (b) median; (c) standard deviation; (d) variance; (e) range. Include the appropriate units \nof measurement.\n\nCHAPTER 3 Cooperative Group Activities \n117\n5. a. A medical researcher has a collection of data at the nominal level of measurement and she \nwants to obtain a representative data value. Which of the following is most appropriate: mean, \nmedian, mode, or midrange? Why?\nb. A botanist wants to obtain data about the plants being grown in homes. If a sample is ob-\ntained by telephoning the first 250 people listed in the local telephone directory, what type of \nsampling is being used? (random, stratified, systematic, cluster, convenience)\nc. A botanist is experimenting with fertilizer sticks used for growing plants. She finds that the \namounts of fertilizer placed in the sticks are not very consistent, so that some fertilization lasts \nlonger than claimed, but others don’t last long enough. She wants to improve quality by making \nthe amounts of fertilizer in the sticks more consistent. When analyzing the amounts of fertil-\nizer for that purpose, which of the following statistics is most relevant: mean, median, mode, \nmidrange, standard deviation, first quartile, third quartile? Should the value of that statistic be \nraised, lowered, or left unchanged?\nTechnology Project\nFreshman 15 Refer to Data Set 10 “Freshman 15” in Appendix B, which includes results from \na study of the legend that college freshmen tend to gain around 15 pounds (or 6.8 kilograms) \nduring their freshman year. That data set includes 5 columns of data from 67 subjects. Use the \nmethods of this chapter to make relevant comparisons, then form a subjective conclusion about \nthe 15-pound (or 6.8-kilogram) weight gain. Write a brief report including your conclusions \nwith supporting graphs and statistics.\nFROM DATA TO DECISION\nSecond-Hand Smoke\nData Set 14 “Passive and Active Smoke” in Appendix B \nlists measures of cotinine from three groups of subjects: \n(1) smokers; (2) nonsmokers exposed to environmental to-\nbacco smoke; and (3) nonsmokers not exposed to environ-\nmental tobacco smoke. Cotinine is an indicator of nicotine \nabsorption.\nCritical Thinking\nUse the methods from this chapter to explore and compare \nthe cotinine measures in the three groups. Are there any \nnotable differences? Are there any outliers? What do you \nconclude about the effects that smokers have on nonsmok-\ners? Write a brief report of your conclusions, and provide \nsupporting statistical evidence.\nCooperative Group Activities\n1. In-class activity In class, each student should record two pulse rates by counting the num-\nber of heartbeats in 1 minute. The first pulse rate should be measured while the student is \nseated, and the second pulse rate should be measured while the student is standing. Use the \nmethods of this chapter to compare results. Do males and females appear to have different \npulse rates? Do pulse rates measured while seated appear to be different from pulse rates mea-\nsured while standing?\n2. Out-of-class activity Appendix B includes many real and interesting data sets. In each \ngroup of three or four students, select a data set from Appendix B and analyze it using the \nmethods discussed so far in this book. Write a brief report summarizing key conclusions.\n3. Out-of-class activity In each group of three or four students, collect an original data set of \nvalues at the interval or ratio level of measurement. Provide the following: (1) a list of sample \nvalues; (2) printed software results of descriptive statistics and graphs; and (3) a written de-\nscription of the nature of the data, the method of collection, and important characteristics.\n\n118\nBasic Concepts of \nProbability\nAddition Rule and \nMultiplication Rule\nComplements, \nConditional Probability, \nand Bayes’ Theorem\nRisks and Odds\nRates of Mortality, \nFertility, and Morbidity\nCounting\n4-1\n4-2\n4-3\n4-4\n4-5\n4-6\nDrug Testing of Job Applicants\nCHAPTER \nPROBLEM\nProbability\nApproximately 85% of U. S. companies test employees  \nand>or job applicants for drug use. A common and inexpen-\nsive (around $50) urine test is the EMIT (enzyme multiplied \nimmunoassay technique) test, which tests for the presence of \nany of five drugs: marijuana, cocaine, amphetamines, opiates, \nor phencyclidine. Most companies require that positive test \nresults be confirmed by a more reliable GC-MS (gas chroma-\ntography mass spectrometry) test.\nLike nearly all medical tests, drug tests are sometimes \nwrong. Wrong results are of two different types: (1) false posi-\ntive results and (2) false negative results. In today’s society, \nthese terms should be clearly understood. A job applicant or \n4 \n\nemployee who gets a false positive result is someone who \nincorrectly appears to be using drugs when he or she is not \nactually using drugs. This type of mistake can unfairly result in \njob denial or termination of employment.\nAnalyzing the Results\nTable 4-1 includes results from 555 adults in the United States. \nIf one of the subjects from Table 4-1 is randomly selected \nfrom those who do not use drugs, what is the probability of a \nfalse positive result? If one of the subjects from Table 4-1 is \nrandomly selected from those who do not use drugs, what is \nthe probability of a true negative result? We will address such \nquestions in this chapter.\n• Prevalence: Proportion of the population having the condi-\ntion (such as drug use or disease) being considered.\n• False positive: Wrong test result that incorrectly indicates \nthat the subject has a condition when the subject does not \nhave that condition.\n• False negative: Wrong test result that incorrectly indicates \nthat the subject does not have a condition when the subject \ndoes have that condition.\n• True positive: Correct test result that indicates that a \n subject has a condition when the subject does have the \ncondition.\n• True negative: Correct test result that indicates that a sub-\nject does not have a condition when the subject does not \nhave the condition.\n• Test sensitivity: The probability of a true positive test \n result, given that the subject actually has the condition \n being tested.\n• Test specificity: The probability of a true negative test \n result, given that the subject does not have the condition \nbeing tested.\n• Positive predictive value: Probability that a subject actu-\nally has the condition, given that the test yields a positive \nresult (indicating that the condition is present).\n• Negative predictive value: Probability that the subject \ndoes not actually have the condition, given that the test \nyields a negative result (indicating that the condition is not \npresent).\nChapter Objectives \n119\nTABLE 4-1 Results from Drug Tests of Job Applicants\nPositive Test Result \n(Test shows drug use.)\nNegative Test Result \n(Test shows no drug use.)\nSubject Uses Drugs\n45\n(True Positive)\n5\n(False Negative)\nSubject Does Not Use Drugs\n25\n(False Positive)\n480\n(True Negative)\nThe main objective of this chapter is to develop a sound understanding of probability \nvalues, because those values constitute the underlying foundation on which methods \nof inferential statistics are built. The important methods of hypothesis testing com-\nmonly use P-values, which are probability values expressed as numbers between 0 \nand 1, inclusive. Smaller probability values, such as 0.01, correspond to events that \nare very unlikely. Larger probability values, such as 0.99, correspond to events that are \nvery likely. Here are the chapter objectives:\nBasic Concepts of Probability\n• Identify probabilities as values between 0 and 1, and interpret those values as \n expressions of likelihood of events.\n• Develop the ability to calculate probabilities of events.\n• Define the complement of an event and calculate the probability of that \n complement.\n4-1\nCHAPTER OBJECTIVES\n>>>\n\n120 \nCHAPTER 4 Probability\nKey Concept The single most important objective of this section is to learn how to \ninterpret probability values, which are expressed as values between 0 and 1. A small \nprobability, such as 0.001, corresponds to an event that rarely occurs.\nRole of Probability in Statistics\nProbability plays a central role in the important statistical method of hypothesis \ntesting introduced later in Chapter 8. Statisticians make decisions using data by \nrejecting explanations (such as chance) based on very low probabilities. See the \nfollowing example illustrating the role of probability and a fundamental way that \nstatisticians think.\n4-1 \nBasic Concepts of Probability\nAddition Rule and Multiplication Rule\n• Develop the ability to calculate the probability that in a single trial, some event A oc-\ncurs or some event B occurs or they both occur. Apply the addition rule by correctly \nadjusting for events that are not disjoint (or are overlapping).\n• Develop the ability to calculate the probability of an event A occurring in a first trial \nand an event B occurring in a second trial. Apply the multiplication rule by adjusting \nfor events that are not independent.\n• Distinguish between independent events and dependent events.\nComplements, Conditional Probability, and Bayes’ Theorem\n• Compute the probability of “at least one” occurrence of an event A.\n• Apply the multiplication rule by computing the probability of some event, given that \nsome other event has already occurred.\nRisks and Odds\n• Compare two probabilities using measures of absolute risk reduction and  \nrelative risk.\n• Obtain a measure of risk by calculating the odds ratio.\n• Measure the practical effectiveness of a treatment by determining the “number \nneeded to treat,” which is the number of subjects that must be treated in order to \nprevent one occurrence of some event.\nRates of Mortality, Fertility, and Morbidity\n• Use rates to describe the likelihood of an event.\n• Determine mortality rates, fertility rates, and morbidity rates.\nCounting\n• Develop the ability to apply the fundamental counting rule, factorial rule, permuta-\ntions rule, and combinations rule.\n• Distinguish between circumstances requiring the permutations rule and those \n requiring the combinations rule.\n4-2\n4-3\n4-4\n4-5\n4-6\nAddition Rule and Multiplication Rule\n• Develop the ability to calculate the probability that in a single trial, some event A oc-\ncurs or some event B occurs or they both occur. Apply the addition rule by correctly\nadjusting for events that are not disjoint (or are overlapping).\n• Develop the ability to calculate the probability of an event A occurring in a first trial\nand an event B occurring in a second trial. Apply the multiplication rule by adjusting\nfor events that are not independent.\n• Distinguish between independent events and dependent events.\nComplements, Conditional Probability, and Bayes’ Theorem\n• Compute the probability of “at least one” occurrence of an event A.\n• Apply the multiplication rule by computing the probability of some event, given that\nsome other event has already occurred.\nRisks and Odds\n• Compare two probabilities using measures of absolute risk reduction and  \nrelative risk.\n• Obtain a measure of risk by calculating the odds ratio.\n• Measure the practical effectiveness of a treatment by determining the “number \nneeded to treat,” which is the number of subjects that must be treated in order to\nprevent one occurrence of some event.\nRates of Mortality, Fertility, and Morbidity\n• Use rates to describe the likelihood of an event.\n• Determine mortality rates, fertility rates, and morbidity rates.\nCounting\n• Develop the ability to apply the fundamental counting rule, factorial rule, permuta-\ntions rule, and combinations rule.\n• Distinguish between circumstances requiring the permutations rule and those\nrequiring the combinations rule.\n\n4-1 Basic Concepts of Probability \n121\nINTERPRETATION\nAmong the 100 babies, 75 girls and 55 girls are both greater than the 50 girls that \nwe typically expect, but only the event of 75 girls leads us to believe that the gender \nselection method is effective. Even though there is a chance of getting 75 girls (or \nmore) in 100 births with no special treatment, the probability of that happening is so \nsmall (0.0000003) that we should reject chance as a reasonable explanation. Instead, \nit would be generally recognized that the results provide strong support for the claim \nthat the gender selection method is effective. This is exactly how statisticians think: \nThey reject explanations (such as chance) based on very low probabilities.\nEXAMPLE 1  Analyzing a Claim\nResearchers have made this claim (really, they have):\nClaim: “We have developed a gender selection method that greatly increases \nthe likelihood of a baby being a girl.”\nHypothesis Used When Testing the Preceding Claim: The method of gender \nselection has no eﬀect, so that for couples using this method, about 50% of the \nbirths result in girls.\n(The probability of a girl in the United States is actually 0.488, but here we assume \nthat boys and girls are equally likely.)\nFigure 4-1 shows the sample data from two tests of 100 couples using the \n gender selection method and the conclusion reached for each test.\n75\nGirls\nStatisticians reject explanations based on\nvery low probabilities\nTest A Result\nProbability of 75 (or more) Girls by\nchance 5 3 in 10,000,000\n5 0.0000003\nChance rejected as\nreasonable explanation\nGender selection method\nappears to be eﬀective\n25\nBoys\n55\nGirls\nTest B Result\nProbability of 55 (or more) Girls by\nchance 5 184 in 1,000\n5 0.184\nChance not rejected as\nreasonable explanation\nCannot conclude gender\nselection method is eﬀective\n45\nBoys\nDiﬀerent Gender Selection Methods\nTested with 100 Births\nFIGURE 4-1 Gender Selection Method Test Data and Conclusions\nBasics of Probability\nIn probability, we deal with procedures (such as generating male>female births or \nmanufacturing defective>nondefective pregnancy test kits) that produce outcomes.\nProbabilities That \nChallenge Intuition\nIn certain cases, \nour subjective \nestimates of \nprobability val-\nues are dramati-\ncally different \nfrom the actual \nprobabilities. \nHere is a classical example: If \nyou take a deep breath, there is \nbetter than a 99% chance that \nyou will inhale a molecule that \nwas exhaled in dying Caesar’s \nlast breath. In that same morbid \nand unintuitive spirit, if Socrates’ \nfatal cup of hemlock was mostly \nwater, then the next glass of \nwater you drink will likely contain \none of those same molecules. \nHere’s another, less morbid \nexample that can be verified: In \nclasses of 25 students, there is \nbetter than a 50% chance that \nat least 2 students will share the \nsame birthday (day and month).\n\n122 \nCHAPTER 4 Probability\nExample 2 illustrates the concepts defined above.\nDEFINITIONS\nAn event is any collection of results or outcomes of a procedure.\nA simple event is an outcome or an event that cannot be further broken down into \nsimpler components.\nThe sample space for a procedure consists of all possible simple events. That is, \nthe sample space consists of all outcomes that cannot be broken down any further.\nEXAMPLE 2  Simple Event and Sample Spaces\nIn the following display, we use “b” to denote a baby boy and “g” to denote a \nbaby girl.\n \nProcedure\n \nExample of Event\nSample Space: Complete \nList of Simple Events\nSingle birth\n1 girl (simple event)\n{b, g}\n3 births\n2 boys and 1 girl (bbg, \nbgb, and gbb are all \nsimple events resulting in \n2 boys and 1 girl)\n{bbb, bbg, bgb, bgg, gbb, \ngbg, ggb, ggg}\nSimple Events:\n \n■With one birth, the result of 1 girl is a simple event and the result of 1 boy is \nanother simple event. They are individual simple events because they cannot be \nbroken down any further.\n \n■With three births, the result of 2 girls followed by a boy (ggb) is a simple event.\n \n■When rolling a single die, the outcome of 5 is a simple event, but the outcome \nof an even number is not a simple event.\nNot a Simple Event: With three births, the event of “2 girls and 1 boy” is not  \na simple event because it can occur with these diﬀerent simple events: ggb,  \ngbg, bgg.\nSample Space: With three births, the sample space consists of the eight  diﬀerent \nsimple events listed in the above table.\nThree Common Approaches to Finding the Probability of an Event\nWe first list some basic notation, and then we present three common approaches to \nfinding the probability of an event.\nNotation for Probabilities\nP denotes a probability.\nA, B, and C denote specific events.\nP(A) denotes the “probability of event A occurring.”\nThe following three approaches for finding probabilities result in values between 0 \nand 1: 0 … P1A2 … 1. Figure 4-2 shows the possible values of probabilities and the \nmore familiar and common expressions of likelihood.\nCertain\nLikely\n50–50 Chance\nUnlikely\nImpossible\n0\n0.5\n1\nFIGURE 4-2 Possible \nValues for Probabilities\n\n4-1 Basic Concepts of Probability \n123\n1. Relative Frequency Approximation of Probability Conduct (or observe) a \nprocedure and count the number of times that event A occurs. P(A) is then ap-\nproximated as follows:\nP1A2 =\nnumber of times A occurred\nnumber of times the procedure was repeated\nWhen referring to relative frequency approximations of probabilities, this text \nwill not distinguish between results that are exact probabilities and those that \nare approximations, so an instruction to “find the probability” could actually \nmean “estimate the probability.”\n2. Classical Approach to Probability (Requires Equally Likely Outcomes) \nIf a procedure has n different simple events that are equally likely, and if \nevent A can occur in s different ways, then\nP1A2 =\nnumber of ways A occurs\nnumber of different simple events = s\nn\nCAUTION When using the classical approach, always confirm that the outcomes \nare equally likely.\n3. Subjective Probabilities P(A), the probability of event A, is estimated by \nusing knowledge of the relevant circumstances.\nFigure 4-3 illustrates the approaches of the preceding three definitions.\n1. Relative Frequency Approach: When trying to de-\ntermine the probability that an individual car crashes in a \nyear, we must examine past results to determine the num-\nber of cars in use in a year and the number of them that \ncrashed; then we ﬁnd the ratio of the number of cars that \ncrashed to the total number of cars. For a recent year, the \nresult is a probability of 0.0480. (See Example 3.)\n2. Classical Approach: When trying to determine the \nprobability of randomly selecting three children who are \nof the same gender, there are two ways to get the same \ngenders (boy/boy/boy and girl/girl/girl) among the eight \nequally likely outcomes, so the probability is 2/8 or 1/4. \n(See Example 4.)\n3. Subjective Probability: When trying to estimate the \nprobability of someone with an appendix getting acute \nappendicitis in the next year, we know from personal ex-\nperience that the probability is quite small. Let’s estimate \nit to be, say, 0.001 (equivalent to 1 chance in 1000). (See \nExample 5.)\nFIGURE 4-3 Three Approaches to Finding a Probability\n\n124 \nCHAPTER 4 Probability\nSimulations Sometimes none of the preceding three approaches can be used. A simu-\nlation of a procedure is a process that behaves in the same ways as the procedure itself \nso that similar results are produced. Probabilities can sometimes be found by using a \nsimulation. See the Technology Project near the end of this chapter.\nRounding Probabilities Although it is difficult to develop a universal rule for round-\ning off probabilities, the following guide will apply to most problems in this text.\nROUNDING PROBABILITIES\nWhen expressing the value of a probability, either give the exact fraction or deci-\nmal or round off final decimal results to three significant digits. (Suggestion: When \na probability is not a simple fraction such as 2>3 or 5>9, express it as a decimal so \nthat the number can be better understood.) All digits in a number are significant ex-\ncept for the zeros that are included for proper placement of the decimal point. See \nthe following examples.\n \n■The probability of 0.4450323339 (from Example 6) has ten significant digits \n(4450323339), and it can be rounded to three significant digits as 0.445.\n \n■The probability of 1>3 can be left as a fraction or rounded to 0.333. (Do not \nround to 0.3.)\n \n■The probability of 2>8 can be expressed as 1>4 or 0.25. (Because 0.25 is exact, \nthere’s no need to express it with three significant digits as 0.250.)\nProbabilities Expressed as Percentages? Mathematically, a probability of 0.25 is \nequivalent to 25%, but there are good reasons for sticking with fractions and decimals \nand not using percentages. Professional journals almost universally express probabili-\nties as decimals, not as percentages. Later in this book, we will use probability values \ngenerated from statistical software, and they will always be in the form of decimals.\nWhen finding probabilities with the relative frequency approach, we obtain an ap-\nproximation instead of an exact value. As the total number of observations increases, \nthe corresponding approximations tend to get closer to the actual probability. This \nproperty is commonly referred to as the law of large numbers.\nLAW OF LARGE NUMBERS\nAs a procedure is repeated again and again, the relative frequency probability of \nan event tends to approach the actual probability.\nThe law of large numbers tells us that relative frequency approximations tend to get \nbetter with more observations. This law reflects a simple notion supported by common \nsense: A probability estimate based on only a few trials can be off by a substantial amount, \nbut with a very large number of trials, the estimate tends to be much more accurate.\nCAUTIONS\n1.  The law of large numbers applies to behavior over a large number of trials, and it \ndoes not apply to any one individual outcome. Gamblers sometimes foolishly lose \nlarge sums of money by incorrectly thinking that a string of losses increases the \nchances of a win on the next bet, or that a string of wins is likely to continue.\n2.  If we know nothing about the likelihood of different possible outcomes, we \nshould not assume that they are equally likely. For example, we should not think \nthat the probability of passing the next statistics test is 1>2, or 0.5 (because we \neither pass the test or do not). The actual probability depends on factors such \nas the amount of preparation and the difficulty of the test.\n\n4-1 Basic Concepts of Probability \n125\nEXAMPLE 3  Relative Frequency Probability: Skydiving\nFind the probability of dying when making a skydiving jump.\nSOLUTION\nIn a recent year, there were about 3,000,000 skydiving jumps and 21 of them \n resulted in deaths. We use the relative frequency approach as follows:\nP1skydiving death2 =\nnumber of skydiving deaths\ntotal number of skydiving jumps =\n21\n3,000,0000 = 0.000007\nHere the classical approach cannot be used because the two outcomes (dying, \n surviving) are not equally likely. A subjective probability can be estimated in the \nabsence of historical data.\nEXAMPLE 4   Classical Probability: Three Children of the  \nSame Gender\nWhen three children are born, the sample space of genders is as shown in Example 1: \n{bbb, bbg, bgb, bgg, gbb, gbg, ggb, ggg}. If boys and girls are equally likely, then \nthose eight simple events are equally likely. Assuming that boys and girls are equally \nlikely, find the probability of getting three children all of the same gender when three \nchildren are born. (In reality, the probability of a boy is 0.512 instead of 0.5.)\nSOLUTION\nThe sample space {bbb, bbg, bgb, bgg, gbb, gbg, ggb, ggg} includes eight equally \nlikely outcomes, and there are exactly two outcomes in which the three children are \nof the same gender: bbb and ggg. We can use the classical approach to get\nP1three children of the same gender2 = 2\n8 = 1\n4  or  0.25\nEXAMPLE 5  Subjective Probability: Acute Appendicitis\nWhat is the probability that you will get acute appendicitis next year?\nSOLUTION\nWe could probably find past results and use the relative frequency approach, but for \nnow, in the absence of historical data on acute appendicitis, we make a subjective \nestimate. Experience suggests that the probability is quite small. Let’s estimate it to \nbe, say, 0.001 (equivalent to 1 chance in 1000). Depending on our knowledge of the \nrelevant circumstances, that subjective estimate might be reasonably accurate or it \nmight be grossly wrong.\nCAUTION Don’t make the common mistake of finding a probability value by \nmindlessly dividing a smaller number by a larger number. Instead, think carefully \nabout the numbers involved and what they represent. Carefully identify the total \nnumber of items being considered, as illustrated in Example 6.\n\n126 \nCHAPTER 4 Probability\nInstead of trying to determine an answer directly from the given statement, first sum-\nmarize the information in a format that allows clear understanding, such as this format:\n 3785 texted while driving\n 4720 did not text while driving\n 8505 total number of drivers in the sample\nWe can now use the relative frequency approach as follows:\n P1texting while driving2 = number of drivers who texted while driving\ntotal number of drivers in the sample\n= 3785\n8505\n = 0.445\nINTERPRETATION\nThere is a 0.445 probability that if a high school driver is randomly selected, he or \nshe texted while driving during the previous 30 days.\nEXAMPLE 6  Texting and Driving\nIn a study of U.S. high school drivers, it was found that 3785 texted while driving \nduring the previous 30 days, and 4720 did not text while driving during that same \ntime period (based on data from “Texting While Driving . . . . ,” by Olsen, Shults, \nEaton, Pediatrics, Vol. 131, No. 6). Based on these results, if a high school driver is \nrandomly selected, find the probability that he or she texted while driving during the \nprevious 30 days.\nSOLUTION\nCAUTION A common mistake is to blindly plug in numbers to get the wrong \nprobability of 3785>4720 = 0.802. We should think about what we are doing, as \nfollows.\nEXAMPLE 7  Thanksgiving Day\nIf a year is selected at random, find the probability that Thanksgiving Day in the \nUnited States will be (a) on a Wednesday or (b) on a Thursday.\nSOLUTION\na. In the United States, Thanksgiving Day always falls on the fourth Thursday  \nin November. It is therefore impossible for Thanksgiving to be on \na  Wednesday. When an event is impossible, its probability is 0. \nP(Thanksgiving on Wednesday) = 0.\nb. It is certain that a Thanksgiving Day in the United States will be on \na  Thursday. When an event is certain to occur, its probability is 1. \nP(Thanksgiving on Thursday) = 1.\nBecause any event imaginable is impossible, certain, or somewhere in between, \nit follows that the mathematical probability of any event A is 0, 1, or a number \nbetween 0 and 1 (as shown in Figure 4-2). That is, 0 … P1A2 … 1.\n\n4-1 Basic Concepts of Probability \n127\nComplementary Events\nSometimes we need to find the probability that an event A does not occur.\nDEFINITION\nThe complement of event A, denoted by A, consists of all outcomes in which event \nA does not occur.\nEXAMPLE 8  Complement of Death from Skydiving\nExample 3 shows that in a recent year, there were 3,000,000 skydiving jumps and \n21 of them resulted in death. Find the probability of not dying when making a \nskydiving jump.\nSOLUTION\nAmong 3,000,000 jumps there were 21 deaths, so it follows that the other 2,999,979 \njumps were survived. We get\nP1not dying when making a skydiving jump2 = 2,999,979\n3,000,000 = 0.999993\nINTERPRETATION\nThe probability of not dying when making a skydiving jump is 0.999993.\nRelationship Between P1A2 and P1A2 If we denote the event of dying in a \n skydiving jump by D, Example 3 showed that P1D2 = 0.000007 and Example 8 \nshowed that P1D2 = 0.999993. The probability of P1D2 could be found by just sub-\ntracting P(D) from 1.\nIdentifying Significant Results with Probabilities:  \nThe Rare Event Rule for Inferential Statistics\nIf, under a given assumption, the probability of a particular observed event is \nvery small and the observed event occurs signiﬁcantly less than or signiﬁcantly \ngreater than what we typically expect with that assumption, we conclude that \nthe assumption is probably not correct.\nWe can use probabilities to identify values that are significantly low or significantly \nhigh as follows.\nUsing Probabilities to Determine When Results Are Significantly High or \nSignificantly Low\n \n■Significantly high number of successes: x successes among n trials is a signifi-\ncantly high number of successes if the probability of x or more successes is un-\nlikely with a probability of 0.05 or less. That is, x is a significantly high number \nof successes if P(x or more) … 0.05.*\n \n■Significantly low number of successes: x successes among n trials is a sig-\nnificantly low number of successes if the probability of x or fewer successes is \nunlikely with a probability of 0.05 or less. That is, x is a significantly low number \nof successes if P(x or fewer) … 0.05.*\n*The value 0.05 is not absolutely rigid. Other values, such as 0.01, could be used to distinguish between results \nthat can easily occur by chance and events that are significant.\n\n128 \nCHAPTER 4 Probability\nSee Example 1 on page 121, which illustrates the following:\n \n■Among 100 births, 75 girls is significantly high because the probability of 75 \nor more girls is 0.0000003, which is less than or equal to 0.05 (so the gender \nselection method appears to be effective).\n \n■Among 100 births, 55 girls is not significantly high because the probability of 55 \nor more girls is 0.184, which is greater than 0.05 (so the gender selection does \nnot appear to be effective).\nProbability Review\nImportant Principles and Notation for Probability\n \n■The probability of an event is a fraction or decimal number between 0 and 1 \ninclusive.\n \n■The probability of an impossible event is 0.\n \n■The probability of an event that is certain to occur is 1.\n \n■Notation: P1A2 = the probability of event A.\n \n■Notation: P1A2 = the probability that event A does not occur.\nStatistical Literacy and Critical Thinking \n1. Probability Rewrite the following statement with the probability expressed as a number \nwith a decimal format: “The probability of selecting someone with blue eyes is 35%.”\n2. Probability Given that the following statement is incorrect, rewrite it correctly: “The prob-\nability of a baby being born a boy is 50-50.”\n3. Births In Example 4 “Three Children of the Same Gender” it was noted that in reality, the \nprobability of a boy is 0.512 instead of 0.5. Let A denote the event of getting a boy when a baby \nis born. What is the value of P1A2?\n4. Subjective Probability Estimate the probability that the next time a physician walks into \na patient’s room and turns on a light switch, she discovers that the light bulb does work.\n5. Identifying Probability Values Which of the following are probabilities?\n0 3>5 5>3 -0.25 250% 7:3 1 50@50 5:1 0.135 2.017\n6. Penicillin “Who discovered penicillin: Sean Penn, William Penn, Penn Jillette, Alexander \nFleming, or Louis Pasteur?” If you make a random guess for the answer to that question, what \nis the probability that your answer is the correct answer of Alexander Fleming?\n7. Avogadro Constant If you are asked on a quiz to give the first (leftmost) nonzero digit \nof the Avogadro constant and, not knowing the answer, you make a random guess, what is the \nprobability that your answer is the correct answer of 6?\n8. Births Example 2 in this section includes the sample space for genders from three births. \nIdentify the sample space for the genders from two births.\nIn Exercises 9–12, assume that 50 births are randomly selected. Use subjective judgment to \ndescribe the given number of girls as (a) significantly low, (b) significantly high, or (c) nei-\nther significantly low nor significantly high.\n9. 47 girls.   10. 26 girls.   11. 23 girls.   12. 5 girls.\n4-1 Basic Skills and Concepts\n\n4-1 Basic Concepts of Probability \n129\nIn Exercises 13–20, express the indicated degree of likelihood as a probability value \nbetween 0 and 1.\n13. Testing If you make a random guess for the answer to a true>false test question, there is a \n50-50 chance of being correct.\n14. MCAT Test When making a random guess for an answer to a multiple-choice question on \nan MCAT test, the possible answers are a, b, c, d, e, so there is 1 chance in 5 of being correct.\n15. Genes One of the four DNA bases of A, G, C, and T is randomly selected, and the result is \nG. Assume that the four DNA bases are equally likely.\n16. Sleepwalking Based on a report in Neurology magazine, 29.2% of survey respondents \nhave sleepwalked.\n17. Randomness When using a computer to randomly generate the last digit of a phone \nnumber to be called for a survey, there is 1 chance in 10 that the last digit is zero.\n18.  Job Applicant Mistakes Based on an Adecco survey of hiring managers who were \nasked to identify the biggest mistakes that job candidates make during an interview, there is a \n50-50 chance that they will identify “inappropriate attire.”\n19. Square Peg Sydney Smith wrote in “On the Conduct of the Understanding” that it is im-\npossible to fit a square peg in a round hole.\n20. Death and Taxes Benjamin Franklin said that death is a certainty of life.\nIn Exercises 21–24, refer to the sample data in Table 4-1, which is included with the \n Chapter Problem. Assume that 1 of the 555 subjects included in Table 4-1 is randomly selected.\nTABLE 4-1 Results from Drug Tests of Job Applicants\nPositive Test Result \n(Test shows drug use.)\nNegative Test Result\n(Test shows no drug use.)\nSubject Uses Drugs\n45\n(True Positive)\n5\n(False Negative)\nSubject Does Not Use Drugs\n25\n(False Positive)\n480\n(True Negative)\n21. Drug Testing Job Applicants Find the probability of selecting someone who got a re-\nsult that is a false negative. Who would suffer from a false negative result? Why?\n22. Drug Testing Job Applicants Find the probability of selecting someone who got a re-\nsult that is a false positive. Who would suffer from a false positive result? Why?\n23.  Drug Testing Job Applicants Find the probability of selecting someone who uses \ndrugs. Does the result appear to be reasonable as an estimate of the “prevalence rate” described \nin the Chapter Problem?\n24. Drug Testing Job Applicants Find the probability of selecting someone who does not \nuse drugs. Does the result appear to be reasonable as an estimate of the proportion of the adult \npopulation that does not use drugs?\nIn Exercises 25–32, find the probability and answer the questions.\n25. XSORT Gender Selection MicroSort’s XSORT gender selection technique was designed \nto increase the likelihood that a baby will be a girl. At one point before clinical trials of the \nXSORT gender selection technique were discontinued, 945 births consisted of 879 baby girls \nand 66 baby boys (based on data from the Genetics & IVF Institute). Based on these results, \nwhat is the probability of a girl born to a couple using MicroSort’s XSORT method? Does it ap-\npear that the technique is effective in increasing the likelihood that a baby will be a girl?\n\n130 \nCHAPTER 4 Probability\n26.  YSORT Gender Selection MicroSort’s YSORT gender-selection technique is de-\nsigned to increase the likelihood that a baby will be a boy. At one point before clinical trials \nof the YSORT gender-selection technique were discontinued, 291 births consisted of 239 \nbaby boys and 52 baby girls (based on data from the Genetics & IVF Institute). Based on \nthese results, what is the probability of a boy born to a couple using MicroSort’s YSORT \nmethod? Does it appear that the technique is effective in increasing the likelihood that a baby \nwill be a boy?\n27. Mendelian Genetics When Mendel conducted his famous genetics experiments with \npeas, one sample of offspring consisted of 428 green peas and 152 yellow peas. Based on those \nresults, estimate the probability of getting an offspring pea that is green. Is the result reasonably \nclose to the expected value of 3>4, as Mendel claimed?\n28. Guessing Birthdays On their first date, Kelly asks Mike to guess the date of her birth, \nnot including the year.\na. What is the probability that Mike will guess correctly? (Ignore leap years.)\nb. Would it be unlikely for him to guess correctly on his first try?\nc. If you were Kelly, and Mike did guess correctly on his first try, would you believe his claim \nthat he made a lucky guess, or would you be convinced that he already knew when you were \nborn?\nd. If Kelly asks Mike to guess her age, and Mike’s guess is too high by 15 years, what is the \nprobability that Mike and Kelly will have a second date?\n29. Online Medicine In a survey, 933 respondents say that they seek medical information \nonline and 139 other respondents say that they never seek medical information online. What is \nthe probability that a randomly selected person never seeks medical information online? Is it \nunlikely for someone to never seek medical information online? How are these results affected \nby the fact that the responses are from subjects who decided to respond to the survey posted on \nthe Internet by AOL?\n30. Car Rollovers In a recent year in the United States, 83,600 passenger cars rolled over \nwhen they crashed, and 5,127,400 passenger cars did not roll over when they crashed. Find the \nprobability that a randomly selected passenger car crash results in a rollover. Is it unlikely for a \ncar to roll over in a crash?\n31. Genetics: Eye Color Each of two parents has the genotype brown>blue, which con-\nsists of the pair of alleles that determine eye color, and each parent contributes one of those \nalleles to a child. Assume that if the child has at least one brown allele, that color will domi-\nnate and the eyes will be brown. (The actual determination of eye color is more complicated \nthan that.)\na. List the different possible outcomes. Assume that these outcomes are equally likely.\nb. What is the probability that a child of these parents will have the blue>blue genotype?\nc. What is the probability that the child will have brown eyes?\n32. X-Linked Genetic Disease Men have XY (or YX) chromosomes and women have XX \nchromosomes. X-linked recessive genetic diseases (such as juvenile retinoschisis) occur when \nthere is a defective X chromosome that occurs without a paired X chromosome that is not defec-\ntive. In the following, represent a defective X chromosome with lowercase x, so a child with the \nxY or Yx pair of chromosomes will have the disease and a child with XX or XY or YX or xX or \nXx will not have the disease. Each parent contributes one of the chromosomes to the child.\na. If a father has the defective x chromosome and the mother has good XX chromosomes, \nwhat is the probability that a son will inherit the disease?\nb. If a father has the defective x chromosome and the mother has good XX chromosomes, \nwhat is the probability that a daughter will inherit the disease?\ncontinued\n\n4-2 Addition Rule and Multiplication Rule \n131\nc. If a mother has one defective x chromosome and one good X chromosome and the father \nhas good XY chromosomes, what is the probability that a son will inherit the disease?\nd. If a mother has one defective x chromosome and one good X chromosome and the father \nhas good XY chromosomes, what is the probability that a daughter will inherit the disease?\nProbability from a Sample Space. In Exercises 33–36, use the given sample space or \nconstruct the required sample space to find the indicated probability.\n33. Three Children Use this sample space listing the eight simple events that are possible when \na couple has three children (as in Example 2 on page 122): {bbb, bbg, bgb, bgg, gbb, gbg, ggb, \nggg}. Assume that boys and girls are equally likely, so that the eight simple events are equally \nlikely. Find the probability that when a couple has three children, there is exactly one girl.\n34. Three Children Using the same sample space and assumption from Exercise 33, find the \nprobability that when a couple has three children, there are exactly two girls.\n35. Four Children Exercise 33 lists the sample space for a couple having three children. After \nidentifying the sample space for a couple having four children, find the probability of getting \nthree girls and one boy (in any order).\n36. Four Children Using the same sample space and assumption from Exercise 35, find the \nprobability that when a couple has four children, all four are of the same gender.\nUsing Probability to Form Conclusions. In Exercises 37–40, use the given probability value \nto determine whether the sample results could easily occur by chance, then form a conclusion.\n37. Predicting Gender A study addressed the issue of whether pregnant women can cor-\nrectly predict the gender of their baby. Among 104 pregnant women, 57 correctly predicted the \ngender of their baby (based on data from “Are Women Carrying ‘Basketballs’…,” by Perry, \nDiPietro, Constigan, Birth, Vol. 26, No. 3). If pregnant women have no such ability, there is a \n0.327 probability of getting such sample results by chance. What do you conclude?\n38. Clinical Trial of Tamiflu Clinical trials involved the use of Tamiflu (oseltamivir phos-\nphate) for treating flu patients. Among 724 patients treated with Tamiflu, 72 (or about 10%) \nexperienced nausea. (An untreated group experienced a 6% rate of nausea.) If Tamiflu really \nhas no effect on nausea, there is a 0.00000246 probability of getting these sample results by \nchance. What do you conclude about the effect of Tamiflu on nausea?\n39. Sleepiness In a clinical trial of OxyContin (oxycodone) used for pain relief, 227 sub-\njects were treated with OxyContin and 52 of them experienced sleepiness (based on data from \nPurdue Pharma L.P.). If OxyContin has no effect on sleepiness, the probability of getting these \nsample results by chance is less than 0.001 (when comparing this sample group with another \ngroup not treated with OxyContin). What do you conclude?\n40. Cell Phones and Cancer A study of 420,095 Danish cell phone users resulted in 135 \nwho developed cancer of the brain or nervous system (based on data from the Journal of the \nNational Cancer Institute). When comparing this sample group to another group of people who \ndid not use cell phones, it was found that there is a probability of 0.512 of getting such sample \nresults by chance. What do you conclude?\nKey Concepts In this section we present the addition rule as a tool for finding \nP(A or B), which is the probability that either event A occurs or event B occurs (or they \nboth occur) as the single outcome of a procedure. To find P(A or B), we begin by add-\ning the number of ways that A can occur and the number of ways that B can occur, but \nadd without double counting. The word “or” in the addition rule is associated with the \naddition of probabilities.\n4-2 \nAddition Rule and Multiplication Rule\n\n132 \nCHAPTER 4 Probability\nThis section also presents the basic multiplication rule used for finding P(A and B), \nwhich is the probability that event A occurs and event B occurs. If the outcome of \nevent A somehow affects the probability of event B, it is important to adjust the prob-\nability of B to reflect the occurrence of event A. The rule for finding P(A and B) is \ncalled the multiplication rule because it involves the multiplication of the probability \nof event A and the probability of event B (where, if necessary, the probability of event \nB is adjusted because of the outcome of event A). The word “and” in the multiplica-\ntion rule is associated with the multiplication of probabilities.\nIn Section 4-1 we considered only simple events, but in this section we consider \ncompound events.\nDEFINITION\nA compound event is any event combining two or more simple events.\nAddition Rule\nNotation for Addition Rule\nP1A or B2 = P1in a single trial, event A occurs or event B occurs or they \nboth occur2\nThe word “or” used in the preceding notation is the inclusive or, which means ei-\nther one or the other or both. The formal addition rule is often presented as a formula, \nbut blind use of formulas is not recommended. Instead, understand the spirit of the \nrule and use that understanding, as in the intuitive addition rule that follows.\nINTUITIVE ADDITION RULE\nTo find P(A or B), add the number of ways event A can occur and the number of \nways event B can occur, but add in such a way that every outcome is counted only \nonce. P(A or B) is equal to that sum, divided by the total number of outcomes in the \nsample space.\nFORMAL ADDITION RULE\nP1A or B2 = P1A2 + P1B2 - P1A and B2\nwhere P(A and B) denotes the probability that A and B both occur at the same time \nas an outcome in a trial of a procedure.\nOne way to apply the addition rule is to add the probability of event A and the \nprobability of event B and, if there is any overlap that causes double-counting, com-\npensate for it by subtracting the probability of outcomes that are included twice. This \napproach is reflected in the above formal addition rule.\nEXAMPLE 1  Drug Testing of Job Applicants\nRefer to Table 4-1, reproduced here for your convenience and viewing pleasure. \nIf 1 subject is randomly selected from the 555 subjects given a drug test, find the \nprobability of selecting a subject who had a positive test result or uses drugs.\nw\nev\nab\nProportions of  \nMales, Females\nIt is well \nknown that \nwhen a baby is \nborn, boys and \ngirls are not \nequally likely. It \nis currently be-\nlieved that 105 boys are born for \nevery 100 girls, so the probability \nof a boy is 0.512. Kristen Navara \nof the University of Georgia \nconducted a study showing that \naround the world, more boys are \nborn than girls, but the difference \nbecomes smaller as people are \nlocated closer to the equator. \nShe used latitudes, tempera-\ntures, unemployment rates, and \ngross national products from \n200 countries and conducted a \nstatistical analysis showing that \nthe proportions of boys appear \nto be affected only by latitude \nand its related weather. So far, no \none has identified a reasonable \nexplanation for this phenomenon.\n\n4-2 Addition Rule and Multiplication Rule \n133\nDisjoint Events and the Addition Rule\nThe addition rule is simplified when the events are disjoint.\nTABLE 4-1 Results from Drug Tests of Job Applicants\nPositive Test Result\n(Test shows drug use.)\nNegative Test Result\n(Test shows no drug use.)\nSubject Uses Drugs\n45\n(True Positive)\n5\n(False Negative)\nSubject Does Not Use Drugs\n25\n(False Positive)\n480\n(True Negative)\n*Numbers in red correspond to positive test results or subjects who use drugs, and the total of  \nthose numbers is 75.\nSOLUTION\nRefer to Table 4-1 and carefully count the number of subjects who tested positive \n(first column) or use drugs (first row), but be careful to count subjects exactly once, \nnot twice. When adding the frequencies from the first column and the first row, \ninclude the frequency of 45 only once. In Table 4-1, there are 45 + 25 + 5 = 75 \nsubjects who had positive test results or use drugs. We get this result:\nP1positive test result or subject uses drugs2 = 75>555 = 0.135\nDEFINITION\nEvents A and B are disjoint (or mutually exclusive) if they cannot occur at the \nsame time. (That is, disjoint events do not overlap.)\nEXAMPLE 2  Disjoint Events\nDisjoint events:\nEvent A—Randomly selecting someone \nfor a clinical trial who is a male\nEvent B—Randomly selecting someone \nfor a clinical trial who is a female\n(The selected person cannot be both.)\nEvents that are not disjoint:\nEvent A—Randomly selecting someone \ntaking a statistics course\nEvent B—Randomly selecting someone \nwho is a female\n(The selected person can be both.)\nWhenever A and B are disjoint, P(A and B) becomes zero in the formal addition \nrule, so for disjoint events A and B we have P1A or B2 = P1A2 + P1B2. But again, \ninstead of blind use of a formula, it is better to understand and use the intuitive addi-\ntion rule.\nHere is a summary of the key points of the addition rule:\n1. To find P(A or B), first associate the word or with addition.\n2. To find the value of P(A or B), add the number of ways A can occur and the \nnumber of ways B can occur, but be careful to add without double counting.\n\n134 \nCHAPTER 4 Probability\nComplementary Events and the Addition Rule\nIn Section 4-1 we used A to indicate that event A does not occur. Common sense dic-\ntates this principle: We are certain (with probability 1) that either an event A occurs or \nit does not occur, so it follows that P1A or A2 = 1. Because events A and A must be \ndisjoint, we can use the addition rule to express this principle as follows:\nP1A or A2 = P1A2 + P1A2 = 1\nThis result of the addition rule leads to the following three expressions that are “equiv-\nalent” in the sense that they are just different forms of the same principle.\nRULE OF COMPLEMENTARY EVENTS\nP1A2 + P1A2 = 1   P1A2 = 1 - P1A2  P1A2 = 1 - P1A2\nEXAMPLE 3  Sleepwalking\nBased on a journal article, the probability of randomly selecting someone who has \nsleepwalked is 0.292, so P(sleepwalked) = 0.292 (based on data from “Prevalence \nand Comorbidity of Nocturnal Wandering in the U.S. General Population,” by \nOhayon et al., Neurology, Vol. 78, No. 20). If a person is randomly selected, find the \nprobability of getting someone who has not sleepwalked.\nSOLUTION\nUsing the rule of complementary events, we get\nP1has not sleepwalked2 = 1 - P1sleepwalked2 = 1 - 0.292 = 0.708\nThe probability of randomly selecting someone who has not sleepwalked is 0.708.\nMultiplication Rule\nNotation for Multiplication Rule\nWe begin with basic notation followed by the multiplication rule. We strongly suggest \nusing the intuitive multiplication rule, because it is based on understanding instead of \nblind use of a formula.\nNotation\nP1A and B2 = P1event A occurs in one trial and event B occurs in a  \n      different trial2\nP1B\u001eA2 represents the probability of event B occurring after it is assumed that \nevent A has already occurred. (Interpret B\u001eA as “event B occurs after event A has \nalready occurred.”)\nCAUTION The notation P(A and B) has two meanings, depending on its context. \nFor the multiplication rule, P(A and B) denotes that event A occurs in one trial and \nevent B occurs in another trial; for the addition rule we use P(A and B) to denote \nthat events A and B both occur in the same trial.\n\n4-2 Addition Rule and Multiplication Rule \n135\nINTUITIVE MULTIPLICATION RULE\nTo find the probability that event A occurs in one trial and event B occurs in an-\nother trial, multiply the probability of event A by the probability of event B, but be \nsure that the probability of event B is found by assuming that event A has already \noccurred.\nFORMAL MULTIPLICATION RULE\nP1A and B2 = P1A2 # P1B\u001e A2\nIndependence and the Multiplication Rule\nWhen applying the multiplication rule and considering whether the probability of \nevent B must be adjusted to account for the previous occurrence of event A, we are \nfocusing on whether events A and B are independent.\nDEFINITIONS\nTwo events A and B are independent if the occurrence of one does not affect the \nprobability of the occurrence of the other. (Several events are independent if the \noccurrence of any does not affect the probabilities of the occurrence of the oth-\ners.) If A and B are not independent, they are said to be dependent.\nCAUTION Don’t think that dependence of two events means that one is the direct \ncause of the other. Having a working light in your kitchen and having a working \nlight in your bedroom are dependent events because they share the same power \nsource. One of the lights may stop working for many reasons, but if one light is out, \nthere is a higher probability that the other light will be out (because of the common \npower source).\nExample 4 illustrates the basic multiplication rule, with independent events in part (a) \nand dependent events in part (b).\nEXAMPLE 4  Drug Screening and the Basic Multiplication Rule\nLet’s use only the 50 test results from the subjects who use drugs (from Table 4-1), \nas shown below:\nPositive Test Results: \n45\nNegative Test Results: \n5\nTotal: \n50\na. If 2 of these 50 subjects are randomly selected with replacement, ﬁnd the \n probability that the ﬁrst selected person had a positive test result and the sec-\nond selected person had a negative test result.\n \nb. Repeat part (a) by assuming that the two subjects are selected without \n replacement.\ncontinued\n\n136 \nCHAPTER 4 Probability\nThe key point of part (b) in Example 4 is this: We must adjust the probability of the \nsecond event to reflect the outcome of the first event. Because selection of the second \nsubject is made without replacement of the first subject, the second probability must \ntake into account the fact that the first selection removed a subject who tested positive, \nso only 49 subjects are available for the second selection, and 5 of them had a negative \ntest result. Part (a) of Example 4 involved sampling with replacement, so the events \nare independent; part (b) of Example 4 involved sampling without replacement, so the \nevents are dependent. See the following.\nSampling In the wonderful world of statistics, sampling methods are critically impor-\ntant, and the following relationships hold:\n \n■Sampling with replacement: Selections are independent events.\n \n■Sampling without replacement: Selections are dependent events.\nException: Treating Dependent Events as Independent\nSome cumbersome calculations can be greatly simplified by using the common prac-\ntice of treating events as independent when small samples are drawn without replace-\nment from large populations. (In such cases, it is rare to select the same item twice.) \nHere is a common guideline routinely used with applications such as analyses of sur-\nvey results:\nTREATING DEPENDENT EVENTS AS INDEPENDENT:  \n5% GUIDELINE FOR CUMBERSOME CALCULATIONS\nWhen sampling without replacement and the sample size is no more than 5% of the \nsize of the population, treat the selections as being independent (even though they \nare actually dependent).\nSOLUTION\na. With Replacement: First selection (with 45 positive results among 50 total \nresults):\nP1positive test result2 = 45\n50\nSecond selection (with 5 negative test results among the same 50 total results):\nP1negative test result2 = 5\n50\nWe now apply the multiplication rule as follows:\nP11st selection is positive and 2nd is negative2 = 45\n50 # 5\n50 = 0.0900\nb. Without Replacement: Without replacement of the ﬁrst subject, the calcula-\ntions are the same as in part (a), except that the second probability must be \nadjusted to reﬂect the fact that the ﬁrst selection was positive and is not avail-\nable for the second selection. After the ﬁrst positive result is selected, we have \n49 test results remaining, and 5 of them are negative. The second probability \nis therefore 5>49, as shown below:\nP11st selection is positive and 2nd is negative2 = 45\n50 # 5\n49 = 0.0918\n\n4-2 Addition Rule and Multiplication Rule \n137\nExample 5 illustrates use of the 5% guideline for cumbersome calculations and it also \nillustrates that the basic multiplication rule extends easily to three or more events.\nEXAMPLE 5   Drug Screening and the 5% Guideline for  \nCumbersome Calculations\nAssume that three adults are randomly selected without replacement from the \n247,436,830 adults in the United States. Also assume that 10% of adults in the United \nStates use drugs. Find the probability that the three selected adults all use drugs.\nSOLUTION\nBecause the three adults are randomly selected without replacement, the three \nevents are dependent, but here we can treat them as being independent by applying \nthe 5% guideline for cumbersome calculations. The sample size of 3 is clearly no \nmore than 5% of the population size of 247,436,830. We get\n P1all 3 adults use drugs2 = P1first uses drugs and second uses drugs and\n third uses drugs2\n = P1first uses drugs2 #  P1second uses drugs2 #  \nP1third uses drugs2\n = 10.10210.10210.102 = 0.00100\nThere is a 0.00100 probability that all three selected adults use drugs.\nCAUTION In any probability calculation, it is extremely important to carefully \nidentify the event being considered. See Example 6, where parts (a) and (b) might \nseem quite similar but their solutions are very different.\nEXAMPLE 6  Birthdays\nWhen two different people are randomly selected from those in your class, find the \nindicated probability by assuming that birthdays occur on the days of the week with \nequal frequencies.\n \na. Find the probability that the two people are born on the same day of the week.\n \nb. Find the probability that the two people are both born on Monday.\nIn Example 5, if we treat the events as dependent without using the 5% guideline, \nwe get the following cumbersome calculation that begins with 247,436,830 adults, \nwith 10% of them (or 24,743,683) using drugs:\n a 24,743,683\n247,436,830ba 24,743,682\n247,436,829ba 24,743,681\n247,436,828b = 0.0009999998909\n = 0.00100 1rounded2\nJust imagine randomly selecting 1000 adults instead of just 3, as is commonly done \nin typical polls. Extending the above calculation to include 1000 factors instead of 3 \nfactors would be what statisticians refer to as “painful.”\ncontinued\n\n138 \nCHAPTER 4 Probability\nRedundancy: Important Application of Multiplication Rule\nThe principle of redundancy is used to increase the reliability of many systems. Our \neyes have passive redundancy in the sense that if one of them fails, we continue to see. \nAn important finding of modern biology is that genes in an organism can often work \nin place of each other. Engineers often design redundant components so that the whole \nsystem will not fail because of the failure of a single component, as in the following \nexample.\nSOLUTION\na. Because no particular day of the week is speciﬁed, the ﬁrst person can be \nborn on any one of the seven weekdays. The probability that the second \n person is born on the same day as the ﬁrst person is 1>7. The probability that \ntwo people are born on the same day of the week is therefore 1>7.\n \nb. The probability that the ﬁrst person is born on Monday is 1>7 and the prob-\nability that the second person is also born on Monday is 1>7. Because the two \nevents are independent, the probability that both people are born on Monday is\n1\n7 # 1\n7 = 1\n49\nWATCH YOUR LANGUAGE! Example 6 illustrates that finding correct or relevant \nprobability values often requires greater language skills than computational skills. \nIn Example 6, what exactly do we mean by “same day of the week”? See how parts \n(a) and (b) in Example 6 are very different.\nEXAMPLE 7  Airbus 310: Redundancy for Better Safety\nModern aircraft are now highly reliable, and one design feature contributing to that \nreliability is the use of redundancy, whereby critical components are duplicated so \nthat if one fails, the other will work. For example, the Airbus 310 twin-engine air-\nliner has three independent hydraulic systems, so if any one system fails, full flight \ncontrol is maintained with another functioning system. For this example, we will as-\nsume that for a typical flight, the probability of a hydraulic system failure is 0.002.\n \na. If the Airbus 310 were to have one hydraulic system, what is the probability \nthat the aircraft’s ﬂight control would work for a ﬂight?\n \nb. Given that the Airbus 310 actually has three independent hydraulic systems, \nwhat is the probability that on a typical ﬂight, control can be maintained with \na working hydraulic system?\nSOLUTION\n \na. The probability of a hydraulic system failure is 0.002, so the probability that \nit does not fail is 0.998. That is, the probability that ﬂight control can be main-\ntained is as follows:\nP11 hydraulic system does not fail2\n     \n= 1 - P1failure2 = 1 - 0.002 = 0.998\n\n4-2 Addition Rule and Multiplication Rule \n139\nRationale for the Multiplication Rule\nTo see the reasoning that underlies the multiplication rule, consider a pop quiz consist-\ning of these two questions:\n1. True or false: A pound of feathers is heavier than a pound of gold.\n2. Who said, “By a small sample, we may judge of the whole piece”?  \n(a) Judge Judy; (b) Judge Dredd; (c) Miguel de Cervantes; (d) George \nGallup; (e) Gandhi\nThe answers are T (true) and c. (The first answer is true, because weights of feath-\ners are in avoirdupois units where a pound is 453.59 g, but weights of gold and other \nprecious metals are in troy units where a pound is 373.24 g. The second answer is \nfrom Don Quixote by Cervantes.)\nHere is the sample space for the different possible answers:\nTa Tb Tc Td Te Fa Fb Fc Fd Fe\nIf both answers are random guesses, then the above 10 possible outcomes are equally \nlikely, so\nP1both correct2 = P1T and c2 = 1\n10 = 0.1\nWith P1T and c2 = 1>10, P1T2 = 1>2, and P1c2 = 1>5, we see that\n1\n10 = 1\n2 # 1\n5\nA tree diagram is a graph of the possible outcomes of a procedure, as in Figure 4-4. \nFigure 4-4 shows that if both answers are random guesses, all 10 branches are equally \nlikely and the probability of getting the correct pair (T, c) is 1>10. For each response to \nthe first question, there are 5 responses to the second. The total number of outcomes is 5 \ntaken 2 times, or 10. The tree diagram in Figure 4-4 therefore provides a visual illustra-\ntion for using multiplication.\n \nb. With three independent hydraulic systems, ﬂight control will be maintained if \nthe three systems do not all fail. The probability of all three hydraulic systems \nfailing is 0.002 #  0.002 #  0.002 = 0.000000008. It follows that the probabil-\nity of maintaining ﬂight control is as follows:\nP1it does not happen that all three hydraulic systems fail2\n= 1 - 0.000000008 = 0.999999992\nINTERPRETATION\nWith only one hydraulic system we have a 0.002 probability of failure, but with \nthree independent hydraulic systems, there is only a 0.000000008 probability that \nflight control cannot be maintained because all three systems failed. By using three \nhydraulic systems instead of only one, risk of failure is decreased not by a factor of \n1>3, but by a factor of 1>250,000. By using three independent hydraulic systems, \nrisk is dramatically decreased and safety is dramatically increased.\nTa\nTb\nTc\nTd\nTe\nFa\nFb\nFc\nFd\nFe\na\nb\nc\nd\ne\na\nb\nc\nd\ne\nT\nF\n10\n5\n5\n2\n3\nFIGURE 4-4 Tree Diagram \nof Test Answers\n\n140 \nCHAPTER 4 Probability\nSummary of Addition Rule and Multiplication Rule\nAddition Rule for P(A or B): The word or suggests addition, and when adding \nP(A) and P(B), we must add in such a way that every outcome is counted only \nonce.\nMultiplication Rule for P(A and B): The word and for two trials suggests \nmultiplication, and when multiplying P(A) and P(B), we must be sure that the \nprobability of event B takes into account the previous occurrence of event A.\nStatistical Literacy and Critical Thinking\n1. Notation When randomly selecting an adult, A denotes the event of selecting someone with \nblue eyes. What do P(A) and P1A2 represent?\n2. Notation When randomly selecting adults, let M denote the event of randomly selecting \na male and let B denote the event of randomly selecting someone with blue eyes. What does \nP1M0 B2 represent? Is P1M0 B2 the same as P1B0 M2?\n3. Sample for a Poll There are 15,524,971 adults in Florida. If The Gallup organization ran-\ndomly selects 1068 adults without replacement, are the selections independent or dependent? \nIf the selections are dependent, can they be treated as being independent for the purposes of \ncalculations?\n4. Rule of Complements When randomly selecting an adult, let B represent the event of \nrandomly selecting someone with Group B blood. Write a sentence describing what the rule of \ncomplements is telling us: P1B or B2 = 1.\nFinding Complements. In Exercises 5–8, find the indicated complements.\n5. LOL A U.S. Cellular survey of smartphone users showed that 26% of respondents answered \n“yes” when asked if abbreviations (such as LOL) are annoying when texting. What is the prob-\nability of randomly selecting a smartphone user and getting a response other than “yes”?\n6. Color Blindness Women have a 0.25% rate of red>green color blindness. If a woman is \nrandomly selected, what is the probability that she does not have red>green color blindness?\n7. Clinical Test When the drug Viagra (sildenafil citrate) was clinically tested, 117 patients \nreported headaches and 617 did not. If one of these patients is randomly selected, find the prob-\nability of getting one who did not report a headache.\n8.  Sobriety Checkpoint When one of the authors observed a sobriety checkpoint con-\nducted by the Dutchess County Sheriff Department, he saw that 676 drivers were screened \nand 6 were arrested for driving while intoxicated. Based on those results, we can estimate that \nP1I2 = 0.000888, where I denotes the event of screening a driver and getting someone who is \nintoxicated. What does P1I2 denote, and what is its value?\nIn Exercises 9–20, use the data in the following table, which summarizes blood groups and \nRh types for randomly selected subjects. Assume that subjects are randomly selected from \nthose included in the table.\nO\nA\nB\nAB\nType\nRh+\n59\n53\n12\n6\nRh−\n 9\n 8\n 3\n2\n4-2 Basic Skills and Concepts\n\n4-2 Addition Rule and Multiplication Rule \n141\n9. Blood Groups and Types If one person is selected, find the probability of getting some-\none who is not Group A.\n10.  Blood Groups and Types If one person is selected, find the probability of getting \nsomeone who is not type Rh+.\n11.  Blood Groups and Types If one person is selected, find the probability of getting \nsomeone who is Group A or type Rh+. Are the events of selecting someone who is Group A and \nthe event of someone who is type Rh+ disjoint events?\n12.  Blood Groups and Types If one person is selected, find the probability of getting \nsomeone who is type Rh− or Group AB. Are the events of selecting someone who is type Rh−\nand the event of someone who is Group AB disjoint events?\n13. Blood Groups and Types If two people are selected, find the probability that they are \nboth Group B.\na. Assume that the selections are made with replacement. Are the events independent?\nb. Assume that the selections are made without replacement. Are the events independent?\n14. Blood Groups and Types If two people are selected, find the probability that they are \nboth type Rh−.\na. Assume that the selections are made with replacement. Are the events independent?\nb. Assume that the selections are made without replacement. Are the events independent?\n15. Blood Groups and Types If two people are selected, find the probability that they are \nboth type Rh+.\na. Assume that the selections are made with replacement. Are the events independent?\nb. Assume that the selections are made without replacement. Are the events independent?\n16. Blood Groups and Types If two people are selected, find the probability that they are \nboth Group AB.\na. Assume that the selections are made with replacement. Are the events independent?\nb. Assume that the selections are made without replacement. Are the events independent?\n17.  Blood Groups and Types If one person is selected, find the probability of getting \nsomeone who is Group A or Group B or type Rh-.\n18.  Blood Groups and Types If one person is selected, find the probability of getting \nsomeone who is Group O or Group AB or type Rh+.\n19. Blood Groups and Types If three different people are selected, find the probability that \nthey are all Group A.\n20. Blood Groups and Types If three different people are selected, find the probability that \nthey are all type Rh-.\nIn Exercises 21–24, use these results from the “1-Panel-THC” test for marijuana use, \nwhich is provided by the company Drug Test Success: Among 143 subjects with positive \ntest results, there are 24 false positive results; among 157 negative results, there are 3 false \nnegative results. (Hint: Construct a table similar to Table 4-1, which is included with the \nChapter Problem.)\n21. Testing for Marijuana Use\na. How many subjects are included in the study?\nb. How many of the subjects had a true negative result?\nc. What is the probability that a randomly selected test subject had a true negative result?\n\n142 \nCHAPTER 4 Probability\n22. Testing for Marijuana Use If one of the test subjects is randomly selected, find the \nprobability that the subject tested negative or used marijuana.\n23. Testing for Marijuana Use If one of the test subjects is randomly selected, find the \nprobability that the subject tested positive or did not use marijuana.\n24. Testing for Marijuana Use If one of the test subjects is randomly selected, find the \nprobability that the subject used marijuana. Do you think that the result reflects the general \npopulation rate of subjects who use marijuana?\nRedundancy. Exercises 25 and 26 involve redundancy.\n25. Redundancy in Computer Hard Drives It is generally recognized that it is wise to \nback up computer data. Assume that there is a 3% rate of disk drive failure in a year (based on \ndata from various sources including lifehacker.com).\na. If you store all of your computer data on a single hard disk drive, what is the probability that \nthe drive will fail during a year?\nb. If all of your computer data are stored on a hard disk drive with a copy stored on a second \nhard disk drive, what is the probability that both drives will fail during a year?\nc. If copies of all of your computer data are stored on three independent hard disk drives, what \nis the probability that all three will fail during a year?\nd. Describe the improved reliability that is gained with backup drives.\n26. Redundancy in Hospital Generators Hospitals typically require backup generators to \nprovide electricity in the event of a power outage. Assume that emergency backup generators \nfail 22% of the times when they are needed (based on data from Arshad Mansoor, senior vice \npresident with the Electric Power Research Institute). A hospital has two backup generators so \nthat power is available if one of them fails during a power outage.\na. Find the probability that both generators fail during a power outage.\nb. Find the probability of having a working generator in the event of a power outage. Is that \nprobability high enough for the hospital?\nAcceptance Sampling. With one method of a procedure called acceptance sampling, a \nsample of items is randomly selected without replacement and the entire batch is accepted \nif every item in the sample is found to be okay (or conforming). Exercises 27 and 28 involve \nacceptance sampling.\n27. Defective Pacemakers Among 8834 cases of heart pacemaker malfunctions, 504 were \nfound to be caused by firmware, which is software programmed into the device (based on data \nfrom “Pacemaker and ICD Generator Malfunctions,” by Maisel et al., Journal of the American \nMedical Association, Vol. 295, No. 16). If the firmware is tested in three different pacemak-\ners randomly selected from this batch of 8834 and the entire batch is accepted if there are no \nfailures, what is the probability that the firmware in the entire batch will be accepted? Is this \nprocedure likely to result in the entire batch being accepted?\n28. Defective Ultrasound Transducers Among 676 ultrasound transducers tested, 269 \nwere defective with transducer errors (based on data from “High Incidence of Defective Ultra-\nsound Transducers in Use in Routine Clinical Practice,” by Martensson et al., European Jour-\nnal of Cardiology, Vol. 10). If four different units are randomly selected and tested, what is the \nprobability that the entire batch will be accepted? Does that probability seem adequate?\nIn Exercises 29 and 30, find the probabilities and indicate when the “5% guideline for cum-\nbersome calculations” is used.\n29. Medical Helicopters In a study of helicopter usage and patient survival, results were \nobtained from 47,637 patients transported by helicopter and 111,874 patients transported by \nground (based on data from “Association Between Helicopter vs Ground Emergency Medical \n\n4-2 Addition Rule and Multiplication Rule \n143\nServices and Survival for Adults with Major Trauma,” by Galvagno et al., Journal of the Ameri-\ncan Medical Association, Vol. 307, No. 15).\na. If 1 of the 159,511 patients in the study is randomly selected, what is the probability that the \nsubject was transported by helicopter?\nb. If 5 of the subjects in the study are randomly selected without replacement, what is the prob-\nability that all of them were transported by helicopter?\n30. Medical Helicopters In the same study cited in the preceding exercise, among the 47,637 \npatients transported by helicopter, 188 of them left the treatment center against medical advice, \nand the other 47,449 did not leave against medical advice. If 40 of the subjects transported by \nhelicopter are randomly selected without replacement, what is the probability that none of them \nleft the treatment center against medical advice?\n31. MRI Reliability Refer to the accompanying figure showing surge protectors p and q used \nto protect an expensive magnetic resonance imaging (MRI) scanner used in a hospital. If there \nis a surge in the voltage, the surge protector reduces it to a safe level. Assume that each surge \nprotector has a 0.985 probability of working correctly when a voltage surge occurs.\na. If the two surge protectors are arranged in series, what is the probability that a voltage surge \nwill not damage the MRI? (Do not round the answer.)\nb. If the two surge protectors are arranged in parallel, what is the probability that a voltage \nsurge will not damage the MRI? (Do not round the answer.)\nc. Which arrangement should be used for better protection?\nSeries conﬁguration\np\nq\nMRI\nParallel conﬁguration\np\nq\nMRI\n32. Same Birthdays If 25 people are randomly selected, find the probability that no 2 of them \nhave the same birthday. Ignore leap years.\n33. Exclusive Or The exclusive or means either one or the other events occurs, but not both.\na. For the formal addition rule, rewrite the formula for P(A or B) assuming that the addition \nrule uses the exclusive or instead of the inclusive or.\nb. Repeat Exercise 11 “Blood Groups and Types” using the exclusive or instead of the inclu-\nsive or.\n34. Complements and the Addition Rule Refer to the table of blood groups and types used \nfor Exercises 9–20. Assume that one subject is randomly selected. Let A represent the event \nof getting someone with Group A blood and let B represent the event of getting someone with \nGroup B blood. Find P1A or B2, find P1A or B2, and then compare the results. In general, does \nP1A or B2 = P1A or B2?\n4-2 Beyond the Basics\n\n144 \nCHAPTER 4 Probability\nKey Concept In Part 1 of this section we extend the use of the multiplication rule to \ninclude the probability that among several trials, we get at least one of some specified \nevent. In Part 2 we consider conditional probability: the probability of an event occur-\nring when we have additional information that some other event has already occurred. \nIn Part 3 we provide a brief introduction to the use of Bayes’ theorem.\nPART 1\n  Complements: The Probability  \nof “At Least One” \nWhen finding the probability of some event occurring “at least once,” we should un-\nderstand the following:\n \n■“At least one” has the same meaning as “one or more.”\n \n■The complement of getting “at least one” particular event is that you get no \noccurrences of that event.\nFor example, not getting at least 1 girl in 10 births is the same as getting no girls, \nwhich is also the same as getting 10 boys.\nNot getting at least 1 girl in 10 births = Getting no girls = Getting 10 boys\nThe following steps describe the details of this backward method of finding the \nprobability of getting at least one of some event:\nFinding the probability of getting at least one of some event:\n1. Let A = getting at least one of some event.\n2. Then A = getting none of the event being considered.\n3. Find P1A2 = probability that event A does not occur. (This is relatively \neasy using the multiplication rule.)\n4. Subtract the result from 1. That is, evaluate this expression:\nP1at least one occurrence of event A2\n  = 1 −P1no occurrences of event A2\n4-3\n \nComplements, Conditional Probability,  \nand Bayes’ Theorem\nEXAMPLE 1  At Least One Subject with Group AB Blood\nThe probability of randomly selecting someone with Group AB blood is 0.0526 \n(based on the table given with Exercises 9–20 in the preceding section). A re-\nsearcher needs at least one subject having Group AB blood. If 20 subjects are ran-\ndomly selected, find the probability of getting at least one with Group AB blood. Is \nthe probability high enough so that the researcher can be reasonably sure of getting \nsomeone with Group AB blood?\nSOLUTION\nStep 1: Let A = at least 1 of the 20 subjects has Group AB blood.\nStep 2: Identify the event that is the complement of A.\n A = not getting at least 1 subject with Group AB blood among 20\n = all 20 subjects have blood that is not Group AB\n\n4-3 Complements, Conditional Probability, and Bayes’ Theorem  \n145\nPART 2\n Conditional Probability \nWe now consider the principle that the probability of an event is often affected by \nknowledge that some other event has occurred. For example, the probability of a \ngolfer making a hole in one is 1>12,000 (based on past results), but if you have the \nadditional knowledge that the selected person is a professional golfer, the probability \nchanges to 1>2375 (based on data from USA Today).\nStep 3: Find the probability of the complement by evaluating P1A2 If there is \na 0.0526 probability of a person having Group AB blood, it follows that there \nis a 0.9474 probability of a person not having Group AB blood, and we get the \n following:\n P1A2 = P1all 20 subjects have blood that is not Group AB2\n = 0.9474 # 0.9474 #  g # 0.9474\n = 0.947420 = 0.339365436\nStep 4: Find P(A) by evaluating 1 - P1A2.\nP1A2 = 1 - P1A2 = 1 - 0.339365436 = 0.661 1rounded2\nINTERPRETATION\nFor a group of 20 subjects, there is a 0.661 probability of getting at least 1 person \nwith Group AB blood. This probability is not very high, so if the researcher needs a \nperson with Group AB blood, more than 20 subjects should be used.\nDEFINITION\nA conditional probability of an event is a probability obtained with the additional \ninformation that some other event has already occurred.\nNotation\nP1B\u001eA2 denotes the conditional probability of event B occurring, given that event A \nhas already occurred.\nINTUITIVE APPROACH FOR FINDING P1B∣A2\nThe conditional probability of B occurring given that A has occurred can be found \nby assuming that event A has occurred and then calculating the probability that \nevent B will occur, as illustrated in Example 2.\nFORMAL APPROACH FOR FINDING P1B∣A2\nThe probability P1B\u001e A2 can be found by dividing the probability of events A and B \nboth occurring by the probability of event A:\nP1B\u001e A2 = P1A and B2\nP1A2\nProsecutor’s Fallacy\nThe prosecu-\ntor’s fallacy is \nmisunderstand-\ning or confusion \nof two different \nconditional \nprobabilities:  \n(1) the probability \nthat a defendant is innocent, giv-\nen that forensic evidence shows \na match; (2) the probability that \nforensics shows a match, given \nthat a person is innocent. The \nprosecutor’s fallacy has led to \nwrong convictions and imprison-\nment of some innocent people.\nLucia de Berk was a nurse \nwho was convicted of murder \nand sentenced to prison in the \nNetherlands. Hospital administra-\ntors observed suspicious deaths \nthat occurred in hospital wards \nwhere de Berk had been present. \nAn expert testified that there was \nonly 1 chance in 342 million that \nher presence was a coincidence. \nHowever, mathematician Richard \nGill calculated the probability to \nbe closer to 1>150, or possibly as \nlow as 1>5. The court used the \nprobability that the suspicious \ndeaths could have occurred with \nde Berk present, given that she \nwas innocent. The court should \nhave considered the probability \nthat de Berk is innocent, given \nthat the suspicious deaths oc-\ncurred when she was present. \nThis error of the prosecutor’s \nfallacy is subtle and can be \nvery difficult to understand and \nrecognize, yet it can lead to the \nimprisonment of innocent people.\n\n146 \nCHAPTER 4 Probability\nThe preceding formula is a formal expression of conditional probability, but blind use \nof formulas is not recommended. Instead, we recommend the intuitive approach, as \nillustrated in Example 2.\nTABLE 4-1 Results from Drug Tests of Job Applicants\nPositive Test Result\n(Test shows drug use.)\nNegative Test Result \n(Test shows no drug use.)\nSubject Uses Drugs\n45\n(True Positive)\n5\n(False Negative)\nSubject Does Not Use Drugs\n25\n(False Positive)\n480\n(True Negative)\nEXAMPLE 2  Pre-Employment Drug Screening\nRefer to Table 4-1 to find the following:\n \na. If 1 of the 555 test subjects is randomly selected, ﬁnd the probability that the \nsubject had a positive test result, given that the subject actually uses drugs. \nThat is, ﬁnd P(positive test result \u001e subject uses drugs).\n \nb. If 1 of the 555 test subjects is randomly selected, ﬁnd the probability that the \nsubject actually uses drugs, given that he or she had a positive test result. That \nis, ﬁnd P(subject uses drugs \u001e positive test result).\nSOLUTION\na. Intuitive Approach: We want P(positive test result \u001e subject uses drugs), the \nprobability of getting someone with a positive test result, given that the se-\nlected subject uses drugs. Here is the key point: If we assume that the selected \nsubject actually uses drugs, we are dealing only with the 50 subjects in the \nﬁrst row of Table 4-1. Among those 50 subjects, 45 had positive test results, \nso we get this result:\nP1positive test result \u001esubject uses drugs2 = 45\n50 = 0.900\n \n Formal Approach: The same result can be found by using the formula for \nP1B\u001eA2given with the formal approach. We use the following notation.\nP1B\u001eA2 = P1positive test result \u001esubject uses drugs2\nwhere B = positive test result and A = subject uses drugs.\n \n  \nIn the following calculation, we use P(subject uses drugs and had a posi-\ntive test result) = 45>555 and P(subject uses drugs) = 50>555 to get the \nfollowing results:\nP1B\u001eA2 = P1A and B2\nP1A2\nbecomes\nP1positive test result \u001esubject uses drugs2\n = P1subject uses drugs and had a positive test result2\nP1subject uses drugs2\n = 45>555\n50>555 = 0.900\n\n4-3 Complements, Conditional Probability, and Bayes’ Theorem  \n147\nConfusion of the Inverse\nNote that in Example 2, P(positive test result \u001e subject uses drugs) ≠P(subject uses \ndrugs \u001e positive test result). This example proves that in general, P1B\u001eA2 ≠P1A\u001eB2.\n(There could be individual cases where P1A\u001eB2 and P1B\u001eA2 are equal, but they are \ngenerally not equal.) To incorrectly think that P1B\u001eA2 and P1A\u001eB2 are equal or to \nincorrectly use one value in place of the other is called confusion of the inverse.\n \n By comparing the intuitive approach to the formal approach, it should be clear \nthat the intuitive approach is much easier to use, and it is also less likely to \nresult in errors. The intuitive approach is based on an understanding of condi-\ntional probability, instead of manipulation of a formula, and understanding is \nso much better.\n \nb. Here we want P(subject uses drugs \u001e positive test result). If we assume that the \nsubject had a positive test result, we are dealing with the 70 subjects in the \nﬁrst column of Table 4-1. Among those 70 subjects, 45 use drugs, so\nP1subject uses drugs \u001epositive test result2 = 45\n70 = 0.643\nAgain, the same result can be found by applying the formula for conditional \nprobability, but we will leave that for those with a special fondness for ma-\nnipulations with formulas.\nINTERPRETATION\nThe first result of P(positive test result \u001e subject uses drugs) = 0.900 indicates that \na subject who uses drugs has a 0.900 probability of getting a positive test result. \nThe second result of P(subject uses drugs \u001e positive test result) = 0.643 indicates \nthat for a subject who gets a positive test result, there is a 0.643 probability that this \nsubject actually uses drugs. Note that P1positive test result \u001esubject uses drugs2\nP1subject uses drugs \u001epositive test result2. See “Confusion of the Inverse” that \nfollows.\nEXAMPLE 3  Confusion of the Inverse\nConsider these events:\nD: It is dark outdoors.\nM: It is midnight.\nIn the following, we conveniently ignore the Alaskan winter and other such \nanomalies.\nP1D\u001eM2 = 1 1It is certain to be dark given that it is midnight.2\nP1M \u001eD2 = 0 1The probability that it is exactly midnight given\nthat it is dark is almost zero.2\nHere, P1D\u001eM2 ≠P1M \u001eD2. Confusion of the inverse occurs when we incorrectly \nswitch those probability values or think that they are equal.\n\n148 \nCHAPTER 4 Probability\nPART 3\nBayes’ Theorem\nIn this section we extend the discussion of conditional probability to include applica-\ntions of Bayes’ theorem (or Bayes’ rule), which we use for revising a probability value \nbased on additional information that is later obtained.\nLet’s consider a study showing that physicians often give very misleading in-\nformation when they experience confusion of the inverse. They tended to confuse \nP(cancer \u001f positive test result) with P(positive test result \u001f cancer). About 95% of physi-\ncians estimated P(cancer \u001f positive test result) to be about 10 times too high, with the \nresult that patients were given diagnoses that were very misleading, and patients were \nunnecessarily distressed by the incorrect information. Let’s take a closer look at this \nclassic example, and let’s hope that we can give physicians information in a better \nformat that is easy to understand.\nEXAMPLE 4  Interpreting Medical Test Results\nAssume cancer has a 1% prevalence rate, meaning that 1% of the population has \ncancer. Denoting the event of having a cancer by C, we have P1C2 = 0.01 for a \nsubject randomly selected from the population. This result is included with the fol-\nlowing performance characteristics of the test for cancer (based on Probabilistic \nReasoning in Clinical Medicine, by David Eddy, Cambridge University Press).\n \n■There is a 1% prevalence rate of the cancer. That is, P1C2 = 0.01.\n \n■The false positive rate is 10%. That is, P(positive test result given that cancer is \nnot present) = 0.10.\n \n■The true positive rate is 80%. That is, P(positive test result given that cancer is \npresent) = 0.80.\nFind P1C\u001fpositive test result2. That is, find the probability that a subject actually \nhas cancer given that he or she has a positive test result.\nSOLUTION\nUsing the given information, we can construct a hypothetical population with the above \ncharacteristics. We can find the entries in Table 4-2 on the next page, as follows.\n \n■Assume that we have 1000 subjects. With a 1% prevalence rate, 10 of the sub-\njects are expected to have cancer. The sum of the entries in the first row of val-\nues is therefore 10.\n \n■The other 990 subjects do not have cancer. The sum of the entries in the second \nrow of values is therefore 990.\n \n■Among the 990 subjects without cancer, 10% get positive test results, so 10% \nof the 990 cancer-free subjects in the second row get positive test results. See \nthe entry of 99 in the second row.\n \n■For the 990 subjects in the second row, 99 test positive, so the other 891 must \ntest negative. See the entry of 891 in the second row.\n \n■Among the 10 subjects with cancer in the first row, 80% of the test results are \npositive, so 80% of the 10 subjects in the first row test positive. See the entry of \n8 in the first row.\n \n■The other 2 subjects in the first row test negative. See the entry of 2 in the \nfirst row.\nIn\nti\nGroup Testing\nDuring World \nWar II, the U.S. \nArmy tested \nfor syphilis \nby giving \neach soldier \nan individual \nblood test that was analyzed \nseparately. One researcher sug-\ngested mixing pairs of blood \nsamples. After the mixed pairs \nwere tested, those with syphilis \ncould be identified by retest-\ning the few blood samples that \nwere in the pairs that tested \npositive. Since the total number \nof analyses was reduced by pair-\ning blood specimens, why not \ncombine them in groups of three \nor four or more? This technique \nof combining samples in groups \nand retesting only those groups \nthat test positive is known as \ngroup testing or pooled testing, or \ncomposite testing. University of \nNebraska statistician Christopher \nBilder wrote an article about this \ntopic in Chance magazine, and \nhe cited some real applications. \nHe noted that the American \nRed Cross uses group testing \nto screen for specific diseases, \nsuch as hepatitis, and group \n testing is used by veterinarians \nwhen cattle are tested for the \nbovine viral diarrhea virus.\n\n4-3 Complements, Conditional Probability, and Bayes’ Theorem  \n149\nThe solution in Example 4 is not very difficult. Another approach is to compute the \nprobability using this formula commonly given with Bayes’ theorem:\nP1A\u001eB2 =\nP1A2 # P1B\u001eA2\n3P1A2 # P1B\u001eA2 4 + 3P1A2 # P1B\u001eA2 4\nIf we replace A with C and replace B with “positive,” we get this solution for Example 4:\n P1C\u001epositive2 =\nP1C2 # P1positive \u001eC2\nP1C2 # P1positive \u001eC2 + P1C2 # P1Positive \u001eC2\n =\n0.01 # 0.80\n10.01 # 0.802 + 10.99 # 0.102 = 0.0748\nStudy Results Here is a truly fascinating fact: When 100 physicians were given \nthe information in Example 4, 95 of them estimated P(C \u001e positive) to be around \n0.70 to 0.80, so they were wrong by a factor of 10. Physicians are extremely intel-\nligent, but here they likely suffered from confusion of the inverse. The given rate \nof 80% for positive test results among those who are true positives implies that \nP1positive \u001eC2 = 0.80, but this is very different from P1C\u001epositive2. The physi-\ncians would have done much better if they had seen the given information in the form \nof a table like Table 4-2.\nThe importance and usefulness of Bayes’ theorem is that it can be used with se-\nquential events, whereby new additional information is obtained for a subsequent \nevent, and that new information is used to revise the probability of the initial event. In \nthis context, the terms prior probability and posterior probability are commonly used.\nTo find P1C\u001epositive test result2, see that the first column of values includes the \npositive test results. In that first column, the probability of randomly selecting a \nsubject with cancer is 8>107 or 0.0748, so P1C\u001epositive test result2 = 0.0748.\nINTERPRETATION\nFor the data given in this example, a randomly selected subject has a 1% chance \nof cancer, but for a randomly selected subject given a test with a positive result, \nthe chance of cancer increases to 7.48%. Based on the data given in this example, \na positive test result should not be devastating news, because there is still a good \nchance that the test is wrong.\nTABLE 4-2 Test Results\nPositive Test Result\n(Test shows cancer.)\nNegative Test Result \n(Test shows no cancer.)\n \nTotal\nCancer\n8\n(True Positive)\n2\n(False Negative)\n10\nNo Cancer\n99\n(False Positive)\n891\n(True Negative)\n990\nDEFINITIONS\nA prior probability is an initial probability value originally obtained before any ad-\nditional information is obtained.\nA posterior probability is a probability value that has been revised by using addi-\ntional information that is later obtained.\n\n150 \nCHAPTER 4 Probability\nRelative to Example 4, P1C2 = 0.01, which is the probability that a randomly se-\nlected subject has cancer. P(C) is an example of a prior probability. Using the ad-\nditional information that the subject has received a positive test result, we found that \nP1C\u001epositive test result2 = 0.0748, and this is a posterior probability because it uses \nthat additional information of the positive test result.\nStatistical Literacy and Critical Thinking\n1. Language: Complement of “At Least One” Let A = the event of getting at least one \ndefective pacemaker battery when 3 batteries are randomly selected with replacement from a \nbatch. Write a statement describing event A.\n2. Probability of At Least One Let A = the event of getting at least 1 defective pacemaker \nbattery when 3 batteries are randomly selected with replacement from a batch. If 5% of the \nbatteries in a batch are defective and the other 95% are all good, which of the following are \ncorrect?\na. P1A2 = 10.95210.95210.952 = 0.857\nb. P1A2 = 1 - 10.95210.95210.952 = 0.143\nc. P1A2 = 10.05210.05210.052 = 0.000125\n3. Notation Let event G = subject has glaucoma (disorder of the eye) and let event Y = test \nindicates that “yes,” the subject has glaucoma. Use your own words to translate the notation \nP1Y \u001e G2 into a verbal statement.\n4. Confusion of the Inverse Using the same events G and Y described in Exercise 3, de-\nscribe confusion of the inverse.\nAt Least One. In Exercises 5–12, find the probability.\n5. Three Girls Find the probability that when a couple has three children, at least one of them \nis a girl. (Assume that boys and girls are equally likely.)\n6. Probability of a Girl Assuming that boys and girls are equally likely, find the probability \nof a couple having a boy when their third child is born, given that the first two children were \nboth girls.\n7. Births in the United States In the United States, the true probability of a baby being a \nboy is 0.512 (based on the data available at this writing). Among the next six randomly selected \nbirths in the United States, what is the probability that at least one of them is a girl?\n8. Births in China In China, where many couples were allowed to have only one child, the \nprobability of a baby being a boy was 0.545. Among six randomly selected births in China, \nwhat is the probability that at least one of them is a girl? Could this system continue to work \nindefinitely? (Phasing out of this policy was begun in 2015.)\n9. Phone Survey Subjects for the California Health Interview Survey are contacted using \ntelephone numbers in which the last four digits are randomly selected (with replacement). Find \nthe probability that for one such phone number, the last four digits include at least one 0.\n10. At Least One Correct Answer If you make random guesses for 10 multiple-choice \nMCAT test questions (each with five possible answers), what is the probability of getting at \nleast 1 correct? If these questions are part of a practice test and an instructor says that you must \nget at least one correct answer before continuing, is there a good chance you will continue?\n11. At Least One Defective Ultrasound Transducer A study showed that 39.8% of ultra-\nsound transducers are defective (based on data from “High Incidence of Defective  Ultrasound \n4-3 Basic Skills and Concepts\n\n4-3 Complements, Conditional Probability, and Bayes’ Theorem  \n151\nTransducers in Use in Routine Clinical Practice,” by Martensson et al., European Journal of \nEchocardiography, Vol. 10, No. 1093.) An engineer needs at least one defective ultrasound \ntransducer so she can try to identify the problem. If she randomly selects 10 ultrasound trans-\nducers from a very large batch, what is the probability that she will get at least one that is de-\nfective? Is that probability high enough so that she can be reasonably sure of getting a defective \ntransducer for her work?\n12. Fruit Flies An experiment with fruit flies involves one parent with normal wings and one \nparent with vestigial wings. When these parents have an offspring, there is a 3>4 probability \nthat the offspring has normal wings and a 1>4 probability of vestigial wings. If the parents give \nbirth to five offspring, what is the probability that at least one of the offspring has vestigial \nwings? If researchers need at least one offspring with vestigial wings, can they be quite confi-\ndent of getting one?\nIdentical and Fraternal Twins. In Exercises 13–16, use the data in the following table. \nInstead of summarizing observed results, the entries reflect the actual probabilities based \non births of twins (based on data from the Northern California Twin Registry and the ar-\nticle “Bayesians, Frequentists, and Scientists,” by Bradley Efron, Journal of the American \nStatistical Association, Vol. 100, No. 469). Identical twins come from a single egg that splits \ninto two embryos, and fraternal twins are from separate fertilized eggs. The table entries \nreflect the principle that among sets of twins, 1 , 3 are identical and 2 , 3 are fraternal. Also, \nidentical twins must be of the same gender and the genders are equally likely (approxi-\nmately), and genders of fraternal twins are equally likely.\nBoy>boy\nBoy>girl\nGirl>boy\nGirl>girl\nIdentical Twins\n5\n0\n0\n5\nFraternal Twins\n5\n5\n5\n5\n13. Identical Twins\na. After having a sonogram, a pregnant woman learns that she will have twins. What is the \nprobability that she will have identical twins?\nb. After studying the sonogram more closely, the physician tells the pregnant woman that she \nwill give birth to twin boys. What is the probability that she will have identical twins? That is, \nfind the probability of identical twins given that the twins consist of two boys.\n14. Fraternal Twins\na. After having a sonogram, a pregnant woman learns that she will have twins. What is the \nprobability that she will have fraternal twins?\nb. After studying the sonogram more closely, the physician tells the pregnant woman that she \nwill give birth to twins consisting of one boy and one girl. What is the probability that she will \nhave fraternal twins?\n15. Fraternal Twins If a pregnant woman is told that she will give birth to fraternal twins, \nwhat is the probability that she will have one child of each gender?\n16. Fraternal Twins If a pregnant woman is told that she will give birth to fraternal twins, \nwhat is the probability that she will give birth to two girls?\n\n152 \nCHAPTER 4 Probability\nIn Exercises 17–20, refer to the accompanying table showing results from a Chembio test \nfor hepatitis C among HIV-infected patients (based on data from a variety of sources).\nPositive Test Result\nNegative Test Result\nHepatitis C\n335\n  10\nNo Hepatitis C\n  2\n1153\n17. False Positive Find the probability of selecting a subject with a positive test result, given \nthat the subject does not have hepatitis C. Why is this case problematic for test subjects?\n18. False Negative Find the probability of selecting a subject with a negative test result, \ngiven that the subject has hepatitis C. What would be an unfavorable consequence of this error?\n19. Positive Predictive Value Find the positive predictive value for the test. That is, find the \nprobability that a subject has hepatitis C, given that the test yields a positive result. Does the \nresult make the test appear to be effective?\n20. Negative Predictive Value Find the negative predictive value for the test. That is, find \nthe probability that a subject does not have hepatitis C, given that the test yields a negative re-\nsult. Does the result make the test appear to be effective?\n21. Redundancy in Computer Hard Drives Assume that there is a 3% rate of disk drive \nfailures in a year (based on data from various sources including lifehacker.com).\na. If all of your computer data are stored on a hard disk drive with a copy stored on a second \nhard disk drive, what is the probability that during a year, you can avoid catastrophe with at \nleast one working drive? Express the result with four decimal places.\nb. If copies of all of your computer data are stored on three independent hard disk drives, what \nis the probability that during a year, you can avoid catastrophe with at least one working drive? \nExpress the result with six decimal places. What is wrong with using the usual round-off rule \nfor probabilities in this case?\n22. Redundancy in Hospital Generators Assume that emergency backup generators fail \n22% of the times when they are needed (based on data from Arshad Mansoor, senior vice presi-\ndent with the Electric Power Research Institute). A hospital has three backup generators so \nthat power is available if at least one of them works in a power failure. Find the probability of \nhaving at least one of the backup generators working, given that a power failure has occurred. \nDoes the result appear to be adequate for the hospital’s needs?\n23. Composite Drug Test Based on the data in Table 4-1 on page 146, assume that the prob-\nability of a randomly selected person testing positive for drug use is 0.126. If drug screening \nsamples are collected from 5 random subjects and combined, find the probability that the com-\nbined sample will reveal a positive result. Is that probability low enough so that further testing \nof the individual samples is rarely necessary?\n24. Composite Water Samples The Fairfield County Department of Public Health tests \nwater for the presence of E. coli (Escherichia coli) bacteria. To reduce laboratory costs, water \nsamples from 10 public swimming areas are combined for one test, and further testing is done \nonly if the combined sample tests positive. Based on past results, there is a 0.005 probability of \nfinding E. coli bacteria in a public swimming area. Find the probability that a combined sample \nfrom 10 public swimming areas will reveal the presence of E. coli bacteria. Is that probability \nlow enough so that further testing of the individual samples is rarely necessary?\n25. Shared Birthdays Find the probability that of 25 randomly selected people, at least 2 \nshare the same birthday.\n4-3 Beyond the Basics\n\n4-4 Risks and Odds \n153\nKey Concept This section introduces absolute risk reduction, relative risk, and odds \nratio as measures helpful for comparing probability values and measuring risk. This \nsection also introduces “number needed to treat” as a measure of the number of sub-\njects that must be treated in order to prevent the single occurrence of some event, such \nas a disease.\nOne simple way to measure risk is to use a probability value. For example, in one \nof the largest medical experiments ever conducted, it was found that among 200,745 \nchildren injected with the Salk vaccine, 33 developed paralytic polio (poliomyelitis). \nIt follows that for this treatment group, P1polio2 = 33>200,745 = 0.000164. How-\never, that single measure does not give us any information about the rate of polio for \nthose children who were injected with a placebo. The risk of polio for children treated \nwith the Salk vaccine should be somehow compared to the risk of polio for those chil-\ndren given a placebo. Let’s consider the data summarized in Table 4-3.\n4-4 \nRisks and Odds\nTABLE 4-3 Prospective Study of Polio and the Salk Vaccine\nPolio\nNo polio\nTotal\nSalk Vaccine\n 33\n200,712\n200,745\nPlacebo\n115\n201,114\n201,229\nBased on the data in Table 4-3, we can identify the following probabilities:\n Polio rate for treatment group: P1polio \u001eSalk vaccine2 =\n33\n200,745 = 0.000164\n Polio rate for placebo group: P1polio \u001eplacebo2 =\n115\n201,229 = 0.00571\nInformal comparison of the preceding two probabilities likely suggests that there is a \nsubstantial difference between the two polio rates. Later chapters will use more effec-\ntive methods for determining whether the apparent difference is actually significant, \nbut in this section we introduce some simple measures for comparing the two rates.\nThe preceding table can be generalized with the following format:\nTABLE 4-4 Generalized Table Summarizing Results of a Prospective Study\nDisease\nNo Disease\nTreatment\na\nb\nPlacebo\nc\nd\nWe noted above that this section introduces some simple measures for comparing \ntwo rates, such as the polio rate for the Salk vaccine treatment group and the polio \nrate for the placebo group, as summarized in Table 4-3. We begin with the absolute \nrisk reduction.\n\n154 \nCHAPTER 4 Probability\nAbsolute Risk Reduction\nDEFINITION\nWhen comparing two probabilities or rates, the absolute risk reduction is simply \nthe absolute value of the following difference.\nAbsolute risk reduction = \u001eP1event occurring in treatment group2\n- P1event occurring in control group2 \u001e\nIf the data are in the generalized format of Table 4−4, we can express the absolute \nrisk reduction as follows:\nAbsolute risk reduction = \u001eP1event occurring in treatment group2\n- P1event occurring in control group2 \u001e\n \n= `\na\na + b -\nc\nc + d `\n(In the above expression, “treatment” might be replaced by the “presence of some \ncondition” or some other equivalent description.)\nCAUTION: The above definition of absolute risk reduction always results in the \npositive difference between a probability in the treatment group and a probability \nin the control group. Consider this when interpreting the effectiveness of the \ntreatment in terms of being helpful or harmful. See Exercises 13−16, where those \nin an atorvastatin treatment group have a higher rate of infections than those in the \nplacebo group. Be careful to interpret the results correctly.\nEXAMPLE 1  Finding Absolute Risk Reduction\nUsing the data summarized in Table 4-3, find the absolute risk reduction, which can \nbe used to measure the effectiveness of the Salk vaccine.\nSOLUTION\nBased on the data in Table 4-3, we have already found that P(polio \u001e Salk vaccine) \n= 0.000164 and P(polio \u001e placebo) = 0.000571. It follows that:\n Absolute risk reduction = \u001eP1polio\u001eSalk vaccine2 - P1polio\u001eplacebo2 \u001e\n = \u001e0.000164 - 0.000571\u001e = 0.000407\nFor a subject treated with the Salk vaccine, there is an absolute risk reduction of \n0.000407 when compared to a subject given a placebo. That is, there are 0.0407% \nfewer events of polio for subjects treated with the Salk vaccine than for subjects given \na placebo. This doesn’t seem like much of a reduction, but when considered in the con-\ntext of the number of polio events in a large population, it is a significant reduction.\nRelative Risk\nSection 1-3 included definitions of retrospective and prospective studies:\n \n■Retrospective Study: Data are collected from a past time period by going back in \ntime (through examinations of records, interviews, etc.).\n \n■Prospective Study: Data are collected in the future from groups or “cohorts” that \nshare common factors.\nA\nMonkey Typists\nA classical \nclaim is that \na monkey \nrandomly \nhitting a key-\nboard would \neventually \nproduce the complete works of \nShakespeare, assuming that it \ncontinues to type century after \ncentury. The multiplication rule \nfor probability has been used to \nfind such estimates. One  \nresult of 1,000,000,000,000,000, \n000,000,000,000,000,000,000 \nyears is considered by some to \nbe too short. In the same spirit, \nSir Arthur Eddington wrote this \npoem: “There once was a brainy \nbaboon, who always breathed \ndown a bassoon. For he said, ‘It \nappears that in billions of years, I \nshall certainly hit on a tune.’”\n\n4-4 Risks and Odds \n155\nIn a prospective study, a commonly used measure for comparing risk is relative risk. \nWe first introduce the following notation, and then we define relative risk.\nNotation\npt = proportion (or incidence rate) of some characteristic in a treatment group\npc = proportion (or incidence rate) of some characteristic in a control group\nDEFINITION\nIn a prospective study, the relative risk (or risk ratio or RR) of a characteristic \nis the ratio pt>pc, where pt is the proportion of the characteristic in the treatment \n(or exposed) group and pc is the proportion in the control group (or group not ex-\nposed). If the data are in the same format as the generalized Table 4-4, then the \nrelative risk is found by evaluating\npt\npc\n=\na\na + b\nc\nc + d\nInterpreting Relative Risk A relative risk value of 1 shows that the risk is the same \nfor the treatment group and the control (or placebo) group. A relative risk value much \ngreater than 1 shows that there is a much greater risk for the treatment group. The fol-\nlowing example illustrates how the relative risk of 0.287 shows that the risk of polio in \nthe treatment group is much less than the risk of polio in the placebo group.\nEXAMPLE 2  Computing Relative Risk\nUsing the data in Table 4-3, find the relative risk.\nSOLUTION\nFor the sample data in Table 4-3, we will consider the treatment group to be the \ngroup of children given the Salk vaccine, and the control group is the group of chil-\ndren given a placebo. Using the preceding notation, we have\npt = proportion of polio in treatment group =\n33\n33 + 200,712 = 0.000164\npc = proportion of polio in control 1placebo2 group =\n115\n115 + 201,114 =  0.000571\nUsing the above values, we can now find the relative risk as follows.\nRelative risk = pt\npc\n= 0.000164\n0.000571 = 0.287\nINTERPRETATION\nWe can interpret this result as follows: The polio rate for children given the Salk \nvaccine is 0.287 of the polio rate for children given a placebo. (A relative risk less \nthan 1 indicates that the treatment results in a reduced risk.) If we were to consider \nthe reciprocal value of 0.000571>0.000164 = 3.48, we see that children in the \n placebo group are 3.48 times more likely to get polio.\n\n156 \nCHAPTER 4 Probability\nNumber Needed to Treat\nOne problem with relative risk is that it may be misleading by suggesting that a treat-\nment is superior or inferior, even when the absolute difference between rates is not \nvery large. For example, if 3 out of 10,000 aspirin users were to experience an imme-\ndiate cure of a cold compared to only 1 out of 10,000 placebo users, the relative risk \nof 3.00 correctly indicates that the incidence of immediate cold cures is three times as \nhigh for aspirin users, but the cure rates of 0.0003 and 0.0001 are so close that, for all \npractical purposes, aspirin should not be considered as a factor affecting the immedi-\nate cure of a cold. With cure rates of 0.0003 and 0.0001, the absolute risk reduction is \n0.0002. Because the absolute risk reduction is so small, the effectiveness of the aspirin \ntreatment would be negligible. In such a situation, the number needed to treat would \nbe a more effective measure that is not so misleading.\nCAUTION: When interpreting relative risk, consider the incidence rates. If the \nprobability of disease in an exposed group is 5>1,000,000 and the probability \nof disease in an unexposed group is 1>1,000,000, the relative risk is 5.0, which \nsounds really bad, but the very low incidence rates suggest that there isn’t much \nrisk in either group.\nDEFINITION\nThe number needed to treat (NNT) is the number of subjects that must be treated \nin order to prevent one event, such as a disease or adverse reaction. It is calcu-\nlated by dividing 1 by the absolute risk reduction.\nnumber needed to treat =\n1\nabsolute risk reduction\nRound-Off Rule If the calculated value of the number needed to treat is not a whole \nnumber, round it up to the next larger whole number.\nIf the sample data are in the format of the generalized Table 4-4, then:\nNumber needed to treat =\n1\n`\na\na + b -\nc\nc + d `\n 1rounded up to the next\nlarger whole number2\nIf 3 out of 10,000 aspirin users were to experience an immediate cure of a cold \ncompared to only 1 out of 10,000 placebo users, the absolute risk reduction is \n\u001e0.0003 - 0.0001\u001e = 0.0002, and the number needed to treat is 1>0.0002 = 5000.\nThis means that we would need to treat 5000 subjects with colds to get one person \nwho experiences an immediate cure.\nEXAMPLE 3  Computing the Number Needed to Treat\nUsing the polio data in Table 4-3, find the number needed to treat, then interpret the \nresult.\nSOLUTION\nIn Example 1 we found that the absolute risk reduction is 0.000407. It is now easy \nto find the number needed to treat.\n\n4-4 Risks and Odds \n157\nOdds\nSo far in this chapter, we have used probability values to express likelihood of various \nevents. Probability values are numbers between 0 and 1 inclusive. However, expres-\nsions of likelihood are often given as odds, such as 50:1 (or “50 to 1”).\n Number needed to treat =\n1\nabsolute risk reduction =\n1\n0.000407 = 2457.002457\n = 2458 1rounded up2\nINTERPRETATION\nThe result of 2458 can be interpreted as follows: We would need to vaccinate 2458 \nchildren with the Salk vaccine (instead of a placebo) to prevent one of the children \nfrom getting polio. Given the extremely serious consequences of polio, the Salk \nvaccine has been found to be very effective and important.\nDEFINITIONS\nThe actual odds against event A occurring are the ratio P1A2>P1A2, usually ex-\npressed in the form of a:b (or “a to b”), where a and b are integers. (Reduce using \nthe largest common factor; if a = 16 and b = 4, express the odds as 4:1 instead \nof 16:4.)\nThe actual odds in favor of event A occurring are the ratio P1A2>P1A2, which is \nthe reciprocal of the actual odds against that event. If the odds against an event \nare a:b, then the odds in favor are b:a.\nNote that in the two preceding definitions, the actual odds against and the actual odds \nin favor describe the actual likelihood of some event. (Gambling situations typically \nuse payoff odds, which describe the amount of profit relative to the amount of a bet. \nFor example, if you bet on the number 7 in roulette, the actual odds against winning \nare 37:1, but the payoff odds are 35:1. Racetracks and casinos are in business to make \na profit, so the payoff odds will usually differ from the actual odds.)\nTABLE 4-5 Retrospective Study of Newborn Discharge and Rehospitalization\nRehospitalized \nwithin a week\nNot rehospitalized \nwithin a week\n \nTotal\nEarly discharge  \n(*30 hours)\n457\n3199\n3656\nLate discharge  \n(30+ hours)\n260\n2860\n3120\nEXAMPLE 4  Rehospitalization and Discharge\nConsider the data in Table 4-5 (based on results from “The Safety of Newborn Early \nDischarge,” by Liu, Clemens, Shay, Davis, and Novack, Journal of the American \nMedical Association, Vol. 278, No. 4).\n \na. For those babies discharged early, ﬁnd the probability of being rehospitalized \nwithin a week.\n \nb. For those babies discharged early, ﬁnd the odds in favor of being rehospital-\nized early.\ncontinued\n\n158 \nCHAPTER 4 Probability\nOdds Ratio\nFor the data in Table 4-5, how does the likelihood of rehospitalization differ between the \nearly discharge group and the late discharge group? One way to address that question is \nto use the odds ratio.\nSOLUTION\na. There were 3656 babies discharged early, and 457 of them were rehospital-\nized within a week, so\nP1rehospitalized2 = 457\n3656 = 1\n8\n \nb. Because P(rehospitalized) = 1>8, it follows that P1rehospitalized2 =\n1 - 1>8= 7>8. We can now ﬁnd the odds in favor of rehospitalization as follows:\nOdds in favor of rehospitalization for the early discharge group\n= P1rehospitalized2\nP1rehospitalized2 = 1>8\n7>8 = 1\n7\nThis result is often expressed as 1:7.\nWith odds of 1:7 in favor of rehospitalization for babies discharged early, it \n follows that the odds against rehospitalization for early discharge are 7:1.\nDEFINITION\nIn a retrospective or prospective study, the odds ratio (OR or relative odds) is a \nmeasure of risk found by evaluating the ratio of the odds in favor of the treatment \ngroup (or case group exposed to the risk factor) to the odds in favor of the control \ngroup, evaluated as follows:\nOdds ratio =\nodds in favor of treatment 1or exposed2 group\nodds in favor of control group\nIf the data are in the format of the generalized Table 4-4 on page 153, then the \nodds ratio can be computed as follows:\nOdds ratio = ad\nbc\nEXAMPLE 5  Computing Odds Ratio\nUsing the data in Table 4-5, find the odds ratio for rehospitalization.\nSOLUTION\nFor this example, we consider the case group to be the babies discharged early, and \nwe consider the control group to be the babies discharged late. The preceding exam-\nple showed that for the early discharge group, the odds in favor of rehospitalization \nare 1:7. Using similar calculations for the late discharge group, we get odds in favor \nof rehospitalization of 1>11 or 1:11. We can now find the odds ratio.\n Odds ratio = odds in favor of rehospitalization in early discharge group\nodds in favor of rehospitalization in late discharge group = 1>7\n1>11\n =  11\n7  or 1.571\n\n4-4 Risks and Odds \n159\nWhy Not Use Relative Risk for Retrospective Studies?\nRelative risk makes sense only if the involved probabilities are good estimates of \nthe actual incidence rates, as in a prospective study. Using relative risk for a retro-\nspective study could incorrectly involve a situation in which researchers can choose \ndisease cases that are very different from actual incidence rates, with the result that \nthe relative risk can be very wrong. That is the reason that relative risk is defined for \nprospective studies only. The odds ratio is defined for prospective and retrospective \nstudies.\n Relative Risk: Prospective study\n Odds Ratio:\n Prospective study or retrospective study\nTable 4–6 includes the results from a prospective study of 1000 randomly selected sub-\njects, which is conducted to investigate the risk of lung cancer from smoking.  Table 4-6 \ncontains entries that are realistic based on current incidence rates. However, Table 4-7 \nbelow is based on a retrospective study in which the researcher went back in time to \nfind 985 subjects with lung cancer and 985 subjects without lung cancer, so Table 4-7 \ndoes not reflect actual incidence rates. See the following.\nFrom Table 4-6: P1lung cancer \u001esmoker2 = 13>180 = 0.0722\nFrom Table 4-7: P1lung cancer \u001esmoker2 = 854>1021 = 0.836\nThe above probabilities are very different, so both of them cannot be good estimates of \nthe likelihood of getting lung cancer from smoking. The above probability of 0.0722 \nis a good estimate because it is based on a prospective study with realistic incidence \nrates, but the probability of 0.836 is a poor estimate because it is based on the retro-\nspective study designed to include an equal number of subjects with lung cancer and \nsubjects without lung cancer.\nNow compare the relative risk values and the odds ratio values from Tables 4-6 \nand 4-7. See that the odds ratio values are approximately the same, but the relative risk \nvalues are dramatically different. The relative risk value of 29.6 from the prospective \nstudy is a good measure, but the relative risk of 6.1 from the retrospective study is a \npoor measure.\nIf we take advantage of the fact that Table 4-5 does correspond to the generalized \nTable 4-4 on page 153, then the odds ratio can also be calculated as follows:\nOdds ratio = ad\nbc = 14572128602\n13199212602 = 1.571\nINTERPRETATION\nThis result indicates that the odds in favor of rehospitalization are 1.571 times \nhigher for babies discharged early when compared to those discharged late. This \nsuggests that newborns discharged early are at substantially increased risk of rehos-\npitalization.\nTABLE 4-6 Prospective Study\nRR = 29.6; OR = 31.8\nLung Cancer\nNo Lung Cancer\nSmoker\n13\n167\nNonsmoker\n 2\n818\nTABLE 4-7 Retrospective Study\nRR = 6.1; OR = 31.9\nLung Cancer\nNo Lung Cancer\nSmoker\n854\n167\nNonsmoker\n131\n818\nTotal\n985\n985\n\n160 \nCHAPTER 4 Probability\nSUMMARY OF KEY POINTS\nDisease\nNo Disease\nTreatment\na\nb\nPlacebo\nc\nd\nStatistical Literacy and Critical Thinking \n1. Notation The relative risk of a characteristic is the ratio pt>pc. What do pt and pc represent?\n2.  Relative Risk Identify an important disadvantage of relative risk used with a relatively \nsmall difference between the rates in the treatment and control groups.\n3. Number Needed to Treat A measure of the effectiveness of an influenza vaccine is the \nnumber needed to treat, which is 37 (under certain conditions). Interpret that number. Does the \nresult apply to every particular group of 37 subjects?\n4. Retrospective , Prospective The odds ratio is a measure used in retrospective or pro-\nspective studies. Describe retrospective and prospective studies.\nHeadaches and Viagra In Exercises 5−12, use the data in the accompanying table \n(based on data from Pfizer, Inc.). That table describes results from a clinical trial of the \ndrug Viagra. Some subjects were treated with Viagra while others were given a placebo; \nthen headache events were recorded.\nHeadache\nNo Headache\nViagra Treatment\n117\n617\nPlacebo\n 29\n696\n5. Type of Study Is the study retrospective or prospective?\n4-4 Basic Skills and Concepts\n \n■Absolute risk reduction = `\na\na + b -\nc\nc + d `\n \n■Number Needed to Treat (NNT) =\n1\nAbsolute Risk Reduction\n \n■Actual odds against event A = P1A2\nP1A2\n \n■Actual odds in favor of event A = P1A2\nP1A2\nRelative risk 1RR2 = pt\npc\n=\na\na + b\nc\nc + d\nOdds ratio 1OR2 = ad\nbc\n(for prospective only)\n\n4-4 Risks and Odds \n161\n6. Probability For those in the Viagra treatment group, find the probability that the subject \nexperienced a headache.\n7. Comparing Probabilities Compare P(headache \u001fViagra treatment) and  \nP(headache \u001f placebo).\n8. Absolute Risk Reduction Find the value of the absolute risk reduction for headaches in \nthe treatment and placebo groups.\n9. Number Needed to Treat Find the number of Viagra users that would need to stop using \nViagra in order to prevent a single headache.\n10. Odds For those in the Viagra treatment group, find the odds in favor of a headache, then \nfind the odds against a headache.\n11. Relative Risk Find the relative risk of a headache for those in the treatment group com-\npared to those in the placebo group. Interpret the result.\n12. Odds Ratio Find the odds ratio for headaches in the treatment group compared to the \nplacebo group, then interpret the result. Should Viagra users be concerned about headaches as \nan adverse reaction?\nClinical Trial of Atorvastatin (Lipitor). In Exercises 13−16, use the data in the accom-\npanying table that summarizes results from a clinical trial of atorvastatin (based on data \nfrom Parke-Davis).\nInfection\nNo Infection\nAtorvastatin (10 mg)\n89\n774\nPlacebo\n27\n243\n13. Absolute Risk Reduction\na. What is the probability of infection in the atorvastatin treatment group?\nb. What is the probability of infection in the placebo group?\nc. Find the value of the absolute risk reduction for infection in the placebo group and the atorv-\nastatin treatment group. Write a brief statement interpreting the result.\n14. Number Needed to Treat Calculate the number needed to treat and interpret the result.\n15. Odds For those who were treated with atorvastatin, find the odds in favor of an infection. \nAlso find the odds in favor of an infection for those given a placebo. Is there much of a differ-\nence between these two results?\n16. Odds Ratio and Relative Risk Find the odds ratio and relative risk for an infection in \nthe group treated with atorvastatin compared to the placebo group. Based on this result, does \natorvastatin appear to increase the risk of an infection? Why or why not?\n17. Odds Ratio and Relative Risk In a clinical trial of 2103 subjects treated with Nasonex \n(mometasone), 26 reported headaches. In a control group of 1671 subjects given a placebo, 22 \nreported headaches. Find the relative risk and odds ratio for the headache data. What do the \nresults suggest about the risk of a headache from the Nasonex treatment?\n18. Design of Experiments You would like to conduct a study to determine the effective-\nness of seat belts in saving lives in car crashes.\na. What would be wrong with randomly selecting 2000 drivers, then randomly assigning half \nof them to a group that uses seat belts and another group that does not wear seat belts?\nb. If 2000 drivers are randomly selected and separated into two groups according to whether \nthey use seat belts, what is a practical obstacle in conducting a prospective study of the effec-\ntiveness of seat belts in car crashes?\n\n162 \nCHAPTER 4 Probability\nIn the biological and health sciences, rates are often used to describe the likelihood of \nan event. Rates are used by researchers and health professionals to monitor the health \nstatus of a community or population. Although any specific time interval could be \nused, we assume a time interval of one year throughout this section.\n4-5 \nRates of Mortality, Fertility, and Morbidity\nDEFINITION\nA rate describes the frequency of occurrence of some event. It is the relative fre-\nquency of an event, multiplied by some number, typically a value such as 1000 or \n100,000. A rate can be expressed as\naa\nb bk\nwhere\na = frequency count of the number of people for whom the event occurred\nb = total number of people exposed to the risk of the event occurring\nk = multiplier number, such as 1000 or 100,000\nThe above general definition is commonly applied to measures of mortality, fertility, \nand morbidity. For the following rates, mortality refers to deaths, fertility refers to \nbirths, and morbidity refers to diseases. Here are additional terms and their meanings:\n \n■Infants: Babies who were born alive\n \n■Neonates: Infants under the age of 28 days\n \n■Fetal Death: Occurs when a fetus is delivered without life after 20 weeks of gestation\n \n■Neonatal Death: Occurs when an infant dies under 28 days of age\nMortality Rates\nCrude 1or unadjusted2 mortality rate = a\ndeaths\npopulation size bk\nInfant mortality rate = adeaths of infants under 1 year of age\nnumber of live births\nbk\nNeonatal mortality rate = adeaths of infants under 28 days of age\nnumber of live births\nbk\nFetal mortality rate =\na\nfetuses delivered without life after 20 weeks of gestation \nnumber of live births +  \n fetuses delivered without life after 20 weeks of gestation bk\nPerinatal mortality rate = afetal deaths + neonatal deaths\nlive births + fetal deaths\nbk\nFertility Rates\nCrude birthrate = a\nlive births\npopulation size bk\nGeneral fertility rate = a\nlive births\nnumber of women aged 15 - 44 bk\n\n4-5 Rates of Mortality, Fertility, and Morbidity \n163\nMorbidity (Disease) Rates\nIncidence rate = areported new cases of disease\npopulation size\nbk\nPrevalence rate = anumber of people with disease at a given time\npopulation size at the given point in time\nbk\nEXAMPLE 1  Crude Mortality Rate\nFor a recent year in the United States, there were 2,515,458 deaths in a population \nof 312,799,495 people. Use those values with a multiplier of 1000 to find the crude \nmortality rate.\nSOLUTION\nWith 2,515,458 people who died, with 312,799,495 people in the population, and \nletting k = 1000, we compute the crude mortality rate as follows:\n Crude mortality rate = a\ndeaths\npopulation size bk = a 2,515,458\n312,799,495b1000\n = 8.0 1rounded2\nINTERPRETATION\nFor this particular year, the death rate is 8.0 people for each 1000 people in the \n population. Using the relative frequency definition of probability given in Section 4-1, \nwe might also say that for a randomly selected person, the probability of death in \nthis year is 2,515,458>312,799,495 = 0.00804. One important advantage of the \nmortality rate of 8.0 people (per 1000 people in the population) is that it results in a \nvalue that uses fewer decimal places and is generally easier to use and understand.\nEXAMPLE 2  Infant Mortality Rate\nThe infant mortality rate is a very important measure of the health of a region. \n (According to the United Nations, the worldwide infant mortality rate is 49.4 per \n1000 live births.) For a recent year, there were 3,953,590 live births in the United \nStates, and there were 23,910 deaths of infants under 1 year of age. Using a mul-\ntiplying factor of k = 1000, find the infant mortality rate of the United States and \ncompare it to the rate of 2.1 for Japan.\nSOLUTION\nThe infant mortality rate is computed as shown below.\n Infant mortality rate = adeaths of infants under 1 year of age\nnumber of live births\nbk\n = a 23,910\n3,953,590b1000\n =  6.0 1rounded2\ncontinued\n\n164 \nCHAPTER 4 Probability\nA crude rate, as defined, is a single value based on crude totals. When compar-\ning two different regions, such as Florida and Colorado, a comparison of rates can be \nmisleading because of differences in factors such as age that might affect the rates. In \na recent year, the crude mortality rates (per 1000 population) were 9.1 in Florida and \n6.4 in Colorado. This is not too surprising, considering that in Florida, roughly 18% of \nthe population is over the age of 65, compared to only 11% for Colorado. The higher \nmortality rate for Florida does not mean that Florida is less healthy; in this case, it \nappears that Florida has a higher death rate largely because it has a higher proportion \nof older residents. Instead of using crude rates, we might use either specific rates or \nadjusted rates.\nSpecific rates are rates specific for some particular group, such as people aged \n18–24, or rates specific for some particular cause of death, such as deaths due to myo-\ncardial infarction.\nAdjusted rates involve calculations that can be quite complicated, but they basi-\ncally make adjustments for important factors, such as age, gender, or race.\nBecause age is the characteristic that typically affects mortality the most, it is the \nmost common factor used as the basis for adjustment. Calculations of adjusted rates \ninvolve the creation of a theoretical standardized population that is used for the re-\ngions being compared. A population of 1,000,000 people with the same composition \nas the United States is often used as the standardized population. Adjusted rates are \nvaluable for comparing different regions, but they do not necessarily reflect the true \ncrude death rates. Adjusted rates should not be used as death rates and they should not \nbe compared to crude rates.\nWhen assessing the accuracy of rates, we should consider the source. Mortality \nrates found in a source such as the Statistical Abstract of the United States (compiled \nby the U.S. Bureau of the Census) are likely to be quite accurate, because each state \nnow has a mandatory death reporting system, although official government reports \nseem to take years to produce. However, morbidity rates are likely to be less accurate, \nbecause some diseases are known to be underreported or not reported at all. Some \nmorbidity rates might be the result of very questionable surveys. However, some sur-\nveys, such as the annual National Health Survey, involve large samples of people who \nare very carefully chosen, so that results are likely to be very accurate.\nStatistical Literacy and Critical Thinking \n1. Birth Rate The birth rate in China is 12.3 per 1000. What exactly does that mean?\n2. Rates Exercise 1 describes the birth rate in China as 12.3 per 1000. Another way to describe \nthe birth rate is to give the rate as a proportion or probability of 0.0123. What advantage does \nthe rate of “12.3 per 1000” have over the rate expressed as 0.0123?\n3. Expected Births Given that China has a birth rate of 12.3 per 1000 and a population of \n1,360,762,587, about how many births are expected in a year?\n4. Incidence and Prevalence What is the difference between a disease incidence rate and a \ndisease prevalence rate?\n4-5 Basic Skills and Concepts\nINTERPRETATION\nThe infant mortality rate of 6.0 deaths per 1000 infants under 1 year of age is sub-\nstantially greater than the infant mortality rate of 2.1 in Japan.\n\n4-5 Rates of Mortality, Fertility, and Morbidity \n165\nFinding Rates. In Exercises 5−12, use the data in the accompanying table (based on data \nfor a recent year from various sources, including the U.S. Census Bureau and the National \nInstitutes of Health) to find the indicated rates. Round results to one decimal place, and use \na multiplying factor of k = 1000 unless indicated otherwise.\nVital Statistics for the United States in One Year\nPopulation: 312,799,495\nDeaths: 2,515,458\nWomen aged 15–44: 61,488,227\nMotor vehicle deaths: 33,783\nLive births: 3,953,590\nFetuses delivered without life after 20 weeks of \ngestation: 26,148\nDeaths of infants under 1 year of age: 23,910\nDeaths of infants under 28 days of age: 15,973\nHIV-infected persons: 1,155,792\nDeaths from HIV infections: 7683\n5. Find the neonatal mortality rate.\n6. Find the fetal mortality rate.\n7. Find the perinatal mortality rate.\n8. Find the crude birth rate.\n9. Find the general fertility rate.\n10. Using a multiplier of k = 100,000, find the motor vehicle death incidence rate.\n11. Find the HIV infection prevalence rate.\n12. Find the HIV infection mortality rate for HIV-infected persons.\n13. Finding Probability An example in this section involved the crude mortality rate, which \nwas found to be 8.0 persons per 1000 population. Find the probability of randomly selecting \nsomeone and getting a person who died within the year. What advantage does the crude mortal-\nity rate have over the probability value?\n14. Finding Probability The crude death rate for China was recently 7.4, and that rate was \ncomputed using a multiplier of k = 1000.\na. Find the probability that a randomly selected Chinese person died within the year.\nb. If two Chinese people are randomly selected, find the probability that they both died within \nthe year, and express the result using three significant digits.\nc. If two Chinese people are randomly selected, find the probability that neither of them died \nwithin the year, and express the result using three significant digits.\n15. Finding Probability The crude death rate for Spain was recently 8.3, and that rate was \ncomputed using a multiplier of k = 1000.\na. Find the probability that a randomly selected Spaniard died within the year.\nb. If two Spaniards are randomly selected, find the probability that they both died within the \nyear, and express the result using three significant digits.\nc. If two Spaniards are randomly selected, find the probability that at least one of them sur-\nvived the year, and express the result using six decimal places. What would be wrong with \nexpressing the answer using three significant digits?\ncontinued\n\n166 \nCHAPTER 4 Probability\n16. Finding Probability In a recent year in the United States, there were 787,650 deaths due \nto cardiovascular disease, and the population was 312,799,495.\na. Find the crude mortality rate for cardiovascular disease. (This result is sometimes called the \ncause-specific death rate.)\nb. Find the probability that a randomly selected person died of cardiovascular disease and \n express the result using three significant digits.\nc. Find the probability that when three people are randomly selected, none of them died \n because of cardiovascular disease.\n17.  Cause-of-Death Ratio In a recent year in the United States, there were 2,515,458 \ndeaths, and 787,650 of them were due to cardiovascular disease. The cause-of-death ratio is \nexpressed as follows:\nadeaths due to specific disease\ntotal number of deaths\nbk where k = 100\na. Find the cause-of-death ratio for cardiovascular disease.\nb. If three of the deaths are randomly selected, find the probability that none of them are due to \ncardiovascular disease.\n18. Crude Mortality Rates The table below lists numbers of deaths and population sizes for \ndifferent age groups for Florida and the United States for a recent year.\na. Find the crude mortality rate for Florida and the crude mortality rate for the United States. Al-\nthough we should not compare crude mortality rates, what does the comparison suggest in this case?\nb. Using only the age group of 65 and older, find the mortality rates for Florida and the United \nStates. Compare the results.\nc. What percentage of the Florida population is made up of people aged 65 and older? What is \nthe percentage for the United States? What do the results suggest about the crude mortality for \nFlorida compared to the United States?\nAge\n0–24\n25–64\n65 and older\nFlorida deaths\n      3625\n     39,820\n   129,395\nFlorida population\n  5,716,861\n   9,842,031\n 3,375,303\nU.S. deaths\n     63,208\n    619,982\n 1,832,268\nU.S. population\n103,542,603\n163,960,163\n45,296,729\n19. Number of Deaths The number of deaths in the United States has been steadily increas-\ning each year. Does this mean that the health of the nation is declining? Why or why not?\n20. Comparing Rates In a recent year, the crude mortality rate of the United States was 8.0 \n(per 1000 population), and the corresponding crude mortality rate for China was 7.4. What is a \nmajor problem with comparing the crude mortality rates of the United States and China?\n21. Adjusted Mortality Rate Refer to the data listed in Exercise 18. Change the Florida popula-\ntion sizes for the three age categories so that they fit the same age distribution as the U.S. popu-\nlation. Next, adjust the corresponding numbers of deaths proportionately. (Use the same Florida \nmortality rates for the individual age categories, but apply those rates to the adjusted population \nsizes.) Finally, compute the Florida mortality rate using the adjusted values. The result is a mortal-\nity rate adjusted for the variable of age. (Better results could be obtained by using more age catego-\nries.) How does this adjusted mortality rate for Florida compare to the mortality rate for the United \nStates? (Note: There are other methods for computing adjusted rates than the one used here.)\n4-5 Beyond the Basics\n\n4-6 Counting \n167\nMULTIPLICATION COUNTING RULE: For a sequence of events in which the first \nevent can occur n1 ways, the second event can occur n2 ways, the third event can \noccur n3 ways, and so on, the total number of possibilities is n1 # n2 # n3 . . ..\nEXAMPLE 1  Multiplication Counting Rule: DNA\nIn a linear triplet of three DNA nucleotides, each of the nucleotides can be any one \nof these four bases (with repetition allowed): A (adenine); C (cytosine); G (guanine); \nT (thymine). Two different examples of triplets are CTA and TTG. What is the total \nnumber of different possible triplets? Given that the four nucleotides are equally \nlikely, what is the probability of getting the triplet of AAA?\nSOLUTION\nThere are 4 different possibilities for each of the three nucleotides, so the total num-\nber of different possible triplets is n1 # n2 # n3 = 4 # 4 # 4 = 64.\nIf the four nucleotides are equally likely, the probability of getting the triplet of \nAAA is 1>64 or 0.0156.\n2. Factorial Rule\nThe factorial rule is used to find the total number of ways that n different items can \nbe rearranged with different arrangements of the same items counted separately. The \nfactorial rule uses the following notation.\nNOTATION\nThe factorial symbol (!) denotes the product of decreasing positive whole num-\nbers. For example, 4! = 4 # 3 # 2 # 1 = 24. By special definition, 0! = 1.\nFACTORIAL RULE The number of different arrangements (order matters) of n \ndifferent items when all n of them are selected is n!.\nThe factorial rule is based on the principle that the first item may be selected n differ-\nent ways, the second item may be selected n - 1 ways, and so on.\nRouting problems often involve applications of the factorial rule, as in the follow-\ning example.\nKey Concept Probability problems typically require that we know the total number of \nsimple events, but finding that number often requires one of the five rules presented in \nthis section. In Section 4-2, with the addition rule, multiplication rule, and conditional \nprobability, we encouraged intuitive rules based on understanding and we discour-\naged blind use of formulas, but this section requires much greater use of formulas as \nwe consider five different methods for counting the number of possible outcomes in a \nvariety of situations. Not all counting problems can be solved with these five methods, \nbut they do provide a strong foundation for the most common real applications.\n1. Multiplication Counting Rule\nThe multiplication counting rule is used to find the total number of possibilities from \nsome sequence of events.\n4-6 \nCounting\n\n168 \nCHAPTER 4 Probability\nPermutations and Combinations: Does Order Count?\nWhen using different counting methods, it is essential to know whether different ar-\nrangements of the same items are counted only once or are counted separately. The \nterms permutations and combinations are standard in this context, and they are de-\nfined as follows:\nEXAMPLE 2  Factorial Rule: Travel Itinerary\nQuest Diagnostics collects blood specimens from different laboratories. A driver is \ndispatched to make collections at 5 different locations. How many different routes \nare possible?\nSOLUTION\nFor those 5 different locations, the number of different routes is 5! =\n5 # 4 # 3 # 2 # 1 = 120.\nNote that this solution could have been done by applying the multiplica-\ntion counting rule. The first stop can be any one of the 5 locations, the second \nstop can be any one of the 4 remaining locations, and so on. The result is again \n5 # 4 # 3 # 2 # 1 = 120. Use of the factorial rule has the advantage of including the \nfactorial symbol, which is sure to impress.\nDEFINITIONS\nPermutations of items are arrangements in which different sequences of the same \nitems are counted separately. (The letter arrangements of abc, acb, bac, bca, cab, \nand cba are all counted separately as six different permutations.)\nCombinations of items are arrangements in which different sequences of the \nsame items are counted as being the same. (The letter arrangements of abc, acb, \nbac, bca, cab, and cba are all considered to be the same single combination.)\nMnemonics for Permutations and Combinations\n \n■Remember “Permutations Position,” where the alliteration reminds us that with \npermutations, the positions of the items makes a difference.\n \n■Remember “Combinations Committee,” which reminds us that with members of \na committee, rearrangements of the same members result in the same committee, \nso order does not count.\n3. Permutations Rule (When All of the Items Are Different)\nThe permutations rule is used when there are n different items available for selection, \nwe must select r of them without replacement, and the sequence of the items matters. \nThe result is the total number of arrangements (or permutations) that are possible. (Re-\nmember: Rearrangements of the same items are counted as different permutations.)\nPERMUTATIONS RULE: When n different items are available and r of them are \nselected without replacement, the number of different permutations (order counts) \nis given by\nnPr =\nn!\n1n - r2!\n\n4-6 Counting \n169\n4. Permutations Rule (When Some Items Are Identical to Others)\nWhen n items are all selected without replacement, but some items are identical, the \nnumber of possible permutations (order matters) is found by using the following rule.\nEXAMPLE 3   Permutations Rule (with Different Items):  \nClinical Trial of New Drug\nWhen testing a new drug, Phase I requires only 5 volunteers, and the objective is \nto assess the drug’s safety. To be very cautious, we plan to treat the 5 subjects in \nsequence, so that any particularly adverse effect can allow us to stop the treatments \nbefore any other subjects are treated. If 8 volunteers are available, how many differ-\nent sequences of 5 subjects are possible?\nSOLUTION\nWe need to select r = 5 subjects from n = 8 volunteers that are available. The num-\nber of different sequences of arrangements is found as shown:\nnPr =\nn!\n1n - r2! =\n8!\n18 - 52! = 6720\nThere are 6720 different possible arrangements of 5 subjects selected from the 8 \nthat are available.\nPERMUTATIONS RULE (WHEN SOME ITEMS ARE IDENTICAL TO OTHERS)\nThe number of different permutations (order counts) when n items are available \nand all n of them are selected without replacement, but some of the items are iden-\ntical to others, is found as follows:\nn!\nn1!n2! . . . nk! where n1 are alike, n2 are alike,…, and nk are alike.\nEXAMPLE 4   Permutations Rule (with Some Identical Items):  \nDesigning Surveys\nWhen designing surveys, pollsters sometimes repeat a question to see if a subject \nis thoughtlessly providing answers just to finish quickly. For one particular survey \nwith 10 questions, 2 of the questions are identical to each other, and 3 other ques-\ntions are also identical to each other. For this survey, how many different arrange-\nments are possible? Is it practical to survey enough subjects so that every different \npossible arrangement is used?\nSOLUTION\nWe have 10 questions with 2 that are identical to each other and 3 others that are \nalso identical to each other, and we want the number of permutations. Using the rule \nfor permutations with some items identical to others, we get\nn!\nn1!n2! . . . nk! = 10!\n2!3! = 3,628,800\n2 # 6\n= 302,400\ncontinued\n\n170 \nCHAPTER 4 Probability\n5. Combinations Rule\nThe combinations rule is used when there are n different items available for selection, \nonly r of them are selected without replacement, and order does not matter. The result \nis the total number of combinations that are possible. (Remember: Rearrangements of \nthe same items are considered to be the same combination.)\nINTERPRETATION\nThere are 302,400 different possible arrangements of the 10 questions. It is not \npractical to accommodate every possible permutation. For typical surveys, the num-\nber of respondents is somewhere around 1000.\nCOMBINATIONS RULE:\nWhen n different items are available, but only r of them are selected without replace-\nment, the number of different combinations (order does not matter) is found as follows:\nnCr =\nn!\n1n - r2!r!\nEXAMPLE 5  Combinations Rule: Phase I of a Clinical Trial\nWhen testing a new drug on humans, a clinical test is normally done in three \nphases. Phase I is conducted with a relatively small number of healthy volunteers. \nAssume that we want to treat 20 healthy humans with a new drug, and we have  \n30 suitable volunteers available. If 20 subjects are selected from the 30 that are \navailable, and the 20 selected subjects are all treated at the same time, how many \ndifferent treatment groups are possible?\nSOLUTION\nBecause all subjects are treated at the same time, order is irrelevant, so we need to \nfind the number of different possible combinations. With n = 30 subjects available \nand with r = 20 subjects selected, the number of combinations is found as follows.\nnCr =\nn!\n1n - r2!r! =\n30!\n130 - 202!20! =\n30!\n10! # 20! = 30,045,015\nINTERPRETATION\nThere are 30,045,015 different possible combinations.\nPermutations or Combinations? Because choosing between permutations and com-\nbinations can often be tricky, we provide the following example that emphasizes the \ndifference between them.\nEXAMPLE 6   Permutations and Combinations:  \nOfficers and Committees\nThe Portland Medical Center must appoint three corporate officers: chief executive \nofficer (CEO), executive chairperson, and chief operating officer (COO). It must \nalso appoint a planning committee with three different members. There are eight \nqualified candidates, and officers can also serve on the planning committee.\n\n4-6 Counting \n171\n \na. How many diﬀerent ways can the oﬃcers be appointed?\n \nb. How many diﬀerent ways can the committee be appointed?\nSOLUTION\nNote that in part (a), order is important because the officers have very different \nfunctions. However, in part (b), the order of selection is irrelevant because the com-\nmittee members all serve the same function.\n \na. Because order does count, we want the number of permutations of r = 3 \npeople selected from the n = 8 available people. We get\nnPr =\nn!\n1n - r2! =\n8!\n18 - 32! = 336\n \nb. Because order does not count, we want the number of combinations of r = 3 \npeople selected from the n = 8 available people. We get\nnCr =\nn!\n1n - r2!r! =\n8!\n18 - 32!3! = 56\nWith order taken into account, there are 336 different ways that the officers can be \nappointed, but without order taken into account, there are 56 different possible com-\nmittees.\nStatistical Literacy and Critical Thinking \n1. Notation What does the symbol ! represent? Six different patients can be scheduled for \nX-ray films 6! different ways, so what is the actual number of ways that six people can be \nscheduled for X-ray films?\n2.  Permutations, Combinations What is the basic difference between permutations and \ncombinations?\n3. Notation Evaluate 9C4. What does the result represent?\n4. Notation Evaluate 9P4. What does the result represent?\nIn Exercises 5–30, express all probabilities as fractions.\n5. Pin Numbers The Kinsale Medical Supply Company issues pin numbers to its employees \nso that they can access an online database. A hacker must randomly guess the correct pin code \nfor the Information Technology supervisor, and that pin code consists of four digits (each 0 \nthrough 9) that must be entered in the correct order. Repetition of digits is allowed. What is the \nprobability of a correct guess on the first try?\n6. Social Security Numbers A Social Security number consists of nine digits in a particular \norder, and repetition of digits is allowed. After seeing the last four digits printed on a receipt, if \nyou randomly select the other digits, what is the probability of getting the correct Social Secu-\nrity number of the person who was given the receipt?\n7. Assigning Shifts The staff supervisor at the Wellington Medical Center must assign a \nteam of two physicians to work the emergency room on Saturday night. If there are 19 physi-\ncians available and two of them are randomly selected, what is the probability of getting the \ntwo youngest physicians?\n4-6 Basic Skills and Concepts\n\n172 \nCHAPTER 4 Probability\n8. Review Board The supervisor at the Wellington Medical Center must select three nurses \nfrom 11 who are available for a review board. How many different ways can that be done?\n9. Blood Test Quest Diagnostics has just received 8 different blood samples. If they are tested \nin random order, what is the probability that they are tested in the alphabetical order of the sub-\njects who provided the samples?\n10. Radio Station Call Letters If radio station call letters must begin with either K or W and \nmust contain a total of either three or four letters, how many different possibilities are there?\n11. Scheduling Routes A new director of the Veterans Health Administration plans to visit \none hospital in each of five different states. If the five states are randomly selected from all 50 \nstates without replacement and the order is also random, what is the probability that she visits \nIdaho, Oregon, Alaska, New Jersey, and Ohio, in that order?\n12. Survey Reliability A health survey with 12 questions is designed so that 3 of the ques-\ntions are identical and 4 other questions are identical (except for minor changes in wording). \nHow many different ways can the 12 questions be arranged?\n13. Safety with Numbers A safe “combination” consists of four numbers between 0 and 99, \nand the safe is designed so that numbers can be repeated. If someone tries to gain access to the \nsafe, what is the probability that he or she will get the correct combination on the first attempt? \nAssume that the numbers are randomly selected. Given the number of possibilities, does it \nseem feasible to try opening the safe by making random guesses for the combination?\n14. Electricity The control panel for an MRI device uses five color-coded wires. If we trou-\nbleshoot by testing two wires at a time, how many different tests are required for every possible \npairing of two wires?\n15. Clinical Trial In a clinical trial of the drug atorvastatin (Lipitor), one group of subjects \nwas given placebos, a second group was given treatments of 10 mg, a third group was given \ntreatments of 20 mg, a fourth group was given treatments of 40 mg, and a fifth group was given \ntreatments of 80 mg. If the Phase I trial involved 15 subjects randomly assigned to the five \ngroups with three in each group, how many different ways can the groups be formed?\n16. Emergency Room Instead of treating emergency room patients in the order that they \narrive, it is common to treat those with more serious problems first. If an emergency room has \nseven different patients, how many ways can they be arranged in sequence?\n17. ZIP Code If you randomly select five digits, each between 0 and 9, with repetition allowed, \nwhat is the probability you will get the ZIP code of the Secretary of Health and Human Services?\n18. FedEx Deliveries With a short time remaining in the day, a FedEx driver has time to make \ndeliveries at 6 locations among the 9 locations remaining. How many different routes are possible?\n19. Phone Numbers Current rules for telephone area codes allow the use of digits 2–9 for \nthe first digit and 0–9 for the second and third digits. How many different area codes are pos-\nsible with these rules? That same rule applies to the exchange numbers, which are the three \ndigits immediately preceding the last four digits of a phone number. Given both of those rules, \nhow many ten-digit phone numbers are possible? Given that these rules apply to the United \nStates and Canada and a few islands, are there enough possible phone numbers? (Assume that \nthe combined population is about 400,000,000.)\n20. Classic Counting Problem A classic counting problem is to determine the number of \ndifferent ways that the letters of “Mississippi” can be arranged. Find that number.\n21. Corporate Officers and Committees The Newport Medical Supply Company must \nappoint a president, chief executive officer (CEO), chief operating officer (COO), and chief \nfinancial officer (CFO). It must also appoint a strategic planning committee with four different \nmembers. There are 10 qualified candidates, and officers can also serve on the committee.\na. How many different ways can the four officers be appointed?\nb. How many different ways can a committee of four be appointed?\ncontinued\n\n4-6 Counting \n173\nc. What is the probability of randomly selecting the committee members and getting the four \nyoungest of the qualified candidates?\n22. Card Access You have an identification card used for access to a secure area of the Wel-\nlington Medical Center. It’s dark and you can’t see your card when you insert it. The card must \nbe inserted with the front side up and the printing configured so that the beginning of your \nname enters first.\na. What is the probability of selecting a random position and inserting the card with the result \nthat the card is inserted correctly?\nb. What is the probability of randomly selecting the card’s position and finding that it is incor-\nrectly inserted on the first attempt, but it is correctly inserted on the second attempt?\nc. How many random selections are required to be absolutely sure that the card works because \nit is inserted correctly?\n23. Amino Acids With 8 different amino acids available, 5 are to be selected to form a chain \n(called a polypeptide chain) in which order counts. How many different chains are possible?\n24. Identity Theft with Credit Cards Credit card numbers typically have 16 digits, but not \nall of them are random.\na. What is the probability of randomly generating 16 digits and getting your MasterCard number?\nb. Receipts often show the last four digits of a credit card number. If only those last four digits are \nknown, what is the probability of randomly generating the other digits of your MasterCard number?\nc. Discover cards begin with the digits 6011. If you know that the first four digits are 6011 and \nyou also know the last four digits of a Discover card, what is the probability of randomly gener-\nating the other digits and getting all of them correct? Is this something to worry about?\n25. What a Word! One of the longest words in standard statistics terminology is “homosce-\ndasticity.” How many ways can the letters in that word be arranged?\n26. Phase I of a Clinical Trial A clinical test on humans of a new drug is normally done \nin three phases. Phase I is conducted with a relatively small number of healthy volunteers. For \nexample, a Phase I test of bexarotene involved only 14 subjects. Assume that we want to treat \n14 healthy humans with this new drug and we have 16 suitable volunteers available.\na. If the subjects are selected and treated one at a time in sequence, how many different sequen-\ntial arrangements are possible if 14 people are selected from the 16 that are available?\nb. If 14 subjects are selected from the 16 that are available, and the 14 selected subjects are all \ntreated at the same time, how many different treatment groups are possible?\nc. If 14 subjects are randomly selected and treated at the same time, what is the probability of \nselecting the 14 youngest subjects?\n27. Lightning and Lottery As of this writing, the Mega Millions lottery is run in 44 states. \nWinning the jackpot requires that you select the correct five different numbers between 1 and \n75 and, in a separate drawing, you must also select the correct single number between 1 and 15. \nFind the probability of winning the jackpot if you buy one ticket. How does the result compare \nto the probability of being struck by lightning in a year, which the National Weather Service \nestimates to be 1>960,000?\n28. Designing Experiment Clinical trials of Nasonex involved a group given placebos and \nanother group given treatments of Nasonex. Assume that a preliminary Phase I trial is to be \nconducted with 12 subjects, including 6 men and 6 women. If 6 of the 12 subjects are randomly \nselected for the treatment group, find the probability of getting 6 subjects of the same gender. \nWould there be a problem with having members of the treatment group all of the same gender?\n\n174 \nCHAPTER 4 Probability\n29. Morse Codes The International Morse code is a way of transmitting coded text by using \nsequences of on>off tones. Each character is 1 or 2 or 3 or 4 or 5 segments long, and each seg-\nment is either a dot or a dash. For example, the letter G is transmitted as two dashes followed \nby a dot, as in — — •. How many different characters are possible with this scheme? Are there \nenough characters for the alphabet and numbers?\n30. Mendel’s Peas Mendel conducted some his famous experiments with peas that were \neither smooth yellow plants or wrinkly green plants. If four peas are randomly selected from a \nbatch consisting of four smooth yellow plants and four wrinkly green plants, find the probabil-\nity that the four selected peas are of the same type.\n31. Computer Variable Names A common computer programming rule is that names of \nvariables must be between one and eight characters long. The first character can be any of the \n26 letters, while successive characters can be any of the 26 letters or any of the 10 digits. For \nexample, allowable variable names include A, BBB, and M3477K. How many different vari-\nable names are possible? (Ignore the difference between uppercase and lowercase letters.)\n32. Handshakes\na. Five physicians gather for a meeting about a patient. If each physician shakes hands with \neach other physician exactly once, what is the total number of handshakes?\nb. If n physicians shake hands with each other exactly once, what is the total number of hand-\nshakes?\nc. How many different ways can five physicians be seated at a round table? (Assume that if \neveryone moves to the right, the seating arrangement is the same.)\nd. How many different ways can n physicians be seated at a round table?\n4-6 Beyond the Basics\n1. Standard Tests Standard tests, such as the MCAT, tend to make extensive use of multiple-\nchoice questions because they are easy to grade using software. If one such multiple-choice \nquestion has possible correct answers of a, b, c, d, e, what is the probability of a wrong answer \nif the answer is a random guess?\n2.  Likelihood of Disease After obtaining a patient’s positive test result, a physician con-\ncludes that there is a 30% chance that the subject has a disease. What is the probability that the \nsubject does not have the disease?\n3. Months If a month is randomly selected after mixing the pages from a calendar, what is the \nprobability that it is a month containing the letter y?\n4.  Sigmoidoscopy, Colonoscopy Based on data from the Centers for Disease Control, \n67.7% of males over the age of 50 have had a sigmoidoscopy or colonoscopy. If two males over \nthe age of 60 are randomly selected, what is the probability that they both have had a sigmoid-\noscopy or colonoscopy?\n5. Subjective Probability Estimate the probability that the next time you get a cut, it requires \nstitches.\nChapter Quick Quiz\n\nIn Exercises 6–10, use the following results from tests of an experiment to test the effective-\nness of an experimental vaccine for children (based on data from USA Today). Express all \nprobabilities in decimal form.\nDeveloped Flu\nDid Not Develop Flu\nVaccine Treatment\n14\n1056\nPlacebo\n95\n 437\n6. If 1 of the 1602 subjects is randomly selected, find the probability of getting 1 that devel-\noped flu.\n7. If 1 of the 1602 subjects is randomly selected, find the probability of getting 1 who had the \nvaccine treatment or developed flu.\n8. If 1 of the 1602 subjects is randomly selected, find the probability of getting 1 who had the \nvaccine treatment and developed flu.\n9. Find the probability of randomly selecting 2 subjects without replacement and finding that \nthey both developed flu.\n10. Find the probability of randomly selecting 1 of the subjects and getting 1 who developed \nflu, given that the subject was given the vaccine treatment.\nIn Exercises 1–10, use the data in the accompanying table and express all results in decimal \nform. (The results are based on “Splinting vs Surgery in the Treatment of Carpal Tunnel Syn-\ndrome,” by Gerritsen et al., Journal of the American Medical Association, Vol. 288, No. 10.)\nTreatment for Carpal Tunnel Syndrome\nSuccessful Treatment\nUnsuccessful Treatment\nSplint Treatment\n60\n23\nSurgery Treatment\n67\n 6\n1. Success If 1 of the patients is randomly selected, find the probability of selecting someone \nwith a successful treatment.\n2. Success Find the probability of randomly selecting a patient and getting one with a suc-\ncessful treatment, given that the patient was treated with splinting.\n3. Success Find the probability of randomly selecting a patient and getting one with a suc-\ncessful treatment, given that the patient was treated with surgery.\n4. Success or Surgery If 1 of the patients is randomly selected, find the probability of get-\nting a patient who had a successful treatment or was treated with surgery.\n5. No Success or Splint If 1 of the patients is randomly selected, find the probability of get-\nting someone who had an unsuccessful treatment or was treated with a splint.\n6. Both Successful If 2 patients are randomly selected without replacement, find the prob-\nability that they both had successful treatments.\n7. Both Successful If 2 patients are randomly selected with replacement, find the probability \nthat they both had successful treatments.\n8. Complement If A represents the event of randomly selecting one patient included in the \ntable and getting someone who was treated with surgery, what does A represent? Find the value \nof P1A2.\nReview Exercises\nCHAPTER 4 Review Exercises \n175\n\n176 \nCHAPTER 4 Probability\n9. Complement If A represents the event of randomly selecting one patient included in the \ntable and getting someone who had a successful treatment, what does A represent? Find the \nvalue of P1A2.\n10. All Three Successful If 3 patients are randomly selected without replacement, find the \nprobability that all three had successful treatments.\n11. Vision Correction About 75% of the U.S. population uses some type of vision correction \n(such as glasses or contact lenses).\na. If someone is randomly selected, what is the probability that he or she does not use vision \ncorrection?\nb. If four different people are randomly selected, what is the probability that they all use vision \ncorrection?\nc. Would it be unlikely to randomly select four people and find that they all use vision correc-\ntion? Why or why not?\n12. National Statistics Day\na. If a person is randomly selected, find the probability that his or her birthday is October 18, \nwhich is National Statistics Day in Japan. Ignore leap years.\nb. If a person is randomly selected, find the probability that his or her birthday is in October. \nIgnore leap years.\nc. Estimate a subjective probability for the event of randomly selecting an adult American and \ngetting someone who knows that October 18 is National Statistics Day in Japan.\nd. Is it unlikely to randomly select an adult American and get someone who knows that Octo-\nber 18 is National Statistics Day in Japan?\n13. Composite Sampling for Diabetes Currently, the rate for new cases of diabetes in a year \nis 3.4 per 1000 (based on data from the Centers for Disease Control and Prevention). When \ntesting for the presence of diabetes, the Portland Diagnostics Laboratory saves money by com-\nbining blood samples for tests. The combined sample tests positive if at least one person has \ndiabetes. If the combined sample tests positive, then the individual blood tests are performed. \nIn a test for diabetes, blood samples from 10 randomly selected subjects are combined. Find \nthe probability that the combined sample tests positive with at least 1 of the 10 people having \ndiabetes. Is it likely that such combined samples test positive?\n14. Redundancy Using battery-powered alarm clocks, it is estimated that the probability of \nfailure on any given day is 1>1000.\na. What is the probability that the alarm clock works for an important event?\nb. When using two alarm clocks for an important event, what is the probability that at least one \nof them works?\nCumulative Review Exercises\n1. Fatal Drunk Driving Listed below are the blood alcohol concentrations (g>dL) of drivers \nconvicted of drunk driving in fatal car crashes (based on data from the National Highway Traf-\nfic Safety Administration).\n0.09 0.11 0.11 0.13 0.14 0.15 0.17 0.17 0.18 0.18 0.23 0.35\nFind the value of the following statistics and include appropriate units.\na. mean         b. median   c. midrange   d. range\ne. standard deviation   f. variance\n\n2. Fatal Drunk Driving Use the same data given in Exercise 1.\na. Identify the 5-number summary and also identify any values that appear to be outliers.\nb. Construct a boxplot.  c. Construct a stemplot.\n3. Organ Donors USA Today provided information about a survey (conducted for Donate Life \nAmerica) of 5100 adult Internet users. Of the respondents, 2346 said they are willing to donate \norgans after death. In this survey, 100 adults were surveyed in each state and the District of Co-\nlumbia, and results were weighted to account for the different state population sizes.\na. What percentage of respondents said that they are willing to donate organs after death?\nb. Based on the poll results, what is the probability of randomly selecting an adult who is will-\ning to donate organs after death?\nc. What term is used to describe the sampling method of randomly selecting 100 adults from \neach state and the District of Columbia?\n4. Sampling Eye Color Based on a study by Dr. P. Sorita Soni, eye colors in the United States \nare as follows: 40% brown, 35% blue, 12% green, 7% gray, 6% hazel.\na. A statistics instructor collects eye color data from her students. What is the name for this \ntype of sample?\nb. Identify one factor that might make the sample from part (a) biased and not representative of \nthe general population of people in the United States.\nc. What is the probability that a randomly selected person will have brown or blue eyes?\nd. If two people are randomly selected, what is the probability that at least one of them has \nbrown eyes?\n5. Blood Pressure and Platelets Given below are the systolic blood pressure measurements \n(mm Hg) and blood platelet counts (1000 cells>mL) of the first few subjects included in Data \nSet 1 “Body Data” in Appendix B. Construct a graph suitable for exploring an association be-\ntween systolic blood pressure and blood platelet count. What does the graph suggest about that \nassociation?\nSystolic\n100\n112\n134\n126\n114\n134\n118\n138\n114\n124\nPlatelet\n319\n187\n297\n170\n140\n192\n191\n286\n263\n193\nCHAPTER 4 Technology Project \n177\nSimulations Calculating probabilities are sometimes painfully difficult, but simulations pro-\nvide us with a very practical alternative to calculations based on formal rules. A simulation \nof a procedure is a process that behaves the same way as the procedure so that similar results \nare produced. Instead of calculating the probability of getting exactly 5 boys in 10 births, you \ncould repeatedly toss 10 coins and count the number of times that exactly 5 heads (or simulated \n“boys”) occur. Better yet, you could do the simulation with a random number generator on a \ncomputer or calculator to randomly generate 1s (or simulated “boys”) and 0s (or simulated \n“girls”). Let’s consider this probability exercise:\nFind the probability that among 50 randomly selected people, at least 3 have  \nthe same birthday.\nFor the above problem, a simulation begins by representing birthdays by integers from \n1 through 365, where 1 represents a birthday of January 1, and 2 represents January 2, \nand so on. We can simulate 50 birthdays by using a calculator or computer to generate 50 \nTechnology Project\ncontinued\n\n178 \nCHAPTER 4 Probability\nrandom numbers (with repetition allowed) between 1 and 365. Those numbers can then be \nsorted, so it becomes easy to examine the list to determine whether any 3 of the simulated \nbirth dates are the same. (After sorting, equal numbers are adjacent.) We can repeat the \nprocess as many times as we wish, until we are satisfied that we have a good estimate of the \nprobability. Use technology to simulate 20 different groups of 50 birthdays. Use the results \nto estimate the probability that among 50 randomly selected people, at least 3 have the same \nbirthday.\nSummary of Simulation Functions:\nStatdisk: \n Select Data from the top menu, select Uniform Generator from the \ndropdown menu.\nExcel: \n Click Insert Function fx, select Math & Trig, select  \nRANDBETWEEN. Copy to additional cells.\nTI-83 , 84 Plus:  Press L, select PROB from the top menu, select randInt from the menu.\nStatCrunch: \n Select Data from the top menu, select Simulate from the dropdown \nmenu, select Discrete Uniform from the submenu.\nMinitab: \n Select Calc from the top menu, select Random Data from the drop-\ndown menu, select Integer from the submenu.\nFROM DATA TO DECISION \nCritical Thinking:  \nInterpreting results from a test for smoking\nIt is estimated that roughly half of patients who smoke lie \nwhen asked if they smoke. Pulse CO-oximeters may be a \nway to get information about smoking without relying on pa-\ntients’ statements. Pulse CO-oximeters use light that shines \nthrough a fingernail, and it measures carboxyhemoglobin \n(carbon monoxide in blood). These devices are used by fire-\nmen and emergency departments to detect carbon monoxide \npoisoning, but they can also be used to identify smokers. The \naccompanying table lists results from people aged 18–44 \nwhen the pulse CO-oximeter is set to detect a 6% or higher \nlevel of carboxyhemoglobin (based on data from “Carbon \nMonoxide Test Can Be Used to Identify Smoker,” by Patrice \nWendling, Internal Medicine News, Vol. 40., No. 1, and \nCenters for Disease Control and Prevention).\nCO-Oximetry Test for Smoking\nPositive Test Result\nNegative Test Result\nSmoker\n49\n 57\nNonsmoker\n24\n370\nAnalyzing the Results\n1. False Positive Based on the results in the table, find the \nprobability that a subject is not a smoker, given that the test \nresult is positive.\n2. True Positive Based on the results in the table, find the \nprobability that a subject smokes, given that the test result is \npositive.\n3. False Negative Based on the results in the table, find the \nprobability that a subject smokes, given that the test result is \nnegative.\n4. True Negative Based on the results in the table, find the \nprobability that a subject does not smoke, given that the test \nresult is negative.\n5. Sensitivity Find the sensitivity of the test by finding the \nprobability of a true positive, given that the subject actually \nsmokes.\n6. Specificity Find the specificity of the test by finding the \nprobability of a true negative, given that the subject does not \nsmoke.\n7. Positive Predictive Value Find the positive predictive \nvalue of the test by finding the probability that the subject \nsmokes, given that the test yields a positive result.\n8. Negative Predictive Value Find the negative predictive \nvalue of the test by finding the probability that the subject \ndoes not smoke, given that the test yields a negative result.\n9. Confusion of the Inverse Find the following values, \nthen compare them. In this case, what is confusion of the \ninverse?\n• P(smoker \u001f positive test result)\n• P(positive test result \u001f smoker)\n\nCooperative Group Activities\n1. In-class activity Divide into groups of three or four and use coin flipping to develop a simula-\ntion that emulates the kingdom that abides by this decree: After a mother gives birth to a son, she \nwill not have any other children. If this decree is followed, does the proportion of girls increase?\n2. In-class activity Divide into groups of three or four and use actual thumbtacks or Hershey’s \nKisses candies, or paper cups, to estimate the probability that when dropped, they will land \nwith the point (or open side) up. How many trials are necessary to get a result that appears to be \nreasonably accurate when rounded to the first decimal place?\n3. Out-of-class activity Marine biologists often use the capture-recapture method as a way \nto estimate the size of a population, such as the number of fish in a lake. This method involves \ncapturing a sample from the population, tagging each member in the sample, and then return-\ning it to the population. A second sample is later captured, and the tagged members are counted \nalong with the total size of this second sample. The results can be used to estimate the size of \nthe population.\nInstead of capturing real fish, simulate the procedure using some uniform collection of \nitems such as colored beads, M&Ms, or index cards. Start with a large collection of at least \n200 of such items. Collect a sample of 50 and use a marker to “tag” each one. Replace the \ntagged items, mix the whole population, then select a second sample and proceed to estimate \nthe population size. Compare the result to the actual population size obtained by counting all \nof the items.\n4. Out-of-class activity In Cumulative Review Exercise 4, it was noted that eye colors in \nthe United States are distributed as follows: 40% brown, 35% blue, 12% green, 7% gray, 6% \nhazel. That distribution can form the basis for probabilities. Conduct a survey by asking fellow \nstudents to identify the color of their eyes. Does the probability of 0.4 for brown eyes appear to \nbe consistent with your results? Why would a large sample be required to confirm that P(hazel \neyes) = 0.06?\nCHAPTER 4 Cooperative Group Activities \n179\n\n180\nProbability Distributions\nBinomial Probability \nDistributions\nPoisson Probability \nDistributions\n5-1\n5-2\n5-3\nIs the XSORT Gender Selection Method Effective?\nCHAPTER \nPROBLEM\nDiscrete Probability \nDistributions\nWe live in a time with incredible advances in technology, med-\nicine, and health care. Cloning is no longer science  fiction. We \nhave iPads, iPhones, virtual-reality headsets, and self-driving \ncars. We carry calculators that can instantly execute many \ncomplex statistical calculations. Heart  pacemakers have defi-\nbrillators capable of shocking and restarting stopped hearts. \nCouples use procedures that are claimed to greatly increase \nthe chance of having a baby with a desired gender.\nSome people argue that gender selection methods should \nbe banned, regardless of the reason, while others enthusiasti-\ncally support the use of such methods. Lisa Belkin asked in the \nNew York Times Magazine, “If we allow parents to choose the \nsex of their child today, how long will it be before they order up \neye color, hair color, personality traits, and IQ?” There are some \nconvincing arguments in favor of at least limited use of gender \nselection. One such argument involves couples carrying  \n5 \n\nX-linked recessive genes. For some of these couples, any male \nchildren have a 50% chance of inheriting a disorder, but none \nof the female children will inherit the disorder. These couples \nmay want to use gender selection as a way to ensure that they \nhave baby girls, thereby guaranteeing that a disorder will not \nbe inherited by any of their children.\nThe Genetics & IVF Institute in Fairfax, Virginia, devel-\noped a technique called MicroSort and claimed that it in-\ncreases the chances of a couple having a baby with a desired \ngender. (Clinical trials of MicroSort have been discontinued.) \nThe  MicroSort XSORT method is claimed to increase the \nchances of a couple having a baby girl, and the MicroSort \nYSORT method is claimed to increase the chances of a \nbaby boy. The latest results for the XSORT method consist \nof 945 couples who wanted to have baby girls. After using \nthe XSORT technique, 879 of those couples had baby girls. \n(See Figure 5-1 for a bar graph illustrating these results.) \nWe usually expect that in 945 births, the number of girls \nshould be somewhere around 472 or 473. Given that 879 out \nof 945 couples had girls, can we conclude that the XSORT \ntechnique is effective, or might we explain the outcome as \njust a chance sample result? In answering that question, we \nwill use principles of probability to determine whether the \nobserved birth  results differ significantly from results that we \nwould expect from random chance. This is a common goal \nof inferential statistics: Determine whether results can be \nreasonably  explained by random chance or whether random \nchance doesn’t appear to be a feasible explanation, so that \nother  factors are influencing results. In this chapter we pres-\nent methods that allow us to find the probabilities we need \nfor  determining whether the XSORT results are significant, \n suggesting that the method is effective.\nFigure 5-2 on the next page provides a visual illustration of what this chapter accom-\nplishes. When investigating the numbers of heads in two coin tosses, we can use the \nfollowing two different approaches:\n• Use real sample data to find actual results: The approach of Chapters 2 and 3 is \nto collect sample data from actual coin tosses, then summarize the results in a table \nrepresenting the frequency distribution, and then find statistics, such as the sample \nmean x and the sample standard deviation s.\n• Use probabilities to find expected results: Using principles of probability from \nChapter 4, we can find the probability for each possible number of heads in two \ntosses. Then we could summarize the results in a table representing a probability \ndistribution.\nIn this chapter we merge the above two approaches as we create a table de-\nscribing what we expect to happen (instead of what did happen), then we find the \npopulation mean m and population standard deviation s. The table at the extreme \nright in Figure 5-2 is a probability distribution, because it describes the distribution \nusing probabilities instead of frequency counts. The remainder of this book and  \nthe core of inferential statistics are based on some knowledge of probability  \ndistributions. In this chapter we focus on discrete probability distributions.  \n \nChapter Objectives \n181\nCHAPTER OBJECTIVES\n>>>\nFIGURE 5-1 Results from the XSORT Method of \nGender Selection\n\n182 \nCHAPTER 5 Discrete Probability Distributions\nKey Concept This section introduces the concept of a random variable and the con-\ncept of a probability distribution. We illustrate how a probability histogram is a graph \nthat visually depicts a probability distribution. We show how to find the important \nparameters of mean, standard deviation, and variance for a probability distribution. \nMost importantly, we describe how to determine whether outcomes are significant \n(significantly low or significantly high). We begin with the related concepts of random \nvariable and probability distribution.\n5-1 \n Probability Distributions\nCount numbers of\nheads in tosses of\ntwo coins.\nCollect sample\ndata from two coin\ntosses, then ﬁnd\nstatistics and\ncreate graphs.\nNumber\nof heads\nx\n0\n1\n2\nf\n27\n56\n17\nCreate a theoretical model\nof the expected results,\nthen ﬁnd parameters.\nFind the probability for\neach possible number of\nheads in two coin tosses.\nP(0) 5 0.25\nP(1) 5 0.50\nP(2) 5 0.25\nChapters\n2 and 3\nChapter 4\nChapters 2 and 3\nChapter 5\nChapter 4\nx 5 0.9\ns 5 0.7\nNumber of\nheads in two\ncoin tosses\nx\n0\n1\n2\nP(x)\n0.25\n0.50\n0.25\nm 5 1.0\ns 5 0.7\nFIGURE 5-2\nHere are the chapter objectives:\nProbability Distributions\n• Define random variable and probability distribution.\n• Determine when a potential probability distribution actually satisfies the necessary \nrequirements.\n• Given a probability distribution, compute the mean and standard deviation, then use \nthose results to determine whether results are significantly low or significantly high.\nBinomial Probability Distributions\n• Describe a binomial probability distribution and find probability values for a binomial \ndistribution.\n• Compute the mean and standard deviation for a binomial distribution, then use \nthose results to determine whether results are significantly low or significantly high.\nPoisson Probability Distributions\n• Describe a Poisson probability distribution and find probability values for a Poisson \ndistribution.\n5-1\n5-2\n5-3\nCollect sample\ndata from two coin\ntosses, then ﬁnd\nstatistics and\ncreate graphs.\nNumber\nof heads\nx\n0\n1\n2\nf\n27\n56\n17\nCreate a theoretical model\nof the expected results,\nthen ﬁnd parameters.\nFind the probability for\neach possible number of\nheads in two coin tosses.\nP(0) 5 0.25\nP(1) 5 0.50\nP(2) 5 0.25\nChapters 2 and 3\nChapter 5\nChapter 4\nx 5 0.9\ns 5 0.7\nNumber of\nheads in two\ncoin tosses\nx\n0\n1\n2\nP(x)x)x\n0.25\n0.50\n0.25\nm 5 1.0\ns 5 0.7\nHere are the chapter objectives:\nProbability Distributions\n• Define random variable and probability distribution.\n• Determine when a potential probability distribution actually satisfies the necessary \nrequirements.\n• Given a probability distribution, compute the mean and standard deviation, then use\nthose results to determine whether results are significantly low or significantly high.\nBinomial Probability Distributions\n• Describe a binomial probability distribution and find probability values for a binomial\ndistribution.\n• Compute the mean and standard deviation for a binomial distribution, then use \nthose results to determine whether results are significantly low or \nw \nw\nsignificantly high.\nPoisson Probability Distributions\n• Describe a Poisson probability distribution and find probability values for a Poisson \ndistribution.\n\n5-1 Probability Distributions \n183\nPART 1\nBasic Concepts of a Probability Distribution\nDEFINITIONS\nA random variable is a variable (typically represented by x) that has a single nu-\nmerical value, determined by chance, for each outcome of a procedure.\nA probability distribution is a description that gives the probability for each value \nof the random variable. It is often expressed in the format of a table, formula, or \ngraph.\nIn Section 1-2 we made a distinction between discrete and continuous data. \n Random variables may also be discrete or continuous, and the following two defini-\ntions are consistent with those given in Section 1-2.\nDEFINITIONS\nA discrete random variable has a collection of values that is finite or countable. \n(If there are infinitely many values, the number of values is countable if it is pos-\nsible to count them individually, such as the number of tosses of a coin before \ngetting heads.)\nA continuous random variable has infinitely many values, and the collec-\ntion of values is not countable. (That is, it is impossible to count the individual \nitems because at least some of them are on a continuous scale, such as body \ntemperatures.)\nThis chapter deals exclusively with discrete random variables, but the following \nchapters deal with continuous random variables.\nProbability Distribution: Requirements\nEvery probability distribution must satisfy each of the following three requirements.\n1. There is a numerical (not categorical) random variable x, and its number values \nare associated with corresponding probabilities.\n2. ΣP(x)  =   1 where x assumes all possible values. (The sum of all probabilities \nmust be 1, but sums such as 0.999 or 1.001 are acceptable because they result \nfrom rounding errors.)\n3. 0 … P(x) … 1 for every individual value of the random variable x. (That is, \neach probability value must be between 0 and 1 inclusive.)\nThe second requirement comes from the simple fact that the random variable x \nrepresents all possible events in the entire sample space, so we are certain (with prob-\nability 1) that one of the events will occur. The third requirement comes from the basic \nprinciple that any probability value must be 0 or 1 or a value between 0 and 1.\nEXAMPLE 1  Genetics\nAlthough the Chapter Problem involves 945 births, let’s consider a simpler example \nthat involves only two births with the following random variable:\nx = number of girls in two births\nThe above x is a random variable because its numerical values depend on chance. \nWith two births, the number of girls can be 0, 1, or 2, and Table 5-1 is a probability \ncontinued\n\n184 \nCHAPTER 5 Discrete Probability Distributions\nNotation for 0+\nIn tables such as Table 5-1 or the binomial probabilities listed in Table A-1 in \nAppendix A, we sometimes use 0+ to represent a probability value that is positive \nbut very small, such as 0.000000123. When rounding a probability value for inclu-\nsion in such a table, rounding to 0 would be misleading because it would incor-\nrectly suggest that the event is impossible.\nProbability Histogram: Graph of a Probability Distribution\nThere are various ways to graph a probability distribution, but for now we will con-\nsider only the probability histogram. Figure 5-3 is a probability histogram corre-\nsponding to Table 5-1. Notice that it is similar to a relative frequency histogram (de-\nscribed in Section 2-2), but the vertical scale shows probabilities instead of relative \nfrequencies based on actual sample results.\ndistribution because it gives the probability for each value of the random variable x \nand it satisfies the three requirements listed earlier:\n \n1. The variable x is a numerical random variable and its values are associated \nwith probabilities, as in Table 5-1.\n \n2. ΣP(x) = 0.25 + 0.50 + 0.25 = 1\n3. Each value of P(x) is between 0 and 1. (Speciﬁcally, 0.25 and 0.50 and 0.25 \nare each between 0 and 1 inclusive.)\nThe random variable x in Table 5-1 is a discrete random variable, because it has \nthree possible values (0, 1, 2), and 3 is a finite number, so this satisfies the require-\nment of being finite or countable.\nTABLE 5-1 Probability \n Distribution for the Number of \nGirls in Two Births\nx: Number  \nof Girls\n \nP(x)\n0\n0.25\n1\n0.50\n2\n0.25\nFIGURE 5-3  Probability Histogram for Number of \nGirls in Two Births\nIn Figure 5-3, we see that the values of 0, 1, 2 along the horizontal axis are lo-\ncated at the centers of the rectangles. This implies that the rectangles are each 1 unit \nwide, so the areas of the rectangles are 0.25, 0.50, and 0.25. The areas of these rectan-\ngles are the same as the probabilities in Table 5-1. We will see in Chapter 6 and future \nchapters that such a correspondence between areas and probabilities is very useful.\nProbability Formula Example 1 involves a table, but a probability distribution \ncould also be in the form of a formula. Consider the formula P(x) =\n1\n2(2 - x)! x!\n\n5-1 Probability Distributions \n185\n(where x can be 0, 1, or 2). Using that formula, we find that P102 = 0.25, P112 = 0.50,\nand P122 = 0.25. The probabilities found using this formula are the same as those in \nTable 5-1. This formula does describe a probability distribution because the three re-\nquirements are satisfied, as shown in Example 1.\nTABLE 5-2 Hospital Job Interview Mistakes\nx\nP(x)\nInappropriate attire\n0.50\nBeing late\n0.44\nLack of eye contact\n0.33\nChecking phone or texting\n0.30\nTotal\n1.57\nEXAMPLE 2  Hospital Job Interview Mistakes\nHiring managers were asked to identify the biggest mistakes that job applicants \nmake during an interview, and Table 5-2 is based on their responses (based on data \nfrom an Adecco survey). Does Table 5-2 describe a probability distribution?\nSOLUTION\nTable 5-2 violates the first requirement because x is not a numerical random vari-\nable. Instead, the “values” of x are categorical data, not numbers. Table 5-2 also \nviolates the second requirement because the sum of the probabilities is 1.57, but that \nsum should be 1. Because the three requirements are not all satisfied, we conclude \nthat Table 5-2 does not describe a probability distribution.\nParameters of a Probability Distribution\nRemember that with a probability distribution, we have a description of a population \ninstead of a sample, so the values of the mean, standard deviation, and variance are \nparameters, not statistics. The mean, variance, and standard deviation of a discrete \nprobability distribution can be found with the following formulas:\nFORMULA 5-1 Mean M for a probability distribution\nm = Σ3x # P1x24 \nFORMULA 5-2 Variance S2 for a probability distribution\ns2 = Σ3 1x - m2 2 # P1x24 (This format is easier to understand.)\nFORMULA 5-3 Variance S2 for a probability distribution\ns2 = Σ3x2 # P1x24 - m2 (This format is easier for manual calculations.)\nFORMULA 5-4 Standard deviation S for a probability distribution\ns = 2Σ3x2 # P1x24 - m2 \n\n186 \nCHAPTER 5 Discrete Probability Distributions\nWhen applying Formulas 5-1 through 5-4, use the following rule for rounding results.\nRound-Off Rule For m, s, And s2 From A Probability Distribution\nRound results by carrying one more decimal place than the number of decimal \nplaces used for the random variable x. If the values of x are integers, round m, s, \nand s2 to one decimal place.\nExceptions to Round-Off Rule In some special cases, the above round-off rule re-\nsults in values that are misleading or inappropriate. For example, with four-engine \njets the mean number of jet engines working successfully throughout a flight is \n3.999714286, which becomes 4.0 when rounded, but that is misleading because it \nsuggests that all jet engines always work successfully. Here we need more precision to \ncorrectly  reflect the true mean, such as the precision in 3.999714.\nExpected Value\nThe mean of a discrete random variable x is the theoretical mean outcome for infinitely \nmany trials. We can think of that mean as the expected value in the sense that it is the \naverage value that we would expect to get if the trials could continue indefinitely.\nDEFINITION\nThe expected value of a discrete random variable x is denoted by E, and it is the \nmean value of the outcomes, so E = m and E can also be found by evaluating \nΣ 3x # P1x24, as in Formula 5-1.\nCAUTION An expected value need not be a whole number, even if the different \npossible values of x might all be whole numbers. The expected number of girls in \nfive births is 2.5, even though five particular births can never result in 2.5 girls. If we \nwere to survey many couples with five children, we expect that the mean number of \ngirls will be 2.5.\nEXAMPLE 3   Finding the Mean, Variance, and  \nStandard Deviation\nTable 5-1 on page 184 describes the probability distribution for the number of girls \nin two births (assuming that boys and girls are equally likely). Find the mean, vari-\nance, and standard deviation for the probability distribution described in Table 5-1 \nfrom Example 1.\nSOLUTION\nIn Table 5-3, the two columns at the left describe the probability distribution given \nearlier in Table 5-1. We create the two columns at the right for the purposes of the \ncalculations required.\nUsing Formulas 5-1 and 5-2 and the table results, we get\nMean: m = Σ3x # P1x2 4 = 1.0\nVariance: s2 = Σ3 1x - m2 2 # P1x2 4 = 0.5\n\n5-1 Probability Distributions \n187\nINTERPRETATION\nAssuming that boys and girls are equally likely in two births, the mean number of \ngirls is 1.0, the variance is 0.50 girls2, and the standard deviation is 0.7 girl. Also, \nthe expected value for the number of girls in two births is 1.0 girl, which is the same \nvalue as the mean. If we were to collect data on a large number of trials with two \nbirths in each trial, we expect to get a mean of 1.0 girl.\nThe standard deviation is the square root of the variance, so\nStandard deviation: s = 20.5 = 0.707107 = 0.7 1rounded2\nRounding: In Table 5-3, we use m = 1.0. If m had been the value of 1.23456, we \nmight round m to 1.2, but we should use its unrounded value of 1.23456 in \nTable 5-3 calculations. Rounding in the middle of calculations can lead to results \nwith errors that are too large.\nTABLE 5-3 Calculating m and s for a Probability Distribution\nx\nP1x2\nx # P1x2\n1x −m 22 # P1x2\n0\n0.25\n0 # 0.25 = 0.00\n10 - 12 2 # 0.25 =  0.25\n1\n0.50\n1 # 0.50 = 0.50\n11 - 12 2 # 0.50 = 0.00\n2\n0.25\n2 # 0.25 = 0.50\n12 - 12 2 # 0.25 =  0.25\nTotal\n  1.00\n   c\nm = Σ3x # P1x24\n       0.50\n       \nc\ns2 = Σ 31x - m2 2 # P1x24\nMaking Sense of Results: Significant Values\nWe present the following two different approaches for determining whether a value of \na random variable x is significantly low or high.\nIdentifying Significant Results with the Range Rule of Thumb\nThe range rule of thumb (introduced in Section 3-2) may be helpful in interpreting the \nvalue of a standard deviation. According to the range rule of thumb, the vast major-\nity of values should lie within 2 standard deviations of the mean, so we can consider \na value to be significant if it is at least 2 standard deviations away from the mean. We \ncan therefore identify “significant” values as follows:\nRange Rule of Thumb for Identifying Significant Values\nSigniﬁcantly low values are 1m - 2s2 or lower.\nSignificantly high values are 1m + 2s2 or higher.\nValues not signiﬁcant: Between 1m -  2s2 and 1m + 2s2\nFigure 3-3 from Section 3-2 illustrates the above criteria:\nValues not signiﬁcant\nSigniﬁcantly\nlow values\nSigniﬁcantly\nhigh values\nm\nm − 2s\nm + 2s\nHINT Know that the use of the number 2 in the range rule of thumb is somewhat \narbitrary, and this is a guideline, not an absolutely rigid rule.\n\n188 \nCHAPTER 5 Discrete Probability Distributions\nIdentifying Significant Results with Probabilities:\n \n■Significantly high number of successes: x successes among n trials is a signifi-\ncantly high number of successes if the probability of x or more successes is 0.05 or \nless. That is, x is a significantly high number of successes if P(x or more) … 0.05.*\n \n■Significantly low number of successes: x successes among n trials is a significantly \nlow number of successes if the probability of x or fewer successes is 0.05 or less. \nThat is, x is a significantly low number of successes if P(x or fewer) … 0.05.*\nEXAMPLE 4   Identifying Significant Results with the  \nRange Rule of Thumb\nIn Example 3 we found that with two births, the mean number of girls is m = 1.0 \ngirl and the standard deviation is s = 0.7 girl. Use those results and the range rule \nof thumb to determine whether 2 girls is a significantly high number of girls.\nSOLUTION\nUsing the range rule of thumb, the value of 2 girls is significantly high if it is greater \nthan or equal to m + 2s. With m = 1.0 girl and s = 0.7 girl, we get\nm + 2s = 1 + 210.72 = 2.4 girls\nSignificantly high numbers of girls are 2.4 and above.\nINTERPRETATION\nBased on these results, we conclude that 2 girls is not a significantly high number of \ngirls (because 2 is not greater than or equal to 2.4).\n*The value 0.05 is not absolutely rigid. Other values, such as 0.01, could be used to distinguish between results \nthat are signiﬁcant and those that are not signiﬁcant.\nIdentification of significantly low or significantly high numbers of successes is some-\ntimes used for the purpose of rejecting assumptions, as stated in the following rare \nevent rule.\nThe Rare Event Rule for Inferential Statistics\nIf, under a given assumption, the probability of a particular outcome is \nvery small and the outcome occurs signiﬁcantly less than or signiﬁcantly \ngreater than what we expect with that assumption, we conclude that the \nassumption is probably not correct.\nFor example, if testing the assumption that boys and girls are equally likely, the out-\ncome of 20 girls in 100 births is significantly low and would be a basis for rejecting \nthat assumption.\nEXAMPLE 5  Identifying Significant Results with Probabilities\nIs 879 girls in 945 births a signiﬁcantly high number of girls?\nWhat does the result suggest about the Chapter Problem, which includes results \nfrom the XSORT method of gender selection? (Among 945 births from parents us-\ning the XSORT method, there were 879 girls. Is 879 girls in those 945 births  \nsigniﬁcantly high?)\n\n5-1 Probability Distributions \n189\nNot Exactly, but “At Least as Extreme”\nIt should be obvious that among 945 births, 879 girls is significantly high, whereas \n475 girls is not significantly high. What makes 879 girls significant while 475 girls \nis not significant? It is not probabilities of exactly 879 girls and 475 girls (they are \nboth less than 0.026). It is the fact that the probability of 879 or more girls is very low \n(0.0000), but the probability of 475 or more girls is not low (0.448).\nPART 2  Expected Value and Rationale for Formulas\nExpected Value\nIn Part 1 of this section we noted that the expected value of a random variable x is equal \nto the mean m. We can therefore find the expected value by computing Σ3x # P1x2 4, \njust as we do for finding the value of m.\nSOLUTION\nA result of 879 girls in 945 births is greater than we expect with random chance, \nbut we need to determine whether 879 girls is significantly high. Here, the relevant \nprobability is the probability of getting 879 or more girls in 945 births. Using \nmethods covered later in Section 5-2, we can find that P(879 or more girls in 945 \nbirths) = 0.0000 (rounded). Because the probability of getting 879 or more girls is \nless than or equal to 0.05, we conclude that 879 girls in 945 births is a significantly \nhigh number of girls. See Figure 5-4, which is a probability histogram showing the \nprobability for the different numbers of girls.\nFIGURE 5-4 Probability Histogram of Girls in 945 Births\nEXAMPLE 6  Births\nAssuming that boys and girls are equally likely, find the expected number of girls in \n945 births. Instead of using Formula 5-1, just think about the number of girls  \nexpected in 945 births.\nSOLUTION\nThe expected number of girls in 945 births is 472.5 girls.\ncontinued\nINTERPRETATION\nIt is unlikely that we would get 879 or more girls in 945 births by chance. It follows \nthat 879 girls in 945 births is significantly high, so the XSORT method appears to \nbe effective (but this does not prove that the XSORT method is responsible for the \nlarge number of girls).\nDo Boys or Girls Run in \nthe Family?\nOne of the \nauthors of \nthis book, his \nsiblings, and \nhis siblings’ \nchildren consist \nof 11 males and \nonly 1 female. \nIs this an example of a phenom-\nenon whereby one particular \ngender runs in a family? This \nissue was studied by examin-\ning a random sample of 8770 \nhouseholds in the United States. \nThe results were reported in the \nChance magazine article “Does \nHaving Boys or Girls Run in the \nFamily?” by  Joseph Rodgers \nand Debby Doughty. Part of \ntheir analysis involves use of the \nbinomial probability distribution \ndiscussed in this section. Their \nconclusion is that “We found no \ncompelling evidence that sex \nbias runs in the family.”\n\n190 \nCHAPTER 5 Discrete Probability Distributions\nRationale for Formulas 5-1 Through 5-4\nInstead of blindly accepting and using formulas, it is much better to have some un-\nderstanding of why they work. When computing the mean from a frequency distribu-\ntion, f represents class frequency and N represents population size. In the expression \nbelow, we rewrite the formula for the mean of a frequency table so that it applies to a \npopulation. In the fraction f>N, the value of f is the frequency with which the value x \noccurs and N is the population size, so f>N is the probability for the value of x. When \nwe replace f>N with P(x), we make the transition from relative frequency based on \na limited number of observations to probability based on infinitely many trials. This \nresult shows why Formula 5-1 is as given earlier in this section.\nm = Σ1f # x2\nN\n= Σc f # x\nN d = Σcx # f\nN d = Σ3x # P1x2 4\nSimilar reasoning enables us to take the variance formula from Chapter 3 and \n apply it to a random variable for a probability distribution; the result is Formula 5-2. \nFormula 5-3 is a shortcut version that will always produce the same result as Formula 5-2. \nAlthough Formula 5-3 is usually easier to work with, Formula 5-2 is easier to under-\nstand directly. Based on Formula 5-2, we can express the standard deviation as\ns = 2Σ3 1x - m2 2 # P1x2 4\nor as the equivalent form given in Formula 5-4.\nINTERPRETATION\nIn any specific sample of 945 births, we can never get 472.5 girls, but 472.5 girls \nis the expected value in the sense that it would be the mean from many samples of \n945 births.\nStatistical Literacy and Critical Thinking \n1. Random Variable The accompanying table lists probabilities for the corresponding num-\nbers of girls in four births. What is the random variable, what are its possible values, and are its \nvalues numerical?\n5-1 Basic Skills and Concepts\nNumber of Girls in Four Births\nNumber of \nGirls x\n \nP(x)\n0\n0.063\n1\n0.250\n2\n0.375\n3\n0.250\n4\n0.063\n2. Discrete or Continuous? Is the random variable given in the accompanying table discrete \nor continuous? Explain.\n3. Probability Distribution For the accompanying table, is the sum of the values of P(x) \nequal to 1, as required for a probability distribution? Does the table describe a probability \ndistribution?\n4. Significant For 100 births, P(exactly 56 girls) = 0.0390 and P(56 or more girls) = 0.136. \nIs 56 girls in 100 births a significantly high number of girls? Which probability is relevant to \nanswering that question?\nIdentifying Discrete and Continuous Random Variables. In Exercises 5 and 6, refer \nto the given values, then identify which of the following is most appropriate: discrete ran-\ndom variable, continuous random variable, or not a random variable.\n5. a. Exact weights of the next 100 babies born in the United States\nb. Responses to the survey question “Which health plan do you have?”\ncontinued\n\n5-1 Probability Distributions \n191\nc. Numbers of families that must be surveyed before finding one with 10 children\nd. Exact foot lengths of humans\ne. Shoe sizes (such as 8 or 8½) of humans\n6. a. Grades (A, B, C, D, F) earned in biostatistics classes\nb. Heights of students in biostatistics classes\nc. Numbers of students in biostatistics classes\nd. Eye colors of biostatistics students\ne. Numbers of times biostatistics students must toss a coin before getting heads\nIdentifying Probability Distributions. In Exercises 7–14, determine whether a prob-\nability distribution is given. If a probability distribution is given, find its mean and standard \ndeviation. If a probability distribution is not given, identify the requirements that are not \nsatisfied.\n7. Genetic Disorder Five males with an X-linked genetic disorder \nhave one child each. The random variable x is the number of children \namong the five who inherit the X-linked genetic disorder.\nx\nP(x)\n0\n0.031\n1\n0.156\n2\n0.313\n3\n0.313\n4\n0.156\n5\n0.031\n8.  Male Color Blindness When conducting research on color \nblindness in males, a researcher forms random groups with five \nmales in each group. The random variable x is the number of males \nin the group who have a form of color blindness (based on data from \nthe National Institutes of Health).\nx\nP(x)\n0\n0.659\n1\n0.287\n2\n0.050\n3\n0.004\n4\n0.001\n5\n0+\n9.  Genetics Experiment A genetics experiment involves off-\nspring peas in groups of four. A researcher reports that for one \ngroup, the number of peas with white flowers has a probability dis-\ntribution as given in the accompanying table.\nx\nP(x)\n0\n0.04\n1\n0.26\n2\n0.36\n3\n0.20\n4\n0.08\n10. Mortality Study For a group of four men, the probability dis-\ntribution for the number x who live through the next year is as given \nin the accompanying table.\nx\nP(x)\n0\n0.0000\n1\n0.0001\n2\n0.0006\n3\n0.0387\n4\n0.9606\n\n192 \nCHAPTER 5 Discrete Probability Distributions\n11. Genetic Disorder Three males with an X-linked genetic dis-\norder have one child each. The random variable x is the number of \nchildren among the three who inherit the X-linked genetic disorder.\nx\nP(x)\n0\n0.4219\n1\n0.4219\n2\n0.1406\n3\n0.0156\n12. Diseased Seedlings An experiment involves groups of four \nseedlings grown under controlled conditions. The random variable x \nis the number of seedlings in a group that meet specific criteria for \nbeing classified as “diseased.”\nx\nP(x)\n0\n0.805\n1\n0.113\n2\n0.057\n3\n0.009\n4\n0.002\nGenetics. In Exercises 13–18, refer to the accompanying table, \nwhich describes results from groups of 8 births from 8 different \nsets of parents. The random variable x represents the number of \ngirls among 8 children.\nNumber \nof Girls x\n \nP(x)\n0\n0.004\n1\n0.031\n2\n0.109\n3\n0.219\n4\n0.273\n5\n0.219\n6\n0.109\n7\n0.031\n8\n0.004\n13. Mean and Standard Deviation Find the mean and standard \ndeviation for the numbers of girls in 8 births.\n14. Range Rule of Thumb for Significant Events Use the \nrange rule of thumb to determine whether 1 girl in 8 births is a sig-\nnificantly low number of girls.\n15. Range Rule of Thumb for Significant Events Use the \nrange rule of thumb to determine whether 6 girls in 8 births is a sig-\nnificantly high number of girls.\n16. Using Probabilities for Significant Events\na. Find the probability of getting exactly 7 girls in 8 births.\nb. Find the probability of getting 7 or more girls in 8 births.\nc. Which probability is relevant for determining whether 7 is a significantly high number of \ngirls in 10 births: the result from part (a) or part (b)?\nd. Is 7 a significantly high number of girls in 8 births? Why or why not?\n17. Using Probabilities for Significant Events \na. Find the probability of getting exactly 6 girls in 8 births.\nb. Find the probability of getting 6 or more girls in 8 births.\nc. Which probability is relevant for determining whether 6 is a significantly high number of \ngirls in 8 births: the result from part (a) or part (b)?\nd. Is 6 a significantly high number of girls in 8 births? Why or why not?\n18. Using Probabilities for Significant Events \na. Find the probability of getting exactly 1 girl in 8 births.\nb. Find the probability of getting 1 or fewer girls in 8 births.\nc. Which probability is relevant for determining whether 1 is a significantly low number of \ngirls in 8 births: the result from part (a) or part (b)?\nd. Is 1 a significantly low number of girls in 8 births? Why or why not?\n\n5-2 Binomial Probability Distributions \n193\nSleepwalking. In Exercises 19–23, refer to the accompanying \ntable, which describes the numbers of adults in groups of five \nwho reported sleepwalking (based on data from “Prevalence and \nComorbidity of Nocturnal Wandering In the U.S. Adult General \nPopulation,” by Ohayon et al., Neurology, Vol. 78, No. 20).\n19. Mean and Standard Deviation Find the mean and standard \ndeviation for the numbers of sleepwalkers in groups of five.\nx\nP(x)\n0\n0.172\n1\n0.363\n2\n0.306\n3\n0.129\n4\n0.027\n5\n0.002\n20. Range Rule of Thumb for Significant Events Use the \nrange rule of thumb to determine whether 4 is a significantly high \nnumber of sleepwalkers in a group of 5 adults.\n21. Range Rule of Thumb for Significant Events Use the \nrange rule of thumb to determine whether 3 is a significantly high \nnumber of sleepwalkers in a group of 5 adults.\nKey Concept Section 5-1 introduced the important concept of a discrete proba-\nbility distribution. Among the various discrete probability distributions that exist, \nthe focus of this section is the binomial probability distribution. Part 1 of this sec-\ntion introduces the binomial probability distribution along with methods for find-\ning probabilities. Part 2 presents easy methods for finding the mean and standard \ndeviation of a binomial distribution. As in other sections, we stress the importance \nof interpreting probability values to determine whether events are significantly low \nor significantly high.\nPART 1\n Basics of Binomial Probability Distribution\nBinomial probability distributions allow us to deal with circumstances in which the \noutcomes belong to two categories, such as cured>not cured or acceptable>defective \nor survived>died.\n5-2 \nBinomial Probability Distributions\n22. Using Probabilities for Identifying Significant Events\na. Find the probability of getting exactly 4 sleepwalkers among 5 adults.\nb. Find the probability of getting 4 or more sleepwalkers among 5 adults.\nc. Which probability is relevant for determining whether 4 is a significantly high number of \nsleepwalkers among 5 adults: the result from part (a) or part (b)?\nd. Is 4 a significantly high number of sleepwalkers among 5 adults? Why or why not?\n23. Using Probabilities for Identifying Significant Events\na. Find the probability of getting exactly 1 sleepwalker among 5 adults.\nb. Find the probability of getting 1 or fewer sleepwalkers among 5 adults.\nc. Which probability is relevant for determining whether 1 is a significantly low number of \nsleepwalkers among 5 adults: the result from part (a) or part (b)?\nd. Is 1 a significantly low number of sleepwalkers among 5 adults? Why or why not?\n\n194 \nCHAPTER 5 Discrete Probability Distributions\nNotation For Binomial Probability Distributions\nS and F (success and failure) denote the two possible categories of all outcomes.\nP1S2 = p \n1p = probability of a success2\nP1F2 = 1 - p = q \n1q = probability of a failure2\nn\nthe fixed number of trials\nx \na specific number of successes in n trials, so x can be any \nwhole number between 0 and n, inclusive\np\nprobability of success in one of the n trials\nq\nprobability of failure in one of the n trials\nP(x) \nprobability of getting exactly x successes among the n trials\nThe word success as used here is arbitrary and does not necessarily represent \nsomething good. Either of the two possible categories may be called the success S \nas long as its probability is identified as p. (The value of q can always be found from \nq = 1 - p. If p = 0.95, then q = 1 - 0.95 = 0.05.)\nDEFINITION\nA binomial probability distribution results from a procedure that meets these four \nrequirements:\n 1.  The procedure has a ﬁxed number of  trials. (A trial is a single observation.)\n 2.  The trials must be independent, meaning that the outcome of any individual trial \ndoesn’t aﬀect the probabilities in the other trials.\n 3.  Each trial must have all outcomes classiﬁed into exactly two categories, com-\nmonly referred to as success and failure.\n 4.  The probability of a success remains the same in all trials.\nCAUTION When using a binomial probability distribution, always be sure that x \nand p are consistent in the sense that they both refer to the same category being \ncalled a success.\nEXAMPLE 1  Hybridization Experiments\nWhen Gregor Mendel conducted his famous hybridization experiments, he used \npeas with green pods and peas with yellow pods. Because green is dominant and \nyellow is recessive, when crossing two parents with the green>yellow pair of genes, \nwe expect that 3>4 of the offspring peas should have green pods. That is, P(green \npod) = 3>4. Assume that all parents have the green>yellow combination of genes, \nand we want to find the probability that exactly three of five offspring peas have \ngreen pods.\n \na. Does this procedure result in a binomial distribution?\n \nb. If this procedure does result in a binomial distribution, identify the values of \nn, x, p, and q.\n\n5-2 Binomial Probability Distributions \n195\nTreating Dependent Events as Independent\nWhen selecting a sample (as in a survey), we usually sample without replacement. \nSampling without replacement results in dependent events, which violates a require-\nment of a binomial distribution. However, we can often treat the events as if they were \nindependent by applying the following 5% guideline introduced in Section 4-2:\n5% Guideline for Cumbersome Calculations\nWhen sampling without replacement and the sample size is no more than \n5% of the size of the population, treat the selections as being independent \n(even though they are actually dependent).\nMethods for Finding Binomial Probabilities\nWe now proceed with three methods for finding the probabilities corresponding to the \nrandom variable x in a binomial distribution. The first method involves calculations \nusing the binomial probability formula and is the basis for the other two methods. \nThe second method involves the use of software or a calculator, and the third method \ninvolves the use of the Appendix Table A-1. (With technology so widespread, such \ntables are becoming obsolete.) If using technology that automatically produces bino-\nmial probabilities, we recommend that you solve one or two exercises using Method 1 \nto better understand the basis for the calculations.\nSOLUTION\na. This procedure does satisfy the requirements for a binomial distribution, as \nshown below.\n \n 1. The number of trials (5) is ﬁxed.\n \n 2. The 5 trials are independent because the probability of any oﬀspring \npea having a green pod is not aﬀected by the outcome of any other \n oﬀspring pea.\n \n 3. Each of the 5 trials has two categories of outcomes: The pea has a green \npod or it does not.\n \n 4. For each oﬀspring pea, the probability that it has a green pod is 3>4 or \n0.75, and that probability remains the same for each of the 5 peas.\n \nb. Having concluded that the given procedure does result in a binomial distribu-\ntion, we now proceed to identify the values of n, x, p, and q.\n \n 1. With 5 oﬀspring peas, we have n = 5.\n2. We want the probability of exactly 3 peas with green pods, so x = 3.\n3. The probability of success (getting a pea with a green pod) for one selec-\ntion is 0.75, so p = 0.75.\n4. The probability of failure (not getting a green pod) is 0.25, so q = 0.25.\nAgain, it is very important to be sure that x and p both refer to the same concept of \n“success.” In this example, we use x to count the number of peas with green pods, \nso p must be the probability that a pea has a green pod. Therefore, x and p do use \nthe same concept of success (green pod) here.\nNot at Home\nPollsters cannot \nsimply ignore \nthose who were \nnot at home \nwhen they \nwere called \nthe first time. \nOne solution \nis to make repeated callback \nattempts until the person can \nbe reached.  Alfred Politz and \nWillard Simmons describe a way \nto compensate for those missed \ncalls without making repeated \ncallbacks. They suggest weight-\ning results based on how often \npeople are not at home. For \nexample, a person at home only \ntwo days out of six will have a  \n2>6 or 1>3 probability of being at \nhome when called the first time. \nWhen such a person is reached \nthe first time, his or her results \nare weighted to count three \ntimes as much as someone who \nis always home. This weighting \nis a compensation for the other \nsimilar people who are home two \ndays out of six and were not at \nhome when called the first time. \nThis clever solution was first \npresented in 1949.\n\n196 \nCHAPTER 5 Discrete Probability Distributions\nFORMULA 5-5  Binomial Probability Formula\nP1x2 =\nn!\n1n - x2!x! # px # qn-x  for x = 0, 1, 2, c, n\nwhere\n n = number of trials\n x = number of successes among n trials\n p = probability of success in any one trial\n q = probability of failure in any one trial 1q = 1 - p2\nFormula 5-5 can also be expressed as P1x2 = nCx # px # qn-x. With x items identi-\ncal to themselves, and n - x other items identical to themselves, the number of \npermutations is nCx = n!3 1n - x2!x!4, so the two sides of this equation are inter-\nchangeable. The factorial symbol !, introduced in Section 4-6, denotes the product \nof decreasing factors. Two examples of factorials are 3! = 3 # 2 # 1 = 6 and 0! = 1 \n(by definition).\nEXAMPLE 2  Hybridization Experiment \nAssuming that the probability of a pea having a green pod is 0.75 (as in Example 1), \nuse the binomial probability formula to find the probability of getting exactly 3 peas \nwith green pods when 5 offspring peas are generated. That is, find P(3) given that \nn = 5, x = 3, p = 0.75, and q = 0.25.\nSOLUTION\nUsing the given values of n, x, p, and q in the binomial probability formula \n (Formula 5-5), we get\n P132 =\n5!\n15 - 32!3! # 0.753 # 0.255-3\n =\n5!\n2!3! # 0.421875 # 0.0625\n = 110210.421875210.06252 = 0.263671875\nThe probability of getting exactly 3 peas with green pods among 5 offspring peas is \n0.264 (rounded to three significant digits).\nCalculation hint: When computing a probability with the binomial probability for-\nmula, it’s helpful to get a single number for n!> 3 1n - x2!x!4 or nCx, a single num-\nber for px, and a single number for qn-x, and then simply multiply the three factors \ntogether as shown in the third line of the calculation in the preceding example. Don’t \nround when you find those three factors; round only at the end, and round to three \nsignificant digits.\nMethod 1: Using the Binomial Probability Formula In a binomial probability \ndistribution, probabilities can be calculated by using Formula 5-5.\n\n5-2 Binomial Probability Distributions \n197\nMethod 2: Using Technology Technology can be used to find binomial probabili-\nties. The screen displays listing binomial probabilities for n = 5 and p = 0.75, as in \nExample 2, are given. Notice that in each display, the probability distribution is given \nas a table.\nStatdisk\nMinitab\nExcel\nTI-83>84 Plus\nMethod 3: Using Table A-1 in Appendix A This method can be skipped if tech-\nnology is available. Table A-1 in Appendix A lists binomial probabilities for select \nvalues of n and p. It cannot be used if n > 8 or if the probability p is not one of the 13 \nvalues included in the table.\nTo use the table of binomial probabilities, we must first locate n and the desired \ncorresponding value of x. At this stage, one row of numbers should be isolated. Now \nalign that row with the desired probability of p by using the column across the top. \nThe isolated number represents the desired probability. A very small probability, such \nas 0.000064, is indicated by 0+.\nEXAMPLE 3  Births \nAssuming that boys and girls are equally likely, find the probability of getting ex-\nactly 5 boys in 8 randomly selected births.\ncontinued\n\n198 \nCHAPTER 5 Discrete Probability Distributions\nPART 2\nUsing Mean and Standard Deviation for \nCritical Thinking \nSection 5-1 included formulas for finding the mean, variance, and standard deviation \nfrom any discrete probability distribution. A binomial distribution is a particular type \nof discrete probability distribution, so we could use those same formulas, but if we \nknow the values of n and p, it is much easier to use the following:\nSOLUTION\nBecause boys and girls are assumed to be equally likely, we have p = 0.5. Because \nthere are 8 births we have n = 8. Because we want the probability of exactly 5 \nboys, we have x = 5.\nRefer to Table A-1with n = 8, x = 0.5, and p = 0.5. Locate n = 8 at the left, \nthen find the row of probabilities for x = 5. Next, look across the top row to find \nthe column of values under p = 0.50. Table A-1 shows that P(5 boys) = 0.219.\nFor Binomial Distributions\nFormula 5-6 Mean: \nm = np\nFormula 5-7 Variance: \ns2 = npq\nFormula 5-8 Standard Deviation:    s = 1npq\nAs in earlier sections, finding values for m and s can be great fun, but it is especially \nimportant to interpret and understand those values, so the range rule of thumb and the \nrare event rule for inferential statistics can be very helpful. Here is a brief summary \nof the range rule of thumb: Values are significantly low or high if they differ from the \nmean by more than 2 standard deviations, as described by the following:\nRange Rule of Thumb\nSigniﬁcantly low values … 1m - 2s2\nSigniﬁcantly high values Ú 1m + 2s2\nValues not signiﬁcant: Between 1m - 2s2 and 1m + 2s2\nEXAMPLE 4  Hybridization Experiment\nUse Formulas 5-6 and 5-8 to find the mean and standard deviation for the numbers \nof peas with green pods when groups of 5 offspring peas are generated. Assume that \nthere is a 0.75 probability that an offspring pea has a green pod.\nSOLUTION\nUsing the values n = 5, p = 0.75, and q = 0.25, Formulas 5-6 and 5-8 can be \n applied as follows:\n        m = np = 15210.752 = 3.8\ns = 1npq = 215210.75210.252 = 1.0 1rounded2\n\n5-2 Binomial Probability Distributions \n199\nFormula 5-6 for the mean makes sense intuitively. If 75% of peas have green pods \nand five offspring peas are generated, we expect to get around 5 # 0.75 = 3.8 peas \nwith green pods. This result can be generalized as m = np. The variance and standard \ndeviation are not so easily justified, and we omit the complicated algebraic manipula-\ntions that lead to Formulas 5-7 and 5-8. Instead, refer again to the preceding example \nand Table 5-3 on page 187 to verify that for a binomial distribution, Formulas 5-6, 5-7, \nand 5-8 will produce the same results as Formulas 5-1, 5-3, and 5-4.\nEXAMPLE 5  Genetics\nIn an actual experiment, Mendel generated 580 offspring peas. He claimed that \n75%, or 435, of them would have green pods. The actual experiment resulted in \n428 peas with green pods.\na. Assuming that groups of 580 oﬀspring peas are generated, ﬁnd the mean and \nstandard deviation for the numbers of peas with green pods.\n \nb. Use the range rule of thumb to ﬁnd the numbers of peas with green pods that \nseparate signiﬁcantly low values and signiﬁcantly high values from values that \nare not signiﬁcant. Based on those numbers, can we conclude that Mendel’s \nactual result of 428 peas with green pods is signiﬁcantly low or signiﬁcantly \nhigh? Does this suggest that Mendel’s value of 75% is wrong?\nSOLUTION\na. With n = 580 oﬀspring peas, with p = 0.75, and q = 0.25, we can ﬁnd \nthe mean and standard deviation for the numbers of peas with green pods as \n follows:\n         m = np = 1580210.752 = 435.0\ns = 1npq = 21580210.75210.252 = 10.4\nFor groups of 580 oﬀspring peas, the mean number of peas with green pods is \n435.0 and the standard deviation is 10.4.\nb. We must now interpret the results to determine whether Mendel’s actual result \nof 428 peas is a result that could easily occur by chance, or whether that result \nis so unlikely that the assumed rate of 75% is wrong. We will use the range \nrule of thumb as follows:\nSignificantly low values … 1m - 2s2 = 435.0 - 2110.42 = 414.2\nSignificantly high values Ú 1m + 2s2 = 435.0 + 2110.42 = 455.8\nINTERPRETATION\nBased on these results, significantly low values are 414.2 or lower, and significantly \nhigh values are 455.8 or higher. That is, if Mendel generated many groups of 580 \noffspring peas and if his 75% rate is correct, the numbers of peas with green pods \nshould usually fall between 414.2 and 455.8. Mendel actually got 428 peas with \ngreen pods, and that value is neither significantly low nor significantly high, so the \nexperimental results are consistent with the 75% rate. The results do not suggest \nthat Mendel’s claimed rate of 75% is wrong.\n\n200 \nCHAPTER 5 Discrete Probability Distributions\nVariation in Statistics Example 5 is a good illustration of the importance of variation \nin statistics. In a traditional algebra course, we might conclude that 428 is not 75% \nof 580 simply because 428 does not equal 435 (which is 75% of 580). However, in \nstatistics we recognize that sample results vary. We don’t expect to get exactly 75% of \nthe peas with green pods. We recognize that as long as the results don’t vary too far \naway from the claimed rate of 75%, they are consistent with that claimed rate of 75%.\nIn this section we presented easy procedures for finding values of the mean m and \nstandard deviation s from a binomial probability distribution. However, it is really \nimportant to be able to interpret those values by using such tools as the range rule of \nthumb for distinguishing values that are significantly low or significantly high from \nvalues that are not significant.\nInstead of the range rule of thumb, we could also use probabilities to determine \nwhen values are significantly high or significantly low.\nUsing Probabilities to Determine When Results Are Significantly High or Low\n \n■Significantly high number of successes: x successes among n trials is a \n significantly high number of successes if the probability of x or more successes \nis 0.05 or less. That is, x is a significantly high number of successes if  \nP(x or more) … 0.05.*\n \n■Significantly low number of successes: x successes among n trials is a \n significantly low number of successes if the probability of x or fewer successes  \nis 0.05 or less. That is, x is a significantly low number of successes if  \nP(x or fewer) … 0.05.*\n*The value 0.05 is not absolutely rigid. Other values, such as 0.01, could be used to distinguish between results \nthat are signiﬁcant and those that are not signiﬁcant.\nRationale for the Binomial Probability Formula\nThe binomial probability formula is the basis for all three methods presented in this \nsection. Instead of accepting and using that formula blindly, let’s see why it works.\nIn Example 2, we used the binomial probability formula to find the probability \nof getting exactly 3 peas with green pods when 5 offspring peas are generated. With \nP(green pod) = 0.75, we can use the multiplication rule from Section 4-2 to find the \nprobability that the first 3 peas have green pods while the last 2 peas do not have green \npods. We get the following result:\nP13 peas with green pods followed by 2 peas with pods that are not green2\n = 0.75 # 0.75 # 0.75 # 0.25 # 0.25\n = 0.753 # 0.252\n = 0.0264\nThis result gives a probability of generating five offspring in which three have green pods. \nHowever, it does not give the probability of getting exactly three peas with green pods be-\ncause it assumes a particular arrangement for three offspring peas with green pods. Other \narrangements for generating three offspring peas with green pods are possible.\nIn Section 4-6 we saw that with three subjects identical to each other (such as peas \nwith green pods) and two other subjects identical to each other (such as peas without \ngreen pods), the total number of arrangements, or permutations, is 5!> 3 15 - 32!3!4, \nor 10. Each of those 10 different arrangements has a probability of 0.753 # 0.252, so the \ntotal probability is as follows:\nP13 peas with green pods among 52 =\n5!\n15 - 32!3! # 0.753 # 0.252\n\n5-2 Binomial Probability Distributions \n201\nThis particular result can be generalized as the binomial probability formula \n(Formula 5-5). That is, the binomial probability formula is a combination of the \nmultiplication rule of probability and the counting rule for the number of arrange-\nments of n items when x of them are identical to each other and the other n - x are \nidentical to each other.\nP (x) =\nn!\n(n - x)!x! # px # qn-x\nThe number of outcomes with  \nexactly x successes among n trials\nThe probability of x successes among  \nn trials for any one particular order\n2   2\nBinomial Distributions\nAccess tech instructions, videos, and data sets at www.TriolaStats.com\nTECH CENTER \nStatistical Literacy and Critical Thinking \n1.  Hybridization Assume that 75% of offspring peas have green pods. Suppose we want \nto find the probability that when five offspring peas are randomly selected, exactly two \nof them are green. What is wrong with using the multiplication rule to find the prob-\nability of getting two peas with green pods followed by three peas with yellow pods: \n(0.75)(0.75)(0.25)(0.25)(0.25) = 0.00879?\n2. Variation and Notation Assume that we want to find the probability that among five off-\nspring peas, exactly two of them have green pods. Also assume that 75% of offspring peas have \ngreen pods (and the others have yellow pods).\na. Identify the values of n, x, p, and q.\nb. For groups of 5 randomly selected offspring peas, find the mean, standard deviation, and \nvariance for the numbers of peas among five that have green pods. Include appropriate units.\n3.  Independent Events Based on a KRC Research survey, when 1020 adults were asked \nabout hand hygiene, 44% said that they wash their hands after using public transportation. Con-\nsider the probability that among 30 different adults randomly selected from the 1020 who were \nsurveyed, there are at least 10 who wash their hands after using public transportation. Given \nthat these subjects were selected without replacement, are the 30 selections independent? Can \nthey be treated as being independent? Can the probability be found using the binomial prob-\nability formula?\n4.  Notation of 0+ Using the same survey from Exercise 3, the probability of randomly \n selecting 30 of the 1020 adults and getting exactly 24 who wash hands after using public trans-\nportation is represented as 0+. What does 0+ indicate? Does 0+ indicate that it is impossible to \nget exactly 24 adults who wash their hands after using public transportation?\n5-2 Basic Skills and Concepts\n\n202 \nCHAPTER 5 Discrete Probability Distributions\nIdentifying Binomial Distributions. In Exercises 5–12, determine whether the given \nprocedure results in a binomial distribution (or a distribution that can be treated as bino-\nmial). For those that are not binomial, identify at least one requirement that is not satisfied.\n5.  Clinical Trial of YSORT The YSORT method of gender selection, developed by the \n Genetics & IVF Institute, was designed to increase the likelihood that a baby will be a boy. \nWhen 291 couples used the YSORT method and gave birth to 291 babies, the weights of the \nbabies were recorded.\n6.  Clinical Trial of YSORT The YSORT method of gender selection, developed by the \n Genetics & IVF Institute, was designed to increase the likelihood that a baby will be a boy. \nWhen 291 couples use the YSORT method and give birth to 291 babies, the genders of the \nbabies are recorded.\n7. Clinical Trial of Lipitor Treating 863 subjects with Lipitor (atorvastatin) and recording \nwhether there is a “yes” response when they are each asked if they experienced a headache \n(based on data from Pfizer, Inc.).\n8. Clinical Trial of Lipitor Treating 863 subjects with Lipitor (atorvastatin) and asking each \nsubject how their head feels (based on data from Pfizer, Inc.).\n9.  Nicorette Treating 50 smokers with Nicorette and asking them how their mouth and \nthroat feel.\n10. Nicorette Treating 50 smokers with Nicorette and recording whether there is a “yes” re-\nsponse when they are asked if they experience any mouth or throat soreness.\n11. Defibrillators Determining whether each of 500 defibrillators is acceptable or defective.\n12. Defibrillators Counting the numbers of defects in each of 500 defibrillators.\nBinomial Probability Formula. In Exercises 13 and 14, answer the questions designed to \nhelp understand the rationale for the binomial probability formula.\n13. Guessing Answers Standard tests, such as the SAT, ACT, or Medical College Admis-\nsion Test (MCAT) typically use multiple choice questions, each with five possible answers \n(a, b, c, d, e), one of which is correct. Assume that you guess the answers to the first three ques-\ntions.\na. Use the multiplication rule to find the probability that the first two guesses are wrong and \nthe third is correct. That is, find P(WWC), where W denotes a wrong answer and C denotes a \ncorrect answer.\nb. Beginning with WWC, make a complete list of the different possible arrangements of two \nwrong answers and one correct answer; then find the probability for each entry in the list.\nc. Based on the preceding results, what is the probability of getting exactly one correct answer \nwhen three guesses are made?\n14. Vision Correction 53% of adults use eyeglasses for vision correction (based on data \nfrom a Vision Council survey). Four adults are randomly selected.\na. Use the multiplication rule to find the probability that the first three use eyeglasses and the \nfourth does not use eyeglasses. That is, find P(EEEN), where E denotes an adult who uses eye-\nglasses and N denotes an adult who does not use eyeglasses.\nb. Beginning with EEEN, make a complete list of the different possible arrangements of three \nadults who use eyeglasses and one who does not use eyeglasses; then find the probability for \neach entry in the list.\nc. Based on the preceding results, what is the probability of getting exactly three adults who \nuse eyeglasses and one who does not?\n\n5-2 Binomial Probability Distributions \n203\nMCAT Test. In Exercises 15–20, assume that random guesses are made for eight multiple \nchoice questions on an MCAT test, so that there are n = 8 trials, each with probability \nof success (correct) given by p = 0.20. Find the indicated probability for the number of \n correct answers.\n15. Find the probability that the number x of correct answers is exactly 7.\n16. Find the probability that the number x of correct answers is at least 4.\n17. Find the probability that the number x of correct answers is fewer than 3.\n18. Find the probability that the number x of correct answers is no more than 2.\n19. Find the probability of no correct answers.\n20. Find the probability that at least one answer is correct.\nIn Exercises 21–24, assume that when adults are randomly selected, 21% do not require \n vision correction (based on data from a Vision Council survey).\n21. If 8 adults are randomly selected, find the probability that exactly 2 of them do not require \nvision correction.\n22. If 20 adults are randomly selected, find the probability that exactly 5 of them do not require \nvision correction.\n23. If 10 adults are randomly selected, find the probability that at least 3 of them do not require \nvision correction.\n24. If 12 adults are randomly selected, find the probability that fewer than 3 of them do not \nrequire vision correction.\nSignificance with Range Rule of Thumb. In Exercises 25 and 26, assume that different \ngroups of couples use the XSORT method of gender selection and each couple gives birth \nto one baby. The XSORT method is designed to increase the likelihood that a baby will be a \ngirl, but assume that the method has no effect, so the probability of a girl is 0.5.\n25. Gender Selection Assume that the groups consist of 36 couples.\na. Find the mean and standard deviation for the numbers of girls in groups of 36 births.\nb. Use the range rule of thumb to find the values separating results that are significantly low or \nsignificantly high.\nc. Is the result of 26 girls a result that is significantly high? What does it suggest about the ef-\nfectiveness of the XSORT method?\n26. Gender Selection Assume that the groups consist of 16 couples.\na. Find the mean and standard deviation for the numbers of girls in groups of 16 births.\nb. Use the range rule of thumb to find the values separating results that are significantly low or \nsignificantly high.\nc. Is the result of 11 girls a result that is significantly high? What does it suggest about the ef-\nfectiveness of the XSORT method?\nSignificance with Range Rule of Thumb. In Exercises 27 and 28, assume that hybrid-\nization experiments are conducted with peas having the property that for offspring, there is \na 0.75 probability that a pea has green pods (as in one of Mendel’s famous experiments).\n27. Hybrids Assume that offspring peas are randomly selected in groups of 10.\na. Find the mean and standard deviation for the numbers of peas with green pods in the groups \nof 10.\ncontinued\n\n204 \nCHAPTER 5 Discrete Probability Distributions\nb. Use the range rule of thumb to find the values separating results that are significantly low or \nsignificantly high.\nc. Is the result of 9 peas with green pods a result that is significantly high? Why or why not?\n28. Hybrids Assume that offspring peas are randomly selected in groups of 16.\na. Find the mean and standard deviation for the numbers of peas with green pods in the groups \nof 16.\nb. Use the range rule of thumb to find the values separating results that are significantly low or \nsignificantly high.\nc. Is a result of 7 peas with green pods a result that is significantly low? Why or why not?\nComposite Sampling. Exercises 29 and 30 involve the method of composite sampling, \nwhereby a medical testing laboratory saves time and money by combining blood samples for \ntests so that only one test is conducted for several people. A combined sample tests positive \nif at least one person has the disease. If a combined sample tests positive, then individual \nblood tests are used to identify the individual with the disease.\n29. HIV It is estimated that worldwide, 1% of those aged 15–49 are infected with the human \nimmunodeficiency virus (HIV) (based on data from the National Institutes of Health). In tests \nfor HIV, blood samples from 36 people are combined. What is the probability that the com-\nbined sample tests positive for HIV? Is it unlikely for such a combined sample to test positive?\n30. Blood Donor Testing The American Red Cross tests every unit of donated blood for \nseveral infectious diseases, including hepatitis B, hepatitis C, HIV, syphilis, and West Nile virus \ninfection. Blood samples from 16 donors are combined and tested, and all 16 individual samples \nare approved only if the combined sample passes all tests. If there is 1.4% chance that a random \nindividual fails any of the tests, find the probability that the combined sample is not approved.\nAcceptance Sampling. Exercises 31 and 32 involve the method of acceptance sampling, \nwhereby a shipment of a large number of items is accepted based on test results from a \nsample of the items.\n31. Aspirin The MedAssist Pharmaceutical Company receives large shipments of aspirin tab-\nlets and uses this acceptance sampling plan: Randomly select and test 40 tablets, and then ac-\ncept the whole batch if there is only one or none that doesn’t meet the required specifications. \nIf one shipment of 5000 aspirin tablets actually has a 3% rate of defects, what is the probability \nthat this whole shipment will be accepted? Will almost all such shipments be accepted, or will \nmany be rejected?\n32. AAA Batteries AAA batteries are made by companies including Duracell, Energizer, \nEveready, and Panasonic, and they are used to power Prestige Medical Xenon pocket otoscopes \n(those things that physicians use to look in your ears). When purchasing bulk orders of AAA \nbatteries, a manufacturer of otoscopes uses this acceptance sampling plan: Randomly select 50 \nbatteries and determine whether each is within specifications. The entire shipment is accepted \nif at most 2 batteries do not meet specifications. A shipment contains 2000 AAA batteries, and \n2% of them do not meet specifications. What is the probability that this whole shipment will be \naccepted? Will almost all such shipments be accepted, or will many be rejected?\nUltimate Binomial Exercises! Exercises 33−36 involve finding binomial probabilities, \nfinding parameters, and determining whether values are significantly high or low by using \nthe range rule of thumb and probabilities.\n33. Gender Selection At an early stage of clinical trials of the XSORT method of gender \nselection, 14 couples using that method gave birth to 13 girls and 1 boy.\na. Assuming that the XSORT method has no effect and boys and girls are equally likely, use \nthe range rule of thumb to identify the limits separating values that are significantly low and \n\n5-2 Binomial Probability Distributions \n205\nthose that are significantly high (for the number of girls in 14 births). Based on the results, is \nthe result of 13 girls significantly high?\nb. Find the probability of exactly 13 girls in 14 births, assuming that the XSORT method has \nno effect.\nc. Find the probability of 13 or more girls in 14 births, assuming that the XSORT method has \nno effect.\nd. Which probability is relevant for determining whether 13 girls is significantly high: the \nprobability from part (b) or part (c)? Based on the relevant probability, is the result of 13 girls \nsignificantly high?\ne. What do the results suggest about the effectiveness of the XSORT method?\n34. Clinical Trial A treatment for hypertension has been found to be successful in 60% of the \npatient population. In a test of a new treatment, 40 subjects are treated for hypertension and 29 \nof these subjects experience success with the new treatment.\na. Assuming that the old success rate of 60% still applies, use the range rule of thumb to iden-\ntify the limits separating numbers of successes that are significantly low or significantly high. \nBased on the results, is 29 successes among the 40 subjects significantly high?\nb. Find the probability that exactly 29 of the 40 cases are successes, assuming that the general \nsuccess rate is 60%.\nc. Find the probability that 29 or more of the cases are successes, assuming that the general \nsuccess rate is 60%.\nd. Which probability is relevant for determining whether 29 successes is significantly high: the \nprobability from part (b) or part (c)? Based on the relevant probability, is the result of 29 suc-\ncesses significantly high?\ne. What do the results suggest about the effectiveness of the new treatment?\n35. Hybrids One of Mendel’s famous experiments with peas included 47 offspring, and 34 of \nthem had long stems. Mendel claimed that under the same conditions, 75% of offspring peas \nwould have long stems. Assume that Mendel’s claim of 75% is true, and assume that a sample \nconsists of 47 offspring peas.\na. Use the range rule of thumb to identify the limits separating values that are significantly low \nand those that are significantly high. Based on the results, is the result of 34 peas with long \nstems either significantly low or significantly high?\nb. Find the probability of exactly 34 peas with long stems.\nc. Find the probability of 34 or fewer peas with long stems.\nd. Which probability is relevant for determining whether 34 peas with long stems is signifi-\ncantly low: the probability from part (b) or part (c)? Based on the relevant probability, is the \nresult of 34 peas with long stems significantly low?\ne. What do the results suggest about Mendel’s claim of 75%?\n36. Vaccine For a specific group of subjects, there is a 5% chance of influenza (“flu”). When \n80 subjects were treated with a vaccine, only one of them presented with influenza.\na. Use the range rule of thumb to identify the limits separating values that are significantly low \nand those that are significantly high. Based on the results, is the result of one subject getting \ninfluenza either significantly low or significantly high?\nb. Find the probability of exactly one subject experiencing influenza, assuming that the vaccine \nhas no effect.\nc. Find the probability of one or fewer subjects experiencing influenza, assuming that the \n vaccine has no effect.\ncontinued\n\n206 \nCHAPTER 5 Discrete Probability Distributions\nd. Which probability is relevant for determining whether one subject experiencing influenza is \nsignificantly low: the probability from part (b) or part (c)? Based on the relevant probability, is \nthe result of one subject experiencing influenza significantly low?\ne. What do the results suggest about the effectiveness of the vaccine?\n37. Geometric Distribution If a procedure meets all the conditions of a binomial distribution \nexcept that the number of trials is not fixed, then the geometric distribution can be used. The \nprobability of getting the first success on the xth trial is given by P1x2 = p11 - p2 x-1, where \np is the probability of success on any one trial. Subjects are randomly selected for the National \nHealth and Nutrition Examination Survey conducted by the National Center for Health Statis-\ntics, Centers for Disease Control and Prevention. The probability that someone is a universal \ndonor (with group O and type Rh negative blood) is 0.06. Find the probability that the first \nsubject to be a universal blood donor is the fifth person selected.\n38. Multinomial Distribution The binomial distribution applies only to cases involving two \ntypes of outcomes, whereas the multinomial distribution involves more than two categories. \nSuppose we have three types of mutually exclusive outcomes denoted by A, B, and C. Let \nP1A2 = p1, P1B2 = p2, and P1C2 = p3. In n independent trials, the probability of x1 out-\ncomes of type A, x2 outcomes of type B, and x3 outcomes of type C is given by\nn!\n1x12!1x22!1x32! # px11 # px22 # px33\nData Set 8 “IQ and Lead” in Appendix B includes 78 subjects from a low lead exposure group, \n22 subjects from a medium lead exposure group, and 21 subjects from a high lead exposure \ngroup. Find the probability of randomly selecting 10 subjects for a follow-up study and getting \n5 from the low lead group, 2 from the medium lead group, and 3 from the high lead group. \nAssume that the selections are made with replacement. Can we use the above expression for \nfinding the probability if the sampling is done without replacement?\n39. Hypergeometric Distribution If we sample from a small finite population without re-\nplacement, the binomial distribution should not be used because the events are not indepen-\ndent. If sampling is done without replacement and the outcomes belong to one of two types, \nwe can use the hypergeometric distribution. If a population has A objects of one type, while \nthe remaining B objects are of the other type, and if n objects are sampled without replacement, \nthen the probability of getting x objects of type A and n - x objects of type B is\nP1x2 =\nA!\n1A - x2!x! #\nB!\n1B - n + x2!1n - x2! ,\n1A + B2!\n1A + B - n2!n!\nIn a medical research project, there are 20 subjects available and 4 of them are infected with \nHIV, while the other 16 are not infected. If 8 of the subjects are randomly selected without re-\nplacement, what is the probability that 3 of the subjects are infected with HIV, while the other 5 \nare not infected? What is the probability if the sampling is done with replacement?\n5-2 Beyond the Basics\nKey Concept In Section 5-1 we introduced general discrete probability distributions \nand in Section 5-2 we considered binomial probability distributions, which is one \nparticular category of discrete probability distributions. In this section we introduce \nPoisson probability distributions, which are another category of discrete probability \ndistributions.\n5-3 \nPoisson Probability Distributions\n\n5-3 Poisson Probability Distributions \n207\nThe following definition states that Poisson distributions are used with occur-\nrences of an event over a specified interval, and here are some applications:\n \n■Number of Internet users logging onto WebMD in one day\n \n■Number of patients arriving at an emergency room in one hour\n \n■Number of Atlantic hurricanes in one year\nDEFINITION\nA Poisson probability distribution is a discrete probability distribution that ap-\nplies to occurrences of some event over a specified interval. The random variable \nx is the number of occurrences of the event in an interval. The interval can be time, \ndistance, area, volume, or some similar unit. The probability of the event occurring \nx times over an interval is given by Formula 5-9.\nFORMULA 5-9  Poisson Probability Distribution\nP1x2 = mx # e-m\nx!\nwhere\ne ≈2.71828\nm = mean number of occurrences of the event in the intervals\nRequirements for the Poisson Probability Distribution\n1.  The random variable x is the number of occurrences of an event in some \n interval.\n2. The occurrences must be random.\n3. The occurrences must be independent of each other.\n4. The occurrences must be uniformly distributed over the interval being used.\nParameters of the Poisson Probability Distribution\n \n■The mean is m.\n \n■The standard deviation is s = 1m.\nProperties of the Poisson Probability Distribution\n1. A particular Poisson distribution is determined only by the mean μ.\n2. A Poisson distribution has possible x values of 0, 1, 2, . . . with no upper limit.\nEXAMPLE 1  Hospital Births\nIn a recent year, there were 4229 births at NYU Langone Medical Center (based on \ndata from the NYU Langone website). Assume that the number of births each day is \nabout the same, and assume that the Poisson distribution is a suitable model.\n \na. Find m, the mean number of births per day.\n \nb. Find the probability that on a randomly selected day, there are exactly 10 \nbirths. That is, ﬁnd P(10), where P(x) is the probability of x births in a day.\ncontinued\n\n208 \nCHAPTER 5 Discrete Probability Distributions\nPoisson Distribution as Approximation to Binomial\nThe Poisson distribution is sometimes used to approximate the binomial distribution \nwhen n is large and p is small. One rule of thumb is to use such an approximation \nwhen the following two requirements are both satisfied.\nRequirements for Using Poisson as an Approximation to Binomial\n1. n Ú 100\n2. np … 10\nIf both requirements are satisfied and we want to use the Poisson distribution as an \napproximation to the binomial distribution, we need a value for m. That value can be \ncalculated by using Formula 5-6 (from Section 5-2):\nSOLUTION\na. The Poisson distribution applies because we are dealing with the occurrences \nof an event (births) over some interval (a day). The mean number of births per \nday is\nm = Number of births\nNumber of days = 4229\n365 = 11.5863\n \nb. Using Formula 5-9, the probability of x = 10 births in a day is found as \nshown here (with x = 10, m = 11.5863, and e = 2.71828):\nP1102 = mx # e-m\nx!\n= 11.586310 # 2.71828-11.5863\n10!\n= 0.112\nThe probability of exactly 10 births in a day is 0.112.\nFORMULA 5-6 Mean for Poisson as an Approximation to Binomial\nm = np\nEXAMPLE 2  Influenza\nIn one year, the rate of influenza is 5%. If 120 people are randomly selected, find \nthe probability of getting at least one who contracts influenza.\nSOLUTION\nThe time interval is a year. With n = 120 and p = 0.05, the conditions n Ú 100 \nand np … 10 are both satisfied, so we can use the Poisson distribution as an approx-\nimation to the binomial distribution. We first need the value of m, which is found as \nfollows:\nm = np = 1120210.052 = 6\nHaving found the value of m, we can proceed to find the probability for specific \nvalues of x. Because we want the probability that x is “at least 1,” we will use the \nclever strategy of first finding P(0), the probability of no subjects getting influenza. \n\n5-3 Poisson Probability Distributions \n209\nThe probability of at least one subject getting influenza can then be found by sub-\ntracting that result from 1. We find P(0) by using x = 0, m = 6, and e = 2.71828, \nas shown here:\nP102 = mx # e-m\nx !\n= 60 # 2.71828-6\n0!\n= 1 # 0.00248\n1\n= 0.00248\nUsing the Poisson distribution as an approximation to the binomial distribution, we \nfind that there is a 0.00248 probability of no subjects with influenza, so the prob-\nability of at least one subject with influenza is 1 - 0.00248 = 0.998. If we use the \nbinomial distribution, we again get a probability of 0.998, so the Poisson approxi-\nmation is quite good here.\nPoisson Distributions\nAccess tech instructions, videos, and data sets at www.TriolaStats.com\nTECH CENTER \nStatistical Literacy and Critical Thinking\n1. Notation In analyzing patient admissions at NYU Langone Medical Center, we find that \n31,645 patients were admitted in a recent year (based on data from the NYU Langone website). \nAssume that we want to find the probability of exactly 85 patient admissions in a randomly \nselected day. In applying Formula 5-9, identify the values of m, x, and e. Also, briefly describe \nwhat each of those symbols represents.\n2. Patient Admissions Use the same patient admission data given in Exercise 1. Let the ran-\ndom variable x represent the number of patient admissions in one day, and assume that it has \na Poisson distribution. What is the standard deviation for the values of the random variable x? \nWhat is the variance?\n3. Poisson Probability Distribution The random variable x represents the number of pa-\ntient admissions in a day, as described in Exercise 1. Assume that the random variable x has a \nPoisson distribution. What are the possible values of x? Is a value of x = 90.3 possible? Is x a \ndiscrete random variable or a continuous random variable?\n4. Probability if 0 For Formula 5-9, what does P(0) represent? Simplify Formula 5-9 for the \ncase in which x = 0.\nBirths. In Exercises 5–8, assume that the Poisson distribution applies, assume that the \nmean number of births at the NYU Langone Medical Center is 11.5863 per day, and \n proceed to find the probability that in a randomly selected day, the number of births is the \nvalue given.\n5. Births Find the probability that in a day, there will be exactly 12 births.\n6. Births Find the probability that in a day, there will be exactly 9 births.\n7. Births Find the probability that in a day, there will be at least 1 birth.\n8. Births Find the probability that in a day, there will be at least 2 births.\n9. Murders In a recent year, there were 333 murders in New York City. Find the mean number \nof murders per day; then use that result to find the probability that in a day, there are no mur-\nders. Does it appear that there are expected to be many days with no murders?\n5-3 Basic Skills and Concepts\n\n210 \nCHAPTER 5 Discrete Probability Distributions\n10. Deaths from Horse Kicks A classical example of the Poisson distribution involves the \nnumber of deaths caused by horse kicks to men in the Prussian Army between 1875 and 1894. \nData for 14 corps were combined for the 20-year period, and the 280 corps-years included a to-\ntal of 196 deaths. After finding the mean number of deaths per corps-year, find the probability \nthat a randomly selected corps-year has the following numbers of deaths: (a) 0, (b) 1, (c) 2, (d) 3, \n(e) 4. The actual results consisted of these frequencies: 0 deaths (in 144 corps-years); 1 death \n(in 91 corps-years); 2 deaths (in 32 corps-years); 3 deaths (in 11 corps-years); 4 deaths (in \n2 corps-years). Compare the actual results to those expected by using the Poisson probabilities. \nDoes the Poisson distribution serve as a good tool for predicting the actual results?\n11.  World War II Bombs In analyzing hits by V-1 buzz bombs in World War II, South \n London was partitioned into 576 regions, each with an area of 0.25 km2. A total of 535 bombs \nhit the combined area of 576 regions.\na. Find the probability that a randomly selected region had exactly 2 hits.\nb. Among the 576 regions, find the expected number of regions with exactly 2 hits.\nc. How does the result from part (b) compare to this actual result: There were 93 regions that \nhad exactly 2 hits?\n12. Disease Cluster Neuroblastoma, a rare form of cancer, occurs in 11 children in a  million, \nso its probability is 0.000011. Four cases of neuroblastoma occurred in Oak Park, Illinois, \nwhich had 12,429 children.\na. Assuming that neuroblastoma occurs as usual, find the mean number of cases in groups of \n12,429 children.\nb. Using the unrounded mean from part (a), find the probability that the number of neuroblas-\ntoma cases in a group of 12,429 children is 0 or 1.\nc. What is the probability of more than one case of neuroblastoma?\nd. Does the cluster of four cases appear to be attributable to random chance? Why or why not?\n13. Car Fatalities The recent rate of car fatalities was 33,561 fatalities for 2969 billion miles \ntraveled (based on data from the National Highway Traffic Safety Administration). Find the \nprobability that for the next billion miles traveled, there will be at least one fatality. What does \nthe result indicate about the likelihood of at least one fatality?\n14. Dandelions Dandelions are studied for their effects on crop production and lawn growth. \nIn one region, the mean number of dandelions per square meter was found to be 7.0 (based on \ndata from Manitoba Agriculture and Food).\na. Find the probability of no dandelions in an area of 1 m2.\nb. Find the probability of at least one dandelion in an area of 1 m2.\nc. Find the probability of at most two dandelions in an area of 1 m2.\n15. Rubella During the last 13 years in the United States, there were 138 cases of rubella.\na. Find the mean number of cases of rubella per year. Round the result to four decimal places.\nb. Find the probability of no cases of rubella in a year.\nc. Find the probability of exactly 9 cases of rubella in a year. How does it compare to the \n2 years among 13 that had exactly 9 cases of rubella?\n16.  Diphtheria During the past 34 years, there were 56 cases of diphtheria in the United \nStates.\na. Find the mean number of cases of diphtheria per year. Express the result with five decimal places.\nb. Find the probability of no cases of diphtheria in a year.\nc. Find the probability that the number of diphtheria cases in a year is 5 or fewer. If a year has \nmore than 5 cases of diphtheria, is that a significantly high number?\n\n6. Drinking Does the table describe a probability distribution? Why or why not?\n7. Drinking Find the mean of the number of heavy drinkers in groups of five randomly se-\nlected adult males.\n8. Drinking Based on the table, the standard deviation is 0.5 male. What is the variance? In-\nclude appropriate units.\n9. Drinking What does the probability of 0+ indicate? Does it indicate that among five ran-\ndomly selected adult males, it is impossible for all of them to be heavy drinkers?\n10. Drinking What is the probability that fewer than three of the five adult males are heavy \ndrinkers? If we were to find that among 5 randomly selected adult males, there are 4 heavy \ndrinkers, is 4 significantly high?\n17. Probability Histogram for a Poisson Distribution Construct the probability histogram \nfor Exercise 16. Is the Poisson probability distribution a normal distribution or is it skewed?\n5-3 Beyond the Basics\nIn Exercises 1–10, use the following: Based on data from the National Center for Health \nStatistics, 20.6% of adult males smoke. A random sample of 64 male adults is obtained.\n1. Smoking Find the mean number of smokers in groups of 64 randomly selected adult males.\n2. Smoking Find the standard deviation of the number of smokers in groups of 64 randomly \nselected adult males.\n3. Smoking Are the results from Exercises 1 and 2 statistics or parameters?\n4. Smoking For a random sample of 64 males, find the numbers separating the outcomes that \nare significantly high or significantly low.\n5. Smoking Find the probability that the first 8 randomly selected males include exactly 3 \nwho smoke.\nIn Exercises 6–10, use the following: Five male adults are randomly selected, and the table \nin the margin lists the probabilities for the number that are heavy drinkers (based on data \nfrom the National Center for Health Statistics). Males are considered to be heavy drinkers if \nthey have at least 14 drinks per week “on average.”\nChapter Quick Quiz\nx\nP(x)\n0\n0.762\n1\n0.213\n2\n0.024\n3\n0.001\n4\n   0+\n5\n 0+\nIn Exercises 1–5, assume that 28% of randomly selected adults have high cholesterol (with \na level of at least 240 mg , dL or are taking medicine to reduce cholesterol), based on results \nfrom the National Center for Health Statistics. Assume that a group of five adults is ran-\ndomly selected.\n1. Cholesterol Find the probability that exactly two of the five adults have high cholesterol.\n2. Cholesterol Find the probability that at least one of the five adults has high cholesterol. \nDoes the result apply to five adults from the same family? Why or why not?\n3. Cholesterol Find the mean and standard deviation for the numbers of adults in groups of \nfive who have high cholesterol.\n4. Cholesterol If all five of the adults have high cholesterol, is five significantly high? Why \nor why not?\nReview Exercises\nCHAPTER 5 Review Exercises \n211\n\n212 \nCHAPTER 5 Discrete Probability Distributions\n5. Cholesterol If the group of five adults includes exactly 1 with high cholesterol, is that \nvalue of 1 significantly low?\n6. Security Survey In a USA Today poll, subjects were asked if passwords should be re-\nplaced with biometric security, such as fingerprints. The results from that poll have been used \nto create the accompanying table. Does this table describe a probability distribution? Why or \nwhy not?\nResponse\nP(x)\nYes\n0.53\nNo\n0.17\nNot sure\n0.30\n7. Condom Failure Rate According to the Department of Health and Human Services, the \nfailure rate for male condoms is 18%. The accompanying table is based on the failure rate of \n18%, where x represents the number of condoms that fail when six are tested.\na. Does the table describe a probability distribution? Why or why not?\nb. Assuming that the table does describe a probability distribution, find its mean.\nc. Assuming that the table does describe a probability distribution, find its standard deviation.\nd. If 6 condoms are tested and 5 of them fail, is 5 a significantly high number of failures? Why \nor why not?\ne. What does the symbol 0+ represent?\nx\nP(x)\n0\n0.304\n1\n0.400\n2\n0.220\n3\n0.064\n4\n0.011\n5\n0.001\n6\n0+\n8.  Poisson: Deaths Currently, an average of 143 residents of Madison, CT (population \n17,858), die each year (based on data from the U.S. National Center for Health Statistics).\na. Find the mean number of deaths per day.\nb. Find the probability that on a given day, there are no deaths.\nc. Find the probability that on a given day, there are more than two deaths.\nd. Based on the preceding results, should Madison have a contingency plan to handle more \nthan two deaths per day? Why or why not?\nCumulative Review Exercises\n1. Manatee Deaths Listed below are the annual numbers of manatee deaths from boats in \nFlorida for each of the past 10 years, listed in chronological order.\n69 79 92 73 90 97 83 88 81 72\na. Find the mean.\nb. Find the median.\nc. Find the range.\nd. Find the standard deviation.\ne. Find the variance.\nf. Describe an important characteristic of the data that is not addressed by the statistics found in \nparts (a) through (e).\ng. Use the range rule of thumb to identify the values separating significant values from those \nthat are not significant.\nh. Based on the result from part (f), do any of the years have a number of manatee deaths that is \nsignificantly low or significantly high?\ni. What is the level of measurement of the data: nominal, ordinal, interval, or ratio?\nj. Are the data discrete or continuous?\n\n2. Analysis of Last Digits The accompanying table lists the last or rightmost digits of weights \nof the females listed in Data Set 1 “Body Data” in Appendix B. The last digits of a data set can \nsometimes be used to determine whether the data have been measured or simply reported. The \npresence of disproportionately more 0s and 5s is often a sure sign that the data have been re-\nported instead of measured.\na. Using the table, find the mean and standard deviation of those last digits. Are the results \nstatistics or parameters?\nb. Examine the given table to determine if there is anything about the sample data (such as \ndisproportionately more 0s and 5s) suggesting that the given last digits are not random? Or do \nthey appear to be random?\nc. Does the table describe a probability distribution? Why or why not?\nx\nf\n0\n11\n1\n11\n2\n16\n3\n14\n4\n16\n5\n24\n6\n13\n7\n14\n8\n19\n9\n  9\n3. Government Health Plan Fox News broadcast a graph similar to the one shown here. The \ngraph is intended to compare the number of people actually enrolled in a government health \nplan (left bar) and the goal for the number of enrollees (right bar). Does the graph depict the \ndata correctly or is it somehow misleading? Explain.\n4. Diabetes Among adults in the United States, 11.5% have diabetes (based on data from the \nNational Center for Health Statistics).\na. Find the probability that a randomly selected adult does not have diabetes.\nb. Find the probability that two randomly selected adults both have diabetes.\nc. Find the probability that among three randomly selected adults, at least one has diabetes.\nd. For groups of 40 randomly selected adults, find the mean and standard deviation for the \nnumbers of adults having diabetes. Are these results statistics or parameters?\ne. If 40 adults are randomly selected and 10 of them have diabetes, is 10 a result that is signifi-\ncantly low or significantly high? Why?\n\t\nCHAPTER 5  Cumulative Review Exercises\t\n213\n\n214 \nCHAPTER 5 Discrete Probability Distributions\nFROM DATA TO DECISION\nCritical Thinking: Determining criteria for concluding \nthat a gender selection method is effective\nYou are responsible for analyzing results from a clinical trial \nof the effectiveness of a new method of gender selection. \nAssume that the sample size of n = 75 couples has already \nbeen established, and each couple will have one child. Fur-\nther assume that each of the couples will be subjected to a \ntreatment that supposedly increases the likelihood that the \nchild will be a girl. Assume that with no treatment, the prob-\nability of a baby being a girl is 0.488, which is currently the \ncorrect value in the United States.\nThere is a danger in obtaining results first, then making \nconclusions about the results. If the results are close to show-\ning the effectiveness of a treatment, it might be tempting to \n conclude that there is an effect when, in reality, there is no ef-\nfect. It is better to establish criteria before obtaining results.\na. Using the methods of this chapter, identify the criteria that \nshould be used for concluding that the treatment is effective in in-\ncreasing the likelihood of a girl. Among the 75 births, how many \ngirls would you require in order to conclude that the gender selec-\ntion procedure is effective? Explain how you arrived at this result.\nb. If 60% of the 75 babies are girls, is that result high enough \nto conclude that the gender selection method is effective? \nWhy or why not?\nc. If 64% of the 75 babies are girls, is that result high enough \nto conclude that the gender selection method is effective? \nWhy or why not?\nCooperative Group Activities\n1. In-class activity Win $1,000,000! The James Randi Educational Foundation offers a \n$1,000,000 prize to anyone who can show “under proper observing conditions, evidence of \nany paranormal, supernatural, or occult power or event.” Divide into groups of three. Select \none person who will be tested for extrasensory perception (ESP) by trying to correctly identify \na digit (0–9) randomly selected by another member of the group. Conduct at least 20 trials. \nAnother group member should record the randomly selected digit, the digit guessed by the \nsubject, and whether the guess was correct or wrong. Construct the table for the probability \ndistribution of randomly generated digits, construct the relative frequency table for the ran-\ndom digits that were actually obtained, and construct a relative frequency table for the guesses \nthat were made. After comparing the three tables, what do you conclude? What proportion of \nguesses is correct? Does it seem that the subject has the ability to select the correct digit signifi-\ncantly more often than would be expected by chance?\nMendel’s Hybrid Experiments One of Mendel’s famous experiments with peas included \n1064 offspring, and 787 of them had long stems. Mendel claimed that under the same condi-\ntions, 75% of offspring peas would have long stems. Assume that Mendel’s claim of 75% is \ntrue, and assume that a sample consists of 1064 offspring peas.\n• Use the range rule of thumb to identify the limits separating values that are significantly low \nand those that are significantly high. Based on the results, is the result of 787 peas with long \nstems either significantly low or significantly high?\n• Find the probability of exactly 787 peas with long stems.\n• Find the probability of 787 or fewer peas with long stems.\n• Which probability is relevant for determining whether 787 peas with long stems is signifi-\ncantly low: the probability from part (b) or part (c)? Based on the relevant probability, is the \nresult of 787 peas with long stems significantly low?\n• What do the results suggest about Mendel’s claim of 75%?\nTechnology Project\n\n2. In-class activity See the preceding activity and design an experiment that would be ef-\nfective in testing someone’s claim that he or she has the ability to identify the color of a card \nselected from a standard deck of playing cards. Describe the experiment with great detail. Be-\ncause the prize of $1,000,000 is at stake, we want to be careful to avoid the serious mistake of \nconcluding that the person has a paranormal power when that power is not actually present. \nThere will likely be some chance that the subject could make random guesses and be correct \nevery time, so identify a probability that is reasonable for the event of the subject passing the \ntest with random guesses. Be sure that the test is designed so that this probability is equal to or \nless than the probability value selected.\n3. In-class activity Suppose we want to identify the probability distribution for the number \nof children in families with at least one child. For each student in the class, find the number \nof brothers and sisters and record the total number of children (including the student) in each \nfamily. Construct the relative frequency table for the result obtained. (The values of the random \nvariable x will be 1, 2, 3, . . . .) What is wrong with using this relative frequency table as an es-\ntimate of the probability distribution for the number of children in randomly selected families?\n4. Out-of-class activity The analysis of the last digits of data can sometimes reveal whether \nthe data have been collected through actual measurements or reported by the subjects. Refer \nto an almanac or the Internet and find a collection of data (such as lengths of rivers in the \nworld), then analyze the distribution of last digits to determine whether the values were ob-\ntained through actual measurements.\n5. Out-of-class activity The photos shown below depict famous statisticians with first names \nof David and John, not necessarily in the order shown. Conduct a survey by asking this ques-\ntion: “Which man is named David and which man is named John?” Do the respondents ap-\npear to give results significantly different from what is expected with random guesses? (See \n“Who Do You Look Like? Evidence of Facial Stereotypes for Male Names” by Lea, Thomas, \nLamkin, and Bell, Psychonomic Bulletin & Review, Vol. 14, Issue 5.)\nCHAPTER 5 Cooperative Group Activities \n215\n\n216\nThe Standard Normal \nDistribution\nReal Applications of \nNormal Distributions\nSampling Distributions \nand Estimators\nThe Central Limit \nTheorem\nAssessing Normality\nNormal as \nApproximation to \nBinomial\n6-1\n6-2\n6-3\n6-4\n6-5\n6-6\nWhat Is a Normal Pulse Rate?\nCHAPTER \nPROBLEM\nNormal Probability \nDistributions\nExploring the pulse rates of adult males and females in Data \nSet 1 “Body Data” from Appendix B reveals the  following:\n• Adult males have pulse rates with a mean of 69.6 bpm \n(beats per minute), a standard deviation of 11.3 bpm, and a \ndistribution that is approximately normal.\n• Adult females have pulse rates with a mean of 74.0 bpm, \na standard deviation of 12.5 bpm, and a distribution that is \napproximately normal.\n• There appears to be a significant difference between pulse \nrates of males and females.\nFor the purposes of this chapter, we will use the above results as \nreasonable estimates of population parameters. See the following:\nm \ns \nDistribution\nMale Adult Pulse Rates (bpm) \n69.6 \n11.3 \nNormal\nFemale Adult Pulse Rates (bpm) \n74.0 \n12.5 \nNormal\n6 \n\nPhysicians routinely measure pulse rates of patients, and the \nnormal range is generally considered to be between 60 bpm and \n100 bpm. Here are conditions for pulse rates outside that range:\nTachycardia: Pulse rate greater than 100 bpm.\nBradycardia: Pulse rate less than 60 bpm\nAn excessively high pulse rate (tachycardia) is generally more \nof a problem than an excessively low pulse rate (bradycar-\ndia). An excessively high pulse rate can indicate a high risk of \nstroke, heart disease, or can even cause death. An excessively \nlow pulse can occur with an athlete in peak physical condition, \nand some drugs such as beta blockers can also cause an  \nexcessively low pulse rate.\nHere are some questions that can be addressed with the \nmethods of this chapter:\n• What is the proportion of adult males who are expected to \nhave pulse rates greater than 100 bpm?\n• What is the proportion of adult males who are expected to \nhave pulse rates less than 60 bpm.\n• For males, if we introduce a criterion whereby the highest \n1% of pulse rates are considered to be significantly high, \nwhat is the cutoff?\n• For males, if we introduce a criterion whereby the lowest 1% \nof pulse rates are considered to be significantly low, what is \nthe cutoff?\nThese same questions can be posed for adult females, and we will \naddress such questions using the methods in this chapter.\nChapter 5 introduced discrete probability distributions, but in this chapter we introduce \ncontinuous probability distributions, and most of this chapter focuses on normal distri-\nbutions. Here are the chapter objectives:\nThe Standard Normal Distribution\n• Describe the characteristics of a standard normal distribution.\n• Find the probability of some range of z values in a standard normal distribution.\n• Find z scores corresponding to regions under the curve representing a standard \nnormal distribution.\nReal Applications of Normal Distributions\n• Develop the ability to describe a normal distribution (not necessarily a standard \n normal distribution).\n• Find the probability of some range of values in a normal distribution.\n• Find x scores corresponding to regions under the curve representing a normal \n distribution.\nSampling Distributions and Estimators\n• Develop the ability to describe a sampling distribution of  a statistic.\n• Determine whether a statistic serves as a good estimator of the corresponding \npopulation parameter.\nThe Central Limit Theorem\n• Describe what the central limit theorem states.\n• Apply the central limit theorem by finding the probability that a sample mean falls \nwithin some specified range of values.\n• Identify conditions for which it is appropriate to use a normal distribution for the \n distribution of sample means.\n6-1\n6-2\n6-3\n6-4\nChapter Objectives \n217\nCHAPTER OBJECTIVES\n>>>\ncontinued\n\n218 \nCHAPTER 6 Normal Probability Distributions\nKey Concept In this section we present the standard normal distribution, which is a \nspecific normal distribution having the following three properties:\n1. Bell-shaped: The graph of the standard normal distribution is bell-shaped (as in \nFigure 6-1).\n2. m = 0: The standard normal distribution has a mean equal to 0.\n3. s = 1: The standard normal distribution has a standard deviation equal to 1.\nIn this section we develop the skill to find areas (or probabilities or relative frequen-\ncies) corresponding to various regions under the graph of the standard normal distri-\nbution. In addition, we find z scores that correspond to areas under the graph. These \nskills become important in the next section as we study nonstandard normal distribu-\ntions and the real and important applications that they involve.\nNormal Distributions\nThere are infinitely many different normal distributions, depending on the values used \nfor the mean and standard deviation. We begin with a brief introduction to this general \nfamily of normal distributions.\n6-1 \nThe Standard Normal Distribution\nAssessing Normality\n• Develop the ability to examine histograms, outliers, and normal quantile plots to \ndetermine whether sample data appear to be from a population having a distribution \nthat is approximately normal.\nNormal as Approximation to Binomial\n• Identify conditions for which it is appropriate to use a normal distribution as an ap-\nproximation to a binomial probability distribution.\n• Use the normal distribution for approximating probabilities for a binomial distribution.\n6-5\n6-6\nAssessing Normality\n• Develop the ability to examine histograms, outliers, and normal quantile plots to \ndetermine whether sample data appear to be from a population having a distribution\nthat is approximately normal.\nNormal as Approximation to Binomial\n• Identify conditions for which it is appropriate to use a normal distribution as an ap-\nfo\nf\nproximation to a binomial probability distribution.\n• Use the normal distribution for approximating probabilities for a binomial distribution.\nDEFINITION\nIf a continuous random variable has a distribution with a graph that is symmetric \nand bell-shaped, as in Figure 6-1, and it can be described by the equation given as \nFormula 6-1, we say that it has a normal distribution.\nFORMULA 6-1\ny = e- 1\n21\nx - m\ns 22\ns22p\nIn this book, we won’t actually use Formula 6-1, but examining the right side of the \nequation reveals that any particular normal distribution is determined by two parame-\nters: the population mean, m, and population standard deviation, s. (In Formula 6-1, x is \na variable that can change, p = 3.14159, and e = 2.71828.) Once specific values are \nselected for m and s, Formula 6-1 is an equation relating x and y, and we can graph \nm\nValue\nCurve is bell-shaped\nand symmetric\nFIGURE 6-1  The Normal \nDistribution\n\n6-1 The Standard Normal Distribution \n219\nthat equation to get a result that will look like Figure 6-1. And that’s about all we need \nto know about Formula 6-1!\nUniform Distributions\nThe major focus of this chapter is the concept of a normal probability distribution, but \nwe begin with a uniform distribution so that we can see the following two very impor-\ntant properties:\n1. The area under the graph of a continuous probability distribution is equal to 1.\n2. There is a correspondence between area and probability, so probabilities \ncan be found by identifying the corresponding areas in the graph using this \nformula for the area of a rectangle:\nArea = height * width\nEXAMPLE 1  Waiting Times for Emergency Room Check-In\nDuring certain time periods at a hospital in New York City, patients arriving at the \nemergency room have waiting times that are uniformly distributed between 0 minutes \nand 5 minutes, as illustrated in Figure 6-2.\nRefer to Figure 6-2 to see these properties:\n \n■All of the different possible waiting times are equally likely.\n \n■Waiting times can be any value between 0 min and 5 min, so it is possible to \nhave a waiting time of 1.234567 min.\n \n■By assigning the probability of 0.2 to the height of the vertical line in Figure 6-2, \nthe enclosed area is exactly 1. (In general, we should make the height of the ver-\ntical line in a uniform distribution equal to 1>range.)\n0\n0.2\n1\n2\nArea 5 1\n3\n4\n5\nx (waiting time in minutes)\nP(x)\nFIGURE 6-2 Uniform Distribution of Waiting Time\nDEFINITION\nA continuous random variable has a uniform distribution if its values are spread \nevenly over the range of possibilities. The graph of a uniform distribution results in \na rectangular shape.\nDensity Curve The graph of any continuous probability distribution is called a \ndensity curve, and any density curve must satisfy the requirement that the total area \nunder the curve is exactly 1. This requirement that the area must equal 1 simplifies \nprobability problems, so the following statement is really important:\nBecause the total area under any density curve is equal to 1, there is a \n correspondence between area and probability.\n\n220 \nCHAPTER 6 Normal Probability Distributions\nStandard Normal Distribution\nThe density curve of a uniform distribution is a horizontal straight line, so we can find \nthe area of any rectangular region by applying this formula:\nArea = height * width\nBecause the density curve of a normal distribution has a more complicated bell shape \nas shown in Figure 6-1, it is more difficult to find areas. However, the basic principle \nis the same: There is a correspondence between area and probability. In Figure 6-4 \nwe show that for a standard normal distribution, the area under the density curve is \nequal to 1. In Figure 6-4, we use “z Score” as a label for the horizontal axis, and this is \ncommon for the standard normal distribution, defined as follows.\nEXAMPLE 2  Waiting Times at an Emergency Room\nGiven the uniform distribution illustrated in Figure 6-2, find the probability that a \nrandomly selected patient has a waiting time of at least 2 minutes.\nSOLUTION\nThe shaded area in Figure 6-3 represents waiting times of at least 2 minutes. Because the \ntotal area under the density curve is equal to 1, there is a correspondence between area \nand probability. We can easily find the desired probability by using areas as follows:\n P1wait time of at least 2 min2 = height *  width of shaded area in Figure 6@3\n = 0.2 * 3\n = 0.6\n0\n0.2\n1\n2\nArea 5 0.2 3 3\n \n5 0.6\n3\n4\n5\nx (waiting time in minutes)\nP(x)\nFIGURE 6-3 Using Area to Find Probability\nINTERPRETATION\nThe probability of randomly selecting a patient with a waiting time of at least  \n2 minutes is 0.6.\n1\n2\n3\n0\nz Score\nArea 5 1\n21\n22\n23\nFIGURE 6-4\nStandard Normal Distribution\n\n6-1 The Standard Normal Distribution \n221\nFinding Probabilities When Given z Scores\nIt is not easy to manually find areas in Figure 6-4, but we can find areas (or prob-\nabilities) for many different regions in Figure 6-4 by using technology, or we can also \nuse Table A-2 (in Appendix A and the Formulas and Tables insert card). Key features \nof the different methods are summarized in Table 6-1, which follows. (StatCrunch \nprovides options for a cumulative left region, a cumulative right region, or the region \nbetween two boundaries.) Because calculators and software generally give more ac-\ncurate results than Table A-2, we strongly recommend using technology. (When there \nare discrepancies, answers in Appendix D will generally include results based on tech-\nnology as well as answers based on Table A-2.)\nTABLE 6-1 Formats Used for Finding Normal Distribution Areas\nCumulative Area from the Left\nThe following provide the cumulative area \nfrom the left up to a vertical line above a \nspecific value of z:\n• Table A-2 \n• Statdisk \n• Minitab \n• Excel \n• StatCrunch \nz\nCumulative Left Region\nArea Between Two Boundaries\nThe following provide the area bounded on \nthe left and bounded on the right by vertical \nlines above specific values.\n• TI-83, 84 Plus calculator \n• StatCrunch \nUpper\nLower\nArea Between Two Boundaries\nDEFINITION\nThe standard normal distribution is a normal distribution with the parameters of \nm = 0 and s = 1. The total area under its density curve is equal to 1 (as in Figure 6-4).\nTable A-2: If using Table A-2, it is essential to understand these points:\n1. Table A-2 is designed only for the standard normal distribution, which is a nor-\nmal distribution with a mean of 0 and a standard deviation of 1.\n2. Table A-2 is on two pages, with the left page for negative z scores and the right \npage for positive z scores.\n3. Each value in the body of the table is a cumulative area from the left up to a \nvertical boundary above a specific z score.\ncontinued\n\n222 \nCHAPTER 6 Normal Probability Distributions\nThe following examples illustrate procedures that can be used with real and im-\nportant applications introduced in the following sections.\nCAUTION When working with a normal distribution, be careful to avoid confusion \nbetween z scores and areas.\nz 5 1.27\n0\nArea 5 0.8980\n(from Table A-2)\nFIGURE 6-5\nFinding Area to the Left of z = 1.27\nEXAMPLE 3  Bone Density Test\nA bone mineral density test can be helpful in identifying the presence or likelihood \nof osteoporosis, a disease causing bones to become more fragile and more likely \nto break. The result of a bone density test is commonly measured as a z score. The \npopulation of z scores is normally distributed with a mean of 0 and a standard de-\nviation of 1, so these test results meet the requirements of a standard normal distri-\nbution, and the graph of the bone density test scores is as shown in Figure 6-5.\nA randomly selected adult undergoes a bone density test. Find the probability \nthat this person has a bone density test score less than 1.27.\nSOLUTION\nNote that the following are the same (because of the aforementioned correspon-\ndence between probability and area):\n \n■Probability that the bone density test score is less than 1.27\n \n■Shaded area shown in Figure 6-5\nSo we need to find the area in Figure 6-5 below z = 1.27. If using Table A-2, \n begin with the z score of 1.27 by locating 1.2 in the left column; next find the \nvalue in the adjoining row of probabilities that is directly below 0.07, as shown in \nthe excerpt on the top of the following page. Table A-2 shows that there is an area \nof 0.8980 corresponding to z = 1.27. We want the area below 1.27, and Table A-2 \ngives the cumulative area from the left, so the desired area is 0.8980. Because of \nthe correspondence between area and probability, we know that the probability of a \nz score below 1.27 is 0.8980.\n4. When working with a graph, avoid confusion between z scores and areas.\nz score: \n Distance along the horizontal scale of the standard normal dis-\ntribution (corresponding to the number of standard deviations \nabove or below the mean); refer to the leftmost column and top \nrow of Table A-2.\nArea: \n Region under the curve; refer to the values in the body of Table A-2.\n5. The part of the z score denoting hundredths is found across the top row of \nTable A-2.\n\n6-1 The Standard Normal Distribution \n223\nTABLE A-2 (continued) Cumulative Area from the LEFT\nz\n.00\n.01\n.02\n.03\n.04\n.05\n.06\n.07\n.08\n.09\n0.0\n.5000\n.5040\n.5080\n.5120\n.5160\n.5199\n.5239\n.5279\n.5319\n.5359\n0.1\n.5398\n.5438\n.5478\n.5517\n.5557\n.5596\n.5636\n.5675\n.5714\n.5753\n0.2\n.5793\n.5832\n.5871\n.5910\n.5948\n.5987\n.6026\n.6064\n.6103\n.6141\n1.0\n.8413\n.8438\n.8461\n.8485\n.8508\n.8531\n.8554\n.8577\n.8599\n.8621\n1.1\n.8643\n.8665\n.8686\n.8708\n.8729\n.8749\n.8770\n.8790\n.8810\n.8830\n1.2\n.8849\n.8869\n.8888\n.8907\n.8925\n.8944\n.8962\n.8980\n.8997\n.9015\n1.3\n.9032\n.9049\n.9066\n.9082\n.9099\n.9115\n.9131\n.9147\n.9162\n.9177\n1.4\n.9192\n.9207\n.9222\n.9236\n.9251\n.9265\n.9279\n.9292\n.9306\n.9319\nINTERPRETATION\nThe probability that a randomly selected person has a bone density test result below \n1.27 is 0.8980, shown as the shaded region in Figure 6-5. Another way to interpret \nthis result is to conclude that 89.80% of people have bone density levels below 1.27.\nEXAMPLE 4   Bone Density Test: Finding the Area to the Right  \nof a Value\nUsing the same bone density test from Example 3, find the probability that a ran-\ndomly selected person has a result above -1.00. A value above -1.00 is considered \nto be in the “normal” range of bone density readings.\nSOLUTION\nWe again find the desired probability by finding a corresponding area. We are look-\ning for the area of the region to the right of z = -1.00 that is shaded in Figure 6-6. \nThe Statdisk display on the top of the following page shows that the area to the \nright of z = -1.00 is 0.841345.\nIf we use Table A-2, we should know that it is designed to apply only to cumu-\nlative areas from the left. Referring to the page with negative z scores, we find that \nthe cumulative area from the left up to z = -1.00 is 0.1587, as shown in Figure \n6-6. Because the total area under the curve is 1, we can find the shaded area by \nsubtracting 0.1587 from 1. The result is 0.8413. Even though Table A-2 is designed \nonly for cumulative areas from the left, we can use it to find cumulative areas from \nthe right, as shown in Figure 6-6.\n0.1587\nz 5 –1.00\n1. Use z 5 21.00\nin Table A-2 to\nﬁnd this area.\n2. Because\n \nthe total area\n \nis 1, this area is\n \n1 2 0.1587 5 0.8413\nFIGURE 6-6  Finding the Area to the \nRight of z = −1\ncontinued\n\n224 \nCHAPTER 6 Normal Probability Distributions\nExample 4 illustrates a way that Table A-2 can be used indirectly to find a cumu-\nlative area from the right. The following example illustrates another way that we can \nfind an area indirectly by using Table A-2.\nINTERPRETATION\nBecause of the correspondence between probability and area, we conclude that \nthe probability of randomly selecting someone with a bone density reading above \n-1 is 0.8413 (which is the area to the right of z = -1.00). We could also say that \n84.13% of people have bone density levels above -1.00.\nz 5 21.00\n0.1587\nThis area\n0.1587\n \nz 5 22.50\n0.0062\nminus this area\n2 0.0062\n \n22.50 21.00\n0.1525\nequals this area\n5 0.1525\nFIGURE 6-7 Finding the Area Between Two z Scores\nEXAMPLE 5   Bone Density Test: Finding the Area Between  \nTwo Values\nA bone density test reading between -1.00 and -2.50 indicates that the subject has \nosteopenia, which is some bone loss. Find the probability that a randomly selected \nsubject has a reading between -1.00 and -2.50.\nSOLUTION\nWe are again dealing with normally distributed values having a mean of 0 and a \nstandard deviation of 1. The values between -1.00 and -2.50 correspond to the \nshaded region in the third graph included in Figure 6-7. Table A-2 cannot be used to \nfind that area directly, but we can use this table to find the following:\n \n1. The area to the left of z = -1.00 is 0.1587.\n \n2. The area to the left of z = -2.50 is 0.0062.\n \n3. The area between z = -2.50 and z = -1.00 (the shaded area at the far right in \nFigure 6-7) is the diﬀerence between the areas found in the preceding two steps:\n \n Statdisk\n\n6-1 The Standard Normal Distribution \n225\nExample 5 can be generalized as the following rule:\nThe area corresponding to the region between two z scores can be found by \nﬁnding the diﬀerence between the two areas found in Table A-2.\nFigure 6-8 illustrates this general rule. The shaded region B can be found by calculat-\ning the difference between two areas found from Table A-2.\nINTERPRETATION\nUsing the correspondence between probability and area, we conclude that there is \na probability of 0.1525 that a randomly selected subject has a bone density read-\ning between -1.00 and -2.50. Another way to interpret this result is to state that \n15.25% of people have osteopenia, with bone density readings between -1.00\nand -2.50.\nHINT Don’t try to memorize a rule or formula for this case. Focus on understanding \nby using a graph. Draw a graph, shade the desired area, and then get creative \nto think of a way to find the desired area by working with cumulative areas from \nthe left.\n0\nz Left\nz Right\nA\nB\nShaded area B 5 (areas A and B combined) — (area A)\nFIGURE 6-8 Finding the Area Between Two z Scores\nProbabilities such as those in the preceding examples can also be expressed with \nthe following notation.\nNotation\nP1a 6 z 6 b2 \ndenotes the probability that the z score is between a and b.\nP1z 7 a2 \ndenotes the probability that the z score is greater than a.\nP1z 6 a2 \ndenotes the probability that the z score is less than a.\nWith this notation, P1-2.50 6 z 6 -1.002 = 0.1525 states in symbols that the \nprobability of a z score falling between -2.50 and -1.00 is 0.1525 (as in Example 5).\nFinding z Scores from Known Areas\nExamples 3, 4, and 5 all involved the standard normal distribution, and they were all \nexamples with this same format: Given z scores, find areas (or probabilities). In many \ncases, we need a method for reversing the format: Given a known area (or probability), \nfind the corresponding z score. In such cases, it is really important to avoid  confusion \nbetween z scores and areas. Remember, z scores are distances along the horizontal \n\n226 \nCHAPTER 6 Normal Probability Distributions\nscale, but areas (or probabilities) are regions under the density curve. (Table A-2 lists \nz-scores in the left column and across the top row, but areas are found in the body of \nthe table.) We should also remember that z scores positioned in the left half of the \ncurve are always negative. If we already know a probability and want to find the cor-\nresponding z score, we use the following procedure.\nProcedure for Finding a z Score from a Known Area\n1. Draw a bell-shaped curve and identify the region under the curve that corre-\nsponds to the given probability. If that region is not a cumulative region from the \nleft, work instead with a known region that is a cumulative region from the left.\n2. Use technology or Table A-2 to find the z score. With Table A-2, use the cu-\nmulative area from the left, locate the closest probability in the body of the \ntable, and identify the corresponding z score.\nSpecial Cases In the solution to Example 6 that follows, Table A-2 leads to a z score \nof 1.645, which is midway between 1.64 and 1.65. When using Table A-2, we can \nusually avoid interpolation by simply selecting the closest value. The accompanying \ntable lists special cases that are often used in a wide variety of applications. (For one \nof those special cases, the value of z = 2.576 gives an area slightly closer to the area \nof 0.9950, but z = 2.575 has the advantage of being the value exactly midway be-\ntween z = 2.57 and z = 2.58.) Except in these special cases, we can usually select \nthe closest value in the table. (If a desired value is midway between two table values, \nselect the larger value.) For z scores above 3.49, we can use 0.9999 as an approxima-\ntion of the cumulative area from the left; for z scores below -3.49, we can use 0.0001 \nas an approximation of the cumulative area from the left.\nSpecial Cases in Table A-2\n \n \nz Score\nCumulative  \nArea from  \nthe Left\n 1.645\n0.9500\n-1.645\n0.0500\n 2.575\n0.9950\n-2.575\n0.0050\nAbove 3.49\n0.9999\nBelow -3.49\n0.0001\n0\nArea 5 0.95\nz 5 ?\nFIGURE 6-9  Finding the 95th Percentile\nEXAMPLE 6  Bone Density Test: Finding a Test Score \nUse the same bone density test scores used in earlier examples. Those scores are \nnormally distributed with a mean of 0 and a standard deviation of 1, so they meet \nthe requirements of a standard normal distribution. Find the bone density score cor-\nresponding to P95, the 95th percentile. That is, find the bone density score that sepa-\nrates the bottom 95% from the top 5%. See Figure 6-9.\nSOLUTION\nFigure 6-9 shows the z score that is the 95th percentile, with 95% of the area (or \n0.95) below it.\nTechnology: We could find the z score using technology. The following Excel  \ndisplay shows that the z score with an area of 0.95 to its left is z = 1.644853627, or \n1.645 when rounded.\n\n6-1 The Standard Normal Distribution \n227\nExcel\nTable A-2: If using Table A-2, search for the area of 0.95 in the body of the table and \nthen find the corresponding z score. In Table A-2 we find the areas of 0.9495 and \n0.9505, but there’s an asterisk with a special note indicating that 0.9500 corresponds \nto a z score of 1.645. We can now conclude that the z score in Figure 6-9 is 1.645, so \nthe 95th percentile is z = 1.645.\nINTERPRETATION\nFor bone density test scores, 95% of the scores are less than or equal to 1.645, and \n5% of them are greater than or equal to 1.645.\nINTERPRETATION\nFor the population of bone density test scores, 2.5% of the scores are equal to or \nless than -1.96 and 2.5% of the scores are equal to or greater than 1.96. Another in-\nterpretation is that 95% of all bone density test scores are between -1.96 and 1.96.\n0\nz 5 1.96\nz 5 21.96\nArea 5 0.025\nArea 5 0.025\nTo ﬁnd this z score,\nlocate the cumulative\narea to the left in \nTable A–2. Locate 0.975 \nin the body of Table A–2.\nFIGURE 6-10 Finding z Scores\nEXAMPLE 7  Bone Density Test \nUsing the same bone density test described in Example 3, we have a standard normal \ndistribution with a mean of 0 and a standard deviation of 1. Find the bone density test \nscore that separates the bottom 2.5% and find the score that separates the top 2.5%.\nSOLUTION\nThe required z scores are shown in Figure 6-10. Those z scores can be found  using \ntechnology. If using Table A-2 to find the z score located to the left, we search \nthe body of the table for an area of 0.025. The result is z = -1.96. To find the \nz score located to the right, we search the body of Table A-2 for an area of 0.975. \n (Remember that Table A-2 always gives cumulative areas from the left.) The result \nis z = 1.96. The values of z = -1.96 and z = 1.96 separate the bottom 2.5% and \nthe top 2.5%, as shown in Figure 6-10.\n\n228 \nCHAPTER 6 Normal Probability Distributions\nCritical Values For a normal distribution, a critical value is a z score on the bor-\nderline separating those z scores that are significantly low or significantly high. Com-\nmon critical values are z = -1.96 and z = 1.96, and they are obtained as shown in \nExample 7. In Example 7, values of z = -1.96 or lower are significantly low because \nonly 2.5% of the population have scores at or below -1.96, and the values at or above \nz = 1.96 are significantly high because only 2.5% of the population have scores at or \nabove 1.96. Critical values will become extremely important in subsequent chapters. \nThe following notation is used for critical z values found by using the standard normal \ndistribution.\nDEFINITION \nFor the standard normal distribution, a critical value is a z score on the borderline \nseparating those z scores that are significantly low or significantly high.\nCAUTION When finding a value of za for a particular value of a, note that a is the \narea to the right of za, but Table A-2 and some technologies give cumulative areas \nto the left of a given z score. To find the value of za, resolve that conflict by using \nthe value of 1 - a. For example, to find z0.1, refer to the z score with an area of 0.9 \nto its left.\nNotation \nThe expression za denotes the z score with an area of a to its right. (a is the Greek \nletter alpha.)\nEXAMPLE 8  Finding the Critical Value zA \nFind the value of z0.025. (Let a = 0.025 in the expression za.)\nSOLUTION\nThe notation of z0.025 is used to represent the z score with an area of 0.025 to its \nright. Refer to Figure 6-10 and note that the value of z = 1.96 has an area of 0.025 \nto its right, so z0.025 = 1.96. Note that z0.025 corresponds to a cumulative left area \nof 0.975.\nExamples 3 through 7 in this section are based on the real application of the bone \ndensity test, with scores that are normally distributed with a mean of 0 and standard \ndeviation of 1, so that these scores have a standard normal distribution. Apart from \nthe bone density test scores, it is rare to find such convenient parameters, because \ntypical normal distributions have means different from 0 and standard deviations dif-\nferent from 1. In the next section we present methods for working with such normal \ndistributions.\nFinding z Scores>Areas (Standard Normal)\nAccess tech instructions, videos, and data sets at www.TriolaStats.com\nTECH CENTER \n\n6-1 The Standard Normal Distribution \n229\n5. Greater than 3.00 minutes. \n6. Less than 4.00 minutes.\n7. Between 2 minutes and 3 minutes. \n8. Between 2.5 minutes and 4.5 minutes.\nStandard Normal Distribution. In Exercises 9–12, find the area of the shaded region. \nThe graph depicts the standard normal distribution of bone density scores with mean 0 and \nstandard deviation 1.\n9. \nz 5 0.44\n \n10. \nz 5 21.04\n11. \nz 5 20.84\nz 5 1.28\n \n12. \nz 5 21.07\nz 5 0.67\nStatistical Literacy and Critical Thinking\n1. Normal Distribution What’s wrong with the following statement? “Because the digits 0, 1, \n2, . . . , 9 are the normal results from lottery drawings, such randomly selected numbers have a \nnormal distribution.”\n2. Normal Distribution A normal distribution is informally described as a probability dis-\ntribution that is “bell-shaped” when graphed. Draw a rough sketch of a curve having the bell \nshape that is characteristic of a normal distribution.\n3. Standard Normal Distribution Identify the two requirements necessary for a normal dis-\ntribution to be a standard normal distribution.\n4. Notation What does the notation za indicate?\nContinuous Uniform Distribution. In Exercises 5–8, refer to the continuous uniform \ndistribution depicted in Figure 6-2 and described in Example 1. Assume that a patient is \nrandomly selected, and find the probability that the waiting time is within the given range.\n6-1 Basic Skills and Concepts \n0\n0.2\n1\n2\nArea 5 1\n3\n4\n5\nx (waiting time in minutes)\nP(x)\nFIGURE 6-2  Uniform Distribution of  \nWaiting Time\n\n230 \nCHAPTER 6 Normal Probability Distributions\nStandard Normal Distribution. In Exercises 13–16, find the indicated z score. The \ngraph depicts the standard normal distribution of bone density scores with mean 0 and \n standard deviation 1.\n13. \n0\n0.8907\nz\n \n14. \nz 0\n0.3050\n15. \nz\n0\n0.9265\n \n16. \nz\n0\n0.2061\nStandard Normal Distribution. In Exercises 17–36, assume that a randomly selected \nsubject is given a bone density test. Those test scores are normally distributed with a mean \nof 0 and a standard deviation of 1. In each case, draw a graph, then find the probability of \nthe given bone density test scores. If using technology instead of Table A-2, round answers \nto four decimal places.\n17. Less than -1.23. \n18. Less than -1.96.\n19. Less than 1.28. \n20. Less than 2.56.\n21. Greater than 0.25. \n22. Greater than 0.18.\n23. Greater than -2.00. \n24. Greater than –3.05.\n25. Between 2.00 and 3.00. \n26. Between 1.50 and 2.50.\n27. Between and -2.55 and -2.00. \n28. Between -2.75 and –0.75.\n29. Between -2.00 and 2.00. \n30. Between -3.00 and 3.00.\n31. Between -1.00 and 5.00. \n32. Between -4.27 and 2.34.\n33. Less than 4.55. \n34. Greater than -3.75.\n35. Greater than 0. \n36. Less than 0.\nFinding Bone Density Scores. In Exercises 37–40 assume that a randomly selected sub-\nject is given a bone density test. Bone density test scores are normally distributed with a mean \nof 0 and a standard deviation of 1. In each case, draw a graph, and then find the bone den-\nsity test score corresponding to the given information. Round results to two decimal places.\n37. Find P99, the 99th percentile. This is the bone density score separating the bottom 99% \nfrom the top 1%.\n38. Find P10, the 10th percentile. This is the bone density score separating the bottom 10% \nfrom the top 90%.\n39. If bone density scores in the bottom 2% and the top 2% are used as cutoff points for levels \nthat are too low or too high, find the two readings that are cutoff values.\n40. Find the bone density scores that can be used as cutoff values separating the lowest 3% and \nhighest 3%.\n\n6-2 Real Applications of Normal Distributions \n231\nCritical Values. In Exercises 41–44, find the indicated critical value. Round results to two \ndecimal places.\n41. z0.10    42. z0.02    43. z0.04    44. z0.15\nBasis for the Range Rule of Thumb and the Empirical Rule. In Exercises 45–48, find \nthe indicated area under the curve of the standard normal distribution; then convert it to a \npercentage and fill in the blank. The results form the basis for the range rule of thumb and \nthe empirical rule introduced in Section 3-2.\n45. About t \n % of the area is between z = -1 and z = 1 (or within 1 standard devia-\ntion of the mean).\n46. About % of the area is between z = -2 and z = 2 (or within 2 standard deviations of the \nmean).\n47. About % \n of the area is between z = -3 and z = 3 (or within 3 standard devia-\ntions of the mean).\n48. About %  \n of the area is between z = -3.5 and z = 3.5 (or within 3.5 standard \ndeviations of the mean).\n49. Significance For bone density scores that are normally distributed with a mean of 0 and a \nstandard deviation of 1, find the percentage of scores that are\na. significantly high (or at least 2 standard deviations above the mean).\nb. significantly low (or at least 2 standard deviations below the mean).\nc. not significant (or less than 2 standard deviations away from the mean).\n50. Distributions In a continuous uniform distribution,\nm = minimum +  \n maximum\n2\n and s = range\n212\na. Find the mean and standard deviation for the distribution of the waiting times represented in \nFigure 6-2, which accompanies Exercises 5–8.\nb. For a continuous uniform distribution with m = 0 and s = 1, the minimum is - 23 and \nthe maximum is 23. For this continuous uniform distribution, find the probability of randomly \nselecting a value between -1 and 1, and compare it to the value that would be obtained by in-\ncorrectly treating the distribution as a standard normal distribution. Does the distribution affect \nthe results very much?\n6-1 Beyond the Basics \nKey Concept Now we really get real as we extend the methods of the previous section \nso that we can work with any nonstandard normal distribution (with a mean different \nfrom 0 and>or a standard deviation different from 1). The key is a simple conversion \n(Formula 6-2) that allows us to “standardize” any normal distribution so that x values \ncan be transformed to z scores; then the methods of the preceding section can be used.\n6-2 \nReal Applications of Normal Distributions\n\n232 \nCHAPTER 6 Normal Probability Distributions\nFORMULA 6-2\nz = x - m\ns\n  (round z scores to 2 decimal places)\nFigure 6-11 illustrates the conversion from a nonstandard to a standard normal \ndistribution. The area in any normal distribution bounded by some score x (as in \nFigure 6-11a) is the same as the area bounded by the corresponding z score in the \nstandard normal distribution (as in Figure 6-11b).\nx\nm\nm\ns\nz 5 x 2\nz\nP\nP\n0\n(b) Standard\n \nNormal Distribution\n(a) Nonstandard\n \nNormal Distribution\nFIGURE 6-11 Converting Distributions\nSome calculators and software do not require the use of Formula 6-2 to convert to \nz scores because probabilities can be found directly. However, if using Table A-2, we \nmust first convert values to standard z scores.\nWhen finding areas with a nonstandard normal distribution, use the following \nprocedure.\nProcedure for Finding Areas with a Nonstandard Normal Distribution\n1. Sketch a normal curve, label the mean and any specific x values, and then shade \nthe region representing the desired probability.\n2. For each relevant value x that is a boundary for the shaded region, use Formula 6-2 \nto convert that value to the equivalent z score. (With many technologies, this step \ncan be skipped.)\n3. Use technology (software or a calculator) or Table A-2 to find the area of \nthe shaded region. This area is the desired probability.\nThe following example illustrates the above procedure.\nEXAMPLE 1   What Is the Proportion of Adult Males with Pulse \nRates Greater Than 100 Bpm?\nIn the Chapter Problem we noted that pulse rates of adult males are normally dis-\ntributed with a mean of 69.6 bpm and a standard deviation of 11.3 bpm. Find the \nproportion of adult males with a pulse rate greater than 100 bpm. These males are \nconsidered to be at a high risk of stroke, heart disease, or cardiac death.\nSOLUTION\nStep 1: See Figure 6-12, which incorporates this information: Men have pulse rates \nthat are normally distributed with a mean of 69.6 bpm and a standard deviation of \n11.3 bpm. The shaded region represents the men with pulse rates above 100 bpm.\n\n6-2 Real Applications of Normal Distributions \n233\n \n0.0036\n100\nm 5 69.6\nx (pulse rate)\nz 5 0\nz 5 2.69\nz scale\nFIGURE 6-12 Pulse Rates of Men\nStep 2: We can convert a pulse rate of 100 bpm to the z score of 2.69 by using \n Formula 6-2 as follows:\nz = x - m\ns\n= 100 - 69.6\n11.3\n= 2.69 1rounded to two decimal places2\nStep 3: Technology: Technology can be used to find that the area to the right \nof 100 bpm in Figure 6-12 is 0.0036. (With many technologies, Step 2 can be \nskipped.)\nTable A-2: Use Table A-2 to find that the cumulative area to the left of z = 2.69 \nis 0.9964. (Remember, Table A-2 is designed so that all areas are cumulative areas \nfrom the left.) Because the total area under the curve is 1, it follows that the shaded \narea in Figure 6-12 is 1 - 0.9964 = 0.0036.\nINTERPRETATION\nThe proportion of men with pulse rates above 100 bpm is 0.0036, which is roughly \n4 men in a thousand. This is a very rare event, so an adult male presenting with a \npulse rate above 100 bpm is extremely rare, or there is some medical condition that \nis causing the high pulse rate.\nEXAMPLE 2  Normal Pulse Rates\nNormal pulse rates are generally considered to be between 60 bpm and 100 bpm.\nGiven that pulse rates of adult males are normally distributed with a mean of \n69.6 bpm and a standard deviation of 11.3 bpm, find the percentage of males with \nnormal pulse rates.\nSOLUTION\nFigure 6-13 shows the shaded region representing men with pulse rates between \n60 bpm and 100 bpm.\nStep 1: See Figure 6-13 on the next page, which incorporates this information:  \nMen have pulse rates that are normally distributed with a mean of 69.6 bpm and a \nstandard deviation of 11.3 bpm. The shaded region represents the men with pulse \nrates between 60 bpm and 100 bpm.\ncontinued\nHigh Cost of Low Quality\nThe Federal \nDrug Adminis-\ntration recently \nreached an \nagreement \nwhereby a \npharmaceutical \ncompany, the Schering-Plough \nCorporation, would pay a record \n$500 million for failure to cor-\nrect problems in manufactur-\ning drugs. According to a New \nYork Times article by Melody \nPetersen, “Some of the problems \nrelate to the lack of controls that \nwould identify faulty medicines, \nwhile others stem from outdated \nequipment. They involve some \n200 medicines, including Claritin, \nthe allergy medicine that is \nSchering’s top-selling product.”\nh\ni\nPl\nh\n\n234 \nCHAPTER 6 Normal Probability Distributions\nStep 2: With some technologies, the shaded area in Figure 6-13 can be found \n directly and it is not necessary to convert the x scores of 60 bpm and 100 bpm to  \nz scores. (See Step 3.)\nIf using Table A-2, we cannot find the shaded area directly, but we can find it \nindirectly by using the same procedures from Section 6-1, as follows: (1) Find the \ncumulative area from the left up to 100 bpm (or z = 2.69); (2) find the cumulative \narea from the left up to 60 bpm (or z = -0.85); (3) find the difference between \nthose two areas. The pulse rates of 100 bpm and 60 bpm are converted to z scores \nby using Formula 6-2 as follows:\nFor x = 100 bpm: z = x - m\ns\n= 100 - 69.6\n11.3\n= 2.69 \n1z = 2.69 yields an area of 0.9964.2\nFor x = 60 bpm: z = x - m\n11.3\n= 60 - 69.6\n11.3\n= -0.85\n1z = -0.85 yields an area of 0.1977.2\nStep 3: Technology: Technology will show that the shaded area in Figure 6-13 is \n0.7986.\nTable A-2: Refer to Table A-2 with z = 2.69 and find that the cumulative area to \nthe left of z = 2.69 is 0.9964. (Remember, Table A-2 is designed so that all areas \nare cumulative areas from the left.) Table A-2 also shows that z = -0.85 corre-\nsponds to an area of 0.1977. Because the areas of 0.9964 and 0.1977 are cumulative \nareas from the left, we find the shaded area in Figure 6-13 as follows:\nShaded area in Figure 6@13 = 0.9964 - 0.1977 = 0.7987\nThere is a small discrepancy between the area of 0.7986 found from technology \nand the area of 0.7987 found from Table A-2. The area obtained from technology \nis more accurate because it is based on unrounded z scores, whereas Table A-2 \nrequires z scores rounded to two decimal places.\nINTERPRETATION\nExpressing the result as a percentage, we conclude that about 80% of men have \npulse rates between 60 bpm and 100 bpm.\n 0.7986\n100\n60\nm 5 69.6\nx (pulse rate)\nz 5 0\nz 5 2.69\nz 5 20.85\nz scale\nFIGURE 6-13 Pulse Rates of Men\n\n6-2 Real Applications of Normal Distributions \n235\nFinding Values from Known Areas\nHere are helpful hints for those cases in which the area (or probability or percentage) \nis known and we must find the relevant value(s):\n1. Graphs are extremely helpful in visualizing, understanding, and successfully \nworking with normal probability distributions, so they should always be \nused.\n2. Don’t confuse z scores and areas. Remember, z scores are distances along the \nhorizontal scale, but areas are regions under the normal curve. Table A-2 lists \nz scores in the left columns and across the top row, but areas are found in the \nbody of the table.\n3. Choose the correct (right>left) side of the graph. A value separating the top \n10% from the others will be located on the right side of the graph, but a value \nseparating the bottom 10% will be located on the left side of the graph.\n4. A z score must be negative whenever it is located in the left half of the normal \ndistribution.\n5. Areas (or probabilities) are always between 0 and 1, and they are never \nnegative.\nProcedure for Finding Values from Known Areas or Probabilities\n1. Sketch a normal distribution curve, write the given probability or percent-\nage in the appropriate region of the graph, and identify the x value(s) being \nsought.\n2. Use technology. If technology is not available, use Table A-2 by referring to \nthe body of Table A-2 to find the area to the left of x; then identify the z score \ncorresponding to that area.\n3. If you know z and must convert to the equivalent x value, use Formula 6-2 by \nentering the values for m, s, and the z score found in Step 2; then solve for x. \nBased on Formula 6-2, we can solve for x as follows:\nx = m + 1z # s2  \n1another form of Formula 6@22\nc\n(If z is located to the left of the mean, be sure that it is a negative number.)\n4. Refer to the sketch of the curve to verify that the solution makes sense in \nthe context of the graph and in the context of the problem.\nThe following example uses this procedure for finding a value from a known area.\nEXAMPLE 3  Pulse Rates\nGiven that pulse rates of adult males are normally distributed with a mean of \n69.6 bpm and a standard deviation of 11.3 bpm, find the pulse rate that separates the \nhighest 1% from the lowest 99%. That is, find P99.\nSOLUTION\nStep 1: Figure 6-14 on the next page shows the normal distribution with the pulse \nrate x that we want to identify. The shaded area represents the lowest 99% of the \npulse rates.\ncontinued\n\n236 \nCHAPTER 6 Normal Probability Distributions\nTable A-2: If using Table A-2, search for an area of 0.9900 in the body of the table. \nThe area of 0.9900 corresponds to z = 2.33.\nStep 3: With z = 2.33, m = 69.6 bpm, and s = 11.3 bpm, we can solve for x by us-\ning Formula 6-2:\nz = x - m\ns  becomes 2.33 = x - 69.6\n11.3\nThe result of x = 95.929 bpm can be found directly or by using the following ver-\nsion of Formula 6-2:\nx = m + 1z # s2 = 69.6 + 12.33 # 11.32 = 95.929 bpm\nStep 4: The solution of x = 95.9 bpm (rounded) in Figure 6-14 is reasonable be-\ncause it is greater than the mean of 69.6 bpm.\nINTERPRETATION\nThe male pulse rate of 95.9 (rounded) separates the top 1% from the bottom 99%.\n \n0.99\nx 5 ?\nm 5 69.6\nx (pulse rate)\nz 5 0\nz 5 2.83\nz scale\nFIGURE 6-14 Finding the 99th Percentile\nStep 2: Technology: Technology will provide the value of x in Figure 6-14. For \nexample, see the accompanying Excel display showing that x = 95.88773098 bpm, \nor 95.9 bpm when rounded.\n Excel\nSignificance\nIn Chapter 4 we saw that probabilities can be used to determine whether values are \nsignificantly high or significantly low. Chapter 4 referred to x successes among n tri-\nals, but we can adapt those criteria to apply to continuous variables as follows:\nSigniﬁcantly high: The value x is signiﬁcantly high if P(x or greater) … 0.05.*\nSigniﬁcantly low: The value x is signiﬁcantly low if P(x or less) … 0.05.*\n*The value of 0.05 is not absolutely rigid, and other values such as 0.01 could be used instead.\n\n6-2 Real Applications of Normal Distributions \n237\nStep 2: Technology: Technology will show that the values of x in Figure 6-15 are \n53.4 beats per minute and 94.6 beats per minute when rounded.\nTable A-2: If using Table A-2, we must work with cumulative areas from the left. \nFor the leftmost value of x, the cumulative area from the left is 0.05, so search for \nan area of 0.05 in the body of the table to get z = -1.645 (identified by the aster-\nisk between 0.0505 and 0.0495). For the rightmost value of x, the cumulative area \nfrom the left is 0.95, so search for an area of 0.9500 in the body of the table to get \nz = 1.645 (identified by the asterisk between 0.9495 and 0.9505). Having found \nthe two z scores, we now proceed to convert them to pulse rates.\nStep 3: We now solve for the two values of x by using Formula 6-2 directly or by \nusing the following version of Formula 6-2:\nLeftmost value of x:  \nx = m + 1z # s2 = 74.0 + 1-1.645 # 12.52 = 53.4\nRightmost value of x: x = m + 1z # s2 = 74.0 + 11.645 # 12.52 = 94.6\nStep 4: Referring to Figure 6-15, we see that the leftmost value of x = 53.4 is rea-\nsonable because it is less than the mean of 74.0. Also, the rightmost value of 94.6 is \nreasonable because it is above the mean of 74.0.\nINTERPRETATION\nHere are the pulse rates of women that are significant:\n \n■Significantly low: 53.4 beats per minute or lower\n \n■Significantly high: 94.6 beats per minute or higher\nPhysicians could use these results to investigate health issues that could cause pulse \nrates to be significantly low or significantly high.\n0.05\nx 5 ?\nx 5 ?\nm 5 74.0\n0.05\nFIGURE 6-15 Pulse Rates of Women\nEXAMPLE 4   Significantly Low or Significantly High Female \nPulse Rates\nUse the preceding criteria to identify pulse rates of women that are significantly low \nor significantly high. Based on Data Set 1 “Body Data” in Appendix B, assume that \nwomen have normally distributed pulse rates with a mean of 74.0 beats per minute \nand a standard deviation of 12.5 beats per minute.\nSOLUTION\nStep 1: We begin with the graph shown in Figure 6-15. We have entered the mean of \n74.0, and we have identified the x values separating the lowest 5% and the highest 5%.\n\n238 \nCHAPTER 6 Normal Probability Distributions\nFinding x Values>Areas\nAccess tech instructions, videos, and data sets at www.TriolaStats.com\nTECH CENTER \nStatistical Literacy and Critical Thinking \n1. Birth Weights Based on Data Set 3 “Births” in Appendix B, birth weights are normally \ndistributed with a mean of 3152.0 g and a standard deviation of 693.4 g.\na. What are the values of the mean and standard deviation after converting all birth weights to \nz scores using z = 1x - m2>s?\nb. The original birth weights are in grams. What are the units of the corresponding z scores?\n2. Birth Weights Based on Data Set 3 “Births” in Appendix B, birth weights are normally \ndistributed with a mean of 3152.0 g and a standard deviation of 693.4 g.\na. For the bell-shaped graph, what is the area under the curve?\nb. What is the value of the median?\nc. What is the value of the mode?\nd. What is the value of the variance?\n3. Normal Distributions What is the difference between a standard normal distribution and a \nnonstandard normal distribution?\n4. Random Digits Computers are commonly used to randomly generate digits of telephone \nnumbers to be called when conducting the California Health Survey. Can the methods of this \nsection be used to find the probability that when one digit is randomly generated, it is less than \n3? Why or why not? What is the probability of getting a digit less than 3?\nIQ Scores. In Exercises 5–8, find the area of the shaded region. The graphs depict IQ \nscores of adults, and those scores are normally distributed with a mean of 100 and a stan-\ndard deviation of 15 (as on the Wechsler IQ test).\n5. \n118\n \n6. \n91\n7. \n79\n133\n \n8. \n124\n112\n6-2 Basic Skills and Concepts\n\n6-2 Real Applications of Normal Distributions \n239\nIQ Scores. In Exercises 9–12, find the indicated IQ score and round to the nearest whole \nnumber. The graphs depict IQ scores of adults, and those scores are normally distributed \nwith a mean of 100 and a standard deviation of 15 (as on the Wechsler IQ test).\n9. \nx\n0.9918\n \n10. \nx\n0.1587\n11. \nx\n0.9798\n \n12. \nx\n0.9099\nFemale Pulse Rates. In Exercises 13–20, assume that an adult female is randomly \n selected. Females have pulse rates that are normally distributed with a mean of 74.0 beats \nper minute and a standard deviation of 12.5 beats per minute (based on Data Set 1 “Body \nData” in Appendix B). (Hint: Draw a graph in each case.)\n13. Find the probability of a pulse rate less than 100 beats per minute.\n14. Find the probability of a pulse rate greater than 80 beats per minute.\n15. Find the probability of a pulse rate between 60 beats per minute and 70 beats per minute.\n16. Find the probability of a pulse rate between 70 beats per minute and 90 beats per minute.\n17. Find P90, which is the pulse rate separating the bottom 90% from the top 10%.\n18.  Find the first quartile Q1, which is the pulse rate separating the bottom 25% from the \ntop 75%.\n19. Significance Instead of using 0.05 for identifying significant values, use the criteria \nthat a value x is significantly high if P(x or greater) … 0.01 and a value is significantly low \nif P(x or less) … 0.01. Find the pulse rates separating significant values from those that are \nnot significant. Using these criteria, is a pulse rate of 102 beats per minute significantly high?\n20. Significance Instead of using 0.05 for identifying significant values, use the criteria \nthat a value x is significantly high if P(x or greater) … 0.025 and a value is significantly low \nif P(x or less) … 0.025. Find the pulse rates separating significant values from those that are \nnot significant. Using these criteria, is a pulse rate of 48 beats per minute significantly low?\n21. Eye Contact In a study of facial behavior, people in a control group are timed for eye con-\ntact in a 5-minute period. Their times are normally distributed with a mean of 184.0  seconds \nand a standard deviation of 55.0 seconds (based on data from “Ethological Study of Facial \n Behavior in Nonparanoid and Paranoid Schizophrenic Patients,” by Pittman, Olk, Orr, and \nSingh, Psychiatry, Vol. 144, No. 1). For a randomly selected person from the control group, \nfind the probability that the eye contact time is greater than 230.0 seconds, which is the mean \nfor paranoid schizophrenics. Based on personal experience, does the result appear to be the \nproportion of people who are paranoid schizophrenics?\n\n240 \nCHAPTER 6 Normal Probability Distributions\n22. Body Temperatures Based on sample results in Data Set 2 “Body Temperatures” in \nAppendix B, assume that human body temperatures are normally distributed with a mean of \n98.20°F and a standard deviation of 0.62°F.\na. According to emedicinehealth.com, a body temperature of 100.4oF or above is considered \nto be a fever. What percentage of normal and healthy persons would be considered to have a \nfever? Does this percentage suggest that a cutoff of 100.4oF is appropriate?\nb. Physicians want to select a minimum temperature for requiring further medical tests. What \nshould that temperature be if we want only 2.0% of healthy people to exceed it? (Such a result \nis a false positive, meaning that the test result is positive, but the subject is not really sick.)\n23.  Low Birth Weight The University of Maryland Medical Center considers “low birth \nweights” to be those less than 5.5 lb or 2495 g. Birth weights are normally distributed with a mean \nof 3152.0 g and a standard deviation of 693.4 g (based on Data Set 3 “Births” in Appendix B).\na. If a birth weight is randomly selected, what is the probability that it is a “low birth weight”?\nb. Find the weights considered to be significantly low using the criterion of a probability of \n0.05 or less. How do these results compare to the criterion of 2495 g?\nc. Compare the results from parts (a) and (b).\n24. Durations of Pregnancies The lengths of pregnancies are normally distributed with a \nmean of 268 days and a standard deviation of 15 days.\na. In a letter to “Dear Abby,” a wife claimed to have given birth 308 days after a brief visit from \nher husband, who was working in another country. Find the probability of a pregnancy lasting \n308 days or longer. What does the result suggest?\nb. If we stipulate that a baby is premature if the duration of pregnancy is in the lowest 3%, \nfind the duration that separates premature babies from those who are not premature. Premature \nbabies often require special care, and this result could be helpful to hospital administrators in \nplanning for that care.\nLarge Data Sets. In Exercises 25 and 26, refer to the data sets in Appendix B and use \nsoftware or a calculator.\n25. Diastolic Blood Pressure of Males Refer to Data Set 1 in Appendix B and use the \ndiastolic blood pressures of males.\na. Find the mean and standard deviation, and verify that the data have a distribution that is \nroughly normal. Round the results using three decimal places.\nb. Treating the unrounded values of the mean and standard deviation as parameters, and assum-\ning that male diastolic blood pressures are normally distributed, find diastolic blood pressures \nseparating the lowest 2.5% and the highest 2.5%. These values could be helpful when physi-\ncians try to determine whether diastolic blood pressures are significantly low or significantly \nhigh.\n26.  Diastolic Blood Pressure of Females Repeat the preceding exercise using females \ninstead of males.\n27. Outliers For the purposes of constructing modified boxplots as described in Section 3-3, \noutliers are defined as data values that are above Q3 by an amount greater than 1.5 *  IQR or \nbelow Q1 by an amount greater than 1.5 *  IQR, where IQR is the interquartile range. Using \nthis definition of outliers, find the probability that when a value is randomly selected from a \nnormal distribution, it is an outlier.\n6-2 Beyond the Basics\n\n6-3 Sampling Distributions and Estimators \n241\nA Short Story Among the population of all adults, exactly 40% have brown eyes (the \nauthors just know this). In a survey of 1000 adults, 42% of the subjects were observed \nto have brown eyes. Being so intrigued by this, 50,000 people became so enthusias-\ntic that they each conducted their own individual survey of 1000 randomly selected \nadults. Each of these 50,000 new surveyors reported the percentage that they found, \nwith results such as 38%, 39%, and 43%. The authors obtained each of the 50,000 \nKey Concept We now consider the concept of a sampling distribution of a statistic. \nInstead of working with values from the original population, we want to focus on \nthe values of statistics (such as sample proportions or sample means) obtained from \nthe population. Figure 6-16 shows the key points that we need to know, so try really, \nreally hard to understand the story that Figure 6-16 tells.\n6-3 \nSampling Distributions and Estimators\nProportions\nSample 1\nSample 2\nSample 3\n(Population Proportion is p)\nDistribution of\nSample Proportions\nSample\nProportions\nSample\nSample proportions tend to\nhave a normal distribution\npˆ pˆ pˆ pˆ pˆ\npˆ pˆ pˆ\npˆ pˆ\npˆ\npˆ\npˆ\npˆ\npˆ pˆ pˆ pˆ pˆ\npˆ\np\nˆ\n•\n•\n•\n1pˆ\n2pˆ\n3pˆ\nSampling\nProcedure:\nRandomly select n\nvalues and ﬁnd\nthe proportion p for\neach sample.\nˆ\nMeans\nSample 1\nSample 2\nSample 3\n(Population Mean is m)\nDistribution of\nSample Means\nSample Means\nSample\nSample means tend to\nhave a normal distribution\n•\n•\n•\nSampling\nProcedure:\nRandomly select n\nvalues and ﬁnd\nthe mean x for\neach sample.\nx x x x x x\nx x x x\nx x x\nx x\nx\nx\nX1\nX2\nX3\nx\nx\nx\nx\nx\nVariances\nSample 1\nSample 2\nSample 3\n(Population Variance is s2)\nDistribution of\nSample Variances\nSample\nVariances\nSample\nSample variances tend to\nhave a skewed distribution\n•\n•\n•\nSampling\nProcedure:\nRandomly select n\nvalues and ﬁnd\nthe variance s2 for\neach sample.\ns2\n1\ns2\n2\ns2\n3\ns2\ns2 s2\ns2 s2 s2\ns2s2s2s2s2s2\ns2s2s2s2s2s2\ns2 s2 s2 s2\ns2s2s2s2s2\nFIGURE 6-16 General Behavior of Sampling Distributions\ncontinued\n\n242 \nCHAPTER 6 Normal Probability Distributions\nsample percentages, changed them to proportions, and then they constructed the his-\ntogram shown in Figure 6-17. Notice anything about the shape of the histogram? It’s \nnormal. Notice anything about the mean of the sample proportions? They are centered \nabout the value of 0.40, which happens to be the population proportion. Moral: When \nsamples of the same size are taken from the same population, the following two prop-\nerties apply:\n1. Sample proportions tend to be normally distributed.\n2. The mean of sample proportions is the same as the population mean.The \nimplications of the preceding properties will be extensive in the chapters \nthat follow.\nFIGURE 6-17 Histogram of 50,000 Sample Proportions\nLet’s formally define sampling distribution, the main character in the preceding short \nstory.\nDEFINITION\nThe sampling distribution of a statistic (such as a sample proportion or sample \nmean) is the distribution of all values of the statistic when all possible samples of \nthe same size n are taken from the same population. (The sampling distribution of a \nstatistic is typically represented as a probability distribution in the format of a prob-\nability histogram, formula, or table.)\nSampling Distribution of Sample Proportion\nThe preceding general definition of a sampling distribution of a statistic can now be \nrestated for the specific case of a sample proportion:\nDEFINITION\nThe sampling distribution of the sample proportion is the distribution of sample \nproportions (or the distribution of the variable pn), with all samples having the same \nsample size n taken from the same population. (The sampling distribution of the \nsample proportion is typically represented as a probability distribution in the format \nof a probability histogram, formula, or table.)\nWe need to distinguish between a population proportion p and a sample proportion, \nand the following notation is common and will be used throughout the remainder of \nthis book, so it’s very important.\n\n6-3 Sampling Distributions and Estimators \n243\nNotation for Proportions\np = population proportion\npn = sample proportion\nHINT pn is pronounced “p-hat.” When symbols are used above a letter, as in x and \npn, they represent statistics, not parameters.\nBehavior of Sample Proportions\n1. The distribution of sample proportions tends to approximate a normal distribution.\n2. Sample proportions target the value of the population proportion in the \nsense that the mean of all of the sample proportions pn is equal to the popu-\nlation proportion p; the expected value of the sample proportion is equal to \nthe population proportion.\nEXAMPLE 1  Sampling Distribution of the Sample Proportion\nConsider repeating this process: Roll a die 5 times and find the proportion of odd \nnumbers (1 or 3 or 5). What do we know about the behavior of all sample propor-\ntions that are generated as this process continues indefinitely?\nSOLUTION\nFigure 6-18 illustrates a process of rolling a die 5 times and finding the proportion of \nodd numbers. (Figure 6-18 shows results from repeating this process 10,000 times, \nbut the true sampling distribution of the sample proportion involves repeating the \nprocess indefinitely.) Figure 6-18 shows that the sample proportions are approxi-\nmately normally distributed. (Because the values of 1, 2, 3, 4, 5, 6 are all equally \nlikely, the proportion of odd numbers in the population is 0.5, and Figure 6-18 shows \nthat the sample proportions have a mean of 0.50.)\nProportions\nSample 1\nSample 2\nSample 3\n(Population Proportion is p 5 0.5)\nDistribution of\nSample Proportions\nSample\nProportions\nSample\np 5 0.5\nSample proportions are\napproximately normal\n•\n•\n•\n0.2\n0.4\n0.8\nSampling Procedure:\nRoll a die 5 times and\nﬁnd the proportion p\nof odd numbers for\neach sample.\nˆ\nFIGURE 6-18 Sample Proportions from 10,000 Trials\n\n244 \nCHAPTER 6 Normal Probability Distributions\nBehavior of Sample Means\n1. The distribution of sample means tends to be a normal distribution. (This will \nbe discussed further in the following section, but the distribution tends to be-\ncome closer to a normal distribution as the sample size increases.)\n2. The sample means target the value of the population mean. (That is, the \nmean of the sample means is the population mean. The expected value of \nthe sample mean is equal to the population mean.)\nDEFINITION\nThe sampling distribution of the sample mean is the distribution of all possible \nsample means (or the distribution of the variable x), with all samples having the \nsame sample size n taken from the same population. (The sampling distribution of \nthe sample mean is typically represented as a probability distribution in the format \nof a probability histogram, formula, or table.)\nEXAMPLE 2  Sampling Distribution of the Sample Mean\nA pediatrician has three patients with measles and they are ages 4, 5, and 9.  \nConsider the population of {4, 5, 9}. If two ages are randomly selected with replace-\nment from the population {4, 5, 9}, identify the sampling distribution of the sample \nmean by creating a table representing the probability distribution of the sample mean. \nDo the values of the sample mean target the value of the population mean?\nSOLUTION\nIf two values are randomly selected with replacement from the population {4, 5, 9}, \nthe leftmost column of Table 6-2 lists the nine different possible samples. The second \ncolumn lists the corresponding sample means. The nine samples are equally likely \nwith a probability of 1>9. We saw in Section 5-1 that a probability distribution gives \nthe probability for each value of a random variable, as in the second and third col-\numns of Table 6-2. The second and third columns of Table 6-2 represent the sampling \ndistribution of the sample mean. In Table 6-2, some of the sample mean values are \nrepeated, so we combined them in Table 6-3.\nTABLE 6-2 Sampling Distribution  \nof Mean\nSample\nSample Mean x\nProbability\n4, 4\n4.0\n1>9\n4, 5\n4.5\n1>9\n4, 9\n6.5\n1>9\n5, 4\n4.5\n1>9\n5, 5\n5.0\n1>9\n5, 9\n7.0\n1>9\n9, 4\n6.5\n1>9\n9, 5\n7.0\n1>9\n9, 9\n9.0\n1>9\nTABLE 6-3 Sampling Distribution \nof Mean (Condensed)\nSample Mean x\nProbability\n4.0\n1>9\n4.5\n2>9\n5.0\n1>9\n6.5\n2>9\n7.0\n2>9\n9.0\n1>9\nSampling Distribution of the Sample Mean\nWe now consider sample means.\n\n6-3 Sampling Distributions and Estimators \n245\nIf we were to create a probability histogram from Table 6-2, it would not have \nthe bell shape that is characteristic of a normal distribution, but that’s because we are \nworking with such small samples. If the population of {4, 5, 9} were much larger \nand if we were selecting samples much larger than n = 2, as in this example, we \nwould get a probability histogram that is much closer to being bell-shaped, indicat-\ning a normal distribution, as in Example 3.\nINTERPRETATION\nBecause Table 6-3 lists the possible values of the sample mean along with their cor-\nresponding probabilities, Table 6-3 is an example of a sampling distribution of a \nsample mean.\nThe value of the mean of the population {4, 5, 9} is m = 6.0. Using either \nTable 6-2 or 6-3, we could calculate the mean of the sample values and we get 6.0. \nBecause the mean of the sample means (6.0) is equal to the mean of the population \n(6.0), we conclude that the values of the sample mean do target the value of the \npopulation mean. It’s unfortunate that this sounds so much like doublespeak, but \nthis illustrates that the mean of the sample means is equal to the population mean m.\nHINT Read the last sentence of the above paragraph a few times until it makes sense.\nEXAMPLE 3  Sampling Distribution of the Sample Mean\nConsider repeating this process: Roll a die 5 times to randomly select 5 values from \nthe population {1, 2, 3, 4, 5, 6}, then find the mean x of the results. What do we \nknow about the behavior of all sample means that are generated as this process con-\ntinues indefinitely?\nSOLUTION\nFigure 6-19 illustrates a process of rolling a die 5 times and finding the mean of the \nresults. Figure 6-19 shows results from repeating this process 10,000 times, but the true \nsampling distribution of the mean involves repeating the process indefinitely. Because \nthe values of 1, 2, 3, 4, 5, 6 are all equally likely, the population has a mean of m = 3.5. \nThe 10,000 sample means included in Figure 6-19 have a mean of 3.5. If the process \nis continued indefinitely, the mean of the sample means will be 3.5. Also, Figure 6-19 \nshows that the distribution of the sample means is approximately a normal distribution.\nMeans\nSample 1\nSample 2\nSample 3\n(Population Mean is m 5 3.5)\nDistribution of\nSample Means\nSample\nMeans\nSample\nm 5 3.5\nSample means are\napproximately normal\n•\n•\n•\n3.4\n4.4\n2.8\nSampling Procedure:\nRoll a die 5 times and\nﬁnd the mean x for\neach sample.\nFIGURE 6-19 Sample Means from 10,000 Trials\n\n246 \nCHAPTER 6 Normal Probability Distributions\nSampling Distribution of the Sample Variance\nLet’s now consider the sampling distribution of sample variances.\nDEFINITION\nThe sampling distribution of the sample variance is the distribution of sample \nvariances (the variable s2), with all samples having the same sample size n taken \nfrom the same population. (The sampling distribution of the sample variance is typi-\ncally represented as a probability distribution in the format of a table, probability \nhistogram, or formula.)\nCAUTION When working with population standard deviations or variances, be \nsure to evaluate them correctly. In Section 3-2 we saw that the computations for \npopulation standard deviations or variances involve division by the population size \nN instead of n - 1, as shown here.\n Population standard deviation:  s = B\nΣ1x - m2 2\nN\n \n Population variance: \n s2 = Σ1x - m2 2\nN\nBecause the calculations are typically performed with software or calculators, be care-\nful to correctly distinguish between the variance of a sample and the variance of a \npopulation.\nBehavior of Sample Variances\n1. The distribution of sample variances tends to be a distribution skewed to the \nright.\n2. The sample variances target the value of the population variance. (That is, \nthe mean of the sample variances is the population variance. The expected \nvalue of the sample variance is equal to the population variance.)\nEXAMPLE 4  Sampling Distribution of the Sample Variance\nConsider repeating this process: Roll a die 5 times and find the variance s2 of the \nresults. What do we know about the behavior of all sample variances that are gener-\nated as this process continues indefinitely?\nSOLUTION\nFigure 6-20 illustrates a process of rolling a die 5 times and finding the variance of \nthe results. Figure 6-20 shows results from repeating this process 10,000 times, but \nthe true sampling distribution of the sample variance involves repeating the process \nindefinitely. Because the values of 1, 2, 3, 4, 5, 6 are all equally likely, the popu-\nlation has a variance of s2 = 2.9, and the 10,000 sample variances included in \nFigure 6-20 have a mean of 2.9. If the process is continued indefinitely, the mean \nof the sample variances will be 2.9. Also, Figure 6-20 shows that the distribution \nof the sample variances is a skewed distribution, not a normal distribution with its \ncharacteristic bell shape.\n\n6-3 Sampling Distributions and Estimators \n247\nEstimators: Unbiased and Biased\nThe preceding examples show that sample proportions, means, and variances tend to \ntarget the corresponding population parameters. More formally, we say that sample \nproportions, means, and variances are unbiased estimators. See the following two \ndefinitions.\nDEFINITIONS\nAn estimator is a statistic used to infer (or estimate) the value of a population \nparameter.\nAn unbiased estimator is a statistic that targets the value of the corresponding \npopulation parameter in the sense that the sampling distribution of the statistic has \na mean that is equal to the corresponding population parameter.\nUnbiased Estimators These statistics are unbiased estimators. That is, they each \ntarget the value of the corresponding population parameter (with a sampling distribu-\ntion having a mean equal to the population parameter):\n \n■Proportion pn\n \n■Mean x\n \n■Variance s2\nBiased Estimators These statistics are biased estimators. That is, they do not target \nthe value of the corresponding population parameter:\n \n■Median\n \n■Range\n \n■Standard deviation s\nImportant Note: The sample standard deviations do not target the population \nstandard deviation s, but the bias is relatively small in large samples, so  \ns is often used to estimate S even though s is a biased estimator of s.\nVariances\nSample 1\nSample 2\nSample 3\n(Population Variance is s2 5 2.9)\nDistribution of\nSample Variances\nSample\nVariances\nSample\ns2 5 2.9\nSample variances tend to\nhave a skewed distribution\n•\n•\n•\n1.8\n2.3\n2.2\nSampling Procedure:\nRoll a die 5 times and\nﬁnd the variance s2\nfor each sample.\nFIGURE 6-20 Sample Variances from 10,000 Trials\n\n248 \nCHAPTER 6 Normal Probability Distributions\nb. The last two columns of Table 6-4 list the values of the range along with the \ncorresponding probabilities, so the last two columns constitute a table summa-\nrizing the probability distribution. Table 6-4 therefore describes the sampling \ndistribution of the sample range.\n \nc. The mean of the sample ranges in Table 6-4 is 20>9, or 2.2. The population of \n{4, 5, 9} has a range of 9 - 4 = 5. Because the mean of the sample ranges \n(2.2) is not equal to the population range (5), the sample ranges do not target \nthe value of the population range.\n \nd. Because the sample ranges do not target the population range, the sample \nrange is a biased estimator of the population range.\nINTERPRETATION\nBecause the sample range is a biased estimator of the population range, a sample \nrange should generally not be used to estimate the value of the population range.\nEXAMPLE 5  Sampling Distribution of the Sample Range\nAs in Example 2, consider samples of size n = 2 randomly selected from the \n population {4, 5, 9}.\n \na. List the diﬀerent possible samples along with the probability of each sample, \nthen ﬁnd the range for each sample.\n \nb. Describe the sampling distribution of the sample range in the format of a table \nsummarizing the probability distribution.\n \nc. Based on the results, do the sample ranges target the population range, which \nis 9 - 4 = 5?\n \nd. What do these results indicate about the sample range as an estimator of the \npopulation range?\nSOLUTION\na. In Table 6-4 we list the nine diﬀerent possible samples of size n = 2 selected \nwith replacement from the population {4, 5, 9}. The nine samples are equally \nlikely, so each has probability 1>9. Table 6-4 also shows the range for each of \nthe nine samples.\nTABLE 6-4 Sampling Distribution of Range\nSample\nSample Range\nProbability\n4, 4\n0\n1>9\n4, 5\n1\n1>9\n4, 9\n5\n1>9\n5, 4\n1\n1>9\n5, 5\n0\n1>9\n5, 9\n4\n1>9\n9, 4\n5\n1>9\n9, 5\n4\n1>9\n9, 9\n0\n1>9\n\n6-3 Sampling Distributions and Estimators \n249\nWhy Sample with Replacement? All of the examples in this section involved sam-\npling with replacement. Sampling without replacement would have the very practi-\ncal advantage of avoiding wasteful duplication whenever the same item is selected \nmore than once. Many of the statistical procedures discussed in the following chapters \nare based on the assumption that sampling is conducted with replacement because of \nthese two very important reasons:\n1. When selecting a relatively small sample from a large population, it makes no \nsignificant difference whether we sample with replacement or without replace-\nment.\n2. Sampling with replacement results in independent events that are unaf-\nfected by previous outcomes, and independent events are easier to analyze \nand result in simpler calculations and formulas.\nStatistical Literacy and Critical Thinking\n1. Births There are about 11,000 births each day in the United States, and the proportion of \nboys born in the United States is 0.512. Assume that each day, 100 births are randomly selected \nand the proportion of boys is recorded.\na. What do you know about the mean of the sample proportions?\nb. What do you know about the shape of the distribution of the sample proportions?\n2.  Sampling with Replacement The Orangetown Medical Research Center randomly se-\nlects 100 births in the United States each day, and the proportion of boys is recorded for each \nsample.\na. Do you think the births are randomly selected with replacement or without replacement?\nb. Give two reasons why statistical methods tend to be based on the assumption that sampling \nis conducted with replacement, instead of without replacement.\n3.  Unbiased Estimators Data Set 3 “Births” in Appendix B includes birth weights of \n400 babies. If we compute the values of sample statistics from that sample, which of the \nfollowing statistics are unbiased estimators of the corresponding population parameters: \nsample mean; sample median; sample range; sample variance; sample standard deviation; \nsample proportion?\n4. Sampling Distribution Data Set 3 “Births” in Appendix B includes a sample of birth \nweights. If we explore this sample of 400 birth weights by constructing a histogram and find-\ning the mean and standard deviation, do those results describe the sampling distribution of the \nmean? Why or why not?\n5.  Good Sample? A geneticist is investigating the proportion of boys born in the world \npopulation. Because she is based in China, she obtains sample data from that country. Is the \nresulting sample proportion a good estimator of the population proportion of boys born world-\nwide? Why or why not?\n6. Physicians There are about 900,000 active physicians in the United States, and they have \nannual incomes with a distribution that is skewed instead of being normal. Many different sam-\nples of 40 physicians are randomly selected, and the mean annual income is computed for each \nsample.\na. What is the approximate shape of the distribution of the sample means (uniform, normal, \nskewed, other)?\nb. What value do the sample means target? That is, what is the mean of all such sample means?\n6-3 Basic Skills and Concepts \n\n250 \nCHAPTER 6 Normal Probability Distributions\nIn Exercises 7–10, use the same population of {4, 5, 9} that was used in Examples 2 and 5. As in \nExamples 2 and 5, assume that samples of size n = 2 are randomly selected with replacement.\n7. Sampling Distribution of the Sample Variance\na. Find the value of the population variance s2.\nb. Table 6-2 describes the sampling distribution of the sample mean. Construct a similar table \nrepresenting the sampling distribution of the sample variance s2. Then combine values of s2 that \nare the same, as in Table 6-3 (Hint: See Example 2 on page 244 for Tables 6-2 and 6-3, which \ndescribe the sampling distribution of the sample mean.)\nc. Find the mean of the sampling distribution of the sample variance.\nd. Based on the preceding results, is the sample variance an unbiased estimator of the popula-\ntion variance? Why or why not?\n8. Sampling Distribution of the Sample Standard Deviation For the following, round \nresults to three decimal places.\na. Find the value of the population standard deviation s.\nb. Table 6-2 describes the sampling distribution of the sample mean. Construct a similar table \nrepresenting the sampling distribution of the sample standard deviation s. Then combine values \nof s that are the same, as in Table 6-3. (Hint: See Example 2 on page 244 for Tables 6-2 and 6-3, \nwhich describe the sampling distribution of the sample mean.)\nc. Find the mean of the sampling distribution of the sample standard deviation.\nd. Based on the preceding results, is the sample standard deviation an unbiased estimator of the \npopulation standard deviation? Why or why not?\n9. Sampling Distribution of the Sample Median\na. Find the value of the population median.\nb. Table 6-2 describes the sampling distribution of the sample mean. Construct a similar table \nrepresenting the sampling distribution of the sample median. Then combine values of the me-\ndian that are the same, as in Table 6-3. (Hint: See Example 2 on page 244 for Tables 6-2 and \n6-3, which describe the sampling distribution of the sample mean.)\nc. Find the mean of the sampling distribution of the sample median.\nd. Based on the preceding results, is the sample median an unbiased estimator of the popula-\ntion median? Why or why not?\n10. Sampling Distribution of the Sample Proportion \na. For the population, find the proportion of odd numbers.\nb. Table 6-2 describes the sampling distribution of the sample mean. Construct a similar table \nrepresenting the sampling distribution of the sample proportion of odd numbers. Then combine \nvalues of the sample proportion that are the same, as in Table 6-3. (Hint: See Example 2 on \npage 244 for Tables 6-2 and 6-3, which describe the sampling distribution of the sample mean.)\nc. Find the mean of the sampling distribution of the sample proportion of odd numbers.\nd. Based on the preceding results, is the sample proportion an unbiased estimator of the popu-\nlation proportion? Why or why not?\nIn Exercises 11–14, use the population of {34, 36, 41, 51} of the amounts of caffeine  \n(mg , 12 oz) in Coca-Cola Zero, Diet Pepsi, Dr Pepper, and Mellow Yello Zero. Assume that \nrandom samples of size n = 2 are selected with replacement.\n11. Sampling Distribution of the Sample Mean\na. After identifying the 16 different possible samples, find the mean of each sample, then \nconstruct a table representing the sampling distribution of the sample mean. In the table, \n\n6-3 Sampling Distributions and Estimators \n251\ncombine values of the sample mean that are the same. (Hint: See Table 6-3 in Example 2 on \npage 244.)\nb. Compare the mean of the population {34, 36, 41, 51} to the mean of the sampling distribu-\ntion of the sample mean.\nc. Do the sample means target the value of the population mean? In general, do sample means \nmake good estimators of population means? Why or why not?\n12. Sampling Distribution of the Median Repeat Exercise 11 using medians instead of means.\n13. Sampling Distribution of the Range Repeat Exercise 11 using ranges instead of means.\n14. Sampling Distribution of the Variance Repeat Exercise 11 using variances instead \nof means.\n15. Births: Sampling Distribution of Sample Proportion When two births are ran-\ndomly selected, the sample space for genders is bb, bg, gb, and gg (where b = boy and g =\ngirl). Assume that those four outcomes are equally likely. Construct a table that describes the \nsampling distribution of the sample proportion of girls from two births. Does the mean of the \nsample proportions equal the proportion of girls in two births? Does the result suggest that a \nsample proportion is an unbiased estimator of a population proportion?\n16. Births: Sampling Distribution of Sample Proportion For three births, assume that \nthe genders are equally likely. Construct a table that describes the sampling distribution of the \nsample proportion of girls from three births. Does the mean of the sample proportions equal the \nproportion of girls in three births? (Hint: See Exercise 15 for two births.)\n17. MCAT Tests Because they enable efficient procedures for evaluating answers, multiple choice \nquestions are commonly used on standardized tests, such as the MCAT or the GRE Biology test. \nSuch questions typically have five choices, one of which is correct. Assume that you must make \nrandom guesses for two such questions. Assume that both questions have correct answers of “a.”\na. After listing the 25 different possible samples, find the proportion of correct answers in each \nsample; then construct a table that describes the sampling distribution of the sample propor-\ntions of correct responses.\nb. Find the mean of the sampling distribution of the sample proportion.\nc. Is the mean of the sampling distribution [from part (b)] equal to the population proportion of \ncorrect responses? Does the mean of the sampling distribution of proportions always equal the \npopulation proportion?\n18. Hybridization A hybridization experiment begins with four peas having yellow pods and \none pea having a green pod. Two of the peas are randomly selected with replacement from this \npopulation.\na. After identifying the 25 different possible samples, find the proportion of peas with yellow \npods in each of them; then construct a table to describe the sampling distribution of the propor-\ntions of peas with yellow pods.\nb. Find the mean of the sampling distribution.\nc. Is the mean of the sampling distribution [from part (b)] equal to the population proportion of \npeas with yellow pods? Does the mean of the sampling distribution of proportions always equal \nthe population proportion?\n19. Using a Formula to Describe a Sampling Distribution Exercise 15 “Births” re-\nquires the construction of a table that describes the sampling distribution of the proportions of \ngirls from two births. Consider the formula shown here, and evaluate that formula using sample \n6-3 Beyond the Basics \ncontinued\n\n252 \nCHAPTER 6 Normal Probability Distributions\nproportions (represented by x) of 0, 0.5, and 1. Based on the results, does the formula describe \nthe sampling distribution? Why or why not?\nP1x2 =\n1\n212 - 2x2!12x2! where x =  0, 0.5, 1\n20. Mean Absolute Deviation Is the mean absolute deviation of a sample a good statistic for \nestimating the mean absolute deviation of the population? Why or why not? (Hint: See Example 5.)\nKey Concept In the preceding section we saw that the sampling distribution of sample \nmeans tends to be a normal distribution as the sample size increases. In this section we \nintroduce and apply the central limit theorem. The central limit theorem allows us to \nuse a normal distribution for some very meaningful and important applications.\n6-4 \nThe Central Limit Theorem\nCENTRAL LIMIT THEOREM\nFor all samples of the same size n with n 7 30, the sampling distribution of x can be \napproximated by a normal distribution with mean m and standard deviation s> 1n.\nGiven any population with any distribution (uniform, skewed, whatever), the dis-\ntribution of sample means x can be approximated by a normal distribution when the \nsamples are large enough with n 7 30. (There are some special cases of very non-\nnormal distributions for which the requirement of n 7 30 isn’t quite enough, so the \nnumber 30 should be higher in those cases, but those cases are relatively rare.)\nEXAMPLE 1  HDL Cholesterol of Females\nFigures 6-21 and 6-22 illustrate the central limit theorem.\n \n■Original data: Figure 6-21 is a histogram of the high-density lipoprotein \n(HDL) cholesterol measures (mg>dL) of the 147 females listed in Data Set \n1 “Body Data” in Appendix B, and those measures have a distribution that is \nskewed to the right instead of being normal.\n \n■Sample means: Figure 6-22 is a histogram of 100 sample means. Each sample \nincludes 100 HDL cholesterol measures of females, and this histogram shows \nthat the sample means have a distribution that is very close to being normal.\nFIGURE 6-21  Nonnormal Distribution: \nHDL Cholesterol from \n147 Women\nFIGURE 6-22  Approximately Normal \nDistribution: Means from \nSamples of Size n = 100 \nof HDL Cholesterol from \nFemales\n\n6-4 The Central Limit Theorem \n253\nA Universal Truth Example 1 and the central limit theorem are truly remarkable be-\ncause they describe a rule of nature that works throughout the universe. If we could \nsend a spaceship to a distant planet “in a galaxy far, far away,” and if we collect samples \nof rocks (all of the same large sample size) and weigh them, the sample means would \nhave a distribution that is approximately normal. Think about the significance of that!\nThe following key points form the foundation for estimating population param-\neters and hypothesis testing—topics discussed at length in the following chapters.\nINTERPRETATION\nThe original HDL cholesterol measurements depicted in Figure 6-21 have a skewed \ndistribution, but when we collect samples and compute their means, those sample \nmeans tend to have a distribution that is normal.\nThe Central Limit Theorem and the Sampling Distribution of x\nGiven\n1. Population (with any distribution) has mean m and standard deviation s.\n2. Simple random samples all of the same size n are selected from the population.\nPractical Rules for Real Applications Involving a Sample Mean x\nRequirements: Population has a normal distribution or n + 30:\nMean of all values of x: \n \n  mx = m\nStandard deviation of all values of x: \n \n \nsx =\ns\n1n\nz score conversion of x: \n \n \n  z = x - m\ns\n1n\nOriginal population is not normally distributed and n \" 30: The distribution of x might not be approximated well \nby a normal distribution, and the methods of this section might not apply. Use other methods, such as nonparametric \nmethods or bootstrapping methods (Section 7-4).\nConsiderations for Practical Problem Solving\n1. Check Requirements: When working with the mean from a sample, verify that the normal distribution can be used \nby confirming that the original population has a normal distribution or the sample size is n 7 30.\n2. Individual Value or Mean from a Sample? Determine whether you are using a normal distribution with a single \nvalue x or the mean x from a sample of n values. See the following.\n • Individual value: When working with an individual value from a normally distributed population, use the methods of \nSection 6-2 with z = x - m\ns\n.\n • Mean from a sample of values: When working with a mean for some sample of n values, be sure to use the value of \ns> 1n for the standard deviation of the sample means, so use z = x - m\ns\n1n\n.\nKEY ELEMENTS \n\n254 \nCHAPTER 6 Normal Probability Distributions\nThe following new notation is used for the mean and standard deviation of the \ndistribution of x.\nNOTATION FOR THE SAMPLING DISTRIBUTION OF x\nIf all possible simple random samples of size n are selected from a population with \nmean m and standard deviation s, the mean of all sample means is denoted by mx \nand the standard deviation of all sample means is denoted by sx.\nMean of all values of x: \nmx = m\nStandard deviation of all values of x: \nsx =\ns\n1n\nNote: sx is called the standard error of  the mean and is sometimes denoted as SEM.\nApplying the Central Limit Theorem\nMany practical problems can be solved with the central limit theorem. Example 2 \nis a good illustration of the central limit theorem because we can see the difference \nbetween working with an individual value in part (a) and working with the mean for \na sample in part (b). Study Example 2 carefully to understand the fundamental differ-\nence between the procedures used in parts (a) and (b). In particular, note that when\nworking with an individual value, we use z = x - m\ns\n, but when working with the \nmean x for a collection of sample values, we use z = x - m\ns> 1n.\nEXAMPLE 2  Pulse Rates of Women\nIn the Chapter Problem it was noted that women have normally distributed pulse \nrates with a mean of 74.0 bpm and a standard deviation of 12.5 bpm.\n \na. Find the probability that 1 randomly selected woman has a pulse rate greater \nthan 80 bpm.\n \nb. Find the probability that a sample of 16 randomly selected women have a \nmean pulse rate greater than 80 bpm.\n \nc. Given that part (b) involves a sample size that is not larger than 30, why can \nthe central limit theorem be used?\nSOLUTION\n \na. Approach Used for an Individual Value: Use the methods presented in \nSection 6-2 because we are dealing with an individual value from a nor-\nmally distributed population. We seek the area of the green-shaded region in \nFigure 6-23(a).\n \n Technology: If using technology (as described at the end of Section 6-2), we \nﬁnd that the green-shaded area in the graph at the left is 0.3156.\n \n Table A-2: If using Table A-2, we convert the pulse rate of 80 bpm to the cor-\nresponding z score, as shown here:\nz = x - m\ns\n= 80 - 74.0\n12.5\n= 0.48\n \n  \nWe refer to Table A-2 to ﬁnd that the cumulative area to the left of z = 0.48 \nis 0.6844, so the green-shaded area in Figure 6-23(a) is 1 - 0.6844 = 0.3156.\n\n6-4 The Central Limit Theorem \n255\n \nb. Approach Used for the Mean of Sample Values: Use the central limit theo-\nrem because we are dealing with the mean of a sample of 16 women, not an \nindividual woman.\n \n Requirement check for part b We can use the normal distribution if the \noriginal population is normally distributed or n 7 30. The sample size is not \ngreater than 30, but the original population of pulse rates of women has a \nnormal distribution, so samples of any size will yield means that are normally \ndistributed. \n \n  \nBecause we are now dealing with a distribution of sample means, we \nmust use the parameters mx and sx, which are evaluated as follows:\nmx = m = 74.0\nsx =\ns\n1n = 12.5\n116 = 3.125\n \n We want to ﬁnd the green-shaded area shown in Figure 6-23(b).\n \n Technology: If using technology, the green-shaded area in Figure 6-23(b) is \n0.0274.\n \n Table A-2: If using Table A-2, we convert the value of x = 80 bpm to the \ncorresponding z score of z = 1.92, as shown here:\nz = x - mx\nsx\n= 80 - 74.0\n12.5\n116\n=\n6\n3.125 = 1.92\n \n From Table A-2 we ﬁnd that the cumulative area to the left of z = 1.92 is \n0.9726, so the green-shaded area of Figure 6-23(b) is 1 - 0.9726 = 0.0274.\n \nc. Even though the sample size is not greater than 30, we can use the central \nlimit theorem because the population of pulse rates of women is normally \ncontinued\nThe Fuzzy Central  \nLimit Theorem\nIn The Cartoon \nGuide to Statis-\ntics, by Gonick \nand Smith, \nthe authors \ndescribe the \nFuzzy Central \nLimit Theorem as follows: “Data \nthat are influenced by many small \nand unrelated random effects \nare approximately normally \ndistributed. This explains why \nthe normal is everywhere: stock \nmarket fluctuations, student \nweights, yearly temperature \naverages, SAT scores: All are the \nresult of many different effects.” \nPeople’s heights, for example, \nare the results of hereditary \nfactors, environmental factors, \nnutrition, health care, geographic \nregion, and other influences, \nwhich, when combined, produce \nnormally distributed values.\nf ll\n“D\nx 5 80\n(s 5 12.5)\nm 5 74.0\nIndividual women\npulse rates\nMeans of\npulse rates\nfrom samples\nof women\n(16 in each\nsample)\nx 5 80\nmx 5 74.0\n(sx 5 3.125)\nFIGURE 6-23 Female Pulse Rates\n(a)\n(b)\n\n256 \nCHAPTER 6 Normal Probability Distributions\nExample 2 shows that we can use the same basic procedures from Section 6-2, \nbut we must remember to correctly adjust the standard deviation when working with a \nsample mean instead of an individual sample value.\nIntroduction to Hypothesis Testing\nCarefully examine the conclusions that are reached in the next example illustrating \nthe type of thinking that is the basis for the important procedure of hypothesis testing \n(formally introduced in Chapter 8). Example 3 uses the rare event rule for inferential \nstatistics, first presented in Section 4-1:\nIdentifying Significant Results with Probabilities: The Rare Event Rule for \nInferential Statistics\nIf, under a given assumption, the probability of a particular observed \nevent is very small and the observed event occurs signiﬁcantly less than or \nsigniﬁcantly greater than what we typically expect with that assumption, \nwe conclude that the assumption is probably not correct.\nThe following example illustrates the above rare event rule.\n distributed. As noted in the requirement check for part (b), samples of any \nsize will yield means that are normally distributed.\nINTERPRETATION\nThere is a 0.3156 probability that an individual woman will have a pulse rate greater \nthan 80 bpm, and there is a 0.0274 probability that 16 randomly selected women \nwill have pulse rates with a mean greater than 80 bpm.\nEXAMPLE 3  Body Temperatures\nAssume that the population of human body temperatures has a mean of 98.6°F, \nas is commonly believed. Also assume that the population standard deviation is \n0.62°F (based on data from University of Maryland researchers). If a sample of size \nn = 106 is randomly selected, find the probability of getting a mean of 98.2°F or \nlower. (The value of 98.2°F was actually obtained from researchers; see the mid-\nnight temperatures for Day 2 in Data Set 2 “Body Temperatures” in Appendix B.)\nSOLUTION\nWe work under the assumption that the population of human body temperatures has \na mean of 98.6°F. We weren’t given the distribution of the population, but because \nthe sample size n = 106 exceeds 30, we use the central limit theorem and conclude \nthat the distribution of sample means is a normal distribution with these parameters:\n \nmx = m = 98.6 1by assumption2\nsx =\ns\n1n =\n0.62\n1106 = 0.0602197\nFigure 6-24 shows the shaded area (see the tiny left tail of the graph) correspond-\ning to the probability we seek. Having already found the parameters that apply to \nthe distribution shown in Figure 6-24, we can now find the shaded area by using the \nsame procedures developed in Section 6-2.\n\n6-4 The Central Limit Theorem \n257\nINTERPRETATION\nThe result shows that if the mean of our body temperatures is really 98.6°F, as we as-\nsumed, then there is an extremely small probability of getting a sample mean of 98.2°F \nor lower when 106 subjects are randomly selected. University of Maryland researchers \ndid obtain such a sample mean, and after confirming that the sample is sound, there are \ntwo feasible explanations: (1) The population mean really is 98.6°F and their sample \nrepresents a chance event that is extremely rare; (2) the population mean is actually lower \nthan the assumed value of 98.6°F and so their sample is typical. Because the probability  \nis so low, it is more reasonable to conclude that the population mean is lower than \n98.6°F. In reality it appears that the true mean body temperature is closer to 98.2°F!\nThis is the type of reasoning used in hypothesis testing, to be introduced in \nChapter 8. For now, we should focus on the use of the central limit theorem for \nfinding the probability of 0.0001, but we should also observe that this theorem will \nbe used later in applying some very important concepts in statistics.\nTechnology: If we use technology to find the shaded area in Figure 6-24, we get \n0.0000000000155, which can be expressed as 0+.\nTable A-2: If we use Table A-2 to find the shaded area in Figure 6-24, we must first \nconvert the score of x = 98.20°F to the corresponding z score:\nz = x - mx\nsx\n= 98.20 - 98.6\n0.0602197\n= -6.64\nReferring to Table A-2 we find that z = -6.64 is off the chart, but for values \nof z below -3.49, we use an area of 0.0001 for the cumulative left area up to \nz = -3.49. We therefore conclude that the shaded region in Figure 6-24 is 0.0001.\n0\nz\nmx 5 98.6\n26.64\nx 5 98.2\n0.0001\nFIGURE 6-24  Means of Body Temperatures from \nSamples of Size n = 106\nCorrection for a Finite Population\nIn applying the central limit theorem, our use of sx = s> 1n assumes that the popula-\ntion has infinitely many members. When we sample with replacement, the population \nis effectively infinite. When sampling without replacement from a finite population, we \nmay need to adjust sx. Here is a common rule of thumb:\nWhen sampling without replacement and the sample size n is greater than \n5% of the ﬁnite population size N (that is, n + 0.05N), adjust the standard \ndeviation of sample means Sx by multiplying it by this ﬁnite population \n correction factor:\nA\nN - n\nN - 1\n\n258 \nCHAPTER 6 Normal Probability Distributions\nExcept for Exercise 21 “Correcting for a Finite Population,” the examples and exer-\ncises in this section assume that the finite population correction factor does not apply, \nbecause we are sampling with replacement, or the population is infinite, or the sample \nsize doesn’t exceed 5% of the population size.\nStatistical Literacy and Critical Thinking\n1. Requirements A researcher collects a simple random sample of grade-point averages of \nbiostatistics students and she calculates the mean of this sample. Under what conditions can \nthat sample mean be treated as a value from a population having a normal distribution?\n2. Small Sample Weights of adult human brains are normally distributed. Samples of weights \nof adult human brains, each of size n = 15, are randomly collected and the sample means are \nfound. Is it correct to conclude that the sample means cannot be treated as being from a normal \ndistribution because the sample size is too small? Explain.\n3. Notation In general, what do the symbols mx and sx represent? What are the values of mx\nand sx for samples of size 64 randomly selected from the population of IQ scores with popula-\ntion mean of 100 and standard deviation of 15?\n4.  Annual Incomes Annual incomes of physicians are known to have a distribution that is \nskewed to the right instead of being normally distributed. Assume that we collect a large 1n 7 302\nrandom sample of annual incomes of physicians. Can the distribution of those incomes in that \nsample be approximated by a normal distribution because the sample is large? Why or why not?\nUsing the Central Limit Theorem. In Exercises 5–8, assume that females have pulse \nrates that are normally distributed with a mean of 74.0 beats per minute and a standard \n deviation of 12.5 beats per minute (based on Data Set 1 “Body Data” in Appendix B).\n5. a. If 1 adult female is randomly selected, find the probability that her pulse rate is less than \n80 beats per minute.\nb. If 16 adult females are randomly selected, find the probability that they have pulse rates with \na mean less than 80 beats per minute.\nc. Why can the normal distribution be used in part (b), even though the sample size does not \nexceed 30?\n6. a. If 1 adult female is randomly selected, find the probability that her pulse rate is greater \nthan 70 beats per minute.\nb. If 25 adult females are randomly selected, find the probability that they have pulse rates with \na mean greater than 70 beats per minute.\nc. Why can the normal distribution be used in part (b), even though n 6 30?\n7. a. If 1 adult female is randomly selected, find the probability that her pulse rate is between \n72 beats per minute and 76 beats per minute.\nb. If 4 adult females are randomly selected, find the probability that they have pulse rates with \na mean between 72 beats per minute and 76 beats per minute.\nc. Why can the normal distribution be used in part (b), even though the sample size does not \nexceed 30?\n8. a. If 1 adult female is randomly selected, find the probability that her pulse rate is between \n78 beats per minute and 90 beats per minute.\nb. If 16 adult females are randomly selected, find the probability that they have pulse rates with \na mean between 78 beats per minute and 90 beats per minute.\nc. Why can the normal distribution be used in part (b), even though n 6 30?\n6-4 Basic Skills and Concepts\n\n6-4 The Central Limit Theorem \n259\n9. Hemoglobin in Men Hemoglobin levels in adult males are normally distributed with a \nmean of 14.7 g>dL and a standard deviation of 1.3 g>dL (based on data from the National \nHealth and Nutrition Examination Survey).\na. The normal hemoglobin range for men is 13.6 g>dL to 17.7 g>dL. What percentage of men \nhave hemoglobin levels in the normal range?\nb. If we randomly collect samples of men with 9 in each sample, what percentage of those \nsamples have a mean hemoglobin level that is within the normal range?\n10. Hemoglobin in Women Hemoglobin levels in adult females are normally distributed \nwith a mean of 13.0 g>dL and a standard deviation of 1.3 g>dL (based on data from the Na-\ntional Health and Nutrition Examination Survey).\na. The normal hemoglobin range for women is 12.1 g>dL to 15.1 g>dL. What percentage of \nwomen have hemoglobin levels in the normal range?\nb. If we randomly collect samples of women with 9 in each sample, what percentage of those \nsamples have a mean hemoglobin level that is within the normal range?\n11. Diastolic BP in Women Diastolic blood pressure is a measure of the pressure when \narteries rest between heartbeats. Diastolic blood pressure levels in women are normally distrib-\nuted with a mean of 70.2 mm Hg and a standard deviation of 11.2 mm Hg (based on Data Set 1 \n“Body Data” in Appendix B).\na. A diastolic blood pressure level above 90 mm Hg is considered to be hypertension. What \npercentage of women have hypertension?\nb. If we randomly collect samples of women with 4 in each sample, what percentage of those \nsamples have a mean above 90 mm Hg?\n12. Diastolic BP in Men Diastolic blood pressure is a measure of the pressure when arteries \nrest between heartbeats. Diastolic blood pressure levels in men are normally distributed with \na mean of 71.3 mm Hg and a standard deviation of 12.0 mm Hg (based on Data Set 1 “Body \nData” in Appendix B).\na. A diastolic blood pressure level above 90 mm Hg is considered to be hypertension. What \npercentage of men have hypertension?\nb. If we randomly collect samples of men with 4 in each sample, what percentage of those \nsamples have a mean above 90 mm Hg?\n13. Mensa Membership in Mensa requires a score in the top 2% on a standard intelligence \ntest. The Wechsler IQ test is designed for a mean of 100 and a standard deviation of 15, and \nscores are normally distributed.\na. Find the minimum Wechsler IQ test score that satisfies the Mensa requirement.\nb. If 4 randomly selected adults take the Wechsler IQ test, find the probability that their mean \nscore is at least 131.\nc. If 4 subjects take the Wechsler IQ test and they have a mean of 132, but the individual scores \nare lost, can we conclude that all 4 of them are eligible for Mensa?\n14. Sleep The amounts of times that adults sleep are normally distributed with a mean of \n6.8 hours and a standard deviation of 1.4 hours (based on data from multiple sources, includ-\ning a Gallup poll and the American Journal of Epidemiology). A common recommendation is \nthat we get between 7 and 9 hours of sleep each night.\na. For someone randomly selected, find the probability that they get between 7 and 9 hours of \nsleep in a night.\nb. If we randomly collect a sample of 5 adults, what is the probability that the sample mean is \nbetween 7 hours and 9 hours?\n\n260 \nCHAPTER 6 Normal Probability Distributions\nErgonomics. Exercises 15–20 involve applications of ergonomics, which is a discipline \nfocused on the design of tools and equipment so that they can be used safely, comfortably, \nand efficiently.\n15. Water Taxi Safety Passengers died when a water taxi sank in Baltimore’s Inner Harbor. \nMen are typically heavier than women and children, so when loading a water taxi, assume a \nworst-case scenario in which all passengers are men. Assume that weights of men are normally \ndistributed with a mean of 189 lb and a standard deviation of 39 lb (based on Data Set 1 “Body \nData” in Appendix B). The water taxi that sank had a stated capacity of 25 passengers, and the \nboat was rated for a load limit of 3500 lb.\na. Given that the water taxi that sank was rated for a load limit of 3500 lb, what is the maxi-\nmum mean weight of the passengers if the boat is filled to the stated capacity of 25 passengers?\nb. If the water taxi is filled with 25 randomly selected men, what is the probability that their \nmean weight exceeds the value from part (a)?\nc. After the water taxi sank, the weight assumptions were revised so that the new capacity be-\ncame 20 passengers. If the water taxi is filled with 20 randomly selected men, what is the prob-\nability that their mean weight exceeds 175 lb, which is the maximum mean weight that does \nnot cause the total load to exceed 3500 lb?\nd. Is the new capacity of 20 passengers safe?\n16. Designing Manholes According to the website www.torchmate.com, “manhole covers \nmust be a minimum of 22 in. in diameter, but can be as much as 60 in. in diameter.” Assume \nthat a manhole is constructed to have a circular opening with a diameter of 22 in. Men have \nshoulder breadths that are normally distributed with a mean of 18.2 in. and a standard deviation \nof 1.0 in. (based on data from the National Health and Nutrition Examination Survey).\na. What percentage of men will fit into the manhole?\nb. Assume that Connecticut’s Eversource company employs 36 men who work in manholes. If \n36 men are randomly selected, what is the probability that their mean shoulder breadth is less \nthan 18.5 in.? Does this result suggest that money can be saved by making smaller manholes \nwith a diameter of 18.5 in.? Why or why not?\n17. Southwest Airlines Seats Southwest Airlines currently has a seat width of 17 in. Men \nhave hip breadths that are normally distributed with a mean of 14.4 in. and a standard deviation \nof 1.0 in. (based on anthropometric survey data from Gordon, Churchill, et al.).\na. Find the probability that if an individual man is randomly selected, his hip breadth will be \ngreater than 17 in.\nb. Southwest Airlines uses a Boeing 737 for some of its flights, and that aircraft seats 122 pas-\nsengers. If the plane is full with 122 randomly selected men, find the probability that these men \nhave a mean hip breadth greater than 17 in.\nc. Which result should be considered for any changes in seat design: the result from part (a) or \npart (b)?\n18. Redesign of Ejection Seats When women were finally allowed to become pilots of \nfighter jets, engineers needed to redesign the ejection seats because they had been originally \ndesigned for men only. The ACES-II ejection seats were designed for men weighing between \n140 lb and 211 lb. Weights of women are now normally distributed with a mean of 171 lb and a \nstandard deviation of 46 lb (based on Data Set 1 “Body Data” in Appendix B).\na. If 1 woman is randomly selected, find the probability that her weight is between 140 lb and \n211 lb.\nb. If 25 different women are randomly selected, find the probability that their mean weight is \nbetween 140 lb and 211 lb.\nc. When redesigning the fighter jet ejection seats to better accommodate women, which \n probability is more relevant: the result from part (a) or the result from part (b)? Why?\n\n6-5 Assessing Normality \n261\n19. Doorway Height The Boeing 757-200 ER airliner carries 200 passengers and has doors \nwith a height of 72 in. Heights of men are normally distributed with a mean of 68.6 in. and a \nstandard deviation of 2.8 in. (based on Data Set 1 “Body Data” in Appendix B).\na. If a male passenger is randomly selected, find the probability that he can fit through the \ndoorway without bending.\nb. If half of the 200 passengers are men, find the probability that the mean height of the 100 men \nis less than 72 in.\nc. When considering the comfort and safety of passengers, which result is more relevant: the \nprobability from part (a) or the probability from part (b)? Why?\nd. When considering the comfort and safety of passengers, why are women ignored in this \ncase?\n20. Loading Aircraft Before every flight, the pilot must verify that the total weight of the \nload is less than the maximum allowable load for the aircraft. The Bombardier Dash 8 aircraft \ncan carry 37 passengers, and a flight has fuel and baggage that allows for a total passenger load \nof 6200 lb. The pilot sees that the plane is full and all passengers are men. The aircraft will be \noverloaded if the mean weight of the passengers is greater than 6200 lb>37 = 167.6 lb. What is \nthe probability that the aircraft is overloaded? Should the pilot take any action to correct for an \noverloaded aircraft? Assume that weights of men are normally distributed with a mean of 189 lb \nand a standard deviation of 39 lb (based on Data Set 1 “Body Data” in Appendix B).\n21. Correcting for a Finite Population In a study of babies born with very low birth weights, \n275 children were given IQ tests at age 8, and their scores approximated a normal distribution \nwith m = 95.5 and s = 16.0 (based on data from “Neurobehavioral Outcomes of School-Age \nChildren Born Extremely Low Birth Weight or Very Preterm,” by Anderson et al., Journal of \nthe American Medical Association, Vol. 289, No. 24). Fifty of those children are to be ran-\ndomly selected without replacement for a follow-up study.\na. When considering the distribution of the mean IQ scores for samples of 50 children, should \nsx be corrected by using the finite population correction factor? Why or why not? What is the \nvalue of sx?\nb. Find the probability that the mean IQ score of the follow-up sample is between 95 and 105.\n6-4 Beyond the Basics\nKey Concept The following chapters include important statistical methods requiring \nthat sample data are from a population having a normal distribution. In this section we \npresent criteria for determining whether the requirement of a normal distribution is \nsatisfied. The criteria involve (1) visual inspection of a histogram to see if it is roughly \nbell-shaped; (2) identifying any outliers; and (3) constructing a normal quantile plot.\nPART 1\nBasic Concepts of Assessing Normality\nWhen trying to determine whether a collection of data has a distribution that is \napproximately normal, we can visually inspect a histogram to see if it is approxi-\nmately bell-shaped (as discussed in Section 2-2), we can identify outliers, and we can \nalso use a normal quantile plot (discussed briefly in Section 2-2).\n6-5 \nAssessing Normality\n\n262 \nCHAPTER 6 Normal Probability Distributions\nProcedure for Determining Whether It Is Reasonable to Assume That Sample \nData Are from a Population Having a Normal Distribution\n1. Histogram: Construct a histogram. If the histogram departs dramatically from a \nbell shape, conclude that the data do not have a normal distribution.\n2. Outliers: Identify outliers. If there is more than one outlier present, conclude \nthat the data might not have a normal distribution. (Just one outlier could be an \nerror or the result of chance variation, but be careful, because even a single out-\nlier can have a dramatic effect on results.)\n3. Normal quantile plot: If the histogram is basically symmetric and the num-\nber of outliers is 0 or 1, use technology to generate a normal quantile plot. \nApply the following criteria to determine whether the distribution is nor-\nmal. (These criteria can be used loosely for small samples, but they should \nbe used more strictly for large samples.)\n Normal Distribution: The population distribution is normal if the pattern of \nthe points is reasonably close to a straight line and the points do not show some \nsystematic pattern that is not a straight-line pattern.\n Not a Normal Distribution: The population distribution is not normal if either \nor both of these two conditions apply:\n • The points do not lie reasonably close to a straight line.\n • The points show some systematic pattern that is not a straight-line pattern.\nHistograms and Normal Quantile Plots\nIn Part 2 of this section we describe the process of constructing a normal quantile plot, \nbut for now we focus on interpreting a normal quantile plot. The following displays \nshow histograms of data along with the corresponding normal quantile plots.\nNormal: The first case shows a histogram of IQ scores that is close to being bell-\nshaped, so the histogram suggests that the IQ scores are from a normal distribution. \nThe corresponding normal quantile plot shows points that are reasonably close to a \nstraight-line pattern, and the points do not show any other systematic pattern that is \nnot a straight line. It is safe to assume that these IQ scores are from a population that \nhas a normal distribution.\nDEFINITION\nA normal quantile plot (or normal probability plot) is a graph of points (x, y) \nwhere each x value is from the original set of sample data, and each y value is the \ncorresponding z score that is expected from the standard normal distribution.\n\n6-5 Assessing Normality \n263\nUniform: The second case shows a histogram of data having a uniform (flat) distribu-\ntion. The corresponding normal quantile plot suggests that the data are not normally \ndistributed. Although the pattern of points is reasonably close to a straight-line pattern, \nthere is another systematic pattern that is not a straight-line pattern. We conclude that \nthese sample values are from a population having a distribution that is not normal.\nSkewed: The third case shows a histogram of the HDL cholesterol measurements. \nThe shape of the histogram is skewed to the right. The corresponding normal quantile \nplot shows points that are not close to a straight-line pattern. These HDL cholesterol \nmeasurements are from a population having a distribution that is not normal.\nTools for Determining Normality\n \n■Histogram, Outliers: If the requirement of a normal distribution is not too \nstrict, simply look at a histogram and find the number of outliers. If the histo-\ngram is roughly bell-shaped and the number of outliers is 0 or 1, treat the popula-\ntion as if it has a normal distribution.\n \n■Normal Quantile Plot: Normal quantile plots can be difficult to construct on \nyour own, but they can be generated with suitable technology.\n \n■Advanced Methods: In addition to the procedures discussed in this section, \nthere are other more advanced procedures for assessing normality, such as the \nchi-square goodness-of-fit test, the Lilliefors test, the Anderson-Darling test, the \nJarque-Bera test, and the Ryan-Joiner test (discussed briefly in Part 2).\nPART 2\nManual Construction of Normal  \nQuantile Plots\nThe following is a relatively simple procedure for manually constructing a normal \nquantile plot, and it is the same procedure used by Statdisk and the TI-83>84 Plus cal-\nculator. Some statistical packages use various other approaches, but the interpretation \nof the graph is essentially the same.\nu-\ny\nn,\nat \nThe Placebo Effect\nIt has long been \nbelieved that \nplacebos actu-\nally help some \npatients. In fact, \nsome formal \nstudies have \nshown that when given a placebo \n(a treatment with no medicinal \nvalue), many test subjects show \nsome improvement. Estimates of \nimprovement rates have typically \nranged between one-third and \ntwo-thirds of patients. However, \na more recent study suggests \nthat placebos have no real ef-\nfect. An article in New England \nJournal of Medicine (Vol. 334, \nNo. 21) was based on research \nof 114 medical studies over \n50 years. The authors of the \narticle concluded that placebos \nappear to have some effect only \nfor relieving pain, but not for \nother physical conditions. They \nconcluded that apart from clinical \ntrials, the use of placebos “can-\nnot be recommended.”\n\n264 \nCHAPTER 6 Normal Probability Distributions\nManual Construction of a Normal Quantile Plot\nStep 1: First sort the data by arranging the values in order from lowest to highest.\nStep 2:  With a sample of size n, each value represents a proportion of 1>n of the \nsample. Using the known sample size n, find the values of 1\n2n, 3\n2n, 5\n2n, and so \non, until you get n values. These values are the cumulative areas to the left \nof the corresponding sample values.\nStep 3:  Use the standard normal distribution (software or a calculator or Table A-2) \nto find the z scores corresponding to the cumulative left areas found in Step 2. \n(These are the z scores that are expected from a normally distributed sample.)\nStep 4:  Match the original sorted data values with their corresponding z scores \nfound in Step 3; then plot the points (x, y), where each x is an original sam-\nple value and y is the corresponding z score.\nStep 5:  Examine the normal quantile plot and use the criteria given in Part 1. Con-\nclude that the population has a normal distribution if the pattern of the \npoints is reasonably close to a straight line and the points do not show some \nsystematic pattern that is not a straight-line pattern.\nEXAMPLE 1  Platelet Counts\nConsider this sample of five patient platelet counts (1000 cells>mL): 125, 229, 236, \n257, 234. With only five values, a histogram will not be very helpful in revealing the \ndistribution of the data. Instead, construct a normal quantile plot for these five val-\nues and determine whether they appear to come from a population that is normally \ndistributed.\nSOLUTION\nThe following steps correspond to those listed in the procedure above for construct-\ning a normal quantile plot.\nStep 1: First, sort the data by arranging them in order. We get 125, 229, 234, \n236, 257.\nStep 2: With a sample of size n = 5, each value represents a proportion of 1>5 \nof the sample, so we proceed to identify the cumulative areas to the left of the \ncorresponding sample values. The cumulative left areas, which are expressed in \ngeneral as 1\n2n, 3\n2n, 5\n2n, and so on, become these specific areas for this example with \nn = 5: 1\n10, 3\n10, 5\n10, 7\n10, 9\n10. These cumulative left areas expressed in decimal form are 0.1, \n0.3, 0.5, 0.7, and 0.9.\nStep 3: We now use technology (or Table A-2) with the cumulative left areas of \n0.1000, 0.3000, 0.5000, 0.7000, and 0.9000 to find these corresponding z scores: \n-1.28, -0.52, 0, 0.52, and 1.28. (For example, the z score of -1.28 has an area of \n0.1000 to its left.)\nStep 4: We now pair the original sorted platelet counts with their corresponding \nz scores. We get these (x, y) coordinates, which are plotted in the following  \nStatdisk display:\n1125, -1.282, 1229, -0.522, 1234, 02, 1236, 0.522, 1257, 1.282\n\n6-5 Assessing Normality \n265\nRyan-Joiner Test The Ryan-Joiner test is one of several formal tests of normality, \neach having its own advantages and disadvantages. Statdisk has a feature of Normal-\nity Assessment that displays a histogram, normal quantile plot, the number of poten-\ntial outliers, and results from the Ryan-Joiner test.\n Statdisk\nINTERPRETATION\nWe examine the normal quantile plot in the Statdisk display. The points do not ap-\npear to lie reasonably close to the straight line, so we conclude that the sample of \nfive platelet counts does not appear to be from a normally distributed population.\nEXAMPLE 2  Platelet Counts \nExample 1 used a sample of five platelet counts. We can use the Normality Assess-\nment feature of Statdisk with a different sample of the 300 platelet counts listed in \nData Set 1 “Body Data” in Appendix B.\nStatdisk\ncontinued\n\n266 \nCHAPTER 6 Normal Probability Distributions\nData Transformations Many data sets have a distribution that is not normal, but \nwe can transform the data so that the modified values have a normal distribution. One \ncommon transformation is to transform each value of x by taking its logarithm. (You \ncan use natural logarithms or logarithms with base 10. If any original values are 0, \ntake logarithms of values of x + 1). If the distribution of the logarithms of the values \nis a normal distribution, the distribution of the original values is called a lognormal \ndistribution. (See Exercises 19 “Transformations” and 20 “Lognormal Distribu-\ntion”.) In addition to transformations with logarithms, there are other transformations, \nsuch as replacing each x value with 1x, or 1>x, or x2. In addition to getting a required \nnormal distribution when the original data values are not normally distributed, such \ntransformations can be used to correct deficiencies, such as a requirement (found in \nlater chapters) that different data sets have the same variance.\nLet’s use the display with the three criteria for assessing normality.\n \n1. Histogram: We can see that the histogram is skewed to the left instead of  \nbeing bell-shaped.\n \n2. Outliers: The display shows that there are 20 possible outliers. If we examine \na sorted list of the 300 platelet counts, there are platelet counts that appear to \nbe outliers.\n \n3. Normal quantile plot: The points in the normal quantile plot do not ﬁt a \nstraight-line pattern very well. We conclude that the 300 platelet counts do not \nappear to be from a population with a normal distribution.\nNormal Quantile Plots\nAccess tech instructions, videos, and data sets at www.TriolaStats.com\nTECH CENTER \nStatistical Literacy and Critical Thinking\n1. Normal Quantile Plot Data Set 1 “Body Data” in Appendix B includes the heights of 147 \nrandomly selected women, and heights of women are normally distributed. If you were to con-\nstruct a histogram of the 147 heights of women in Data Set 1, what shape do you expect the \nhistogram to have? If you were to construct a normal quantile plot of those same heights, what \npattern would you expect to see in the graph?\n2. Normal Quantile Plot After constructing a histogram of the ages of the 147 women in-\ncluded in Data Set 1 “Body Data” in Appendix B, you see that the histogram is far from being \nbell-shaped. What do you now know about the pattern of points in the normal quantile plot?\n3. Small Sample An article includes elapsed times (hours) to lumbar puncture for 19 patients \nwho entered emergency rooms with sudden and severe “thunderclap” headaches (based on data \nfrom “Thunderclap Headache and Normal Computed Tomographic Results: Value of Cerebro-\nspinal Fluid Analysis,” by DuPont et al., Mayo Clinic Proceedings, Vol. 83, No. 12). Given \nthat the sample size is less than 30, what requirement must be met in order to treat the sample \nmean as a value from a normally distributed population? Identify three tools for verifying that \nrequirement.\n6-5 Basic Skills and Concepts \n\n6-5 Assessing Normality \n267\n4. Assessing Normality The accompanying histogram is constructed from the diastolic blood \npressure measurements of the 147 women included in Data Set 1 “Body Data” in  Appendix B. If \nyou plan to conduct further statistical tests and there is a loose requirement of a normally distrib-\nuted population, what do you conclude about the population distribution based on this histogram?\n Minitab\nInterpreting Normal Quantile Plots. In Exercises 5–8, examine the normal quantile \nplot and determine whether the sample data appear to be from a population with a normal \ndistribution.\n5. Head Lengths of Bears The normal quantile plot represents the head lengths (in.) of \nbears listed in Data Set 11 “Bear Measurements.”\n6. Diet Pepsi The normal quantile plot represents weights (pounds) of the contents of cans of \nDiet Pepsi.\n7. Patient Service Times The normal quantile plot represents service times (minutes) of \nrandomly selected patients.\n\n268 \nCHAPTER 6 Normal Probability Distributions\n8. Visual Acuity Data Set 5 “Vision” includes measures of visual acuity. Shown here is the nor-\nmal quantile plot resulting from the listed measurements from the right eye of the 300 subjects.\nDetermining Normality. In Exercises 9–12, refer to the indicated sample data and deter-\nmine whether they appear to be from a population with a normal distribution. Assume that \nthis requirement is loose in the sense that the population distribution need not be exactly \nnormal, but it must be a distribution that is roughly bell-shaped.\n9. Irises The petal lengths of irises, as listed in Data Set 16 “Iris Measurements” in Appendix B.\n10. Births The lengths of stay (days) of newborn babies, as listed in Data Set 3 “Births” in \nAppendix B.\n11. Cuckoo Egg Lengths The lengths of cuckoo eggs in wren nests, as listed in Data Set 17 \n“Cuckoo Egg Lengths” in Appendix B.\n12. Bears The neck sizes of bears, as listed in Data Set 11 “Bear Measurements” in Appendix B.\nUsing Technology to Generate Normal Quantile Plots. In Exercises 13–16, use tech-\nnology to generate a normal quantile plot. Then determine whether the data come from a \nnormally distributed population.\n13.  Birth weights from Data Set 3 “Births” in Appendix B.\n14.  Lengths of stay from Data Set 3 “Births” in Appendix B.\n15.  White blood cell counts of females from Data Set 1 “Body Data” in Appendix B.\n16.  Red blood cell counts of females from Data Set 1 “Body Data” in Appendix B.\nConstructing Normal Quantile Plots. In Exercises 17 and 18, use the given data values to \nidentify the corresponding z scores that are used for a normal quantile plot; then identify the \ncoordinates of each point in the normal quantile plot. Construct the normal quantile plot, then \ndetermine whether the sample data appear to be from a population with a normal distribution.\n17. Female Arm Circumferences A sample of arm circumferences (cm) of females from \nData Set 1 “Body Data” in Appendix B: 40.7, 44.3, 34.2, 32.5, 38.5.\n18. Brain Volumes A sample of human brain volumes (cm3) is obtained from those listed \nin Data Set 9 “IQ and Brain Size” from Appendix B: 1272, 1051, 1079, 1034, 1070, 1173, \n1079, 1067.\n19. Transformations The heights (in inches) of men listed in Data Set 1 “Body Data” in \n Appendix B have a distribution that is approximately normal, so it appears that those heights \nare from a normally distributed population.\n6-5 Beyond the Basics \ncontinued\n\n6-6 Normal as Approximation to Binomial \n269\na. If 2 inches is added to each height, are the new heights also normally distributed?\nb. If each height is converted from inches to centimeters, are the heights in centimeters also \nnormally distributed?\nc. Are the logarithms of normally distributed heights also normally distributed?\n20. Lognormal Distribution The following are costs (dollars) of treating patients. Test these \nvalues for normality, then take the logarithm of each value and test for normality. What do you \nconclude?\n237,592 160,680 153,500 117,120 7304 6037 4483 4367 2658 1361 311\nKey Concept Section 5-2 introduced binomial probability distributions, and this sec-\ntion presents a method for using a normal distribution as an approximation to a bi-\nnomial probability distribution, so that some problems involving proportions can be \nsolved by using a normal distribution. Here are the two main points of this section:\n \n■Given probabilities p and q (where q = 1 - p) and sample size n, if the condi-\ntions np Ú 5 and nq Ú 5 are both satisfied, then probabilities from a binomial \nprobability distribution can be approximated reasonably well by using a normal \ndistribution having these parameters:\n m = np\n s = 1npq.\n \n■The binomial probability distribution is discrete (with whole numbers for the \nrandom variable x), but the normal approximation is continuous. To compensate, \nwe use a “continuity correction” with a whole number x represented by the inter-\nval from x - 0.5 to x + 0.5.\nBrief Review of Binomial Probability Distribution In Section 5-2 we saw that \na binomial probability distribution has (1) a fixed number of trials; (2) trials that are \nindependent; (3) trials that are each classified into two categories commonly referred \nto as success and failure; and (4) trials with the property that the probability of success \nremains constant. Section 5-2 also introduced the following notation.\nNotation\nn = the ﬁxed number of trials\nx = the specific number of successes in n trials\np = probability of success in one of the n trials\nq = probability of failure in one of the n trials (so q = 1 - p)\nRationale for Using a Normal Approximation We saw in Section 6-3 that the \nsampling distribution of a sample proportion tends to approximate a normal distribu-\ntion. Also, see the probability histogram on the next page for the binomial distribution \nwith n = 580 and p = 0.25. (In one of Mendel’s famous hybridization experiments, \nhe expected 25% of his 580 peas to be yellow.) The bell shape of this graph suggests \nthat we can use a normal distribution to approximate the binomial distribution.\n6-6 \nNormal as Approximation to Binomial\n\n270 \nCHAPTER 6 Normal Probability Distributions\n Minitab\nNormal Distribution as an Approximation to the Binomial Distribution\nRequirements\n1. The sample is a simple random sample of size n from a population in which the proportion of successes is p, or the \nsample is the result of conducting n independent trials of a binomial experiment in which the probability of success is p.\n2. np Ú 5 and nq Ú 5.\n(The requirements of np Ú 5 and nq Ú 5 are common, but some recommend using 10 instead of 5.)\nNormal Approximation\nIf the above requirements are satisfied, then the probability distribution of the random variable x can be approximated by \na normal distribution with these parameters:\n • m = np\n • s = 1npq\nContinuity Correction\nWhen using the normal approximation, adjust the discrete whole number x by using a continuity correction so that any \nindividual value x is represented in the normal distribution by the interval from x - 0.5 to x + 0.5.\nKEY ELEMENTS \nProcedure for Using a Normal Distribution to Approximate a  \nBinomial Distribution\n1. Check the requirements that np Ú 5 and nq Ú 5.\n2. Find m = np and s = 1npq to be used for the normal distribution.\n3. Identify the discrete whole number x that is relevant to the binomial probability \nproblem being considered, and represent that value by the region bounded by \nx - 0.5 and x + 0.5.\n4. Graph the normal distribution and shade the desired area bounded by \nx - 0.5 or x + 0.5 as appropriate.\nEXAMPLE 1  Was Mendel Wrong? \nIn one of Mendel’s famous hybridization experiments, he expected that among 580 \noffspring peas, 145 of them (or 25%) would be yellow, but he actually got 152 yellow \npeas. Assuming that Mendel’s rate of 25% is correct, find the probability of  \n\n6-6 Normal as Approximation to Binomial \n271\n(s 5 10.4283)\n151.5\nm 5 145\nArea 5 0.2665\nProbability\nNormal\nBinomial\n151.5\n152.5\n0.00\n0.01\n0.02\n0.03\n0.04\nFIGURE 6-25 Number of Yellow Peas Among 580\ngetting 152 or more yellow peas by random chance. That is, given n = 580 and \np = 0.25, find P(at least 152 yellow peas). Is 152 yellow peas significantly high?\nSOLUTION\nStep 1: Requirement check: With n = 580 and p = 0.25, we get np =  \n(580)(0.25) = 145 and nq = (580)(0.75) = 435, so the requirements that  \nnp Ú 5 and nq Ú 5 are both satisfied.\nStep 2: We now find m and s needed for the normal distribution:\nm = np = 580 # 0.25 = 145\ns = 1npq = 2580 # 0.25 # 0.75 = 10.4283\nStep 3: We want the probability of at least 152 yellow peas, so the discrete whole \nnumber relevant to this example is x = 152. We use the continuity correction as \nwe represent the discrete value of 152 in the graph of the normal distribution by the \ninterval between 151.5 and 152.5 (as shown in the top portion of Figure 6-25).\nStep 4: See the bottom portion of Figure 6-25, which shows the normal distribution \nand the area to the right of 151.5 (representing “152 or more” yellow peas).\ncontinued\n\n272 \nCHAPTER 6 Normal Probability Distributions\nContinuity Correction\nWe want the area to the right of 151.5 in the bottom portion of Figure 6-25.\nTechnology: If using technology, we find that the shaded area is 0.2665.\nTable A-2: If using Table A-2, we must first find the z score using x = 151.5, \nm = 145, and s = 10.4283 as follows:\nz = x - m\ns\n= 151.5 - 145\n10.4283\n= 0.62\nUsing Table A-2, we find that z = 0.62 corresponds to a cumulative left \narea of 0.7324, so the shaded region in the bottom portion of Figure 6-25 is \n1 - 0.7324 = 0.2676. (The result of 0.2665 from technology is more accurate.)\nINTERPRETATION\nMendel’s result of 152 yellow peas is greater than the 145 yellow peas he expected \nwith his theory of hybrids, but with P(152 or more yellow peas) = 0.2665, we see \nthat 152 yellow peas is not significantly high. That is a result that could easily oc-\ncur with a true rate of 25% for yellow peas. This experiment does not contradict \n Mendel’s theory.\nDEFINITION\nWhen we use the normal distribution (which is a continuous probability distribution) \nas an approximation to the binomial distribution (which is discrete), a continuity \ncorrection is made to a discrete whole number x in the binomial distribution by \nrepresenting the discrete whole number x by the interval from x - 0.5 to x + 0.5 \n(that is, adding and subtracting 0.5).\nExample 1 used a continuity correction when the discrete value of 152 was repre-\nsented in the normal distribution by the area between 151.5 and 152.5. Because we \nwanted the probability of “152 or more” yellow peas, we used the area to the right of \n151.5. Here are other uses of the continuity correction:\nStatement About the Discrete Value\nArea of the Continuous Normal Distribution\nAt least 152 (includes 152 and above)\nTo the right of 151.5\nMore than 152 (doesn’t include 152)\nTo the right of 152.5\nAt most 152 (includes 152 and below)\nTo the left of 152.5\nFewer than 152 (doesn’t include 152)\nTo the left of 151.5\nExactly 152\nBetween 151.5 and 152.5\nEXAMPLE 2  Exactly 252 Yellow Peas\nUsing the same information from Example 1, find the probability of exactly 152 \nyellow peas among the 580 offspring peas. That is, given n = 580 and assuming \nthat p = 0.25, find P(exactly 152 yellow peas). Is this result useful for determining \nwhether 152 yellow peas is significantly high?\n\n6-6 Normal as Approximation to Binomial \n273\nINTERPRETATION\nIn Section 4-1 we saw that x successes among n trials is significantly high if the \nprobability of x or more successes is unlikely with a probability of 0.05 or less. In \ndetermining whether Mendel’s result of 152 yellow peas contradicts his theory that \n25% of the offspring should be yellow peas, we should consider the probability \nof 152 or more yellow peas, not the probability of exactly 152 peas. The result of \n0.0305 is not the relevant probability; the relevant probability is 0.2665 found in Ex-\nample 1. In general, the relevant result is the probability of getting a result at least \nas extreme as the one obtained.\nSOLUTION\nSee Figure 6-26, which shows the normal distribution with m = 145 and s = 10.4283.\nThe shaded area approximates the probability of exactly 152 yellow peas. That region \nis the vertical strip between 151.5 and 152.5, as shown. We can find that area by using \nthe same methods introduced in Section 6-2.\nTechnology: Using technology, the shaded area is 0.0305.\nTable A-2: Using Table A-2, we convert 151.5 and 152.5 to z = 0.62 and z = 0.72,\nwhich yield cumulative left areas of 0.7324 and 0.7642. Because they are both cu-\nmulative left areas, the shaded region in Figure 6-26 is 0.7642 - 0.7324 = 0.0318.\nThe probability of exactly 152 yellow peas is 0.0318.\n(s 5 10.4283)\n152.5\nm 5 145\nThis shaded area\napproximates the\nprobability of exactly\n152 yellow peas.\n151.5\nFIGURE 6-26 Probability of Exactly 152 Yellow Peas\nTechnology for Binomial Probabilities\nThis topic of using a normal distribution to approximate a binomial distribution was \nonce quite important, but we can now use technology to find binomial probabilities \nthat were once beyond our capabilities. For example, see the following Statdisk dis-\nplay on the next page showing that for Example 1, the probability of 152 or more \nyellow peas is 0.2650, and for Example 2, the probability of exactly 152 yellow peas \nis 0.0301, so there is no real need to use a normal approximation. However, there are \ncases where we need to use a normal approximation, and Section 8-3 uses a normal \napproximation to a binomial distribution for an important statistical method intro-\nduced in that section.\n\n274 \nCHAPTER 6 Normal Probability Distributions\nStatistical Literacy and Critical Thinking \n1.  Continuity Correction In testing the assumption that the probability of a baby boy is \n0.512, a geneticist obtains a random sample of 1000 births and finds that 502 of them are boys. \nUsing the continuity correction, describe the area under the graph of a normal distribution cor-\nresponding to the following. (For example, the area corresponding to “the probability of at least \n502 boys” is this: the area to the right of 501.5.)\na. The probability of 502 or fewer boys\nb. The probability of exactly 502 boys\nc. The probability of more than 502 boys\n2.  Checking Requirements Common tests such as the SAT, ACT, LSAT (Law School \n Admissions Test), and MCAT (Medical College Admissions Test) use multiple choice test \nquestions, each with possible answers of a, b, c, d, e, and each question has only one correct \nanswer. We want to find the probability of getting at least 25 correct answers for someone who \nmakes random guesses for answers to a block of 100 questions. If we plan to use the methods \nof this section with a normal distribution used to approximate a binomial distribution, are the \nnecessary requirements satisfied? Explain.\n3. Notation Common tests such as the SAT, ACT, LSAT, and MCAT tests use multiple choice \ntest questions, each with possible answers of a, b, c, d, e, and each question has only one cor-\nrect answer. For people who make random guesses for answers to a block of 100 questions, \nidentify the values of p, q, m, and s. What do m and s measure?\n4. Distribution of Proportions Each week, Nielsen Media Research conducts a survey of \n5000 households and records the proportion of households tuned to Sanjay Gupta MD. If we \nobtain a large collection of those proportions and construct a histogram of them, what is the ap-\nproximate shape of the histogram?\n6-6 Basic Skills and Concepts\n\n6-6 Normal as Approximation to Binomial \n275\nUsing Normal Approximation. In Exercises 5–8, do the following: If the requirements \nof np # 5 and nq # 5 are both satisfied, estimate the indicated probability by using the \nnormal distribution as an approximation to the binomial distribution; if np * 5 or nq * 5, \nthen state that the normal approximation should not be used.\n5. Births of Boys With n = 20 births and p = 0.512 for a boy, find P(fewer than 8 boys).\n6. Births of Boys With n = 8 births and p = 0.512 for a boy, find P(exactly 5 boys).\n7. Guessing on United States Medical Licensing Examinations With n = 20 guesses \nand p = 0.2 for a correct answer, find P(at least 6 correct answers).\n8. Guessing on United States Medical Licensing Examinations With n = 50 guesses \nand p = 0.2 for a correct answer, find P(exactly 12 correct answers).\nEye Colors. In Exercises 9–12, assume that eye colors are distributed as shown in the ac-\ncompanying display (based on data from a study by Dr. P. Sorita at Indiana University), and \nalso assume that 100 people are randomly selected.\n9.  Blue Eyes Find the probability that at least 40 of the 100 subjects have blue eyes. Is \n40 people with blue eyes significantly high?\n10. Blue Eyes Find the probability that at least 49 of the 100 subjects have blue eyes. Is \n49 people with blue eyes significantly high?\n11. Green Eyes Find the probability that fewer than 5 of the 100 subjects have green eyes. Is \n4 people with green eyes significantly low?\n12. Brown Eyes Find the probability that among the 100 subjects, 33 or fewer have brown \neyes. Is 33 people with brown eyes significantly low?\n13. Tamiflu Assume that 10% of subjects treated with Tamiflu (oseltamivir) experienced the \nadverse reaction of nausea (based on clinical trials).\na. Find the probability that among 250 randomly selected subjects treated with Tamiflu, ex-\nactly 17 of them experience nausea.\nb. Find the probability that among 250 randomly selected subjects treated with Tamiflu, the \nnumber who experience nausea is 17 or fewer.\nc. Does it appear that 17 cases of nausea among the 250 subjects is significantly low?\n14. Mendelian Genetics When Mendel conducted his famous genetics experiments with \npeas, one sample of offspring consisted of 929 peas, with 705 of them having red flowers. If \nwe assume, as Mendel did, that under these circumstances, there is a 3>4 probability that a pea \nwill have a red flower, we would expect that 696.75 (or about 697) of the peas would have red \nflowers, so the result of 705 peas with red flowers is more than expected.\na. If Mendel’s assumed probability is correct, find the probability of getting 705 or more peas \nwith red flowers.\ncontinued\n\n276 \nCHAPTER 6 Normal Probability Distributions\nb. Is 705 peas with red flowers significantly high?\nc. What do these results suggest about Mendel’s assumption that 3>4 of peas will have red \nflowers?\n15. Sleepwalking Assume that 29.2% of people have sleepwalked (based on “Prevalence \nand Comorbidity of Nocturnal Wandering in the U.S. Adult General Population,” by Ohayon \net al., Neurology, Vol. 78, No. 20). Assume that in a random sample of 1480 adults, 455 have \nsleepwalked.\na. Assuming that the rate of 29.2% is correct, find the probability that 455 or more of the 1480 \nadults have sleepwalked.\nb. Is that result significantly high?\nc. What does the result suggest about the rate of 29.2%?\n16. Cell Phones and Brain Cancer In a study of 420,095 cell phone users in Denmark, it \nwas found that 135 developed cancer of the brain or nervous system. For those not using cell \nphones, there is a 0.000340 probability of a person developing cancer of the brain or nervous \nsystem. We therefore expect about 143 cases of such cancers in a group of 420,095 randomly \nselected people.\na. Find the probability of 135 or fewer cases of such cancers in a group of 420,095 people.\nb. What do these results suggest about media reports that indicate cell phones cause cancer of \nthe brain or nervous system?\n17. Births The probability of a baby being born a boy is 0.512. Consider the problem of \nfinding the probability of exactly 7 boys in 11 births. Solve that problem using (1) normal ap-\nproximation to the binomial using Table A-2; (2) normal approximation to the binomial using \ntechnology instead of Table A-2; (3) using technology with the binomial distribution instead of \nusing a normal approximation. Compare the results. Given that the requirements for using the \nnormal approximation are just barely met, are the approximations off by very much?\n6-6 Beyond the Basics\nBone Density Test. In Exercises 1–4, assume that scores on a bone mineral density test \nare normally distributed with a mean of 0 and a standard deviation of 1.\n1. Bone Density Sketch a graph showing the shape of the distribution of bone density test \nscores.\n2. Bone Density Find the score separating the lowest 9% of scores from the highest 91%.\n3. Bone Density For a randomly selected subject, find the probability of a score greater than \n-2.93.\n4. Bone Density For a randomly selected subject, find the probability of a score between \n0.87 and 1.78.\n5. Notation \na. Identify the values of m and s for the standard normal distribution.\nb. What do the symbols mx and sx represent?\nChapter Quick Quiz\n\nIn Exercises 6–10, assume that women have diastolic blood pressure measures that are \nnormally distributed with a mean of 70.2 mm Hg and a standard deviation of 11.2 mm Hg \n(based on Data Set 1 “Body Data” in Appendix B).\n6. Diastolic Blood Pressure Find the probability that a randomly selected woman has a \nnormal diastolic blood pressure level, which is below 80 mm Hg.\n7. Diastolic Blood Pressure Find the probability that a randomly selected woman has a \ndiastolic blood pressure level between 60 mm Hg and 80 mm Hg.\n8. Diastolic Blood Pressure Find P90, the 90th percentile for the diastolic blood pressure \nlevels of women.\n9. Diastolic Blood Pressure If 16 women are randomly selected, find the probability that \nthe mean of their diastolic blood pressure levels is less than 75 mm Hg.\n10.  Diastolic Blood Pressure The accompanying normal quantile plot was constructed \nfrom the diastolic blood pressure levels of a sample of women. What does this graph suggest \nabout diastolic blood pressure levels of women?\n1. Bone Density Test A bone mineral density test is used to identify a bone disease. The re-\nsult of a bone density test is commonly measured as a z score, and the population of z scores is \nnormally distributed with a mean of 0 and a standard deviation of 1.\na. For a randomly selected subject, find the probability of a bone density test score less than 1.54.\nb. For a randomly selected subject, find the probability of a bone density test score greater than \n-1.54.\nc. For a randomly selected subject, find the probability of a bone density test score between \n-1.33 and 2.33.\nd. Find Q1, the bone density test score separating the bottom 25% from the top 75%.\ne. If the mean bone density test score is found for 9 randomly selected subjects, find the prob-\nability that the mean is greater than 0.50.\n2. Biometric Security In designing a security system based on eye (iris) recognition, we must \nconsider the standing eye heights of women, which are normally distributed with a mean of \n59.7 in. and a standard deviation of 2.5 in. (based on anthropometric survey data from Gordon, \nChurchill, et al.).\na. If an eye recognition security system is positioned at a height that is uncomfortable for \nwomen with standing eye heights less than 54 in., what percentage of women will find that \nheight uncomfortable?\nb. In positioning the eye recognition security system, we want it to be suitable for the lowest \n95% of standing eye heights of women. What standing eye height of women separates the low-\nest 95% of standing eye heights from the highest 5%?\nReview Exercises\nCHAPTER 6 Review Exercises \n277\n\n278 \nCHAPTER 6 Normal Probability Distributions\n3. Biometric Security Standing eye heights of men are normally distributed with a mean of \n64.3 in. and a standard deviation of 2.6 in. (based on anthropometric survey data from Gordon, \nChurchill, et al.).\na. If an eye recognition security system is positioned at a height that is uncomfortable for men \nwith standing eye heights greater than 70 in., what percentage of men will find that height un-\ncomfortable?\nb. In positioning the eye recognition security system, we want it to be suitable for the tallest \n98% of standing eye heights of men. What standing eye height of men separates the tallest 98% \nof standing eye heights from the lowest 2%?\n4. Sampling Distributions Scores on the Gilliam Autism Rating Scale (GARS) are nor-\nmally distributed with a mean of 100 and a standard deviation of 15. A sample of 64 GARS \nscores is randomly selected and the sample mean is computed.\na. Describe the distribution of such sample means.\nb. What is the mean of all such sample means?\nc. What is the standard deviation of all such sample means?\n5. Unbiased Estimators\na. What is an unbiased estimator?\nb. For the following statistics, identify those that are unbiased estimators: mean, median, range, \nvariance, proportion.\nc. Determine whether the following statement is true or false: “The sample standard deviation is a \nbiased estimator, but the bias is relatively small in large samples, so s is often used to estimate s.”\n6. Disney Monorail The Mark VI monorail used at Disney World has doors with a height of \n72 in. Heights of men are normally distributed with a mean of 68.6 in. and a standard deviation \nof 2.8 in. (based on Data Set 1 “Body Data” in Appendix B).\na. What percentage of adult men can fit through the doors without bending? Does the door \ndesign with a height of 72 in. appear to be adequate? Explain.\nb. What doorway height would allow 99% of adult men to fit without bending?\n7. Disney Monorail Consider the same Mark VI monorail described in the preceding exer-\ncise. Again assume that heights of men are normally distributed with a mean of 68.6 in. and a \nstandard deviation of 2.8 in.\na. In determining the suitability of the monorail door height, why does it make sense to con-\nsider men while women are ignored?\nb. Mark VI monorail cars have a capacity of 60 passengers. If a car is loaded with 60 randomly \nselected men, what is the probability that their mean height is less than 72 in.?\nc. Why can’t the result from part (b) be used to determine how well the doorway height accom-\nmodates men?\n8.  Assessing Normality of BMI Data Listed below are measures of body mass index \n(BMI) for women listed in Data Set 1 “Body Data.”\na. Do these measures appear to come from a population that has a normal distribution? Why or \nwhy not?\nb. Can the mean of this sample be treated as a value from a population having a normal distri-\nbution? Why or why not?\n15.9 18.7 24.2 28.7 28.8 28.9 28.9 28.9 29.0 29.1 29.3 31.4 59.0\n9. Hybridization Experiment In one of Mendel’s experiments with plants, 1064 offspring \nconsisted of 787 plants with long stems. According to Mendel’s theory, 3>4 of the offspring \n\nplants should have long stems. Assuming that Mendel’s proportion of 3>4 is correct, find the \nprobability of getting 787 or fewer plants with long stems among 1064 offspring plants. Based \non the result, is 787 offspring plants with long stems significantly low? What does the result \nimply about Mendel’s claimed proportion of 3>4?\n10. Tall Clubs The social organization Tall Clubs International has a requirement that women \nmust be at least 70 in. tall. Assume that women have normally distributed heights with a mean \nof 63.7 in. and a standard deviation of 2.9 in. (based on Data Set 1 in Appendix B).\na. Find the percentage of women who satisfy the height requirement.\nb. If the height requirement is to be changed so that the tallest 2.5% of women are eligible, \nwhat is the new height requirement?\nIn Exercises 1–3, use the following left threshold audiometry measures from females (from \nData Set 4 “Audiometry” in Appendix B).\n15.9 18.7 24.2 28.7 28.8 28.9 28.9 28.9 29.0 29.1 29.3 31.4\n1. Audiometry\na. Find the mean x.\nb. Find the median.\nc. Find the standard deviation s.\nd. Convert the highest measure to a z score.\ne. What level of measurement (nominal, ordinal, interval, ratio) describes this data set?\nf. Are the measures of hearing discrete data or continuous data?\n2. Audiometry\na. Find Q1, Q2, and Q3.\nb. Construct a boxplot.\nc. Based on the accompanying normal quantile plot of the audiometry measurements, what do \nyou conclude about these sample data?\n3. Left-Handedness According to data from the American Medical Association, 10% of us \nare left-handed.\na. If three people are randomly selected, find the probability that they are all left-handed.\nb. If three people are randomly selected, find the probability that at least one of them is \n left-handed.\nCumulative Review Exercises\nCHAPTER 6 Cumulative Review Exercises \n279\ncontinued\n\n280 \nCHAPTER 6 Normal Probability Distributions\nc. Why can’t we solve the problem in part (b) by using the normal approximation to the bino-\nmial distribution?\nd. If groups of 50 people are randomly selected, what is the mean number of left-handed peo-\nple in such groups?\ne. If groups of 50 people are randomly selected, what is the standard deviation for the numbers \nof left-handed people in such groups?\nf. Use the range rule of thumb to determine whether 8 left-handed people is a significantly high \nnumber of left-handed people in a randomly selected group of 50 people.\n4. Blue Eyes Assume that 35% of us have blue eyes (based on a study by Dr. P. Soria at \n Indiana University).\na. Let B denote the event of selecting someone who has blue eyes. What does the event B\n denote?\nb. Find the value of P1B2.\nc. Find the probability of randomly selecting three different people and finding that all of them \nhave blue eyes.\nd. Find the probability that among 100 randomly selected people, at least 45 have blue eyes.\ne. If 35% of us really do have blue eyes, is a result of 45 people with blue eyes among 100 ran-\ndomly selected people a result that is significantly high?\n5. Foot Lengths of Women Assume that foot lengths of women are normally distributed \nwith a mean of 9.6 in. and a standard deviation of 0.5 in., based on data from the U.S. Army \nAnthropometry Survey (ANSUR).\na. Find the probability that a randomly selected woman has a foot length less than 10.0 in.\nb. Find the probability that a randomly selected woman has a foot length between 8.0 in. and \n11.0 in.\nc. Find P95.\nd. Find the probability that 25 women have foot lengths with a mean greater than 9.8 in.\nSome methods in this chapter are easy with technology but very difficult without it. The two \nprojects that follow illustrate how easy it is to use technology for assessing normality and find-\ning binomial probabilities.\n1. Assessing Normality It is often necessary to determine whether sample data appear to \nbe from a normally distributed population, and that determination is helped with the construc-\ntion of a histogram and normal quantile plot. Refer to Data Set 1 “Body Data” in Appendix B. \nFor each of the 13 columns of data (not including age or gender), determine whether the data \nappear to be from a normally distributed population. Use Statdisk or any other technology. \n(Download a free copy of Statdisk from www.statdisk.org.)\n2. Binomial Probabilities Section 6-6 described a method for using a normal distribution to \napproximate a binomial distribution. Many technologies are capable of generating probabilities \nfor a binomial distribution. Instead of using a normal approximation to a binomial distribution, \nuse technology to find the exact binomial probabilities in Exercises 9–12 of Section 6-6.\nTechnology Projects\n\nFROM DATA TO DECISION\nCritical Thinking: Designing a campus  \ndormitory elevator\nAn Ohio college student died when he tried to escape from \na dormitory elevator that was overloaded with 24 passen-\ngers. The elevator was rated for a maximum weight of 2500 \npounds. Let’s consider this elevator with an allowable weight \nof 2500 pounds. Let’s also consider parameters for weights \nof adults, as shown in the accompanying table (based on \nData Set 1 “Body Data” in Appendix B).\nWeights of Adults\nMales\nFemales\nm\n189 lb\n171 lb\ns\n39 lb\n46 lb\nDistribution\nNormal\nNormal\nWe could consider design features such as the type of music \nthat could be played on the elevator. We could select songs \nsuch as “Imagine” or “Daydream Believer.” Instead, we will \nfocus on the critical design feature of weight.\na. First, elevators commonly have a 25% margin of error, \nso they can safely carry a load that is 25% greater than the \nstated load. What amount is 25% greater than 2500 pounds? \nLet’s refer to this amount as “the maximum safe load,” \nwhile the 2500-pound limit is the “placard maximum load.”\nb. Now we need to determine the maximum number of pas-\nsengers that should be allowed. Should we base our calcula-\ntions on the maximum safe load or the 2500-pound placard \nmaximum load?\nc. The weights given in the accompanying table are weights \nof adults not including clothing or textbooks. Add another \n10 pounds for each student’s clothing and textbooks. What \nis the maximum number of elevator passengers that should \nbe allowed?\nd. Do you think that weights of college students are different \nfrom weights of adults from the general population? If so, \nhow? How would that affect the elevator design?\n1. In-class activity Divide into groups of three or four students and address these issues af-\nfecting the design of manhole covers.\n• Which of the following is most relevant for determining whether a manhole cover diameter of \n24 in. is large enough: weights of men, weights of women, heights of men, heights of women, \nhip breadths of men, hip breadths of women, shoulder breadths of men, shoulder breadths of \nwomen?\n• Why are manhole covers usually round? (This was once a popular interview question asked \nof applicants at IBM, and there are at least three good answers. One good answer is sufficient \nhere.)\n2. Out-of-class activity Divide into groups of three or four students. In each group, develop \nan original procedure to illustrate the central limit theorem. The main objective is to show that \nwhen you randomly select samples from a population, the means of those samples tend to be \nnormally distributed, regardless of the nature of the population distribution. For this illustra-\ntion, begin with some population of values that does not have a normal distribution.\n3. In-class activity Divide into groups of three or four students. Using a coin to simulate \nbirths, each individual group member should simulate 25 births and record the number of simu-\nlated girls. Combine all results from the group and record n = total number of births and x =\nnumber of girls. Given batches of n births, compute the mean and standard deviation for the \nnumber of girls. Is the simulated result unusual? Why or why not?\n4. In-class activity Divide into groups of three or four students. Select a set of data from \n Appendix B (excluding Data Sets that were used in examples or exercises in Section 6-5). Use \nthe methods of Section 6-5 to construct a histogram and normal quantile plot, and then deter-\nmine whether the data set appears to come from a normally distributed population.\nCooperative Group Activities\nCHAPTER 6 Cooperative Group Activities \n281\n\n282\nEstimating a Population \nProportion\nEstimating a Population \nMean\nEstimating a Population \nStandard Deviation or \nVariance\nBootstrapping: \nUsing Technology for \nEstimates\n7-1\n7-2\n7-3\n7-4\nDoes Touch Therapy Work?\nCHAPTER \nPROBLEM\nEstimating Parameters \nand Determining \nSample Sizes\nMany patients pay $30 to $60 for a session of touch therapy in \nwhich the touch therapist moves his or her hands within a few \ninches of the patient’s body without actually making physical \ncontact. The objective is to cure a wide variety of medical con-\nditions, including cancer, AIDS, asthma, heart disease, head-\naches, burns, and bone fractures. The intent is that a profes-\nsionally trained touch therapist can detect poor alignments in \nthe patient’s energy field, and can then reposition energy fields \nto create an energy balance that fosters the healing process.\nWhen she was in the fourth grade, nine-year old Emily \nRosa chose the topic of touch therapy for a science fair project. \nShe convinced 21 experienced touch therapists to participate \nin a simple test of their ability to detect a human energy field. \nEmily constructed a cardboard partition with two holes for \n7 \n\nhands. Each touch therapist would put both hands through the \ntwo holes, and Emily would place her hand just above one of \nthe therapist’s hands; then the therapist was asked to identify \nthe hand that Emily had selected. Emily used a coin toss to \nrandomly select the hand to be used. This test was repeated \n280 times. If the touch therapists really did have the ability to \nsense a human energy field, they should have identified the \ncorrect hand significantly more than 50% of the time. If they \ndid not have the ability to detect the energy field and they just \nguessed, they should have been correct about 50% of the time. \nHere are Emily’s results: Among the 280 trials, the touch thera-\npists identified the correct hand 123 times, for a success rate of \n43.9%. Emily, with the help of her mother, a statistician, and a \nphysician, submitted her findings for publication in the Journal \nof the American Medical Association. After a careful and thor-\nough review of the experimental design and results, the article \n“A Close Look at Therapeutic Touch” was published (Journal of \nthe American Medical Association, Vol. 279, No. 13). Emily be-\ncame the youngest researcher to be published in that journal. \nAnd she won a blue ribbon for her science fair project.\nLet’s consider the key results from Emily’s project. Among \nthe 280 trials, the touch therapists were correct 123 times. We \nhave a sample proportion with n = 280 and x = 123 suc-\ncesses. Arguments against the validity of the study might include \nthe claim that the number of trials is too small to be meaningful, \nor that the touch therapists just had a bad day and, because \nof chance, they were not as successful as the population of all \ntouch therapists. We will consider such issues in this chapter.\nIn this chapter we begin the study of methods of inferential statistics. Listed below are \nthe major activities of inferential statistics, and this chapter introduces methods for the \nfirst activity of using sample data to estimate population parameters. Chapter 8 will intro-\nduce the basic methods for testing claims (or hypotheses) about population  parameters.\nMajor Activities of Inferential Statistics\n1. Use sample data to estimate values of population parameters (such as a population \nproportion or population mean).\n2. Use sample data to test hypotheses (or claims) made about population parameters.\nHere are the chapter objectives.\nEstimating a Population Proportion\n• Construct a confidence interval estimate of a population proportion and interpret \nsuch confidence interval estimates.\n• Identify the requirements necessary for the procedure that is used, and determine \nwhether those requirements are satisfied.\n• Develop the ability to determine the sample size necessary to estimate a population \nproportion.\nEstimating a Population Mean\n• Construct a confidence interval estimate of a population mean, and be able to inter-\npret such confidence interval estimates.\n• Determine the sample size necessary to estimate a population mean.\nEstimating a Population Standard Deviation or Variance\n• Develop the ability to construct a confidence interval estimate of a population  standard \ndeviation or variance, and be able to interpret such confidence interval  estimates.\n7-1\n7-2\n7-3\nChapter Objectives \n283\nCHAPTER OBJECTIVES\n>>>\n\n284 \nCHAPTER 7 Estimating Parameters and Determining Sample Sizes\nKey Concept This section presents methods for using a sample proportion to make \nan inference about the value of the corresponding population proportion. This section \nfocuses on the population proportion p, but we can also work with probabilities or \npercentages. When working with percentages, we will perform calculations with the \nequivalent proportion value. Here are the three main concepts included in this section:\n \n■Point Estimate: The sample proportion (denoted by pn) is the best point estimate \n(or single value estimate) of the population proportion p.\n \n■Confidence Interval: We can use a sample proportion to construct a confidence \ninterval estimate of the true value of a population proportion, and we should \nknow how to construct and interpret such confidence intervals.\n \n■Sample Size: We should know how to find the sample size necessary to estimate \na population proportion.\nThe concepts presented in this section are used in the following sections and chapters, \nso it is important to understand this section quite well.\nPART 1\n  Point Estimate, Confidence Interval,  \nand Sample Size \nPoint Estimate\nIf we want to estimate a population proportion with a single value, the best estimate \nis the sample proportion pn. Because pn consists of a single value that is equivalent to a \npoint on a line, it is called a point estimate.\n7-1 \nEstimating a Population Proportion\nBootstrapping: Using Technology for Estimates\n• Develop the ability to use technology along with the bootstrapping method to con-\nstruct a confidence interval estimate of a population proportion, population mean, \nand population standard deviation and population variance.\n7-4\nBootstrapping: Using Technology for Estimates\n• Develop the ability to use technology along with the bootstrapping method to con-\nstruct a confidence interval estimate of a population proportion, population mean,\nand population standard deviation and population variance.\nDEFINITION\nA point estimate is a single value used to estimate a population parameter.\nThe sample proportion pn is the best point estimate of the population \np roportion p.\nUnbiased Estimator We use pn as the point estimate of p because it is unbiased and \nit is the most consistent of the estimators that could be used. (An unbiased estima-\ntor is a statistic that targets the value of the corresponding population parameter in \nthe sense that the sampling distribution of the statistic has a mean that is equal to the \ncorresponding population parameter. The statistic pn targets the population proportion \np.) The sample proportion pn is the most consistent estimator of p in the sense that the \nstandard deviation of sample proportions tends to be smaller than the standard devia-\ntion of other unbiased estimators of p.\n\n7-1 Estimating a Population Proportion \n285\nConfidence Interval\nWhy Do We Need Confidence Intervals? In Example 1 we saw that 0.439 is our best \npoint estimate of the population proportion p, but we have no indication of how good \nthat best estimate is. A confidence interval gives us a much better sense of how good \nan estimate is.\nEXAMPLE 1\nTouch Therapy\nThe Chapter Problem describes a test of touch therapy. If the touch therapists had \nthe ability to sense a human energy field, they should have identified the correct \nhand significantly more than 50% of the time. If they made random guesses, their \nsuccess rate should be around 50%. Using the result of 123 correct responses in the \n280 trials, find the best point estimate of the proportion of correct responses.\nSOLUTION\nBecause the sample proportion is the best point estimate of the population propor-\ntion, we conclude that the best point estimate of p is 123>280 or 0.439. (If using \nthe sample results to estimate the percentage of correct responses, the best point \n estimate is 43.9%.)\nDEFINITION\nA confidence interval (or interval estimate) is a range (or an interval) of values \nused to estimate the true value of a population parameter. A confidence interval is \nsometimes abbreviated as CI.\nDEFINITION\nThe confidence level is the probability 1 - a (such as 0.95, or 95%) that the con-\nfidence interval actually does contain the population parameter, assuming that the \nestimation process is repeated a large number of times. (The confidence level is \nalso called the degree of confidence, or the confidence coefficient.)\nThe following table shows the relationship between the confidence level and the cor-\nresponding value of a. The confidence level of 95% is the value used most often.\nMost Common Confidence Levels\nCorresponding Values of A\n90% (or 0.90) confidence level:\na = 0.10\n95% (or 0.95) confidence level:\na = 0.05\n99% (or 0.99) confidence level:\na = 0.01\nHere’s an example of a confidence interval found later in Example 3:\nThe 0.95 (or 95%) conﬁdence interval estimate of the population proportion \np is 0.381 * p * 0.497.\ne \nBias in Internet  \nSurveys?\nCapitalizing on \nthe widespread \nuse of technol-\nogy and social \nmedia, there is a \ngrowing trend to \nconduct surveys \nusing only the \nInternet instead of using in-\nperson interviews or phone calls \nto randomly selected subjects. \nInternet surveys are faster and \nmuch less expensive, and they \nprovide important advantages in \nsurvey design and administra-\ntion. But are Internet surveys \nbiased because they use only \nsubjects randomly selected from \nthe 90% of the U.S. population \nthat uses the Internet? The Pew \nResearch Center studied this \nissue by comparing results from \nonline polls to polls that included \nthe offline population. It was \nfound that the differences were \ngenerally quite small, but topics \nrelated to the Internet and tech-\nnology resulted in much larger \ndifferences. We should be careful \nto consider consequences of \nbias with Internet surveys.\n\n286 \nCHAPTER 7 Estimating Parameters and Determining Sample Sizes\nInterpreting a Confidence Interval\nWe must be careful to interpret confidence intervals correctly. There is a correct inter-\npretation and many different and creative incorrect interpretations of the confidence \ninterval 0.381 6 p 6 0.497.\nCorrect: \n “We are 95% confident that the interval from 0.381 to 0.497 actu-\nally does contain the true value of the population proportion p.”\n This is a short and acceptable way of saying that if we were to \nselect many different random samples of size 280 (as in the Chapter \nProblem) and construct the corresponding confidence intervals, 95% \nof them would contain the population proportion p. In this correct \ninterpretation, the confidence level of 95% refers to the success rate \nof the process used to estimate the population proportion.\nWrong: \n “There is a 95% chance that the true value of p will fall between \n0.381 and 0.497.”\n This is wrong because p is a population parameter with a fixed \nvalue; it is not a random variable with values that vary.\nWrong: \n “95% of sample proportions will fall between 0.381 and 0.497.”\n This is wrong because the values of 0.381 and 0.497 result from one \nsample; they are not parameters describing the behavior of all samples.\nConfidence Level: The Process Success Rate A confidence level of 95% tells us that \nthe process we are using should, in the long run, result in confidence interval limits that \ncontain the true population proportion 95% of the time. Suppose that the true proportion \nof correct responses by the touch therapists is p = 0.50. See Figure 7-1, which shows \nthat 19 out of 20 (or 95%) different confidence intervals contain the assumed value of \np = 0.50. Figure 7-1 is trying to tell this story: With a 95% confidence level, we expect \nabout 19 out of 20 confidence intervals (or 95%) to contain the true value of p.\nThis conﬁdence interval\ndoes not contain p 5 0.50.\n0.45\np 5 0.50\n0.55\nFIGURE 7-1  Confidence Intervals from  \n20 Different Samples\nCritical Values\nCritical values are formally defined on the next page and they are based on the follow-\ning observations:\n1. When certain requirements are met, the sampling distribution of sample propor-\ntions can be approximated by a normal distribution, as shown in Figure 7-2.\n2. A z score associated with a sample proportion has a probability of a>2 of fall-\ning in the right tail portion of Figure 7-2.\n3. The z score at the boundary of the right-tail region is commonly denoted \nby za>2 and is referred to as a critical value because it is on the borderline \nseparating z scores that are significantly high.\nza/2\na/2\na/2\nFound from\ntechnology or\nTable A-2\nz 5 0\nFIGURE 7-2\nCritical \nValue zA,2 in the Standard \nNormal Distribution\n\n7-1 Estimating a Population Proportion \n287\nExample 2 showed that a 95% confidence level results in a critical value of \nza>2 = 1.96. This is the most common critical value, and it is listed with two other \ncommon values in the table that follows.\nConfidence Level\na\nCritical Value, zA>2\n90%\n0.10\n1.645\n95%\n0.05\n     1.96\n99%\n0.01\n2.575\nDEFINITION\nA critical value is the number on the borderline separating sample statistics that \nare significantly high or low from those that are not significant. The number za>2 is a \ncritical value that is a z score with the property that it is at the border that separates \nan area of a>2 in the right tail of the standard normal distribution (as in Figure 7-2).\nEXAMPLE 2\nFinding a Critical Value\nFind the critical value za>2 corresponding to a 95% confidence level.\nSOLUTION\nA 95% confidence level corresponds to a = 0.05, so a>2 = 0.025. Figure 7-3 \nshows that the area in each of the green-shaded tails is a>2 = 0.025. We find \nza>2 = 1.96 by noting that the cumulative area to its left must be 1 - 0.025, or \n0.975. We can use technology or refer to Table A-2 to find that the cumulative left \narea of 0.9750 corresponds to z = 1.96. For a 95% confidence level, the critical \nvalue is therefore za>2 = 1.96.\nNote that when finding the critical z score for a 95% confidence level, we use a \ncumulative left area of 0.9750 (not 0.95). Think of it this way:\nThis is our \n The area in both  \nThe area in the right The cumulative area from the left,\nconfidence level: \ntails is: \n tail is: \nexcluding the right tail, is:\n95% \nu  A = 0.05 \nu  \nA,2 = 0.025 \nu  \n1 −0.025 = 0.975\nConﬁdence Level: 95%\nThe total area to the\nleft of this boundary\nis 0.975.\na/2 5 0.025\na/2 5 0.025\nz 5 0\nza/2 5 1.96\n2za/2 5 21.96\nFIGURE 7-3  Finding the Critical Value zA,2 for a 95%  \nConfidence Level\nHow the Poll Was \nConducted\nThe New York \nTimes is quite \ngood at report-\ning poll results. \nThat newspaper \noften reports on \npoll results with \nan accompanying article bearing \nthe headline “How the Poll Was \nConducted.” The description \ntypically includes the sample \nsize, the margin of error, and the \nfollowing statement disclosing \nthat the confidence level is 95%: \n“In theory, in 19 cases out of 20, \noverall results based on such \nsamples will differ by no more \nthan. . . .” One recent report also \nprovided information that the poll \nincluded adults who were regis-\ntered to vote; landline telephone \nnumbers were randomly selected \nby a computer; cell phone num-\nbers were also randomly gener-\nated; and results were weighted \naccording to geographic region, \nsex, race, marital status, age, \nand education. The “How the Poll \nWas Conducted” descriptions \nare a model for all media who \nreport on polls.\ni l\nb\ni\n\n288 \nCHAPTER 7 Estimating Parameters and Determining Sample Sizes\nDEFINITION\nWhen data from a simple random sample are used to estimate a population propor-\ntion p, the difference between the sample proportion pn and the population propor-\ntion p is an error. The maximum likely amount of that error is the margin of error, \ndenoted by E. There is a probability of 1 - a (such as 0.95) that the difference be-\ntween pn and p is E or less. The margin of error E is also called the maximum error \nof  the estimate and can be found by multiplying the critical value and the estimated \nstandard deviation of sample proportions, as shown in Formula 7-1.\nFORMULA 7-1\nE = za>2B\npnqn\nn  margin of error for proportions\nc \nc\nCritical value Estimated standard deviation of sample proportions\nConfidence Interval for Estimating a Population Proportion p\nObjective\nConstruct a confidence interval used to estimate a population proportion p.\nNotation\np =  population proportion\npn = sample proportion\nn = number of sample values\nE = margin of error\nza>2 =  critical value: the z score separating an area of a>2 \nin the right tail of the standard normal distribution\nKEY ELEMENTS\n1. The sample is a simple random sample.\n2. The conditions for the binomial distribution are satis-\nfied: There is a fixed number of trials, the trials are \nindependent, there are two categories of outcomes, and \nthe probabilities remain constant for each trial (as in \nSection 5-2).\n3. There are at least 5 successes and at least 5 failures. \n(This requirement is a way to verify that np Ú 5 and \nnq Ú 5, so the normal distribution is a suitable ap-\nproximation to the binomial distribution.)\nConfidence Interval Estimate of p\npn - E 6 p 6 pn + E  where  E = za>2B\npnqn\nn\nThe confidence interval is often expressed in the following two equivalent formats:\npn { E or \n1pn - E,  pn + E2\nRound-Off Rule for Confidence Interval Estimates of p\nRound the confidence interval limits for p to three significant digits.\nRequirements\nMargin of Error\nWe now formally define the margin of error E that we have all heard about so often in \nmedia reports.\n\n7-1 Estimating a Population Proportion \n289\nProcedure for Constructing a Confidence Interval for p\n1. Verify that the requirements in the preceding Key Elements box are satisfied.\n2. Use technology or Table A-2 to find the critical value za>2 that corresponds to \nthe desired confidence level.\n3. Evaluate the margin of error E = za>22pnqn>n.\n4. Using the value of the calculated margin of error E and the value of the sample \nproportion pn, find the values of the confidence interval limits pn - E and \npn + E. Substitute those values in the general format for the confidence interval.\n5. Round the resulting confidence interval limits to three significant digits.\nEXAMPLE 3  Constructing a Confidence Interval: Touch Therapy\nIn the Chapter Problem we noted that in an experiment with touch therapists, they \nmade correct responses in 123 of the 280 trials. The sample results are n = 280 and \npn = 123>280, or 0.439.\n \na. Find the margin of error E that corresponds to a 95% conﬁdence level.\n \nb. Find the 95% conﬁdence interval estimate of the population proportion p.\n \nc. Based on the results, can we safely conclude that the touch therapists had a \nsuccess rate equivalent to tossing a coin?\nSOLUTION\nREQUIREMENT CHECK (1) The experiment was examined and found to be sound, so \nwe will treat the results as simple random samples. (2) The conditions for a bino-\nmial experiment are satisfied, because there is a fixed number of trials (280), the \ntrials are independent (because the response from one touch therapist doesn’t affect \nthe probability of the response from another touch therapist), there are two catego-\nries of outcome (response was correct or incorrect), and the probability remains \nconstant and is not changing over time. (3) The number of successes (123 correct \nresponses) and the number of failures (157 incorrect responses) are both at least 5. \nThe check of requirements has been successfully completed. \nTechnology The confidence interval and margin of error can be easily found using \ntechnology. From the Statdisk display we can see the required entries on the left \nand the results displayed on the right. The results show that the margin of error is \nE = 0.0581 (rounded) and the confidence interval is 0.381 6 p 6 0.497 (round-\ned). (The Wilson score confidence interval included in the display will be discussed \nlater in Part 2 of this section.)\nStatdisk\ncontinued\n\n290 \nCHAPTER 7 Estimating Parameters and Determining Sample Sizes\nFinding the Point Estimate and E from a Confidence Interval\nSometimes we want to better understand a confidence interval that might have been \nobtained from a journal article or technology. If we already know the confidence inter-\nval limits, the sample proportion (or the best point estimate) pn and the margin of error \nE can be found as follows:\nPoint estimate of p: \npn = 1upper confidence interval limit2 + 1lower confidence interval limit2\n2\nMargin of error:\nE = 1upper confidence interval limit2 - 1lower confidence interval limit2\n2\nManual Calculation Here is how to find the confidence interval with manual cal-\nculations:\na. The margin of error is found by using Formula 7-1 with za>2 = 1.96 (as found \nin Example 2), pn = 0.439,  qn = 0.561, and n = 280.\nE = za>2 B\npnqn\nn = 1.96 B\n10.4392 10.5612\n280\n= 0.058129\n \nb. Constructing the conﬁdence interval is really easy now that we know that \npn = 0.439 and E = 0.058129. Simply substitute those values to obtain this \nresult:\n pn - E 6 p 6 pn + E\n 0.439 - 0.058129 6 p 6 0.439 + 0.058129\n 0.381 6 p 6 0.497 1rounded to three significant digits2\nThis same result could be expressed in the format of 0.439 { 0.058 or \n(0.381, 0.497). If we want the 95% conﬁdence interval for the true population \npercentage, we could express the result as 38.1% 6 p 6 49.7%.\n \nc. Based on the conﬁdence interval obtained in part (b), it appears that fewer \nthan 50% of the touch therapist responses are correct (because the interval of \nvalues from 0.381 to 0.497 is an interval that is completely below 0.50).\nEXAMPLE 4   Finding the Sample Proportion  \nand Margin of Error\nThe article “High-Dose Nicotine Patch Therapy,” by Dale, Hurt, et al. (Journal \nof the American Medical Association, Vol. 274, No. 17) includes this statement: \n “Of the 71 subjects, 70% were abstinent from smoking at 8 weeks (95% confidence \ninterval [CI], 58% to 81%).” Use that statement to find the point estimate pn and the \nmargin of error E.\n\n7-1 Estimating a Population Proportion \n291\nUsing Confidence Intervals for Hypothesis Tests\nA confidence interval can be used to informally address some claim made about a \npopulation proportion p. For example, if sample results consist of 70 girls in 100 \nbirths, the resulting 95% confidence interval of 0.610 6 p 6 0.790 can be used to \ninformally support a claim that the proportion of girls is different from 50% (because \n0.50 is not contained within the confidence interval).\nDetermining Sample Size\nIf we plan to collect sample data in order to estimate some population proportion, \nhow do we know how many sample units we must get? If we solve the formula for the \nmargin of error E (Formula 7-1) for the sample size n, we get Formula 7-2 that fol-\nlows. Formula 7-2 requires pn as an estimate of the population proportion p, but if no \nsuch estimate is known (as is often the case), we replace pn by 0.5 and replace qn by 0.5, \nwith the result given in Formula 7-3. Replacing pn and qn with 0.5 results in the largest \npossible sample size, so we are sure that the sample size is adequate for estimating p.\nSOLUTION\nWe get the 95% confidence interval of 0.58 6 p 6 0.81 from the given statement \nof “58% to 81%.” The point estimate pn is the value midway between the upper and \nlower confidence interval limits, so we get\n pn = 1upper confidence limit2 + 1lower confidence limit2\n2\n = 0.81 + 0.58\n2\n= 0.695\nThe margin of error can be found as follows:\n E = 1upper confidence limit2 - 1lower confidence limit2\n2\n = 0.81 - 0.58\n2\n= 0.115\nFinding the Sample Size Required to Estimate a Population Proportion\nObjective\nDetermine how large the sample size n should be in order to estimate the population proportion p.\nNotation\np = population proportion\npn = sample proportion\nn = number of sample values\nE = desired margin of error\nza>2 =  z score separating an area of a>2 in the right tail of the standard normal distribution\nKEY ELEMENTS\ncontinued\n\n292 \nCHAPTER 7 Estimating Parameters and Determining Sample Sizes\nRequirements\nThe sample must be a simple random sample of independent sample units.\nWhen an estimate pn is known:  Formula 7-2  n =\n3za>242 pnqn\nE2\nWhen no estimate pn is known:  Formula 7-3  n =\n3za>242 0.25\nE2\nIf a reasonable estimate of pn can be made by using previous samples, a pilot study, or someone’s expert knowledge, use \nFormula 7-2. If nothing is known about the value of pn, use Formula 7-3.\nRound-Off Rule for Determining Sample Size\nIf the computed sample size n is not a whole number, round the value of n up to the next larger whole number, so the \nsample size is sufficient instead of being slightly insufficient. For example, round 384.16 to 385.\nEXAMPLE 5   What Percentage of Children Have Received \n Measles Vaccinations?\nIf we were to conduct a survey to determine the percentage of children (older than \n1 year) who have received measles vaccinations, how many children must be sur-\nveyed in order to be 95% confident that the sample percentage is in error by no \nmore than three percentage points?\n \na. Assume that a recent survey showed that 90% of children have received \nmeasles vaccinations.\n \nb. Assume that we have no prior information suggesting a possible value of the \npopulation proportion.\nSOLUTION\n \na. With a 95% conﬁdence level, we have a = 0.05, so za>2 = 1.96. Also, the \nmargin of error is E = 0.03, which is the decimal equivalent of “three per-\ncentage points.” The prior survey suggests that pn = 0.90, so qn = 0.10 (found \nfrom qn = 1 - 0.90). Because we have an estimated value of pn, we use \n Formula 7-2 as follows:\n n =\n3za>242 pnqn\nE2\n= 31.9642 10.90210.102\n0.032\n \n= 384.16 = 385 1rounded up2\n \n We must obtain a simple random sample that includes at least 385 children.\n \nb. With no prior knowledge of pn (or qn), we use Formula 7-3 as follows:\nn =\n3za>242 # 0.25\nE2\n= 31.9642 # 0.25\n0.032\n \n= 1067.11 = 1068 1rounded  up2\n \n We must obtain a simple random sample that includes at least 1068 children.\n\n7-1 Estimating a Population Proportion \n293\nRole of the Population Size N Formulas 7-2 and 7-3 are remarkable because they \nshow that the sample size does not depend on the size (N) of the population; the \nsample size depends on the desired confidence level, the desired margin of error, and \nsometimes the known estimate of pn. (See Exercise 37 for dealing with cases in which \na relatively large sample is selected without replacement from a finite population, so \nthe sample size n does depend on the population size N.)\nPART 2\nBetter-Performing Confidence Intervals \nDisadvantage of Wald Confidence Interval\nCoverage Probability The coverage probability of a confidence interval is the ac-\ntual proportion of such confidence intervals that contain the true population propor-\ntion. If we select a specific confidence level, such as 0.95 (or 95%), we would like to \nget the actual coverage probability equal to our desired confidence level. However, for \nthe confidence interval described in Part 1 (called a “Wald confidence interval”), the \nactual coverage probability is usually less than or equal to the confidence level that we \nselect, and it could be substantially less. For example, if we select a 95% confidence \nlevel, we usually get 95% or fewer of confidence intervals containing the population \nproportion p. (This is sometimes referred to as being “too liberal.”) For this reason, \nthe Wald confidence interval is rarely used in professional applications and profes-\nsional journals.\nBetter-Performing Confidence Intervals\nImportant note about exercises: Except for some Beyond the Basics exercises, the \nexercises for this Section 7-1 are based on the method for constructing a Wald con-\nfidence interval as described in Part 1, not the confidence intervals described here. It \nis recommended that students learn the methods presented earlier, but recognize that \nthere are better methods available, and they can be used with suitable technology.\nINTERPRETATION\nTo be 95% confident that our sample percentage is within three percentage points \nof the true percentage for all children, we should obtain a simple random sample of \n1068 children, assuming no prior knowledge. By comparing this result to the sam-\nple size of 385 found in part (a), we can see that if we have no knowledge of a prior \nstudy, a larger sample is required to achieve the same results compared to when the \nvalue of pn can be estimated.\nCAUTION Try to avoid these three common errors when calculating sample size:\n1.  Don’t make the mistake of using E = 3 as the margin of error corresponding to \n“three percentage points.” If the margin of error is three percentage points, use \nE = 0.03.\n2.  Be sure to substitute the critical z score for za>2. For example, when working with \n95% conﬁdence, be sure to replace za>2 with 1.96. Don’t make the mistake of \nreplacing za>2 with 0.95 or 0.05.\n3.  Be sure to round up to the next higher integer; don’t round oﬀ using the usual \nround-oﬀ rules. Round 1067.11to 1068.\n\n294 \nCHAPTER 7 Estimating Parameters and Determining Sample Sizes\nPlus Four Method The plus four confidence interval performs better than the Wald \nconfidence interval in the sense that its coverage probability is closer to the confi-\ndence level that is used. The plus four confidence interval uses this very simple pro-\ncedure: Add 2 to the number of successes x, add 2 to the number of failures (so that \nthe number of trials n is increased by 4), and then find the Wald confidence interval \nas described in Part 1 of this section. The plus four confidence interval is very easy to \ncalculate and it has coverage probabilities similar to those for the Wilson score confi-\ndence interval that follows.\nWilson Score Another confidence interval that performs better than the Wald CI is \nthe Wilson score confidence interval:\n pn +\nz2\na>2\n2n { za>2 B\npnqn +\nz2\na>2\n4n\nn\n1 +\nz2\na>2\nn\nThe Wilson score confidence interval performs better than the Wald CI in the sense \nthat the coverage probability is closer to the confidence level. With a confidence level \nof 95%, the Wilson score confidence interval would get us closer to a 0.95 probability \nof containing the parameter p. The complexity of the above expression can be circum-\nvented by using some technologies, such as Statdisk or XLSTAT, that provide Wilson \nscore confidence interval results.\nClopper-Pearson Method The Clopper-Pearson method is an “exact” method in \nthe sense that it is based on the exact binomial distribution instead of an approxima-\ntion of a distribution. It is criticized for being too conservative in this sense: When we \nselect a specific confidence level, the coverage probability is usually greater than or \nequal to the selected confidence level. Select a confidence level of 0.95, and the actual \ncoverage probability is usually 0.95 or greater, so that 95% or more of such confidence \nintervals will contain p. Calculations with this method are too messy to consider here.\nWhich Method Is Best? There are other methods for constructing confidence inter-\nvals that are not discussed here. There isn’t universal agreement on which method is \nbest for constructing a confidence interval estimate of p.\n \n■The Wald confidence interval is best as a teaching tool for introducing students \nto confidence intervals.\n \n■The plus four confidence interval is almost as easy as Wald and it performs bet-\nter than Wald by having a coverage probability closer to the selected confidence \nlevel.\nAgain, note that except for some Beyond the Basic exercises, the exercises that fol-\nlow are based on the Wald confidence interval given earlier, not the better-performing \nconfidence intervals discussed here.\nProportions: Confidence Intervals & Sample Size Determination\nAccess tech instructions, videos, and data sets at www.TriolaStats.com\nTECH CENTER \n\n7-1 Estimating a Population Proportion \n295\nStatistical Literacy and Critical Thinking\n1. Reporting Results Here is a result stated in a format commonly used in the media: “In a \nclinical trial of 227 subjects treated with OxyContin (oxycodone), 13% of the subjects reported \ndizziness. The margin of error is {4 percentage points.” What important feature of the poll is \nomitted?\n2. Margin of Error For the poll described in Exercise 1, describe what is meant by the state-\nment that “the margin of error was given as {4 percentage points.”\n3. Notation For the poll described in Exercise 1, what values do pn, qn, n, E, and p represent? If \nthe confidence level is 95%, what is the value of a?\n4. Confidence Levels Given specific sample data, such as the data given in Exercise 1, which \nconfidence interval is wider: the 95% confidence interval or the 80% confidence interval? Why \nis it wider?\nFinding Critical Values. In Exercises 5–8, find the critical value zA, 2 that corresponds to \nthe given confidence level.\n5. 90%   6. 99%   7. 99.5%   8. 98%\nFormats of Confidence Intervals. In Exercises 9–12, express the confidence interval us-\ning the indicated format. (The confidence intervals are based on proportions of eye colors.)\n9. Brown Eyes Express 0.375 6  p 6 0.425 in the form of pn { E.\n10. Blue Eyes Express 0.275 6  p 6 0.425 in the form of pn { E.\n11. Green Eyes Express the confidence interval (0.0780, 0.162) in the form of \npn - E 6 p 6 pn + E.\n12. Gray Eyes Express the confidence interval 0.070 { 0.021 in the form of \npn - E 6 p 6 pn + E.\nConstructing and Interpreting Confidence Intervals. In Exercises 13–16, use the \ngiven sample data and confidence level. In each case, (a) find the best point estimate of the \npopulation proportion p; (b) identify the value of the margin of error E; (c) construct the \nconfidence interval; (d) write a statement that correctly interprets the confidence interval.\n13. OxyContin In a clinical trial of OxyContin (oxycodone), 16 subjects experienced head-\naches among the 227 subjects treated with OxyContin. Construct a 95% confidence interval for \nthe proportion of treated subjects who experience headaches.\n14. Eliquis The drug Eliquis (apixaban) is used to help prevent blood clots in certain patients. \nIn clinical trials, among 5924 patients treated with Eliquis, 153 developed the adverse reaction \nof nausea (based on data from Bristol-Myers Squibb Co.). Construct a 99% confidence interval \nfor the proportion of adverse reactions.\n15. Survey Return Rate In a study of cell phone use and brain hemispheric dominance, an \nInternet survey was e-mailed to 5000 subjects randomly selected from an online group whose \nfocus is related to ears. 717 surveys were returned. Construct a 90% confidence interval for the \nproportion of returned surveys.\n16. Medical Malpractice In a study of 1228 randomly selected medical malpractice lawsuits, \nit was found that 856 of them were dropped or dismissed (based on data from the Physicians \nInsurers Association of America). Construct a 95% confidence interval for the proportion of \nmedical malpractice lawsuits that are dropped or dismissed.\n7-1 Basic Skills and Concepts \n\n296 \nCHAPTER 7 Estimating Parameters and Determining Sample Sizes\nCritical Thinking. In Exercises 17–28, use the data and confidence level to construct a \nconfidence interval estimate of p, then address the given question.\n17. Births A random sample of 860 births in New York State included 426 boys. Construct \na 95% confidence interval estimate of the proportion of boys in all births. It is believed that \namong all births, the proportion of boys is 0.512. Do these sample results provide strong evi-\ndence against that belief?\n18. Mendelian Genetics One of Mendel’s famous genetics experiments yielded 580 peas, \nwith 428 of them green and 152 yellow.\na. Find a 99% confidence interval estimate of the percentage of green peas.\nb. Based on his theory of genetics, Mendel expected that 75% of the offspring peas would be \ngreen. Given that the percentage of offspring green peas is not 75%, do the results contradict \nMendel’s theory? Why or why not?\n19. OxyContin The drug OxyContin (oxycodone) is used to treat pain, but it is danger-\nous because it is addictive and can be lethal. In clinical trials, 227 subjects were treated with \n OxyContin and 52 of them developed nausea (based on data from Purdue Pharma L.P.).\na. Construct a 95% confidence interval estimate of the percentage of OxyContin users who \ndevelop nausea.\nb. Compare the result from part (a) to this 95% confidence interval for 5 subjects who developed \nnausea among the 45 subjects given a placebo instead of OxyContin: 1.93% 6 p 6 20.3%.\nWhat do you conclude?\n20. Medication Usage In a survey of 3005 adults aged 57 through 85 years, it was found that \n81.7% of them used at least one prescription medication (based on data from “Use of Prescrip-\ntion and Over-the-Counter Medications and Dietary Supplements Among Older Adults in the \nUnited States,” by Qato et al., Journal of the American Medical Association, Vol. 300, No. 24).\na. How many of the 3005 subjects used at least one prescription medication?\nb. Construct a 90% confidence interval estimate of the percentage of adults aged 57 through \n85 years who use at least one prescription medication.\nc. What do the results tell us about the proportion of college students who use at least one \n prescription medication?\n21. Cell Phones and Cancer A study of 420,095 Danish cell phone users found that 0.0321% \nof them developed cancer of the brain or nervous system. Prior to this study of cell phone use, \nthe rate of such cancer was found to be 0.0340% for those not using cell phones. The data are \nfrom the Journal of the National Cancer Institute.\na. Use the sample data to construct a 90% confidence interval estimate of the percentage of cell \nphone users who develop cancer of the brain or nervous system.\nb. Do cell phone users appear to have a rate of cancer of the brain or nervous system that is dif-\nferent from the rate of such cancer among those not using cell phones? Why or why not?\n22. Lipitor In clinical trials of the drug Lipitor (atorvastatin), 270 subjects were given a pla-\ncebo and 7 of them had allergic reactions. Among 863 subjects treated with 10 mg of the drug, \n8 experienced allergic reactions. Construct the two 95% confidence interval estimates of the \npercentages of allergic reactions. Compare the results. What do you conclude?\n23. Gender Selection Before its clinical trials were discontinued, the Genetics & IVF In-\nstitute conducted a clinical trial of the XSORT method designed to increase the probability of \nconceiving a girl and, among the 945 babies born to parents using the XSORT method, there \nwere 879 girls. Construct the 95% confidence interval estimate of the percentage of success. \nWhat do you conclude?\n\n7-1 Estimating a Population Proportion \n297\n 24. Gender Selection Before its clinical trials were discontinued, the Genetics & IVF In-\nstitute conducted a clinical trial of the YSORT method designed to increase the probability of \nconceiving a boy and, among the 291 babies born to parents using the YSORT method, there \nwere 239 boys. What do you conclude?\n25. Postponing Death An interesting hypothesis is that individuals can temporarily postpone \ntheir death to survive a major holiday or important event such as a birthday. In a study of this \nphenomenon, it was found that in the week before and the week after Thanksgiving, there were \n12,000 total deaths, and 6062 of them occurred in the week before Thanksgiving (based on data \nfrom “Holidays, Birthdays, and Postponement of Cancer Death,” by Young and Hade, Journal \nof the American Medical Association, Vol. 292, No. 24.) Construct a 95% confidence interval \nestimate of the proportion of number of deaths in the week before Thanksgiving to the total \ndeaths in the week before and the week after Thanksgiving. Based on the result, does there \nappear to be any indication that people can temporarily postpone their death to survive the \nThanksgiving holiday? Why or why not?\n26. Cloning Survey A Gallup poll included 1012 randomly selected adults who were asked \nwhether “cloning of humans should or should not be allowed.” Results showed that 901 of \nthose surveyed indicated that cloning should not be allowed. A news reporter wants to deter-\nmine whether these survey results constitute strong evidence that the majority (more than 50%) \nof people are opposed to such cloning. Construct a 99% confidence interval estimate of the \nproportion of adults believing that cloning of humans should not be allowed. Is there strong \nevidence supporting the claim that the majority is opposed to such cloning?\n27. Smoking Cessation In a program designed to help patients stop smoking, 198 patients \nwere given sustained care, and 82.8% of them were no longer smoking after one month. Among \n199 patients given standard care, 62.8% were no longer smoking after one month (based on \ndata from “Sustained Care Intervention and Postdischarge Smoking Cessation Among Hospi-\ntalized Adults,” by Rigotti et al., Journal of the American Medical Association, Vol. 312, No. \n7). Construct the two 95% confidence interval estimates of the percentages of success. Com-\npare the results. What do you conclude?\n28. Measured Results vs. Reported Results The same study cited in the preceding exer-\ncise produced these results after six months for the 198 patients given sustained care: 25.8% \nwere no longer smoking, and these results were biochemically confirmed, but 40.9% of these \npatients reported that they were no longer smoking. Construct the two 95% confidence inter-\nvals. Compare the results. What do you conclude?\nDetermining Sample Size. In Exercises 29–36, use the given data to find the minimum \nsample size required to estimate a population proportion or percentage.\n29. Lefties Find the sample size needed to estimate the percentage of California residents who \nare left-handed. Use a margin of error of three percentage points, and use a confidence level of \n99%.\na. Assume that pn and qn are unknown.\nb. Assume that based on prior studies, about 10% of Californians are left-handed.\nc. How do the results from parts (a) and (b) change if the entire United States is used instead \nof California?\n30. Chickenpox You plan to conduct a survey to estimate the percentage of adults who have \nhad chickenpox. Find the number of people who must be surveyed if you want to be 90% con-\nfident that the sample percentage is within two percentage points of the true percentage for the \npopulation of all adults.\na. Assume that nothing is known about the prevalence of chickenpox.\nb. Assume that about 95% of adults have had chickenpox.\nc. Does the added knowledge in part (b) have much of an effect on the sample size?\n\n298 \nCHAPTER 7 Estimating Parameters and Determining Sample Sizes\n 31. Bachelor’s Degree in Four Years In a study of government financial aid for college stu-\ndents, it becomes necessary to estimate the percentage of full-time college students who earn a \nbachelor’s degree in four years or less. Find the sample size needed to estimate that percentage. \nUse a 0.05 margin of error, and use a confidence level of 95%.\na. Assume that nothing is known about the percentage to be estimated.\nb. Assume that prior studies have shown that about 40% of full-time students earn bachelor’s \ndegrees in four years or less.\nc. Does the added knowledge in part (b) have much of an effect on the sample size?\n32. Astrology A sociologist plans to conduct a survey to estimate the percentage of health \ncare professionals who believe in astrology. How many health care professionals must be sur-\nveyed if we want a confidence level of 99% and a margin of error of four percentage points?\na. Assume that nothing is known about the percentage to be estimated.\nb. Use the information from a previous Harris survey in which 26% of respondents said that \nthey believed in astrology.\n33. Biometric Security In considering the use of biometric security (such as fingerprints) to \nreplace passwords, you want to estimate the percentage of adults who believe that passwords \nshould be replaced with biometric security. How many randomly selected adults must you sur-\nvey? Assume that you want to be 95% confident that the sample percentage is within 2.5 per-\ncentage points of the true population percentage.\na. Assume that nothing is known about the percentage of adults who believe that passwords \nshould be replaced with biometric security.\nb. Assume that a prior survey suggests that about 53% of adults believe that biometric security \nshould replace passwords (based on a USA Today report).\nc. Does the additional survey information from part (b) have much of an effect on the sample \nsize that is required?\n 34. Nicotine Patches You plan to conduct a clinical trial to test the effectiveness of nicotine \npatch therapy in helping smokers to stop smoking. How many smokers must be included in \norder to be 99% confident that the estimate is in error by no more than two percentage points?\na. Assume that nothing is known about the effectiveness of nicotine patch therapy.\nb. Assume that a prior clinical trial suggests that nicotine patch therapy has a success rate of \nabout 45% (based on data from “High-Dose Nicotine Patch Therapy,” by Dale et al., Journal of \nthe American Medical Association, Vol. 274, No. 17).\nc. Does the additional survey information from part (b) have much of an effect on the sample \nsize that is required?\n 35. Vision Correction A manufacturing company is considering entering the new market of \neyeglasses. How many people must be surveyed in order to be 90% confident that the estimated \npercentage of adults who wear eyeglasses is within three percentage points of the true popula-\ntion percentage?\na. Assume that nothing is known about the percentage of adults who wear eyeglasses.\nb. Assume that about 53% of adults wear eyeglasses (based on a Vision Council prior survey).\nc. Given that the required sample size is relatively small, could you simply survey the adults \nthat you know?\n36. Women Who Give Birth An epidemiologist plans to conduct a survey to estimate the \npercentage of women who give birth. How many women must be surveyed in order to be 99% \nconfident that the estimated percentage is in error by no more than two percentage points?\na. Assume that nothing is known about the percentage to be estimated.\ncontinued\n\n7-2 Estimating a Population Mean \n299\nb. Assume that a prior study conducted by the U.S. Census Bureau showed that 82% of women \ngive birth.\nc. What is wrong with surveying randomly selected adult women?\n37. Finite Population Correction Factor For Formulas 7-2 and 7-3 we assume that the pop-\nulation is infinite or very large and that we are sampling with replacement. When we sample \nwithout replacement from a relatively small population with size N, we modify E to include \nthe finite population correction factor shown here, and we can solve for n to obtain the result \nshown below. Use this result to repeat part (b) of Exercise 36, assuming that we limit our popu-\nlation to a county with 2500 women who have completed the time during which they can give \nbirth.\nE = za>2 B\npnqn\nn\n B\nN - n\nN - 1   n =\nNpnqn3za>242\npnqn 3za>242 + 1N - 12E2\n38. One-Sided Confidence Interval A one-sided claim about a population proportion is a \nclaim that the proportion is less than (or greater than) some specific value. Such a claim can \nbe formally addressed using a one-sided confidence interval for p, which can be expressed as \np 6 pn + E or p 7 pn - E, where the margin of error E is modified by replacing za>2 with \nza. (Instead of dividing a between two tails of the standard normal distribution, put all of it in \none tail.) Use the data given in Exercise 13 “OxyContin” to construct a one-sided 95% confi-\ndence interval that would be suitable for addressing the claim that the rate of headaches among \n OxyContin users is less than 10%.\n39. Coping with No Success According to the Rule of Three, when we have a sample size \nn with x = 0 successes, we have 95% confidence that the true population proportion has an \nupper bound of 3>n. (See “A Look at the Rule of Three,” by Jovanovic and Levy, American \nStatistician, Vol. 51, No. 2.)\na. If n independent trials result in no successes, why can’t we find confidence interval limits by \nusing the methods described in this section?\nb. If 40 couples use a method of gender selection and each couple has a baby girl, what is the \n95% upper bound for p, the proportion of all babies who are boys?\n7-1 Beyond the Basics \nKey Concept The main goal of this section is to present methods for using a sample \nmean x to make an inference about the value of the corresponding population mean m.\nThere are three main concepts included in this section:\n \n■Point Estimate: The sample mean x is the best point estimate (or single value \nestimate) of the population mean m.\n \n■Confidence Interval: Use sample data to construct and interpret a confidence \ninterval estimate of the true value of a population mean m.\n \n■Sample Size: Find the sample size necessary to estimate a population mean.\nPart 1 of this section deals with the very realistic and commonly used case in which \nwe want to estimate m and the population standard deviation s is not known. Part 2 \nincludes a brief discussion of the procedure used when s is known, which is very rare.\n7-2 \nEstimating a Population Mean\n\n300 \nCHAPTER 7 Estimating Parameters and Determining Sample Sizes\nPART 1\nEstimating a Population Mean When S\nIs Not Known \nIt’s rare that we want to estimate the unknown value of a population mean m but we \nsomehow know the value of the population standard deviation s, so Part 1 focuses on \nthe realistic situation in which s is not known.\nPoint Estimate As discussed in Section 6-3, the sample mean x is an unbiased es-\ntimator of the population mean m. Also, for many populations, sample means tend to \nvary less than other measures of center. For these reasons, the sample mean x is usu-\nally the best point estimate of the population mean m.\nThe sample mean x is the best point estimate of the population mean M.\nBecause even the best point estimate gives us no indication of how accurate it is, we \nuse a confidence interval (or interval estimate), which consists of a range (or an inter-\nval) of values instead of just a single value.\nConfidence Interval The accompanying Key Elements box includes the key ele-\nments for constructing a confidence interval estimate of a population mean m in the \ncommon situation where s is not known.\nConfidence Interval for Estimating a Population Mean with s Not Known\nObjective\nConstruct a confidence interval used to estimate a population mean.\nNotation\nm = population mean \nn = number of sample values\nx = sample mean \nE = margin of error\ns = sample standard deviation\nRequirements\nKEY ELEMENTS\n1. The sample is a simple random sample.\n2. Either or both of these conditions are satisfied: The \npopulation is normally distributed or n 7 30.\nConfidence Interval\nFormats: x - E 6 m 6 x + E  or  x { E  or  \n1x - E, x + E2\n • Margin of Error: E = ta>2 #\ns\n1n (Use df = n - 1.)\n • Confidence Level: The confidence interval is associ-\nated with a confidence level, such as 0.95 (or 95%), \nand a is the complement of the confidence level. For \na 0.95 (or 95%) confidence level, a = 0.05.\n • Critical Value: ta>2 is the critical t value separating an \narea of a>2 in the right tail of the Student t distribution.\n • Degrees of Freedom: df = n - 1 is the number of \ndegrees of freedom. Used when finding the critical \nvalue.\nRound-Off Rule\n1. Original Data: When using an original set of data val-\nues, round the confidence interval limits to one more \ndecimal place than is used for the original set of data.\n2. Summary Statistics: When using the summary statistics \nof n, x, and s, round the confidence interval limits to the \nsame number of decimal places used for the sample mean.\n\n7-2 Estimating a Population Mean \n301\nRequirement of “Normality or n + 30”\nNormality The method for finding a confidence interval estimate of m is robust \nagainst a departure from normality, which means that the normality requirement is \nloose. The distribution need not be perfectly bell-shaped, but it should appear to be \nsomewhat symmetric with one mode and no outliers.\nSample Size n + 30 This is a common guideline, but sample sizes of 15 to 30 are \nadequate if the population appears to have a distribution that is not far from being \nnormal and there are no outliers. For some population distributions that are extremely \nfar from normal, the sample size might need to be larger than 30. This text uses the \nsimplified criterion of n 7 30 as justification for treating the distribution of sample \nmeans as a normal distribution.\nStudent t Distribution\nIn this section we use a Student t distribution, which is commonly referred to as a t distri-\nbution. It was developed by William Gosset (1876–1937), who was a Guinness Brewery \nemployee who needed a distribution that could be used with small samples. The brewery \nprohibited publication of research results, but Gosset got around this by publishing under \nthe pseudonym “Student.” Here are some key points about the Student t distribution:\n \n■Student t Distribution If a population has a normal distribution, then the distri-\nbution of\nt = x - m\ns\n1n\nis a Student t distribution for all samples of size n. A Student t distribution is \ncommonly referred to as a t distribution.\n \n■Degrees of Freedom Finding a critical value ta>2 requires a value for the degrees \nof freedom (or df). In general, the number of degrees of freedom for a collection \nof sample data is the number of sample values that can vary after certain restric-\ntions have been imposed on all data values. (Example: If 10 test scores have the \nrestriction that their mean is 80, then their sum must be 800, and we can freely \nassign values to the first 9 scores, but the 10th score would then be determined, \nso in this case there are 9 degrees of freedom.) For the methods of this section, \nthe number of degrees of freedom is the sample size minus 1.\nDegrees of freedom = n −1\n \n■Finding Critical Value tA,2 A critical value ta>2 can be found using technology \nor Table A-3. Technology can be used with any number of degrees of freedom, \nbut Table A-3 can be used for select numbers of degrees of freedom only. If using \nTable A-3 to find a critical value of ta>2, but the table does not include the exact \nnumber of degrees of freedom, you could use the closest value, or you could be \nconservative by using the next lower number of degrees of freedom found in the \ntable, or you could interpolate.\n \n■The Student t distribution is different for different sample sizes. (See Figure 7-4 \non the next page for the cases n = 3 and n = 12.)\n \n■The Student t distribution has the same general symmetric bell shape as the stan-\ndard normal distribution, but has more variability (with wider distributions), as \nwe expect with small samples.\n \n■The Student t distribution has a mean of t = 0 (just as the standard normal distri-\nbution has a mean of z = 0).\nst\nis\nbe \nre\nEstimating Wildlife \nPopulation Sizes\nThe National \nForest Man-\nagement \nAct protects \nendangered \nspecies, includ-\ning the northern \nspotted owl, \nwith the result that the for-\nestry industry was not allowed \nto cut vast regions of trees in \nthe Pacific Northwest. Biologists \nand statisticians were asked to \nanalyze the problem, and they \nconcluded that survival rates and \npopulation sizes were decreas-\ning for the female owls, known to \nplay an important role in species \nsurvival. Biologists and statisti-\ncians also studied salmon in the \nSnake and Columbia rivers in \nWashington State, and penguins \nin New Zealand. In the article \n“Sampling Wildlife Popula-\ntions” (Chance, Vol. 9, No. 2), \nauthors Bryan Manly and Lyman \nMcDonald comment that in such \nstudies, “biologists gain through \nthe use of modeling skills that are \nthe hallmark of good statistics. \nStatisticians gain by being intro-\nduced to the reality of problems \nby biologists who know what the \ncrucial issues are.”\n\n302 \nCHAPTER 7 Estimating Parameters and Determining Sample Sizes\n \n■The standard deviation of the Student t distribution varies with the sample size, \nbut it is greater than 1 (unlike the standard normal distribution, which has s = 1).\n \n■As the sample size n gets larger, the Student t distribution gets closer to the stan-\ndard normal distribution.\n0\nStandard\nnormal\ndistribution\nStudent t\ndistribution\nwith n 5 12\nStudent t\ndistribution\nwith n 5 3\nFIGURE 7-4 Student t Distributions for n = 3 and n = 12\nThe Student t distribution has the same general shape and \nsymmetry as the standard normal distribution, but it has the \ngreater variability that is expected with small samples.\nProcedure for Constructing a Confidence Interval for M\nConfidence intervals can be easily constructed with technology or they can be manu-\nally constructed by using the following procedure.\n1. Verify that the two requirements are satisfied: The sample is a simple random \nsample and the population is normally distributed or n 7 30.\n2. With s unknown (as is usually the case), use n - 1 degrees of freedom and use \ntechnology or a t distribution table (such as Table A-3) to find the critical value \nta>2 that corresponds to the desired confidence level.\n3. Evaluate the margin of error using E = ta>2 # s> 1n.\n4. Using the value of the calculated margin of error E and the value of the sample \nmean x, substitute those values in one of the formats for the confidence inter-\nval: x - E 6 m 6 x + E or x { E or \n1x - E, x + E2.\n5. Round the resulting confidence interval limits as follows: With an original \nset of data values, round the confidence interval limits to one more decimal \nplace than is used for the original set of data, but when using the summary \nstatistics of n, x, and s, round the confidence interval limits to the same \nnumber of decimal places used for the sample mean.\nEXAMPLE 1  Finding a Critical Value tA,2\nFind the critical value ta>2 corresponding to a 95% confidence level given that the \nsample has size n = 15.\nSOLUTION\nBecause n = 15, the number of degrees of freedom is n - 1 = 14. The 95% confi-\ndence level corresponds to a = 0.05, so there is an area of 0.025 in each of the two \ntails of the t distribution, as shown in Figure 7-5.\ncontinued\n\n7-2 Estimating a Population Mean \n303\nUsing Technology Technology can be used to find that for 14 degrees of freedom \nand an area of 0.025 in each tail, the critical value is ta>2 = t0.025 = 2.145.\nUsing Table A-3 To find the critical value using Table A-3, use the column with \n0.05 for the “Area in Two Tails” (or use the same column with 0.025 for the “Area \nin One Tail”). The number of degrees of freedom is df = n - 1 = 14. We get \nta>2 = t0.025 = 2.145.\nt 5 0\nta/2 5 2.145\n 0.025\n 0.025\nFIGURE 7-5 Critical Value tA,2\nEXAMPLE 2  Confidence Interval Using Birth Weights\nListed below are weights (hectograms, or hg) of randomly selected girls at birth, \nbased on data from the National Center for Health Statistics. Here are the summary \nstatistics: n = 15, x = 30.9 hg, s = 2.9 hg. Use the sample data to construct a \n95% confidence interval for the mean birth weight of girls.\n33 28 33 37 31 32 31 28 34 28 33 26 30 31 28\nSOLUTION\nREQUIREMENT CHECK We must first verify that the requirements are satisfied.  \n(1) The sample is a simple random sample. (2) Because the sample size is n = 15, \nthe requirement that “the population is normally distributed or the sample size is \ngreater than 30” can be satisfied only if the sample data appear to be from a  \nnormally distributed population, so we need to investigate normality. The accompa-\nnying normal quantile plot shows that the sample data appear to be from a normally \ndistributed population, so this second requirement is satisfied. \ncontinued\n\n304 \nCHAPTER 7 Estimating Parameters and Determining Sample Sizes\nInterpreting the Confidence Interval The confidence interval is associated with \na confidence level, such as 0.95 (or 95%). When interpreting a confidence interval \nestimate of μ, know that the confidence level gives us the success rate of the procedure \nused to construct the confidence interval. For example, the 95% confidence interval \nestimate of 29.2 hg 6 m 6 32.5 hg can be interpreted as follows:\n“We are 95% conﬁdent that the interval from 29.2 hg to 32.5 hg actually \ndoes contain the true value of M.”\nBy “95% confident” we mean that if we were to select many different samples of the \nsame size and construct the corresponding confidence intervals, in the long run, 95% \nof the confidence intervals should actually contain the value of m.\nFinding a Point Estimate and Margin of Error E from a Confidence Interval\nTechnology and journal articles often express a confidence interval in a format such \nas (10.0, 30.0). The sample mean x is the value midway between those limits, and the \nUsing Technology Technology can be used to automatically construct the confi-\ndence interval. Shown here is the StatCrunch display resulting from the 15 birth \nweights. The display shows the lower confidence interval limit (29.247163) and \nthe upper confidence interval limit (32.486171). After rounding to one decimal \nplace (as in the sample mean), we can express the 95% confidence interval as \n29.2 hg 6 m 6 32.5 hg.\n StatCrunch\nUsing t Distribution Table Using Table A-3, the critical value is t0.025 = 2.145 as \nshown in Example 1. We now find the margin of error E as shown here:\nE = ta>2\n s\n1n = 2.145 # 2.9\n115 = 1.606126\nWith x = 30.9 hg and E = 1.606126 hg, we construct the confidence interval as \nfollows:\n x - E 6 m 6 x + E\n 30.9 - 1.606126 6 m 6 30.9 + 1.606126\n 29.3 hg 6 m 6 32.5 hg     1rounded to one decimal place2\nThe lower confidence interval limit of 29.3 hg is actually 29.2 hg if we use technol-\nogy or if we use summary statistics with more decimal places than the one decimal \nplace used in the preceding calculation.\nINTERPRETATION\nWe are 95% confident that the limits of 29.2 hg and 32.5 hg actually do contain \nthe value of the population mean m. If we were to collect many different random \nsamples of 15 newborn girls and find the mean weight in each sample, about 95% \nof the resulting confidence intervals should contain the value of the mean weight of \nall newborn girls.\nEstimating Sugar in \nOranges\nIn Florida, \nmembers \nof the citrus \nindustry make \nextensive use \nof statistical \nmethods. One \nparticular application involves the \nway in which growers are paid \nfor oranges used to make orange \njuice. An arriving truckload of \noranges is first weighed at the re-\nceiving plant, and then a sample \nof about a dozen oranges is \nrandomly selected. The sample is \nweighed and then squeezed, and \nthe amount of sugar in the juice \nis measured. Based on the sam-\nple results, an estimate is made \nof the total amount of sugar in \nthe entire truckload. Payment \nfor the load of oranges is based \non the estimate of the amount of \nsugar because sweeter oranges \nare more valuable than those less \nsweet, even though the amounts \nof juice may be the same.\ni\nl\nli\ni\n\n7-2 Estimating a Population Mean \n305\nmargin of error E is one-half the difference between those limits (because the upper \nlimit is x + E and the lower limit is x - E, the distance separating them is 2E).\nPoint estimate of m:   x = 1upper confidence limit2 + 1lower confidence limit2\n2\nMargin of error:     E = 1upper confidence limit2 - 1lower confidence limit2\n2\nFor example, the confidence interval (10.0, 30.0) yields x = 20.0 and E = 10.0.\nUsing Confidence Intervals to Describe, Explore, or Compare Data\nIn some cases, confidence intervals might be among the different tools used to \ndescribe, explore, or compare data sets, as in the following example.\nEXAMPLE 3  Second-Hand Smoke\nFigure 7-6 shows graphs of confidence interval estimates of the mean cotinine level \nin each of three samples: (1) people who smoke; (2) people who don’t smoke but \nare exposed to tobacco smoke at home or work; (3) people who don’t smoke and \nare not exposed to smoke. (The sample data are listed in Data Set 14 “Passive and \nActive Smoke” in Appendix B.) Because cotinine is produced by the body when \nnicotine is absorbed, cotinine is a good indication of nicotine intake. Figure 7-6 \nhelps us see the effects of second-hand smoke. In Figure 7-6, we see that the con-\nfidence interval for smokers does not overlap the other confidence intervals, so it \nappears that the mean cotinine level of smokers is different from that of the other \ntwo groups. The two nonsmoking groups have confidence intervals that do overlap, \nso it is possible that they have the same mean cotinine level. It is helpful to compare \nconfidence intervals or their graphs, but such comparisons should not be used for \nmaking formal and final conclusions about equality of means. Chapters 9 and 12 \nintroduce better methods for formal comparisons of means.\n225\n0\n25\n50\n75\n100\n125\n150\n175\n200\n225\nCotinine (ng/mL)\nPeople not exposed to smoke\nSmokers\nPeople  exposed to smoke\nFIGURE 7-6 Comparing Confidence Intervals\nCAUTION Confidence intervals can be used informally to compare different data \nsets, but the overlapping of  confidence intervals should not be used for making \nformal and final conclusions about equality of  means.\nDetermining Sample Size\nIf we want to collect a sample to be used for estimating a population mean m, how \nmany sample values do we need? When determining the sample size needed to esti-\nmate a population mean, we must have an estimated or known value of the population \nstandard deviation s, so that we can use Formula 7-4 shown in the accompanying Key \nElements box.\n\n306 \nCHAPTER 7 Estimating Parameters and Determining Sample Sizes\nPopulation Size Formula 7-4 does not depend on the size (N) of the population (ex-\ncept for cases in which a relatively large sample is selected without replacement from \na finite population).\nRounding The sample size must be a whole number because it is the number of sam-\nple values that must be found, but Formula 7-4 usually gives a result that is not a \nwhole number. The round-off rule is based on the principle that when rounding is \nnecessary, the required sample size should be rounded upward so that it is at least ad-\nequately large instead of being slightly too small.\nDealing with Unknown S When Finding Sample Size Formula 7-4 requires that \nwe substitute a known value for the population standard deviation s, but in reality, \nit is usually unknown. When determining a required sample size (not constructing a \nconfidence interval), here are some ways that we can work around the problem of not \nknowing the value of s:\n1. Use the range rule of thumb (see Section 3-2) to estimate the standard deviation \nas follows: s ≈range>4, where the range is determined from sample data. \n(With a sample of 87 or more values randomly selected from a normally distrib-\nuted population, range>4 will yield a value that is greater than or equal to s at \nleast 95% of the time.)\n2. Start the sample collection process without knowing s and, using the first \nseveral values, calculate the sample standard deviation s and use it in place of \ns. The estimated value of s can then be improved as more sample data are \nKEY ELEMENTS\nFinding the Sample Size Required to Estimate a Population Mean\nObjective\nDetermine the sample size n required to estimate the value of a population mean m.\nNotation\nm = population mean\ns = population standard deviation\nx = sample mean\nE = desired margin of error\nza>2 = z score separating an area of a>2 in the right \n   tail of the standard normal distribution\nRequirement\nThe sample must be a simple random sample.\nSample Size\nThe required sample size is found by using Formula 7-4.\nFORMULA 7-4    n = c\nza>2s\nE\nd\n2\nRound-Off Rule\nIf the computed sample size n is not a whole number, round the value of n up to the next larger whole number.\n\n7-2 Estimating a Population Mean \n307\nobtained, and the required sample size can be adjusted as you collect more \nsample data.\n3. Estimate the value of s by using the results of some other earlier study. In \naddition, we can sometimes be creative in our use of other known results. \nFor example, Wechsler IQ tests are designed so that the standard deviation \nis 15. Biostatistics students have IQ scores with a standard deviation less \nthan 15, because they are a more homogeneous group than people randomly \nselected from the general population. We do not know the specific value \nof s for Biostatistics students, but we can be safe by using s = 15. Using \na value for s that is larger than the true value will make the sample size \nlarger than necessary, but using a value for s that is too small would result \nin a sample size that is inadequate. When determining the sample size n, \nany errors should always be conservative in the sense that they make the \nsample size too large instead of too small.\nEXAMPLE 4  IQ Scores of Smokers\nAssume that we want to estimate the mean IQ score for the population of adults \nwho smoke. How many smokers must be randomly selected for IQ tests if we want \n95% confidence that the sample mean is within 3 IQ points of the population mean?\nSOLUTION\nFor a 95% confidence interval, we have a = 0.05, so za>2 = 1.96. Because we \nwant the sample mean to be within 3 IQ points of m, the margin of error is E = 3. \nAlso, we can assume that s = 15 (see the discussion that immediately precedes \nthis example). Using Formula 7-4, we get\nn = c\nza>2s\nE\nd\n2\n= c 1.96 # 15\n3\nd\n2\n= 96.04 = 97 1rounded up2\nINTERPRETATION\nAmong the thousands of adults who smoke, we need to obtain a simple random \nsample of at least 97 of their IQ scores. With a simple random sample of only 97 \nadult smokers, we will be 95% confident that the sample mean x is within 3 IQ \npoints of the true population mean m.\nPART 2\nEstimating a Population Mean  \nWhen S Is Known \nIn the real world of professional statisticians and professional journals and reports, it \nis extremely rare that we want to estimate an unknown value of a population mean m \nbut we somehow know the value of the population standard deviation s. If we some-\nhow do know the value of s, the confidence interval is constructed using the standard \nnormal distribution instead of the Student t distribution, so the same procedure from \nPart 1 can be used with this margin of error:\nMargin of error: E = za>2 # s\n1n 1used with known s2\n\n308\t\nChapter 7  Estimating Parameters and Determining Sample Sizes\nChoosing the Appropriate Distribution\nWhen constructing a confidence interval estimate of the population mean m, it is \nimportant to use the correct distribution. Table 7-1 summarizes the key points to \nconsider.\nExample 5   Confidence Interval Estimate of M with Known S\nUse the same 15 birth weights of girls given in Example 2, for which n = 15 \nand x = 30.9 hg. Construct a 95% confidence interval estimate of the mean birth \nweight of all girls by assuming that s is known to be 2.9 hg.\nsolution\nRequirement check  The requirements were checked in Example 2. The require-\nments are satisfied. \nWith a 95% confidence level, we have a = 0.05, and we get za>2 = 1.96 (as in \nExample 2 from Section 7-1). Using za>2 = 1.96, s = 2.9 hg, and n = 15, we find \nthe value of the margin of error E:\n E = za>2 # s\n1n\n = 1.96 # 2.9\n115 = 1.46760\nWith x = 30.9 and E = 1.46760, we find the 95% confidence interval as follows:\n x - E 6 m 6 x + E\n 30.9 - 1.46760 6 m 6 30.9 + 1.46760\n 29.4 hg 6 m 6 32.4 hg 1rounded to one decimal place2\nThe confidence interval found here using the normal distribution is slightly nar-\nrower than the confidence interval found using the t distribution in Example 2. \nBecause za>2 = 1.96 is smaller than ta>2 = 2.145, the margin of error E is smaller \nand the confidence interval is narrower. The critical value ta>2 is larger because the \nt distribution incorporates the greater amount of variation that we get with smaller \nsamples.\nRemember, this example illustrates the situation in which the population \nstandard deviation s is known, which is rare. The more realistic situation with s \nunknown is considered in Part 1 of this section.\nTable 7-1  Choosing Between Student t and z (Normal) Distributions\nConditions\nMethod\ns not known and normally distributed population\nor\ns not known and n 7 30\nUse Student t distribution.\ns known and normally distributed population\nor\ns known and n 7 30 (In reality, s is rarely \nknown.)\nUse normal (z) distribution.\nPopulation is not normally distributed and \nn … 30.\nUse the bootstrapping method (Section 7-4) \nor a nonparametric method.\n\n7-2 Estimating a Population Mean \n309\nMeans: Confidence Intervals & Sample Size Determination\nAccess tech instructions, videos, and data sets at www.TriolaStats.com\nTECH CENTER \nStatistical Literacy and Critical Thinking\nIn Exercises 1–3, refer to the accompanying screen display that results from measured \nhemoglobin levels (g , dL) in 100 randomly selected adult females. The confidence level of \n95% was used.\n7-2 Basic Skills and Concepts\nTI-83, 84 Plus\n1. Hemoglobin Refer to the accompanying screen display.\na. Express the confidence interval in the format that uses the “less than” symbol. If the original \nlisted data use two decimal places, round the confidence interval limits accordingly.\nb. Identify the best point estimate of m and the margin of error.\nc. In constructing the confidence interval estimate of m, why is it not necessary to confirm that \nthe sample data appear to be from a population with a normal distribution?\n2. Degrees of Freedom\na. What is the number of degrees of freedom that should be used for finding the critical \nvalue ta>2?\nb. Find the critical value ta>2 corresponding to a 95% confidence level.\nc. Give a brief general description of the number of degrees of freedom.\n3. Interpreting a Confidence Interval The results in the screen display are based on a 95% \nconfidence level. Write a statement that correctly interprets the confidence interval.\n4. Normality Requirement What does it mean when we say that the confidence interval \nmethods of this section are robust against departures from normality?\nUsing Correct Distribution. In Exercises 5–8, assume that we want to construct a confi-\ndence interval. Do one of the following, as appropriate: (a) Find the critical value tA,2,  \n(b) find the critical value zA,2, (c) state that neither the normal distribution nor the t distri-\nbution applies.\n5. Audiometry Confidence level is 95%, s is not known, and the normal quantile plot of \nmeasured right-ear hearing thresholds from 10 randomly selected adult females is shown on \nthe top of the next page.\ncontinued\n\n310 \nCHAPTER 7 Estimating Parameters and Determining Sample Sizes\n6. Vision Confidence level is 90%, s is not known, and the histogram of right-eye vision mea-\nsurements is obtained from a random sample of 61 adult males.\n7. Vision Confidence level is 99%, s = 24.8, and the histogram of 61 right-eye vision mea-\nsurements from a random sample of 61 adult males is shown in Exercise 6.\n8. Birth Weights Here are summary statistics for randomly selected weights of newborn girls: \nn = 205, x = 30.4 hg, s = 7.1 hg (based on Data Set 3 “Births” in Appendix B). The confi-\ndence level is 95%.\nConfidence Intervals. In Exercises 9–24, construct the confidence interval estimate of \nthe mean.\n9. Birth Weights of Girls Use these summary statistics given in Exercise 8: n = 205,\nx = 30.4 hg, s = 7.1 hg. Use a 95% confidence level. Are the results very different from those \nfound in Example 2 with only 15 sample values?\n10. Birth Weights of Boys Use these summary statistics for birth weights of 195 boys: \nx = 32.7 hg, s = 6.6 hg (based on Data Set 3 “Births” in Appendix B). Use a 95% confidence \nlevel. Are the results very different from those found in Exercise 9? Does it appear that boys \nand girls have very different birth weights?\n11. Mean Body Temperature Data Set 2 “Body Temperatures” in Appendix B includes a \nsample of 106 body temperatures having a mean of 98.20°F and a standard deviation of 0.62°F. \nConstruct a 95% confidence interval estimate of the mean body temperature for the entire pop-\nulation. What does the result suggest about the common belief that 98.6°F is the mean body \ntemperature?\n12. Atkins Weight Loss Program In a test of weight loss programs, 40 adults used the \n Atkins weight loss program. After 12 months, their mean weight loss was found to be 2.1 lb, \nwith a standard deviation of 4.8 lb. Construct a 90% confidence interval estimate of the mean \nweight loss for all such subjects. Does the Atkins program appear to be effective? Does it ap-\npear to be practical?\n\n7-2 Estimating a Population Mean \n311\n 13. Insomnia Treatment A clinical trial was conducted to test the effectiveness of the drug \nzopiclone for treating insomnia in older subjects. Before treatment with zopiclone, 16 subjects \nhad a mean wake time of 102.8 min. After treatment with zopiclone, the 16 subjects had a mean \nwake time of 98.9 min and a standard deviation of 42.3 min (based on data from “Cognitive \nBehavioral Therapy vs Zopiclone for Treatment of Chronic Primary Insomnia in Older Adults,” \nby Sivertsen et al., Journal of the American Medical Association, Vol. 295, No. 24). Assume \nthat the 16 sample values appear to be from a normally distributed population and construct a \n98% confidence interval estimate of the mean wake time for a population with zopiclone treat-\nments. What does the result suggest about the mean wake time of 102.8 min before the treat-\nment? Does zopiclone appear to be effective?\n14. Garlic for Reducing Cholesterol In a test of the effectiveness of garlic for lowering cho-\nlesterol, 49 subjects were treated with raw garlic. Cholesterol levels were measured before and \nafter the treatment. The changes (before minus after) in their levels of low-density lipoprotein \n(LDL) cholesterol (in mg>dL) had a mean of 0.4 and a standard deviation of 21.0 (based on \ndata from “Effect of Raw Garlic vs Commercial Garlic Supplements on Plasma Lipid Concen-\ntrations in Adults with Moderate Hypercholesterolemia,” by Gardner et al., Archives of Internal \nMedicine, Vol. 167). Construct a 98% confidence interval estimate of the mean net change in \nLDL cholesterol after the garlic treatment. What does the confidence interval suggest about the \neffectiveness of garlic in reducing LDL cholesterol?\n15. Genes Samples of DNA are collected, and the four DNA bases of A, G, C, and T are \ncoded as 1, 2, 3, and 4, respectively. The results are listed below. Construct a 95% confidence \ninterval estimate of the mean. What is the practical use of the confidence interval?\n2 2 1 4 3 3 3 3 4 1\n16. Arsenic in Rice Listed below are amounts of arsenic (mg, or micrograms, per serving) in \nsamples of brown rice from California (based on data from the Food and Drug Administration). \nUse a 90% confidence level. The Food and Drug Administration also measured amounts of ar-\nsenic in samples of brown rice from Arkansas. Can the confidence interval be used to describe \narsenic levels in Arkansas?\n5.4 5.6 8.4 7.3 4.5 7.5 1.5 5.5 9.1 8.7\n17. Cell Phone Radiation Listed below are the measured radiation emissions (in W>kg) \ncorresponding to these cell phones: Samsung SGH-tss9, Blackberry Storm, Blackberry Curve, \nMotorola Moto, T-Mobile Sidekick, Sanyo Katana Eclipse, Palm Pre, Sony Ericsson, Nokia \n6085, Apple iPhone 3GS, Kyocera Neo E1100. The data are from the Environmental Working \nGroup. The media often present reports about the dangers of cell phone radiation as a cause of \ncancer. Construct a 90% confidence interval estimate of the population mean. What does the \nresult suggest about the Federal Communications Commission (FCC) standard that cell phone \nradiation must be 1.6 W>kg or less?\n0.38 0.55 1.54 1.55 0.50 0.60 0.92 0.96 1.00 0.86 1.46\n18. Lead in Medicine Listed below are the lead concentrations (in mg>g) measured in dif-\nferent Ayurveda medicines. Ayurveda is a traditional medical system commonly used in India. \nThe lead concentrations listed here are from medicines manufactured in the United States. The \ndata are based on the article “Lead, Mercury, and Arsenic in US and Indian Manufactured \nAyurvedic Medicines Sold via the Internet,” by Saper et al., Journal of the American Medical \nAssociation, Vol. 300, No. 8. Use the sample data to construct a 95% confidence interval esti-\nmate of the mean of the lead concentrations for the population of all such medicines. If a safety \nstandard requires lead concentrations less than 7 mg>g, does it appear that the population mean \nis less than that level?\n3.0 6.5 6.0 5.5 20.5 7.5 12.0 20.5 11.5 17.5\n19. Mercury in Sushi A Food and Drug Administration (FDA) guideline is that the mer-\ncury in fish should be below 1 part per million (ppm). Listed below are the amounts of mer-\ncury (ppm) found in tuna sushi sampled at different stores in New York City. The study was \ncontinued\n\n312 \nCHAPTER 7 Estimating Parameters and Determining Sample Sizes\nsponsored by the New York Times, and the stores (in order) are D’Agostino, Eli’s Manhattan, \nFairway, Food Emporium, Gourmet Garage, Grace’s Marketplace, and Whole Foods. Construct \na 98% confidence interval estimate of the mean amount of mercury in the population. Given \nthat the FDA guideline is that fish should have a maximum of 1 ppm of mercury, what does the \nconfidence interval suggest?\n0.56 0.75 0.10 0.95 1.25 0.54 0.88\n20. Years in College Listed below are the numbers of years it took for a random sample of \ncollege students to earn bachelor’s degrees (based on data from the National Center for Educa-\ntion Statistics). Construct a 95% confidence interval estimate of the mean time required for all \ncollege students to earn bachelor’s degrees. Does it appear that college students typically earn \nbachelor’s degrees in four years? Is there anything about the data that would suggest that the \nconfidence interval might not be a good result?\n4 4 4 4 4 4 4.5 4.5 4.5 4.5 4.5 4.5 6 6 8 9 9 13 13 15\n21. Caffeine in Soft Drinks Listed below are measured amounts of caffeine (mg per 12 oz of \ndrink) obtained in one can from each of 20 brands (7-UP, A&W Root Beer, Cherry Coke,…, \nTaB). Use a confidence level of 99%. Does the confidence interval give us good information \nabout the population of all cans of the same 20 brands that are consumed? Does the sample ap-\npear to be from a normally distributed population? If not, how are the results affected?\n0 0 34 34 34 45 41 51 55 36 47 41 0 0 53 54 38 0 41 47\n22. Shoveling Heart Rates Because cardiac deaths appear to increase after heavy snow-\nfalls, an experiment was designed to compare cardiac demands of snow shoveling to those \nof using an electric snow thrower. Ten subjects cleared tracts of snow using both meth-\nods, and their maximum heart rates (beats per minute, or BPM) were recorded during both \nactivities. The following results were obtained (based on data from “Cardiac Demands of \nHeavy Snow Shoveling,” by Franklin et al., Journal of the American Medical Association, \nVol. 273, No. 11):\nManual Snow Shoveling Maximum Heart Rates: n = 10, x = 175 BPM, s = 15 BPM\nElectric Snow Thrower Maximum Heart Rates: n = 10, x = 124 BPM, s = 18 BPM\na. Find the 95% confidence interval estimate of the population mean for those people who \nshovel snow manually.\nb. Find the 95% confidence interval estimate of the population mean for those people who use \nthe electric snow thrower.\nc. If you are a physician with concerns about cardiac deaths fostered by manual snow shovel-\ning, what single value in the confidence interval from part (a) would be of greatest concern?\nd. Compare the confidence intervals from parts (a) and (b) and interpret your findings.\n23. Echinacea Treatment In a study designed to test the effectiveness of echinacea for treat-\ning upper respiratory tract infections in children, 337 children were treated with echinacea and \n370 other children were given a placebo. The numbers of days of peak severity of symptoms \nfor the echinacea treatment group had a mean of 6.0 and a standard deviation of 2.3. The num-\nbers of days of peak severity of symptoms for the placebo group had a mean of 6.1 days and a \nstandard deviation of 2.4 days (based on data from “Efficacy and Safety of Echinacea in Treat-\ning Upper Respiratory Tract Infections in Children,” by Taylor et al., Journal of the American \nMedical Association, Vol. 290, No. 21).\na. Construct the 95% confidence interval for the mean number of days of peak severity of \nsymptoms for those who receive echinacea treatment.\nb. Construct the 95% confidence interval for the mean number of days of peak severity of \nsymptoms for those who are given a placebo.\nc. Compare the two confidence intervals. What do the results suggest about the effectiveness \nof echinacea?\n\n7-2 Estimating a Population Mean \n313\n24. Acupuncture for Migraines In a study designed to test the effectiveness of acupuncture \nfor treating migraine, 142 subjects were treated with acupuncture and 80 subjects were given \na sham treatment. The numbers of migraine attacks for the acupuncture treatment group had \na mean of 1.8 and a standard deviation of 1.4. The numbers of migraine attacks for the sham \ntreatment group had a mean of 1.6 and a standard deviation of 1.2.\na. Construct the 95% confidence interval estimate of the mean number of migraine attacks for \nthose treated with acupuncture.\nb. Construct the 95% confidence interval estimate of the mean number of migraine attacks for \nthose given a sham treatment.\nc. Compare the two confidence intervals. What do the results suggest about the effectiveness \nof acupuncture?\nAppendix B Data Sets. In Exercises 25 and 26, use the Appendix B data sets to construct \nthe confidence interval estimates of the mean.\n25. Pulse Rates Refer to Data Set 1 “Body Data” in Appendix B and construct a 95% con-\nfidence interval estimate of the mean pulse rate of adult females; then do the same for adult \nmales. Compare the results.\n26. Nicotine in Cigarettes Refer to Data Set 15 “Cigarette Contents” in Appendix B and as-\nsume that the samples are simple random samples obtained from normally distributed popula-\ntions.\na. Construct a 95% confidence interval estimate of the mean amount of nicotine in cigarettes \nthat are king size, non-filtered, non-menthol, and non-light.\nb. Construct a 95% confidence interval estimate of the mean amount of nicotine in cigarettes \nthat are 100 mm, filtered, non-menthol, and non-light.\nc. Compare the results. Do filters on cigarettes appear to be effective?\nSample Size. In Exercises 27–34, find the sample size required to estimate the population \nmean.\n27. Mean IQ of Nurses The Wechsler IQ test is designed so that the mean is 100 and the \nstandard deviation is 15 for the population of normal adults. Find the sample size necessary to \nestimate the mean IQ score of nurses. We want to be 99% confident that our sample mean is \nwithin 4 IQ points of the true mean. The mean for this population is clearly greater than 100. \nThe standard deviation for this population is less than 15 because it is a group with less varia-\ntion than a group randomly selected from the general population; therefore, if we use s = 15 \nwe are being conservative by using a value that will make the sample size at least as large as \nnecessary. Assume then that s = 15 and determine the required sample size. Does the sample \nsize appear to be practical?\n28. Mean IQ of Psychologists See the preceding exercise, in which we can assume that \ns = 15 for the IQ scores. Psychologists are a group with IQ scores that vary less than the IQ \nscores of the general population. Find the sample size needed to estimate the mean IQ of psy-\nchologists, given that we want 98% confidence that the sample mean is within 3 IQ points of \nthe population mean. Does the sample size appear to be practical?\n29. Mean Grade-Point Average Assume that all grade-point averages are to be standard-\nized on a scale between 0 and 4. How many grade-point averages must be obtained so that the \nsample mean is within 0.01 of the population mean? Assume that a 95% confidence level is de-\nsired. If we use the range rule of thumb, we can estimate s to be range>4 = 14 - 02>4 = 1.\nDoes the sample size seem practical?\n30. Mean Weight of Male Medical Students Data Set 1 “Body Data” in Appendix B in-\ncludes weights of 153 randomly selected adult males, and those weights have a standard de-\nviation of 17.65 kg. Because it is reasonable to assume that weights of male medical students \ncontinued\n\n314 \nCHAPTER 7 Estimating Parameters and Determining Sample Sizes\nhave less variation than weights of the population of adult males, we can be conservative by \nletting s = 17.65 kg. How many male medical students must be weighed in order to estimate \nthe mean weight of all male medical students? Assume that we want 90% confidence that the \nsample mean is within 1.5 kg of the population mean. Does it seem reasonable to assume that \nweights of male medical students have less variation than weights of the population of adult \nmales?\n31. Mean Age of Female Medical Students Data Set 1 “Body Data” in Appendix B in-\ncludes ages of 147 randomly selected adult females, and those ages have a standard deviation \nof 17.7 years. Assume that ages of female medical students have less variation than ages of \nfemales in the general population, so let s = 17.7 years for the sample size calculation. How \nmany female medical student ages must be obtained in order to estimate the mean age of all \nfemale medical students? Assume that we want 95% confidence that the sample mean is within \none-half year of the population mean. Does it seem reasonable to assume that ages of female \nmedical students have less variation than ages of females in the general population?\n32. Mean Pulse Rate of Females Data Set 1 “Body Data” in Appendix B includes pulse \nrates of 147 randomly selected adult females, and those pulse rates vary from a low of 36 bpm \nto a high of 104 bpm. Find the minimum sample size required to estimate the mean pulse rate \nof adult females. Assume that we want 99% confidence that the sample mean is within 2 bpm \nof the population mean.\na. Find the sample size using the range rule of thumb to estimate s.\nb. Assume that s = 12.5 bpm, based on the value of s = 12.5 bpm for the sample of 147 \nfemale pulse rates.\nc. Compare the results from parts (a) and (b). Which result is likely to be better?\n33. Mean Pulse Rate of Males Data Set 1 “Body Data” in Appendix B includes pulse rates \nof 153 randomly selected adult males, and those pulse rates vary from a low of 40 bpm to a \nhigh of 104 bpm. Find the minimum sample size required to estimate the mean pulse rate of \nadult males. Assume that we want 99% confidence that the sample mean is within 2 bpm of the \npopulation mean.\na. Use the range rule of thumb to estimate s.\nb. Assume that s = 11.3 bpm, based on the value of s = 11.3 bpm for the sample of 153 male \npulse rates.\nc. Compare the results from parts (a) and (b). Which result is likely to be better?\n34. Mean Body Temperature Data Set 2 “Body Temperatures” in Appendix B includes 106 \nbody temperatures of adults for day 2 at 12 AM, and they vary from a low of 96.5°F to a high \nof 99.6°F. Find the minimum sample size required to estimate the mean body temperature of \nall adults. Assume that we want 98% confidence that the sample mean is within 0.1°F of the \npopulation mean.\na. Find the sample size using the range rule of thumb to estimate s.\nb. Assume that s = 0.62°F, based on the value of s = 0.62°F for the sample of 106 body \ntemperatures.\nc. Compare the results from parts (a) and (b). Which result is likely to be better?\n35. Finite Population Correction Factor If a simple random sample of size n is selected \nwithout replacement from a finite population of size N, and the sample size is more than 5% of \nthe population size 1n 7 0.05N2, better results can be obtained by using the finite population \ncorrection factor, which involves multiplying the margin of error E by 11N - n2>1N - 12. \n7-2 Beyond the Basics\ncontinued\n\n7-3 Estimating a Population Standard Deviation or Variance \n315\nFor a sample of 40 platelet counts of females from Data Set 1 “Body Data” in Appendix B, we \nget x = 255.1 and s = 65.4. All platelet counts are in 1000 cells>mL.\na. Construct a 95% confidence interval estimate of m assuming that the population is large.\nb. Construct a 95% confidence interval estimate of m assuming that the sample is selected \nwithout replacement from a population of 500 females.\nc. Compare the results.\nKey Concept This section presents methods for using a sample standard deviation s \n(or a sample variance s2) to estimate the value of the corresponding population stan-\ndard deviation s (or population variance s2). Here are the main concepts included in \nthis section:\n \n■Point Estimate: The sample variance s2 is the best point estimate (or single \nvalue estimate) of the population variance s2. The sample standard deviation s is \ncommonly used as a point estimate of s, even though it is a biased estimator, as \ndescribed in Section 6-3.\n \n■Confidence Interval: When constructing a confidence interval estimate of a \npopulation standard deviation (or population variance), we construct the con-\nfidence interval using the x2 distribution. (The Greek letter x is pronounced \n“kigh.”)\nChi-Square Distribution\nHere are key points about the x2(chi-square or chi-squared) distribution:\n \n■In a normally distributed population with variance s2, if we randomly select in-\ndependent samples of size n and, for each sample, compute the sample variance \ns2, the sample statistic x2 = 1n - 12s2>s2 has a sampling distribution called \nthe chi-square distribution, as shown in Formula 7-5.\n7-3 \nEstimating a Population Standard Deviation or Variance\nFORMULA 7-5\nx2 = 1n - 12s2\ns2\n \n■Critical Values of X2 We denote a right-tailed critical value by x2\nR and we de-\nnote a left-tailed critical value by x2\nL. Those critical values can be found by using \ntechnology or Table A-4, and they require that we first determine a value for the \nnumber of degrees of freedom.\n \n■Degrees of Freedom For the methods of this section, the number of degrees of \nfreedom is the sample size minus 1.\nDegrees of freedom: df = n −1\ncontinued\n\n316 \nCHAPTER 7 Estimating Parameters and Determining Sample Sizes\n \n■The chi-square distribution is skewed to the right, unlike the normal and Student \nt distributions (see Figure 7-7).\n \n■The values of chi-square can be zero or positive, but they cannot be negative, as \nshown in Figure 7-7.\n \n■The chi-square distribution is different for each number of degrees of freedom, \nas illustrated in Figure 7-8. As the number of degrees of freedom increases, the \nchi-square distribution approaches a normal distribution.\nNot symmetric\nAll values are nonnegative\n0\nx2\nFIGURE 7-7 Chi-Square Distribution\n0\n5\n10\n15\n20\n25\n30\n35\n40\n45\nx2\ndf 5 10\ndf 5 20\nFIGURE 7-8  Chi-Square Distribution for \ndf = 10 and df = 20\nBecause the chi-square distribution is not symmetric, a confidence interval esti-\nmate of s2 does not fit a format of s2 - E 6 s2 6 s2 + E, so we must do separate \ncalculations for the upper and lower confidence interval limits. If using Table A-4 for \nfinding critical values, note the following design feature of that table:\nIn Table A-4, each critical value of X2 in the body of the table corresponds \nto an area given in the top row of the table, and each area in that top row \nis a cumulative area to the right of the critical value.\nCAUTION Table A-2 for the standard normal distribution provides cumulative areas \nfrom the left, but Table A-4  for the chi-square distribution uses cumulative areas \nfrom the right.\nEXAMPLE 1  Finding Critical Values of X2\nA simple random sample of 22 IQ scores is obtained (as in Example 2, which fol-\nlows). Construction of a confidence interval for the population standard deviation s \nrequires the left and right critical values of x2 corresponding to a confidence level \nof 95% and a sample size of n = 22. Find x2\nL (the critical value of x2 separating an \narea of 0.025 in the left tail), and find x2\nR (the critical value of x2 separating an area \nof 0.025 in the right tail).\nSOLUTION\nWith a sample size of n = 22, the number of degrees of freedom is df = n - 1 = 21.\nSee Figure 7-9.\n\n7-3 Estimating a Population Standard Deviation or Variance \n317\nWhen obtaining critical values of x2 from Table A-4, if a number of degrees of \nfreedom is not found in the table, you can be conservative by using the next lower \nnumber of degrees of freedom, or you can use the closest critical value in the table, \nor you can get an approximate result with interpolation. For numbers of degrees of \nfreedom greater than 100, use the equation given in Exercise 23 on page 324, or use a \nmore extensive table, or use technology.\nAlthough s2 is the best point estimate of s2, there is no indication of how good \nit is, so we use a confidence interval that gives us a range of values associated with a \nconfidence level.\n0\nx2\nL 5 10.283\nx2\nR 5 35.479\nx2\n(df 5 21)\n 0.025\n 0.025\nTable A-4:\nUse df 5 21 and\na cumulative right\narea of 0.975.\nTable A-4:\nUse df 5 21 and\na cumulative right\narea of 0.025.\nFIGURE 7-9 Finding Critical Values of X2\nThe critical value to the right 1x2\nR = 35.4792 is obtained from Table A-4  in \na straightforward manner by locating 21 in the degrees-of-freedom column at the \nleft and 0.025 across the top row. The leftmost critical value of x2\nL = 10.283 also \ncorresponds to 21 in the degrees-of-freedom column, but we must locate 0.975 (or \n1 - 0.025) across the top row because the values in the top row are always areas \nto the right of the critical value. Refer to Figure 7-9 and see that the total area to the \nright of x2\nL = 10.283 is 0.975.\nConfidence Interval for Estimating a Population Standard Deviation or Variance\nObjective\nConstruct a confidence interval estimate of a population standard deviation or variance.\nNotation\ns = population standard deviation \ns2 = population variance\ns = sample standard deviation \ns2 = sample variance\nn = number of sample values \nE = margin of error\nx2\nL = left-tailed critical value of x2 \nx2\nR = right-tailed critical value of x2\nKEY ELEMENTS\ncontinued\n\n318 \nCHAPTER 7 Estimating Parameters and Determining Sample Sizes\nProcedure for Constructing a Confidence Interval for S or S2\nConfidence intervals can be easily constructed with technology or they can be con-\nstructed by using Table A-4 with the following procedure.\n1. Verify that the two requirements are satisfied: The sample is a random sample \nfrom a normally distributed population.\n2. Using n - 1 degrees of freedom, find the critical values x2\nR and x2\nL that corre-\nspond to the desired confidence level (as in Example 1).\n3. Construct a confidence interval estimate of s2 by using the following:\n1n - 12s2\nx2\nR\n6 s2 6 1n - 12s2\nx2\nL\n4. To get a confidence interval estimate of s, take the square root of each compo-\nnent of the above confidence interval.\n5. Round the confidence interval limits using the round-off rule given in the \npreceding Key Elements box.\nUsing Confidence Intervals for Comparisons or Hypothesis Tests\nComparisons Confidence intervals can be used informally to compare the varia-\ntion in different data sets, but the overlapping of confidence intervals should not be \nRequirements\n1. The sample is a simple random sample.\n2. The population must have normally distributed values (even if the sample is large). The requirement of a normal \ndistribution is much stricter here than in earlier sections, so large departures from normal distributions can result in \nlarge errors. (If the normality requirement is not satisfied, use the bootstrap method described in Section 7-4.)\nConfidence Interval for the Population Variance S2\n1n - 12s2\nx2\nR\n6 s2 6 1n - 12s2\nx2\nL\nConfidence Interval for the Population Standard Deviation S\nB\n1n - 12s2\nx2\nR\n6 s 6 B\n1n - 12s2\nx2\nL\nRound-Off Rule\n1. Original Data: When using the original set of data values, round the confidence interval limits to one more decimal \nplace than is used for the original data.\n2. Summary Statistics: When using the summary statistics (n, s), round the confidence interval limits to the same num-\nber of decimal places used for the sample standard deviation.\nCAUTION A confidence interval can be expressed in a format such as  \n11.0 6 s 6 20.4 or a format of (11.0, 20.4), but it cannot be expressed in a format \nof s { E.\n\n7-3 Estimating a Population Standard Deviation or Variance \n319\nused for making formal and final conclusions about equality of variances or standard \ndeviations.\nEXAMPLE 2  Confidence Interval for Estimating S of IQ Scores\nData Set 8 “IQ and Lead” in Appendix B lists IQ scores for subjects in three differ-\nent lead exposure groups. The 22 full IQ scores for the group with medium expo-\nsure to lead (Group 2) have a standard deviation of 14.29263. Consider the sample \nto be a simple random sample and construct a 95% confidence interval estimate of \ns, the standard deviation of the population from which the sample was obtained.\nSOLUTION\nREQUIREMENT CHECK\nStep 1: Check requirements. (1) The sample can be treated as a simple random \nsample. (2) The accompanying histogram has a shape very close to the bell shape of \na normal distribution, so the requirement of normality is satisfied. \nMinitab\nStep 2: Using Technology The confidence interval can be found using technology. \nThe StatCrunch display shows the lower and upper confidence interval limits for \nthe 95% confidence interval estimate of s2, so we get 120.9 6 s2 6 417.2. Tak-\ning square roots, we get 11.0 6 s 6 20.4\nStatCrunch\nUsing Table A-4  If using Table A-4, we first use the sample size of n = 22 to \nfind degrees of freedom: df = n - 1 = 21. In Table A-4, refer to the row cor-\nresponding to 21 degrees of freedom, and refer to the columns with areas of 0.975 \nand 0.025. (For a 95% confidence level, we divide a = 0.05 equally between the \ntwo tails of the chi-square distribution, and we refer to the values of 0.975 and \n0.025 across the top row of Table A-4.) The critical values are x2\nL = 10.283 and \nx2\nR = 35.479 (as shown in Example 1).\ncontinued\n\n320 \nCHAPTER 7 Estimating Parameters and Determining Sample Sizes\nRationale for the Confidence Interval See Figure 7-9 on page 317 to make sense \nof this statement: If we select random samples of size n from a normally distrib-\nuted population with variance s2, there is a probability of 1 - a that the statistic \n1n - 12s2>s2 will fall between the critical values of x2\nL and x2\nR. It follows that there \nis a 1 - a probability that both of the following are true:\n1n - 12s2\ns2\n6 x2\nR and 1n - 12s2\ns2\n7 x2\nL\nMultiply both of the preceding inequalities by s2, then divide each inequality by the \nappropriate critical value of x2, so the two preceding inequalities can be expressed in \nthese equivalent forms:\n1n - 12s2\nx2\nR\n6 s2 and 1n - 12s2\nx2\nL\n7 s2\nThe two preceding inequalities can be combined into one inequality to get the format \nof the confidence interval used in this section:\n1n - 12s2\nx2\nR\n6 s2 6 1n - 12s2\nx2\nL\nDetermining Sample Size\nThe procedures for finding the sample size necessary to estimate s are much more \ncomplex than the procedures given earlier for means and proportions. For normally \ndistributed populations, Table 7-2 or the formula given in Exercise 24 “Finding Sam-\nple Size” on page 324 can be used.\nStep 3: Using the critical values of 10.283 and 35.479, the sample standard devia-\ntion of s = 14.29263, and the sample size of n = 22, we construct the 95% confi-\ndence interval by evaluating the following:\n 1n - 12s2\nx2\nR\n6 s2 6 1n - 12s2\nx2\nL\n 122 - 12114.292632 2\n35.479\n6 s2 6 122 - 12114.292632 2\n10.283\nStep 4: Evaluating the expression above results in 120.9 6 s2 6 417.2. Finding \nthe square root of each part (before rounding), then rounding to one decimal place, \nyields this 95% confidence interval estimate of the population standard deviation: \n11.0 6 s 6 20.4.\nINTERPRETATION\nBased on this result, we have 95% confidence that the limits of 11.0 and 20.4 contain \nthe true value of s. The confidence interval can also be expressed as (11.0, 20.4), but \nit cannot be expressed in a format of s { E.\nTABLE 7-2 Finding Sample Size\ns\n \nTo be 95%  \nconfident that \ns is within . . .\nof the value  \nof s, the sample \nsize n should be \nat least\n1%\n19,205\n5%\n768\n10%\n192\n20%\n48\n30%\n21\n40%\n12\n50%\n8\n \nTo be 99%  \nconfident that \ns is within . . .\nof the value  \nof s, the sample \nsize n should be \nat least\n1%\n33,218\n5%\n1,336\n10%\n336\n20%\n85\n30%\n38\n40%\n22\n50%\n14\n\n7-3 Estimating a Population Standard Deviation or Variance \n321\nEXAMPLE 3  Finding Sample Size for Estimating S\nWe want to estimate the standard deviation s of all IQ scores of people with exposure to \nlead. We want to be 99% confident that our estimate is within 5% of the true value of s. \nHow large should the sample be? Assume that the population is normally distributed.\nSOLUTION\nFrom Table 7-2, we can see that 99% confidence and an error of 5% for s corre-\nspond to a sample of size 1336. We should obtain a simple random sample of 1336 \nIQ scores from the population of subjects exposed to lead.\nConfidence Interval Estimate for Standard Deviation or Variance\nAccess tech instructions, videos, and data sets at www.TriolaStats.com\nTECH CENTER \nStatistical Literacy and Critical Thinking\n1. Brain Volume Using all of the brain volumes listed in Data Set 9 “IQ and Brain Size,” we get \nthis 95% confidence interval estimate: 9027.8 6 s2 6 33,299.8, and the units of measurement \nare (cm3)2. Identify the corresponding confidence interval estimate of s and include the appropri-\nate units. Given that the original values are whole numbers, round the limits using the round-off rule \ngiven in this section. Write a statement that correctly interprets the confidence interval estimate of s.\n2. Expressing Confidence Intervals Example 2 showed how the statistics of n = 22 and \ns = 14.3 result in this 95% confidence interval estimate of s: 11.0 6 s 6 20.4. That confi-\ndence interval can also be expressed as (11.0, 20.4), but it cannot be expressed as 15.7 { 4.7.\nGiven that 15.7 { 4.7 results in values of 11.0 and 20.4, why is it wrong to express the confi-\ndence interval as 15.7 { 4.7?\n3. Last Digit Analysis The accompanying dotplot depicts the last digits of the weights of \n153 males in Data Set 1 “Body Data.” Do those digits appear to be from a normally distributed \npopulation? If not, does the large sample size of n = 153 justify treating the values as if they \nwere from a normal distribution? Can the sample be used to construct a 95% confidence inter-\nval estimate of s for the population of all such digits?\n7-3  Basic Skills and Concepts\n4. Normality Requirement What is different about the normality requirement for a confidence \ninterval estimate of s and the normality requirement for a confidence interval estimate of m?\nFinding Critical Values and Confidence Intervals. In Exercises 5–8, use the given infor-\nmation to find the number of degrees of freedom, the critical values X2\nL and X2\nR, and the confi-\ndence interval estimate of S. The samples are from Appendix B and it is reasonable to assume \nthat a simple random sample has been selected from a population with a normal distribution.\n5. Nicotine in Menthol Cigarettes 95% confidence; n = 25, s = 0.24 mg.\n6. White Blood Cell Counts of Men 95% confidence; n = 153, s = 1.86.\n\n322 \nCHAPTER 7 Estimating Parameters and Determining Sample Sizes\n7. Platelet Counts of Women 99% confidence; n = 147, s = 65.4.\n8. Heights of Men 99% confidence; n = 153, s = 7.10 cm.\nFinding Confidence Intervals. In Exercises 9–16, assume that each sample is a simple \nrandom sample obtained from a population with a normal distribution.\n9. Body Temperature Data Set 2 “Body Temperatures” in Appendix B includes a sample of \n106 body temperatures having a mean of 98.20°F and a standard deviation of 0.62°F (for day 2 \nat 12 AM). Construct a 95% confidence interval estimate of the standard deviation of the body \ntemperatures for the entire population.\n10. Atkins Weight Loss Program In a test of weight loss programs, 40 adults used the Atkins \nweight loss program. After 12 months, their mean weight loss was found to be 2.1 lb, with \na standard deviation of 4.8 lb. Construct a 90% confidence interval estimate of the standard \ndeviation of the weight loss for all such subjects. Does the confidence interval give us informa-\ntion about the effectiveness of the diet?\n11. Insomnia Treatment A clinical trial was conducted to test the effectiveness of the drug zop-\niclone for treating insomnia in older subjects. After treatment with zopiclone, 16 subjects had a \nmean wake time of 98.9 min and a standard deviation of 42.3 min (based on data from “Cognitive \nBehavioral Therapy vs Zopiclone for Treatment of Chronic Primary Insomnia in Older Adults,” \nby Sivertsen et al., Journal of the American Medical Association, Vol. 295, No. 24). Assume that \nthe 16 sample values appear to be from a normally distributed population and construct a 98% \nconfidence interval estimate of the standard deviation of the wake times for a population with \nzopiclone treatments. Does the result indicate whether the treatment is effective?\n12. Garlic for Reducing Cholesterol In a test of the effectiveness of garlic for lowering cho-\nlesterol, 49 subjects were treated with raw garlic. Cholesterol levels were measured before and \nafter the treatment. The changes (before minus after) in their levels of LDL cholesterol (in mg>dL) \nhad a mean of 0.4 and a standard deviation of 21.0 (based on data from “Effect of Raw Garlic \nvs Commercial Garlic Supplements on Plasma Lipid Concentrations in Adults with Moderate \nHypercholesterolemia,” by Gardner et al., Archives of Internal Medicine, Vol. 167). Construct \na 98% confidence interval estimate of the standard deviation of the changes in LDL cholesterol \nafter the garlic treatment. Does the result indicate whether the treatment is effective?\n 13. World’s Smallest Mammal The world’s smallest mammal is the bumblebee bat, also \nknown as the Kitti’s hog-nosed bat (or Craseonycteris thonglongyai as it is affectionately \ncalled). Such bats are roughly the size of a large bumblebee. Listed below are weights (in \ngrams) from a sample of these bats. Construct a 95% confidence interval estimate of the stan-\ndard deviation of weights for all such bats.\n1.7 1.6 1.5 2.0 2.3 1.6 1.6 1.8 1.5 1.7 2.2 1.4 1.6 1.6 1.6\n 14. Queues A Providence Hospital experiment involves two different waiting line configura-\ntions for patients arriving for admission. The waiting times (in seconds) are recorded with a \nsingle-line configuration that feeds four stations and another configuration with individual lines \nat the four stations. Determine whether there is a difference in variation between the two data \nsets. Which configuration appears to be better?\n  Single Line\n  390  396  402  408  426  438  444  462  462  462 \n Individual Lines  252  324  348  372  402  462  462  510  558  600\n 15. Shoveling Heart Rates Because cardiac deaths appear to increase after heavy snowfalls, \nan experiment was designed to compare cardiac demands of snow shoveling to those of using an \nelectric snow thrower. Ten subjects cleared tracts of snow using both methods, and their maxi-\nmum heart rates (beats per minute, or BPM) were recorded during both activities. The results \nshown below were obtained (based on data from “Cardiac Demands of Heavy Snow Shoveling,” \nby Franklin et al., Journal of the American Medical Association, Vol. 273, No. 11).\n  Manual Snow Shoveling:  n = 10, x = 175 BPM, s = 15 BPM\n Electric Snow Thrower:  n = 10, x = 124 BPM, x = 124, s = 18 BPM\ncontinued\n\n7-3 Estimating a Population Standard Deviation or Variance \n323\na. Construct a 95% confidence interval estimate of the population standard deviation s for \nthose who did manual snow shoveling.\nb. Construct a 95% confidence interval estimate of the population standard deviation s for \nthose who used the automated electric snow thrower.\nc. Compare the results. Does the variation appear to be different for the two groups?\n16. Acupuncture for Migraines In a study designed to test the effectiveness of acupuncture \nfor treating migraine headaches, 142 subjects were treated with acupuncture and 80 subjects \nwere given a sham treatment. The numbers of migraine attacks for the acupuncture treatment \ngroup had a mean of 1.8 and a standard deviation of 1.4. The numbers of migraine attacks for \nthe sham treatment group had a mean of 1.6 and a standard deviation of 1.2. Construct a 95% \nconfidence interval estimate of s for each of the two groups, and then compare the results.\nLarge Data Sets from Appendix B. In Exercises 17 and 18, use the data set in \n Appendix B. Assume that each sample is a simple random sample obtained from a popula-\ntion with a normal distribution.\n17. Birth Length of Stay Refer to Data Set 3 “Births” in Appendix B.\na. Use the lengths of stay (days) for the 205 girls to construct a 95% confidence interval esti-\nmate of the standard deviation of the population from which the sample was obtained. For criti-\ncal values, use x2\nL = 166.337 and x2\nR = 245.449. Does the distribution of those data appear to \nbe approximately normal? How does that affect the results?\nb. Repeat part (a) using the 195 boys and, for critical values, use x2\nL = 157.321 and \nx2\nR = 234.465.\nc. Compare the results from part (a) and part (b).\n18. Birth Weights Refer to Data Set 3 “Births” in Appendix B\na. Use the 205 birth weights of girls to construct a 95% confidence interval estimate of the \nstandard deviation of the population from which the sample was obtained. For critical values, \nuse x2\nL = 166.337 and x2\nR = 245.449.\nb. Repeat part (a) using the 195 birth weights of boys and, for critical values, use x2\nL = 157.321 \nand x2\nR = 234.465.\nc. Compare the results from part (a) and part (b).\nDetermining Sample Size. In Exercises 19–22, assume that each sample is a simple ran-\ndom sample obtained from a normally distributed population. Use Table 7-2 on page 320 to \nfind the indicated sample size.\n 19. IQ of Biostatistics Professors You want to estimate s for the population of IQ scores \nof biostatistics professors. Find the minimum sample size needed to be 95% confident that the \nsample standard deviation s is within 1% of s. Is this sample size practical?\n20. ER Waiting Times You want to estimate s for the population of waiting times for hos-\npital emergency rooms. You want to be 99% confident that the sample standard deviation is \nwithin 1% of s. Find the minimum sample size. Is this sample size practical?\n21. Statistics Student Incomes You want to estimate the standard deviation of the annual \nincomes of all current statistics students. Find the minimum sample size needed to be 95% con-\nfident that the sample standard deviation is within 20% of the population standard deviation. \nAre those incomes likely to satisfy the requirement of a normal distribution?\n22. Aspirin Quality When attempting to verify the aspirin contents in manufactured tablets, \nyou must estimate the standard deviation of the population of aspirins in use. Find the mini-\nmum sample size needed to be 99% confident that the sample standard deviation is within 10% \nof the population standard deviation.\n\n324 \nCHAPTER 7 Estimating Parameters and Determining Sample Sizes\n23. Finding Critical Values In constructing confidence intervals for s or s2, Table A-4  can \nbe used to find the critical values x2\nL and x2\nR only for select values of n up to 101, so the number \nof degrees of freedom is 100 or smaller. For larger numbers of degrees of freedom, we can ap-\nproximate x2\nL and x2\nR by using\nx2 = 1\n23 {za>2 + 22k - 142\nwhere k is the number of degrees of freedom and za>2 is the critical z score described in Sec-\ntion 7-1. Use this approximation to find the 95% critical values x2\nL and x2\nR for the acupuncture \ntreatment group in Exercise 16 “Acupuncture for Migraines” where n = 142. How do the \nresults compare to the actual critical values of x2\nL = 110.020 and x2\nR = 175.765?\n24. Finding Sample Size Instead of using Table 7-2 for determining the sample size required \nto estimate a population standard deviation s, the following formula can be used:\nn = 1\n2\n a\nza>2\nd b\n2\nwhere za>2 corresponds to the confidence level and d is the decimal form of the percentage \n error. For example, to be 95% confident that s is within 15% of the value of s, use za>2 = 1.96\nand d = 0.15 to get a sample size of n = 86. Find the sample size required to estimate s, \n assuming that we want 98% confidence that s is within 15% of s.\n7-3 Beyond the Basics\nKey Concept The preceding sections presented methods for estimating population pro-\nportions, means, and standard deviations (or variances). All of those methods have certain \nrequirements that limit the situations in which they can be used. When some of the require-\nments are not satisfied, we can often use the bootstrap method to estimate a parameter with \na confidence interval. The bootstrap method typically requires the use of software.\nSampling Requirement The preceding methods of this chapter all have a require-\nment that the sample must be a simple random sample. If the sample is not collected \nin an appropriate way, there’s a good chance that nothing can be done to get a us-\nable confidence interval estimate of a parameter. Bootstrap methods do not correct for \npoor sampling methods.\nRequirements Listed below are important requirements from the preceding sections \nof this chapter:\n \n■CI for Proportion (Section 7-1): There are at least 5 successes and at least 5 \nfailures, or np Ú 5 and nq Ú 5.\n \n■CI for Mean (Section 7-2): The population is normally distributed or n 7 30.\n \n■CI for S or S2 (Section 7-3): The population must have normally distributed \nvalues, even if the sample is large.\nWhen the above requirements are not satisfied, we should not use the methods pre-\nsented in the preceding sections of this chapter, but we can use the bootstrap method \ninstead. The bootstrap method does not require large samples. This method does not \nrequire the sample to be collected from a normal or any other particular distribution, \nand so it is called a nonparametric or distribution-free method; other nonparamet-\nric methods are included in Chapter 13.\n7-4 \nBootstrapping: Using Technology for Estimates\n\n7-4 Bootstrapping: Using Technology for Estimates \n325\nWhy Is It Called “Bootstrap”? The term “bootstrap” is used because the data “pull \nthemselves up by their own bootstraps” to generate new data sets. In days of yore, \n“pulling oneself up by one’s bootstraps” meant that an impossible task was somehow \naccomplished, and the bootstrap method described in this section might seem impos-\nsible, but it works!\nHow Many? In the interest of providing manageable examples that don’t occupy mul-\ntiple pages each, the examples in this section involve very small data sets and no more \nthan 20 bootstrap samples, but we should use at least 1000 bootstrap samples when \nwe use bootstrap methods in serious applications. Professional statisticians commonly \nuse 10,000 or more bootstrap samples.\nBootstrap Procedure for a Confidence Interval Estimate of a Parameter\n1. Given a simple random sample of size n, obtain many (such as 1000 or more) \nbootstrap samples of the same size n.\n2. For the parameter to be estimated, find the corresponding statistic for each \nof the bootstrap samples. (Example: For a confidence estimate of m, find the \n sample mean x from each bootstrap sample.)\n3. Sort the list of sample statistics from low to high.\nDEFINITION\nGiven a simple random sample of size n, a bootstrap sample is another random \nsample of n values obtained with replacement from the original sample.\nCAUTION Note that a bootstrap sample involves sampling with replacement, so \nthat when a sample value is selected, it is replaced before the next selection is \nmade.\nWithout replacement, every sample would be the same as the original sample, so the \nproportions or means or standard deviations or variances would all be the same, and \nthere would be no confidence “interval.”\nEXAMPLE 1  Bootstrap Sample of Incomes\nWhen one of the authors collected annual incomes of current statistics students, he \nobtained these results (in thousands of dollars): 0, 2, 3, 7.\nOriginal Sample\nBootstrap Sample\n0\n7\n2\n2\n3\n2\n7\n3\nThe sample of {7, 2, 2, 3} is one bootstrap sample obtained from the original sam-\nple. Other bootstrap samples may be different.\nIncomes tend to have distributions that are skewed instead of being normal, so \nwe should not use the methods of Section 7-2 with a small sample of incomes. This \nis a situation in which the bootstrap method comes to the rescue.\nhe\nHow Many People  \nDo You Know?\nIt’s difficult for \nanyone to count \nthe number \nof people he \nor she knows, \nbut statistical \nmethods can \nbe used to estimate the mean \nnumber of people that we all \nknow. The simple approach of \njust asking someone how many \npeople are known has worked \npoorly in the past. A much \nbetter approach is to select a \nrepresentative sample of people \nand ask each person how many \npeople he or she knows who \nare named Marc, Mario, Jason, \nGinny, Rachel, or Todd. (Uncom-\nmon names are more effective \nbecause people with more com-\nmon names are more difficult to \naccurately recall.) Responses \nare then used to project the total \nnumber of people that are known. \n(If sample subjects know a mean \nof 1.76 people with those names, \nand we know that 0.288% of the \npopulation has those names, \nthen the mean number of people \nknown is 1.76>0.00288 = 611.) \nAccording to one estimate, the \nmean number of people known \nis 611, and the median is 472. \n(See “How Many People Do \nYou Know? Efficiently Estimat-\ning Personal Network Size,” by \n McCormick, Salganik, and Zheng, \nJournal of the American Statisti-\ncal Association, Vol. 105, No. 4.)\ncontinued\n\n326 \nCHAPTER 7 Estimating Parameters and Determining Sample Sizes\n4. Using the sorted list of the statistics, create the confidence interval by find-\ning corresponding percentile values. Procedures for finding percentiles are \ngiven in Section 3-3. (Example: Using a list of sorted sample means, the \n90% confidence interval limits are P5 and P95. The 90% confidence interval \nestimate of m is P5 6 m 6 P95.)\nUsefulness of Results For the purpose of illustrating the bootstrap procedure, \n Examples 2, 3, and 4 all involve very small samples with only 20 bootstrap samples. \nConsequently, the resulting confidence intervals include almost the entire range of \nsample values, and those confidence intervals are not very useful. Larger samples \nwith 1000 or more bootstrap samples will provide much better results than those \nfrom Examples 2, 3, and 4.\nProportions\nWhen working with proportions, it is very helpful to represent the data from the two \ncategories by using 0’s and 1’s, as in the following example.\nTABLE 7-3 Bootstrap Samples for p\nBootstrap Sample\npn\nSorted pn\n1\n0\n0\n1\n0.50\n0.00\nP5 = 0.00\n1\n0\n1\n0\n0.50\n0.00\n0\n1\n1\n1\n0.75\n0.00\n0\n0\n0\n0\n0.00\n0.00\n0\n1\n0\n0\n0.25\n0.25\n1\n0\n0\n0\n0.25\n0.25\n0\n1\n0\n1\n0.50\n0.25\n1\n0\n0\n0\n0.25\n0.25\n0\n0\n0\n0\n0.00\n0.25\n0\n0\n1\n1\n0.50\n0.25\n90% Confidence Interval:\n0\n0\n0\n1\n0.25\n0.25\n0.00 6 p 6 0.75\n0\n0\n1\n0\n0.25\n0.25\n1\n1\n1\n0\n0.75\n0.50\n0\n0\n0\n0\n0.00\n0.50\n0\n0\n0\n0\n0.00\n0.50\n0\n1\n1\n0\n0.50\n0.50\n0\n0\n1\n0\n0.25\n0.50\n1\n0\n0\n0\n0.25\n0.75\n1\n1\n1\n0\n0.75\n0.75\nP95 = 0.75\n0\n0\n0\n1\n0.25\n0.75\nEXAMPLE 2  Eye Color Survey: Bootstrap CI for Proportion\nIn a survey, four randomly selected subjects were asked if they have brown eyes, and here are the results: 0, \n0, 1, 0 (where 0 = no and 1 = yes). Use the bootstrap resampling procedure to construct a 90% confidence \ninterval estimate of the population proportion p, the proportion of people with brown eyes in the population.\nSOLUTION\nREQUIREMENT CHECK The sample is a simple random sample. \n(There is no requirement of at least 5 successes and at least 5 \nfailures, or np Ú 5 and nq Ú 5. There is no requirement that \nthe sample must be from a normally distributed population.) \nStep 1: In Table 7-3, we created 20 bootstrap samples from \nthe original sample of 0, 0, 1, 0.\nStep 2: Because we want a confidence interval estimate of the \npopulation proportion p, we want the sample proportion pn for \neach of the 20 bootstrap samples, and those sample propor-\ntions are shown in the column to the right of the bootstrap \nsamples.\nStep 3: The column of data shown farthest to the right is a list \nof the 20 sample proportions arranged in order (“sorted”) from \nlowest to highest.\nStep 4: Because we want a confidence level of 90%, we want \nto find the percentiles P5 and P95. Recall that P5 separates the \nlowest 5% of values, and P95 separates the top 5% of values. \nUsing the methods from Section 3-3 for finding percentiles, \nwe use the sorted list of bootstrap sample proportions to find \nthat P5 = 0.00 and P95 = 0.75. The 90% confidence interval \nestimate of the population proportion is 0.00 6 p 6 0.75.\nINTERPRETATION\nThe confidence interval of 0.00 6 p 6 0.75 is quite wide. After all, every confidence interval for every pro-\nportion must fall between 0 and 1, so the 90% confidence interval of 0.00 6 p 6 0.75 doesn’t seem to be \nhelpful, but it is based on only four sample values.\n\n7-4 Bootstrapping: Using Technology for Estimates \n327\nMeans\nIn Section 7-2 we noted that when constructing a confidence interval estimate of a \npopulation mean, there is a requirement that the sample is from a normally distributed \npopulation or the sample size is greater than 30. The bootstrap method can be used \nwhen this requirement is not satisfied.\nHINT Example 2 uses only 20 bootstrap samples, but effective use of the bootstrap \nmethod typically requires the use of software to generate 1000 or more bootstrap \nsamples.\nTABLE 7-4 Bootstrap Samples for m\nBootstrap Sample\nx\nSorted x\n3\n3\n0\n2\n2.00\n1.75\nP5 = 1.75\n0\n3\n2\n2\n1.75\n1.75\n7\n0\n2\n7\n4.00\n1.75\n3\n2\n7\n3\n3.75\n2.00\n0\n0\n7\n2\n2.25\n2.00\n7\n0\n0\n3\n2.50\n2.25\n3\n0\n3\n2\n2.00\n2.50\n3\n7\n3\n7\n5.00\n2.50\n0\n3\n2\n2\n1.75\n2.50\n0\n3\n7\n0\n2.50\n2.75\n90% Confidence Interval:\n0\n7\n2\n2\n2.75\n3.00\n1.75 6 m 6 4.875\n7\n2\n2\n3\n3.50\n3.25\n7\n2\n3\n7\n4.75\n3.25\n2\n7\n2\n7\n4.50\n3.50\n0\n7\n2\n3\n3.00\n3.75\n7\n3\n7\n2\n4.75\n4.00\n3\n7\n0\n3\n3.25\n4.50\n0\n0\n3\n7\n2.50\n4.75\n3\n3\n7\n0\n3.25\n4.75\nP95 = 4.875\n2\n0\n2\n3\n1.75\n5.00\nEXAMPLE 3  Incomes: Bootstrap CI for Mean\nWhen one of the authors collected a simple random sample of annual incomes of his statistics students, he obtained \nthese results (in thousands of dollars): 0, 2, 3, 7. Use the bootstrap resampling procedure to construct a 90% confi-\ndence interval estimate of the mean annual income of the population of all of the author’s statistics students.\nSOLUTION\nREQUIREMENT CHECK The sample is a simple random sample and there is no requirement that the sample must be from \na normally distributed population. Because distributions of incomes are typically skewed instead of normal, we should \nnot use the methods of Section 7-2 for finding the confidence interval, but the bootstrap method can be used. \nStep 1: In Table 7-4, we created 20 bootstrap samples \n(with replacement!) from the original sample of 0, 2, 3, \n7. (Here we use only 20 bootstrap samples, so we have a \nmanageable example that doesn’t occupy many pages of \ntext, but we usually want at least 1000 bootstrap samples.)\nStep 2: Because we want a confidence interval estimate \nof the population mean m, we want the sample mean x for \neach of the 20 bootstrap samples, and those sample means \nare shown in the column to the right of the bootstrap \nsamples.\nStep 3: The column of data shown farthest to the right is \na list of the 20 sample means arranged in order (“sorted”) \nfrom lowest to highest.\nStep 4: Because we want a confidence level of 90%, we \nwant to find the percentiles P5 and P95. Again, P5 separates \nthe lowest 5% of values, and P95 separates the top 5% of \nvalues. Using the methods from Section 3-3 for finding \npercentiles, we use the sorted list of bootstrap sample \nmeans to find that P5 = 1.75 and P95 = 4.875. The 90% \nconfidence interval estimate of the population mean is \n1.75 6 m 6 4.875, where the values are in thousands of \ndollars.\nStandard Deviations\nIn Section 7-3 we noted that when constructing confidence interval estimates of popu-\nlation standard deviations or variances, there is a requirement that the sample must \nbe from a population with normally distributed values. Even if the sample is large, \n\n328 \nCHAPTER 7 Estimating Parameters and Determining Sample Sizes\nthis normality requirement is much stricter than the normality requirement used for \nestimating population means. Consequently, the bootstrap method becomes more im-\nportant for confidence interval estimates of s or s2.\nEXAMPLE 4  Incomes: Bootstrap CI for Standard Deviation\nUse these same incomes (thousands of dollars) from Example 3: 0, 2, 3, 7. Use the \nbootstrap resampling procedure to construct a 90% confidence interval estimate of \nthe population standard deviation s, the standard deviation of the annual incomes of \nthe population of the author’s statistics students.\nSOLUTION\nREQUIREMENT CHECK The same requirement check used in Example 3 applies  \nhere. \nThe same basic procedure used in Example 3 is used here. Example 3 already \nincludes 20 bootstrap samples, so here we find the standard deviation of each \nbootstrap sample, and then we sort them to get this sorted list of sample standard \ndeviations:\n1.26 1.26 1.26 1.41 1.41 2.22 2.31 2.38 2.63 2.63\n2.87 2.87 2.89 2.94 2.99 3.30 3.32 3.32 3.32 3.56\nThe 90% confidence interval limits are found from this sorted list of standard devia-\ntions by finding P5 and P95. Using the methods from Section 3-3, we get P5 = 1.26 \nand P95 = 3.44. The 90% confidence interval estimate of the population standard \ndeviation s is 1.26 6 s 6 3.44, where the values are in thousands of dollars.\nAgain, know that for practical reasons, the examples of this section involved very \nsmall data sets and no more than 20 bootstrap samples, but use at least 1000 bootstrap \nsamples. The use of 10,000 or more bootstrap samples is common.\nBootstrap Resampling\nAccess tech instructions, videos, and data sets at www.TriolaStats.com\nTECH CENTER \nStatistical Literacy and Critical Thinking \n1. Replacement Why does the bootstrap method require sampling with replacement? What \nwould happen if we used the methods of this section but sampled without replacement?\n2. Bootstrap Sample Here is a random sample of numbers of patients in a day who required \nmedication at a clinic: 12, 19, 13, 43, 15. For this sample, what is a bootstrap sample?\n3. Bootstrap Sample Given the sample data from Exercise 2, which of the following are not \npossible bootstrap samples?\na. 12, 19, 13, 43, 15 \nb. 12, 19, 15 \nc. 12, 12, 12, 43, 43\nd. 14, 20, 12, 19, 15 \ne. 12, 13, 13, 12, 43, 15, 19\n7-4 Basic Skills and Concepts\n\n7-4 Bootstrapping: Using Technology for Estimates \n329\n4. How Many? The examples in this section all involved no more than 20 bootstrap samples. \nHow many should be used in real applications?\nIn Exercises 5–8, use the relatively small number of given bootstrap samples to construct \nthe confidence interval.\n5. Survey Responses In a physician’s office, four patients are asked if they would be willing \nto complete a survey before leaving. Responses included these: no, yes, no, no. Letting “yes”\n= 1 and letting “no” = 0, here are ten bootstrap samples for those responses: {0, 0, 0, 0}, \n{1, 0, 1, 0}, {1, 0, 1, 0}, {0, 0, 0, 0}, {0, 0, 0, 0}, {0, 1, 0, 0}, {0, 0, 0, 0}, {0, 0, 0, 0}, \n{0, 1, 0, 0}, {1, 1, 0, 0}. Using only the ten given bootstrap samples, construct a 90% confi-\ndence interval estimate of the proportion of patients who said that they would be willing to \ncomplete the survey.\n6. ER Admissions An emergency room official records whether patients are admitted to the \nhospital, and the results include these: admitted, admitted, not admitted, not admitted. Letting \n“admitted” = 1 and letting “not admitted” = 0, here are ten bootstrap samples for these pa-\ntients: {0, 0, 0, 0}, {0, 1, 0, 0}, {0, 1, 0, 1}, {0, 0, 1, 0}, {1, 1, 1, 0}, {0, 1, 1, 0}, {1, 0, 0, 1}, \n{0, 1, 1, 1}, {1, 0, 1, 0}, {1, 0, 0, 1}. Using only the ten given bootstrap samples, construct an \n80% confidence interval estimate of the proportion of patients who are admitted.\n7. Freshman 15 Here is a sample of amounts of weight change (kg) of college students in their \nfreshman year (from Data Set 10 “Freshman 15” in Appendix B): 11, 3, 0, -2, where -2 repre-\nsents a loss of 2 kg and positive values represent weight gained. Here are ten bootstrap samples: \n{11, 11, 11, 0}, {11, -2, 0, 11}, {11, -2, 3, 0}, {3, -2, 0, 11}, {0, 0, 0, 3}, {3, -2, 3, -2}, \n{11, 3, -2, 0}, {-2, 3, -2, 3}, {-2, 0, -2, 3}, {3, 11, 11, 11}.\na. Using only the ten given bootstrap samples, construct an 80% confidence interval estimate \nof the mean weight change for the population.\nb. Using only the ten given bootstrap samples, construct an 80% confidence interval estimate \nof the standard deviation of the weight changes for the population.\n8. Cell Phone Radiation Here is a sample of measured radiation emissions (cW>kg) for cell \nphones (based on data from the Environmental Working Group): 38, 55, 86, 145. Here are \nten bootstrap samples: {38, 145, 55, 86}, {86, 38, 145, 145}, {145, 86, 55, 55}, {55, 55, 55, \n145}, {86, 86, 55, 55}, {38, 38, 86, 86}, {145, 38, 86, 55}, {55, 86, 86, 86}, {145, 86, 55, 86}, \n{38, 145, 86, 55}.\na. Using only the ten given bootstrap samples, construct an 80% confidence interval estimate \nof the population mean.\nb. Using only the ten given bootstrap samples, construct an 80% confidence interval estimate \nof the population standard deviation.\nIn Exercises 9–22, use technology to create the large number of bootstrap samples.\n9. Freshman 15 Repeat Exercise 7 “Freshman 15” using a confidence level of 90% for parts \n(a) and (b) and using 1000 bootstrap samples instead of the 10 that were given in Exercise 7.\n10. Cell Phone Radiation Repeat Exercise 8 “Cell Phone Radiation” using a confidence \nlevel of 90% for parts (a) and (b), using 1000 bootstrap samples instead of the 10 that were \ngiven in Exercise 8.\n11. ER Wait Times The District of Columbia has some of the longest emergency room wait-\ning times in the United States. Here are times (minutes) patients waited in District of Columbia \nemergency rooms before seeing a physician: 40, 68, 72, 67, 54, 59, 68, 47, 55, 74, 63, 73. Use \nthe bootstrap method with 1000 bootstrap samples.\na. Construct a 99% confidence interval estimate of the population mean. Is the result dramati-\ncally different from the 99% confidence interval that would be found using the confidence \ninterval constructed by using the t distribution, as in Section 7-2?\ncontinued\n\n330 \nCHAPTER 7 Estimating Parameters and Determining Sample Sizes\nb. Construct a 95% confidence interval estimate of the population standard deviation. Is the \nresult dramatically different from the 95% confidence interval that would be found using the x2\ndistribution, as in Section 7-3?\n12. ER Wait Times Repeat Exercise 11 “ER Wait Times” using these emergency room wait-\ning times (minutes) from Florida: 29, 49, 31, 24, 14, 37, 43, 40, 35, 34, 10, 38, 2, 54.\n13. Lipitor In clinical trials of the drug Lipitor (atorvastatin), 863 subjects were treated with \n10 mg of the drug, and 8 of them experienced allergic reactions. Use the bootstrap method to \nconstruct a 95% confidence interval estimate of the percentage of treated subjects who experi-\nence allergic reactions. Use 1000 bootstrap samples. How does the result compare to the confi-\ndence interval found in Exercise 22 from Section 7-1 on page 296?\n14. Eliquis The drug Eliquis (apixaban) is used to help prevent blood clots in certain patients. \nIn clinical trials, among 5924 patients treated with Eliquis, 153 developed the adverse reaction \nof nausea (based on data from Bristol-Myers Squibb Co.). Use the bootstrap method to con-\nstruct a 99% confidence interval estimate of the proportion of patients who experience nausea. \nUse 1000 bootstrap samples. How does the result compare to the confidence interval found in \nExercise 14 “Eliquis” from Section 7-1 on page 295?\n15. Survey Return Rate In a study of cell phone use and brain hemispheric dominance, an In-\nternet survey was e-mailed to 5000 subjects randomly selected from an online otological group \n(focused on ears), and 717 surveys were returned. Use the bootstrap method to construct a 90% \nconfidence interval estimate of the proportion of returned surveys. Use 1000 bootstrap samples. \nHow does the result compare to the confidence interval found in Exercise 15 “Survey Return \nRate” from Section 7-1 on page 295?\n16. Medical Malpractice In a study of 1228 randomly selected medical malpractice lawsuits, \nit was found that 856 of them were dropped or dismissed (based on data from the Physicians \nInsurers Association of America). Use the bootstrap method to construct a 95% confidence in-\nterval estimate of the proportion of lawsuits that are dropped or dismissed. Use 1000 bootstrap \nsamples. How does the result compare to the confidence interval found in Exercise 16 “Medi-\ncal Malpractice” from Section 7-1 on page 295?\n17. Student Evaluations Listed below are student evaluation ratings of courses, where a \nrating of 5 is for “excellent.” The ratings were obtained at the University of Texas at Austin. \nUsing the bootstrap method with 1000 bootstrap samples, construct a 90% confidence interval \nestimate of m. How does the result compare to the result that would be obtained by using the \nmethods from Section 7-2?\n3.8 3.0 4.0 4.8 3.0 4.2 3.5 4.7 4.4 4.2 4.3 3.8 3.3 4.0 3.8\n18. Caffeine in Soft Drinks Listed below are measured amounts of caffeine (mg per 12 oz of \ndrink) obtained in one can from each of 20 brands. Using the bootstrap method with 1000 bootstrap \nsamples, construct a 99% confidence interval estimate of m. How does the result compare to the \nconfidence interval found in Exercise 21 “Caffeine in Soft Drinks” in Section 7-2 on page 312?\n0 0 34 34 34 45 41 51 55 36 47 41 0 0 53 54 38 0 41 47\n 19. Cell Phone Radiation Here are the measured radiation emissions (in W>kg) from differ-\nent cell phones: 0.38, 0.55, 1.54, 1.55, 0.50, 0.60, 0.92, 0.96, 1.00, 0.86, 1.46. Use the bootstrap \nmethod with 1000 bootstrap samples to find a 90% confidence interval estimate of m. How does \nthe result compare to the confidence interval found for Exercise 17 in Section 7-2 on page 311?\n 20. Cell Phone Radiation Repeat Exercise 19 using the standard deviation instead of the mean. \nCompare the confidence interval to the one that would be found using the methods of Section 7-3.\n21. Analysis of Last Digits Weights of respondents were recorded as part of the California \nHealth Interview Survey. The last digits of weights from 50 randomly selected respondents are \nlisted below.\n5 0 1 0 2 0 5 0 5 0 3 8 5 0 5 0 5 6 0 0 0 0 0 0 8\n5 5 0 4 5 0 0 4 0 0 0 0 0 8 0 9 5 3 0 5 0 0 0 5 8\ncontinued\n\na. Use the bootstrap method with 1000 bootstrap samples to find a 95% confidence interval \nestimate of s.\nb. Find the 95% confidence interval estimate of s found by using the methods of Section 7-3.\nc. Compare the results. If the two confidence intervals are different, which one is better? Why?\n22. Analysis of Last Digits Repeat Exercise 21 “Analysis of Last Digits” using the mean in-\nstead of the standard deviation. Compare the confidence interval to the one that would be found \nusing the methods of Section 7-2.\n23. Effect of the Number of Bootstrap Samples Repeat Exercise 21 “Analysis of Last \nDigits” using 10,000 bootstrap samples instead of 1000. What happens?\n24. Distribution Shapes Use the sample data given in Exercise 21 “Analysis of Last Digits.” \na. Do the original sample values appear to be from a normally distributed population? Explain.\nb. Do the 1000 bootstrap samples appear to have means that are from a normally distributed \npopulation? Explain.\nc. Do the 1000 bootstrap samples appear to have standard deviations that are from a normally \ndistributed population? Explain.\n7-4 Beyond the Basics\n1. Vision Correction Here is a 95% confidence interval estimate of the proportion of adults \nwho correct their vision by wearing contact lenses: 0.110 6 p 6 0.150 (based on data from a \nVision Council survey). What is the best point estimate of the proportion of adults in the popu-\nlation who correct their vision by wearing contact lenses?\n2.  Interpreting CI Write a brief statement that correctly interprets the confidence interval \ngiven in Exercise 1.\n3. Critical Value For the survey described in Exercise 1, find the critical value that would be \nused for constructing a 99% confidence interval estimate of the population proportion.\n4. Vision Correction From the same survey results cited in Exercise 1 “Vision Correction,” it \nwas reported that 3% of adults correct their vision with surgery, and the margin of error is {1.0\npercentage points. Identify the confidence interval.\n5. Sample Size for Proportion Find the sample size required to estimate the percentage of \ncollege students who take a statistics course. Assume that we want 95% confidence that the \nproportion from the sample is within four percentage points of the true population percentage.\n6. Sample Size for Mean Find the sample size required to estimate the mean IQ of surgeons. \nAssume that we want 98% confidence that the mean from the sample is within three IQ points \nof the true population mean. Also assume that s = 15.\n7. Requirements A quality control analyst has collected a random sample of 12 batteries used \nin heart pacemakers and she plans to test their voltage level and construct a 95% confidence \ninterval estimate of the mean voltage level for the population of batteries. What requirements \nmust be satisfied in order to construct the confidence interval using the method with the t dis-\ntribution?\n8. Degrees of Freedom In general, what does “degrees of freedom” refer to? For the sample \ndata described in Exercise 7, find the number of degrees of freedom, assuming that you want to \nconstruct a confidence interval estimate of m using the t distribution.\nChapter Quick Quiz\nCHAPTER 7 Chapter Quick Quiz \n331\n\n332 \nCHAPTER 7 Estimating Parameters and Determining Sample Sizes\n9. Critical Value Refer to Exercise 7 and assume that the requirements are satisfied. Find the \ncritical value that would be used for constructing a 95% confidence interval estimate of m using \nthe t distribution.\n10. Which Method? Refer to Exercise 7 and assume that a sample of 12 voltage levels ap-\npears to be from a population with a distribution that is substantially far from being normal. \nShould a 95% confidence interval estimate of s be constructed using the x2 distribution? If \nnot, what other method could be used to find a 95% confidence interval estimate of s?\nReview Exercises\n1. Brain Cancer Cluster In a study designed to determine whether there was a cluster of brain \ncancer cases at a Pratt & Whitney plant, records from 223,000 employees were studied and \n723 employees with brain tumors were found. Treat those employees as a random sample and \nconstruct a 95% confidence interval estimate of the proportion of all adults who develop such \ntumors. Write a brief statement interpreting that confidence interval.\n2. Medicare A hospital wants to estimate the percentage of admitted patients who receive \nMedicare benefits. If we want to estimate that percentage based on examination of randomly \nselected patient payment records, how many patient records must be examined in order to be \n90% confident that we are within four percentage points of the population percentage?\n3. Cuckoo Egg Lengths Listed below are lengths (mm) of cuckoo eggs.\na. Identify the best point estimate of the population mean m.\nb. Construct a 95% confidence interval estimate of the mean length of all cuckoo eggs.\nc. Write a statement that interprets the confidence interval.\n22.05 22.05 22.05 22.05 22.05 22.05 22.05 22.05 22.05 22.05 22.25 22.25\n4. Lefties There have been several studies conducted in an attempt to identify ways in which \nleft-handed people are different from those who are right handed. Assume that you want to \nestimate the mean IQ of all left-handed adults. How many random left-handed adults must \nbe tested in order to be 99% confident that the mean IQ of the sample group is within four IQ \npoints of the mean IQ of all left-handed adults? Assume that s is known to be 15.\n5. Distributions Identify the distribution (normal, Student t, chi-square) that should be used \nin each of the following situations. If none of the three distributions can be used, what other \nmethod could be used?\na. In constructing a confidence interval of m, you have 75 sample values and they appear to be \nfrom a population with a skewed distribution. The population standard deviation is not known.\nb. In constructing a confidence interval estimate of m, you have 75 sample values and they ap-\npear to be from a population with a skewed distribution. The population standard deviation is \nknown to be 18.2 cm.\nc. In constructing a confidence interval estimate of s, you have 75 sample values and they \n appear to be from a population with a skewed distribution.\nd. In constructing a confidence interval estimate of s, you have 75 sample values and they \n appear to be from a population with a normal distribution.\ne. In constructing a confidence interval estimate of p, you have 1200 survey respondents and \n5% of them answered “yes” to the first question.\n6. Sample Size You have been assigned the task of conducting a survey to study prescription \nmedication purchases of adults.\na. If you want to estimate the percentage of adults who have purchased prescription medication \nduring the past 30 days, how many adults must you survey if you want 95% confidence that \nyour percentage has a margin of error of three percentage points?\ncontinued\n\nb. If you want to estimate the mean amount that adults have spent on prescription medications \nduring the past 30 days, how many adults must you survey if you want 95% confidence that your \nsample mean is in error by no more than $5? (Based on results from a pilot study, assume that \nthe standard deviation of amounts spent on prescription medications in the past 30 days is $39.)\nc. If you plan to obtain the estimates described in parts (a) and (b) with a single survey having \nseveral questions, how many adults must be surveyed?\n7. Aspirin Generic aspirin tablets are supposed to contain 325 mg of aspirin. Listed below are \nthe measured amounts of aspirin (mg) found in randomly selected tablets. Construct a 95% \nconfidence interval estimate of the mean amount of aspirin in tablets. Do these tablets appear \nto be acceptable?\n330 358 318 338 317 329 339 324 409 248 357 315\n8. Aspirin\na. Use the sample data from Exercise 7 and construct a 95% confidence interval estimate of s.\nb. Assume that we want almost all of the tablets to contain between 315 mg and 335 mg of aspi-\nrin. Find the range, then use the range rule of thumb to estimate the desired standard deviation.\nc. Based on the results from parts (a) and (b), what do you conclude?\n9. Bootstrap for Aspirin Repeat Exercise 7 using 1000 bootstrap samples. How does the re-\nsult compare to the confidence interval found in Exercise 7?\n10. CI for Proportion In a TE Connectivity survey of 1000 randomly selected adults, 2% said \nthat they “did not know” when asked if they felt comfortable being in a self-driving vehicle. \nThere is a need to construct a 95% confidence interval estimate of the proportion of all adults in \nthe population who don’t know.\na. Find the confidence interval using the normal distribution as an approximation to the \n binomial distribution.\nb. Find the confidence interval using 1000 bootstrap samples.\nc. Compare the results.\nCHAPTER 7 Cumulative Review Exercises \n333\nFeet. Listed below are lengths (cm) of feet of adult males. Use these values for Exercises 1–5.\n26.7 25.9 26.4 29.2 26.8 28.1 25.4 27.9 27.5 28.8\n1. Statistics Find the mean, median, standard deviation, and range. Are the results statistics or \nparameters?\n2. Range Rule of Thumb Use the results from Exercise 1 with the range rule of thumb to find \nthe limits separating those that are significantly low and those that are significantly high. Is a \nfoot length of 30 cm significantly high (or long)?\n3. Level of Measurement What is the level of measurement of the foot lengths (nominal, or-\ndinal, interval, ratio)? Are the original unrounded foot lengths continuous data or discrete data?\n4. Distribution Do the given data appear to be from a normally distributed population? Explain.\n5. Confidence Interval Construct a 95% confidence interval estimate of the mean foot length \nfor the population of all adult males.\n6. Sample Size Find the sample size necessary to estimate the mean foot length for the popu-\nlation of adult females. Assume that we want 95% confidence that the sample mean is in error \nby no more than 0.1 cm. Based on a prior study, assume that adult females have foot lengths \nwith a standard deviation of 1.12 cm.\nCumulative Review Exercises\n\n334 \nCHAPTER 7 Estimating Parameters and Determining Sample Sizes\n7. Foot Lengths Based on Data Set 7 “Foot and Height,” assume that women have foot lengths \nthat are normally distributed with a mean of 24.20 cm and a standard deviation of 1.12 cm.\na. Find the probability that a randomly selected woman has a foot length greater than 25.00 cm.\nb. Find the probability that 25 randomly selected women have foot lengths with a mean greater \nthan 25.00 cm.\nc. For the population of foot lengths of women, find the 95th percentile.\n8. Piercing, Tattoos, Infections Survey subjects were asked if they knew that body pierc-\nings and tattoos can transmit infectious disease. There were 1440 responses of “yes” and 48 \nresponses of “no” (based on data from “Body Piercing and Tattoos: A Survey on Young Adults’ \nKnowledge of the Risks and Practices in Body Art,” by Quaranta et al., BioMed Central Public \nHealth, published online). Find the 99% confidence interval estimate of the percentage of those \nwho know that body piercings and tattoos can transmit infectious disease. Does the population \nappear to be well informed about the risk of infectious disease?\nBody Temperatures Data Set 2 “Body Temperatures” in Appendix B includes body tempera-\ntures (°F) of a sample of healthy adults. Use technology for the following.\na. Find the mean and standard deviation of the body temperatures at 8 AM on day 2.\nb. Generate a histogram and normal quantile plot of the body temperatures at 8 AM on day \n2. Does it appear that the temperatures are from a population having a normal distribution? \nExplain.\nc. In obtaining a 95% confidence interval estimate of the body temperatures of all adults, are \nthe requirements for using a t distribution satisfied? Explain.\nd. Find a 95% confidence interval estimate of the mean body temperature of all adults.\ne. Find a 95% confidence interval estimate of the mean body temperature of all adults, using \n1000 bootstrap samples.\nf. What do you conclude about the common belief that the mean body temperature is 98.6°F?\nTechnology Project\nFROM DATA TO DECISION\nCritical Thinking: What does the survey tell us?\nSurveys have become an integral part of our lives. Because \nit is so important that every citizen has the ability to interpret \nsurvey results, surveys are the focus of this project.\nFour researchers conducted a survey of 717 subjects. Here \nare some findings (based on data from “Hemispheric Domi-\nnance and Cell Phone Use,” by Seidman et al., JAMA  \nOtolaryngology - Head Neck Surgery, Vol. 139, No. 5):\n•  The respondents include 642 right-handed subjects, 69 left-\nhanded subjects, and 6 ambidextrous subjects.\n•  Among the 642 right-handed subjects, 436 prefer to use \ntheir right ear for cell phone use, 166 prefer their left ear, \nand 40 have no preference.\n•  Among the 69 left-handed subjects, 16 prefer to use their \nright ear for cell phone use, 50 prefer their left ear, and 3 \nhave no preference.\nAnalyzing the Data\n1. Use the survey results to construct a 95% confidence inter-\nval estimate of the proportion of all right-handed people who \nprefer their right ear for cell phone use.\n2. Use the result from part (a) and identify the margin of error.\n3. A common criticism of surveys is that they poll only a very \nsmall percentage of the population and therefore cannot be \naccurate. Is a sample of only 717 people taken from a large \npopulation a sample size that is too small? Write a brief ex-\nplanation of why the sample size of 717 is or is not too small.\n4. Does it appear that most right-handed people prefer their \nright ear for cell phone use? Does it appear that most left-\nhanded people prefer their left ear for cell phone use?\n5. The survey was e-mailed to 5000 people and 717 surveys \nwere returned. What does the response rate suggest about the re-\nsults? What does the sampling method suggest about the results?\n\n1. Out-of-class activity Collect sample data, and use the methods of this chapter to construct \nconfidence interval estimates of population parameters. Here are some suggestions for parameters:\n• Proportion of students at your college who can raise one eyebrow without raising the other \neyebrow.\n• Mean pulse rate of male college students, or mean pulse rate of female college students.\n• Mean length of words in New York Times editorials and mean length of words in a profes-\nsional journal, such as Journal of the American Medical Association.\n• Proportion of students at your college who have consumed an alcoholic beverage within the \nlast seven days.\n• Mean number of hours that students at your college study each week.\n2. In-class activity Without using any measuring device, each student should draw a line \nbelieved to be 3 in. long and another line believed to be 3 cm long. Then use rulers to measure \nand record the lengths of the lines drawn. Find the means and standard deviations of the two \nsets of lengths. Use the sample data to construct a confidence interval for the length of the line \nestimated to be 3 in., and then do the same for the length of the line estimated to be 3 cm. Do \nthe confidence interval limits actually contain the correct length? Compare the results. Do the \nestimates of the 3-in. line appear to be more accurate than those for the 3-cm line?\n3. In-class activity Assume that a method of gender selection can affect the probability of a baby \nbeing a girl, so that the probability becomes 1>4. Each student should simulate 20 births by drawing \n20 cards from a shuffled deck. Replace each card after it has been drawn, then reshuffle. Consider \nthe hearts to be girls and consider all other cards to be boys. After making 20 selections and record-\ning the “genders” of the babies, construct a confidence interval estimate of the proportion of girls. \nDoes the result appear to be effective in identifying the true value of the population proportion? (If \ndecks of cards are not available, use some other way to simulate the births, such as using the random \nnumber generator on a calculator or using digits from phone numbers or Social Security numbers.)\n4. Out-of-class activity Groups of three or four students should go to the library and collect \na sample consisting of the ages of books (based on copyright dates). Plan and describe the \nsampling procedure, execute the sampling procedure, and then use the results to construct a \nconfidence interval estimate of the mean age of all books in the library.\n5. In-class activity Each student should estimate the length of the classroom. The values \nshould be based on visual estimates, with no actual measurements being taken. After the es-\ntimates have been collected, construct a confidence interval, then measure the length of the \nroom. Does the confidence interval contain the actual length of the classroom? Is there a “col-\nlective wisdom,” whereby the class mean is approximately equal to the actual room length?\n6. In-class activity Divide into groups of three or four. Examine a sample of different issues \nof a current magazine and find the proportion of pages that include advertising. Based on the \nresults, construct a 95% confidence interval estimate of the percentage of all such pages that \nhave advertising. Compare results with other groups.\n7. Out-of-class activity Identify a topic of general interest and coordinate with all members \nof the class to conduct a survey. Instead of conducting a “scientific” survey using sound prin-\nciples of random selection, use a convenience sample consisting of respondents who are read-\nily available, such as friends, relatives, and other students. Analyze and interpret the results. \nIdentify the population. Identify the shortcomings of using a convenience sample, and try to \nidentify how a sample of subjects randomly selected from the population might be different.\n8. Out-of-class activity Each student should find an article in a professional journal that in-\ncludes a confidence interval of the type discussed in this chapter. Write a brief report describing \nthe confidence interval and its role in the context of the article.\nCooperative Group Activities\nCHAPTER 7 Cooperative Group Activities \n335\n\n336\nBasics of Hypothesis \nTesting\nTesting a Claim About a \nProportion\nTesting a Claim About a \nMean\nTesting a Claim About \na Standard Deviation or \nVariance\n8-1\n8-2\n8-3\n8-4\nDoes the MicroSort Method of Gender Selection \nIncrease the Likelihood That a Baby Will Be a Girl?\nCHAPTER \nPROBLEM\nHypothesis Testing\nGender selection methods are somewhat controversial. Some \npeople believe that use of such methods should be prohib-\nited, regardless of the reason. Others believe that limited use \nshould be allowed for medical reasons, such as to prevent \ngender-specific hereditary disorders. For example, some cou-\nples carry X-linked recessive genes, so that a male child has a \n50% chance of inheriting a serious disorder and a female child \nhas no chance of inheriting the disorder. These couples may \nwant to use a gender selection method to increase the likeli-\nhood of having a baby girl so that none of their children inherit \nthe disorder.\nMethods of gender selection have been around for many \nyears. In the 1980s, ProCare Industries sold a product called \nGender Choice. It cost only $49.95, but the Food and Drug \n8 \n\nAdministration told the company to stop distributing Gender \nChoice because there was no evidence to support the claim \nthat it was 80% reliable.\nThe Genetics & IVF Institute developed a newer gen-\nder selection method called MicroSort. Clinical trials for \nthis method were never completed and MicroSort was not \nbrought to market. The MicroSort XSORT method was de-\nsigned to increase the likelihood of a baby girl, and the \nYSORT method was designed to increase the likelihood of \na boy. The MicroSort website included this statement: “The \nGenetics & IVF Institute is offering couples the ability to in-\ncrease the chance of having a child of the desired gender \nto reduce the probability of X-linked diseases or for family \nbalancing.” For a cost exceeding $3000, the Genetics & IVF \nInstitute claimed that it could increase the probability of hav-\ning a baby of the gender that a couple prefers. In clinical tri-\nals, among 945 babies born to parents who used the XSORT \nmethod in trying to have a baby girl, 879 couples did have \nbaby girls, for a success rate of 93%. Under normal circum-\nstances with no special treatment, girls occur in about 50% \nof births. (Actually, the current birth rate of girls is 48.8%, but \nwe will use 50% to keep things simple.) These results provide \nus with an interesting question: Given that 879 out of 945 \ncouples had girls, can we actually support the claim that the \nXSORT technique is effective in increasing the probability of \na girl? When the Genetics & IVF Institute chose to discontinue \nthe clinical trials, does it appear that a major reason was inef-\nfectiveness of their methods?\nHere are the chapter objectives:\nBasics of Hypothesis Testing\n• Develop the ability to identify the null and alternative hypotheses when given some \nclaim about a population parameter (such as a proportion, mean, standard deviation, \nor variance).\n• Develop the ability to calculate a test statistic, find critical values, calculate P-values, \nand state a final conclusion that addresses the original claim. Here are the compo-\nnents that should be included in the hypothesis test:\n• Statements of the null and alternative hypotheses expressed in symbolic form\n• Value of the test statistic\n• Selection of the sampling distribution to be used for the hypothesis test\n• Identification of a P-value and>or critical value(s)\n• Statement of a conclusion rejecting the null hypothesis or failing to reject the \nnull hypothesis\n• Statement of a final conclusion that uses simple and nontechnical terms to \naddress the original claim\nTesting a Claim About a Proportion\n• Develop the ability to conduct a formal hypothesis test of a claim about a popula-\ntion proportion. The procedure should include the components listed above with the \n objectives for Section 8-1.\nTesting a Claim About a Mean\n• Develop the ability to use sample data to conduct a formal hypothesis test of a claim \nmade about a population mean. The procedure should include the same compo-\nnents listed above with the objectives for Section 8-1.\n8-1\n8-2\n8-3\nChapter Objectives \n337\nCHAPTER OBJECTIVES\n>>>\n\n338 \nCHAPTER 8 Hypothesis Testing\nKey Concept In this section we present key components of a formal hypothesis test. \nThe concepts in this section are general and apply to hypothesis tests involving pro-\nportions, means, or standard deviations or variances. In Part 1, we begin with the “big \npicture” to understand the basic underlying approach to hypothesis tests. Then we de-\nscribe null and alternative hypotheses, significance level, types of tests (two-tailed, \nleft-tailed, right-tailed), test statistic, P-value, critical values, and statements of conclu-\nsions. In Part 2 we describe types of errors (type I and type II). In Part 3 we describe \nthe power of a hypothesis test.\nPART 1\n Basic Concepts of Hypothesis Testing\nWe begin with two very basic definitions.\n8-1 \nBasics of Hypothesis Testing\nTesting a Claim About a Standard Deviation or Variance\n• Develop the ability to use sample data to conduct a formal hypothesis test of a claim \nmade about a population standard deviation or variance. The procedure should in-\nclude the same components listed with the objectives for Section 8-1.\n8-4\nTesting a Claim About a Standard Deviation or Variance\n• Develop the ability to use sample data to conduct a formal hypothesis test of a claim\nmade about a population standard deviation or variance. The procedure should in-\nclude the same components listed with the objectives for Section 8-1.\nDEFINITIONS\nIn statistics, a hypothesis is a claim or statement about a property of a population.\nA hypothesis test (or test of significance) is a procedure for testing a claim about \na property of a population.\nThe “property of a population” referred to in the preceding definitions is often the \nvalue of a population parameter, so here are some examples of typical hypotheses (or \nclaims):\n \n■m 6 98.6°F “The mean body temperature of humans is less than 98.6°F.”\n \n■p 7 0.5 “The proportion of girls born to parents using the XSORT method of \ngender selection is greater than 0.5.”\n \n■s = 15 “The population of nurses has IQ scores with a standard deviation equal \nto 15.”\nEXAMPLE 1  XSORT Method of Gender Selection\nConsider the claim from the Chapter Problem that “the XSORT technique is effec-\ntive in increasing the probability of a girl.” Using p to denote the proportion of girls \nborn to parents using the XSORT method of gender selection, the “effective” claim \nis equivalent to the claim that the proportion is significantly greater than half, or \np 7 0.5. The expression p 7 0.5 is the symbolic form of the original claim.\n\n8-1 Basics of Hypothesis Testing \n339\nThe Big Picture In Example 1, we have the claim that the proportion p is such that \np 7 0.5. Among 945 babies, how many do we need to get a significantly high number \nof girls?\n \n■A result of 473 girls (or 50.1%) could easily occur by chance under normal cir-\ncumstances with no treatment, so 473 is not significantly high.\n \n■The actual result of 879 girls (or 93.0%) appears to be significantly high.\nThe method of hypothesis testing gives us a standard and widely accepted procedure \nfor deciding whether such results are significant.\nUsing Technology It is easy to obtain hypothesis-testing results using technology. The \naccompanying screen displays show results from different technologies, so we can use \ncomputers or calculators to do all of the computational heavy lifting. Examining the \nscreen displays, we see some common elements. They all display a “test statistic” of \nz = 26.45 (rounded), and they all include a “P-value” of 0.0000 (rounded). These two \nresults are important, but understanding the hypothesis-testing procedure is critically \nimportant. Focus on understanding how the hypothesis-testing procedure works and \nlearn the associated terminology. Only then will results from technology make sense.\nStatdisk\nMinitab\nTI-83 , 84 Plus\nXLSTAT\nStatCrunch\nSignificance Hypothesis tests are also called tests of significance. In Section 4-1 we \nused probabilities to determine when sample results are significantly low or signifi-\ncantly high. This chapter formalizes those concepts in a unified procedure that is used \noften throughout many different fields of application. Figure 8-1 on the next page \nsummarizes the procedures used in two slightly different methods for conducting a \nformal hypothesis test. We will proceed to conduct a formal test of the claim from \nExample 1 that p 7 0.5. In testing that claim, we will use the sample data from the \nresults cited in the Chapter Problem, with x = 879 girls among n = 945 births.\nat \ner \nAspirin Not Helpful for \nGeminis and Libras\nPhysician \nRichard Peto \nsubmitted an ar-\nticle to Lancet, a \nBritish medical \njournal. The \narticle showed \nthat patients \nhad a better chance of surviving \na heart attack if they were treated \nwith aspirin within a few hours of \ntheir heart attacks. Lancet editors \nasked Peto to break down his \nresults into subgroups to see if \nrecovery worked better or worse \nfor different groups, such as \nmales or females. Peto believed \nthat he was being asked to use \ntoo many subgroups, but the edi-\ntors insisted. Peto then agreed, \nbut he supported his objections \nby showing that when his pa-\ntients were categorized by signs \nof the zodiac, aspirin was useless \nfor Gemini and Libra heart attack \npatients, but aspirin is a lifesaver \nfor those born under any other \nsign. This shows that when con-\nducting multiple hypothesis tests \nwith many different subgroups, \nthere is a very large chance of \ngetting some wrong results.\n\n340 \nCHAPTER 8 Hypothesis Testing\n8. Restate Decision in Nontechnical Terms\nConstruct a conﬁdence interval with a conﬁdence \nlevel selected as in Table 8-1.\nBecause a conﬁdence interval estimate of a population\nparameter contains the likely values of that parameter,\nreject a claim that the population parameter has a value\nthat is not included in the conﬁdence interval.\nTable 8-1\nSigniﬁcance \n0.01\nLevel for \n0.05\nHypothesis \n0.10\nTest\nTwo-Tailed Test\nOne-Tailed Test\n99%\n95%\n90%\n98%\n90%\n80%\nConﬁdence Level for Conﬁdence Interval\nConﬁdence Interval Method\nRestate this previous decision in simple nontechnical terms, and \naddress the original claim.\n5. Identify the Test Statistic\nIdentify the test statistic that is relevant to the test and determine its \nsampling distribution (such as normal, t, chi-square).\n4. Select Signiﬁcance Level\nSelect the signiﬁcance level A based on the seriousness of a type type I error. \nMake A small if the consequences of rejecting a true H0 are severe.\n \n• The values of 0.05 and 0.01 are very common.\n2. Give Symbolic Form\nGive the symbolic form that must be true when the original claim is false.\n1. Identify the Claim\nIdentify the claim to be tested and express it in symbolic form.\n3. Identify Null and Alternative Hypothesis\nConsider the two symbolic expressions obtained so far:\n \n• Alternative hypothesis H1 is the one NOT containing equality, so H1 uses \n \n the symbol . or , or Þ.\n \n• Null hypothesis H0 is the symbolic expression that the parameter equals\n \n the ﬁxed value being considered.\n7. Make a Decision\n• Reject H0 if P-value # a.\n• Fail to reject H0 if P-value . a.\n6. Find Values\nFind the value of the test statistic and the \nP-value (see Figure 8-3). Draw a graph and \nshow the test statistic and P-value.\n7. Make a Decision\n• Reject H0 if the test statistic is in the\ncritical region.\n• Fail to reject H0 if the test statistic is not in \nthe critical region.\n6. Find Values\nP-Value Method\nCritical Value Method\nFind the value of the test statistic and the \ncritical values. Draw a graph showing the test \nstatistic, critical value(s) and critical region.\nFIGURE 8-1  \nProcedure for \nHypothesis Tests\n\n8-1 Basics of Hypothesis Testing \n341\nSteps 1, 2, 3: Use the Original Claim to Create a Null \nHypothesis H0 and an Alternative Hypothesis H1\nThe objective of Steps 1, 2, 3 is to identify the null hypothesis and alternative \nhypothesis so that the formal hypothesis test includes these standard components that \nare often used in many different disciplines. The null hypothesis includes the working \nassumption for the purposes of conducting the test.\nDEFINITIONS\nThe null hypothesis (denoted by H0) is a statement that the value of a popula-\ntion parameter (such as proportion, mean, or standard deviation) is equal to some \nclaimed value.\nThe alternative hypothesis (denoted by H1 or Ha or HA) is a statement that the pa-\nrameter has a value that somehow differs from the null hypothesis. For the methods \nof this chapter, the symbolic form of the alternative hypothesis must use one of \nthese symbols: 6, 7, ≠.\nThe term null is used to indicate no change or no effect or no difference. We conduct \nthe hypothesis test by assuming that the parameter is equal to some specified value so \nthat we can work with a single distribution having a specific value.\nExample: Here is an example of a null hypothesis involving a proportion:\nH0: p = 0.5\nExample: Here are different examples of alternative hypotheses involving proportions:\nH1: p 7 0.5  H1: p 6 0.5  H1: p ≠0.5\nGiven the claim from Example 1 that the gender selection method is effective in \nincreasing the probability that a baby will be a girl, we can apply Steps 1, 2, and 3 in \nFigure 8-1 as follows.\nStep 1:  Identify the claim to be tested and express it in symbolic form. Using p to \ndenote the probability of selecting a girl, the claim that the gender selection is effec-\ntive can be expressed in symbolic form as p 7 0.5.\nStep 2:  Give the symbolic form that must be true when the original claim is false. If \nthe original claim of p 7 0.5 is false, then p … 0.5 must be true.\nStep 3:  This step is in two parts: Identify the alternative hypothesis H1 and identify \nthe null hypothesis H0.\n• Identify H1: Using the two symbolic expressions p 7 0.5 and p … 0.5, the alter-\nnative hypothesis H1 is the one that does not contain equality. Of those two ex-\npressions, p 7 0.5 does not contain equality, so we get\nH1: p 7 0.5\n• Identify H0: The null hypothesis H0 is the symbolic expression that the parameter \nequals the fixed value being considered, so we get\nH0: p = 0.5\nThe result of the first three steps is the identification of the null and alternative \nhypotheses:\nH0: p = 0.5 1null hypothesis2\nH1: p 7 0.5 1alternative hypothesis2\n\n342 \nCHAPTER 8 Hypothesis Testing\nNote About Forming Your Own Claims (Hypotheses): If you are conducting a study \nand want to use a hypothesis test to support your claim, your claim must be worded so \nthat it becomes the alternative hypothesis (and can be expressed using only the symbols \n6, 7, or ≠). You can never support a claim that a parameter is equal to a specified value.\nStep 4: Select the Significance Level A\nTABLE 8-2\nParameter\nSampling Distribution\nRequirements\nTest Statistic\nProportion p\nNormal (z)\nnp Ú 5 and nq Ú 5\nz = pn - p\nA\npq\nn\nMean m\nt\ns not known and normally \ndistributed population\nor\ns not known and n 7 30\nt =\nx - m\ns\n2n\nMean m\nNormal (z)\ns known and normally dis-\ntributed population\nor\ns known and n 7 30\nz =\nx - m\ns\n2n\nSt. dev. s or  \nvariance s2\nx2\nStrict requirement: normally \ndistributed population\nx2 =\n1n - 12s2\ns2\nStep 6: Find the Value of the Test Statistic, Then Find \nEither the P-Value or the Critical Value(s)\nDEFINITION\nThe test statistic is a value used in making a decision about the null hypothesis. It \nis found by converting the sample statistic (such as pn, x, or s) to a score (such as \nz, t, or x2) with the assumption that the null hypothesis is true.\nDEFINITION\nThe significance level A for a hypothesis test is the probability value used as the \ncutoff for determining when the sample evidence constitutes significant evidence \nagainst the null hypothesis. By its nature, the significance level a is the probability \nof mistakenly rejecting the null hypothesis when it is true:\nSignificance level A = P1rejecting H0 when H0 is true2\nThe significance level a is the same a introduced in Section 7-1, where we defined \n“critical value.” Common choices for a are 0.05, 0.01, and 0.10; 0.05 is the most com-\nmon choice.\nStep 5: Identify the Statistic Relevant to the Test and \nDetermine Its Sampling Distribution (such as normal, t,  \nor X2 )\nTable 8-2 lists parameters along with the corresponding sampling distributions.\nExample: The claim p 7 0.5 is a claim about the population proportion p, so use \nthe normal distribution provided that the requirements are satisfied. (With n = 945, \np = 0.5, and q = 0.5 from Example 1, np Ú 5 and nq Ú 5 are both true.)\n\n8-1 Basics of Hypothesis Testing \n343\nIn this chapter we use the test statistics listed in the last column of Table 8-2.\nExample: Preliminary results from the XSORT method of gender selection in-\nvolved 14 babies, with 13 of them being girls. Here we have n = 14 and x = 13, so \npn = x>n = 13>14 = 0.929. With the null hypothesis of H0: p = 0.5, we are working \nwith the assumption that p = 0.5, and it follows that q = 1 - p = 0.5. We can evalu-\nate the test statistic as shown below (or technology can find the test statistic for us).\nz = pn - p\nA\npq\nn\n=\n13\n14 - 0.5\nB\n10.5210.52\n14\n= 3.21\nFinding the P-value and>or critical value(s) requires that we first consider whether the \nhypothesis test is two-tailed, left-tailed, or right-tailed, which are described as follows.\nTwo-Tailed, Left-Tailed, Right-Tailed\nDEFINITION\nThe critical region (or rejection region) is the area corresponding to all values of \nthe test statistic that cause us to reject the null hypothesis.\nDepending on the claim being tested, the critical region could be in the two extreme \ntails, it could be in the left tail, or it could be in the right tail.\n \n■Two-tailed test: The critical region is in the two extreme regions (tails) under \nthe curve (as in the top graph in Figure 8-2).\n \n■Left-tailed test: The critical region is in the extreme left region (tail) under the \ncurve (as in the middle graph in Figure 8-2).\n \n■Right-tailed test: The critical region is in the extreme right region (tail) under \nthe curve (as in the bottom graph in Figure 8-2).\nSign used in H1: Þ\nTwo-tailed test\nSign used in H1: ,\nLeft-tailed test\nSign used in H1: .\nRight-tailed test\nFIGURE 8-2 Critical \nRegion in Two-Tailed, \nLeft-Tailed, and Right-\nTailed Tests\nHINT Look at the symbol used in the alternative hypothesis H1.\n• The symbol 7 points to the right and the test is right-tailed.\n• The symbol 6 points to the left and the test is left-tailed.\n• The symbol ≠is used for a two-tailed test.\nExample: With H0: p = 0.5 and H1: p 7 0.5, we reject the null hypothesis and \n support the alternative hypothesis only if the sample proportion is greater than 0.5 \nby a signiﬁcant amount, so the hypothesis test in this case is right-tailed.\nP-Value Method\nWith the P-value method of testing hypotheses, we make a decision by comparing \nthe P-value to the significance level.\nDEFINITION\nIn a hypothesis test, the P-value is the probability of getting a value of the test sta-\ntistic that is at least as extreme as the test statistic obtained from the sample data, \nassuming that the null hypothesis is true.\n\n344 \nCHAPTER 8 Hypothesis Testing\nTo find the P-value, first find the area beyond the test statistic, then use the procedure \ngiven in Figure 8-3. That procedure can be summarized as follows:\n \n■Critical region in left tail:  P-value = area to the left of the test statistic\n \n■Critical region in right tail: P-value = area to the right of the test statistic\n \n■Critical region in two tails: P-value = twice the area in the tail beyond the test \nstatistic\nP-value\nP-value is\ntwice this area.\nTest statistic\nTest statistic\nTest statistic\nTest statistic\nP-value is\ntwice this area.\nP-value\nIs the test\nstatistic to the\nright or left of\ncenter?\nLeft\nRight\nLeft-tailed\nRight-tailed\nP-value 5 twice the\narea to the left of\nthe test statistic\nP-value 5 area to\nthe left of the\ntest statistic\nP-value 5 twice the\narea to the right of\nthe test statistic\nP-value 5 area to\nthe right of the\ntest statistic\nWhat type\nof test?\nStart\nFIGURE 8-3 Finding P-Values\nExample: Using only the preliminary results of the XSORT method of gender selec-\ntion, we have 13 girls in 14 births and the test statistic is z = 3.21 and it has a normal \ndistribution area of 0.0007 to its right, so a right-tailed test with test statistic z = 3.21\nhas a P-value of 0.0007.\nCAUTION Don’t confuse a P-value with the parameter p or the statistic pn. Know the \nfollowing notation:\nP-value = probability of a test statistic at least as extreme as the one obtained\np = population proportion\npn = sample proportion\nP-Value and Hypothesis Testing Controversy\nThe standard method of testing hypotheses and the use of P-values have very wide-\nspread acceptance and use, but not everyone is convinced that these methods are \nT\ng\nJournal Bans P-Values!\nThe P-value \nmethod \nof testing \nhypotheses \nhas received \nwidespread \nacceptance in \nthe research community, but the \neditors of the journal Basic and \nApplied Social Psychology took a \ndramatic stance when they said \nthat they would no longer publish \narticles that included P-values. In \nan editorial, David Trafimow and \nMichael Marks stated their belief \nthat “the P-value bar is too easy \nto pass and sometimes serves \nas an excuse for lower quality \nresearch.” David Trafimow stated \nthat he did not know which \nstatistical method should replace \nthe use of P-values.\nMany reactions to the P-value \nban acknowledged that although \nP-values can be misused and \nmisinterpreted, their use as a \nvaluable research tool remains.\n\n8-1 Basics of Hypothesis Testing \n345\nsound. Editors of the Journal of Basic and Applied Social Psychology took a strong \nstand when they said that they would no longer publish articles that included P-values. \nThey said that P-values are an excuse for lower-quality research and the P-value cri-\nterion is too easy to pass. In the past, P-values have been misinterpreted and misused, \nso a serious and important statistical analysis should not rely solely on P-value results. \nInstead, it would be wise to consider other aspects, such as the following.\n \n■Sample Size: Very large samples could result in small P-values suggesting that \nresults are significant when the results don’t really make much of a practical dif-\nference.\n \n■Power: Part 3 of this section discusses the concept of power, and it is often help-\nful to analyze power as part of an analysis.\n \n■Other Factors: Instead of relying on just one outcome such as the P-value, it \nis generally better to also consider other results, such as a confidence interval, \nresults from simulations, practical significance, design of the study, quality of \nthe sample, consequences of type I and type II errors (discussed in Part 2 of this \n section), and replication of results.\nThis chapter presents the same methods of hypothesis testing and the same use of \nP-values that are currently being used, but again, it should be stressed that important \napplications should also consider other factors, such as those listed above.\nCritical Value Method\nWith the critical value method (or traditional method) of testing hypotheses, we \nmake a decision by comparing the test statistic to the critical value(s).\nDEFINITION\nIn a hypothesis test, the critical value(s) separates the critical region (where we \nreject the null hypothesis) from the values of the test statistic that do not lead to re-\njection of the null hypothesis.\nCritical values depend on the null hypothesis, the sampling distribution, and the sig-\nnificance level a.\nExample: The critical region in Figure 8-4 is shaded in green. Figure 8-4 shows that \nwith a significance level of a = 0.05, the critical value is z = 1.645.\np 5 0.5\nor\nz 5 0\nCritical Region:\nArea of a 5 0.05\nused to identify\nsigniﬁcantly high\nsample proportions\nCritical Value:\nz 5 1.645\nFIGURE 8-4 Critical Value and Critical Region\n\n346 \nCHAPTER 8 Hypothesis Testing\nStep 7: Make a Decision to Either Reject H0 or Fail  \nto Reject H0.\nDecision Criteria for the P-Value Method:\n \n■If P-value … a, reject H0. (“If the P is low, the null must go.”)\n \n■If P-value 7 a, fail to reject H0.\nExample: With significance level a = 0.05 and P-value = 0.0007, we have \nP-value … a, so reject H0. Remember, the P-value is the probability of getting a sample \nresult at least as extreme as the one obtained, so if the P-value is low (less than or \nequal to a), the sample statistic is significantly low or significantly high.\nDecision Criteria for the Critical Value Method:\n \n■If the test statistic is in the critical region, reject H0.\n \n■If the test statistic is not in the critical region, fail to reject H0.\nExample: With test statistic z = 3.21 and the critical region from z = 1.645 to infin-\nity, the test statistic falls within the critical region, so reject H0.\nStep 8: Restate the Decision Using Simple and  \nNontechnical Terms\nWithout using technical terms not understood by most people, state a final conclusion \nthat addresses the original claim with wording that can be understood by those with-\nout knowledge of statistical procedures.\nExample: There is sufficient evidence to support the claim that with the XSORT \nmethod of gender selection, the probability of getting a baby girl is greater than 0.5.\nWording the Final Conclusion For help in wording the final conclusion, refer to \nTable 8-3, which lists the four possible circumstances and their corresponding conclu-\nsions. Note that only the first case leads to wording indicating support for the original \nconclusion. If you want to support some claim, state it in such a way that it becomes \nthe alternative hypothesis, and then hope that the null hypothesis gets rejected.\nTABLE 8-3 Wording of the Final Conclusion\nCondition\nConclusion\nOriginal claim does not include equality,  \nand you reject H0.\n“There is sufficient evidence to support the claim \nthat . . . (original claim).”\nOriginal claim does not include equality,  \nand you fail to reject H0.\n“There is not sufficient evidence to support the \nclaim that . . . (original claim).”\nOriginal claim includes equality, and you  \nreject H0.\n“There is sufficient evidence to warrant rejection \nof the claim that . . . (original claim).”\nOriginal claim includes equality, and you fail  \nto reject H0.\n“There is not sufficient evidence to warrant rejec-\ntion of the claim that . . . (original claim).”\nAccept or Fail to Reject? We should say that we “fail to reject the null hypothesis” \ninstead of saying that we “accept the null hypothesis.” The term accept is misleading, \nbecause it implies incorrectly that the null hypothesis has been proved, but we can \nnever prove a null hypothesis. The phrase fail to reject says more correctly that the \navailable evidence isn’t strong enough to warrant rejection of the null hypothesis.\nMultiple Negatives Final conclusions can include as many as three negative terms. \n(Example: “There is not sufficient evidence to warrant rejection of the claim of no dif-\nference between 0.5 and the population proportion.”) For such confusing conclusions, \nS\nto\nLie Detectors  \nand the Law\nWhy not sim-\nply require all \ncriminal sus-\npects to take \npolygraph (lie \ndetector) tests \nand eliminate \ntrials by jury? According to the \nCouncil of Scientific Affairs of the \nAmerican Medical Association, \nwhen lie detectors are used to \ndetermine guilt, accuracy can \nrange from 75% to 97%. How-\never, a high accuracy rate of 97% \ncan still result in a high percent-\nage of false positives, so it is \npossible that 50% of innocent \nsubjects incorrectly appear to \nbe guilty. Such a high chance of \nfalse positives rules out the use \nof polygraph tests as the single \ncriterion for determining guilt.\n\n8-1 Basics of Hypothesis Testing \n347\nit is better to restate them to be understandable. Instead of saying that “there is not \nsufficient evidence to warrant rejection of the claim of no difference between 0.5 and \nthe population proportion,” a better statement would be this: “Until stronger evidence \nis obtained, continue to assume that the population proportion is equal to 0.5.”\nCAUTION Never conclude a hypothesis test with a statement of “reject the \nnull hypothesis” or “fail to reject the null hypothesis.” Always make sense of the \nconclusion with a statement that uses simple nontechnical wording that addresses \nthe original claim.\nConfidence Intervals for Hypothesis Tests\nIn this section we have described the individual components used in a hypothesis test, \nbut the following sections will combine those components in comprehensive proce-\ndures. We can test claims about population parameters by using the P-value method \nor the critical value method summarized in Figure 8-1, or we can use confidence \nintervals.\nA confidence interval estimate of a population parameter contains the likely val-\nues of that parameter. If a confidence interval does not include a claimed value of a \npopulation parameter, reject that claim. For two-tailed hypothesis tests, construct a \nconfidence interval with a confidence level of 1 - a, but for a one-tailed hypothesis \ntest with significance level a, construct a confidence interval with a confidence level \nof 1 - 2a. (See Table 8-1 on page 340 for common cases.) For a left-tailed test or a \nright-tailed test, we could also use a one-sided confidence interval; see Exercise 38 in \nSection 7-1. After constructing the confidence interval, use this criterion:\nA conﬁdence interval estimate of a population parameter contains the \nlikely values of that parameter. We should therefore reject a claim that the \npopulation parameter has a value that is not included in the  conﬁdence \ninterval.\nEquivalent Methods\nIn some cases, a conclusion based on a confidence interval may be different from a \nconclusion based on a hypothesis test. The P-value method and critical value method \nare equivalent in the sense that they always lead to the same conclusion. The following \ntable shows that for the methods included in this chapter, a confidence interval estimate \nof a proportion might lead to a conclusion different from that of a hypothesis test.\n \n \nParameter\nIs a confidence interval equivalent to a hypothesis \ntest in the sense that they always lead to the same \nconclusion?\nProportion\nNo\nMean\nYes\nStandard Deviation or Variance\nYes\nPART 2\n Type I and Type II Errors \nWhen testing a null hypothesis, we arrive at a conclusion of rejecting it or failing \nto reject it. Our conclusions are sometimes correct and sometimes wrong (even \nif we apply all procedures correctly). Table 8-4 includes two different types of \n\n348 \nCHAPTER 8 Hypothesis Testing\nerrors and we distinguish between them by calling them type I and type II errors, \nas  described here:\n \n■Type I error: The mistake of rejecting the null hypothesis when it is actually \ntrue. The symbol a (alpha) is used to represent the probability of a type I error.\nA = P1type I error2 = P1rejecting H0 when H0 is true2\n \n■Type II error: The mistake of failing to reject the null hypothesis when it is actu-\nally false. The symbol b (beta) is used to represent the probability of a type II error.\nB = P1type II error2 = P1failing to reject H0 when H0 is false2\nMemory Hint for Type I and Type II Errors Remember “routine for fun,” and use \nthe consonants from those words (RouTiNe FoR FuN) to remember that a type I er-\nror is RTN: Reject True Null (hypothesis), and a type II error is FRFN: Fail to Reject a \nFalse Null (hypothesis).\nHint for Describing Type I and Type II Errors Descriptions of a type I error and \na type II error refer to the null hypothesis being true or false, but when wording a \nstatement representing a type I error or a type II error, be sure that the conclusion \naddresses the original claim (which may or may not be the null hypothesis). See \nExample 2.\nTABLE 8-4 Type I and Type II Errors\nTrue State of Nature\nNull hypothesis is true\nNull hypothesis is false\nPreliminary \nConclusion\nReject H0\nType I error:\nReject a true H0.\nP (type I error) = a\nCorrect decision\nFail to reject H0\nCorrect decision\nType II error:\nFail to reject a false H0.\nP(type II error) = b\nEXAMPLE 2  Describing Type I and Type II Errors\nConsider the claim that the XSORT gender selection method is effective in increas-\ning the likelihood of a baby girl, so that the probability of a baby girl is p 7 0.5. \nGiven the following null and alternative hypotheses, write statements describing  \n(a) a type I error, and (b) a type II error.\nH0: p = 0.5\nH1: p 7 0.5 1original claim that will be addressed in the final conclusion2\nSOLUTION\n \na. Type I Error: A type I error is the mistake of rejecting a true null hypothesis, \nso the following is a type I error: In reality p = 0.5, but sample evidence \nleads us to conclude that p 7 0.5.\n \n •  In this case, a type I error is to conclude that the XSORT gender selection \nmethod is eﬀective when in reality it has no eﬀect.\n\n8-1 Basics of Hypothesis Testing \n349\nControlling Type I and Type II Errors Step 4 in our standard procedure for test-\ning hypotheses is to select a significance level a (such as 0.05), which is the prob-\nability of a type I error. The values of a, b, and the sample size n are all related, so if \nyou choose any two of them, the third is automatically determined (although b can’t \nbe determined until an alternative value of the population parameter has been speci-\nfied along with a and n). One common practice is to select the significance level a,\nthen select a sample size that is practical, so the value of b is determined. Generally, \ntry to use the largest a that you can tolerate, but for type I errors with more serious \nconsequences, select smaller values of a. Then choose a sample size n as large as is \nreasonable, based on considerations of time, cost, and other relevant factors. Another \ncommon practice is to select a and b so the required sample size n is automatically \ndetermined. (See Example 4 in Part 3 of this section.)\nPART 3\n Power of a Hypothesis Test \nWe use b to denote the probability of failing to reject a false null hypothesis, so \nP(type II error) = b. It follows that 1 - b is the probability of rejecting a false null \nhypothesis, so 1 - b is a probability that is one measure of the effectiveness of a \n hypothesis test.\n \nb. Type II Error: A type II error is the mistake of failing to reject the null hy-\npothesis when it is false, so the following is a type II error: In reality p 7 0.5, \nbut we fail to support that conclusion.\n \n •  In this case, a type II error is to conclude that the XSORT gender selection \nmethod has no eﬀect, when it really is eﬀective in increasing the likelihood \nof a baby girl.\nDEFINITION\nThe power of a hypothesis test is the probability 1 - b of rejecting a false null \nhypothesis. The value of the power is computed by using a particular significance \nlevel a and a particular value of the population parameter that is an alternative to \nthe value assumed true in the null hypothesis.\nBecause determination of power requires a particular value that is an alternative to the \nvalue assumed in the null hypothesis, a hypothesis test can have many different values \nof power, depending on the particular values of the population parameter chosen as \nalternatives to the null hypothesis.\nEXAMPLE 3  Power of a Hypothesis Test\nConsider these preliminary results from the XSORT method of gender selection: \nThere were 13 girls among the 14 babies born to couples using the XSORT method. \nIf we want to test the claim that girls are more likely 1p 7 0.52 with the XSORT \nmethod, we have the following null and alternative hypotheses:\nH0: p = 0.5  H1: p 7 0.5\nLet’s use a significance level of a = 0.05. In addition to all given test components, \nfinding power requires that we select a particular value of p that is an alternative to \ncontinued\n\n350 \nCHAPTER 8 Hypothesis Testing\nBecause the calculations of power are quite complicated, the use of technology is \nstrongly recommended. (In this section, only Exercises 33–35 involve power.)\nPower and the Design of Experiments\nJust as 0.05 is a common choice for a significance level, a power of at least 0.80 is a \ncommon requirement for determining that a hypothesis test is effective. (Some statisti-\ncians argue that the power should be higher, such as 0.85 or 0.90.) When designing an \nexperiment, we might consider how much of a difference between the claimed value of a \nparameter and its true value is an important amount of difference. If testing the effective-\nness of the XSORT gender selection method, a change in the proportion of girls from \n0.5 to 0.501 is not very important, whereas a change in the proportion of girls from 0.5 \nto 0.9 would be very important. Such magnitudes of differences affect power. When de-\nsigning an experiment, a goal of having a power value of at least 0.80 can often be used \nto determine the minimum required sample size, as in the following example.\nthe value assumed in the null hypothesis H0: p = 0.5. Find the values of power cor-\nresponding to these alternative values of p: 0.6, 0.7, 0.8, and 0.9.\nSOLUTION\nThe values of power in the following table were found by using Minitab, and exact \ncalculations are used instead of a normal approximation to the binomial distribution.\nSpecific Alternative Value of p\nb\nPower of Test = 1 −b\n0.6\n0.820\n0.180\n0.7\n0.564\n0.436\n0.8\n0.227\n0.773\n0.9\n0.012\n0.988\nINTERPRETATION\nOn the basis of the power values listed above, we see that this hypothesis test has a \npower of 0.180 (or 18.0%) of rejecting H0: p = 0.5 when the population proportion \np is actually 0.6. That is, if the true population proportion is actually equal to 0.6, \nthere is an 18.0% chance of making the correct conclusion of rejecting the false null \nhypothesis that p = 0.5. That low power of 18.0% is not so good.\nThere is a 0.436 probability of rejecting p = 0.5 when the true value of p is \nactually 0.7. It makes sense that this test is more effective in rejecting the claim \nof p = 0.5 when the population proportion is actually 0.7 than when the popula-\ntion proportion is actually 0.6. (When identifying animals assumed to be horses, \nthere’s a better chance of rejecting an elephant as a horse—because of the greater \ndifference—than rejecting a mule as a horse.) In general, increasing the difference \nbetween the assumed parameter value and the actual parameter value results in an \nincrease in power, as shown in the table above.\nEXAMPLE 4   Finding the Sample Size Required to  \nAchieve 80% Power\nHere is a statement similar to one in an article from the Journal of the American \nMedical Association: “The trial design assumed that with a 0.05 significance level, \n153 randomly selected subjects would be needed to achieve 80% power to detect \n\n8-1 Basics of Hypothesis Testing \n351\na reduction in the coronary heart disease rate from 0.5 to 0.4.” From that statement \nwe know the following:\n \n■Before conducting the experiment, the researchers selected a significance level \nof 0.05 and a power of at least 0.80.\n \n■The researchers decided that a reduction in the proportion of coronary heart \ndisease from 0.5 to 0.4 is an important and clinically significant difference that \nthey wanted to detect (by correctly rejecting the false null hypothesis).\n \n■Using a significance level of 0.05, power of 0.80, and the alternative proportion \nof 0.4, technology such as Minitab is used to find that the required minimum \nsample size is 153.\nThe researchers can then proceed by obtaining a sample of at least 153 randomly \nselected subjects. Because of factors such as dropout rates, the researchers are likely \nto need somewhat more than 153 subjects. (See Exercise 35.)\nStatistical Literacy and Critical Thinking \n1. Vitamin C and Aspirin A bottle contains a label stating that it contains Spring Valley pills \nwith 500 mg of vitamin C, and another bottle contains a label stating that it contains Bayer pills \nwith 325 mg of aspirin. When testing claims about the mean contents of the pills, which would \nhave more serious implications: rejection of the Spring Valley vitamin C claim or rejection of \nthe Bayer aspirin claim? Is it wise to use the same significance level for hypothesis tests about \nthe mean amount of vitamin C and the mean amount of aspirin?\n2. Estimates and Hypothesis Tests Data Set 2 “Body Temperatures” in Appendix B in-\ncludes sample body temperatures. We could use methods of Chapter 7 for making an estimate, \nor we could use those values to test the common belief that the mean body temperature is \n98.6°F. What is the difference between estimating and hypothesis testing?\n3. Mean Height of Men A formal hypothesis test is to be conducted using the claim that the \nmean height of men is equal to 174.1 cm.\na. What is the null hypothesis, and how is it denoted?\nb. What is the alternative hypothesis, and how is it denoted?\nc. What are the possible conclusions that can be made about the null hypothesis?\nd. Is it possible to conclude that “there is sufficient evidence to support the claim that the mean \nheight of men is equal to 174.1 cm”?\n4. Interpreting P-value The Ericsson method is one of several methods claimed to increase \nthe likelihood of a baby girl. In a clinical trial, results could be analyzed with a formal hypoth-\nesis test with the alternative hypothesis of p 7 0.5, which corresponds to the claim that the \nmethod increases the likelihood of having a girl, so that the proportion of girls is greater than \n0.5. If you have an interest in establishing the success of the method, which of the following \nP-values would you prefer: 0.999, 0.5, 0.95, 0.05, 0.01, 0.001? Why?\nIdentifying H0 and H1. In Exercises 5–8, do the following:\na. Express the original claim in symbolic form.\nb. Identify the null and alternative hypotheses.\n5. Hypertension Claim: Most adults do not have hypertension. When 983 randomly selected \nadults were tested, it was found that 70.9% of them do not have hypertension.\n8-1 Basic Skills and Concepts\n\n352 \nCHAPTER 8 Hypothesis Testing\n6. Cell Phones Claim: Fewer than 95% of nurses have a cell phone. In a survey of 1128 \nnurses, 87% said that they have a cell phone.\n7. Pulse Rates Claim: The mean pulse rate (in beats per minute, or bpm) of adult males is \nequal to 69 bpm. For the random sample of 153 adult males in Data Set 1 “Body Data” from \nAppendix B, the mean pulse rate is 69.6 bpm and the standard deviation is 11.3 bpm.\n8. Pulse Rates Claim: The standard deviation of pulse rates of adult males is more than 11 \nbpm. For the random sample of 153 adult males in Data Set 1 “Body Data” from Appendix B, \nthe pulse rates have a standard deviation of 11.3 bpm.\nConclusions. In Exercises 9–12, refer to the exercise identified. Make subjective esti-\nmates to decide whether results are significantly low or significantly high, then state a con-\nclusion about the original claim. For example, if the claim is that a coin favors heads and \nsample results consist of 11 heads in 20 flips, conclude that there is not sufficient evidence \nto support the claim that the coin favors heads (because it is easy to get 11 heads in 20 flips \nby chance with a fair coin).\n9. Exercise 5 “Hypertension” \n10. Exercise 6 “Cell Phone”\n11. Exercise 7 “Pulse Rates” \n12. Exercise 8 “Pulse Rates”\nTest Statistics. In Exercises 13–16, refer to the exercise identified and find the value of the \ntest statistic. (Refer to Table 8-2 on page 342 to select the correct expression for evaluating the \ntest statistic.)\n13. Exercise 5 “Hypertension” \n14. Exercise 6 “Cell Phone”\n15. Exercise 7 “Pulse Rates” \n16. Exercise 8 “Pulse Rates”\nP-Values. In Exercises 17–20, do the following:\na. Identify the hypothesis test as being two-tailed, left-tailed, or right-tailed.\nb. Find the P-value. (See Figure 8-3 on page 344.)\nc. Using a significance level of a = 0.05, should we reject H0 or should we fail to reject H0?\n17. The test statistic of z = 1.00 is obtained when testing the claim that p 7 0.3.\n18. The test statistic of z = -2.50 is obtained when testing the claim that p 6 0.75.\n19. The test statistic of z = 2.01 is obtained when testing the claim that p ≠0.345.\n20. The test statistic of z = -1.94 is obtained when testing the claim that p = 3>8.\nCritical Values. In Exercises 21–24, refer to the information in the given exercise and do \nthe following.\na. Find the critical value(s).\nb. Using a significance level of a = 0.05, should we reject H0 or should we fail to reject H0?\n21. Exercise 17 \n22. Exercise 18\n23. Exercise 19 \n24. Exercise 20\nFinal Conclusions. In Exercises 25–28, use a significance level of A = 0.05 and use the \ngiven information for the following:\na. State a conclusion about the null hypothesis. (Reject H0 or fail to reject H0.)\nb. Without using technical terms or symbols, state a final conclusion that addresses the original \nclaim.\n 25. Original claim: More than 70% of adults do not have hypertension. The hypothesis test \nresults in a P-value of 0.2678.\n\n8-1 Basics of Hypothesis Testing \n353\n 26. Original claim: Fewer than 90% of nurses have a cell phone. The hypothesis test results in \na P-value of 0.0003.\n27. Original claim: The mean pulse rate (in beats per minute) of adult males is 72 bpm. The \nhypothesis test results in a P-value of 0.0095.\n28. Original claim: The standard deviation of pulse rates of adult males is more than 11 bpm. \nThe hypothesis test results in a P-value of 0.3045.\nType I and Type II Errors. In Exercises 29–32, provide statements that identify the type I \nerror and the type II error that correspond to the given claim. (Although conclusions are \nusually expressed in verbal form, the answers here can be expressed with statements that \ninclude symbolic expressions such as p = 0.1.)\n29. The proportion of people who write with their left hand is equal to 0.1.\n30. The proportion of people with blue eyes is equal to 0.35.\n31. The proportion of adults who use the Internet is greater than 0.87.\n32. The proportion of people who require no vision correction is less than 0.25.\n33. Interpreting Power Chantix (varenicline) tablets are used as an aid to help people stop \nsmoking. In a clinical trial, 129 subjects were treated with Chantix twice a day for 12 weeks, \nand 16 subjects experienced abdominal pain (based on data from Pfizer, Inc.). If someone \nclaims that more than 8% of Chantix users experience abdominal pain, that claim is supported \nwith a hypothesis test conducted with a 0.05 significance level. Using 0.18 as an alternative \nvalue of p, the power of the test is 0.96. Interpret this value of the power of the test.\n34. Calculating Power Consider a hypothesis test of the claim that the Ericsson method of \ngender selection is effective in increasing the likelihood of having a baby girl, so that the claim \nis p 7 0.5. Assume that a significance level of a = 0.05 is used, and the sample is a simple \nrandom sample of size n = 64.\na. Assuming that the true population proportion is 0.65, find the power of the test, which is \nthe probability of rejecting the null hypothesis when it is false. (Hint: With a 0.05 significance \nlevel, the critical value is z = 1.645, so any test statistic in the right tail of the accompanying \ntop graph is in the rejection region where the claim is supported. Find the sample proportion pn\nin the top graph, and use it to find the power shown in the bottom graph.)\nb\nz 5 1.645\na 5 0.05\np 5 0.5\np 5 0.65\nPower\nb. Explain why the green-shaded region of the bottom graph represents the power of the test.\n35. Finding Sample Size to Achieve Power Researchers plan to conduct a test of a gender \nselection method. They plan to use the alternative hypothesis of H1: p 7 0.5 and a significance \nlevel of a = 0.05. Find the sample size required to achieve at least 80% power in detecting an \nincrease in p from 0.50 to 0.55. (This is a very difficult exercise. Hint: See Exercise 34.)\n8-1 Beyond the Basics\n\n354 \nCHAPTER 8 Hypothesis Testing\nKey Concept This section describes a complete procedure for testing a claim made \nabout a population proportion p. We illustrate hypothesis testing with the P-value \nmethod, the critical value method, and the use of confidence intervals. The methods of \nthis section can be used with claims about population proportions, probabilities, or the \ndecimal equivalents of percentages.\nThere are different methods for testing a claim about a population proportion. \nPart 1 of this section is based on the use of a normal approximation to a binomial \ndistribution, and this method serves well as an introduction to basic concepts, but it \nis not a method used by professional statisticians. Part 2 discusses other methods that \nmight require the use of technology.\nPART 1\n Normal Approximation Method\nThe following box includes the key elements used for testing a claim about a population \nproportion by using a normal distribution as an approximation to a binomial distribution.\n8-2 \nTesting a Claim About a Proportion\nTesting a Claim About a Population Proportion (Normal Approximation Method)\nObjective\nConduct a formal hypothesis test of a claim about a population proportion p.\nNotation\nKEY ELEMENTS \nn = sample size or number of trials\npn = x\nn (sample proportion)\np =  population proportion (p is the value used in the \nstatement of the null hypothesis)\nq = 1 - p\nRequirements\n1. The sample observations are a simple random sample.\n2. The conditions for a binomial distribution are satisfied:\n • There is a fixed number of trials.\n • The trials are independent.\n • Each trial has two categories of “success” and “failure.”\n • The probability of a success remains the same in all \ntrials.\n3. The conditions np Ú 5 and nq Ú 5 are both satisfied, \nso the binomial distribution of sample proportions \ncan be approximated by a normal distribution with \nm = np and s = 1npq (as described in Section 6-6). \nNote that p used here is the assumed proportion used in \nthe claim, not the sample proportion pn.\nTest Statistic for Testing a Claim About a Proportion\nz = pn - p\nA\npq\nn\nP-Values: P-values are automatically provided by technol-\nogy. If technology is not available, use the standard normal \ndistribution (Table A-2) and refer to Figure 8-1 on page 340.\nCritical Values: Use the standard normal distribution \n(Table A-2).\nThe test statistic does not include a correction for continuity (as described in Section 6-6), \nbecause its effect tends to be very small with large samples.\n\n8-2 Testing a Claim About a Proportion \n355\nEquivalent Methods\nWhen testing claims about proportions, the confidence interval method is not equiv-\nalent to the P-value and critical value methods, so the confidence interval method \ncould result in a different conclusion. (Both the P-value method and the critical value \nmethod use the same standard deviation based on the claimed proportion p, so they \nare equivalent to each other, but the confidence interval method uses an estimated \nstandard deviation based on the sample proportion.) Recommendation: Use a confi-\ndence interval to estimate a population proportion, but use the P-value method or criti-\ncal value method for testing a claim about a proportion. See Exercise 30.\nClaim: The XSORT Method of Gender Selection  \nIs Effective\nLet’s use the preliminary results from tests of the XSORT method of gender selection. \nThose preliminary results consisted of 14 babies born to couples using the XSORT \nmethod of gender selection, and 13 of the babies were girls. Use these results to test \nthe claim that most babies born to couples using the XSORT method are girls. We \ninterpret “most” to mean “more than half” or “greater than 0.5.”\nREQUIREMENT CHECK We first check the three requirements.\n1. The 14 babies are not randomly selected, but based on the design of the clinical \ntrial, they can be treated as being random.\n2. There is a fixed number (14) of independent trials with two categories (the baby \nis a girl or is not).\n3. The requirements np Ú 5 and nq Ú 5 are both satisfied with n = 14, \np = 0.5, and q = 0.5. [The value of p = 0.5 comes from the claim. We \nget np = 114210.52 = 7, which is greater than or equal to 5, and we get \nnq = 114210.52 = 7, which is also greater than or equal to 5.]\nThe three requirements are satisfied. \nSolution: P-Value Method\nTechnology Computer programs and calculators usually provide a P-value, so the \nP-value method is used. Different technologies will display the test statistic of \nz = 3.21 and the P-value of 0.0007.\nTable A-2 If technology is not available, Figure 8-1 on page 340 in the preceding sec-\ntion lists the steps for using the P-value method. Using those steps from Figure 8-1, \nwe can test the claim that “most babies born to couples using the XSORT method are \ngirls” as follows.\nStep 1: The original claim is that the XSORT method is effective in increasing the like-\nlihood of a baby girl, and that claim can be expressed in symbolic form as p 7 0.5.\nStep 2: The opposite of the original claim is p … 0.5.\nStep 3: Of the preceding two symbolic expressions, the expression p 7 0.5 does not \ncontain equality, so it becomes the alternative hypothesis. The null hypothesis is the state-\nment that p equals the fixed value of 0.5. We can therefore express H0 and H1 as follows:\nH0: p = 0.5\nH1: p 7 0.5 1original claim2\nv-\nd \nue \ny\nd \nProcess of Drug \nApproval\nGaining Food \nand Drug \nAdministration \n(FDA) approval \nfor a new drug \nis expensive \nand time- \nconsuming. \nHere are the different stages of \ngetting approval for a new drug:\n• Phase I study: The safety of \nthe drug is tested with a small \n(20–100) group of volunteers.\n• Phase II: The drug is tested for \neffectiveness in randomized tri-\nals involving a larger (100–300) \ngroup of subjects. This phase \noften has subjects randomly \nassigned to either a treatment \ngroup or a placebo group.\n• Phase III: The goal is to better \nunderstand the effective-\nness of the drug as well as its \nadverse reactions. This phase \ntypically involves 1,000–3,000 \nsubjects, and it might require \nseveral years of testing.\nLisa Gibbs wrote in Money \nmagazine that “the (drug) indus-\ntry points out that for every 5,000 \ntreatments tested, only 5 make it \nto clinical trials and only 1 ends \nup in drugstores.” Total cost \nestimates vary from a low of  \n$40 million to as much as  \n$1.5 billion.\ncontinued\n\n356 \nCHAPTER 8 Hypothesis Testing\nStep 4: For the significance level, we select a = 0.05, which is a very common \nchoice.\nStep 5: Because we are testing a claim about a population proportion p, the sample sta-\ntistic pn is relevant to this test. The sampling distribution of sample proportions pn can be \napproximated by a normal distribution in this case (as described in Section 6-3).\nStep 6: The test statistic z = 3.21 can be found by using technology, or it can be \ncalculated by using pn = 13>14 (sample proportion), n = 14 (sample size), p = 0.5 \n(assumed in the null hypothesis), and q = 1 - 0.5 = 0.5.\nz = pn - p\nA\npq\nn\n=\n13\n14 - 0.5\nB\n10.5210.52\n14\n= 3.21\nThe P-value can be found from technology, or it can be found by using the fol-\nlowing procedure, which is shown in Figure 8-3 on page 344:\nLeft-tailed test: \nP-value = area to left of test statistic z\nRight-tailed test: \nP-value = area to right of test statistic z\nTwo-tailed test: \nP-value =  twice the area of the extreme region bounded by \nthe test statistic z\nBecause this hypothesis test is right-tailed with a test statistic of z = 3.21, the \nP-value is the area to the right of z = 3.21. Referring to Table A-2, we see that the \ncumulative area to the left of z = 3.21 is 0.9993, so the area to the right of that test \nstatistic is 1 - 0.9993 = 0.0007. We get P-value = 0.0007. Figure 8-5 shows the \ntest statistic and P-value for this example.\nStep 7: Because the P-value of 0.0007 is less than or equal to the significance level \nof a = 0.05, we reject the null hypothesis.\nStep 8: Because we reject H0: p = 0.5, we support the alternative hypothesis of \np 7 0.5. We conclude that there is sufficient sample evidence to support the claim \nthat the XSORT method is effective in increasing the likelihood of a baby girl. (See \nTable 8-3 on page 346 for help with wording this final conclusion.)\np 5 0.5\nor\nz 5 0\nP-value 5 0.0007\np 5     5 0.929\nor\nz 5 3.21\nˆ\n13\n14\nFIGURE 8-5 P-Value Method\np 5 0.5\nor\nz 5 0\nCritical Region:\nArea of a 5 0.05\nused to identify\nsigniﬁcantly high\nsample proportions\nCritical Value:\nz 5 1.645\nFIGURE 8-6 Critical Value Method\n\n8-2 Testing a Claim About a Proportion \n357\nSolution: Critical Value Method\nThe critical value method of testing hypotheses is summarized in Figure 8-1 on \npage 340 in Section 8-1. When using the critical value method with the claim that \n“most babies born to couples using the XSORT method are girls,” Steps 1 through \n5 are the same as Steps 1 through 5 for the P-value method, as shown. We continue \nwith Step 6 of the critical value method.\nStep 6: The test statistic is computed to be z = 3.21, as shown for the preceding \nP-value method. With the critical value method, we now find the critical values (in-\nstead of the P-value). This is a right-tailed test, so the area of the critical region is an \narea of a = 0.05 in the right tail. Referring to Table A-2 and applying the methods \nof Section 6-1, we find that the critical value is z = 1.645, which is at the boundary \nof the critical region, as shown in Figure 8-6.\nStep 7: Because the test statistic does fall within the critical region, we reject the null \nhypothesis.\nStep 8: Because we reject H0: p = 0.5, we conclude that there is sufficient sample \nevidence to support the claim that for couples using the XSORT gender selection \nmethod, most (more than half) of their babies are girls.\nSolution: Confidence Interval Method\nThe claim that “with the XSORT method of gender selection, most babies are girls” is \na claim that can be tested with a 0.05 significance level by constructing a 90% confi-\ndence interval. (See Table 8-1 on page 340 to see why the 0.05 significance level cor-\nresponds to a 90% confidence interval.)\nThe 90% confidence interval estimate of the population proportion p is found \nusing the sample data consisting of n = 14 and pn = 13>14. Using the methods of \n Section 7-1 we get: 0.815 6 p 6 1.042. The entire range of values in this confidence \ninterval is greater than 0.5. Because we are 90% confident that the limits of 0.815 and \n1.042 contain the true value of p, the sample data appear to support the claim that \nmost (more than 0.5) XSORT babies are girls. In this case, the conclusion is the same \nas with the P-value method and the critical value method, but that is not always the \ncase. It is possible that a conclusion based on the confidence interval can be different \nfrom the conclusion based on the P-value method or critical value method.\nFinding the Number of Successes x\nWhen using technology for hypothesis tests of proportions, we must usually enter \nthe sample size n and the number of successes x, but in real applications the sample \nproportion pn is often given instead of x. The number of successes x can be found by \nevaluating x = npn, as illustrated in Example 1. Note that in Example 1, the result of \n5587.712 adults must be rounded to the nearest whole number of 5588.\nCAUTION: Don’t confuse the following notation.\n•  P-value = probability of getting a test statistic at least as extreme as the one repre-\nsenting the sample data, assuming that the null hypothesis H0 is true\n• p = population proportion\n• pn = sample proportion\n-\nIs 0.05 a Bad Choice?\nThe value of \n0.05 is a very \ncommon choice \nfor serving as \nthe cutoff sepa-\nrating results \nconsidered to \nbe significant from those that are \nnot. Science writer John Timmer \nwrote in Ars Technica that some \nproblems with conclusions in \nscience are attributable to the \nfact that statistics is sometimes \nweak because of the common \nuse of 0.05 for a significance \nlevel. He gives examples of \nparticle physics and genetics \nexperiments in which P-values \nmust be much lower than 0.05. \nHe cites a study by statistician \nValen Johnson, who suggested \nthat we should raise standards \nby requiring that experiments use \na P-value of 0.005 or lower. We \ndo know that the choice of 0.05 \nis largely arbitrary, and lowering \nthe significance level will result \nin fewer conclusions of signifi-\ncance, along with fewer wrong \nconclusions.\n\n358 \nCHAPTER 8 Hypothesis Testing\nEXAMPLE 1  Finding the Number of Successes x\nA study of sleepwalking or “nocturnal wandering” was described in the journal \nNeurology, and it included information that 29.2% of 19,136 American adults have \nsleepwalked. What is the actual number of adults who have sleepwalked?\nSOLUTION\nThe number of adults who have sleepwalked is 29.2% of 19,136, or 0.292 * 19,136\n= 5587.712, but the result must be a whole number, so we round the product to the \nnearest whole number of 5588.\nCAUTION When conducting hypothesis tests of claims about proportions, slightly \ndifferent results can be obtained when calculating the test statistic using a given \nsample proportion instead of using a rounded value of x found by using x = npn.\nEXAMPLE 2  Fewer Than 30% of Adults Have Sleepwalked\nUsing the same sleepwalking data from Example 1 (n = 19,136 and pn = 29.2%),  \nwould a reporter be justified in stating that “fewer than 30% of adults have sleep-\nwalked”? Let’s use a 0.05 significance level to test the claim that for the adult popu-\nlation, the proportion of those who have sleepwalked is less than 0.30.\nSOLUTION\nREQUIREMENT CHECK (1) The sample is a simple random sample. (2) There is a \nfixed number (19,136) of independent trials with two categories (a subject has \nsleepwalked or has not). (3) The requirements np Ú 5 and nq Ú 5 are both satisfied \nwith n = 19,136 and p = 0.30. [We get np = 119,136210.302 = 5740.8, which \nis greater than or equal to 5, and we also get nq = 119,136210.702 = 13,395.2, \nwhich is greater than or equal to 5.] The three requirements are all satisfied. \nStep 1: The original claim is expressed in symbolic form as p 6 0.30.\nStep 2: The opposite of the original claim is p Ú 0.30.\nStep 3: Because p 6 0.30 does not contain equality, it becomes H1. We get\nH0: p = 0.30 1null hypothesis2\nH1: p 6 0.30 1alternative hypothesis and original claim2\nStep 4: The significance level is a = 0.05.\nStep 5: Because the claim involves the proportion p, the statistic relevant to this test \nis the sample proportion pn and the sampling distribution of sample proportions can \nbe approximated by the normal distribution.\nStep 6: Technology If using technology, the test statistic and the P-value will be \nprovided. See the following results from StatCrunch showing that the test statistic is \nz = -2.41 (rounded) and the P-value = 0.008.\n\n8-2 Testing a Claim About a Proportion \n359\nCritical Value Method If we were to repeat Example 2 using the critical value method of \ntesting hypotheses, we would see that in Step 6 the critical value is z = -1.645, which \ncan be found from technology or Table A-2. In Step 7 we would reject the null hypothesis \nbecause the test statistic of z = -2.41 would fall within the critical region bounded by \nz = -1.645. We would then reach the same conclusion given in Example 2.\nConfidence Interval Method If we were to repeat Example 2 using the confidence \ninterval method, we would use a 90% confidence level because we have a left-tailed \ntest. (See Table 8-1.) We get this 90% confidence interval: 0.287 6 p 6 0.297. Be-\ncause the entire range of the confidence interval falls below 0.30, there is sufficient \nevidence to support the claim that fewer than 30% of adults have sleepwalked.\nPART 2\nExact Methods for Testing Claims About a \nPopulation Proportion p\nInstead of using the normal distribution as an approximation to the binomial distribu-\ntion, we can get exact results by using the binomial probability distribution itself. Bi-\nnomial probabilities are a real nuisance to calculate manually, but technology makes \nTable A-2 If technology is not available, proceed as follows to conduct the  \nhypothesis test using the P-value method summarized in Figure 8-1 on page 340.\nThe test statistic z = -2.41 is calculated as follows:\nz = pn - p\nA\npq\nn\n=\n5588\n19,136 - 0.30\nB\n10.30210.702\n19,136\n= -2.41\nRefer to Figure 8-3 on page 344 for the procedure for finding the P-value.  \nFigure 8-3 shows that for this left-tailed test, the P-value is the area to the left of \nthe test statistic. Using Table A-2, we see that the area to the left of z = -2.41 is \n0.0080, so the P-value is 0.0080.\nStep 7: Because the P-value of 0.0080 is less than or equal to the significance level \nof 0.05, we reject the null hypothesis.\nINTERPRETATION\nBecause we reject the null hypothesis, we support the alternative hypothesis. We \ntherefore conclude that there is sufficient evidence to support the claim that fewer \nthan 30% of adults have sleepwalked.\nStatCrunch\nLefties Die Sooner?\nA study by \npsychologists \nDiane Halpern \nand Stanley \nCoren received \nconsiderable \nmedia atten-\ntion and generated considerable \ninterest when it concluded that \nleft-handed people don’t live as \nlong as right-handed people. \nBased on their study, it appeared \nthat left-handed people live an \naverage of nine years less than \nrighties. The Halpern>Coren \nstudy has been criticized for \nusing flawed data. They used \nsecond-hand data by surveying \nrelatives about people who had \nrecently died. The myth of lefties \ndying younger became folklore \nthat has survived many years. \nHowever, more recent studies \nshow that left-handed people do \nnot have shorter lives than those \nwho are right-handed.\n\n360 \nCHAPTER 8 Hypothesis Testing\nthis approach quite simple. Also, this exact approach does not require that np Ú 5 and \nnq Ú 5, so we have a method that applies when that requirement is not satisfied. To \ntest hypotheses using the exact method, find P-values as follows:\nExact Method Identify the sample size n, the number of successes x, and the claimed \nvalue of the population proportion p (used in the null hypothesis); then find the P-value \nby using technology for finding binomial probabilities as follows:\nLeft-tailed test:   P-value = P1x or fewer successes among n trials2\nRight-tailed test:   P-value = P1x or more successes among n trials2\nTwo-tailed test:   P-value =  twice the smaller of the preceding left-tailed and \nright-tailed values\nNote: There is no universally accepted method for the above two-tailed exact case, \nso this case can be treated with other different approaches, some of which are quite \ncomplex. For example, Minitab uses a “likelihood ratio test” that is different from the \nabove approach that is commonly used.\nEXAMPLE 3  Using the Exact Method\nIn testing a method of gender selection, 10 randomly selected couples are treated \nwith the method, they each have a baby, and 9 of the babies are girls. Use a 0.05 \nsignificance level to test the claim that with this method, the probability of a baby \nbeing a girl is greater than 0.75.\nSOLUTION\nREQUIREMENT CHECK The normal approximation method described in Part 1 of \nthis section requires that np Ú 5 and nq Ú 5, but nq = (10)(0.25) = 2.5, so the \nrequirement is violated. The exact method has only the requirements of being a \nsimple random sample and satisfying the conditions for binomial distribution, and \nthose two requirements are satisfied. \nHere are the null and alternative hypotheses:\nH0: p = 0.75 1null hypothesis2\nH1: p 7 0.75 1alternative hypothesis and original claim2\nInstead of using the normal distribution, we use technology to find probabilities in a \nbinomial distribution with p = 0.75. Because this is a right-tailed test, the P-value \nis the probability of 9 or more successes among 10 trials, assuming that p = 0.75. \nSee the following Statdisk display of exact probabilities from the binomial distri-\nbution. This Statdisk display shows that the probability of 9 or more successes is \n0.2440252 when rounded to seven decimal places, so the P-value is 0.2440252. The \nP-value is high (greater than 0.05), so we fail to reject the null hypothesis. There is \nnot sufficient evidence to support the claim that with the gender selection method, \nthe probability of a girl is greater than 0.75.\n\n8-2 Testing a Claim About a Proportion \n361\nImproving the Exact Method A criticism of the exact method is that it is too conser-\nvative in the sense that the actual probability of a type I error is typically less than or \nequal to a, and it could be much lower than a.\nWith the exact method, the actual probability of a type I error is less than \nor equal to A, which is the desired probability of a type I error.\nA simple continuity correction improves the conservative behavior of the exact \nmethod with an adjustment to the P-value that is obtained by subtracting from it the \nvalue that is one-half the binomial probability at the boundary, as shown below. (See \nExercise 33.) This method is easy to apply if technology is available for finding bino-\nmial probabilities.\nSimple Continuity Correction to the Exact Method\nLeft-tailed test: \nP-value = P1x or fewer2 - 1\n2P1exactly x2\nRight-tailed test: \nP-value = P1x or more2 - 1\n2P1exactly x2\nTwo-tailed test: \n P-value =  twice the smaller of the preceding left-tailed \nand right-tailed values\nThe above “simple continuity correction” is described in “Modifying the Exact Test for a \nBinomial Proportion and Comparisons with Other Approaches,” by Alan Huston, Jour-\nnal of Applied Statistics, Vol. 33, No. 7. For another improvement that uses weighted tail \nareas based on a measure of skewness, see the preceding article by Alan Huston.\nStatdisk\nHypothesis Test: Proportion\nAccess tech instructions, videos, and data sets at www.TriolaStats.com\nTECH CENTER \n\n362 \nCHAPTER 8 Hypothesis Testing\nStatistical Literacy and Critical Thinking\nIn Exercises 1–4, use these results from a USA Today survey in which 510 people chose to \nrespond to this question that was posted on the USA Today website: “Should Americans \nreplace passwords with biometric security (fingerprints, etc)?” Among the respondents, 53% \nsaid yes. We want to test the claim that more than half of the population believes that pass-\nwords should be replaced with biometric security.\n1. Number and Proportion\na. Identify the actual number of respondents who answered yes.\nb. Identify the sample proportion and the symbol used to represent it.\n2. Null and Alternative Hypotheses Identify the null hypothesis and alternative hypothesis.\n3. Equivalence of Methods If we use the same significance level to conduct the hypoth-\nesis test using the P-value method, the critical value method, and a confidence interval, which \nmethod is not equivalent to the other two?\n4. Requirements and Conclusions\na. Are any of the three requirements violated? Can the methods of this section be used to test \nthe claim?\nb. It was stated that we can easily remember how to interpret P-values with this: “If the P is \nlow, the null must go.” What does this mean?\nc. Another memory trick commonly used is this: “If the P is high, the null will fly.” Given that \na hypothesis test never results in a conclusion of proving or supporting a null hypothesis, how \nis this memory trick misleading?\nd. Common significance levels are 0.01 and 0.05. Why would it be unwise to use a significance \nlevel with a number like 0.0483?\nUsing Technology. In Exercises 5–8, identify the indicated values or interpret the given \ndisplay. Use the normal distribution as an approximation to the binomial distribution as \n described in Part 1 of this section. Use a 0.05 significance level and answer the following:\na. Is the test two-tailed, left-tailed, or right-tailed?\nb. What is the test statistic?\nc. What is the P-value?\nd. What is the null hypothesis, and what do you conclude about it?\ne. What is the final conclusion?\n5. Adverse Reactions to Drug The drug Lipitor (atorvastatin) is used to treat high choles-\nterol. In a clinical trial of Lipitor, 47 of 863 treated subjects experienced headaches (based on \ndata from Pfizer). The accompanying TI-83>84 Plus calculator display shows results from a \ntest of the claim that fewer than 10% of treated subjects experience headaches.\n8-2 Basic Skills and Concepts\nTI-83 , 84 Plus\n\n8-2 Testing a Claim About a Proportion \n363\n6. Self-Driving Vehicles In a TE Connectivity survey of 1000 adults, 29% said that they \nwould feel comfortable in a self-driving vehicle. The accompanying StatCrunch display results \nfrom testing the claim that more than 1>4 of adults feel comfortable in a self-driving vehicle.\nStatCrunch\n7. Hygiene A KRC Research poll of 1020 randomly selected adults showed that 65% of them \nwash their hands after touching an animal. The following Minitab display results from a test of \nthe claim that 67% of adults wash their hands after touching an animal.\nMinitab\n8. Biometric Security In a USA Today survey of 510 people, 53% said that we should replace \npasswords with biometric security, such as fingerprints. The accompanying Statdisk display \nresults from a test of the claim that half of us say that we should replace passwords with bio-\nmetric security.\nTesting Claims About Proportions. In Exercises 9–28, test the given claim. Identify the \nnull hypothesis, alternative hypothesis, test statistic, P-value, or critical value(s), then state \nthe conclusion about the null hypothesis, as well as the final conclusion that addresses the \noriginal claim. Use the P-value method unless your instructor specifies otherwise. Use the \nnormal distribution as an approximation to the binomial distribution, as described in Part 1 \nof this section.\n9. Gender Selection The Genetics & IVF Institute conducted a clinical trial of the YSORT \nmethod designed to increase the probability of conceiving a boy. 291 babies were born to parents \nusing the YSORT method, and 239 of them were boys. Use a 0.01 significance level to test the \nclaim that the YSORT method is effective in increasing the likelihood that a baby will be a boy.\n10. Eliquis The drug Eliquis (apixaban) is used to help prevent blood clots in certain patients. \nIn clinical trials, among 5924 patients treated with Eliquis, 153 developed the adverse reaction \nof nausea (based on data from Bristol-Myers Squibb Co.). Use a 0.05 significance level to test \nthe claim that 3% of Eliquis users develop nausea. Does nausea appear to be a problematic \nadverse reaction?\n11. Stem Cell Survey Adults were randomly selected for a Newsweek poll. They were asked \nif they “favor or oppose using federal tax dollars to fund medical research using stem cells \nobtained from human embryos.” Of those polled, 481 were in favor, 401 were opposed, and \n120 were unsure. A politician claims that people don’t really understand the stem cell issue and \ntheir responses to such questions are random responses equivalent to a coin toss. Exclude the \n120 subjects who said that they were unsure, and use a 0.01 significance level to test the claim \nthat the proportion of subjects who respond in favor is equal to 0.5. What does the result sug-\ngest about the politician’s claim?\n12. Clinical Trial of Tamiflu Clinical trials involved treating flu patients with Tamiflu (osel-\ntamivir phosphate), which is a medicine intended to attack the influenza virus and stop it from \ncausing flu symptoms. Among 724 patients treated with Tamiflu, 72 experienced nausea as an \nadverse reaction. Use a 0.05 significance level to test the claim that the rate of nausea is greater \nthan the 6% rate experienced by flu patients given a placebo. Does nausea appear to be a con-\ncern for those given the Tamiflu treatment?\nStatdisk\n\n364 \nCHAPTER 8 Hypothesis Testing\n13. OxyContin The drug OxyContin (oxycodone) is used to treat pain, but it is dangerous \nbecause it is addictive and can be lethal. In clinical trials, 227 subjects were treated with \n OxyContin and 52 of them developed nausea (based on data from Purdue Pharma L.P.). Use a \n0.05 significance level to test the claim that more than 20% of OxyContin users develop nau-\nsea. Does the rate of nausea appear to be too high?\n14. Medical Malpractice In a study of 1228 randomly selected medical malpractice lawsuits, \nit was found that 856 of them were dropped or dismissed (based on data from the Physicians \nInsurers Association of America). Use a 0.01 significance level to test the claim that most medi-\ncal malpractice lawsuits are dropped or dismissed. Should this be comforting to physicians?\n15. Survey Return Rate In a study of cell phone use and brain hemispheric dominance, an \nInternet survey was e-mailed to 5000 subjects randomly selected from an online group involved \nwith ears. 717 surveys were returned. Use a 0.01 significance level to test the claim that the \nreturn rate is less than 15%.\n16. Drug Screening The company Drug Test Success provides a “1-Panel-THC” test for mar-\nijuana usage. Among 300 tested subjects, results from 27 subjects were wrong (either a false \npositive or a false negative). Use a 0.05 significance level to test the claim that less than 10% of \nthe test results are wrong. Does the test appear to be good for most purposes?\n17. Births A random sample of 860 births in New York State included 426 boys. Use a 0.05 \nsignificance level to test the claim that 51.2% of newborn babies are boys. Do the results sup-\nport the belief that 51.2% of newborn babies are boys?\n18. Mendelian Genetics When Mendel conducted his famous genetics experiments with \npeas, one sample of offspring consisted of 428 green peas and 152 yellow peas. Use a 0.01 \nsignificance level to test Mendel’s claim that under the same circumstances, 25% of offspring \npeas will be yellow. What can we conclude about Mendel’s claim?\n19. Predicting Gender of Baby A study addressed the issue of whether pregnant women can \ncorrectly guess the gender of their baby. Among 104 recruited subjects, 55% correctly guessed \nthe gender of the baby (based on data from “Are Women Carrying ‘Basketballs’ Really Having \nBoys? Testing Pregnancy Folklore,” by Perry, DiPietro, and Constigan, Birth, Vol. 26, No. 3). \nUse these sample data to test the claim that the success rate of such guesses is no different from \nthe 50% success rate expected with random chance guesses. Use a 0.05 significance level.\n20. Predicting Gender of Baby In the same study cited in the preceding exercise, 45 of the \npregnant women had more than 12 years of education, and 32 of them made correct predic-\ntions. Use these results to test the claim that women with more than 12 years of education have \na proportion of correct predictions that is greater than the 0.5 proportion expected with random \nguesses. Use a 0.01 significance level. Do these women appear to have an ability to correctly \npredict the gender of their babies?\n21. Touch Therapy When she was 9 years of age, Emily Rosa did a science fair experiment \nin which she tested professional touch therapists to see if they could sense her energy field. She \nflipped a coin to select either her right hand or her left hand, and then she asked the therapists \nto identify the selected hand by placing their hand just under Emily’s hand without seeing it \nand without touching it. Among 280 trials, the touch therapists were correct 123 times (based \non data in “A Close Look at Therapeutic Touch,” Journal of the American Medical Associa-\ntion, Vol. 279, No. 13). Use a 0.10 significance level to test the claim that touch therapists use a \nmethod equivalent to random guesses. Do the results suggest that touch therapists are effective?\n22. Touch Therapy Repeat the preceding exercise using a 0.01 significance level. Does the \nconclusion change?\n23. Cell Phones and Cancer In a study of 420,095 Danish cell phone users, 135 subjects de-\nveloped cancer of the brain or nervous system (based on data from the Journal of the National \nCancer Institute as reported in USA Today). Test the claim of a somewhat common belief that \nsuch cancers are affected by cell phone use. That is, test the claim that cell phone users develop \ncancer of the brain or nervous system at a rate that is different from the rate of 0.0340% for \n\n8-2 Testing a Claim About a Proportion \n365\npeople who do not use cell phones. Because this issue has such great importance, use a 0.005 \nsignificance level. Based on these results, should cell phone users be concerned about cancer of \nthe brain or nervous system?\n24. Lie Detectors Trials in an experiment with a polygraph yield 98 results that include 24 cases \nof wrong results and 74 cases of correct results (based on data from experiments conducted by \nresearchers Charles R. Honts of Boise State University and Gordon H. Barland of the Depart-\nment of Defense Polygraph Institute). Use a 0.05 significance level to test the claim that such \npolygraph results are correct less than 80% of the time. Based on the results, should polygraph \ntest results be prohibited as evidence in trials?\n25. Testing Effectiveness of Nicotine Patches In one study of smokers who tried to quit \nsmoking with nicotine patch therapy, 39 were smoking one year after the treatment and 32 \nwere not smoking one year after the treatment (based on data from “High-Dose Nicotine Patch \nTherapy,” by Dale et al., Journal of the American Medical Association, Vol. 274, No. 17). Use a \n0.05 significance level to test the claim that among smokers who try to quit with nicotine patch \ntherapy, the majority are smoking a year after the treatment. What do these results suggest \nabout the effectiveness of nicotine patch therapy for those trying to quit smoking?\n26. Postponing Death An interesting and popular hypothesis is that individuals can tem-\nporarily postpone death to survive a major holiday or important event such as a birthday. In \na study, it was found that there were 6062 deaths in the week before Thanksgiving, and 5938 \ndeaths the week after Thanksgiving (based on data from “Holidays, Birthdays, and Postpone-\nment of Cancer Death,” by Young and Hade, Journal of the American Medical Association, \nVol. 292, No. 24). If people can postpone death until after Thanksgiving, then the proportion \nof deaths in the week before should be less than 0.5. Use a 0.05 significance level to test the \nclaim that the proportion of deaths in the week before Thanksgiving is less than 0.5. Based on \nthe result, does there appear to be any indication that people can temporarily postpone death to \nsurvive the Thanksgiving holiday?\n27. Smoking Stopped In a program designed to help patients stop smoking, 198 patients \nwere given sustained care, and 82.8% of them were no longer smoking after one month (based \non data from “Sustained Care Intervention and Postdischarge Smoking Cessation Among \n Hospitalized Adults,” by Rigotti et al., Journal of the American Medical Association, Vol. 312, \nNo. 7). Use a 0.01 significance level to test the claim that 80% of patients stop smoking when \ngiven sustained care. Does sustained care appear to be effective?\n28. Medication Usage In a survey of 3005 adults aged 57 through 85 years, it was found that \n81.7% of them used at least one prescription medication (based on data from “Use of Prescrip-\ntion and Over-the-Counter Medications and Dietary Supplements Among Older Adults in the \nUnited States,” by Qato et al., Journal of the American Medical Association, Vol. 300, No. 24). \nUse a 0.01 significance level to test the claim that more than 3>4 of adults use at least one pre-\nscription medication. Does the rate of prescription use among adults appear to be high?\n29. Exact Method For each of the three different methods of hypothesis testing (identified in \nthe column at the left), enter the P-values corresponding to the given alternative hypothesis and \nsample data. Comment on the results.\nH1: p 3 0.5  \nn = 10, x = 9\nH1: p 3 0.4 \nn = 10, x = 9\nH1: p + 0.5 \nn = 1009, x = 545\nNormal approximation\nExact\nExact with simple  \ncontinuity correction\n8-2 Beyond the Basics\n\n366 \nCHAPTER 8 Hypothesis Testing\n30. Using Confidence Intervals to Test Hypotheses When analyzing the last digits of tele-\nphone numbers of hospital patients, it is found that among 1000 randomly selected digits, 119 \nare zeros. If the digits are randomly selected, the proportion of zeros should be 0.1.\na. Use the critical value method with a 0.05 significance level to test the claim that the propor-\ntion of zeros equals 0.1.\nb. Use the P-value method with a 0.05 significance level to test the claim that the proportion of \nzeros equals 0.1.\nc. Use the sample data to construct a 95% confidence interval estimate of the proportion of \nzeros. What does the confidence interval suggest about the claim that the proportion of zeros \nequals 0.1?\nd. Compare the results from the critical value method, the P-value method, and the confidence \ninterval method. Do they all lead to the same conclusion?\n31. Power For a hypothesis test with a specified significance level a, the probability of a type I \nerror is a, whereas the probability b of a type II error depends on the particular value of p that \nis used as an alternative to the null hypothesis.\na. Using an alternative hypothesis of p 6 0.4, using a sample size of n = 50, and assuming \nthat the true value of p is 0.25, find the power of the test. See Exercise 34 “Calculating Power” \nin Section 8-1. [Hint: Use the values p = 0.25 and pq>n = 10.25210.752>50.4\nb. Find the value of b, the probability of making a type II error.\nc. Given the conditions cited in part (a), find the power of the test. What does the power tell us \nabout the effectiveness of the test?\nKey Concept Testing a claim about a population mean is one of the most important \nmethods presented in this book. This section deals with the very realistic and com-\nmonly used case in which the population standard deviation s is not known.\nIn reality, it is very rare that we test a claim about an unknown value of a popula-\ntion mean m but we somehow know the value of the population standard deviation s. \nThe realistic situation is that we test a claim about a population mean and the value of \nthe population standard deviation s is not known. When s is not known, we estimate \nit with the sample standard deviation s. From the central limit theorem (Section 6-4), \nwe know that the distribution of sample means x is approximately a normal distribu-\ntion with mean mx = m and standard deviation sx = s> 1n, but if s is unknown, we \nestimate s> 1n with s> 1n, which is used in the test statistic for a “t test.” This test \nstatistic has a distribution called the Student t distribution. The requirements, test \nstatistic, P-value, and critical values are summarized in the Key Elements box that \nfollows.\nEquivalent Methods\nFor the t test described in this section, the P-value method, the critical value method, \nand the confidence interval method are all equivalent in the sense that they all lead to \nthe same conclusions.\n8-3 \nTesting a Claim About a Mean\n\n8-3 Testing a Claim About a Mean \n367\nRequirement of Normality or n + 30 This t test is robust against a departure \nfrom normality, meaning that the test works reasonably well if the departure from \nnormality is not too extreme. Verify that there are no outliers and that the histogram or \ndotplot has a shape that is not very far from a normal distribution.\nIf the original population is not itself normally distributed, we use the condition \nn 7 30 for justifying use of the normal distribution, but there is no exact specific \nminimum sample size that works for all cases. Sample sizes of 15 to 30 are sufficient \nif the population has a distribution that is not far from normal, but some populations \nhave distributions that are extremely far from normal, and sample sizes greater than \n30 might be necessary. In this text we use the simplified criterion of n 7 30 as justi-\nfication for treating the distribution of sample means as a normal distribution, regard-\nless of how far the distribution departs from a normal distribution.\nImportant Properties of the Student t Distribution\nHere is a brief review of important properties of the Student t distribution first pre-\nsented in Section 7-2:\n1. The Student t distribution is different for different sample sizes (see Figure 7-4 \nin Section 7-2).\n2. The Student t distribution has the same general bell shape as the standard nor-\nmal distribution; its wider shape reflects the greater variability that is expected \nwhen s is used to estimate s.\nTesting Claims About a Population Mean with s Not Known\nObjective\nUse a formal hypothesis test to test a claim about a population mean m.\nNotation\nKEY ELEMENTS \nn = sample size \nx = sample mean\ns = sample standard deviation \nmx =  population mean (this value is taken from the claim and is used in the \nstatement of the null hypothesis H0)\nRequirements\n1. The sample is a simple random sample.\n2. Either or both of these conditions are satisfied: The \npopulation is normally distributed or n 7 30.\nTest Statistic for Testing a Claim About a Mean\nt = x - mx\ns\n2n\n \n1Round t to three decimal places, as in Table A@3.2\nP-Values: Use technology or use the Student t distri-\nbution (Table A-3) with degrees of freedom given by \ndf = n - 1. (Figure 8-3 in Section 8-1 on page 344 sum-\nmarizes the procedure for finding P-values.)\nCritical Values: Use the Student t distribution (Table A-3) \nwith degrees of freedom given by df = n - 1. (When \n Table A-3 doesn’t include the number of degrees of free-\ndom, you could be conservative by using the next lower \nnumber of degrees of freedom found in the table, you \ncould use the closest number of degrees of freedom in the \ntable, or you could interpolate.)\ncontinued\n\n368 \nCHAPTER 8 Hypothesis Testing\n3. The Student t distribution has a mean of t = 0 (just as the standard normal dis-\ntribution has a mean of z = 0).\n4. The standard deviation of the Student t distribution varies with the sample size \nand is greater than 1 (unlike the standard normal distribution, which has s = 1).\n5. As the sample size n gets larger, the Student t distribution gets closer to the \nstandard normal distribution.\nP-Value Method with Technology\nIf suitable technology is available, the P-value method of testing hypotheses is the \nway to go.\nEXAMPLE 1  Adult Sleep: P-Value Method with Technology\nThe authors obtained times of sleep for randomly selected adult subjects in-\ncluded in the National Health and Nutrition Examination Study, and those times \n(hours) are listed below. Here are the unrounded statistics for this sample: n = 12, \nx = 6.83333333 hours, s = 1.99240984 hours. A common recommendation is \nthat adults should sleep between 7 hours and 9 hours each night. Use the P-value \nmethod with a 0.05 significance level to test the claim that the mean amount of \nsleep for adults is less than 7 hours.\n4 8 4 4 8 6 9 7 7 10 7 8\nSOLUTION\nREQUIREMENT CHECK (1) The sample is a simple random sample. (2) The second \nrequirement is that “the population is normally distributed or n 7 30.” The sample \nsize is n = 12, which does not exceed 30, so we must determine whether the sample \ndata appear to be from a normally distributed population. The accompanying histo-\ngram and normal quantile plot, along with the apparent absence of outliers, indicate \nthat the sample appears to be from a population with a distribution that is approxi-\nmately normal. Both requirements are satisfied. \nStatdisk\nHere are the steps that follow the procedure summarized in Figure 8-1 on page 340.\nStep 1: The claim that “the mean amount of adult sleep is less than 7 hours” be-\ncomes m 6 7 hours when expressed in symbolic form.\nStep 2: The alternative (in symbolic form) to the original claim is m Ú 7 hours.\nStep 3: Because the statement m 6 7 hours does not contain the condition of equal-\nity, it becomes the alternative hypothesis H1. The null hypothesis H0 is the state-\nment that m = 7 hours.\n“How Statistics Can Help \nSave Failing Hearts”\nA New York \nTimes ar-\nticle by David \nLeonhardt \nfeatured the \nheadline \nof “How \nStatistics Can Help Save Failing \nHearts.” Leonhardt writes that \npatients have the best chance of \nrecovery if their clogged arteries \nare opened within two hours \nof a heart attack. In 2005, the \nU.S. Department of Health and \nHuman Services began posting \nhospital data on its website  \nwww.hospitalcompare.hhs.gov, \nand it included the percentage \nof heart attack patients who re-\nceived treatment for blocked ar-\nteries within two hours of arrival \nat the hospital. Not wanting to be \nembarrassed by poor data, doc-\ntors and hospitals are reducing \nthe time it takes to unblock those \nclogged arteries. Leonhardt \nwrites about the University of \nCalifornia, San Francisco Medical \nCenter, which cut its time in half \nfrom almost three hours to about \n90 minutes. Effective use of \nsimple statistics can save lives.\n\n8-3 Testing a Claim About a Mean \n369\nH0: m = 7 hours 1null hypothesis2\nH1: m 6 7 hours 1alternative hypothesis and original claim2\nStep 4: As specified in the statement of the problem, the significance level is \na = 0.05.\nStep 5: Because the claim is made about the population mean m, the sample statistic \nmost relevant to this test is the sample mean x, and we use the t distribution.\nStep 6: The sample statistics of n = 12, x = 6.83333333 hours, s = 1.99240984 \nhours are used to calculate the test statistic as follows, but technologies provide the \ntest statistic of t = -0.290. In calculations such as the following, it is good to carry \nextra decimal places and not round.\nt = x - mx\ns\n2n\n= 6.83333333 - 7\n1.99240984\n212\n= -0.290\nP-Value with Technology We could use technology to obtain the P-value. Shown \nhere are results from several technologies, and we can see that the P-value is 0.3887 \n(rounded). (SPSS shows a two-tailed P-value of 0.777, so it must be halved for this \none-tailed test.)\nStep 7: Because the P-value of 0.3887 is greater than the significance level of \na = 0.05, we fail to reject the null hypothesis.\nINTERPRETATION\nStep 8: Because we fail to reject the null hypothesis, we conclude that there is not \nsufficient evidence to support the claim that the mean amount of adult sleep is less \nthan 7 hours.\nMinitab\nStatCrunch\nTI-83 , 84 Plus\nExcel (XLSTAT)\nStatdisk\nJMP\nSPSS\nc \nMeta-Analysis\nThe term meta-\nanalysis refers \nto a technique \nof conduct-\ning a study \nthat essen-\ntially combines \nresults of other studies. It has the \nadvantage that separate smaller \nsamples can be combined into \none big sample, making the \ncollective results more meaning-\nful. It also has the advantage \nof using work that has already \nbeen done. Meta-analysis has \nthe disadvantage of being only \nas good as the studies that are \nused. If the previous studies are \nflawed, the “garbage in, garbage \nout” phenomenon can occur. The \nuse of meta-analysis is currently \npopular in medical research and \npsychological research. As an \nexample, a study of migraine \nheadache treatments was based \non data from 46 other studies. \n(See “Meta-Analysis of Migraine \nHeadache Treatments: Combin-\ning Information from Heteroge-\nneous Designs,” by Dominici \net al., Journal of the American \nStatistical Association, Vol. 94, \nNo. 445.)\n\n370 \nCHAPTER 8 Hypothesis Testing\nExamine the technology displays to see that only two of them include critical values, \nbut they all include P-values. This is a major reason why the P-value method of test-\ning hypotheses has become so widely used in recent years.\nP-Value Method Without Technology\nIf suitable technology is not available, we can use Table A-3 to identify a range of \nvalues containing the P-value. In using Table A-3, keep in mind that it is designed for \npositive values of t and right-tail areas only, but left-tail areas correspond to the same \nt values with negative signs.\nEXAMPLE 2  Adult Sleep: P-Value Method Without Technology\nExample 1 is a left-tailed test with a test statistic of t = -0.290 (rounded) and a sam-\nple size of n = 12, so the number of degrees of freedom is df = n - 1 = 11. Using \nthe test statistic of t = -0.290 with Table A-3, examine the values of t in the row for  \ndf = 11 to see that 0.290 is less than all of the listed t values in the row, which indi-\ncates that the area in the left tail below the test statistic of t = -0.290 is greater than \n0.10. In this case, Table A-3 allows us to conclude that the P-value 7 0.10, but tech-\nnology provided the P-value of 0.3887. With a P-value 7 0.10, the conclusions are \nthe same as in Example 1.\nHINT: Because using Table A-3 to find a range of values containing the P-value \ncan be a bit tricky, the critical value method (see Example 3) might be easier than \nthe P-value method if suitable technology is not available.\nCritical Value Method\nEXAMPLE 3  Adult Sleep: Critical Value Method\nExample 1 is a left-tailed test with test statistic t = -0.290 (rounded). The \nsample size is n = 12, so the number of degrees of freedom is df = n - 1 = 11. \nGiven the significance level of a = 0.05, refer to the row of Table A-3 corre-\nsponding to 11 degrees of freedom, and refer to the column identifying an “area \nin one tail” of 0.05 (the significance level). The intersection of the row and col-\numn yields the critical value of t = 1.796, but this test is left-tailed, so the actual \ncritical value is t = -1.796. Figure 8-7 shows that the test statistic of t = -0.290 \ndoes not fall within the critical region bounded by the critical value t = -1.796, \nso we fail to reject the null hypothesis. The conclusions are the same as those \ngiven in  Example 1.\n\n8-3 Testing a Claim About a Mean \n371\nConfidence Interval Method\nEXAMPLE 4  Adult Sleep: Confidence Interval Method\nExample 1 is a left-tailed test with significance level a = 0.05, so we should use \n90% as the confidence level (as indicated by Table 8-1 on page 340). For the sample \ndata given in Example 1, here is the 90% confidence interval estimate of m:  \n5.80 hours 6 m 6 7.87 hours. In testing the claim that m 6 7 hours, we use  \nH0: m = 7 hours, but the assumed value of m = 7 hours is contained within the con-\nfidence interval limits, so the confidence interval is telling us that 7 hours could be \nthe value of m. We don’t have sufficient evidence to reject H0: m = 7 hours, so we \nfail to reject this null hypothesis and we get the same conclusions given in Example 1.\nEXAMPLE 5  Is the Mean Body Temperature Really 98.6°F?\nData Set 2 “Body Temperatures” in Appendix B includes measured body tempera-\ntures with these statistics for 12 AM on day 2: n = 106, x = 98.20°F, s = 0.62°F. \nUse a 0.05 significance level to test the common belief that the population mean  \nis 98.6°F.\nSOLUTION\nREQUIREMENT CHECK (1) With the study design used, we can treat the sample as a \nsimple random sample. (2) The second requirement is that “the population is nor-\nmally distributed or n 7 30.” The sample size is n = 106, so the second require-\nment is satisfied and there is no need to investigate the normality of the data. Both \nrequirements are satisfied. \nHere are the steps that follow the procedure summarized in Figure 8-1.\nStep 1: The claim that “the population mean is 98.6°F” becomes m = 98.6°F when \nexpressed in symbolic form.\nStep 2: The alternative (in symbolic form) to the original claim is m ≠98.6°F.\ncontinued\nHuman Lie Detectors\nResearchers \ntested 13,000 \npeople for \ntheir ability to \ndetermine when \nsomeone is ly-\ning. They found \n31 people with exceptional skills \nat identifying lies. These human \nlie detectors had accuracy rates \naround 90%. They also found \nthat federal officers and sheriffs \nwere quite good at detecting lies, \nwith accuracy rates around 80%. \nPsychology Professor Maureen \nO’Sullivan questioned those who \nwere adept at identifying lies, \nand she said that “all of them pay \nattention to nonverbal cues and \nthe nuances of word usages and \napply them differently to differ-\nent people. They could tell you \neight things about someone after \nwatching a two-second tape. It’s \nscary, the things these people \nnotice.” Methods of statistics can \nbe used to distinguish between \npeople unable to detect lying and \nthose with that ability.\ni\nl kill\nm 5 7\nor\nt 5 0\nCritical Value:\nt 5 21.796\na 5 0.05\nSample Mean:\nx 5 6.833 hours\nor t 5 20.290\n2\nFIGURE 8-7 t Test: Critical Value Method\n\n372 \nCHAPTER 8 Hypothesis Testing\nStep 3: Because the statement m ≠98.6°F does not contain the condition of equality, \nit becomes the alternative hypothesis H1. The null hypothesis H0 is the statement \nthat m = 98.6°F.\nH0: m = 98.6°F 1null hypothesis and original claim2\nH1: m ≠98.6°F 1alternative hypothesis2\nStep 4: As specified in the statement of the problem, the significance level is \na = 0.05.\nStep 5: Because the claim is made about the population mean m, the sample statistic \nmost relevant to this test is the sample mean x. We use the t distribution because \nthe relevant sample statistic is x and the requirements for using the t distribution are \nsatisfied.\nStep 6: The sample statistics are used to calculate the test statistic as follows, but \ntechnologies use unrounded values to provide the test statistic of t = -6.61.\nt = x - mx\ns\n2n\n= 98.20 - 98.6\n0.62\n2106\n= -6.64\nP-Value: The P-value is 0.0000 or 0+ (or “less than 0.01” if using Table A-3).\nCritical Values: The critical values are {1.983 (or {1.984 if using Table A-3).\nConfidence Interval: The 95% confidence interval is 98.08°F 6 m 6 98.32°F.\nStep 7: All three approaches lead to the same conclusion: Reject H0.\n \n■ P-Value: The P-value of 0.0000 is less than the significance level of a = 0.05.\n \n■Critical Values: The test statistic t = -6.64 falls in the critical region bounded \nby {1.983.\n \n■Confidence Interval: The claimed mean of 98.6°F does not fall within the con-\nfidence interval of 98.08°F 6 m 6 98.32°F.\nINTERPRETATION\nStep 8: There is sufficient evidence to warrant rejection of the common belief that \nthe population mean body temperature is 98.6°F.\nAlternative Methods Used When Population Is Not Normal and n \" 30\nThe methods of this section include two requirements: (1) The sample is a simple \nrandom sample; (2) either the population is normally distributed or n 7 30. If we \nhave sample data that are not collected in an appropriate way, such as a voluntary \n response sample, it is likely that there is nothing that can be done to salvage the \ndata, and the methods of this section should not be used. If the data are a simple \nrandom sample but the second condition is violated, there are alternative methods that \ncould be used, including these three alternative methods:\n \n■Bootstrap Resampling Use the confidence interval method of testing hypoth-\neses, but obtain the confidence interval using bootstrap resampling, as described \nin Section 7-4. Be careful to use the appropriate confidence level, as indicated by \nTable 8-1 on page 340. Reject the null hypothesis if the confidence interval limits do \nnot contain the value of the mean claimed in the null hypothesis. See Example 6.\n\n8-3 Testing a Claim About a Mean \n373\n \n■Sign Test See Section 13-2.\n \n■Wilcoxon Signed-Ranks Test See Section 13-3.\nEXAMPLE 6  Bootstrap Resampling\nListed below is a random sample of times (seconds) of tobacco use in animated \nchildren’s movies (from Data Set 13 “Alcohol and Tobacco in Movies”). Use a 0.05 \nsignificance level to test the claim that the sample is from a population with a mean \ngreater than 1 minute (or 60 seconds).\n0 223 0 176 0 548 0 37 158 51 0 0 299 37 0 11 0 0 0 0\nSOLUTION\nREQUIREMENT CHECK The t test described in this section requires that the popula-\ntion is normally distributed or n 7 30, but we have n = 20 and the accompanying \nnormal quantile plot shows that the sample does not appear to be from a normally \ndistributed population. The t test should not be used. \nSOLUTION\nInstead of incorrectly using the t test, we use the bootstrap resampling method de-\nscribed in Section 7-4. After obtaining 1000 bootstrap samples and finding the mean \nof each sample, we sort the means. Because the test is right-tailed with a 0.05 sig-\nnificance level, we use the 1000 sorted sample means to find the 90% confidence \ninterval limits of P5 = 29.9 seconds and P95 = 132.9 seconds. The 90% confidence \ninterval is 29.9 seconds 6 m 6 132.9 seconds. (These values can vary somewhat.) \nBecause the assumed mean of 60 seconds is contained within those confidence inter-\nval limits, we fail to reject H0: m = 60 seconds. There is not sufficient evidence to \nsupport H1: m 7 60 seconds.\nINTERPRETATION\nThere is not sufficient evidence to support the claim that the given sample is from a \npopulation with a mean greater than 60 seconds.\nHypothesis Test: Mean\nAccess tech instructions, videos, and data sets at www.TriolaStats.com\nTECH CENTER \n\n374 \nCHAPTER 8 Hypothesis Testing\nStatistical Literacy and Critical Thinking\n1. Alcohol Use and Video Games: Checking Requirements Twelve different video games \nshowing alcohol use were observed. The duration times of alcohol use were recorded, with the \ntimes (seconds) listed below (based on data from “Content and Ratings of Teen-Rated Video \nGames,” by Haninger and Thompson, Journal of the American Medical Association, Vol. 291, \nNo. 7). What requirements must be satisfied to test the claim that the sample is from a popula-\ntion with a mean greater than 90 sec? Are the requirements all satisfied?\n84 14 583 50 0 57 207 43 178 0 2 57\n2. df If we are using the sample data from Exercise 1 for a t test of the claim that the population \nmean is greater than 90 sec, what does df denote, and what is its value?\n3. t Test Exercise 2 refers to a t test. What is a t test? Why is the letter t used?\n4. Confidence Interval Assume that we will use the sample data from Exercise 1 “Alcohol \nUse and Video Games” with a 0.05 significance level in a test of the claim that the population \nmean is greater than 90 sec. If we want to construct a confidence interval to be used for testing \nthat claim, what confidence level should be used for the confidence interval? If the confidence \ninterval is found to be 21.1 sec 6 m 6 191.4 sec, what should we conclude about the claim?\nFinding P-values. In Exercises 5–8, either use technology to find the P-value or use \nTable A-3 to find a range of values for the P-value.\n5. Body Temperature The claim is that for 12 AM body temperatures, the mean is \nm 6 98.6°F. The sample size is n = 4 and the test statistic is t = -2.503.\n6. Body Temperature Data Set 2 “Body Temperatures” in Appendix B includes measured \nhuman body temperatures with these statistics for 12 AM on day 1: n = 93, x = 98.12°F,\ns = 0.65°F. In testing the claim that the mean body temperature is 98.6°F, the test statistic \nt = -7.122 is obtained.\n7. Platelets The claim is that for the population of adult females, the mean platelet count is \nm 6 300. The sample size is n = 15 and the test statistic is t = -0.666.\n8. Platelets The claim is that for the population of adult males, the mean platelet count is \nm 7 210. The sample size is n = 53 and the test statistic is t = 1.368.\nTesting Hypotheses. In Exercises 9–24, assume that a simple random sample has been \nselected and test the given claim. Unless specified by your instructor, use either the P-value \nmethod or the critical value method for testing hypotheses. Identify the null and alternative \nhypotheses, test statistic, P-value (or range of P-values), or critical value(s), and state the \nfinal conclusion that addresses the original claim.\n9. Body Temperatures Data Set 2 “Body Temperatures” in Appendix B includes 38 body \ntemperatures measured at 8 AM on day 1 of a study, and the accompanying XLSTAT dis-\nplay results from using those data to test the claim that the mean body temperature is equal to \n98.6°F. Conduct the hypothesis test using these results.\n8-3  Basic Skills and Concepts\n10. Body Temperatures Data Set 2 “Body Temperatures” in Appendix B includes 70 body \ntemperatures measured at 8 AM on day 2 of a study, and the accompanying JMP display results \nfrom using those data to test the claim that the mean body temperature is equal to 98.6oF. Con-\nduct the hypothesis test using these results.\n\n8-3 Testing a Claim About a Mean \n375\n 11. Platelets Data Set 1 “Body Data” in Appendix B includes platelet counts (1000 cells>mL) \nmeasured from 147 adult females. In testing the claim that the population of adult females has a \nmean platelet count less than 270, the accompanying Statdisk display is obtained by assuming \na 0.05 significance level.\n12. Platelets Data Set 1 “Body Data” in Appendix B includes platelet counts (1000 cells>mL) \nmeasured from 153 adult males. In testing the claim that the population of adult males has a \nmean platelet count greater than 220, the accompanying Minitab display is obtained.\n13. Birth Weight Data Set 3 “Births” in Appendix B includes birth weights of 205 females, and \nthe summary statistics are x = 3037.1 g and s = 706.3 g. Use a 0.01 significance level to test \nthe claim that the population of birth weights of females is greater than 3000 g.\n14. Birth Weight Data Set 1 “Body Data” in Appendix B includes birth weights of 195 males, \nand the summary statistics are x = 3272.8 g and s = 660.2 g. Use a 0.01 significance level to \ntest the claim that the population of birth weights of males is less than 3400 g.\n15. Garlic for Reducing Cholesterol In a test of the effectiveness of garlic for lowering cho-\nlesterol, 49 subjects were treated with raw garlic. Cholesterol levels were measured before and \nafter the treatment. The changes (before minus after) in their levels of low-density lipoprotein \n(LDL) cholesterol (in mg>dL) have a mean of 0.4 and a standard deviation of 21.0 (based on \ndata from “Effect of Raw Garlic vs Commercial Garlic Supplements on Plasma Lipid Concen-\ntrations in Adults with Moderate Hypercholesterolemia,” by Gardner et al., Archives of Internal \nMedicine, Vol. 167, No. 4). Use a 0.05 significance level to test the claim that with garlic treat-\nment, the mean change in LDL cholesterol is greater than 0. What do the results suggest about \nthe effectiveness of the garlic treatment?\n16. Insomnia Treatment A clinical trial was conducted to test the effectiveness of the drug \nzopiclone for treating insomnia in older subjects. Before treatment with zopiclone, 16 subjects \nhad a mean wake time of 102.8 min. After treatment with zopiclone, the 16 subjects had a \nmean wake time of 98.9 min and a standard deviation of 42.3 min (based on data from “Cog-\nnitive Behavioral Therapy vs Zopiclone for Treatment of Chronic Primary Insomnia in Older \nAdults,” by Sivertsen et al., Journal of the American Medical Association, Vol. 295, No. 24). \nAssume that the 16 sample values appear to be from a normally distributed population, and \ntest the claim that after treatment with zopiclone, subjects have a mean wake time of less than \n102.8 min. Does zopiclone appear to be effective?\n17. Is the Diet Practical? When 40 people used the Weight Watchers diet for one year, their \nmean weight loss was 3.0 lb and the standard deviation was 4.9 lb (based on data from “Com-\nparison of the Atkins, Ornish, Weight Watchers, and Zone Diets for Weight Loss and Heart \nDisease Reduction,” by Dansinger et al., Journal of the American Medical Association, \nVol. 293, No. 1). Use a 0.01 significance level to test the claim that the mean weight loss is \ngreater than 0. Based on these results, does the diet appear to have statistical significance? \nDoes the diet appear to have practical significance?\n18. Conductor Life Span A New York Times article noted that the mean life span for 35 male \nsymphony conductors was 73.4 years, in contrast to the mean of 69.5 years for males in the \ngeneral population. Assuming that the 35 males have life spans with a standard deviation of \n8.7 years, use a 0.05 significance level to test the claim that male symphony conductors have \na mean life span that is greater than 69.5 years. Does it appear that male symphony conduc-\ntors live longer than males from the general population? Why doesn’t the experience of being \na male symphony conductor cause men to live longer? (Hint: Are male symphony conductors \nborn as conductors, or do they become conductors at a much later age?)\n\n376 \nCHAPTER 8 Hypothesis Testing\n19. Course Evaluations Data from student course evaluations were obtained from the Uni-\nversity of Texas at Austin. The summary statistics are n = 436, x = 3.97, s = 0.55. Use a \n0.05 significance level to test the claim that the population of student course evaluations has a \nmean equal to 4.00. Do the results apply to the population of all students?\n20. Treating Chronic Fatigue Syndrome Patients with chronic fatigue syndrome were \ntested, and then retested after being treated with fludrocortisone. A standard scale from -7 \nto +7 is used to measure fatigue before and after the treatment. The changes are summarized \nwith these statistics: n = 21, x = 4.00, s = 2.17 (based on data from “The Relationship Be-\ntween Neurally Mediated Hypotension and the Chronic Fatigue Syndrome,” by Bou-Holaigah, \nRowe, Kan, and Calkins, Journal of the American Medical Association, Vol. 274, No. 12). The \nchanges were computed in a way that makes positive values represent improvements. Use a \n0.01 significance level to test the claim that the mean change is positive. Does the treatment \nappear to be effective?\n21. Lead in Medicine Listed below are the lead concentrations (in mg>g) measured in dif-\nferent Ayurveda medicines. Ayurveda is a traditional medical system commonly used in In-\ndia. The lead concentrations listed here are from medicines manufactured in the United States \n(based on data from “Lead, Mercury, and Arsenic in US and Indian Manufactured Ayurvedic \nMedicines Sold via the Internet,” by Saper et al., Journal of the American Medical Association, \nVol. 300, No. 8). Use a 0.05 significance level to test the claim that the mean lead concentration \nfor all such medicines is less than 14 mg>g.\n3.0 6.5 6.0 5.5 20.5 7.5 12.0 20.5 11.5 17.5\n22. Got a Minute? Students of one of the authors estimated the length of one minute without \nreference to a watch or clock, and the times (seconds) are listed below. Use a 0.05 significance \nlevel to test the claim that these times are from a population with a mean equal to 60 seconds. \nDoes it appear that students are reasonably good at estimating one minute?\n69 81 39 65 42 21 60 63 66 48 64 70 96 91 65\n 23. Car Booster Seats The National Highway Traffic Safety Administration conducted crash \ntests of child booster seats for cars. Listed below are results from those tests, with the measure-\nments given in hic (standard “head injury condition” units). The safety requirement is that the \nhic measurement should be less than 1000 hic. Use a 0.01 significance level to test the claim \nthat the sample is from a population with a mean less than 1000 hic. Do the results suggest that \nall of the child booster seats meet the specified requirement?\n774 649 1210 546 431 612\n24. Heights of Supermodels Listed below are the heights (cm) for the simple random sam-\nple of female supermodels Lima, Bundchen, Ambrosio, Ebanks, Iman, Rubik, Kurkova, Kerr, \nKroes, Swanepoel, Prinsloo, Hosk, Kloss, Robinson, Heatherton, and Refaeli. Use a 0.01 sig-\nnificance level to test the claim that supermodels have heights with a mean that is greater than \nthe mean height of 162 cm for women in the general population. Given that there are only 16 \nheights represented, can we really conclude that supermodels are taller than the typical woman?\n178  177  176  174  175  178  175  178  178  177  180  176  180  178  180  176\nLarge Data Sets from Appendix B. In Exercises 25–28, use the data set in Appendix B \nto test the given claim. Use the P-value method unless your instructor specifies otherwise.\n25. Pulse Rates Use the pulse rates of adult females listed in Data Set 1 “Body Data” in \n Appendix B to test the claim that the mean is less than 75 bpm. Use a 0.05 significance level.\n26. Pulse Rates Use the pulse rates of adult males listed in Data Set 1 “Body Data” in \n Appendix B to test the claim that the mean is less than 75 bpm. Use a 0.05 significance level.\n\n8-4 Testing a Claim About a Standard Deviation or Variance \n377\n27. Diastolic Blood Pressure for Women Use the diastolic blood pressure measurements \nfor adult females listed in Data Set 1 “Body Data” in Appendix B and test the claim that the \nadult female population has a mean diastolic blood pressure level less than 90 mm Hg. A dia-\nstolic blood pressure above 90 is considered to be hypertension. Use a 0.05 significance level. \nBased on the result, can we conclude that none of the adult females in the sample have hyper-\ntension?\n28. Diastolic Blood Pressure for Men Repeat the preceding exercise for adult males instead \nof adult females.\n29. Finding Critical t Values When finding critical values, we often need signifi-\ncance levels other than those available in Table A-3. One approach is to approximate \ncritical t values by calculating t = 2df # 1eA2>df - 12 where df = n - 1, e = 2.718,\nA = z18 # df + 32>18 # df + 12, and z is the critical z score. Use this approximation to find \nthe critical t score for Exercise 11 “Platelets,” using a significance level of 0.05. Compare the \nresult to the critical t value shown in the Statdisk display. Does this approximation appear to \nwork reasonably well?\n30. Interpreting Power For the sample data in Example 1 “Adult Sleep” from this section, \nMinitab and StatCrunch show that the hypothesis test has a power of 0.4943 of supporting \nthe claim that m 6 7 hours of sleep when the actual population mean is 6.0 hours of sleep. \nInterpret this value of the power, then identify the value of b and interpret that value. (For \nthe t test in this section, a “noncentrality parameter” makes calculations of power much more \ncomplicated than the process described in Section 8-1, so software is recommended for power \ncalculations.)\n8-3 Beyond the Basics\nKey Concept This section presents methods for conducting a formal hypothesis test \nof a claim made about a population standard deviation s or population variance s2.\nThe methods of this section use the chi-square distribution that was first introduced in \nSection 7-3. \n8-4 \nTesting a Claim About a Standard Deviation or Variance\nEquivalent Methods\nWhen testing claims about s or s2, the P-value method, the critical value method, \nand the confidence interval method are all equivalent in the sense that they will always \nlead to the same conclusion.\nCAUTION The x2 (chi-square) test of this section is not robust against a departure \nfrom normality, meaning that the test does not work well if the population has \na distribution that is far from normal. The condition of a normally distributed \npopulation is therefore a much stricter requirement when testing claims about s or \ns2 than when testing claims about a population mean m.\n\n378 \nCHAPTER 8 Hypothesis Testing\nCAUTION Table A-4 for the chi-square distribution uses cumulative areas from \nthe right (unlike Table A-2 for the standard normal distribution, which provides \ncumulative areas from the left.) See Example 1 in Section 7-3.\nTesting Claims About s or s2\nObjective:\nConduct a hypothesis test of a claim made about a population standard deviation s or population variance s2.\nNotation\nn = sample size \ns = sample standard deviation\ns = population standard deviation \ns2 =  sample variance\ns2 =  population variance\nKEY ELEMENTS \nRequirements\n1. The sample is a simple random sample.\n2. The population has a normal distribution. (This is a fairly strict requirement.)\nTest Statistic\nx2 = 1n - 12s2\ns2\n 1round to three decimal places, as in Table A@42\nP-Values: Use technology or Table A-4 with degrees of freedom of df = n - 1.\nCritical Values: Use Table A-4 with degrees of freedom df = n - 1.\nProperties of the Chi-Square Distribution\nThe chi-square distribution was introduced in Section 7-3, where we noted the follow-\ning important properties.\n1. All values of x2 are nonnegative, and the distribution is not symmetric (see \n Figure 8-8).\n2. There is a different x2 distribution for each number of degrees of freedom (see \nFigure 8-9).\n3. The critical values are found in Table A-4 using\ndegrees of freedom = n −1\nHere is an important note if using Table A-4 for finding critical values:\nIn Table A-4, each critical value of X2 in the body of the table corresponds \nto an area given in the top row of the table, and each area in that top row \nis a cumulative area to the right of the critical value.\n\n8-4 Testing a Claim About a Standard Deviation or Variance \n379\nNot symmetric\nAll values are nonnegative\nx2\n0\nFIGURE 8-8  Properties of the Chi-Square \nDistribution\n0\n5\n10\n15\n20\n25\n30\n35\n40\n45\nx2\ndf 5 20\ndf 5 10\nFIGURE 8-9  Chi-Square Distribution for \ndf = 10 and df = 20\nEXAMPLE 1   P-Value Method: Do Supermodel Heights  \nVary Less?\nListed below are the heights (cm) for the simple random sample of female super-\nmodels: Lima, Bundchen, Ambrosio, Ebanks, Iman, Rubik, Kurkova, Kerr, Kroes, \nSwanepoel, Prinsloo, Hosk, Kloss, Robinson, Heatherton, and Refaeli. Use a 0.01 \nsignificance level to test the claim that supermodels have heights with a standard \ndeviation that is less than s = 7.5 cm for the population of women. Does it appear \nthat heights of supermodels vary less than heights of women from the population?\n178 177 176 174 175 178 175 178 178 177 180 176 180 178 180 176\nSOLUTION\nREQUIREMENT CHECK (1) The sample is a simple random sample. (2) In checking for \nnormality, we see that the sample has no outliers, the accompanying normal quantile \nplot shows points that are reasonably close to a straight-line pattern, and there is no \nother pattern that is not a straight line. Both requirements are satisfied. \nStatdisk\nTechnology Technology capable of conducting this test will typically display the  \nP-value. The StatCrunch result is shown on the top of the next page. (Instead of  \nusing the assumed value of s for H0 and H1, StatCrunch uses s2. For the null  \nhypothesis, s = 7.5 is equivalent to s2 = 7.52 = 56.25.) The display shows that \nthe test statistic is x2 = 0.907 (rounded) and the P-value is less than 0.0001.\ncontinued\n\n380 \nCHAPTER 8 Hypothesis Testing\nCritical Value Method\nTechnology typically provides a P-value, so the P-value method is used. If technol-\nogy is not available, the P-value method of testing hypotheses is a bit challenging, \nbecause Table A-4 allows us to find only a range of values for the P-value. Instead, \nwe could use the critical value method. Steps 1 through 5 in Example 1 would be \nthe same. In Step 6, the test statistic is calculated by using s = 7.5 cm (as assumed \nin the null hypothesis in Example 1); n = 16, and s = 1.843909 cm, which is the \nunrounded standard deviation computed from the original list of 16 heights. We get \nthis test statistic:\nx2 = 1n - 12s2\ns2\n= 116 - 12 11.8439092 2\n7.52\n= 0.907\nThe critical value of x2 = 5.229 is found from Table A-4, and it corresponds to \n15 degrees of freedom and an “area to the right” of 0.99 (based on the significance \nlevel of 0.01 for a left-tailed test). See Figure 8-10. In Step 7 we reject the null \nhypothesis because the test statistic of x2 = 0.907 falls in the critical region, as \nshown in Figure 8-10. We conclude that there is sufficient evidence to support the \nclaim that supermodels have heights with a standard deviation that is less than 7.5 cm \nfor the population of women.\nStatCrunch\nStep 1: The claim that “the standard deviation is less than 7.5 cm” is expressed in \nsymbolic form as s 6 7.5 cm.\nStep 2: If the original claim is false, then s Ú 7.5 cm.\nStep 3: The expression s 6 7.5 cm does not contain equality, so it becomes the al-\nternative hypothesis. The null hypothesis is the statement that s = 7.5 cm.\nH0: s = 7.5 cm\nH1: s 6 7.5 cm 1original claim2\nStep 4: The significance level is a = 0.01.\nStep 5: Because the claim is made about s, we use the x2 (chi-square) distribution.\nStep 6: The StatCrunch display shows the test statistic of x2 = 0.907 (rounded), \nand it shows that the P-value is less than 0.0001.\nStep 7: Because the P-value is less than the significance level of a = 0.01, we \nreject H0.\nINTERPRETATION\nStep 8: There is sufficient evidence to support the claim that female supermodels \nhave heights with a standard deviation that is less than 7.5 cm for the population of \nwomen. It appears that heights of supermodels do vary less than heights of women \nin the general population.\n\n8-4 Testing a Claim About a Standard Deviation or Variance \n381\nConfidence Interval Method\nAs stated earlier, when testing claims about s or s2, the P-value method, the critical \nvalue method, and the confidence interval method are all equivalent in the sense that \nthey will always lead to the same conclusion. See Example 2.\na 5 0.01\nCritical Value:\nx2 5 5.229\nTest Statistic:\nx2 5 0.907\nFIGURE 8-10 Testing the Claim That S * 7.5 cm\nEXAMPLE 2  Supermodel Heights: Confidence Interval Method\nRepeat the hypothesis test in Example 1 by constructing a suitable confidence \ninterval.\nSOLUTION\nFirst, we should be careful to select the correct confidence level. Because the \nhypothesis test is left-tailed and the significance level is 0.01, we should use a \nconfidence level of 98%, or 0.98. (See Table 8-1 on page 340 for help in selecting \nthe correct confidence level.)\nUsing the methods described in Section 7-3, we can use the sample data listed \nin Example 1 to construct a 98% confidence interval estimate of s. We use n = 16, \ns = 1.843909 cm, x2\nL = 5.229, and x2\nR = 30.578. (The critical values x2\nL and x2\nR \nare found in Table A-4. Use the row with df = n - 1 = 15. The 0.98 confidence \nlevel corresponds to a = 0.02, and we divide that area of 0.02 equally between the \ntwo tails so that the areas to the right of the critical values are 0.99 and 0.01. Refer \nto Table A-4 and use the columns with areas of 0.99 and 0.01 and use the 15th row.)\n B\n1n - 12s2\nx2\nR\n6 s 6 B\n1n - 12s2\nx2\nL\n B\n116 - 1211.84390922\n30.578\n6 s 6 B\n116 - 1211.84390922\n5.229\n 1.3 cm 6 s 6 3.1 cm\nWith this confidence interval, we can support the claim that s 6 7.5 cm because all \nvalues of the confidence interval are less than 7.5 cm. We reach the same conclusion \nfound with the P-value method and the critical value method.\n\n382 \nCHAPTER 8 Hypothesis Testing\nAlternative Method Used When Population Is Not Normal\nThe methods of this section include two requirements: (1) The sample is a simple \nrandom sample; (2) the population is normally distributed. If sample data are not col-\nlected in a random manner, the methods of this section do not apply. If the sample \nappears to be from a population not having a normal distribution, we could use the \nconfidence  interval method of testing hypotheses, but obtain the confidence interval \nusing bootstrap resampling, as described in Section 7-4. Be careful to use the appropri-\nate confidence level, as indicated by Table 8-1 on page 340. Reject the null hypothesis \nif the confidence interval limits do not contain the value of the mean claimed in the null \nhypothesis. See the Technology Project near the end of this chapter.\nStatistical Literacy and Critical Thinking \n1. Birth Weights Shown below are birth weights (in kilograms) of male babies born to moth-\ners taking a special vitamin supplement (based on data from the New York State Department of \nHealth). Assume that we want to use the sample data to test the claim that the sample is from \na population with a standard deviation equal to 0.470 kg, which is the standard deviation for \nthe population not given the special vitamin supplement. What requirements must be satisfied? \nHow does the normality requirement for a hypothesis test of a claim about a standard deviation \ndiffer from the normality requirement for a hypothesis test of a claim about a mean?\n3.73 4.37 3.73 4.33 3.39 3.68 4.68 3.52\n3.02 4.09 2.47 4.13 4.47 3.22 3.43 2.54\n2. Birth Weights Use the data and the claim given in Exercise 1 to identify the null and alter-\nnative hypotheses and the test statistic. What is the sampling distribution of the test statistic?\n3. Birth Weights For the sample data from Exercise 1, we get a P-value of 0.0291 when test-\ning the claim that the sample is from a population with a standard deviation equal to 0.470 kg. \nAssume that the test is conducted with a significance level given by a = 0.05.\na. What should we conclude about the null hypothesis?\nb. What should we conclude about the original claim?\nc. Does the vitamin supplement appear to affect the variation among birth weights?\n4. Birth Weights: Confidence Interval If we use the data given in Exercise 1, we \nget this 95% confidence interval estimate of the standard deviation of birth weights: \n0.486 kg 6 s 6 1.017 kg. When testing the claim that the sample is from a population with a \nstandard deviation equal to 0.470 kg, what do we conclude from the confidence interval?\n8-4 Basic Skills and Concepts\nHypothesis Test: Standard Deviation or Variance\nAccess tech instructions, videos, and data sets at www.TriolaStats.com\nTECH CENTER \n\n8-4 Testing a Claim About a Standard Deviation or Variance \n383\nTesting Claims About Variation. In Exercises 5–16, test the given claim. Identify the null \nhypothesis, alternative hypothesis, test statistic, P-value, or critical value(s), then state the con-\nclusion about the null hypothesis, as well as the final conclusion that addresses the original \nclaim. Assume that a simple random sample is selected from a normally distributed population.\n5. Pulse Rates of Men A simple random sample of 153 men results in a standard deviation of \n11.3 beats per minute (based on Data Set 1 “Body Data” in Appendix B). The normal range of \npulse rates of adults is typically given as 60 to 100 beats per minute. If the range rule of thumb \nis applied to that normal range, the result is a standard deviation of 10 beats per minute. Use \nthe sample results with a 0.05 significance level to test the claim that pulse rates of men have a \nstandard deviation equal to 10 beats per minute; see the accompanying StatCrunch display for \nthis test. What do the results indicate about the effectiveness of using the range rule of thumb \nwith the “normal range” from 60 to 100 beats per minute for estimating s in this case?\n6. Pulse Rates of Women Repeat the preceding exercise using the pulse rates of women \nlisted in Data Set 1 “Body Data” in Appendix B. For the sample of pulse rates of women, \nn = 147 and s = 12.5. See the accompanying JMP display that results from using the original \nlist of pulse rates instead of the summary statistics. (Hint: The bottom three rows of the display \nprovide P-values for a two-tailed test, a left-tailed test, and a right-tailed test, respectively.) \nWhat do the results indicate about the effectiveness of using the range rule of thumb with the \n“normal range” from 60 to 100 beats per minute for estimating s in this case?\n7. Body Temperature Example 5 in Section 8-3 involved a test of the claim that humans \nhave body temperatures with a mean equal to 98.6°F. The sample of 106 body temperatures \nhas a standard deviation of 0.62°F. The conclusion in that example would change if the sample \nstandard deviation s were 2.08°F or greater. Use a 0.01 significance level to test the claim that \nthe sample of 106 body temperatures is from a population with a standard deviation less than \n2.08°F. What does the result tell us about the validity of the hypothesis test in Example 5 in \nSection 8-3?\n8. Birth Weights A simple random sample of birth weights of 30 girls has a standard devia-\ntion of 829.5 hg. Use a 0.01 significance level to test the claim that birth weights of girls have \nthe same standard deviation as the birth weights of boys, which is 660.2 hg (based on Data Set \n3 “Births” in Appendix B).\n9. Physician IQ Scores For a random sample of IQ scores of 18 physicians, the mean is \n124.2 and the standard deviation is 9.6 (based on data from a study conducted at the University \nof Wisconsin at Madison). Use a 0.05 significance level to test the claim that because physi-\ncians are a more homogeneous population than the general population, their IQ scores have a \nstandard deviation less than 15, which is the standard deviation for the general population.\n10. Statistics Test Scores Tests in one of the author’s statistics classes have scores with a \nstandard deviation equal to 14.1. One of his last classes had 27 test scores with a standard devi-\nation of 9.3. Use a 0.01 significance level to test the claim that this class has less variation than \nother past classes. Does a lower standard deviation suggest that this last class is doing better?\n11. New Filling Process The Orange Machine Company supplies a tool for pouring cold \nmedicine into bottles in such a way that the standard deviation of the contents is 4.25 g. A new \nfilling process is tested on 71 bottles and the standard deviation for this sample is 3.87 g. Use a \n0.05 significance level to test the claim that the new process dispenses amounts with a standard \ndeviation less than the standard deviation of 4.25 g for the old process. Is the new process better \nin the sense of dispensing amounts that are more consistent?\n\n384 \nCHAPTER 8 Hypothesis Testing\n 12. Spoken Words Couples were recruited for a study of how many words people speak in a \nday. A random sample of 56 males resulted in a mean of 16,576 words and a standard deviation \nof 7871 words. Use a 0.01 significance level to test the claim that males have a standard devia-\ntion that is greater than the standard deviation of 7460 words for females (based on data from \n“Are Women Really More Talkative Than Men?” by Mehl et al., Science, Vol. 317, No. 5834).\n13. Weight Loss from Diet When 40 people used the Weight Watchers diet for one year, \ntheir weight losses had a standard deviation of 4.9 lb (based on data from “Comparison of the \n Atkins, Ornish, Weight Watchers, and Zone Diets for Weight Loss and Heart Disease Reduc-\ntion,” by Dansinger, et al., Journal of the American Medical Association, Vol. 293, No. 1). Use \na 0.01 significance level to test the claim that the amounts of weight loss have a standard devia-\ntion equal to 6.0 lb, which appears to be the standard deviation for the amounts of weight loss \nwith the Zone diet.\n14. Sphygmomanometers An aneroid sphygmomanometer is a mechanical device used to \nmeasure blood pressure. A random sample of these devices is tested for accuracy and the errors \n(mm Hg) are listed below (based on data from “How Accurate Are Sphygmomanometers?” \nby Mion and Pierin, Journal of Human Hypertension, Vol. 12, No. 4). One of the devices is \nconsidered to be unacceptable if its error is more than 3 mm Hg. We will use this criterion for \nconcluding that the sample is from a population of unacceptable devices: s 7 1.5 mm Hg. Use \na 0.05 significance level with the sample data to test the claim that the sample is from a popula-\ntion with a standard deviation greater than 1.5 mm Hg. What does the result suggest about the \naccuracy of aneroid sphygmomanometers?\n-4 -11 5 5 8 14 -16 -12 4 6 -6\n15. Queues Providence Hospital once had separate waiting lines for patients arriving for ad-\nmission, but it now has a single waiting line that feeds the processing stations as vacancies \noccur. The standard deviation of waiting times with the old multiple-line configuration was \n109.3 sec. Listed below is a simple random sample of waiting times (minutes) with the single \nwaiting line. Use a 0.05 significance level to test the claim that with a single waiting line, the \nwaiting times have a standard deviation less than 109.3 sec. What improvement occurred when \nmultiple waiting lines were replaced by a single waiting line?\n390 396 402 408 426 438 444 462 462 462\n16. World’s Smallest Mammal The world’s smallest mammal is the bumblebee bat, also \nknown as the Kitti’s hog-nosed bat (or Craseonycteris thonglongyai). Such bats are roughly \nthe size of a large bumblebee. Listed below are weights (in grams) from a sample of these bats. \nUsing a 0.05 significance level, test the claim that these weights come from a population with a \nstandard deviation equal to 0.30 g, which is the standard deviation of weights of the bumblebee \nbats from one region in Thailand. Do these bats appear to have weights with the same variation \nas the bats from that region in Thailand?\n1.7 1.6 1.5 2.0 2.3 1.6 1.6 1.8 1.5 1.7 2.2 1.4 1.6 1.6 1.6\n17. Finding Critical Values of X2 For large numbers of degrees of freedom, we can approxi-\nmate critical values of x2 as follows:\nx2 = 1\n21z + 22k - 12 2\nHere k is the number of degrees of freedom and z is the critical value(s) found from technology \nor Table A-2. In Exercise 12 “Spoken Words,” we have df = 55, so Table A-4 does not list an \nexact critical value. If we want to approximate a critical value of x2 in the right-tailed hypoth-\nesis test with a = 0.01 and a sample size of 56, we let k = 55 with z = 2.33 (or the more \n8-4 Beyond the Basics\n\naccurate value of z = 2.326348 found from technology). Use this approximation to estimate \nthe critical value of x2 for Exercise 12. How close is it to the critical value of x2 = 82.292\nobtained by using Statdisk and Minitab?\n18. Finding Critical Values of X2 Repeat Exercise 17 using this approximation (with k and z \nas described in Exercise 19):\nx2 = k a1 - 2\n9k + zA\n2\n9k b\n3\n1. Distributions Using the methods of this chapter, identify the distribution that should be \nused for testing a claim about the given population parameter.\na. Mean\nb. Proportion\nc. Standard deviation\n2. Tails Determine whether the given claim involves a hypothesis test that is left-tailed, two-\ntailed, or right-tailed.\na. p ≠0.5\nb. m 6 98.6\nc. s 7 15\n3. Instagram Poll In a Pew Research Center poll of Internet users aged 18−29, 53% said that \nthey use Instagram. We want to use a 0.05 significance level to test the claim that the majority \nof Internet users aged 18−29 use Instagram.\na. Identify the null and alternative hypotheses.\nb. Using a sample size of 532, find the value of the test statistic.\nc. Technology is used to find that the P-value for the test is 0.0827. What should we conclude \nabout the null hypothesis?\nd. What should we conclude about the original claim?\n4. P-Value Find the P-value in a test of the claim that the mean annual income of a nurse is \ngreater than $60,000 (based on data from the Bureau of Labor Statistics) given that the test \nstatistic is t = 2.462 for a sample of 30 nurses.\n5. Conclusions True or false: In hypothesis testing, it is never valid to form a conclusion of \nsupporting the null hypothesis.\n6. Conclusions True or false: The conclusion of “fail to reject the null hypothesis” has exactly \nthe same meaning as “accept the null hypothesis.”\n7. Uncertainty True or false: If correct methods of hypothesis testing are used with a large \nsimple random sample that satisfies the test requirements, the conclusion will always be true.\n8. Chi-Square Test In a test of the claim that s = 10 for the population of IQ scores of \nnurses, we find that the rightmost critical value is x2\nR = 40.646. Is the leftmost critical x2\nL value \nequal to -40.646?\n9. Robust Explain what is meant by the statements that the t test for a claim about m is robust, \nbut the x2 test for a claim about s2 is not robust.\nChapter Quick Quiz\nCHAPTER 8 Chapter Quick Quiz \n385\n\n386 \nCHAPTER 8 Hypothesis Testing\n10. Equivalent Methods Which of the following statements are true?\na. When testing a claim about a population mean m, the P-value method, critical value method, \nand confidence interval method are all equivalent in the sense that they always yield the same \nconclusions.\nb. When testing a claim about a population proportion p, the P-value method, critical value \nmethod, and confidence interval method are all equivalent in the sense that they always yield \nthe same conclusions.\nc. When testing a claim about any population parameter, the P-value method, critical value \nmethod, and confidence interval method are all equivalent in the sense that they always yield \nthe same conclusions.\nReview Exercises\n1. True, False Characterize each of the following statements as being true or false.\na. In a hypothesis test, a very high P-value indicates strong support of the alternative hypoth-\nesis.\nb. The Student t distribution can be used to test a claim about a population mean whenever the \nsample data are randomly selected from a normally distributed population.\nc. When using a x2 distribution to test a claim about a population standard deviation, there is a \nvery loose requirement that the sample data are from a population having a normal distribution.\nd. When conducting a hypothesis test about the claimed proportion of surgeons who have cur-\nrent passports, the problems with a convenience sample can be overcome by using a larger \nsample size.\ne. When repeating the same hypothesis test with different random samples of the same size, the \nconclusions will all be the same.\n2. Is Nessie Real? This question was posted on the America Online website: Do you believe \nthe Loch Ness monster exists? Among 21,346 responses, 64% were “yes.” Use a 0.01 signifi-\ncance level to test the claim that most people believe that the Loch Ness monster exists. How \nis the conclusion affected by the fact that Internet users who saw the question could decide \nwhether to respond?\n3. Red Blood Cell Count A simple random sample of 40 adult males is obtained, and the \nred blood cell count (in cells per microliter) is measured for each of them, with these results: \nn = 40, x = 4.932 million cells per microliter, s = 0.504 million cells per microliter (from \nData Set 1 “Body Data” in Appendix B). Use a 0.01 significance level to test the claim that \nthe sample is from a population with a mean less than 5.4 million cells per microliter, which is \noften used as the upper limit of the range of normal values. Does the result suggest that each of \nthe 40 males has a red blood cell count below 5.4 million cells per microliter?\n4. Smoking Recently, a simple random sample of 572 adult males showed that 124 of them \nsmoke (based on data from the Centers for Disease Control and Prevention). It has been estab-\nlished that in 2008, 20.4% of adult males smoke. Use a 0.05 significance level to test the claim \nthat the rate of smoking by adult males is now the same as in 2008.\n5. Controlling Cholesterol The Westbrook Pharmaceutical Company manufactures atorv-\nastatin pills, designed to lower cholesterol levels. Listed below are the amounts (in mg) of \natorvastatin in a random sample of the pills. Use a 0.05 significance level to test the claim that \nthe pills come from a population in which the mean amount of atorvastatin is equal to 25 mg.\n24.1 24.4 24.3 24.9 24.1 26.2 25.1 24.7 24.4 25.0 24.7 25.1 25.3 25.5 25.5\n\n6. BMI for Miss America A claimed trend of thinner Miss America winners has generated \ncharges that the contest encourages unhealthy diet habits among young women. Listed below \nare body mass indexes (BMI) for recent Miss America winners. Use a 0.01 significance level \nto test the claim that recent winners are from a population with a mean BMI less than 20.16, \nwhich was the BMI for winners from the 1920s and 1930s. Given that BMI is a measure of the \nrelative amounts of body fat and height, do recent winners appear to be significantly smaller \nthan those from the 1920s and 1930s?\n19.5 20.3 19.6 20.2 17.8 17.9 19.1 18.8 17.6 16.8\n7. BMI for Miss America Use the same BMI indexes given in Exercise 6. Use a 0.01 signifi-\ncance level to test the claim that recent Miss America winners are from a population with a \nstandard deviation equal to 1.34, which was the standard deviation of BMI for winners from \nthe 1920s and 1930s. Do recent winners appear to have variation that is different from that of \nthe 1920s and 1930s?\n8. Type I Error and Type II Error\na. In general, what is a type I error? In general, what is a type II error?\nb. For the hypothesis test in Exercise 6 “BMI for Miss America,” write a statement that would \nbe a type I error, and write another statement that would be a type II error.\n1. Lightning Deaths Listed below are the numbers of deaths from lightning strikes in the \nUnited States each year for a sequence of 14 recent and consecutive years. Find the values of \nthe indicated statistics.\n51 44 51 43 32 38 48 45 27 34 29 26 28 23\na. Mean  b. Median  c. Standard deviation  d. Variance  e. Range\nf. What important feature of the data is not revealed from an examination of the statistics, and \nwhat tool would be helpful in revealing it?\n2. Lightning Deaths Refer to the sample data in Cumulative Review Exercise 1.\na. What is the level of measurement of the data (nominal, ordinal, interval, ratio)?\nb. Are the values discrete or continuous?\nc. Are the data categorical or quantitative?\nd. Is the sample a simple random sample?\n3. Confidence Interval for Lightning Deaths Use the sample values given in Cumulative \nReview Exercise 1 to construct a 99% confidence interval estimate of the population mean. \nAssume that the population has a normal distribution. Write a brief statement that interprets the \nconfidence interval.\n4. Hypothesis Test for Lightning Deaths Refer to the sample data given in Cumulative \nReview Exercise 1 and consider those data to be a random sample of annual lightning deaths \nfrom recent years. Use those data with a 0.01 significance level to test the claim that the \nmean number of annual lightning deaths is less than the mean of 72.6 deaths from the 1980s. \nIf the mean is now lower than in the past, identify one of the several factors that could ex-\nplain the decline.\nCumulative Review Exercises\nCHAPTER 8 Cumulative Review Exercises \n387\n\n388 \nCHAPTER 8 Hypothesis Testing\n5. Lightning Deaths The accompanying bar chart shows the numbers of lightning strike \ndeaths broken down by gender for a recent period of nine years. What is wrong with the graph?\n6. Lightning Deaths The graph in Cumulative Review Exercise 5 was created by using data \nconsisting of 232 male deaths from lightning strikes and 55 female deaths from lightning \nstrikes. Assume that these data are randomly selected lightning deaths and proceed to test the \nclaim that the proportion of male deaths is greater than 1>2. Use a 0.01 significance level. Any \nexplanation for the result?\n7. Lightning Deaths The graph in Cumulative Review Exercise 5 was created by using \ndata consisting of 232 male deaths from lightning strikes and 55 female deaths from light-\nning strikes. Assume that these data are randomly selected lightning deaths and proceed to \nconstruct a 95% confidence interval estimate of the proportion of males among all lightning \ndeaths. Based on the result, does it seem feasible that males and females have equal chances of \nbeing killed by lightning?\n8. Lightning Deaths Based on the results given in Cumulative Review Exercise 6, assume \nthat for a randomly selected lightning death, there is a 0.8 probability that the victim is a male.\na. Find the probability that three random people killed by lightning strikes are all males.\nb. Find the probability that three random people killed by lightning strikes are all females.\nc. Find the probability that among three people killed by lightning strikes, at least one is a male.\nd. If five people killed by lightning strikes are randomly selected, find the probability that ex-\nactly three of them are males.\ne. A study involves random selection of different groups of 50 people killed by lightning strikes. \nFor those groups, find the mean and standard deviation for the numbers of male victims.\nf. For the same groups described in part (e), would 46 be a significantly high number of males \nin a group? Explain.\n9. Odds Ratio In a study of the relationship between headaches and body weight, there were \n4489 overweight subjects, and 331 of them experienced migraine headaches. Among 5487 sub-\njects with normal weight, 358 experienced migraine headaches (based on data from “Body \nMass Index and Episodic Headaches,” by Bigal et al., Archives of Internal Medicine, Vol. 167, \nNo. 18). Find the odds ratio and interpret the result.\n\nTechnology Project\n1.  Bootstrapping and Robustness Consider the probability distribution defined by the \nformula P1x2 =\n3x2\n1000 where x can be any value between 0 and 10 inclusive (not just integers). \nThe accompanying graph of this probability distribution shows that its shape is very far from the \nbell shape of a normal distribution. This probability distribution has parameters m = 7.5 and \ns = 1.93649. Listed below is a simple random sample of values from this distribution, and the \nnormal quantile plot for this sample is shown. Given the very non-normal shape of the distribution, \nit is not surprising to see the normal quantile plot with points that are far from a straight-line pattern, \nconfirming that the sample does not appear to be from a normally distributed population.\n8.69 2.03 9.09 7.15 9.05 9.40 6.30 7.89 7.98 7.67\n7.77 7.17 8.86 8.29 9.21 7.80 7.70 8.12 9.11 7.64\nP1x2 = 3x2\n1000  defined on [0, 10]\nNormal Quantile Plot of 20 Sample Values\na. Mean Test the claim that the 20 given sample values are from a population having a mean equal \nto 7.5, which is the known population mean. Because the sample is not from a normally distributed \npopulation and because n = 20 does not satisfy the requirement of n 7 30, we should not use the \nmethods of Section 8-3. Instead, test the claim by using the confidence interval method based on a \nbootstrap sample of size 1000 (See Section 7-4). Use a 0.05 significance level. Does the bootstrap \nconfidence interval contain the known population mean of 7.5? Is the bootstrap method effective \nfor this test? What happens if we conduct this test by throwing all caution to the wind and con-\nstructing the 95% confidence interval by using the t distribution as described in Section 7-2?\nb. Standard Deviation Test the claim that the 20 sample values are from a population with a \nstandard deviation equal to 1.93649, which is the known population standard deviation. Use the \nconfidence interval method based on a bootstrap sample of size 1000. (See Section 7-4.) Use \na 0.05 significance level. Does the bootstrap confidence interval contain the known population \nstandard deviation of 1.93649? Is the bootstrap method effective for this test? What happens if \nwe conduct the test by throwing all caution to the wind and constructing the 95% confidence \ninterval by using the x2 distribution as described in Section 7-3?\nCHAPTER 8 Technology Project \n389\n\n390 \nCHAPTER 8 Hypothesis Testing\nCooperative Group Activities\n1.  Out-of-class activity In the United States, 40% of us have brown eyes, according to \nDr. P. Sorita Soni at Indiana University. Groups of three or four students should randomly \n select people and identify the color of their eyes. The claim that 40% of us have brown eyes can \nthen be tested.\n2. In-class activity After dividing into groups of between 10 and 20 people, each group mem-\nber should record the number of heartbeats in a minute. After calculating the sample mean and \nstandard deviation, each group should proceed to test the claim that the mean is greater than \n48 beats per minute, which is the result for one of the authors. (When people exercise, they \ntend to have lower pulse rates.)\n3. In-class activity Without using any measuring device, each student should draw a line be-\nlieved to be 3 in. long and another line believed to be 3 cm long. Then use rulers to measure and \nrecord the lengths of the lines drawn. Find the means and standard deviations of the two sets \nof lengths. Test the claim that the lines estimated to be 3 in. have a mean length that is equal to \n3 in. Test the claim that the lines estimated to be 3 cm have a mean length that is equal to 3 cm. \nCompare the results. Do the estimates of the 3-in. line appear to be more accurate than those \nfor the 3-cm line? What do these results suggest?\n4. In-class activity Assume that a method of gender selection can affect the probability of a \nbaby being a girl so that the probability becomes 1>4. Each student should simulate 20 births \nby drawing 20 cards from a shuffled deck. Replace each card after it has been drawn, then \nreshuffle. Consider the hearts to be girls and consider all other cards to be boys. After making \n20 selections and recording the “genders” of the babies, use a 0.10 significance level to test the \nclaim that the proportion of girls is equal to 1>4. How many students are expected to get results \nleading to the wrong conclusion that the proportion is not 1>4? How does that relate to the \nprobability of a type I error? Does this procedure appear to be effective in identifying the ef-\nfectiveness of the gender selection method? (If decks of cards are not available, use some other \nway to simulate the births, such as using the random number generator on a calculator or using \ndigits from phone numbers or Social Security numbers.)\nFROM DATA TO DECISION\nCritical Thinking: Testing the Salk Vaccine\nThe largest health experiment ever conducted involved a test of \nthe Salk vaccine designed to protect children from the devastat-\ning effects of polio. The test included 201,229 children who \nwere given the Salk vaccine, and 33 of them developed polio. \nThe claim that the Salk vaccine is effective is equivalent to the \nclaim that the proportion of vaccinated children who develop \npolio is less than 0.0000573, which was the rate of polio among \nchildren not given the Salk vaccine. (Note: The actual Salk vac-\ncine experiment involved another group of 200,745 children \nwho were injected with an ineffective salt solution instead of \nthe Salk vaccine. This study design with a treatment group and \nplacebo group is very common and very effective. Methods for \ncomparing two proportions are presented in Chapter 9.)\nAnalyzing the Results\na. Test the given claim using a 0.05 significance level. Does \nthe Salk vaccine appear to be effective?\nb. For the hypothesis test from part (a), consider the follow-\ning two errors:\n•  Concluding that the Salk vaccine is effective when it is not \neffective.\n•  Concluding that the Salk vaccine is not effective when it is \neffective.\nDetermine which of the above two errors is a type I error \nand determine which is a type II error. Which error would \nhave worse consequences? How could the hypothesis test be \nconducted in order to reduce the chance of making the more \nserious error?\n\n5. Out-of-class activity Groups of three or four students should go to the library and collect a \nsample consisting of the ages of books (based on copyright dates). Plan and describe the sam-\npling plan, execute the sampling procedure, and then use the results to test the claim that the \nmean age of books in the library is greater than 20 years.\n6. In-class activity A class project should be designed to conduct a test in which each student \nis given a taste of Coke and a taste of Pepsi. The student is then asked to identify which sample \nis Coke. After all of the results are collected, test the claim that the success rate is better than \nthe rate that would be expected with random guesses.\n7.  In-class activity Each student should estimate the length of the classroom. The values \nshould be based on visual estimates, with no actual measurements being taken. After the esti-\nmates have been collected, measure the length of the room, then test the claim that the sample \nmean is equal to the actual length of the classroom. Is there a “collective wisdom,” whereby the \nclass mean is approximately equal to the actual room length?\n8. Out-of-class activity Using one wristwatch that is reasonably accurate, set the time to be \nexact. Visit www.time.gov to set the exact time. If you cannot set the time to the nearest sec-\nond, record the error for the watch you are using. Now compare the time on this watch to the \ntime on other watches that have not been set to the exact time. Record the errors with negative \nsigns for watches that are ahead of the actual time and positive signs for those watches that are \nbehind the actual time. Use the data to test the claim that the mean error of all wristwatches is \nequal to 0. Do we collectively run on time, or are we early or late? Also test the claim that the \nstandard deviation of errors is less than 1 min. What are the practical implications of a standard \ndeviation that is excessively large?\n9. In-class activity In a group of three or four people, conduct an extrasensory perception \n(ESP) experiment by selecting one of the group members as the subject. Draw a circle on one \nsmall piece of paper and draw a square on another sheet of the same size. Repeat this experi-\nment 20 times: Randomly select the circle or the square and place it in the subject’s hand be-\nhind his or her back so that it cannot be seen, then ask the subject to identify the shape (without \nseeing it); record whether the response is correct. Test the claim that the subject has ESP be-\ncause the proportion of correct responses is greater than 0.5.\n10. Out-of-class activity Each student should find an article in a professional journal that \nincludes a hypothesis test of the type discussed in this chapter. Write a brief report describing \nthe hypothesis test and its role in the context of the article.\nCHAPTER 8 Cooperative Group Activities \n391\n\n392\nTwo Proportions\nTwo Means: \nIndependent Samples\nTwo Dependent \nSamples (Matched \nPairs)\nTwo Variances or \nStandard Deviations\n9-1\n9-2\n9-3\n9-4\nIs the “Freshman 15” Real, or Is It a Myth?\nCHAPTER \nPROBLEM \nInferences from Two \nSamples\nThere is a common and popular belief that college students \ntypically gain 15 lb (or 6.8 kg) during their freshman year. \nThis 15-lb weight gain has been dubbed the “Freshman 15.” \nReasonable explanations for this phenomenon include the \nnew stresses of college life (not including a statistics class, \nwhich is just plain fun); new eating habits; less free time \nfor physical activities; cafeteria food with an abundance of \nfat and  carbohydrates; the new freedom to choose among \na variety of foods (including sumptuous pizzas that are \njust a phone call away); and a lack of sleep that results in \nlower levels of leptin, which helps regulate appetite and \nmetabolism. But is the Freshman 15 real, or is it a myth that \nhas been perpetuated through anecdotal evidence and>or \nflawed data?\n9 \n\nSeveral studies have focused on the credibility of the \nFreshman 15 belief. We will consider one reputable study \nwith results published in the article “Changes in Body Weight \nand Fat Mass of Men and Women in the First Year of College: \nA Study of the ‘Freshman 15’,” by Daniel Hoffman, Peggy \n Policastro, Virginia Quick, and Soo-Kyung Lee, Journal of \nAmerican College Health, Vol. 55, No. 1. The authors of that ar-\nticle have provided the data from their study, and much of it is \nlisted in Data Set 10 “Freshman 15” in Appendix B. If you exam-\nine the weights in Data Set 10, you should note the following:\n• The weights in Data Set 10 are in kilograms, not pounds, \nand 15 lb is equivalent to 6.8 kg. The “Freshman 15 \n(pounds)” is equivalent to the “Freshman 6.8 kilograms.”\n• Data Set 10 includes two weights for each of the 67 study \nsubjects. Each subject was weighed in September of the \nfreshman year, and again in April of the freshman year. These \ntwo measurements were made at the beginning and end of the \nseven months of campus life that passed between the mea-\nsurements. It is important to recognize that each individual pair \nof before and after measurements is from the same student, so \nthe lists of 67 “before” weights and 67 “after” weights consti-\ntute paired data from the 67 subjects in the study.\n• Because the Freshman 15 refers to weight gained,  \nwe will use weight changes in this format:  \n(April weight) - (September weight). If a student does \ngain 15 lb, the value of (April weight) - (September \nweight) is 15 lb, or 6.8 kg. (A negative weight “gain” indi-\ncates that the student lost weight.)\n• The published article about the Freshman 15 study is \nmarked by some limitations, including these:\n1. All subjects volunteered for the study.\n2.  All of the subjects were attending Rutgers, the State Uni-\nversity of New Jersey.\nThe Freshman 15 constitutes a claim made about the pop-\nulation of college students. If we use md to denote the mean of \nall (April weight) - (September weight) differences for college \nstudents during their freshman year, the Freshman 15 is the \nclaim that md = 15 lb or md = 6.8 kg. Because the sample \nweights are measured in kilograms, we will consider the claim \nto be md = 6.8 kg. Later in this chapter, a formal hypothesis \ntest will be used to test this claim. We will then be able to reach \none of two possible conclusions: Either there is sufficient evi-\ndence to warrant rejection of the claim that md = 6.8 kg (so \nthe Freshman 15 is rejected), or we will conclude that there is \nnot sufficient evidence to warrant rejection of the claim that  \nmd = 6.8 kg (so the Freshman 15 cannot be rejected). We will \nthen be better able to determine whether the Freshman 15 is a \nmyth.\nInferential statistics involves forming conclusions (or inferences) about a population pa-\nrameter. Two major activities of inferential statistics are estimating values of population \nparameters using confidence intervals (as in Chapter 7) and testing claims made about \npopulation parameters (as in Chapter 8). Chapters 7 and 8 both involved methods for \ndealing with a sample from one population, but this chapter extends those methods to \nsituations involving two populations. Here are the chapter objectives:\nTwo Proportions\n• Conduct a formal hypothesis test of a claim made about two population proportions.\n• Construct a confidence interval estimate of the difference between two population \nproportions.\nTwo Means: Independent Samples\n• Distinguish between a situation involving two independent samples and a situation \ninvolving two samples that are not independent.\n9-1\n9-2\nChapter Objectives \n393\nCHAPTER OBJECTIVES\n>>>\n\n394 \nCHAPTER 9 Inferences from Two Samples\nKey Concept In this section we present methods for (1) testing a claim made about \ntwo population proportions and (2) constructing a confidence interval estimate of the \ndifference between two population proportions. The methods of this chapter can also \nbe used with probabilities or the decimal equivalents of percentages.\n9-1 \nTwo Proportions\n• Conduct a formal hypothesis test of a claim made about two independent  populations.\n• Construct a confidence interval estimate of the difference between the means of \ntwo independent populations.\nTwo Dependent Samples (Matched Pairs)\n• Identify sample data consisting of matched pairs.\n• Conduct a formal hypothesis test of a claim made about the mean of the differences \nbetween matched pairs.\n• Construct a confidence interval estimate of the mean difference between matched pairs.\nTwo Variances or Standard Deviations\n• Develop the ability to conduct a formal hypothesis test of a claim made about two \npopulation standard deviations or variances.\n9-3\n9-4\n• Conduct a formal hypothesis test of a claim made about two independent populations.\n• Construct a confidence interval estimate of the difference between the means of\ntwo independent populations.\nTwo Dependent Samples (Matched Pairs)\n• Identify sample data consisting of matched pairs.\n• Conduct a formal hypothesis test of a claim made about the mean of the differences \nbetween matched pairs.\n• Construct a confidence interval estimate of the mean difference between matched pairs.\nTwo Variances or Standard Deviations\nTw\nT\n• Develop the ability to conduct a formal hypothesis test of a claim made about two\npopulation standard deviations or variances.\nInferences About Two Proportions\nObjectives\nKEY ELEMENTS \n1. Hypothesis Test: Conduct a hypothesis test of a claim \nabout two population proportions.\n2. Confidence Interval: Construct a confidence interval \nestimate of the difference between two population \nproportions.\nNotation for Two Proportions\nFor population 1 we let\np1 = population proportion \npn1 = x1\nn1\n  (sample proportion)\nn1 = size of the first sample \nqn1 = 1 - pn1 (complement of pn1)\nx1 = number of successes in the first sample\nThe corresponding notations p2, n2, x2, pn2, and qn2 apply to population 2.\nPooled Sample Proportion\nThe pooled sample proportion is denoted by p and it combines the two sample proportions into one proportion, as \nshown here:\np = x1 + x2\nn1 + n2\nq = 1 - p\ncontinued\n\n9-1 Two Proportions \n395\nEquivalent Methods\nWhen testing a claim about two population proportions:\n \n■The P-value method and the critical value method are equivalent.\n \n■The confidence interval method is not equivalent to the P-value method or the \ncritical value method.\nRecommendation: If you want to test a claim about two population proportions, use \nthe P-value method or critical value method; if you want to estimate the difference \nbetween two population proportions, use the confidence interval method.\nHypothesis Tests\nFor tests of hypotheses made about two population proportions, we consider only \ntests having a null hypothesis of p1 = p2 (so the null hypothesis is H0: p1 = p2).\nWith the assumption that p1 = p2, the estimates of pn1 and pn2 are combined to provide \nthe best estimate of the common value of pn1 and pn2, and that combined value is the \npooled sample proportion p given in the preceding Key Elements box. The follow-\ning example will help clarify the roles of x1, n1, pn1, p, and so on. Note that with the \nRequirements\n1. The sample proportions are from two simple random \nsamples.\n2. The two samples are independent. (Samples are inde-\npendent if the sample values selected from one popula-\ntion are not related to or somehow naturally paired or \nmatched with the sample values selected from the other \npopulation.)\n3. For each of the two samples, there are at least 5 suc-\ncesses and at least 5 failures. (That is, npn Ú 5 and \nnqn Ú 5 for each of the two samples).\nTest Statistic for Two Proportions (with H0: p1 = p2)\nz = 1pn1 - pn22 - 1p1 - p22\nA\np q\nn1\n+ p q\nn2\n where p1 - p2 = 0 (assumed in the null hypothesis)\nwhere p = x1 + x2\nn1 + n2\n (pooled sample proportion) and q = 1 - p\nP-Value: P-values are automatically provided by technol-\nogy. If technology is not available, use Table A-2 (standard \nnormal distribution) and find the P-value using the proce-\ndure given in Figure 8-3 on page 344 from Section 8-1.\nCritical Values: Use Table A-2. (Based on the signifi-\ncance level a, find critical values by using the same proce-\ndures introduced in Section 8-1.)\nConfidence Interval Estimate of p1 −p2\nThe confidence interval estimate of the difference p1 - p2 is\n1pn1 - pn22 - E 6 1p1 - p22 6 1pn1 - pn22 + E\nwhere the margin of error E is given by\nE = za>2B\npn1qn1\nn1\n+ pn2qn2\nn2\nRounding: Round the confidence interval limits to three significant digits.\n\n396 \nCHAPTER 9 Inferences from Two Samples\nassumption of equal population proportions, the best estimate of the common popula-\ntion proportion is obtained by pooling both samples into one big sample, so that p is \nthe estimator of the common population proportion.\nP-Value Method\nEXAMPLE 1  Do Airbags Save Lives?\nThe table below lists results from a simple random sample of front-seat occupants \ninvolved in car crashes (based on data from “Who Wants Airbags?” by Meyer and \nFinney, Chance, Vol. 18, No. 2). Use a 0.05 significance level to test the claim that \nthe fatality rate of occupants is lower for those in cars equipped with airbags.\nAirbag Available\nNo Airbag Available\nOccupant Fatalities\n41\n52\nTotal number of occupants\n11,541\n9,853\nSOLUTION\nREQUIREMENT CHECK We first verify that the three necessary requirements are sat-\nisfied. (1) The data are from two simple random samples. (2) The two samples are \nindependent of each other. (3) The airbag group includes 41 occupants who were \nkilled and 11,500 occupants who were not killed, so the number of successes is at \nleast 5 and the number of failures is at least 5. The second group includes 52 occu-\npants who were killed and 9801 who were not killed, so the number of successes is \nat least 5 and the number of failures is at least 5. The requirements are satisfied. \nWe will use the P-value method of hypothesis testing, as summarized in \n Figure 8-1 on page 340. In the following steps we stipulate that the group with \nairbags is Sample 1, and the group without airbags is Sample 2.\nStep 1: The claim that the fatality rate is lower for those with airbags can be ex-\npressed as p1 6 p2.\nStep 2: If p1 6 p2 is false, then p1 Ú p2.\nStep 3: Because the claim of p1 6 p2  does not contain equality, it becomes the al-\nternative hypothesis. The null hypothesis is the statement of equality, so we have\nH0: p1 = p2  H1: p1 6 p2 1original claim2\nStep 4: The significance level is a = 0.05.\nStep 5: This step and the following step can be circumvented by using technol-\nogy; see the display that follows this example. If not using technology, we use the \nnormal distribution (with the test statistic given earlier in the Key Elements box) as \nan approximation to the binomial distribution. We estimate the common value of \np1 and p2 with the pooled sample estimate p calculated as shown below, with extra \ndecimal places used to minimize rounding errors in later calculations.\np = x1 + x2\nn1 + n2\n=\n41 + 52\n11,541 + 9,853 = 0.004347\nWith p = 0.004347, it follows that q = 1 - 0.004347 = 0.995653.\n\n9-1 Two Proportions \n397\nStep 6: We can now find the value of the test statistic. Note that the null hypothesis \nassumption of p1 = p2 implies that p1 - p2 = 0 in the following calculation.\n z = 1pn1 - pn22 - 1p1 - p22\nA\np q\nn1\n+ p q\nn2\n \n =\na\n41\n11,541 -\n52\n9,853b - 0\nB\n10.0043472 10.9956532\n11,541\n+ 10.0043472 10.9956532\n9,853\n \n = -1.91\nThis is a left-tailed test, so the P-value is the area to the left of the test statistic \nz = -1.91 (as indicated by Figure 8-3 on page 344). Refer to Table A-2 and find \nthat the area to the left of the test statistic z = -1.91 is 0.0281, so the P-value is \n0.0281. (Technology provides a more accurate P-value of 0.0280.) The test statistic \nand P-value are shown in Figure 9-1(a).\nStep 7: Because the P-value of 0.0281 is less than the significance level of a = 0.05, \nwe reject the null hypothesis of p1 = p2. (“If the P is low, the null must go.”)\nINTERPRETATION\nWe must address the original claim that the fatality rate is lower for occupants in \ncars equipped with airbags. Because we reject the null hypothesis, we conclude \nthat there is sufficient evidence to support the claim that the proportion of accident \nfatalities for occupants in cars with airbags is less than the proportion of fatalities \nfor occupants in cars without airbags. (See Table 8-3 on page 346 for help in word-\ning the final conclusion.) Based on these results, there appears to be strong evidence \nthat drivers in cars with airbags are at lower risk of a fatality.\nThe sample data used in this example are only part of the data given in the \narticle cited in the statement of the problem. If all of the available data are used, the \ntest statistic becomes z = -57.76, and the P-value is very close to 0, so using all of \nthe data provides even more compelling evidence of the effectiveness of airbags in \nsaving lives.\np1 2 p2 5 0\n or\n  z  5 0\nTest Statistic:\nz 5 21.91\nP-value 5 0.0281\n \nTest Statistic:\nz 5 21.91\np1 2 p2 5 0\n or\n  z  5 0\na 5 0.05\nz  = –1.645\nFIGURE 9-1 Testing the Claim of a Lower Fatality Rate with Airbags\n(a) P-Value method \n(b) Critical Value Method\n\n398 \nCHAPTER 9 Inferences from Two Samples\nTechnology Software and calculators usually provide a P-value, so the P-value \nmethod is typically used for testing a claim about two proportions. See the accom-\npanying Statdisk results from Example 1 showing the test statistic of z = -1.91\n(rounded) and the P-value of 0.0280.\nStatdisk\nCritical Value Method\nThe critical value method of testing hypotheses can also be used for Example 1. In \nStep 6, instead of finding the P-value, find the critical value. With a significance level \nof a = 0.05 in a left-tailed test based on the normal distribution, we refer to Table A-2 \nand find that an area of a = 0.05 in the left tail corresponds to the critical value of \nz = -1.645. In Figure 9-1(b) we can see that the test statistic of z = -1.91 falls within \nthe critical region beyond the critical value of -1.645. We again reject the null hypoth-\nesis. The conclusions are the same as in Example 1.\nConfidence Intervals\nUsing the format given in the preceding Key Elements box, we can construct a confi-\ndence interval estimate of the difference between population proportions (p1 - p2). If \na confidence interval estimate of p1 - p2 does not include 0, we have evidence sug-\ngesting that p1 and p2 have different values. The confidence interval uses a standard \ndeviation based on the use of sample proportions, whereas a hypothesis test uses a \nstandard deviation based on the assumption that the two population proportions are \nequal and their common value is estimated by pooling the sample proportions. Conse-\nquently, a conclusion based on a confidence interval might be different from a conclu-\nsion based on a hypothesis test. See the caution that follows Example 2.\nEXAMPLE 2   Confidence Interval for Claim About  \nTwo Proportions\nUse the sample data given in Example 1 to construct a 90% confidence interval esti-\nmate of the difference between the two population proportions. What does the result \nsuggest about the claim that “the fatality rate of occupants is lower for those in cars \nequipped with airbags”?\nSOLUTION\nREQUIREMENT CHECK We are using the same data from Example 1, and the same \nrequirement check applies here, so the requirements are satisfied. \nThe confidence interval can be found using technology; see the preceding \n Statdisk display. If not using technology, proceed as follows.\n\n9-1 Two Proportions \n399\nWith a 90% confidence level, za>2 = 1.645 (from Table A-2). We first calculate \nthe value of the margin of error E as shown here.\n E = za>2 B\npn1qn1\nn1\n+ pn2qn2\nn2\n= 1.645 S\na\n41\n11,541ba11,500\n11,541b\n11,541\n+\na 52\n9,853ba 9801\n9,853b\n9,853\n= 0.001507\nWith pn1 - pn2 = 41>11,541 - 52>9,853 = -0.001725 and E = 0.001507, the \nconfidence interval is evaluated as follows, with the confidence interval limits \nrounded to three significant digits:\n 1pn1 - pn22 - E 6 1p1 - p22 6 1pn1 - pn22 + E\n-0.001725 - 0.001507 6 1p1 - p22 6 -0.001725 + 0.001507\n - 0.00323 6 1p1 - p22 6 -0.000218\nSee the preceding Statdisk display showing the same confidence interval obtained \nhere.\nINTERPRETATION\nThe confidence interval limits do not contain 0, suggesting that there is a significant \ndifference between the two proportions. The confidence interval suggests that the \nfatality rate is lower for occupants in cars with airbags than for occupants in cars \nwithout airbags. The confidence interval also provides an estimate of the amount of \nthe difference between the two fatality rates.\nA confidence interval provides additional information beyond just a decision on \nwhether or not to reject a hypothesis. It also provides information about the range \nof plausible values of the true risk difference. In this example, the range of values \nin the confidence interval is roughly -0.003 to -0.002. We can translate these \n numbers into rates by multiplying by some population size, say, 1000. Using the \n90% confidence interval, we estimate that drivers without airbags are at increased \nrisk of a fatal car accident by somewhere between 2 and 3 additional fatalities per \n1000 occupants.\nCAUTION Use of One Confidence Interval Don’t test for equality of two \npopulation proportions by determining whether there is an overlap between \ntwo individual confidence interval estimates of the two individual population \nproportions. When compared to the confidence interval estimate of p1 - p2, \nthe analysis of overlap between two individual confidence intervals is more \nconservative (by rejecting equality less often), and it has less power (because it is \nless likely to reject p1 - p2 when in reality p1 ≠p2). See Exercise 25 “Overlap of \nConfidence Intervals.”\nWhat Can We Do When the Requirements Are Not Satisfied?\nBad Samples If we violate the requirement that we have two simple random samples, \nwe could be in big trouble. For example, if we have two convenience samples, there is \nprobably nothing that can be done to salvage them.\nFewer Than 5 Successes or Fewer Than 5 Failures in a Hypothesis Test If we vio-\nlate the requirement that each of the two samples has at least 5 successes and at least 5 \n\n400 \nCHAPTER 9 Inferences from Two Samples\nfailures, we can use Fisher’s exact test, which provides an exact P-value instead of using \nthe method based on a normal distribution approximation. Fisher’s exact test involves \nvery complicated calculations, so the use of technology is strongly recommended. \nStatdisk, Minitab, XLSTAT, and StatCrunch all have the ability to perform Fisher’s ex-\nact test. (See Section 11-2.)\nFewer Than 5 Successes or Fewer Than 5 Failures in a Confidence Interval If we \nviolate the requirement that each of the two samples has at least 5 successes and at \nleast 5 failures, we can use bootstrap resampling methods to construct a confidence \ninterval. See Section 7-4.\nRationale: Why Do the Procedures of This Section Work?\nHypothesis Tests With n1pn1 Ú 5 and n1qn1 Ú 5, the distribution of pn1 can be approxi-\nmated by a normal distribution with mean p1, standard deviation 1p1q1>n1, and vari-\nance p1q1\n >  n1 (based on Sections 6-6 and 7-1). This also applies to the second sample. \nThe distributions of pn1 and pn2 are each approximated by a normal distribution, so \nthe difference pn1 - pn2 will also be approximated by a normal distribution with mean \np1 - p2 and variance\ns2\n1p1-p22 = s2\np1 + s2\np2 = p1q1\nn1\n+ p2q2\nn2\n(The result above is based on this property: The variance of the differences between \ntwo independent random variables is the sum of their individual variances.)\nThe pooled estimate of the common value of p1 and p2 is p =  \n1x1 + x22>1n1 + n22. If we replace p1 and p2 by p and replace q1 and q2 by \nq = 1 - p, the variance above leads to the following standard deviation:\ns1p1-p22 = A\np q\nn1\n+ p q\nn2\nWe now know that the distribution of pn1 - pn2 is approximately normal, with mean \np1 - p2 and standard deviation as shown above, so the z test statistic has the form \ngiven in the Key Elements box near the beginning of this section.\nConfidence Interval The form of the confidence interval requires an expression for \nthe variance different from the one given above. When constructing a confidence in-\nterval estimate of the difference between two proportions, we don’t assume that the \ntwo proportions are equal, and we estimate the standard deviation as\nB\npn1qn1\nn1\n+ pn2qn2\nn2\nIn the test statistic\nz = 1pn1 - pn22 - 1p1 - p22\nB\npn1qn1\nn1\n+ pn2qn2\nn2\nuse the positive and negative values of z (for two tails) and solve for p1 - p2. The \nresults are the limits of the confidence interval given in the Key Elements box near the \nbeginning of this section.\nn n\nn\nn\nn n\nInferences with Two Proportions\nAccess tech instructions, videos, and data sets at www.TriolaStats.com\nTECH CENTER \n\n9-1 Two Proportions \n401\nStatistical Literacy and Critical Thinking \n1. Verifying Requirements In the largest clinical trial ever conducted, 401,974 children were \nrandomly assigned to two groups. The treatment group consisted of 201,229 children given the \nSalk vaccine for polio, and 33 of those children developed polio. The other 200,745 children \nwere given a placebo, and 115 of those children developed polio. If we want to use the methods \nof this section to test the claim that the rate of polio is less for children given the Salk vaccine, \nare the requirements for a hypothesis test satisfied? Explain.\n2. Notation For the sample data given in Exercise 1, consider the Salk vaccine treatment group \nto be the first sample. Identify the values of n1, pn1, qn1, n2, pn2, qn2, p, and q. Round all values so \nthat they have six significant digits.\n3. Hypotheses and Conclusions Refer to the hypothesis test described in Exercise 1.\na. Identify the null hypothesis and the alternative hypothesis.\nb. If the P-value for the test is reported as “less than 0.001,” what should we conclude about the \noriginal claim?\n4. Using Confidence Intervals\na. Assume that we want to use a 0.05 significance level to test the claim that p1 6 p2. Which is \nbetter: a hypothesis test or a confidence interval?\nb. In general, when dealing with inferences for two population proportions, which two of the \nfollowing are equivalent: confidence interval method; P-value method; critical value method?\nc. If we want to use a 0.05 significance level to test the claim that p1 6 p2, what confidence \nlevel should we use for the confidence interval?\nd. If we test the claim in part (c) using the sample data in Exercise 1, we get this confidence \ninterval: -0.000508 6 p1 - p2 6 -0.000309. What does this confidence interval suggest \nabout the claim?\nInterpreting Displays. In Exercises 5 and 6, use the results from the given displays.\n5. Testing Laboratory Gloves The New York Times published an article about a study in \nwhich Professor Denise Korniewicz and other Johns Hopkins researchers subjected laboratory \ngloves to stress. Among 240 vinyl gloves, 63% leaked viruses. Among 240 latex gloves, 7% \nleaked viruses. See the accompanying display of the Statdisk results. Using a 0.01 significance \nlevel, test the claim that vinyl gloves have a greater virus leak rate than latex gloves.\n9-1  Basic Skills and Concepts\nStatdisk\n6. Treating Carpal Tunnel Syndrome Carpal tunnel syndrome is a common wrist complaint \nresulting from a compressed nerve, and it is often the result of extended use of repetitive wrist \nmovements, such as those associated with the use of a keyboard. In a randomized controlled \ntrial, 73 patients were treated with surgery and 67 were found to have successful treatments. \nAmong 83 patients treated with splints, 60 were found to have successful treatments (based on \ndata from “Splinting vs Surgery in the Treatment of Carpal Tunnel Syndrome,” by Gerritsen \nStatCrunch\ncontinued\n\n402 \nCHAPTER 9 Inferences from Two Samples\net al., Journal of the American Medical Association, Vol. 288, No. 10). Use the accompanying \nStatCrunch display with a 0.01 significance level to test the claim that the success rate is better \nwith surgery.\nTesting Claims About Proportions. In Exercises 7–22, test the given claim. Identify the \nnull hypothesis, alternative hypothesis, test statistic, P-value or critical value(s), then state \nthe conclusion about the null hypothesis, as well as the final conclusion that addresses the \noriginal claim.\n7. Ginkgo for Dementia The herb ginkgo biloba is commonly used as a treatment to prevent \ndementia. In a study of the effectiveness of this treatment, 1545 elderly subjects were given \nginkgo and 1524 elderly subjects were given a placebo. Among those in the ginkgo treatment \ngroup, 246 later developed dementia, and among those in the placebo group, 277 later devel-\noped dementia (based on data from “Ginkgo Biloba for Prevention of Dementia,” by DeKosky \net al., Journal of the American Medical Association, Vol. 300, No. 19). We want to use a 0.01 \nsignificance level to test the claim that ginkgo is effective in preventing dementia.\na. Test the claim using a hypothesis test.\nb. Test the claim by constructing an appropriate confidence interval.\nc. Based on the results, is ginkgo effective in preventing dementia?\n8. Clinical Trials of Lipitor Lipitor (atorvastatin) is a drug used to control cholesterol. In \nclinical trials of Lipitor, 94 subjects were treated with Lipitor and 270 subjects were given a \nplacebo. Among those treated with Lipitor, 7 developed infections. Among those given a pla-\ncebo, 27 developed infections. We want to use a 0.05 significance level to test the claim that the \nrate of infections was the same for those treated with Lipitor and those given a placebo.\na. Test the claim using a hypothesis test.\nb. Test the claim by constructing an appropriate confidence interval.\nc. Based on the results, is the rate of infections different for those treated with Lipitor?\n9. Smoking Cessation Programs Among 198 smokers who underwent a “sustained care” \nprogram, 51 were no longer smoking after six months. Among 199 smokers who underwent \na “standard care” program, 30 were no longer smoking after six months (based on data from \n“Sustained Care Intervention and Postdischarge Smoking Cessation Among Hospitalized \nAdults,” by Rigotti et al., Journal of the American Medical Association, Vol. 312, No. 7). We \nwant to use a 0.01 significance level to test the claim that the rate of success for smoking cessa-\ntion is greater with the sustained care program.\na. Test the claim using a hypothesis test.\nb. Test the claim by constructing an appropriate confidence interval.\nc. Does the difference between the two programs have practical significance?\n10. Are Radiation Effects the Same for Men and Women? Among 2739 female atom \nbomb survivors, 1397 developed thyroid diseases. Among 1352 male atom bomb survivors, \n436 developed thyroid diseases (based on data from “Radiation Dose-Response Relationships \nfor Thyroid Nodules and Autoimmune Thyroid Diseases in Hiroshima and Nagasaki Atomic \nBomb Survivors 55–58 Years After Radiation Exposure,” by Imaizumi et al., Journal of the \nAmerican Medical Association, Vol. 295, No. 9).\na. Use a 0.01 significance level to test the claim that female survivors and male survivors have \ndifferent rates of thyroid diseases.\nb. Construct the confidence interval corresponding to the hypothesis test conducted with a 0.01 \nsignificance level. What conclusion does the confidence interval suggest?\n11. Dreaming in Black and White A study was conducted to determine the proportion of peo-\nple who dream in black and white instead of color. Among 306 people over the age of 55, 68 \n\n9-1 Two Proportions \n403\ndream in black and white, and among 298 people under the age of 25, 13 dream in black and \nwhite (based on data from “Do We Dream in Color?” by Eva Murzyn, Consciousness and Cogni-\ntion, Vol. 17, No. 4). We want to use a 0.01 significance level to test the claim that the proportion \nof people over 55 who dream in black and white is greater than the proportion of those under 25.\na. Test the claim using a hypothesis test.\nb. Test the claim by constructing an appropriate confidence interval.\nc. An explanation given for the results is that those over the age of 55 grew up exposed to \nmedia that were mostly displayed in black and white. Can the results from parts (a) and (b) be \nused to verify that explanation?\n12. Clinical Trials of OxyContin OxyContin (oxycodone) is a drug used to treat pain, but \nit is well known for its addictiveness and danger. In a clinical trial, among subjects treated \nwith OxyContin, 52 developed nausea and 175 did not develop nausea. Among other subjects \ngiven placebos, 5 developed nausea and 40 did not develop nausea (based on data from Purdue \nPharma L.P.). Use a 0.05 significance level to test for a difference between the rates of nausea \nfor those treated with OxyContin and those given a placebo.\na. Use a hypothesis test.\nb. Use an appropriate confidence interval.\nc. Does nausea appear to be an adverse reaction resulting from OxyContin?\n13. Are Seat Belts Effective? A simple random sample of front-seat occupants involved in \ncar crashes is obtained. Among 2823 occupants not wearing seat belts, 31 were killed. Among \n7765 occupants wearing seat belts, 16 were killed (based on data from “Who Wants Airbags?” \nby Meyer and Finney, Chance, Vol. 18, No. 2). We want to use a 0.05 significance level to test \nthe claim that seat belts are effective in reducing fatalities.\na. Test the claim using a hypothesis test.\nb. Test the claim by constructing an appropriate confidence interval.\nc. What does the result suggest about the effectiveness of seat belts?\n14. Cardiac Arrest at Day and Night A study investigated survival rates for in-hospital pa-\ntients who suffered cardiac arrest. Among 58,593 patients who had cardiac arrest during the \nday, 11,604 survived and were discharged. Among 28,155 patients who suffered cardiac arrest \nat night, 4139 survived and were discharged (based on data from “Survival from In-Hospital \nCardiac Arrest During Nights and Weekends,” by Peberdy et al., Journal of the American Medi-\ncal Association, Vol. 299, No. 7). We want to use a 0.01 significance level to test the claim that \nthe survival rates are the same for day and night.\na. Test the claim using a hypothesis test.\nb. Test the claim by constructing an appropriate confidence interval.\nc. Based on the results, does it appear that for in-hospital patients who suffer cardiac arrest, the \nsurvival rate is the same for day and night?\n15. Is Echinacea Effective for Colds? Rhinoviruses typically cause common colds. In a test \nof the effectiveness of echinacea, 40 of the 45 subjects treated with echinacea developed rhi-\nnovirus infections. In a placebo group, 88 of the 103 subjects developed rhinovirus infections \n(based on data from “An Evaluation of Echinacea angustifolia in Experimental Rhinovirus In-\nfections,” by Turner et al., New England Journal of Medicine, Vol. 353, No. 4). We want to use \na 0.05 significance level to test the claim that echinacea has an effect on rhinovirus infections.\na. Test the claim using a hypothesis test.\nb. Test the claim by constructing an appropriate confidence interval.\nc. Based on the results, does echinacea appear to have any effect on the infection rate?\n\n404 \nCHAPTER 9 Inferences from Two Samples\n16. Bednets to Reduce Malaria In a randomized controlled trial in Kenya, insecticide-treated \nbednets were tested as a way to reduce malaria. Among 343 infants using bednets, 15 devel-\noped malaria. Among 294 infants not using bednets, 27 developed malaria (based on data from \n“Sustainability of Reductions in Malaria Transmission and Infant Mortality in Western Kenya \nwith Use of Insecticide-Treated Bednets,” by Lindblade et al., Journal of the American Medical \nAssociation, Vol. 291, No. 21). We want to use a 0.01 significance level to test the claim that the \nincidence of malaria is lower for infants using bednets.\na. Test the claim using a hypothesis test.\nb. Test the claim by constructing an appropriate confidence interval.\nc. Based on the results, do the bednets appear to be effective?\n17. Cell Phones and Handedness A study was conducted to investigate the association \nbetween cell phone use and hemispheric brain dominance. Among 216 subjects who prefer to \nuse their left ear for cell phones, 166 were right-handed. Among 452 subjects who prefer to \nuse their right ear for cell phones, 436 were right-handed (based on data from “Hemispheric \nDominance and Cell Phone Use,” by Seidman et al., JAMA Otolaryngology—Head & Neck \nSurgery, Vol. 139, No. 5). We want to use a 0.01 significance level to test the claim that the rate \nof right-handedness for those who prefer to use their left ear for cell phones is less than the rate \nof right-handedness for those who prefer to use their right ear for cell phones. (Try not to get \ntoo confused here.)\na. Test the claim using a hypothesis test.\nb. Test the claim by constructing an appropriate confidence interval.\n18. Denomination Effect A trial was conducted with 75 women in China given a 100-yuan \nbill, while another 75 women in China were given 100 yuan in the form of smaller bills (a \n50-yuan bill plus two 20-yuan bills plus two 5-yuan bills). Among those given the single bill, \n60 spent some or all of the money. Among those given the smaller bills, 68 spent some or all \nof the money (based on data from “The Denomination Effect,” by Raghubir and Srivastava, \n Journal of Consumer Research, Vol. 36). We want to use a 0.05 significance level to test the \nclaim that when given a single large bill, a smaller proportion of women in China spend some or \nall of the money when compared to the proportion of women in China given the same amount \nin smaller bills.\na. Test the claim using a hypothesis test.\nb. Test the claim by constructing an appropriate confidence interval.\nc. If the significance level is changed to 0.01, does the conclusion change?\n19. Headache Treatment In a study of treatments for very painful “cluster” headaches, 150 \npatients were treated with oxygen and 148 other patients were given a placebo consisting of \nordinary air. Among the 150 patients in the oxygen treatment group, 116 were free from head-\naches 15 minutes after treatment. Among the 148 patients given the placebo, 29 were free from \nheadaches 15 minutes after treatment (based on data from “High-Flow Oxygen for Treatment \nof Cluster Headache,” by Cohen, Burns, and Goadsby, Journal of the American Medical As-\nsociation, Vol. 302, No. 22). We want to use a 0.01 significance level to test the claim that the \noxygen treatment is effective.\na. Test the claim using a hypothesis test.\nb. Test the claim by constructing an appropriate confidence interval.\nc. Based on the results, is the oxygen treatment effective?\n20. Does Aspirin Prevent Heart Disease? In a trial designed to test the effectiveness of aspirin \nin preventing heart disease, 11,037 male physicians were treated with aspirin and 11,034 male \nphysicians were given placebos. Among the subjects in the aspirin treatment group, 139 experi-\nenced myocardial infarctions (heart attacks). Among the subjects given placebos, 239 experienced \n\n9-1 Two Proportions \n405\nmyocardial infarctions (based on data from “Final Report on the Aspirin Component of the Ongo-\ning Physicians’ Health Study,” New England Journal of Medicine, Vol. 321: 129–135). Use a 0.05 \nsignificance level to test the claim that aspirin has no effect on myocardial infarctions.\na. Test the claim using a hypothesis test.\nb. Test the claim by constructing an appropriate confidence interval.\nc. Based on the results, does aspirin appear to be effective?\n21. Lefties In a random sample of males, it was found that 23 write with their left hands and \n217 do not. In a random sample of females, it was found that 65 write with their left hands and \n455 do not (based on data from “The Left-Handed: Their Sinister History,” by Elaine Fowler \nCostas, Education Resources Information Center, Paper 399519). We want to use a 0.01 sig-\nnificance level to test the claim that the rate of left-handedness among males is less than that \namong females.\na. Test the claim using a hypothesis test.\nb. Test the claim by constructing an appropriate confidence interval.\nc. Based on the results, is the rate of left-handedness among males less than the rate of left-\nhandedness among females?\n22. Ground vs. Helicopter for Serious Injuries A study investigated rates of fatalities \namong patients with serious traumatic injuries. Among 61,909 patients transported by heli-\ncopter, 7813 died. Among 161,566 patients transported by ground services, 17,775 died (based \non data from “Association Between Helicopter vs Ground Emergency Medical Services and \nSurvival for Adults with Major Trauma,” by Galvagno et al., Journal of the American Medical \nAssociation, Vol. 307, No. 15). Use a 0.01 significance level to test the claim that the rate of \nfatalities is higher for patients transported by helicopter.\na. Test the claim using a hypothesis test.\nb. Test the claim by constructing an appropriate confidence interval.\nc. Considering the test results and the actual sample rates, is one mode of transportation better \nthan the other? Are there other important factors to consider?\n23. Determining Sample Size The sample size needed to estimate the difference between \ntwo population proportions to within a margin of error E with a confidence level of 1 - a can \nbe found by using the following expression:\nE = za>2A\np1q1\nn1\n+ p2q2\nn2\nReplace n1 and n2 by n in the formula above (assuming that both samples have the same size) \nand replace each of p1, q1, p2, and q2 by 0.5 (because their values are not known). Solving for \nn results in this expression:\nn =\nz2\na>2\n2E 2\nUse this expression to find the size of each sample if you want to estimate the difference \nbetween the proportions of men and women who consume medication daily. Assume that you \nwant 95% confidence that your error is no more than 0.03.\n24. Yawning and Fisher’s Exact Test In one segment of the TV series Mythbusters, an ex-\nperiment was conducted to test the common belief that people are more likely to yawn when \nthey see others yawning. In one group, 34 subjects were exposed to yawning, and 10 of them \n9-1  Beyond the Basics\ncontinued\n\n406 \nCHAPTER 9 Inferences from Two Samples\nyawned. In another group, 16 subjects were not exposed to yawning, and 4 of them yawned. We \nwant to test the belief that people are more likely to yawn when they are exposed to yawning.\na. Why can’t we test the claim using the methods of this section?\nb. If we ignore the requirements and use the methods of this section, what is the P-value? How \ndoes it compare to the P-value of 0.5128 obtained by using Fisher’s exact test?\nc. Comment on the conclusion of the Mythbusters segment that yawning is contagious.\n25. Overlap of Confidence Intervals In the article “On Judging the Significance of \n Differences by Examining the Overlap Between Confidence Intervals,” by Schenker and \nGentleman (American Statistician, Vol. 55, No. 3), the authors consider sample data in this \nstatement: “Independent simple random samples, each of size 200, have been drawn, and \n112 people in the first sample have the attribute, whereas 88 people in the second sample have \nthe attribute.”\na. Use the methods of this section to construct a 95% confidence interval estimate of the differ-\nence p1 - p2. What does the result suggest about the equality of p1 and p2?\nb. Use the methods of Section 7-1 to construct individual 95% confidence interval estimates \nfor each of the two population proportions. After comparing the overlap between the two confi-\ndence intervals, what do you conclude about the equality of p1 and p2?\nc. Use a 0.05 significance level to test the claim that the two population proportions are equal. \nWhat do you conclude?\nd. On the basis of the preceding results, what should you conclude about the equality of p1 \nand p2? Which of the three preceding methods is least effective in testing for the equality of \np1 and p2?\n26. Equivalence of Hypothesis Test and Confidence Interval Two different simple ran-\ndom samples are drawn from two different populations. The first sample consists of 20 people, \nwith 10 having a common attribute. The second sample consists of 2000 people, with 1404 of \nthem having the same common attribute. Compare the results from a hypothesis test of p1 = p2 \n(with a 0.05 significance level) and a 95% confidence interval estimate of p1 - p2.\nKey Concept This section presents methods for using sample data from two inde-\npendent samples to test hypotheses made about two population means or to construct \nconfidence interval estimates of the difference between two population means. In \nPart 1 we discuss situations in which the standard deviations of the two populations \nare unknown and are not assumed to be equal. In Part 2 we briefly discuss two other \nsituations: (1) The two population standard deviations are unknown but are assumed \nto be equal; (2) the unrealistic case in which two population standard deviations are \nboth known.\nPART 1\nIndependent Samples: S1 and S2 Unknown \nand Not Assumed Equal\nThis section involves two independent samples, and the following section deals with \nsamples that are dependent. It is important to know the difference between indepen-\ndent samples and dependent samples.\n9-2 \nTwo Means: Independent Samples\n\n9-2 Two Means: Independent Samples \n407\nHere is an example of independent samples and another example of dependent \nsamples:\n \n■Independent Samples: Heights of Men and Women Data Set 1 “Body Data” in \nAppendix B includes the following heights (cm) of samples of men and women, \nand the two samples are not matched according to some inherent relationship. \nThey are actually two independent samples that just happen to be listed in a way \nthat might cause us to incorrectly think that they are matched.\n Heights 1cm2 of Men \n 172 154 156 158 169\n Heights 1cm2 of Women  186 161 179 167 179\n \n■Dependent Samples: Heights of Husbands and Wives Students of one of the \nauthors collected data consisting of the heights (cm) of husbands and the heights \n(cm) of their wives. Five of those pairs of heights are listed below. These two \nsamples are dependent, because the height of each husband is matched with the \nheight of his wife.\n Height 1cm2 of Husband  175 180 173 176 178\n Height 1cm2 of Wife \n 160 165 163 162 166\nFor inferences about means from two independent populations, the following box \nsummarizes key elements of a hypothesis test and a confidence interval estimate of the \ndifference between the population means.\nDEFINITIONS\nTwo samples are independent if the sample values from one population are not \nrelated to or somehow naturally paired or matched with the sample values from the \nother population.\nTwo samples are dependent (or consist of matched pairs) if the sample values \nare somehow matched, where the matching is based on some inherent relation-\nship. (That is, each pair of sample values consists of two measurements from the \nsame subject—such as before>after data—or each pair of sample values consists \nof matched pairs—such as husband>wife data—where the matching is based on \nsome meaningful relationship. Caution: “Dependence” does not require a direct \ncause>effect relationship.)\nHINT If the two samples have different sample sizes with no missing data, they \nmust be independent. If the two samples have the same sample size, the samples \nmay or may not be independent.\nInferences About Two Means: Independent Samples\nObjectives\nKEY ELEMENTS \n1. Hypothesis Test: Conduct a hypothesis test of a \nclaim about two independent population means.\n2. Confidence Interval: Construct a confidence \ninterval estimate of the difference between two \nindependent population means.\ncontinued\n\n408 \nCHAPTER 9 Inferences from Two Samples\nNotation\nFor population 1 we let\nm1 = population mean \nx1 = sample mean\ns1 = population standard deviation \ns1 = sample standard deviation\nn1 = size of the first sample\nThe corresponding notations m2, s2, x2, s2, and n2, apply to population 2.\nRequirements\n1. The values of s1 and s2 are unknown and we do not as-\nsume that they are equal.\n2. The two samples are independent.\n3. Both samples are simple random samples.\n4. Either or both of these conditions are satisfied: The \ntwo sample sizes are both large (with n1 7 30 and \nn2 7 30) or both samples come from populations \nhaving normal distributions. (The methods used here \nare robust against departures from normality, so for \nsmall samples, the normality requirement is loose in \nthe sense that the procedures perform well as long as \nthere are no outliers and departures from normality \nare not too extreme.)\nHypothesis Test Statistic for Two Means: Independent Samples (with H0: M1 = M2)\nt = 1x1 - x22 - 1m1 - m22\nB\ns2\n1\nn1\n+ s2\n2\nn2\n \n1where m1 - m2 is often assumed to be 02\nDegrees of Freedom: When finding critical values or  \nP-values, use the following for determining the number of \ndegrees of freedom, denoted by df. (Although these two \nmethods typically result in different numbers of degrees of \nfreedom, the conclusion of a hypothesis test is rarely af-\nfected by the choice.)\n1. Use this simple and conservative estimate:\ndf = smaller of n1 −1 and n2 −1\n2. Technologies typically use the more accurate but \nmore difficult estimate given in Formula 9-1.\nFORMULA 9-1\ndf =\n1A + B2 2\nA2\nn1 - 1 +\nB2\nn2 - 1\nwhere A = s2\n1\nn1\n and B = s2\n2\nn2\nNote: Answers in Appendix D include technology answers \nbased on Formula 9-1 along with “Table” answers based \non using Table A-3 with the simple estimate of df given in \noption 1 above.\nP-Values: \n P-values are automatically provided by technology. If technology is not available, refer to the t distri-\nbution in Table A-3. Use the procedure summarized in Figure 8-3 on page 344.\nCritical Values: \nRefer to the t distribution in Table A-3.\nConfidence Interval Estimate of M1 −M2: Independent Samples\nThe confidence interval estimate of the difference m1 -  m2 is\n1x1 - x22 - E 6 1m1 - m22 6 1x1 - x22 + E\nwhere\nE = ta>2B\ns2\n1\nn1\n+ s2\n2\nn2\nand the number of degrees of freedom df is as described above for hypothesis tests.  \n(In this book, we use df = smaller of n1 - 1 and n2 - 1.)\n\n9-2 Two Means: Independent Samples \n409\nEquivalent Methods\nThe P-value method of hypothesis testing, the critical value method of hypothesis \ntesting, and confidence intervals all use the same distribution and standard error, so \nthey are all equivalent in the sense that they result in the same conclusions.\nP-Value Method\nEXAMPLE 1  Second-Hand Smoke\nData Set 14 “Passive and Active Smoke” includes measures of cotinine (ng>mL) in \nsubjects from different groups. Cotinine is produced when nicotine is absorbed by \nthe body, so cotinine is a good indicator of nicotine. Listed below are the summary \nstatistics from a group of smokers and another group of subjects who do not smoke \nbut are exposed to environmental tobacco smoke at home or work. Use a 0.05 sig-\nnificance level to test the claim that the population of smokers has a higher mean \ncotinine level than the nonsmokers exposed to smoke. Do smokers appear to have \nhigher of levels of cotinine than nonsmokers who are exposed to smoke?\nSmokers n = 40, x = 172.5 ng>mL, s = 119.5 ng>mL\nNonsmokers Exposed to Smoke n = 40, x = 60.6 ng>mL, s = 138.1 ng>mL\nSOLUTION\nREQUIREMENT CHECK (1) The values of the two population standard deviations are \nnot known and we are not making an assumption that they are equal. (2) The two \nsamples are independent. They are not matched or paired in any way. (3) The samples \nare simple random samples. (4) Both samples are large, with more than 30 subjects. \nThe requirements are all satisfied. \nUsing the P-value method summarized in Figure 8-1 on page 340, we can test \nthe claim as follows.\nStep 1: The claim that “the population of smokers has a higher mean cotinine level \nthan the nonsmokers exposed to smoke” can be expressed as m1 7 m2.\nStep 2: If the original claim is false, then m1 … m2.\nStep 3: The alternative hypothesis is the expression not containing equality, and the \nnull hypothesis is an expression of equality, so we have\nH0: m1 = m2        H1: m1 7 m2 \nWe now proceed with the assumption that m1 = m2, or m1 - m2 = 0.\nStep 4: The significance level is a = 0.05.\nStep 5: Because we have two independent samples and we are testing a claim about \nthe two population means, we use a t distribution with the test statistic given earlier \nin this section.\nStep 6: The test statistic is calculated using the statistics given in the statement of \nthe problem:\nt = 1x1 - x22 - 1m1 - m22\nB\ns2\n1\nn1\n+ s2\n2\nn2\n= 1172.5 - 60.62 - 0\nB\n119.52\n40\n+ 138.12\n40\n= 3.875\nis \no\nExpensive Diet Pill\nThere are many \npast examples \nin which ineffec-\ntive treatments \nwere marketed \nfor substan-\ntial profits. \nCapsules of “Fat Trapper” \nand  “Exercise in a Bottle,” \nmanufactured by the Enforma \nNatural Products company, were \nadvertised as being effective \ntreatments for weight reduction. \nAdvertisements claimed that after \ntaking the capsules, fat would be \nblocked and calories would be \nburned, even without exercise. \nBecause the Federal Trade Com-\nmission identified claims that \nappeared to be unsubstantiated, \nthe company was fined $10 mil-\nlion for deceptive advertising.\nThe effectiveness of such \ntreatments can be determined \nwith experiments in which one \ngroup of randomly selected \nsubjects is given the treatment, \nwhile another group of randomly \nselected subjects is given a \nplacebo. The resulting weight \nlosses can be compared using \nstatistical methods, such as \nthose described in this section.\nT\n”\ncontinued\n\n410 \nCHAPTER 9 Inferences from Two Samples\nTechnology The tricky part about the preceding P-value approach is that Table A-3 \ncan only give a range for the P-value, and determining that range is often a bit tricky. \nTechnology automatically provides the P-value, so technology makes the P-value \nmethod quite easy. See the accompanying XLSTAT display showing the test statistic \nof t = 3.8755 and the P-value of 0.0001.\nCritical Value Method\nIf technology is not available, the critical value method of testing a claim about two \nmeans is generally easier than the P-value method. Example 1 can be solved using the \ncritical value method. When finding critical values in Table A-3, we use df = smaller \nof n1 - 1 and n2 - 1 as a relatively easy way to avoid using the really messy calcu-\nlation required with Formula 9-1. In Example 1 with sample sizes of n1 = 40 and \nn2 = 40, the number of degrees of freedom is 39, so using Table A-3 with df = 39 \nand a = 0.05 in the right tail, we get the critical value of t = 1.685. Technology uses \nFormula 9-1 to find the more accurate critical value of t = 1.665. See Figure 9-2. The \ntest statistic of t = 3.875 falls in the critical region, so we reject the null hypothesis, \nas we did in Example 1.\nP-Value With test statistic t = 3.875, we refer to Table A-3 (t Distribution). The \nnumber of degrees of freedom is the smaller of n1 - 1 and n2 - 1, or the smaller \nof 140 - 12 and 140 - 12, which is 39. With df = 39 and a right-tailed test, \nTable A-3 indicates that the test statistic t = 3.875 results in a P-value that is less \nthan 0.005. Technology will provide the P-value of 0.0001 when using the original \ndata or unrounded sample statistics.\nStep 7: Because the P-value is less than the significance level of 0.05, we reject the \nnull hypothesis. (“If the P is low, the null must go.”)\nINTERPRETATION\nStep 8: There is sufficient evidence to support the claim that the population of \nsmokers has a higher mean cotinine level than the nonsmokers exposed to smoke. It \nappears that smoking is associated with higher levels of cotinine than nonsmokers \nexposed to smoke.\nXLSTAT\nt 5 0\na\u001f2 5 0.025\na\u001f2 5 0.025\nTest Statistic:\nt 5 20.660\nt 5 22.093\nt 5 2.093\nFIGURE 9-2  Hypothesis Test of Means from \nTwo Independent Populations\n\n9-2 Two Means: Independent Samples \n411\nConfidence Intervals\nEXAMPLE 2  Confidence Interval for Second-Hand Smoke\nUsing the sample data given in Example 1, construct a 90% confidence interval es-\ntimate of the difference between the mean cotinine level of smokers and the mean \ncotinine level of nonsmokers exposed to smoke.\nSOLUTION\nREQUIREMENT CHECK Because we are using the same data from Example 1, the \nsame requirement check applies here, so the requirements are satisfied. \nWe first find the value of the margin of error E. In Table A-3 with df = 39 and \na = 0.10 in two tails, we get critical values of t = {1.685. (Technology can be \nused to find the more accurate critical values of t = {1.665.)\nE = ta>2B\ns2\n1\nn1\n+ s2\n2\nn2\n= 1.685B\n119.52\n40\n+ 138.12\n40\n= 48.655276\nUsing E = 48.655276, x1 = 172.5, and x2 = 60.6, we can now find the confidence \ninterval as follows:\n1x1 - x22 - E 6 1m1 - m22 6 1x1 - x22 + E\n63.2 ng>mL 6 1m1 - m22 6 160.6 ng>mL\nIf we use technology to obtain more accurate results, we get the confidence interval \nof 63.8 ng>mL 6 1m1 - m22 6 160.0 ng>mL, so we can see that the confidence \ninterval above is quite good, even though we used a simplified method for finding \nthe number of degrees of freedom (instead of getting more accurate results by using \nFormula 9-1).\nINTERPRETATION\nWe are 90% confident that the limits of 63.2 ng>mL and 160.6 ng>mL actually \ndo contain the difference between the two population means. Because those limits \ndo not contain 0, this confidence interval suggests that the mean cotinine level of \nsmokers is greater than the mean cotinine level of nonsmokers exposed to smoke.\nPART 2\nAlternative Methods\nPart 1 of this section dealt with situations in which the two population standard devia-\ntions are unknown and are not assumed to be equal. In Part 2 we address two other \nsituations:\n1. The two population standard deviations are unknown but are assumed to be \nequal.\n2. The two population standard deviations are both known.\nAlternative Method: Assume That S1 = S2 and Pool the Sample Variances\nEven when the specific values of s1 and s2 are not known, if it can be assumed that \nthey have the same value, the sample variances s2\n1 and s2\n2 can be pooled to obtain an \n\n412 \nCHAPTER 9 Inferences from Two Samples\nestimate of the common population variance s2\n . The pooled estimate of S2 is denoted \nby s2\np and is a weighted average of s2\n1 and s2\n2, which is used in the test statistic for this \ncase:\nTest Statistic  t = 1x1 - x22 - 1m1 - m22\nB\ns2p\nn1\n+\ns2p\nn2\nwhere s2\np = 1n1 - 12s2\n1 + 1n2 - 12s2\n2\n1n1 - 12 + 1n2 - 12\n \n1pooled sample variance2\nand the number of degrees of freedom is df = n1 +  n2 - 2.\nThe requirements for this case are the same as in Part 1, except the first requirement \nis that s1 and s2 are not known but they are assumed to be equal. Confidence intervals \nare found by evaluating 1x1 - x22 - E 6 1m1 - m22 6 1x1 - x22 + E with the \nfollowing margin of error E.\nMargin of Error for Confidence Interval E = ta>2 B\ns2p\nn1\n+\ns2p\nn2\nwhere s2\np is as given in the test statistic above, and df = n1 + n2 - 2.\nWhen Should We Assume That S1 = S2? If we use randomness to assign subjects \nto treatment and placebo groups, we know that the samples are drawn from the same \npopulation. So if we conduct a hypothesis test assuming that two population means \nare equal, it is not unreasonable to also assume that the samples are from populations \nwith the same standard deviations (but we should still check that assumption).\nAdvantage of Pooling The advantage of this alternative method of pooling sample \nvariances is that the number of degrees of freedom is a little higher, so hypothesis tests \nhave more power and confidence intervals are a little narrower.\nIn the article “Homogeneity of Variance in the Two-Sample Means Test” (by \nMoser and Stevens, American Statistician, Vol. 46, No. 1), the authors note that we \nrarely know that s1 = s2. They analyze the performance of the different tests by con-\nsidering sample sizes and powers of the tests. They conclude that more effort should \nbe spent learning the method given in Part 1, and less emphasis should be placed on \nthe method based on the assumption of s1 = s2.\nAlternative Method Used When S1 and S2 Are Known\nIn reality, the population standard deviations s1 and s2 are almost never known, but \nif they are somehow known, the test statistic and confidence interval are based on the \nnormal distribution instead of the t distribution. The requirements are the same as \nthose given in Part 1, except for this first requirement: s1 and s2 are known. Critical \nvalues and P-values are found using technology or Table A-2, and the test statistic for \nthis case is as follows:\nTest Statistic z = 1x1 - x22 - 1m1 - m22\nB\ns2\n1\nn1\n+ s2\n2\nn2\nConfidence intervals are found by evaluating  \n1x1 - x22 - E 6 1m1 - m22 6 1x1 - x22 + E, where:\nMargin of Error for Confidence Interval E = za>2B\ns2\n1\nn1\n+ s2\n2\nn2\ne\nb\nc\nGender Gap in Drug \nTesting\nA study of the \nrelationship \nbetween \nheart attacks \nand doses \nof aspirin \ninvolved \n22,000 male physicians. \nThis study, like many others, \nexcluded women. The General \nAccounting Office criticized the \nNational Institutes of Health for \nnot including both genders in \nmany studies because results of \nmedical tests on males do not \nnecessarily apply to females. \nFor example, women’s hearts \nare different from men’s in many \nimportant ways. When forming \nconclusions based on sample \nresults, we should be wary of \nan inference that extends to a \npopulation larger than the one \nfrom which the sample was \ndrawn.\n\n9-2 Two Means: Independent Samples \n413\nWhat if One Standard Deviation Is Known and the Other Is Unknown? If s1\nis known but s2 is unknown, use the procedures in Part 1 of this section with these \nchanges: Replace s1 with the known value of s1 and use the number of degrees of free-\ndom found from the expression below. (See “The Two-Sample t Test with One Vari-\nance Unknown,” by Maity and Sherman, The American Statistician, Vol. 60, No. 2.)\ndf =\nas2\n1\nn1\n+ s2\n2\nn2\nb\n2\n1s2\n2>n22 2\nn2 - 1\nRecommended Strategy for Two Independent Means\nHere is the recommended strategy for the methods of this section:\nAssume that S1 and S2 are unknown, do not assume that S1 = S2, and use \nthe test statistic and confidence interval given in Part 1 of this section.\nInferences with Two Means: Independent Samples\nAccess tech instructions, videos, and data sets at www.TriolaStats.com\nTECH CENTER \nStatistical Literacy and Critical Thinking \n1. Independent and Dependent Samples Which of the following involve independent \n samples?\na. Data Set 2 “Body Temperatures” includes body temperatures of subjects measured at 8 AM \nand again at 12 AM on Day 1 of observation.\nb. Data Set 6 “Family Heights” includes heights of fathers and heights of their daughters.\nc. Data Set 1 “Body Data” includes pulse rates of 147 adult females and 153 adult males.\n2. Confidence Interval for Hemoglobin Large samples of women and men are ob-\ntained and the hemoglobin level is measured in each subject. Here is the 95% confidence \ninterval for the difference between the two population means, where the measures from \nwomen correspond to population 1 and the measures from men correspond to population 2: \n-1.76 g>dL 6 m1 - m2 6 -1.62 g>dL.\na. What does the confidence interval suggest about equality of the mean hemoglobin level in \nwomen and the mean hemoglobin level in men?\nb. Write a brief statement that interprets that confidence interval.\nc. Express the confidence interval with measures from men being population 1 and measures \nfrom women being population 2.\n3. Hypothesis Tests and Confidence Intervals for Hemoglobin\na. Exercise 2 includes a confidence interval. If you use the P-value method or the critical value \nmethod from Part 1 of this section to test the claim that women and men have the same mean \n9-2 Basic Skills and Concepts\ncontinued\n\n414 \nCHAPTER 9 Inferences from Two Samples\nhemoglobin levels, will the hypothesis tests and the confidence interval result in the same con-\nclusion?\nb. In general, if you conduct a hypothesis test using the methods of Part 1 of this section, will \nthe P-value method, the critical value method, and the confidence interval method result in the \nsame conclusion?\nc. Assume that you want to use a 0.01 significance level to test the claim that the mean hemo-\nglobin amount in women is less than the mean hemoglobin amount in men. What confidence \nlevel should be used if you want to test that claim using a confidence interval?\n4. Degrees of Freedom For Example 1 on page 409, we used df = smaller of n1 - 1 and \nn2 - 1, we got df = 39, and the corresponding critical value is t = 1.685. If we calculate \ndf using Formula 9-1, we get df = 76.423, and the corresponding critical value is t = 1.665.\nHow is using a critical value of t = 1.685 more “conservative” than using the critical value of \nt = 1.665? (Hint: What magnitude of difference between the two sample means is required \nwhen using a critical value of t = 1.685 compared to the critical value of 1.665?)\nIn Exercises 5–22, assume that the two samples are independent simple random samples \nselected from normally distributed populations, and do not assume that the population stan-\ndard deviations are equal. (Note: Answers in Appendix D include technology answers based \non Formula 9-1 along with “Table” answers based on Table A-3 with df equal to the smaller \nof n1 −1 and n2 −1.)\n5. Hypothesis Test of Effectiveness of Humidity in Treating Croup In a randomized \ncontrolled trial conducted with children suffering from viral croup, 46 children were treated \nwith low humidity while 46 other children were treated with high humidity. Researchers used \nthe Westley Croup Score to assess the results after one hour. The low-humidity group had a \nmean score of 0.98 with a standard deviation of 1.22, while the high-humidity group had a \nmean score of 1.09 with a standard deviation of 1.11 (based on data from “Controlled Delivery \nof High vs Low Humidity vs Mist Therapy for Croup Emergency Departments,” by Scolnik \net al., Journal of the American Medical Association, Vol. 295, No. 11). Use a 0.05 significance \nlevel to test the claim that the two groups are from populations with the same mean. What does \nthe result suggest about the common treatment of humidity?\n6. Effectiveness of Echinacea In a randomized, double-blind, placebo-controlled trial \nof children, echinacea was tested as a treatment for upper respiratory infections in children. \n“Days of fever” was one criterion used to measure effects. Among 337 children treated \nwith  echinacea, the mean number of days with fever was 0.81, with a standard deviation of \n1.50 days. Among 370 children given a placebo, the mean number of days with fever was 0.64 \nwith a standard  deviation of 1.16 days (based on data from “Efficacy and Safety of Echinacea \nin Treating  Upper Respiratory Tract Infections in Children,” by Taylor et al., Journal of the \n American Medical Association, Vol. 290, No. 21). Use a 0.05 significance level to test the claim \nthat echinacea affects the number of days with fever. Based on these results, does echinacea \nappear to be effective?\n7. Effects of Cocaine on Children A study was conducted to assess the effects that occur \nwhen children are exposed to cocaine before birth. Children were tested at age 4 for object \nassembly skill, which was described as “a task requiring visual-spatial skills related to math-\nematical competence.” The 190 children born to cocaine users had a mean of 7.3 and a standard \ndeviation of 3.0. The 186 children not exposed to cocaine had a mean score of 8.2 with a stan-\ndard deviation of 3.0. (The data are based on “Cognitive Outcomes of Preschool Children with \nPrenatal Cocaine Exposure,” by Singer et al., Journal of the American Medical Association, \nVol. 291, No. 20.)\na. Use a 0.05 significance level to test the claim that prenatal cocaine exposure is associated \nwith lower scores of four-year-old children on the test of object assembly.\nb. Test the claim in part (a) by using a confidence interval.\n\n9-2 Two Means: Independent Samples \n415\n8. Magnet Treatment of Pain People spend around $5 billion annually for the purchase of \nmagnets used to treat a wide variety of pains. Researchers conducted a study to determine \nwhether magnets are effective in treating back pain. Pain was measured using the visual ana-\nlog scale, and the results given below are among the results obtained in the study (based on \ndata from “Bipolar Permanent Magnets for the Treatment of Chronic Lower Back Pain: A Pi-\nlot Study,” by Collacott, Zimmerman, White, and Rindone, Journal of the American Medical \n Association, Vol. 283, No. 10).\na. Use a 0.05 significance level to test the claim that those treated with magnets have a greater \nmean reduction in pain than those given a sham treatment (similar to a placebo).\nb. Construct the confidence interval appropriate for the hypothesis test in part (a).\nc. Does it appear that magnets are effective in treating back pain? Is it valid to argue that mag-\nnets might appear to be effective if the sample sizes are larger?\n Reduction in Pain Level After Magnet Treatment:  n = 20, x = 0.49, s = 0.96\n Reduction in Pain Level After Sham Treatment:   n = 20, x = 0.44, s = 1.4\n9. Cigarette Tar The mean tar content of a simple random sample of 25 unfiltered king-size \ncigarettes is 21.1 mg, with a standard deviation of 3.2 mg. The mean tar content of a simple \nrandom sample of 25 filtered 100-mm cigarettes is 13.2 mg with a standard deviation of 3.7 mg \n(from Data Set 15 “Cigarette Contents” in Appendix B).\na. Use a 0.05 significance level to test the claim that unfiltered king-size cigarettes have a mean \ntar content greater than that of filtered 100-mm cigarettes. What does the result suggest about \nthe effectiveness of cigarette filters?\nb. Construct a 90% confidence interval estimate of the difference between the mean tar content \nof unfiltered king-size cigarettes and the mean tar content of filtered 100-mm cigarettes. Does \nthe result suggest that 100-mm filtered cigarettes have less tar than unfiltered king-size ciga-\nrettes?\n10. Bipolar Depression Treatment In clinical experiments involving different groups of in-\ndependent samples, it is important that the groups be similar in the important ways that affect \nthe experiment. In an experiment designed to test the effectiveness of paroxetine for treating bi-\npolar depression, subjects were measured using the Hamilton depression scale, with the results \ngiven below (based on data from “Double-Blind, Placebo-Controlled Comparison of Imipra-\nmine and Paroxetine in the Treatment of Bipolar Depression,” by Nemeroff et al., American \nJournal of Psychiatry, Vol. 158, No. 6). Use a 0.05 significance level to test the claim that the \ntreatment group and placebo group come from populations with the same mean. What does \nthe result of the hypothesis test suggest about paroxetine as a treatment for bipolar depression?\n Placebo group: \n n = 43, x = 21.57, s = 3.87\n Paroxetine treatment group:  n = 33, x = 20.38, s = 3.91\n11. Effects of Alcohol An experiment was conducted to test the effects of alcohol. The errors \nwere recorded in a test of visual and motor skills for a treatment group of people who drank \nethanol and another group given a placebo. The results are shown in the accompanying table \n(based on data from “Effects of Alcohol Intoxication on Risk Taking, Strategy, and Error Rate \nin Visuomotor Performance,” by Streufert et al., Journal of Applied Psychology, Vol. 77, No. 4).\na. Use a 0.05 significance level to test the claim that there is a difference between the treatment \ngroup and control group. If there is a significant difference, can we conclude that the treatment \ncauses a decrease in visual and motor skills?\nb. Construct a 95% confidence interval estimate of the difference between the two population \nmeans. Do the results support the common belief that drinking is hazardous for drivers, pilots, \nship captains, and so on? Why or why not?\nTreatment \nGroup\nPlacebo \nGroup\nn1 = 22\nn2 = 22\nx1 = 4.20\nx2 = 1.71\ns1 = 2.20\ns2 = 0.72\n\n416 \nCHAPTER 9 Inferences from Two Samples\n12. Effect of Marijuana Use on College Students Many studies have been conducted to \ntest the effects of marijuana use on mental abilities. In one such study, groups of light and heavy \nusers of marijuana in college were tested for memory recall, with the results given below (based \non data from “The Residual Cognitive Effects of Heavy Marijuana Use in College Students,” by \nPope and Yurgelun-Todd, Journal of the American Medical Association, Vol. 275, No. 7).\na. Use a 0.01 significance level to test the claim that the population of heavy marijuana users \nhas a lower mean than the light users. Should marijuana use be of concern to college students?\nb. Construct a 98% confidence interval for the difference between the two population means. \nDoes the confidence interval include zero? What does the confidence interval suggest about the \nequality of the two population means?\n Items sorted correctly by light marijuana users:  n = 64, x = 53.3, s = 3.6\n Items sorted correctly by heavy marijuana users:  n = 65, x = 51.3, s = 4.5\n13. Second-Hand Smoke Data Set 14 “Passive and Active Smoke” includes cotinine levels \nmeasured in a group of nonsmokers exposed to tobacco smoke (n = 40, x = 60.58 ng>mL,\ns = 138.09 ng>mL) and a group of nonsmokers not exposed to tobacco smoke (n = 40,\nx = 16.35 ng>mL, s = 62.53 ng>mL). Cotinine is a metabolite of nicotine, meaning that \nwhen nicotine is absorbed by the body, cotinine is produced.\na. Use a 0.05 significance level to test the claim that nonsmokers exposed to tobacco smoke \nhave a higher mean cotinine level than nonsmokers not exposed to tobacco smoke.\nb. Construct the confidence interval appropriate for the hypothesis test in part (a).\nc. What do you conclude about the effects of second-hand smoke?\n14. BMI We know that the mean weight of men is greater than the mean weight of women, and \nthe mean height of men is greater than the mean height of women. A person’s body mass index \n(BMI) is computed by dividing weight (kg) by the square of height (m). Given below are the \nBMI statistics for random samples of females and males taken from Data Set 1 “Body Data” in \nAppendix B.\na. Use a 0.05 significance level to test the claim that females and males have the same mean \nBMI.\nb. Construct the confidence interval that is appropriate for testing the claim in part (a).\nc. Do females and males appear to have the same mean BMI?\n Female BMI:  n = 70, x = 29.10, s = 7.39\n  Male BMI:  n = 80, x = 28.38, s = 5.37\n15. IQ and Lead Exposure Data Set 8 “IQ and Lead” in Appendix B lists full IQ scores for \na random sample of subjects with low lead levels in their blood and another random sample of \nsubjects with high lead levels in their blood. The statistics are summarized below.\na. Use a 0.05 significance level to test the claim that the mean IQ score of people with low \nblood lead levels is higher than the mean IQ score of people with high blood lead levels.\nb. Construct a confidence interval appropriate for the hypothesis test in part (a).\nc. Does exposure to lead appear to have an effect on IQ scores?\n Low Blood Lead Level:  n = 78, x = 92.88462, s = 15.34451\n High Blood Lead Level:  n = 21, x = 86.90476, s = 8.988352\n16. Seat Belts A study of seat belt use involved children who were hospitalized after motor \nvehicle crashes. For a group of 123 children who were wearing seat belts, the number of days \nin intensive care units (ICU) has a mean of 0.83 and a standard deviation of 1.77. For a group \nof 290 children who were not wearing seat belts, the number of days spent in ICUs has a mean \n\n9-2 Two Means: Independent Samples \n417\nof 1.39 and a standard deviation of 3.06 (based on data from “Morbidity Among Pediatric Mo-\ntor Vehicle Crash Victims: The Effectiveness of Seat Belts,” by Osberg and Di Scala, American \nJournal of Public Health, Vol. 82, No. 3).\na. Use a 0.05 significance level to test the claim that children wearing seat belts have a lower \nmean length of time in an ICU than the mean for children not wearing seat belts.\nb. Construct a confidence interval appropriate for the hypothesis test in part (a).\nc. What important conclusion do the results suggest?\n17. Bad Stuff in Children’s Movies Data Set 13 “Alcohol and Tobacco in Movies” includes \nlengths of times (seconds) of tobacco use shown in animated children’s movies. For the Disney \nmovies, n = 33, x =  61.6 sec, s = 118.8 sec. For the other movies, n = 17, x = 49.3 sec, \ns = 69.3 sec. The sorted times for the non-Disney movies are listed below.\na. Use a 0.05 significance level to test the claim that Disney animated children’s movies and \nother animated children’s movies have the same mean time showing tobacco use.\nb. Construct a confidence interval appropriate for the hypothesis test in part (a).\nc. Conduct a quick visual inspection of the listed times for the non-Disney movies and com-\nment on the normality requirement. How does the normality of the 17 non-Disney times affect \nthe results?\n0 0 0 0 0 0 1 5 6 17 24 55 91 117 155 162 205\n18. Radiation in Baby Teeth Listed below are amounts of strontium-90 (in millibecquerels, \nor mBq, per gram of calcium) in a simple random sample of baby teeth obtained from Pennsyl-\nvania residents and New York residents born after 1979 (based on data from “An Unexpected \nRise in Strontium-90 in U.S. Deciduous Teeth in the 1990s,” by Mangano et al., Science of the \nTotal Environment, Vol. 317).\na. Use a 0.05 significance level to test the claim that the mean amount of strontium-90 from \nPennsylvania residents is greater than the mean amount from New York residents.\nb. Construct a confidence interval for testing the claim in part (a).\nPennsylvania:\n155\n142\n149\n130\n151\n163\n151\n142\n156\n133\n138\n161\nNew York:\n133\n140\n142\n131\n134\n129\n128\n140\n140\n140\n137\n143\n19. Longevity Listed below are the numbers of years that popes and British monarchs (since \n1690) lived after their election or coronation (based on data from Computer-Interactive Data \nAnalysis, by Lunn and McNeil, John Wiley & Sons). Treat the values as simple random sam-\nples from a larger population.\na. Use a 0.01 significance level to test the claim that the mean longevity for popes is less than \nthe mean for British monarchs after coronation.\nb. Construct a confidence interval for testing the claim in part (a).\nPopes:\n 2\n 9\n21\n 3\n 6\n10\n18\n11\n6\n25\n23\n 6\n 2\n15\n32\n25\n11\n 8\n17\n19\n5\n15\n 0\n26\nKings and Queens:\n17\n 6\n13\n12\n13\n33\n59\n10\n7\n63\n 9\n25\n36\n15\n20. Blanking Out on Tests Many students have had the unpleasant experience of panick-\ning on a test because the first question was exceptionally difficult. The arrangement of test \nitems was studied for its effect on anxiety. The following scores are measures of “debilitating \ntest anxiety,” which most of us call panic or blanking out (based on data from “Item Arrange-\nment, Cognitive Entry Characteristics, Sex and Test Anxiety as Predictors of Achievement in \nExamination Performance,” by Klimko, Journal of Experimental Education, Vol. 52, No. 4.) Is \ncontinued\n\n418 \nCHAPTER 9 Inferences from Two Samples\nthere sufficient evidence to support the claim that the two populations of scores have different \nmeans? Is there sufficient evidence to support the claim that the arrangement of the test items \nhas an effect on the score?\nQuestions Arranged from Easy to Difficult\nQuestions Arranged from Difficult to Easy\n24.64\n39.29\n16.32\n32.83\n28.02\n33.62\n34.02\n26.63\n30.26\n33.31\n20.60\n21.13\n26.69\n28.90\n35.91\n26.68\n29.49\n35.32\n26.43\n24.23\n 7.10\n32.86\n21.06\n27.24\n32.34\n29.34\n33.53\n28.89\n28.71\n31.73\n30.02\n21.96\n27.62\n42.91\n30.20\n32.54\n25.49\n38.81\n27.85\n30.29\n30.72\n21. Do Men and Women Have the Same Mean Diastolic Blood Pressure? Refer to Data \nSet 1 “Body Data” and use a 0.05 significance level to test the claim that women and men have \nthe same mean diastolic blood pressure.\n22. Birth Weights Refer to Data Set 3 “Births” and use the birth weights of boys and girls. \nTest the claim that at birth, girls have a lower mean weight than boys.\n23. Pooling Repeat Exercise 15 “IQ and Lead Exposure” by assuming that the two population \nstandard deviations are equal, so s1 = s2. Use the appropriate method from Part 2 of this sec-\ntion. Does pooling the standard deviations yield results showing greater significance?\n24. Degrees of Freedom In Exercise 20 “Blanking Out on Tests,” using the “smaller of \nn1 - 1 and n2 - 1” for the number of degrees of freedom results in df = 15. Find the number \nof degrees of freedom using Formula 9-1. In general, how are hypothesis tests and confidence \nintervals affected by using Formula 9-1 instead of the “smaller of n1 - 1 and n2 - 1”?\n25. No Variation in a Sample An experiment was conducted to test the effects of alcohol. Re-\nsearchers measured the breath alcohol levels for a treatment group of people who drank ethanol \nand another group given a placebo. The results are given below (based on data from “Effects of \nAlcohol Intoxication on Risk Taking, Strategy, and Error Rate in Visuomotor Performance,” by \nStreufert et al., Journal of Applied Psychology, Vol. 77, No. 4). Use a 0.05 significance level to \ntest the claim that the two sample groups come from populations with the same mean.\n Treatment Group:  n1 = 22, x1 = 0.049, s1 = 0.015\n Placebo Group: \n n2 = 22, x2 = 0.000, s2 = 0.000\n9-2 Beyond the Basics\nKey Concept This section presents methods for testing hypotheses and construct-\ning confidence intervals involving the mean of the differences of the values from two \npopulations that are dependent in the sense that the data consist of matched pairs. The \npairs must be matched according to some relationship, such as before>after measure-\nments from the same subjects or husbands and wives.\nGood Experimental Design\nSuppose we want to test the effectiveness of a drug designed to lower blood pressure. \nIt would be better to use before>after measurements from a single group of subjects \ntreated with the drug than to use measurements from one group of subjects who were \n9-3 \nTwo Dependent Samples (Matched Pairs)\n\n9-3 Two Dependent Samples (Matched Pairs) \n419\nnot treated with the drug and a separate group who were treated. The advantage of \nusing matched pairs (before>after measurements) is that we reduce extraneous varia-\ntion, which could occur with the two different independent samples. This strategy for \ndesigning an experiment can be generalized by the following design principle:\nWhen designing an experiment or planning an observational study, using \ndependent samples with matched pairs is generally better than using two \nindependent samples.\nDéjà Vu All Over Again The methods of hypothesis testing in this section are the \nsame methods for testing a claim about a population mean (Part 1 of Section 8-3), ex-\ncept that here we use the differences from the matched pairs of sample data.\nThere are no exact procedures for dealing with dependent samples, but the fol-\nlowing approximation methods are commonly used.\nInferences About Differences from Matched Pairs\nObjectives\nKEY ELEMENTS \n1. Hypothesis Test: Use the differences from two dependent \nsamples (matched pairs) to test a claim about the mean \nof the population of all such differences.\n2. Confidence Interval: Use the differences from two \ndependent samples (matched pairs) to construct a con-\nfidence interval estimate of the mean of the population \nof all such differences.\nNotation for Dependent Samples\nd = individual difference between the two values in a single matched pair\nmd = mean value of the differences d for the population of all matched pairs of data\nd = mean value of the differences d for the paired sample data\nsd = standard deviation of the differences d for the paired sample data\nn = number of pairs of sample data\nRequirements\n1. The sample data are dependent (matched pairs).\n2. The matched pairs are a simple random sample.\n3. Either or both of these conditions are satisfied: The \nnumber of pairs of sample data is large (n 7 30) or the \npairs of values have differences that are from a popula-\ntion having a distribution that is approximately normal. \nThese methods are robust against departures for nor-\nmality, so the normality requirement is loose.\nTest Statistic for Dependent Samples (with H0: Md = 0)\nt = d - md\nsd\n2n\nP-Values: \n P-values are automatically provided by technology or the t distribution in Table A-3 can be used.  \nUse the procedure given in Figure 8-3 on page 344. \nCritical Values: Use Table A-3 (t distribution). For degrees of freedom, use df = n - 1.\nConfidence Intervals for Dependent Samples\nd - E 6 md 6 d + E\nwhere E = ta>2\nsd\n2n\n (Degrees of freedom: df = n - 1.)\n\n420 \nCHAPTER 9 Inferences from Two Samples\nProcedures for Inferences with Dependent Samples\n1. Verify that the sample data consist of dependent samples (or matched pairs), \nand verify that the requirements in the preceding Key Elements box are satis-\nfied.\n2. Find the difference d for each pair of sample values. (Caution: Be sure to sub-\ntract in a consistent manner, such as “before - after.”)\n3. Find the value of d (mean of the differences) and sd (standard deviation of the \ndifferences).\n4. For hypothesis tests and confidence intervals, use the same t test procedures \nused for a single population mean (described in Part 1 of Section 8-3).\nEquivalent Methods\nBecause the hypothesis test and confidence interval in this section use the same distri-\nbution and standard error, they are equivalent in the sense that they result in the same \nconclusions. Consequently, a null hypothesis that the mean difference equals 0 can be \ntested by determining whether the confidence interval includes 0.\nEXAMPLE 1   Are Body Temperatures Different in the Morning \nand at Night?\nTable 9-1 lists body temperatures of five subjects at 8 AM and at 12 AM. The data are \nmatched pairs because each pair of temperatures is measured in the same person. Data \nSet 2 in Appendix B lists 69 pairs of such data for Day 2 of the observations, but we \nuse only 5 of those pairs so that we can easily show the steps in the procedure.\nUse the data in Table 9-1 with a 0.05 significance level to test the claim that \nthere is no difference in body temperatures measured at 8 AM and at 12 AM.\nTABLE 9-1 Body Temperatures of Five Subjects on the Same Day\nTemperature (°F) at 8 AM\n98.0\n 97.6\n 97.2\n 97.0\n 98.0\nTemperature (°F) at 12 AM\n97.0\n 98.8\n 97.6\n 97.7\n 98.8\nDifference d\n 1.0\n−1.2\n−0.4\n−0.7\n−0.8\nSOLUTION\nREQUIREMENT CHECK We address the three requirements listed earlier in the  Key \nElements box. (1) The samples are dependent, since each pair of temperatures is \nmatched because the two values are from the same person. (2) The pairs of data are \nrandomly selected. We will consider the data to be a simple random sample. (3) Be-\ncause the number of pairs of data is n = 5, which is not large, we should check for \nnormality of the differences and we should check for outliers. There are no outliers, \nand a normal quantile plot would show that the points approximate a straight-line \npattern with no other pattern, so the differences satisfy the loose requirement of be-\ning from a normally distributed population. All requirements are satisfied. \nWe will follow the same method of hypothesis testing that we used for testing a \nclaim about a mean (see Figure 8-1 on page 340), but we use differences instead of \nraw sample data.\nStep 1: The claim that there is no difference in body temperatures measured at  \n8 AM and at 12 AM can be expressed as md =  0.\n\n9-3 Two Dependent Samples (Matched Pairs) \n421\nStep 2: If the original claim is not true, then md ≠0.\nStep 3: The null hypothesis must express equality and the alternative hypothesis \ncannot include equality, so we have\nH0: md = 0 1original claim2   H1: md ≠0 \nStep 4: The significance level is a = 0.05.\nStep 5: We use the Student t distribution.\nStep 6: Before finding the value of the test statistic, we must first find the values of \nd and sd. We use the differences from Table 9-1 (1, -1.2, -0.4, -0.7, -0.8) to find \nthese sample statistics: d = -0.42°F and sd = 0.84°F. Using these sample statis-\ntics and the assumption from the null hypothesis that md = 0, we can now find the \nvalue of the test statistic. (The value of t = -1.113 is obtained if unrounded values \nof d and sd are used; technology will provide a test statistic of t = -1.113.)\nt = d - md\nsd\n2n\n= -0.42 - 0\n0.84\n25\n= -1.118\nP-Value Method\nTechnology Technology will provide a P-value of 0.3281\nTable Because we are using a t distribution, we refer to Table A-3 for the row with \ndf = 4 and we see that the test statistic t = -1.118 corresponds to an “Area in Two \nTails” that is greater than 0.20, so P-value 7 0.20. See Figure 9-3(a).\nCritical Value Method Refer to Table A-3 to find the critical values of t = {2.776 \nas follows: Use the column for 0.05 (Area in Two Tails), and use the row with de-\ngrees of freedom of n - 1 = 4. Table A-3 shows a t value of 2.776, but this test is \ntwo-tailed so there are two critical values: t = {2.776. See Figure 9-3(b).\nStep 7: If we use the P-value method, we fail to reject H0 because the P-value of \n0.3281 is greater than the significance level of 0.05. If we use the critical value \nmethod, we fail to reject H0 because the test statistic does not fall in the critical \nregion.\ncontinued\nCrest and Dependent \nSamples\nIn the late \n1950s, Procter \n& Gamble in-\ntroduced Crest \ntoothpaste as \nthe first such \nproduct with \nfluoride. To test the effectiveness \nof Crest in reducing cavities, \nresearchers conducted experi-\nments with several sets of twins. \nOne of the twins in each set was \ngiven Crest with fluoride, while \nthe other twin continued to use \nordinary toothpaste without \nfluoride. It was believed that \neach pair of twins would have \nsimilar eating, brushing, and \ngenetic characteristics. Results \nshowed that the twins who used \nCrest had significantly fewer \ncavities than those who did not. \nThis use of twins as dependent \nsamples allowed the researchers \nto control many of the different \nvariables affecting cavities.\nh\nff\ni\nt 5 0\nArea 5 0.16405\nArea 5 0.16405\nTest Statistic:\nt 5 21.118\n \nt 5 0\nTest Statistic:\nt 5 21.118\nCritical Value:\nt 5 22.776\nCritical Value:\nt 5 2.776\n5 0.025\na\n2\n5 0.025\na\n2\nFIGURE 9-3 Hypothesis Test with Dependent Samples\n(a) P-Value Method \n(b) Critical Value Method\n\n422 \nCHAPTER 9 Inferences from Two Samples\nINTERPRETATION\nWe conclude that there is not sufficient evidence to warrant rejection of the null \nhypothesis that md = 0. There is not sufficient evidence to warrant rejection of the \nclaim of no difference in body temperatures measured at 8 AM and at 12 AM.\nTechnology Software and calculators typically provide a P-value, so the P-value \nmethod of testing hypotheses is usually used. See the accompanying Statdisk re-\nsults showing the test statistic of t = -1.113 and the P-value of 0.3281. Because \nthe P-value of 0.3281 is greater than the significance level of 0.05, we fail to reject \nthe null hypothesis and we conclude that there is not sufficient evidence to warrant \nrejection of the claim of no difference in body temperatures measured at 8 AM and \nat 12 AM.\nStatdisk\nEXAMPLE 2   Confidence Interval for Estimating the Mean of  \nthe Temperature Differences\nUsing the same sample data in Table 9-1, construct a 95% confidence interval \nestimate of md, which is the mean of the temperature differences. By using a con-\nfidence level of 95%, we get a result that could be used for the hypothesis test in \nExample 1.\nSOLUTION\nREQUIREMENT CHECK The solution for Example 1 includes verification that the re-\nquirements are satisfied. \nThe preceding Statdisk display shows the 95% confidence interval. It is found \nusing the values of d = -0.42, sd = 0.84, and ta>2 = 2.776 (found from Table A-3 \nwith n - 1 = 4 degrees of freedom and an area of 0.05 divided equally between \nthe two tails). We first find the value of the margin of error E.\nE = ta>2\nsd\n2n\n= 2.776 # 0.84\n25\n= 1.042831\nWe now find the confidence interval as shown below. If we use the unrounded  \nsd = 0.8438009, we get the more accurate confidence interval of  \n-1.47°F 6 md 6 0.63°F.\nd - E 6 md 6 d + E\n-0.42 - 1.042831 6 md 6 -0.42 + 1.042831\n-1.46oF 6 md 6 0.62oF\n\n9-3 Two Dependent Samples (Matched Pairs) \n423\nINTERPRETATION\nWe have 95% confidence that the limits of -1.47°F and 0.63°F contain the true \nvalue of the mean of the difference between body temperatures at 8 AM and 12 AM. \nIn the long run, 95% of such samples will lead to confidence interval limits that \nactually do contain the true population mean of the differences. See that the confi-\ndence interval includes the value of 0, so it is very possible that the mean of the dif-\nferences is equal to 0, indicating that there is no significant difference between the \n8 AM body temperatures and the 12 AM body temperatures. Keep in mind that this \nconclusion is based on the very small sample included in Table 9-1.\nEXAMPLE 3  Is the “Freshman 15” Real, or Is It a Myth?\nThe Chapter Problem states that according to the “Freshman 15,” college students \ntypically gain 15 lb (or 6.8 kg) during their freshman year. Data Set 10 “Freshman \n15” includes results from a study designed to test that common belief. Test that \nclaim using a 0.05 significance level.\nSOLUTION\nREQUIREMENT CHECK We address the three requirements. (1) The samples are de-\npendent, since each pair of weights is matched because the two values are from the \nsame person. (2) Although the sample isn’t really a simple random sample, we will \ntreat it as a simple random sample for the purposes of this example. (3) Because the \nnumber of pairs of data is n = 67, which is large, we satisfy the third requirement. \nAll requirements are satisfied. \nThe claim is that college students “typically” gain 15 lb (or 6.8 kg) during \ntheir freshman year. Using differences in the format of “April weight - September \nweight,” that claim is expressed as md = 6.8 kg, so we use the following null and \nalternative hypotheses:\nH0: md = 6.8 kg H1: md ≠6.8 kg\nUsing technology, we can easily find that the 95% confidence interval estimate of \nthe difference is 0.2 kg 6 md 6 2.1 kg. That confidence interval does not include \nthe value of 6.8 kg, so there is sufficient evidence to warrant rejection of the null \nhypothesis. That confidence interval consists of positive values only, so there does \nappear to be weight gain, but it is likely to be between 0.4 lb (or 0.2 kg) and 4.6 lb \n(or 2.1 kg), not 15 lb. The concept of the “Freshman 15” appears to greatly exaggerate \nthe typical freshman weight gain. The “Freshman 15” is therefore a myth, but we \nshould qualify that conclusion by noting that the sample of 67 subjects includes \nvolunteers from Rutgers University and it is not a simple random sample, so it is \npossible that the conclusion is not correct.\nM.\n-\nTwins in Twinsburg\nDuring the first \nweekend in \nAugust of each \nyear, Twinsburg, \nOhio, celebrates \nits annual \n“Twins Days in \nTwinsburg” festival. Thousands \nof twins from around the world \nhave attended this festival in the \npast. Scientists saw the festival \nas an opportunity to study identi-\ncal twins. Because they have the \nsame basic genetic structure, \nidentical twins are ideal for study-\ning the different effects of hered-\nity and environment on a variety \nof traits, such as male baldness, \nheart disease, and deafness—\ntraits that were recently studied \nat one Twinsburg festival. A study \nof twins showed that myopia \n(near-sightedness) is strongly af-\nfected by hereditary factors, not \nby environmental factors such as \nwatching television, surfing the \nInternet, or playing computer or \nvideo games.\nAlternative Method Used When Population Is Not Normal and n \" 30\nBootstrap The Key Elements box near the beginning of this section included the fol-\nlowing requirement: The number of pairs of sample data is large (n 7 30) or the pairs \nof values have differences that are from a population having a distribution that is ap-\nproximately normal. If that condition is violated, we can use the “Bootstrap Procedure \nfor a Confidence Interval Estimate of a Parameter” included in Section 7-4. For each \npair of data values, find the difference d, then use the list of differences and apply the \nbootstrap method described in Section 7-4. Use percentiles to find the confidence in-\nterval that can be used for hypothesis tests. See Exercise 22 “Bootstrap.”\n\n424 \nCHAPTER 9 Inferences from Two Samples\nInferences with Two Means: Dependent Samples\nAccess tech instructions, videos, and data sets at www.TriolaStats.com\nTECH CENTER \nStatistical Literacy and Critical Thinking \n1. True Statements? For the methods of this section, which of the following statements are true?\na. When testing a claim using a simple random sample of ten matched pairs of heights, hypoth-\nesis tests using the P-value method, critical value method, and confidence interval method will \nall result in the same conclusion.\nb. The methods of this section are robust against departures from normality, which means that \nthe distribution of sample differences must be very close to a normal distribution.\nc. If we want to use a confidence interval to test the claim that md 6 0 with a 0.01 significance \nlevel, the confidence interval should have a confidence level of 98%.\nd. The methods of this section can be used with annual incomes of 50 randomly selected nurses \nin North Carolina and 50 randomly selected nurses in South Carolina.\ne. If we have ten matched pairs of heights of nurses, the methods of this section require that we \nuse a sample size of n = 20.\n2. Notation Listed below are body temperatures from five different subjects measured at 8 AM \nand again at 12 AM (from Data Set 2 “Body Temperatures”). Find the values of d and sd. In \ngeneral, what does md represent?\nTemperature 1°F2 at 8 AM\n97.8\n99.0\n97.4\n97.4\n97.5\nTemperature 1°F2 at 12 AM\n98.6\n99.5\n97.5\n97.3\n97.6\n3. Units of Measure If the values listed in Exercise 2 are changed so that they are expressed \nin Celsius degrees instead of Fahrenheit degrees, how are hypothesis test results affected?\n4. Degrees of Freedom If we use the sample data in Exercise 2 for constructing a 99% con-\nfidence interval, what is the number of degrees of freedom that should be used for finding the \ncritical value of ta>2? What is the critical value ta>2?\nIn Exercises 5–16, use the listed paired sample data, and assume that the samples are simple \nrandom samples and that the differences have a distribution that is approximately normal.\n5. Is Blood Pressure the Same for Both Arms? Listed below are systolic blood pres-\nsure measurements (mm Hg) taken from the right and left arms of the same woman (based on \ndata from “Consistency of Blood Pressure Differences Between the Left and Right Arms,” by \n Eguchi et al., Archives of Internal Medicine, Vol. 167). Use a 0.01 significance level to test for a \ndifference between the measurements from the two arms. What do you conclude?\nRight arm\n102\n101\n 94\n 79\n 79\nLeft arm\n175\n169\n182\n146\n144\n6. Heights of Presidents A popular theory is that presidential candidates have an advantage \nif they are taller than their main opponents. Listed below are heights (cm) of presidents along \nwith the heights of their main opponents.\n9-3 Basic Skills and Concepts\n\n9-3 Two Dependent Samples (Matched Pairs) \n425\na. Use the sample data with a 0.05 significance level to test the claim that for the population of \nheights of presidents and their main opponents, the differences have a mean greater than 0 cm \n(so presidents tend to be taller than their opponents).\nb. Construct the confidence interval that could be used for the hypothesis test described in part (a). \nWhat feature of the confidence interval leads to the same conclusion reached in part (a)?\nHeight (cm) of President\n185\n178\n175\n183\n193\n173\nHeight (cm) of Main Opponent\n171\n180\n173\n175\n188\n178\n7. Body Temperatures Listed below are body temperatures from seven different subjects \n measured at two different times in a day (from Data Set 2 “Body Temperatures” in Appendix B).\na. Use a 0.05 significance level to test the claim that there is no difference between body tem-\nperatures measured at 8 AM and at 12 AM.\nb. Construct the confidence interval that could be used for the hypothesis test in part (a). What \nfeature of the confidence interval leads to the same conclusion reached in part (a)?\nBody Temperature 1°F2 at 8 AM\n96.6\n97.0\n97.0\n97.8\n97.0\n97.4\n96.6\nBody Temperature 1°F2 at 12 AM\n99.0\n98.4\n98.0\n98.6\n98.5\n98.9\n98.4\n8. The Spoken Word Listed below are the numbers of words spoken in a day by each member \nof six different couples.\na. Use a 0.05 significance level to test the claim that among couples, males speak fewer words \nin a day than females.\nb. Construct the confidence interval that could be used for the hypothesis test described in part (a). \nWhat feature of the confidence interval leads to the same conclusion reached in part (a)?\nMale\n15,684\n26,429\n1,411\n7,771\n18,876\n15,477\n14,069\n25,835\nFemale\n24,625\n13,397\n18,338\n17,791\n12,964\n16,937\n16,255\n18,667\n9. Heights of Mothers and Daughters Listed below are heights (in.) of mothers and their \nfirst daughters. The data are from a journal kept by Francis Galton. (See Data Set 6 “Family \nHeights.”) Use a 0.05 significance level to test the claim that there is no difference in heights \nbetween mothers and their first daughters.\nHeight of Mother\n68.0\n60\n61.0\n63.5\n69\n64.0\n69\n64\n63.5\n66\nHeight of Daughter\n68.5\n60\n63.5\n67.5\n68\n65.5\n69\n68\n64.5\n63\n10. Heights of Fathers and Sons Listed below are heights (in.) of fathers and their first \nsons. The data are from a journal kept by Francis Galton. (See Data Set 6 “Family Heights”) \nUse a 0.05 significance level to test the claim that there is no difference in heights between \nfathers and their first sons.\nHeight of Father\n72\n66\n69\n70\n70\n70\n70\n75\n68.2\n65\nHeight of Son\n73\n68\n68\n71\n70\n70\n71\n71\n70.0\n63\n11. Friday the 13th Researchers collected data on the numbers of hospital admissions result-\ning from motor vehicle crashes, and results are given below for Fridays on the 6th of a month \nand Fridays on the following 13th of the same month (based on data from “Is Friday the 13th \nBad for Your Health?” by Scanlon et al., British Medical Journal, Vol. 307, as listed in the Data \nand Story Line online resource of data sets). Construct a 95% confidence interval estimate of \nthe mean of the population of differences between hospital admissions on days that are Friday \ncontinued\n\n426 \nCHAPTER 9 Inferences from Two Samples\nthe 6th of a month and days that are Friday the 13th of a month. Use the confidence interval \nto test the claim that when the 13th day of a month falls on a Friday, the numbers of hospital \nadmissions from motor vehicle crashes are not affected.\nFriday the 6th\n 9\n 6\n11\n11\n3\n 5\nFriday the 13th\n13\n12\n14\n10\n4\n12\n12. Before, After Treatment Results Captopril is a drug designed to lower systolic blood \npressure. When subjects were treated with this drug, their systolic blood pressure readings (in \nmm Hg) were measured before and after the drug was taken. Results are given in the accom-\npanying table (based on data from “Essential Hypertension: Effect of an Oral Inhibitor of An-\ngiotensin-Converting Enzyme,” by MacGregor et al., British Medical Journal, Vol. 2). Using a \n0.01 significance level, is there sufficient evidence to support the claim that captopril is effec-\ntive in lowering systolic blood pressure?\nSubject\nA\nB\nC\nD\nE\nF\nG\nH\nI\nJ\nK\nL\nBefore\n200\n174\n198\n170\n179\n182\n193\n209\n185\n155\n169\n210\nAfter\n191\n170\n177\n167\n159\n151\n176\n183\n159\n145\n146\n177\n13. Two Heads Are Better Than One Listed below are brain volumes (cm3) of twins from \nData Set 9 “IQ and Brain Size” in Appendix B. Construct a 99% confidence interval estimate \nof the mean of the differences between brain volumes for the first-born and the second-born \ntwins. What does the confidence interval suggest?\nFirst Born\n1005\n1035\n1281\n1051\n1034\n1079\n1104\n1439\n1029\n1160\nSecond Born\n 963\n1027\n1272\n1079\n1070\n1173\n1067\n1347\n1100\n1204\n14. Hypnotism for Reducing Pain A study was conducted to investigate the effectiveness \nof hypnotism in reducing pain. Results for randomly selected subjects are given in the accom-\npanying table (based on “An Analysis of Factors That Contribute to the Efficacy of Hypnotic \nAnalgesia,” by Price and Barber, Journal of Abnormal Psychology, Vol. 96, No. 1). The values \nare before and after hypnosis; the measurements are in centimeters on a pain scale, with higher \nvalues representing greater pain. Construct a 95% confidence interval for the mean of the “be-\nfore>after” differences. Does hypnotism appear to be effective in reducing pain?\nSubject\nA\nB\nC\nD\nE\nF\nG\nH\nBefore\n6.6\n6.5\n9.0\n10.3\n11.3\n8.1\n6.3\n11.6\nAfter\n6.8\n2.4\n7.4\n 8.5\n 8.1\n6.1\n3.4\n 2.0\n15. Self-Reported and Measured Male Heights As part of the National Health and Nutri-\ntion Examination Survey, the Department of Health and Human Services obtained self-reported \nheights (in.) and measured heights (in.) for males aged 12–16. Listed below are sample results. \nConstruct a 99% confidence interval estimate of the mean difference between reported heights \nand measured heights. Interpret the resulting confidence interval, and comment on the implica-\ntions of whether the confidence interval limits contain 0.\nReported\n68\n71\n63\n70\n71\n60\n65\n64\n54\n63\n66\n72\nMeasured\n67.9\n69.9\n64.9\n68.3\n70.3\n60.6\n64.5\n67.0\n55.6\n74.2\n65.0\n70.8\n16. Historical Data Set In 1908, “Student” (William Gosset) published the article “The Prob-\nable Error of a Mean” (Biometrika, Vol. 6, No. 1). He included the data listed below for two dif-\nferent types of straw seed (regular and kiln dried) that were used on adjacent plots of land. The \nlisted values are the yields of straw in cwt (100 lb, or hundredweight) per acre, and the yields \nare paired by the plot of land that they share.\ncontinued\n\n9-3 Two Dependent Samples (Matched Pairs) \n427\na. Using a 0.05 significance level, test the claim that there is no difference between the yields \nfrom the two types of seed.\nb. Construct a 95% confidence interval estimate of the mean difference between the yields \nfrom the two types of seed.\nc. Does it appear that either type of seed is better?\nRegular\n19.25\n22.75\n23\n23\n22.5\n19.75\n24.5\n15.5\n18\n14.25\n17\nKiln dried\n25\n24\n24\n28\n22.5\n19.5\n22.25\n16\n17.25\n15.75\n17.25\nLarger Data Sets. In Exercises 17–20, use the indicated Data Sets from Appendix B.  \nThe complete data sets can be found at www.TriolaStats.com. Assume that the paired \nsample data are simple random samples and the differences have a distribution that is \n approximately normal.\n17. Body Temperatures Repeat Exercise 7 “Body Temperatures” using all of the 8 AM and \n12 AM body temperatures on Day 2 as listed in Data Set 2 “Body Temperatures” in Appendix B. \nUse a significance level of 0.05.\n18. Heights of Mothers and Daughters Repeat Exercise 9 “Heights of Mothers and Daugh-\nters” using all of the heights of mothers and daughters listed in Data Set 6 “Family Heights” in \nAppendix B.\n19. Heights of Fathers and Sons Repeat Exercise 10 “Heights of Fathers and Sons” using \nall of the heights of fathers and sons listed in Data Set 6 “Family Heights” in Appendix B.\n20. Tobacco and Alcohol in Children’s Movies Refer to Data Set 13 “Alcohol and Tobacco \nin Movies” in Appendix B and use the times (seconds) that animated Disney movies showed \nthe use of tobacco and the times that they showed the use of alcohol. Use a 0.05 significance \nlevel to test the claim that the mean of the differences is greater than 0 sec so that more time is \ndevoted to showing tobacco than alcohol.\n21. Body Temperatures Refer to Data Set 2 “Body Temperatures” in Appendix B and use \nall of the matched pairs of body temperatures at 8 AM and 12 AM on Day 1. When using a \n0.05 significance level for testing a claim of a difference between the temperatures at 8 AM \nand at 12 AM on Day 1, how are the hypothesis test results and confidence interval results af-\nfected if the temperatures are converted from degrees Fahrenheit to degrees Celsius? What is \nthe relationship between the confidence interval limits for the body temperatures in degrees \nFahrenheit and the confidence interval limits for the body temperatures in degrees Celsius?\nHint: C = 5\n91F - 322.\n22. Bootstrap\na. If paired sample data (x, y) are such that the values of x do not appear to be from a popula-\ntion with a normal distribution, and the values of y do not appear to be from a population with \na normal distribution, does it follow that the values of d will not appear to be from a population \nwith a normal distribution?\nb. For the hypothesis test described in Exercise 21, use the temperatures in degrees Fahrenheit \nand find the 95% confidence interval estimate of md based on 1000 bootstrap samples. Generate \nthe bootstrap samples using the values of d.\n9-3 Beyond the Basics\n\n428 \nCHAPTER 9 Inferences from Two Samples\nKey Concept In this section we present the F test for testing claims made about two \npopulation variances (or standard deviations). The F test (named for statistician Sir \nRonald Fisher) uses the F distribution introduced in this section. The F test requires \nthat both populations have normal distributions. Instead of being robust, this test is \nvery sensitive to departures from normal distributions, so the normality requirement is \nquite strict. Part 1 describes the F test procedure for conducting a hypothesis test, and \nPart 2 gives a brief description of two alternative methods for comparing variation in \ntwo samples.\nPART 1   F Test as a Hypothesis Test with Two \nVariances or Standard Deviations\nThe following Key Elements box includes elements of a hypothesis test of a claim \nabout two population variances or two population standard deviations. The procedure \nis based on using two sample variances, but the same procedure is used for claims \nmade about two population standard deviations.\nThe actual F test could be two-tailed, left-tailed, or right-tailed, but we can make \ncomputations much easier by stipulating that the larger of the two sample variances is \ndenoted by s2\n1. It follows that the smaller sample variance is denoted as s2\n2. This stipu-\nlation of denoting the larger sample variance by s2\n1 allows us to avoid the somewhat \nmessy problem of finding a critical value of F for the left tail.\n9-4 \nTwo Variances or Standard Deviations\nKEY ELEMENTS \nHypothesis Test with Two Variances or Standard Deviations\nObjective\nConduct a hypothesis test of a claim about two population \nvariances or standard deviations. (Any claim made about \ntwo population standard deviations can be restated with an \nequivalent claim about two population variances, so the \nsame procedure is used for two population standard devia-\ntions or two population variances.)\nNotation\ns2\n1 = larger of the two sample variances\nn1 = size of the sample with the larger variance\ns2\n1 = variance of the population from which the sample \nwith the larger variance was drawn\nThe symbols s2\n2, n2, and s2\n2 are used for the other sample \nand population.\nRequirements\n1. The two populations are independent.\n2. The two samples are simple random samples.\n3. Each of the two populations must be normally distrib-\nuted, regardless of their sample sizes. This F test is not \nrobust against departures from normality, so it performs \npoorly if one or both of the populations have a distri-\nbution that is not normal. The requirement of normal \ndistributions is quite strict for this F test.\ncontinued\n\n9-4 Two Variances or Standard Deviations \n429\nTest Statistic for Hypothesis Tests with Two Variances (with H0: S2\n1 = S2\n2)\nF = s2\n1\ns2\n2\n 1where s2\n1 is the larger of the two sample variances2\nExplore the Data! Because the F test requirement of normal distributions is quite \nstrict, be sure to examine the distributions of the two samples using histograms and \nnormal quantile plots, and confirm that there are no outliers. (See “Assessing Normal-\nity” in Section 6-5.)\nF Distribution\nFor two normally distributed populations with equal variances 1s2\n1 = s2\n22, the \nsampling distribution of the test statistic F = s2\n1>s2\n2 is the F distribution shown \nin Figure 9-4 (provided that we have not yet imposed the stipulation that the larger \nsample variance is s2\n1). If you repeat the process of selecting samples from two \nnormally distributed populations with equal variances, the distribution of the ratio \ns2\n1>s2\n2 is the F distribution.\nP-Values: P-values are automatically provided by tech-\nnology. If technology is not available, use the computed \nvalue of the F test statistic with Table A-5 to find a range \nfor the P-value.\nCritical Values: Use Table A-5 to find critical F values \nthat are determined by the following:\n1. The significance level a (Table A-5 includes critical \nvalues for a = 0.025 and a = 0.05.)\n2. Numerator degrees of freedom = n1 −1 \n (determines column of Table A-5)\n3. Denominator degrees of freedom = n2 −1 \n (determines row of Table A-5). For significance level \na = 0.05, refer to Table A-5 and use the right-tail  \narea of 0.025 or 0.05 depending on the type of test,  \nas shown here:\n • Two-tailed test: Use Table A-5 with 0.025 in the right \ntail. (The significance level of 0.05 is divided between \nthe two tails, so the area in the right tail is 0.025.)\n • One-tailed test: Use Table A-5 with a = 0.05 in the \nright tail.\nFind the critical F value for the right tail: Because we are stip-\nulating that the larger sample variance is s2\n1, all one-tailed tests \nwill be right-tailed and all two-tailed tests will require that we \nfind only the critical value located to the right. (We have no \nneed to find the critical value at the left tail, which is not very \ndifficult. See Exercise 19 “Finding Lower Critical F Values.”)\n0\nNot symmetric\n(skewed to the right)\nF\nNonnegative \nvalues only\na\nValue of F 5\ns1\n2\n2\ns2\nFIGURE 9-4 F Distribution\n\n430 \nCHAPTER 9 Inferences from Two Samples\nThere is a different F distribution for each different pair of degrees of freedom for the \nnumerator and denominator.\nSee Figure 9-4 and note these properties of the F distribution:\n \n■The F distribution is not symmetric.\n \n■Values of the F distribution cannot be negative.\n \n■The exact shape of the F distribution depends on the two different degrees of \nfreedom.\nInterpreting the Value of the F Test Statistic\nIf the two populations have equal variances, the ratio s2\n1>s2\n2 will tend to be close to 1. \nBecause we are stipulating that s2\n1 is the larger sample variance, the ratio s2\n1>s2\n2 will be \na large number whenever s2\n1 and s2\n2 are far apart in value. Consequently, a value of F \nnear 1 will be evidence in favor of s2\n1 = s2\n2, but a large value of F will be evidence \nagainst s2\n1 = s2\n2.\nLarge values of F are evidence against S2\n1 = S2\n2.\nEXAMPLE 1  Effect of Birth Weight on IQ Score\nWhen investigating a relationship between birth weight and IQ, researchers found \nthat 258 subjects with extremely low birth weights (less than 1000 g) had Wechsler \nIQ scores at age 8 with a mean of 95.5 and a standard deviation of 16.0. For 220 \nsubjects with normal birth weights, the mean IQ score at age 8 is 104.9 and the \nstandard deviation is 14.1. (Based on data from “Neurobehavioral Outcomes of \nSchool-Age Children Born Extremely Low Birth Weight or Very Preterm in the \n1990s,” by Anderson et al., Journal of the American Medical Association, Vol. 289, \nNo. 24.) Using a 0.05 significance level, test the claim that babies with extremely \nlow birth weights and babies with normal birth weights have different amounts of \nvariation.\nSOLUTION\nREQUIREMENT CHECK (1) The two populations are independent of each other. The \ntwo samples are not matched in any way. (2) Given the design for the study, we \n assume that the two samples can be treated as simple random samples. (3) Based on \nan analysis of the original data, assume that the two samples are from populations \nhaving normal distributions. \nInstead of using the sample standard deviations to test the claim of equal popu-\nlation standard deviations, we use the sample variances to test the claim of equal \npopulation variances, but we can state the hypotheses and conclusions in terms of \nstandard deviations. Because we stipulate in this section that the larger variance is \ndenoted by s2\n1, we let s2\n1 = 16.02 and s2\n2 = 14.12.\nStep 1: The claim of different amounts of variation is equivalent to a claim of dif-\nferent standard deviations, which is expressed symbolically as s1 ≠s2.\nStep 2: If the original claim is false, then s1 = s2.\nStep 3: Because the null hypothesis is the statement of equality and because the al-\nternative hypothesis cannot contain equality, we have\nH0\n : s1 = s2  H1\n : s1 ≠s2 1original claim2\n\n9-4 Two Variances or Standard Deviations \n431\nStep 4: The significance level is a = 0.05.\nStep 5: Because this test involves two population variances, we use the F \n distribution.\nStep 6: The test statistic is\nF = s2\n1\ns2\n2\n= 16.02\n14.12 = 1.2877\nP-Value Method\nTechnology Using technology, we can find that the P-value is 0.0537, so we fail to \nreject H0. (See the accompanying Statdisk display.)\nTable The format and limitations of Table A-5 make the P-value method a bit tricky \nwithout technology, but here goes. For a two-tailed test with significance level 0.05, \nthere is an area of 0.025 in the right tail, so we use the two pages for the F distribu-\ntion (Table A-5) with “0.025 in the right tail.” With numerator degrees of freedom =\nn1 - 1 = 257 and denominator degrees of freedom = n2 - 1 = 219, Table A-5 \ntells us that the critical value of F is somewhere between 1.0000 and 1.4327. The test \nstatistic of F = 1.2877 is between 1.000 and 1.4327, so Table A-5 is no help for this \nexample.\nCritical Value Method Using technology, we find that the critical values are 0.7755 \nand 1.2928. (See the accompanying Statdisk display.) The test statistic F = 1.2877 \nfalls between those two critical values, so the test statistic does not fall in the critical \nregion and we fail to reject H0.\nINTERPRETATION\nThere is not sufficient evidence to support the claim that the two populations have \ndifferent amounts of variation.\nStatdisk\nCaution: Part 2 of Section 9-2 includes methods for testing claims about two popula-\ntion means, and one of those methods has a requirement that s1 = s2. Using the F \ntest is not recommended as a way to decide whether this requirement is met. For Sec-\ntion 9-2, using the F test runs the risk of using differences that are too small to have an \neffect on the t test for two independent samples. That approach is often described as \nbeing analogous to sending someone out to sea in a rowboat (the preliminary F test) to \ndetermine whether the sea is safe for an ocean liner (the t test).\nPART 2\nAlternative Methods\nPart 1 of this section presents the F test for testing claims made about the standard \ndeviations (or variances) of two independent populations. Because that test is so sen-\nsitive to departures from normality, we now briefly describe two alternative methods \nthat are not so sensitive to departures from normality.\nCount Five\nThe count five method is a relatively simple alternative to the F test, and it does not \nrequire normally distributed populations. (See “A Quick, Compact, Two-Sample \nDispersion Test: Count Five,” by McGrath and Yeh, American Statistician, Vol. 59, \n\n432 \nCHAPTER 9 Inferences from Two Samples\nNo. 1.) If the two sample sizes are equal, and if one sample has at least five of the larg-\nest mean absolute deviations (MAD), then we conclude that its population has a larger \nvariance. See Exercise 17 “Count Five Test” for the specific procedure.\nLevene-Brown-Forsythe Test\nThe Levene-Brown-Forsythe test (or modified Levene’s test) is another alternative \nto the F test, and it is much more robust against departures from normality. This \ntest begins with a transformation of each set of sample values. Within the first sam-\nple, replace each x value with \u001ax - median\u001a, and apply the same transformation \nto the second sample. Using the transformed values, conduct a t test of equality of \nmeans for independent samples, as described in Part 1 of Section 9-2. Because the \ntransformed values are now deviations, the t test for equality of means is actually \na test comparing variation in the two samples. See Exercise 18 “Levene-Brown-\nForsythe Test.”\nThere are other alternatives to the F test, as well as adjustments that improve the \nperformance of the F test. See “Fixing the F Test for Equal Variances,” by Shoemaker, \nAmerican Statistician, Vol. 57, No. 2.\nInferences from Two Standard Deviations\nAccess tech instructions, videos, and data sets at www.TriolaStats.com\nTECH CENTER \n9-4 Basic Skills and Concepts\nStatistical Literacy and Critical Thinking \n1. F Test Statistic\na. If s2\n1 represents the larger of two sample variances, can the F test statistic ever be less than 1?\nb. Can the F test statistic ever be a negative number?\nc. If testing the claim that s2\n1 ≠s2\n2, what do we know about the two samples if the test statis-\ntic F is very close to 1.\nd. Is the F distribution symmetric, skewed left, or skewed right?\n2. F Test If using the sample data in Data Set 1 “Body Data” in Appendix B for a test of \nthe claim that heights of men and heights of women have different variances, we find that \ns = 7.48296 cm for women and s = 7.10098 cm for men.\na. Find the values of s2\n1 and s2\n2 and express them with appropriate units of measure.\nb. Identify the null and alternative hypotheses.\nc. Find the value of the F test statistic and round it to four decimal places.\nd. The P-value for this test is 0.5225. What do you conclude about the stated claim?\n3. Testing Normality For the hypothesis test described in Exercise 2, the sample sizes are \nn1 = 147 and n2 = 153. When using the F test with these data, is it correct to reason that there \nis no need to check for normality because n1 7 30 and n2 7 30?\n4. Robust What does it mean when we say that the F test described in this section is not robust \nagainst departures from normality?\n\n9-4 Two Variances or Standard Deviations \n433\nIn Exercises 5–16, test the given claim.\n5. Testing Effects of Alcohol Researchers conducted an experiment to test the effects of \nalcohol. Errors were recorded in a test of visual and motor skills for a treatment group of 22 \npeople who drank ethanol and another group of 22 people given a placebo. The errors for the \ntreatment group have a standard deviation of 2.20, and the errors for the placebo group have a \nstandard deviation of 0.72 (based on data from “Effects of Alcohol Intoxication on Risk Taking, \nStrategy, and Error Rate in Visuomotor Performance,” by Streufert et al., Journal of  Applied \nPsychology, Vol. 77, No. 4). Use a 0.05 significance level to test the claim that the treatment \ngroup has errors that vary significantly more than the errors of the placebo group.\n6. Second-Hand Smoke Data Set 14 “Passive and Active Smoke” includes cotinine lev-\nels measured in a group of smokers (n = 40, x = 172.48 ng>mL, s = 119.50 ng>mL) \nand a group of nonsmokers not exposed to tobacco smoke (n = 40, x = 16.35 ng>mL, \ns = 62.53 ng>mL). Cotinine is a metabolite of nicotine, meaning that when nicotine is ab-\nsorbed by the body, cotinine is produced.\na. Use a 0.05 significance level to test the claim that the variation of cotinine in smokers is \ngreater than the variation of cotinine in nonsmokers not exposed to tobacco smoke.\nb. The 40 cotinine measurements from the nonsmoking group consists of these values (all in \nng>mL): 1, 1, 90, 244, 309, and 35 other values that are all 0. Does this sample appear to be \nfrom a normally distributed population? If not, how are the results from part (a) affected?\n7. Baseline Characteristics In journal articles about clinical experiments, it is common to \ninclude baseline characteristics of the different treatment groups so that they can be compared. \nIn an article about the effects of different diets, a table of baseline characteristics showed that \n40 subjects treated with the Atkins diet had a mean age of 47 years with a standard deviation \nof 12 years. Also, 40 subjects treated with the Zone diet had a mean age of 51 years with a \nstandard deviation of 9 years. Use a 0.05 significance level to test the claim that subjects from \nboth treatment groups have ages with the same amount of variation. How are comparisons of \ntreatments affected if the treatment groups have different characteristics?\n8. IQ and Lead Exposure Data Set 8 “IQ and Lead” in Appendix B lists full IQ scores for a \nrandom sample of subjects with low lead levels in their blood and another random sample of \nsubjects with high lead levels in their blood. The statistics are summarized below. Use a 0.05 \nsignificance level to test the claim that IQ scores of people with low lead levels vary more than \nIQ scores of people with high lead levels.\n Low Lead Level:  n = 78, x = 92.88462, s = 15.34451\n High Lead Level:  n = 21, x = 86.90476, s = 8.988352\n9. Magnet Treatment of Pain Researchers conducted a study to determine whether magnets are \neffective in treating back pain, with results given below (based on data from “Bipolar  Permanent \nMagnets for the Treatment of Chronic Lower Back Pain: A Pilot Study,” by Collacott, Zimmerman, \nWhite, and Rindone, Journal of the American Medical Association, Vol. 283, No. 10). The values \nrepresent measurements of pain using the visual analog scale. Use a 0.05 significance level to test the \nclaim that those given a sham treatment (similar to a placebo) have pain reductions that vary more \nthan the pain reductions for those treated with magnets.\n Reduction in Pain Level After Sham Treatment:  n = 20, x = 0.44, s = 1.4\n Reduction in Pain Level After Magnet Treatment:  n = 20, x = 0.49, s = 0.96\n10. Humidity in Treating Croup In a randomized controlled trial conducted with children \nsuffering from viral croup, 46 children were treated with low humidity while 46 other children \nwere treated with high humidity. Researchers used the Westley Croup Score to assess the re-\nsults after one hour. The low-humidity group had a mean score of 0.98 with a standard devia-\ntion of 1.22, while the high-humidity group had a mean score of 1.09 with a standard deviation \nof 1.11 (based on data from “Controlled Delivery of High vs Low Humidity vs Mist Therapy \ncontinued\n\n434 \nCHAPTER 9 Inferences from Two Samples\nfor Croup Emergency Departments,” by Scolnik et al., Journal of the American Medical Asso-\nciation, Vol. 295, No. 11). Use a 0.05 significance level to test the claim that the two groups are \nfrom populations with the same standard deviation.\n11. Cigarette Filters and Nicotine Listed below are statistics from measured nicotine con-\ntents of randomly selected filtered and non-filtered king-size cigarettes (based on data from \nthe Federal Trade Commission). Use a 0.05 significance level to test the claim that king-size \ncigarettes with filters have amounts of nicotine that vary more than the amounts of nicotine in \nnon-filtered king-size cigarettes.\n Filtered Kings \n n = 21, x = 0.94 mg, s = 0.31 mg\n Non@filtered Kings  n = 8, x = 1.65 mg, s = 0.16 mg\n12. Zinc Treatment Use a 0.05 significance level to test the claim that weights of babies born \nto mothers given placebos vary more than weights of babies born to mothers given zinc supple-\nments. Use the following statistics (based on data from “The Effect of Zinc Supplementation \non Pregnancy Outcome,” by Goldenberg et al., Journal of the American Medical Association, \nVol. 274, No. 6).\n Placebo group: \n n = 16, x = 3088 g, s = 728 g\n Treatment group:  n = 16, x = 3214 g, s = 669 g\n13. Body Temperatures of Men and Women Listed below are the body temperatures (°F) mea-\nsured in males at 8 AM on Day 2 as listed in Data Set 2 “Body Temperatures” in  Appendix B. \nFor the body temperatures of females measured at the same time, we get n = 59, x = 97.45°F,\nand s = 0.66°F. Use a 0.05 significance level to test the claim that men have body tempera-\ntures that vary more than the body temperatures of women.\n97.0 98.0 96.4 98.2 98.8 98.6 97.8 98.7 97.8 96.4 96.9\n14. Radiation in Baby Teeth Listed below are amounts of strontium-90 (in millibecquerels, \nor mBq, per gram of calcium) in a simple random sample of baby teeth obtained from Pennsyl-\nvania residents and New York residents born after 1979 (based on data from “An Unexpected \nRise in Strontium-90 in U.S. Deciduous Teeth in the 1990s,” by Mangano et al., Science of the \nTotal Environment, Vol. 317). Use a 0.05 significance level to test the claim that amounts of \nstrontium-90 from Pennsylvania residents vary more than amounts from New York residents.\nPennsylvania:\n155\n142\n149\n130\n151\n163\n151\n142\n156\n133\n138\n161\nNew York:\n133\n140\n142\n131\n134\n129\n128\n140\n140\n140\n137\n143\n15. Longevity Listed below are the numbers of years that popes and British monarchs (since \n1690) lived after their election or coronation. Treat the values as simple random samples from \na larger population. Use a 0.05 significance level to test the claim that both populations of lon-\ngevity times have the same variation.\nPopes:\n2\n9\n21\n3\n6\n10\n18\n11\n6\n25\n23\n6\n2\n15\n32\n25\n11\n8\n17\n19\n5\n15\n0\n26\nKings and Queens:\n17\n6\n13\n12\n13\n33\n59\n10\n7\n63\n9\n25\n36\n15\n16. Blanking Out on Tests Many students have had the unpleasant experience of panicking \non a test because the first question was exceptionally difficult. The arrangement of test items \nwas studied for its effect on anxiety. The following scores are measures of “debilitating test \nanxiety,” which most of us call panic or blanking out (based on data from “Item Arrangement, \nCognitive Entry Characteristics, Sex and Test Anxiety as Predictors of Achievement in Exami-\nnation Performance,” by Klimko, Journal of Experimental Education, Vol. 52, No. 4.) Using a \n0.05 significance level, test the claim that the two populations of scores have different amounts \nof variation. The data are listed on the top of the next page.\n\nQuestions Arranged from Easy to Difficult\nQuestions Arranged from Difficult to Easy\n24.64\n39.29\n16.32\n32.83\n28.02\n33.62\n34.02\n26.63\n30.26\n33.31\n20.60\n21.13\n26.69\n28.90\n35.91\n26.68\n29.49\n35.32\n26.43\n24.23\n 7.10\n32.86\n21.06\n27.24\n32.34\n29.34\n33.53\n28.89\n28.71\n31.73\n30.02\n21.96\n27.62\n42.91\n30.20\n32.54\n25.49\n38.81\n27.85\n30.29\n30.72\n17. Count Five Test for Comparing Variation in Two Populations Repeat Exercise 16 \n“Blanking Out on Tests,” but instead of using the F test, use the following procedure for the \n“count five” test of equal variations (which is not as complicated as it might appear).\na. For each value x in the first sample, find the absolute deviation \u001ax - x \u001a , then sort the abso-\nlute deviation values. Do the same for the second sample.\nb. Let c1 be the count of the number of absolute deviation values in the first sample that are \ngreater than the largest absolute deviation value in the second sample. Also, let c2 be the count \nof the number of absolute deviation values in the second sample that are greater than the largest \nabsolute deviation value in the first sample. (One of these counts will always be zero.)\nc. If the sample sizes are equal 1n1 = n22, use a critical value of 5. If n1 ≠n2, calculate the \ncritical value shown below.\n log1a>22\n log  a\nn1\nn1 + n2\nb\nd. If c1 Ú critical value, then conclude that s2\n1 7 s2\n2. If c2 Ú critical value, then conclude \nthat s2\n2 7 s2\n1. Otherwise, fail to reject the null hypothesis of s2\n1 = s2\n2.\n18. Levene-Brown-Forsythe Test Repeat Exercise 16 “Blanking Out on Tests” using the \nLevene-Brown-Forsythe test.\n19. Finding Lower Critical F Values For hypothesis tests that are two-tailed, the methods of \nPart 1 require that we need to find only the upper critical value. Let’s denote the upper critical \nvalue by FR, where the subscript indicates the critical value for the right tail. The lower critical \nvalue FL (for the left tail) can be found as follows: (1) Interchange the degrees of freedom used \nfor finding FR; (2) then, using the degrees of freedom found in Step 1, find the F value from \nTable A-5; (3) take the reciprocal of the F value found in Step 2, and the result is FL. Find the \ncritical values FL and FR for Exercise 16 “Blanking Out on Tests.”\n9-4 Beyond the Basics\nIn Exercises 1–5, use the following survey results: Randomly selected subjects were asked if \nthey were aware that the earth has lost half of its wildlife population during the past  \n50 years. Among 1121 women, 23% said that they were aware. Among 1084 men, 26% said \nthat they were aware (based on data from a Harris poll).\n1. Biodiversity Identify the null and alternative hypotheses resulting from the claim that for \nthe people who were aware of the statement, the proportion of women is equal to the propor-\ntion of men.\nChapter Quick Quiz\nCHAPTER 9 Chapter Quick Quiz \n435\n\n436 \nCHAPTER 9 Inferences from Two Samples\n2. Biodiversity Find the values of x1 (the number of women who were aware of the statement), \nx2 (the number of men who were aware of the statement), pn1, pn2, and the pooled proportion p\nobtained when testing the claim given in Exercise 1.\n3. Biodiversity When testing the claim that p1 = p2, a test statistic of z = -1.64 is obtained. \nFind the P-value for the hypothesis test.\n4. Biodiversity When using the given sample data to construct a 95% confidence interval esti-\nmate of the difference between the two population proportions, the result of (-0.0659, 0.00591) \nis obtained from technology.\na. Express that confidence interval in a format that uses the symbol 6.\nb. What feature of the confidence interval is a basis for deciding whether there is a significant \ndifference between the proportion of women aware of the statement and the proportion of men \nwho are aware?\n5.  Biodiversity Assume that a P-value of 0.1 is obtained when testing the claim given in \n Exercise 1 “Biodiversity.” What should be concluded about the null hypothesis? What should \nbe the final conclusion?\n6. True? Determine whether the following statement is true: When random samples of 50 male \nnurses and 50 female nurses are obtained and we want to test the claim that male nurses and \nfemale nurses have different mean annual incomes, there is no need to confirm that the samples \nare from populations with normal distributions.\n7.  True? When we collect random samples to test the claim that the proportion of female \nsurgeons in the United States is equal to the proportion of female surgeons outside the United \nStates, there is a requirement that np Ú 30 and nq Ú 30.\n8. Dependent or Independent? Listed below are measures of visual acuity of the right and \nleft eyes of five subjects (from Data Set 5 “Vision” in Appendix B). Are the data dependent or \nindependent?\nRight eye\n60\n25\n20\n50\n30\nLeft eye\n80\n20\n25\n50\n25\n9. Hypotheses Identify the null and alternative hypotheses for using the sample data from \n Exercise 8 in testing the claim that for differences between right-eye measurements and left-\neye measurements, those differences are from a population with a mean equal to 0.\n10. Test Statistics Identify the test statistics that should be used for testing the following \nclaims.\na. The mean of the differences between platelet counts of husbands and platelet counts of their \nwives is equal to 0.\nb. The mean platelet count of adult Californians is equal to the mean platelet count of adult Texans.\nc. The proportion of men with diabetes is equal to the proportion of women with diabetes.\nd. The variation among pulse rates of women is equal to the variation among pulse rates of men.\n1. Blinding Among 13,200 submitted abstracts that were blindly evaluated (with authors and \ninstitutions not identified), 26.7% were accepted for publication. Among 13,433 abstracts that \nwere not blindly evaluated, 29.0% were accepted (based on data from “Effect of Blinded Peer \nReview on Abstract Acceptance,” by Ross et al., Journal of the American Medical Association, \nVol. 295, No. 14). Use a 0.01 significance level to test the claim that the acceptance rate is the \nsame with or without blinding. How might the results be explained?\nReview Exercises\n\n2. Blinding Construct the confidence interval that could be used to test the claim in Exercise 1. \nWhat feature of the confidence interval leads to the same conclusion from Exercise 1?\n3. Heights Listed below are heights (cm) randomly selected from the sample of women and \nheights (cm) randomly selected from the sample of men (from Data Set 1 “Body Data” in \n Appendix B). Use a 95% confidence level to estimate the magnitude of the difference between \nthe mean height of women and the mean height of men.\nWomen:\n160.3\n167.7\n166.9\n153.3\n160.0\n177.3\n169.1\n134.5\n163.3\n171.1\nMen:\n190.3\n169.8\n179.8\n179.8\n177.0\n178.5\n173.5\n178.7\n179.0\n181.3\n4. Heights Use a 0.01 significance level with the sample data from Exercise 3 to test the claim \nthat women have heights with a mean that is less than the mean height of men.\n5. Effects of Physical Training A study was conducted to investigate effects of physical \ntraining. Sample data from ten subjects are listed below, with all weights given in kilograms. \n(See “Effect of Endurance Training on Possible Determinants of VO2 During Heavy Exercise,” \nby Casaburi et al., Journal of Applied Physiology, Vol. 62, No. 1.)\na. Is there sufficient evidence to conclude that there is a difference between the pre-training and \npost-training weights? What do you conclude about the effect of training on weight?\nb. Construct a 95% confidence interval for the mean of the differences between pre-training \nand post-training weights.\nPre-training:\n99\n57\n62\n69\n74\n77\n59\n92\n70\n85\nPost-training:\n94\n57\n62\n69\n66\n76\n58\n88\n70\n84\n6. Variation of Heights Use the sample data given in Exercise 3 “Heights” and test the claim \nthat women and men have heights with the same variation. Use a 0.05 significance level.\nCHAPTER 9 Cumulative Review Exercises \n437\nFamily Heights. In Exercises 1–5, use the following heights (in.) of fathers, mothers, and \ntheir adult sons (from Data Set 6 “Family Heights”). The data are matched so that each col-\numn consists of heights from the same family.\nFather\n68.0\n68.0\n65.5\n66.0\n67.5\n70.0\n68.0\n71.0\nMother\n64.0\n60.0\n63.0\n59.0\n62.0\n69.0\n65.5\n66.0\nSon\n71.0\n64.0\n71.0\n68.0\n70.0\n71.0\n71.7\n71.0\n1. a. Are the three samples independent or dependent? Why?\nb. Find the mean, median, range, standard deviation, and variance of the heights of the sons. \nExpress results with the appropriate units.\nc. What is the level of measurement of the sample data (nominal, ordinal, interval, ratio)?\nd. Are the original unrounded heights discrete data or continuous data?\n2. Scatterplot Construct a scatterplot of the paired father>son heights. What does the graph \nsuggest?\n3. Confidence Interval Construct a 95% confidence interval estimate of the mean height of \nsons. Write a brief statement that interprets the confidence interval.\n4. Hypothesis Test Use a 0.05 significance level to test the claim that differences between \nheights of fathers and their sons have a mean of 0 in.\nCumulative Review Exercises\n\n438 \nCHAPTER 9 Inferences from Two Samples\n5.  Assessing Normality Refer to the accompanying normal quantile plot to determine \nwhether the sample of heights of fathers appears to be from a normally distributed population.\n6. Braking Reaction Times: Histogram Listed below are sorted braking reaction times \n(in 1>10,000 sec) for male and female subjects (based on data from the RT-2S Brake Reac-\ntion Time Tester). Construct a histogram for the reaction times of males. Use a class width \nof 8 and use 28 as the lower limit of the first class. Instead of using class boundaries for the \nhorizontal axis, use class midpoint values. Does it appear that the data are from a population \nwith a normal distribution?\nMale\n28\n30\n31\n34\n34\n36\n36\n36\n36\n38\n39\n40\n40\n40\n40\n41\n41\n41\n42\n42\n44\n46\n47\n48\n48\n49\n51\n53\n54\n54\n56\n57\n60\n61\n61\n63\nFemale\n22\n24\n34\n36\n36\n37\n39\n41\n41\n43\n43\n45\n45\n47\n53\n54\n54\n55\n56\n57\n57\n57\n58\n61\n62\n63\n66\n67\n68\n71\n72\n76\n77\n78\n79\n80\n7. Braking Reaction Times: Normal? The accompanying normal quantile plot is obtained \nby using the braking reaction times of females listed in Exercise 6. Interpret this graph.\n8. Braking Reaction Times: Boxplots Use the same data from Exercise 6 and use the same \nscale to construct a boxplot of the braking reaction times of males and another boxplot for the \nbraking reaction times of females. What do the boxplots suggest?\n9. Braking Reaction Times: Hypothesis Test Use the sample data from Exercise 6 with \na 0.01 significance level to test the claim that males and females have the same mean braking \nreaction time.\n10. Braking Reaction Times: Confidence Intervals\na. Construct a 99% confidence interval estimate of the mean braking reaction time of males, \nconstruct a 99% confidence interval estimate of the mean braking reaction time of females, and \nthen compare the results.\nb. Construct a 99% confidence interval estimate of the difference between the mean braking \nreaction time of males and the mean braking reaction time of females.\nc. Which is better for comparing the mean reaction times of males and females: the results \nfrom part (a) or the results from part (b)?\n\nMany technologies are capable of generating normally distributed data drawn from a popula-\ntion with a specified mean and standard deviation. In Example 3 of Section 6-1, we noted that \nbone density test scores are measured as z scores having a normal distribution with a mean of \n0 and a standard deviation of 1. Generate two sets of sample data that represent simulated bone \ndensity scores, as shown below.\n• Treatment Group: Generate 10 sample values from a normally distributed population of \nbone density scores with mean 0 and standard deviation 1.\n• Placebo Group: Generate 15 sample values from a normally distributed population of bone \ndensity scores with mean 0 and standard deviation 1.\nStatdisk: \nSelect Data, then Normal Generator.\nMinitab: \nSelect Calc, Random Data, Normal.\nExcel: \nSelect Data Analysis, Random Number Generation.\nTI-83 , 84 Plus: \n Press MATH, select PROB, then use randNorm function with \nthe format of (x, s, n).\n \nStatCrunch: \nClick on Data, select Simulate, select Normal.\nBecause each of the two samples consists of random selections from a normally distributed \npopulation with a mean of 0 and a standard deviation of 1, the data are generated so that both \ndata sets really come from the same population, so there should be no difference between the \ntwo sample means.\na. After generating the two data sets, use a 0.10 significance level to test the claim that the two \nsamples come from populations with the same mean.\nb. If this experiment is repeated many times, what is the expected percentage of trials leading \nto the conclusion that the two population means are different? How does this relate to a type I \nerror?\nc. If your generated data lead to the conclusion that the two population means are different, \nwould this conclusion be correct or incorrect in reality? How do you know?\nd. If part (a) is repeated 20 times, what is the probability that none of the hypothesis tests leads \nto rejection of the null hypothesis?\ne. Repeat part (a) 20 times. How often was the null hypothesis of equal means rejected? Is this \nthe result you expected?\nTechnology Project\nCHAPTER 9 Technology Project \n439\n\n440 \nCHAPTER 9 Inferences from Two Samples\nFROM DATA TO DECISION\nCritical Thinking: Ages of workers killed  \nin the Triangle Factory fire\nListed below are the ages (years) of the 146 employees who \nperished in the Triangle Factory fire that occurred on March \n25, 1911, in Manhattan (based on data from the Kheel Cen-\nter and the New York Times). One factor contributing to the \nlarge number of deaths is that almost all exits were locked so \nthat employees could be checked for theft when they finished \nwork at the end of the day. That fire revealed grossly poor \nand unsafe working conditions that led to changes in building \ncodes and labor laws.\nAnalyzing the Results\n1. First explore the combined male and female ages using \nsuitable statistics and graphs. What is the mean age? What \nare the minimum and maximum ages? What is the standard \ndeviation of the ages? Are there any outliers? Describe the \ndistribution of the ages.\n2. Examination of the two lists shows that relatively few men \nperished in the fire. Treat the ages as sample data and deter-\nmine whether there is sufficient evidence to support the claim \nthat among the workers who perish in such circumstances, \nthe majority are women.\n3. Construct a 95% confidence interval estimate of the mean \nage of males and construct another 95% confidence interval \nestimate of the mean age of females. Compare the results.\n4. Treat the ages as sample data and determine whether there \nis sufficient evidence to support the claim that female work-\ners have a mean age that is less than that of male workers.\n5. Treat the ages as sample data and determine whether there \nis sufficient evidence to support the claim that ages of males \nand females have different standard deviations.\n6. Based on the preceding results, identify any particularly \nnotable features of the data.\nMales\n38\n19\n30\n24\n23\n23\n19\n18\n19\n33\n17\n22\n33\n25\n20\n23\n22\nFemales\n24\n16\n25\n31\n22\n18\n19\n22\n16\n23\n17\n15\n21\n18\n17\n17\n17\n31\n20\n36\n18\n25\n30\n16\n25\n25\n21\n19\n17\n18\n20\n18\n26\n26\n16\n18\n18\n17\n22\n17\n20\n22\n18\n20\n16\n25\n18\n40\n21\n18\n19\n19\n18\n18\n19\n16\n19\n16\n16\n21\n33\n21\n14\n22\n19\n19\n23\n19\n18\n21\n39\n20\n14\n27\n22\n15\n19\n16\n16\n19\n18\n21\n18\n19\n19\n20\n18\n43\n16\n20\n18\n30\n21\n22\n18\n21\n35\n22\n21\n22\n21\n22\n17\n24\n25\n20\n18\n32\n20\n21\n19\n24\n17\n18\n30\n18\n16\n22\n22\n17\n22\n20\n15\n20\n17\n21\n21\n18\n17\n\nCooperative Group Activities\n1. Out-of-class activity Collect sample data and test the claim that people who exercise tend \nto have pulse rates that are lower than those who do not exercise.\n2. Out-of-class activity Collect sample data and test the claim that the proportion of female \nstudents who smoke is equal to the proportion of male students who smoke.\n3. Out-of-class activity Measure and record the height of the man and woman from each of \nseveral different couples. Estimate the mean of the differences between the heights of men and \nthe heights of their partners. Compare the result to the difference between the mean height of \nmen and the mean height of women included in Data Set 1 “Body Data” in Appendix B. Do the \nresults suggest that height is a factor when people select partners?\n4. In-class activity Divide into groups according to gender, with about 10 or 12 students in \neach group. Each group member should record his or her pulse rate by counting the number of \nheartbeats in 1 minute, and then the group statistics 1n, x, s2should be calculated. The groups \nshould test the null hypothesis of no difference between their mean pulse rate and the mean of \nthe pulse rates for the population from which subjects of the same gender were selected for \nData Set 1 “Body Data” in Appendix B.\n5. Out-of-class activity Randomly select a sample of male students and a sample of female \nstudents and ask each selected person a yes>no question, such as whether the federal govern-\nment should fund stem cell research. Record the response, the gender of the respondent, and \nthe gender of the person asking the question. Use a formal hypothesis test to determine whether \nthere is a difference between the proportions of yes responses from males and females. Also, \ndetermine whether the responses appear to be influenced by the gender of the interviewer.\n6. Out-of-class activity Construct a short survey of just a few questions, including a ques-\ntion asking the subject to report his or her height. After the subject has completed the survey, \nmeasure the subject’s height (without shoes) using an accurate measuring system. Record the \ngender, reported height, and measured height of each subject. Do male subjects appear to exag-\ngerate their heights? Do female subjects appear to exaggerate their heights? Do the errors for \nmales appear to have the same mean as the errors for females?\n7. In-class activity Without using any measuring device, ask each student to draw a line be-\nlieved to be 3 in. long and another line believed to be 3 cm long. Then use rulers to measure and \nrecord the lengths of the lines drawn. Record the errors along with the genders of the students \nmaking the estimates. Test the claim that when estimating the length of a 3-in. line, the mean \nerror from males is equal to the mean error from females. Also, do the results show that we \nhave a better understanding of the British system of measurement (inches) than the SI system \n(centimeters)?\n8. Out-of-class activity Obtain sample data and test the claim that husbands are older than \ntheir wives.\n9. Out-of-class activity Survey married couples and record the number of credit cards each \nperson has. Analyze the paired data to determine whether husbands have more credit cards, \nwives have more credit cards, or they both have about the same number of credit cards. Try to \nidentify reasons for any discrepancy.\n10. Out-of-class activity Obtain sample data to test the claim that in the college library, sci-\nence books have a mean age that is less than the mean age of novels.\n11. Out-of-class activity Conduct experiments and collect data to test the claim that there are \nno differences in taste between ordinary tap water and different brands of bottled water.\nCHAPTER 9 Cooperative Group Activities \n441\n\n442\nCorrelation\nRegression\nPrediction Intervals and \nVariation\nMultiple Regression\nDummy Variables and \nLogistic Regression\n10-1\n10-2\n10-3\n10-4\n10-5\nSave Money and Time (or Not?) with a Simpler  \nHealth Test?\nCHAPTER \nPROBLEM\nCorrelation and \nRegression\nWhen assessing the health of a person, some body measure-\nments are relatively easy, quick, and inexpensive, while others \nare more expensive and time consuming. Measuring pulse rate \ntakes only a minute and requires only a clock or watch, but \nmeasuring a person’s white blood cell count requires drawing \na blood sample that must be sent to a laboratory. Monitoring \nthe white blood cell count is important because those white \nblood cells help fight infections. If there is a strong correlation \nbetween pulse rate and white blood cell count, we could use \nthe pulse rate to predict the white blood cell count and thereby \nsave money and time. In this chapter, we will investigate the \ncorrelation between the pulse rate and white blood cell count \nof females. We will begin with the data in Table 10-1, which \nuses only five of the pairs of data available in Data Set 1  \n10 \n\n“Body Data” in Appendix B. We consider this smaller data set \nfor the purposes of illustrating the methods of this chapter. \nPulse rates are measured in beats per minute, and the white \nblood cell count gives the number of white blood cells  \nexpressed in units of 1000 cells>mL.\nUsing the methods of this chapter, we can address questions \nsuch as these:\n• Is there a correlation between pulse rates of females and \ntheir white blood cell counts?\n• If there is a correlation between pulse rates of females and \ntheir white blood cell counts, can we describe it with an equa-\ntion so that we can predict white blood cell count given a \npulse rate? If so, how accurate is the prediction likely to be?\nA major focus of this chapter is to analyze paired sample data. In Section 9-3 we \nconsidered sample data consisting of matched pairs, but the goal in Section 9-3 was \nto make inferences about the mean of  the differences from the matched pairs. In this \nchapter we again consider paired sample data, but the objective is fundamentally dif-\nferent from that of Section 9-3. In this chapter we present methods for determining \nwhether there is a correlation, or association, between two variables. For linear correla-\ntions, we can identify an equation of a straight line that best fits the data, and we can \nuse that equation to predict the value of one variable given the value of the other vari-\nable. Here are the chapter objectives:\nCorrelation\n• Use paired data to find the value of the linear correlation coefficient r.\n• Determine whether there is sufficient evidence to support a conclusion that there is \na linear correlation between two variables.\nRegression\n• Use paired sample data to find the equation of the regression line.\n• Find the best predicted value of a variable given some value of the other variable.\nPrediction Intervals and Variation\n• Use paired sample data to determine the value of the coefficient of determination  \nr 2, and to interpret that value.\n• Use paired sample data to use a given value of one variable to find a predicted \nvalue and a prediction interval for a second variable.\nMultiple Regression\n• Interpret results from technology to determine whether a multiple regression equa-\ntion is suitable for making predictions.\n• Compare results from different combinations of predictor variables and identify the \ncombination that results in the best multiple regression equation.\n10-1\n10-2\n10-3\n10-4\nChapter Objectives \n443\nCHAPTER OBJECTIVES\n>>>\nTABLE 10-1 Pulse Rates and White Blood Cell Counts  \nof Adult Females\nPulse Rate\n56.0\n82.0\n78.0\n86.0\n88.0\nWhite Blood Cell Count\n 6.9\n 8.1\n 6.4\n 6.3\n10.9\n\n444 \nCHAPTER 10 Correlation and Regression\nKey Concept In Part 1 we introduce the linear correlation coefficient r, which is a \nnumber that measures how well paired sample data fit a straight-line pattern when \ngraphed. We use the sample of paired data (sometimes called bivariate data) to find \nthe value of r (usually found using technology), then we use that value to decide \nwhether there is a linear correlation between the two variables. In this section we con-\nsider only linear relationships, which means that when graphed in a scatterplot, the \npoints approximate a straight-line pattern. In Part 2, we discuss methods for conduct-\ning a formal hypothesis test that can be used to decide whether there is a linear cor-\nrelation between all population values for the two variables.\nPART 1  Basic Concepts of Correlation \nWe begin with the basic definition of correlation, a term commonly used in the con-\ntext of an association between two variables.\n10-1 \nCorrelation\nDummy Variables and Logistic Regression\n• Find regression equations that include a dummy variable, which has only two  \npossible discrete values.\n• Apply methods of logistic regression when a dummy variable is the response (y) \nvariable.\n10-5\nDummy Variables and Logistic Regression\n• Find regression equations that include a dummy variable, which has only two \npossible discrete values.\n• Apply methods of logistic regression when a dummy variable is the response (y)\ny)\ny\nvariable.\nDEFINITIONS\nA correlation exists between two variables when the values of one variable are \nsomehow associated with the values of the other variable.\nA linear correlation exists between two variables when there is a correlation and \nthe plotted points of paired data result in a pattern that can be approximated by a \nstraight line.\nTable 10-1, for example, includes paired sample data consisting of pulse rates and \nwhite blood cell counts for five adult females. We will determine whether there is a \nlinear correlation between the variable x (pulse rate) and the variable y (white blood \ncell count). Instead of blindly jumping into the calculation of the linear correlation \ncoefficient r, it is wise to first explore the data.\nExplore!\nBecause it is always wise to explore sample data before applying a formal statistical \nprocedure, we should use a scatterplot to explore the paired data visually. Figure 10-1 \nshows a scatterplot of the data. The plotted points do not appear to follow a straight-\nline pattern very well, so it might appear that there is no linear correlation.\n\n10-1 Correlation \n445\nInterpreting Scatterplots\nFigure 10-2 shows four scatterplots with different characteristics.\n \n■Figure 10-2(a): Distinct straight-line, or linear, pattern. We say that there is a \npositive linear correlation between x and y, since as the x values increase, the cor-\nresponding y values also increase.\n \n■Figure 10-2(b): Distinct straight-line, or linear pattern. We say that there is a \nnegative linear correlation between x and y, since as the x values increase, the \ncorresponding y values decrease.\n \n■Figure 10-2(c): No distinct pattern which suggests that there is no correlation \nbetween x and y.\n \n■Figure 10-2(d): Distinct pattern suggesting a correlation between x and y, but the \npattern is not that of a straight line.\nFIGURE 10-1  Scatterplot of Pulse Rates and \nWhite Blood Cell Counts\n(a) Positive correlation: r = 0.859\n(b) Negative correlation: r = −0.971\n(c) No correlation: r = 0.074\n(d) Nonlinear relationship: r = 0.330\nFIGURE 10-2 Scatterplots\n\n446 \nCHAPTER 10 Correlation and Regression\nMeasure the Strength of the Linear Correlation with r\nBecause conclusions based on visual examinations of scatterplots are largely subjec-\ntive, we need more objective measures. We use the linear correlation coefficient r, \nwhich is a number that measures the strength of the linear association between the two \nvariables.\nDEFINITION\nThe linear correlation coefficient r measures the strength of the linear correlation \nbetween the paired quantitative x values and y values in a sample. The linear cor-\nrelation coefficient r is computed by using Formula 10-1 or Formula 10-2, included \nin the following Key Elements box. [The linear correlation coefficient is sometimes \nreferred to as the Pearson product moment correlation coefficient in honor of \nKarl Pearson (1857–1936), who originally developed it.]\nBecause the linear correlation coefficient r is calculated using sample data, it \nis a sample statistic used to measure the strength of the linear correlation between x \nand y. If we had every pair of x and y values from an entire population, the result of \nFormula 10-1 or Formula 10-2 would be a population parameter, represented by r\n(Greek letter rho).\nCalculating and Interpreting the Linear Correlation Coefficient r\nObjective\nDetermine whether there is a linear correlation between two variables.\nNotation for the Linear Correlation Coefficient\nn \nnumber of pairs of sample data.\nΣ \ndenotes addition of the items indicated.\nΣx \nsum of all x values.\nΣx2 \n indicates that each x value should be squared and then those squares added.\n(Σx)2 \n indicates that the x values should be added and the total then squared. Avoid confusing Σx2 and (Σx)2.\nΣxy \n indicates that each x value should first be multiplied by its corresponding y value. After obtaining all such prod-\nucts, find their sum.\nr \nlinear correlation coefficient for sample data.\nr \nlinear correlation coeﬃcient for a population of paired data.\nRequirements\nKEY ELEMENTS\nGiven any collection of sample paired quantitative data, \nthe linear correlation coefficient r can always be com-\nputed, but the following requirements should be satisfied \nwhen using the sample paired data to make a conclusion \nabout the linear correlation in the corresponding popula-\ntion of paired data.\n1. The sample of paired (x, y) data is a simple random \nsample of quantitative data. (It is important that the \nsample data have not been collected using some  \ninappropriate method, such as using a voluntary  \nresponse sample.)\ncontinued\n\n10-1 Correlation \n447\n2. Visual examination of the scatterplot must confirm \nthat the points approximate a straight-line pattern.*\n3. Because results can be strongly affected by the \npresence of outliers, any outliers must be removed \nif they are known to be errors. The effects of any \nother outliers should be considered by calculating \nr with and without the outliers included.*\nFormulas for Calculating r\nFORMULA 10-1 r =\nn1Σxy2 - 1Σx21Σy2\n2n1Σx22 - 1Σx2 22n1Σy22 - 1Σy2 2 1Good format for calculations2\nFORMULA 10-2 r =\nΣ1zx zy2\nn - 1  1Good format for understanding2\nwhere zx denotes the z score for an individual sample value x and zy is the z score for the corresponding sample value y.\nRounding the Linear Correlation Coefficient r\nRound the linear correlation coefficient r to three decimal places so that its value can be directly compared to critical \nvalues in Table A-6.\nInterpreting the Linear Correlation Coefficient r\n \n• Using P-Value from Technology to Interpret r: Use the P-value and significance level a as follows:\nP-value … a: Supports the claim of a linear correlation. \nP-value 7 a: Does not support the claim of a linear correlation.\n \n• Using Table A-6 to Interpret r: Consider critical values from Table A-6 or technology as being both positive and \nnegative, draw a graph similar to Figure 10-3 that accompanies Example 4 on page 451, and then use the follow-\ning decision criteria:\nCorrelation If the computed linear correlation coeﬃcient r lies in the left tail beyond the leftmost critical value \nor if it lies in the right tail beyond the rightmost critical value (that is, 0 r0 Ú critical value), conclude that there \nis suﬃcient evidence to support the claim of a linear correlation.\nNo Correlation If the computed linear correlation coeﬃcient lies between the two critical values (that is, \n0 r0 6 critical value), conclude that there is not suﬃcient evidence to support the claim of a linear correlation.\nCAUTION Remember, the methods of this section apply to a linear correlation. If \nyou conclude that there does not appear to be a linear correlation, it is possible \nthat there might be some other association that is not linear, as in Figure 10-2(d) on \npage 445. Always create a scatterplot to see relationships that might not be linear.\n*Note: Requirements 2 and 3 above are simplified at-\ntempts at checking this formal requirement: The pairs of \n(x, y) data must have a bivariate normal distribution. \nNormal distributions are discussed in Chapter 6, but this \nassumption basically requires that for any fixed value of x, \nthe corresponding values of y have a distribution that is ap-\nproximately normal, and for any fixed value of y, the val-\nues of x have a distribution that is approximately normal. \nThis requirement is usually difficult to check, so for now, \nwe will use Requirements 2 and 3 as listed above.\n\n448 \nCHAPTER 10 Correlation and Regression\nProperties of the Linear Correlation Coefficient r\n1. The value of r is always between -1 and 1 inclusive. That is, -1 … r … 1.\n2. If all values of either variable are converted to a different scale, the value of r \ndoes not change.\n3. The value of r is not affected by the choice of x or y. Interchange all x values \nand y values, and the value of r will not change.\n4. r measures the strength of a linear relationship. It is not designed to measure \nthe strength of a relationship that is not linear, as in Figure 10-2(d).\n5. r is very sensitive to outliers in the sense that a single outlier could dramati-\ncally affect its value.\nCalculating the Linear Correlation Coefficient r\nThe following three examples illustrate three different methods for finding the value \nof the linear correlation coefficient r, but you need to use only one method. The use \nof technology (as in Example 1) is strongly recommended. If manual calculations are \nabsolutely necessary, Formula 10-1 is recommended (as in Example 2). If a better un-\nderstanding of r is desired, Formula 10-2 is recommended (as in Example 3).\nStatdisk\nMinitab\nStatCrunch\nXLSTAT\nEXAMPLE 1  Finding r Using Technology\nTo better illustrate the calculation of r, we use the data from Table 10-1 reproduced \nhere. Use technology to find the value of the correlation coefficient r for the data in \nTable 10-1.\nTABLE 10-1 Pulse Rates and White Blood Cell Counts of Adult Females\nPulse Rate\n56.0\n82.0\n78.0\n86.0\n88.0\nWhite Blood Cell Count\n 6.9\n 8.1\n 6.4\n 6.3\n10.9\nSOLUTION\nThe value of r will be automatically calculated with software or a calculator. See the \naccompanying technology displays showing that r = 0.405 (rounded).\nP\nPalm Reading\nSome people \nbelieve that \nthe length of \ntheir palm’s \nlifeline can be \nused to predict \nlongevity. In a \nletter published in the Journal of \nthe American Medical Associa-\ntion, authors M. E. Wilson and \nL. E. Mather refuted that belief \nwith a study of cadavers. Ages \nat death were recorded, along \nwith the lengths of palm lifelines. \nThe authors concluded that there \nis no correlation between age \nat death and length of lifeline. \nPalmistry lost, hands down.\n\n10-1 Correlation \n449\nTI-83/84 Plus\nSPSS\nJMP\nEXAMPLE 2  Finding r Using Formula 10-1\nUse Formula 10-1 to find the value of the linear correlation coefficient r for the five \npairs of data listed in Table 10-1.\nSOLUTION\nUsing Formula 10-1, the value of r is calculated as shown below. Here, the variable \nx is used for the pulse rate, and the variable y is used for the white blood cell count. \nBecause there are five pairs of data, n = 5. Other required values are computed in \nTable 10-2.\nTABLE 10-2 Calculating r with Formula 10-1\n \nx (Pulse Rate)\ny (White Blood  \nCell Count)\n \nx2\n \ny2\n \nxy\n56\n 6.9\n3136\n 47.61\n386.4\n82\n 8.1\n6724\n 65.61\n664.2\n78\n 6.4\n6084\n 40.96\n499.2\n86\n 6.3\n7396\n 39.69\n541.8\n88\n10.9\n7744\n118.81\n959.2\nΣx = 390\nΣy = 38.6\nΣ x2 = 31,084\nΣy2 = 312.68\nΣxy = 3050.8\nUsing Formula 10-1 with the paired data in Table 10-2, r is calculated as follows:\n r =\nnΣ xy - 1Σx2 1Σy2\n2n1Σx22 - 1Σx2 22n1Σy22 - 1Σy2 2\n =\n513050.82 - 13902138.62\n25131,0842 - 13902 2251312.682 - 138.62 2\n =\n200\n23320273.44\n= 0.405\n\n450 \nCHAPTER 10 Correlation and Regression\nTABLE 10-3 Calculating r with Formula 10-2\n \nx (Pulse Rate)\ny (White Blood \nCell Count)\n \nzx\n \nzy\n \nzx # zy\n56\n 6.9\n-1.707531\n  -0.427920\n0.730687\n82\n 8.1\n0.310460\n0.198304\n0.061566\n78\n 6.4\n0\n  -0.688847\n0\n86\n 6.3\n0.620920\n  -0.741032\n-0.460122\n88\n10.9\n0.776151\n1.659495\n1.288018\nΣ1zx # zy2 = 1.620148\nEXAMPLE 3  Finding r Using Formula 10-2\nUse Formula 10-2 to find the value of the linear correlation coefficient r for the five \npairs of data listed in Table 10-1.\nSOLUTION\nIf manual calculations are absolutely necessary, Formula 10-1 is much easier than \nFormula 10-2, but Formula 10-2 has the advantage of making it easier to understand \nhow r works. (See the rationale for r discussed later in this section.) As in Example 2,  \nthe variable x is used for the pulse rates, and the variable y is used for the white \nblood cell counts. In Formula 10-2, each sample value is replaced by its correspond-\ning z score. For example, using unrounded numbers, the pulse rates have a mean of \nx = 78.0 and a standard deviation of sx = 12.884099, so the first pulse rate of 56 is \nconverted to a z score of -1.707531 as shown here:\nzx = x - x\nsx\n= 56 - 78.0\n12.884099 = -1.707531\nTable 10-3 lists the z scores for all of the pulse rates (see the third column) and the \nz scores for all of the white blood cell counts (see the fourth column). The last col-\numn of Table 10-3 lists the products zx # zy.\nUsing Σ1zx # zy2 = 1.620148 from Table 10-3, the value of r is calculated by using \nFormula 10-2 as shown below.\nr =\nΣ1zx # zy2\nn - 1\n= 1.620148\n4\n= 0.405\nIs There a Linear Correlation?\nWe know from the preceding three examples that the value of the linear correlation \ncoefficient is r = 0.405 for the five pairs of sample data in Table 10-1. We now pro-\nceed to interpret the meaning of r = 0.405 found from the five pairs of sample data, \nand our goal is to decide whether there appears to be a linear correlation between \npulse rates and white blood cell counts of all adult females. Using the criteria given \nin the preceding box, we can base our interpretation on a P-value or a critical value \nfrom Table A-6. See the criteria for “Interpreting the Linear Correlation Coefficient \nr” given in the preceding Key Elements box.\n\n10-1 Correlation \n451\nEXAMPLE 4  Is There a Linear Correlation?\nUsing the value of r = 0.405 for the five pairs of values in Table 10-1 and using a \nsignificance level of 0.05, is there sufficient evidence to support a claim that there is \na linear correlation between pulse rates and white blood cell counts?\nSOLUTION\nREQUIREMENT CHECK The first requirement of a simple random sample is satis-\nfied by the design of the study. The data are quantitative. The second require-\nment of a scatterplot showing a straight-line pattern is very questionable; see the \nscatterplot in Figure 10-1 on page 445. The scatterplot of Figure 10-1 also shows \nthat the third requirement of no outliers is questionable because the leftmost \npoints appear to be relatively far from the other points. We will proceed as if the \nrequirements are satisfied. \nWe can base our conclusion about correlation on either the P-value obtained from \ntechnology or the critical value found in Table A-6. (See the criteria for “Interpreting \nthe Linear Correlation Coefficient r” given in the preceding Key Elements box.)\n • Using P-Value from Technology to Interpret r: Use the P-value and signifi-\ncance level a as follows:\n \n \nP@value … a: Supports the claim of a linear correlation.\n \n \nP@value 7 a: Does not support the claim of a linear correlation.\nFor the data in Table 10-1, technology can be used to find that the P-value is \n0.4988. Because that P-value is greater than the significance level of 0.05, we \nconclude that there is not sufficient evidence to support the conclusion of a \nlinear correlation between pulse rates and white blood cell counts for all adult \nfemales.\n • Using Table A-6 to Interpret r: Consider critical values from Table A-6 as  \nbeing both positive and negative, and draw a graph similar to Figure 10-3. For \nthe data in Table 10-1, Table A-6 yields a critical value of 0.878 (for a 0.05 \nsignificance level). We now compare the computed value of r = 0.405 to the \ncritical values of r = {0.878 as shown in Figure 10-3.\nCorrelation If the computed linear correlation coefficient r lies in the left or \nright tail region beyond the critical value for that tail, conclude that there is suf-\nficient evidence to support the claim of a linear correlation.\ncontinued\n0\n−1\n1\nCorrelation\nCorrelation\nNo correlation\nSample Data:\nr = 0.405\nr = 0.878\nCritical Value\nr = −0.878\nCritical Value\nFIGURE 10-3 Critical r Values and the Computed r Value\n\n452 \nCHAPTER 10 Correlation and Regression\nExample 4 led to the conclusion of no linear correlation, but if we use the 147 \npairs of pulse rates and white blood cell counts for all of the females included in Data \nSet 1 “Body Data” in Appendix B, we get r = 0.221 and a P-value of 0.007, so the \nlarger data set leads to the conclusion that there is sufficient evidence to support the \nclaim that there is a linear correlation. But even though we have evidence to support \nthe claim of a linear correlation, the low value of r = 0.221 suggests that the correla-\ntion is not very strong. See the following interpretation based on the value of r2.\nInterpreting r: Explained Variation\nIf we conclude that there is a linear correlation between x and y, we can find a linear \nequation that expresses y in terms of x, and that equation can be used to predict values \nof y for given values of x. In Section 10-2 we will describe a procedure for finding \nsuch equations and show how to predict values of y when given values of x. But a \npredicted value of y will not necessarily be the exact result that occurs because in \naddition to x, there are other factors affecting y, such as random variation and other \ncharacteristics not included in the study. In Section 10-3 we will present a rationale \nand more details about this principle:\nThe value of r2 is the proportion of the variation in y that is explained by the \nlinear relationship between x and y.\nEXAMPLE 5  Explained Variation\nUsing the 147 pairs of pulse rates and white blood cell counts from females in Data \nSet 1, we get r = 0.221. What proportion of the variation in white blood cell counts \ncan be explained by the variation in the pulse rates?\nSOLUTION\nWith r = 0.221 we get r2 = 0.049.\nINTERPRETATION\nWe conclude that 0.049 (or about 5%) of the variation in white blood cell counts \ncan be explained by the linear relationship between pulse rates and white blood cell \ncounts. That’s not much. This also implies that about 95% of the variation in white \nblood cell counts cannot be explained by pulse rates.\nNo Correlation If the computed linear correlation coefficient lies between the \ntwo critical values, conclude that there is not sufficient evidence to support the \nclaim of a linear correlation.\nBecause Figure 10-3 shows that the computed value of r = 0.405 lies between \nthe two critical values, we conclude that there is not sufficient evidence to support \nthe claim of a linear correlation between pulse rates and white blood cell counts for \nadult females.\nINTERPRETATION\nBased on the five pairs of data in Table 10-1, we do not have sufficient evidence to \nconclude that there is a linear correlation between pulse rates and white blood cell \ncounts (but a larger data set might lead to a different conclusion).\n\n10-1 Correlation \n453\nInterpreting r with Causation: Don’t Go There!\nUsing the 147 pairs of pulse rates and white blood cell counts from females in Data \nSet 1 “Body Data” in Appendix B, we conclude that there is a linear correlation. We \nshould not make any conclusion that includes a statement about a cause-effect rela-\ntionship between the two variables. We should not conclude that higher pulse rates \ncause higher white blood cell counts. See the first of the following common errors, \nand know this:\nCorrelation does not imply causality!\nCommon Errors Involving Correlation\nHere are three of the most common errors made in interpreting results involving \ncorrelation:\n1. Assuming that correlation implies causality. One classic example involves \npaired data consisting of the stork population in Copenhagen and the \nnumber of human births. For several years, the data suggested a linear cor-\nrelation. Bulletin: Storks do not actually cause births, and births do not \ncause storks. Both variables were affected by another variable lurking in \nthe background. (A lurking variable is one that affects the variables being \nstudied but is not included in the study.) Here, an increasing human popu-\nlation resulted in more births and increased construction of thatched roofs \nthat attracted storks!\n2. Using data based on averages. Averages suppress individual variation and may \ninflate the correlation coefficient. One study produced a 0.4 linear correlation \ncoefficient for paired data relating income and education among individuals, \nbut the linear correlation coefficient became 0.7 when regional averages were \nused.\n3. Ignoring the possibility of a nonlinear relationship. If there is no linear  \ncorrelation, there might be some other correlation that is not linear, as in \nFigure 10-2(d) on page 445.\nPART 2\n Formal Hypothesis Test \nHypotheses If conducting a formal hypothesis test to determine whether there is \na significant linear correlation between two variables, use the following null and \nalternative hypotheses that use r to represent the linear correlation coefficient of \nthe population:\nNull Hypothesis\n   H0\n : r = 0 1No correlation2\nAlternative Hypothesis  H1\n : r ≠0 1Correlation2\nTest Statistic The same methods of Part 1 can be used with the test statistic r, or the \nt test statistic can be found using the following:\nTest Statistic  t =\nr\nB\n1 - r2\nn - 2\n 1with n - 2 degrees of freedom2\nIf the above t test statistic is used, P-values and critical values can be found \nusing technology or Table A-3 as described in earlier chapters. See the follow-\ning example.\n\n454 \nCHAPTER 10 Correlation and Regression\nEXAMPLE 6  Hypothesis Test Using the P-Value from the t Test\nUse the paired pulse rates and white blood cell counts from Table 10-1 on page 443 \nto conduct a formal hypothesis test of the claim that there is a linear correlation \nbetween the two variables. Use a 0.05 significance level with the P-value method \nof testing hypotheses.\nSOLUTION\nREQUIREMENT CHECK The requirements were addressed in Example 4. \nTo claim that there is a linear correlation is to claim that the population  \nlinear correlation coefficient r is different from 0. We therefore have the following \nhypotheses:\n H0\n : r = 0 1There is no linear correlation.2\n H1\n : r ≠0 1There is a linear correlation.2\nThe linear correlation coefficient is r = 0.405 and n = 5 (because there are 5 pairs \nof sample data), so the test statistic is\nt =\nr\nB\n1 - r2\nn - 2\n=\n0.405\nB\n1 - 0.4052\n5 - 2\n= 0.767\nWith n - 2 = 3 degrees of freedom, Table A-3 shows that the test statistic of  \nt = 0.767 yields a P-value that is greater than 0.20. Technologies show that the \nP-value is 0.499 when rounded. Because the P-value of 0.499 is greater than the \nsignificance level of 0.05, we fail to reject H0. (“If the P is low, the null must go.” \nThe P-value of 0.499 is not low.)\nINTERPRETATION\nWe conclude that there is not sufficient evidence to support the claim of a linear \ncorrelation between pulse rates and white blood cell counts of adult females.\nOne-Tailed Tests The examples and exercises in this section generally involve \ntwo-tailed tests, but one-tailed tests can occur with a claim of a positive linear correla-\ntion or a claim of a negative linear correlation. In such cases, the hypotheses will be as \nshown below.\nClaim of Negative Correlation \n(Left-Tailed Test)\nClaim of Positive Correlation \n(Right-Tailed Test)\nH0: r = 0\nH0: r = 0\nH1: r 6 0\nH1: r 7 0\nFor these one-tailed tests, the P-value method can be used as in earlier chapters.\nRationale for Methods of This Section We have presented Formulas 10-1 and \n10-2 for calculating r and have illustrated their use. Those formulas are given on the \nnext page, along with some other formulas that are “equivalent,” in the sense that they \nall produce the same values.\n\n10-1 Correlation \n455\nFIGURE 10-4   Scatterplot of z Scores from Pulse Rates and \nWhite Blood Cell Counts in Table 10-1\nFORMULA 10-1  r =\nnΣxy - 1Σx2 1Σy2\n2n1Σx22 - 1Σx2 22n1Σy22 - 1Σy2 2\nFORMULA 10-2  r =\nΣ1zx zy2\nn - 1\nr = Σ1x - x 2 1 y - y 2\n1n - 12sx sy\n  r =\na c 1x - x 2\nsx\n1 y - y 2\nsy\nd\nn - 1\nr =\nsxy\n1sxx 1syy\nWe will use Formula 10-2 to help us understand the reasoning that underlies the \ndevelopment of the linear correlation coefficient. Because Formula 10-2 uses z scores, \nthe value of Σ1zxzy2 does not depend on the scale that is used for the x and y values. \nFigure 10-1 on page 445 shows the scatterplot of the pulse rate and white blood cell \ncount data from Table 10-1, and Figure 10-4 shows the scatterplot of the z scores from \nthe same sample data. Compare Figure 10-1 to Figure 10-4 and see that they are es-\nsentially the same scatterplots with different scales. Figure 10-4 shows the same coor-\ndinate axes that we have all come to know and love from earlier mathematics courses. \nFigure 10-4 shows the scatterplot partitioned into four quadrants.\nIf the points of the scatterplot approximate an uphill line, individual values of the \nproduct zx # zy tend to be positive (because most of the points are found in the first and \nthird quadrants, where the values of zx and zy are either both positive or both negative), \nso Σ1zx zy2 tends to be positive. If the points of the scatterplot approximate a downhill \nline, most of the points are in the second and fourth quadrants, where zx and zy are \nopposite in sign, so Σ1zx zy2 tends to be negative. Points that follow no linear pattern \ntend to be scattered among the four quadrants, so the value of Σ1zx zy2 tends to be \nclose to 0.\nWe can therefore use Σ1zx zy2 as a measure of how the points are configured \namong the four quadrants. A large positive sum suggests that the points are predomi-\nnantly in the first and third quadrants (corresponding to a positive linear correlation), a \nlarge negative sum suggests that the points are predominantly in the second and fourth \n\n456 \nCHAPTER 10 Correlation and Regression\nquadrants (corresponding to a negative linear correlation), and a sum near 0 suggests \nthat the points are scattered among the four quadrants (with no linear correlation). We \ndivide Σ1zx zy2 by n - 1 to get an average instead of a statistic that becomes larger \nsimply because there are more data values. (The reasons for dividing by n - 1 instead \nof n are essentially the same reasons that relate to the standard deviation.) The end \nresult is Formula 10-2, which can be algebraically manipulated into any of the other \nexpressions for r.\nStatistical Literacy and Critical Thinking\n1. Notation Twenty different statistics students are randomly selected. For each of them, their \nbody temperature (oC) is measured and their head circumference (cm) is measured.\na. For this sample of paired data, what does r represent, and what does r represent?\nb. Without doing any research or calculations, estimate the value of r.\nc. Does r change if the body temperatures are converted to Fahrenheit degrees?\n2. Interpreting r For the same two variables described in Exercise 1, if we find that r = 0, does \nthat indicate that there is no association between those two variables?\n3. Global Warming If we find that there is a linear correlation between the concentration of \ncarbon dioxide (CO2) in our atmosphere and the global mean temperature, does that indicate \nthat changes in CO2 cause changes in the global mean temperature? Why or why not?\n4. Scatterplots Match these values of r with the five scatterplots shown here and on the top of \nthe next page: 0.268, 0.992, -1, 0.746, and 1.\n10-1 Basic Skills and Concepts \n(a)\n(b)\n(c)\n(d)\nCorrelation\nAccess tech instructions, videos, and data sets at www.TriolaStats.com\nTECH CENTER\n\n10-1 Correlation \n457\nInterpreting r. In Exercises 5–8, use a significance level of A = 0.05 and refer to the  \naccompanying displays.\n5.  Bear Weight and Chest Size Fifty-four wild bears were anesthetized, and then their \nweights and chest sizes were measured and listed in Data Set 11 “Bear Measurements.” Results \nare shown in the accompanying Statdisk display. Is there sufficient evidence to support the \nclaim that there is a linear correlation between the weights of bears and their chest sizes? When \nmeasuring an anesthetized bear, is it easier to measure chest size than weight? If so, does it ap-\npear that a measured chest size can be used to predict the weight?\n(e)\n6. Cereal Killers The amounts of sugar (grams of sugar per gram of cereal) and calories (per \ngram of cereal) were recorded for a sample of 16 different cereals. TI-83>84 Plus calculator \nresults are shown here. Is there sufficient evidence to support the claim that there is a linear cor-\nrelation between sugar and calories in a gram of cereal? Explain.\nTI-83 , 84 Plus\n7. Heights of Fathers and Sons The heights (in inches) of a sample of 134 father>son pairs of \nsubjects were measured and the results are listed in Data Set 6 “Family Heights” in Appendix B. \nXLSTAT results are shown below. Is there sufficient evidence to support the claim that there is a \nlinear correlation between the heights of fathers and the heights of their sons? Explain.\n\n458 \nCHAPTER 10 Correlation and Regression\n8. Heights of Mothers and Daughters The heights (in inches) of a sample of 134 mother>\ndaughter pairs of subjects were measured and the results are listed in Data Set 6 “Family \nHeights” in Appendix B. StatCrunch results are shown below. StatCrunch also indicates that \nthe P-value is less than 0.0001. Is there sufficient evidence to support the claim that there is a \nlinear correlation between the heights of mothers and the heights of their daughters? Explain.\nExplore! Exercises 9 and 10 provide two data sets from “Graphs in Statistical Analysis,” \nby F. J. Anscombe, The American Statistician, Vol. 27. For each exercise,\na. Construct a scatterplot.\nb. Find the value of the linear correlation coefficient r, then determine whether there is suffi-\ncient evidence to support the claim of a linear correlation between the two variables.\nc. Identify the feature of the data that would be missed if part (b) was completed without con-\nstructing the scatterplot.\n9. \nx\n10\n8\n13\n9\n11\n14\n6\n4\n12\n7\n5\ny\n9.14\n8.14\n8.74\n8.77\n9.26\n8.10\n6.13\n3.10\n9.13\n7.26\n4.74\n10. \nx\n10\n8\n13\n9\n11\n14\n6\n4\n12\n7\n5\ny\n7.46\n6.77\n12.74\n7.11\n7.81\n8.84\n6.08\n5.39\n8.15\n6.42\n5.73\n11. Outlier Refer to the accompanying Minitab-generated scatterplot.\na. Examine the pattern of all 10 points and subjectively determine whether there appears to be \na correlation between x and y.\nb. After identifying the 10 pairs of coordinates corresponding to the 10 points, find the value of \nthe correlation coefficient r and determine whether there is a linear correlation.\nc. Now remove the point with coordinates (10, 10) and repeat parts (a) and (b).\nd. What do you conclude about the possible effect from a single pair of values?\nMinitab\n12. Clusters Refer to the following Minitab-generated scatterplot. The four points in the lower \nleft corner are measurements from women, and the four points in the upper right corner are \nfrom men.\n\n10-1 Correlation \n459\na. Examine the pattern of the four points in the lower left corner (from women) only, and sub-\njectively determine whether there appears to be a correlation between x and y for women.\nb. Examine the pattern of the four points in the upper right corner (from men) only, and subjec-\ntively determine whether there appears to be a correlation between x and y for men.\nc. Find the linear correlation coefficient using only the four points in the lower left corner (for \nwomen). Will the four points in the upper left corner (for men) have the same linear correlation \ncoefficient?\nd. Find the value of the linear correlation coefficient using all eight points. What does that \nvalue suggest about the relationship between x and y?\ne. Based on the preceding results, what do you conclude? Should the data from women and the \ndata from men be considered together, or do they appear to represent two different and distinct \npopulations that should be analyzed separately?\nMinitab\nTesting for a Linear Correlation. In Exercises 13–28, construct a scatterplot, and find \nthe value of the linear correlation coefficient r. Also find the P-value or find the critical \nvalues of r from Table A-6. Use a significance level of A = 0.05. Determine whether there \nis sufficient evidence to support a claim of a linear correlation between the two variables. \n(Save your work because the same data sets will be used in Section 10-2 exercises.)\n13. IQ and Brain Volume The table below lists IQ scores and brain volumes (cm3) and body \nweights (kg) of subjects (from Data Set 9 “IQ and Brain Size” in Appendix B). Is there suf-\nficient evidence to conclude that there is a linear correlation between IQ scores and brain vol-\numes? Does it appear that people with larger brains have higher IQ scores?\nIQ\n87\n101\n103\n96\n101\n96\n93\n88\n97\n114\n113\nBrain \nVolume\n \n1027\n \n1281\n \n1051\n \n1079\n \n1173\n \n1079\n \n1067\n \n1104\n \n1029\n \n1100\n \n1204\nBody \nWeight\n \n58.514\n \n63.958\n \n133.358\n \n107.503\n \n61.236\n \n61.236\n \n83.916\n \n79.38\n \n81.648\n \n88.452\n \n79.38\n14. IQ and Weight Use the paired IQ and body weight data from the preceding exercise. Is \nthere sufficient evidence to conclude that there is a linear correlation between IQ scores and \nbody weights?\n15. CSI Statistics Police sometimes measure shoe prints at crime scenes so that they can learn \nsomething about criminals. Listed below are shoe print lengths, foot lengths, and heights of males \n(from Data Set 7 “Foot and Height” in Appendix B). Is there sufficient evidence to conclude that \nthere is a linear correlation between shoe print lengths and heights of males? Based on these re-\nsults, does it appear that police can use a shoe print length to estimate the height of a male?\nShoe Print (cm)\n29.7\n29.7\n31.4\n31.8\n27.6\nFoot Length (cm)\n25.7\n25.4\n27.9\n26.7\n25.1\nHeight (cm)\n175.3\n177.8\n185.4\n175.3\n172.7\n\n460 \nCHAPTER 10 Correlation and Regression\n16. CSI Statistics Use the paired foot length and height data from the preceding exercise. Is \nthere sufficient evidence to conclude that there is a linear correlation between foot lengths and \nheights of males? Based on these results, does it appear that police can use foot length to esti-\nmate the height of a male?\n17. Lemons and Car Crashes Listed below are annual data for various years. The data are \nweights (metric tons) of lemons imported from Mexico and U.S. car crash fatality rates per \n100,000 population [based on data from “The Trouble with QSAR (or How I Learned to Stop \nWorrying and Embrace Fallacy),” by Stephen Johnson, Journal of Chemical Information and \nModeling, Vol. 48, No. 1]. Is there sufficient evidence to conclude that there is a linear correla-\ntion between weights of lemon imports from Mexico and U.S. car fatality rates? Do the results \nsuggest that imported lemons cause car fatalities?\nLemon Imports\n230\n265\n358\n480\n530\nCrash Fatality Rate\n15.9\n15.7\n15.4\n15.3\n14.9\n18. Crickets and Temperature A classic application of correlation involves the association \nbetween the temperature and the number of times a cricket chirps in 1 minute. Listed below \nare the numbers of chirps in 1 min and the corresponding temperatures in °F (based on data \nfrom The Song of Insects, by George W. Pierce, Harvard University Press). Is there sufficient \nevidence to conclude that there is a linear correlation between the number of chirps in 1 min \nand the temperature?\nChirps in 1 min\n882\n1188\n1104\n864\n1200\n1032\n960\n900\nTemperature  1°F2\n69.7\n93.3\n84.3\n76.3\n88.6\n82.6\n71.6\n79.6\n19. Pulse Rate and Blood Pressure The table below lists pulse rates, systolic blood pres-\nsures (mm Hg), and diastolic blood pressures (mm Hg) of adult females (from Data Set 1 \n“Body Data” in Appendix B). Is there sufficient evidence to conclude that there is a linear cor-\nrelation between pulse rate and systolic blood pressure?\nPulse\n 86\n 72\n 82\n 82\n 64\n68\n 70\n 78\n 96\n 72\n 60\n 98\nSystolic\n126\n104\n130\n106\n158\n96\n156\n112\n122\n114\n102\n126\nDiastolic\n 70\n 66\n 74\n 64\n 74\n52\n 90\n 70\n 68\n 74\n 60\n 68\n20. Blood Pressure Use the paired systolic and diastolic data from the preceding exercise. Is \nthere sufficient evidence to conclude that there is a linear correlation between systolic blood \npressures and diastolic blood pressures of adult females?\n21.  Weighing Seals with a Camera Listed below are the overhead widths (cm) of seals \nmeasured from photographs and the weights (kg) of the seals (based on “Mass Estimation of \nWeddell Seals Using Techniques of Photogrammetry,” by R. Garrott of Montana State Univer-\nsity). The purpose of the study was to determine if weights of seals could be determined from \noverhead photographs. Is there sufficient evidence to conclude that there is a linear correlation \nbetween overhead widths of seals from photographs and the weights of the seals?\nOverhead Width\n7.2\n7.4\n9.8\n9.4\n8.8\n8.4\nWeight\n116\n154\n245\n202\n200\n191\n22. Manatees Listed below are numbers of registered pleasure boats in Florida (tens of thou-\nsands) and the numbers of manatee fatalities from encounters with boats in Florida for each \nof several recent years. The values are from Data Set 12 “Manatee Deaths.” Is there sufficient \nevidence to conclude that there is a linear correlation between numbers of registered pleasure \nboats and numbers of manatee boat fatalities?\nPleasure Boats\n99\n99\n97\n95\n90\n90\n87\n90\n90\nManatee Fatalities\n92\n73\n90\n97\n83\n88\n81\n73\n68\n\n10-1 Correlation \n461\n23. POTUS Media periodically discuss the issue of heights of winning presidential candidates \nand heights of their main opponents. Listed below are those heights (cm) from several recent \npresidential elections. Is there sufficient evidence to conclude that there is a linear correla-\ntion between heights of winning presidential candidates and heights of their main opponents? \nShould there be such a correlation?\nPresident\n178\n182\n188\n175\n179\n183\n192\n182\n177\n185\n188\n188\n183\n188\nOpponent\n180\n180\n182\n173\n178\n182\n180\n180\n183\n177\n173\n188\n185\n175\n24. Tree Circumference and Height Listed below are the circumferences (in feet) and the heights \n(in feet) of trees in Marshall, Minnesota (based on data from “Tree Measurements,” by Stanley Rice, \nAmerican Biology Teacher, Vol. 61, No. 9). Is there sufficient evidence to support the claim of a linear \ncorrelation between circumferences and heights of trees? Why should there be a correlation?\nCircumference\n1.8\n1.9\n1.8\n2.4\n5.1\n3.1\n5.5\n5.1\n8.3\n13.7\n5.3\n4.9\nHeight\n21.0\n33.5\n24.6\n40.7\n73.2\n24.9\n40.4\n45.3\n53.5\n93.8\n64.0\n62.7\nAppendix B Data Sets. In Exercises 25–32, use the data in Appendix B to construct a \nscatterplot, find the value of the linear correlation coefficient r, and find either the P-value \nor the critical values of r using A = 0.05. Determine whether there is sufficient evidence to \nsupport the claim of a linear correlation between the two variables. (Save your work  \nbecause the same data sets will be used in Section 10-2 exercises.)\n25. IQ and Brain Volume Use all of the paired IQ scores and brain volumes in Data Set 9 \n“IQ and Brain Size” in Appendix B.\n26. IQ and Weight Use all of the paired IQ scores and body weights in Data Set 9 “IQ and \nBrain Size” in Appendix B.\n27. CSI Statistics Use the paired shoe print lengths and heights of the 19 males from Data Set \n7 “Foot and Height.”\n28. CSI Statistics Use the paired foot lengths and heights of the 19 males from Data Set 7 \n“Foot and Height.”\n29. Pulse Rate and Blood Pressure Use all of the paired pulse rates and systolic blood \npressure amounts for adult females from Data Set 1 “Body Data” in Appendix B.\n30. Blood Pressure Use all of the paired systolic and diastolic data for adult females as listed \nin Data Set 1 “Body Data” in Appendix B. Is there sufficient evidence to conclude that there is a \nlinear correlation between systolic blood pressures and diastolic blood pressures of adult females?\n31.  Audiometry Use the right ear threshold measurements and the corresponding left ear \nthreshold measurements from Data Set 4 “Audiometry” in Appendix B. Is there sufficient evi-\ndence to support the claim of a linear correlation?\n32. Vision Use the measurements of visual acuity from the right eye and left eye as listed in Data Set 5 \n“Vision” in Appendix B. Is there sufficient evidence to support the claim of a linear correlation?\n10-1 Beyond the Basics \n33. Transformed Data In addition to testing for a linear correlation between x and y, we can \noften use transformations of data to explore other relationships. For example, we might replace \neach x value by x2 and use the methods of this section to determine whether there is a linear \ncorrelation between y and x2. Given the paired data in the accompanying table, construct the \nscatterplot and then test for a linear correlation between y and each of the following. Which \ncase results in the largest value of r?\na. x  b. x2  c. log x  d. 1x  e. 1>x\nx\n2\n3\n20\n50\n95\ny\n0.3\n0.5\n1.3\n1.7\n2.0\n\n462 \nCHAPTER 10 Correlation and Regression\n34. Finding Critical r Values Table A-6 lists critical values of r for selected values of n and a. \nMore generally, critical r values can be found by using the formula\nr =\nt\n2t2 + n - 2\nwhere the t value is found from the table of critical t values (Table A-3) assuming a two-tailed case with \nn - 2 degrees of freedom. Use the formula for r given here and Table A-3 (with n - 2 degrees \nof freedom) to find the critical r values corresponding to H1: r ≠0, a = 0.02, and n = 27.\nKey Concept This section presents methods for finding the equation of the straight \nline that best fits the points in a scatterplot of paired sample data. That best-fitting \nstraight line is called the regression line, and its equation is called the regression equa-\ntion. We can use the regression equation to make predictions for the value of one of \nthe variables, given some specific value of the other variable. In Part 2 of this section \nwe discuss marginal change, influential points, and residual plots as tools for analyz-\ning correlation and regression results.\nPART 1\n Basic Concepts of Regression \nIn some cases, two variables are related in a deterministic way, meaning that given a value \nfor one variable, the value of the other variable is exactly determined without any error, \nas in the equation y = 2.54x for converting a distance x from inches to centimeters. Such \nequations are considered in algebra courses, but statistics courses focus on probabilistic \nmodels, which are equations with a variable that is not determined completely by the \nother variable. For example, the height of a child cannot be determined completely by the \nheight of the father and>or mother. Sir Francis Galton (1822–1911) studied the phenom-\nenon of heredity and showed that when tall or short couples have children, the heights \nof those children tend to regress, or revert to the more typical mean height for people of \nthe same gender. We continue to use Galton’s “regression” terminology, even though our \ndata do not always involve the same height phenomena studied by Galton.\n10-2 \nRegression\nDEFINITIONS\nGiven a collection of paired sample data, the regression line (or line of best fit, or least-\nsquares line) is the straight line that “best” fits the scatterplot of the data. (The specific \ncriterion for the “best-fitting” straight line is the “least-squares” property described later.)\nThe regression equation\nyn = b0 + b1x\nalgebraically describes the regression line. The regression equation expresses a  \nrelationship between x (called the explanatory variable, or predictor variable, or  \nindependent variable) and yn (called the response variable or dependent variable).\nThe preceding definition shows that in statistics, the typical equation of a straight \nline y = mx + b is expressed in the form yn = b0 + b1x, where b0 is the y-intercept \nand b1 is the slope. The values of the slope b1 and y-intercept b0 can be easily found \nby using any one of the many computer programs and calculators designed to provide \nthose values, as illustrated in Example 1. The values of b1 and b0 can also be found \nwith manual calculations, as shown in Example 2.\n\n10-2 Regression \n463\nFinding the Equation of the Regression Line\nObjective\nFind the equation of a regression line.\nNotation for the Equation of a Regression Line\nSample Statistic\nPopulation Parameter\ny-intercept of regression equation\nb0\nb0\nSlope of regression equation\nb1\nb1\nEquation of the regression line\nyn = b0 + b1x\ny = b0 + b1x\nRequirements\nKEY ELEMENTS\nFormulas for Finding the Slope b1 and y-Intercept b0 in the Regression Equation yn = b0 + b1x\n*Note: Requirements 2 and 3 above are simpliﬁed attempts \nat checking the following formal requirements for regres-\nsion analysis:\n• For each fixed value of x, the corresponding values of y \nhave a normal distribution.\n1. The sample of paired (x, y) data is a random sample of \nquantitative data.\n2. Visual examination of the scatterplot shows that the \npoints approximate a straight-line pattern.*\n3. Outliers can have a strong effect on the regression \nequation, so remove any outliers if they are known to \nbe errors. Consider the effects of any outliers that are \nnot known errors.*\n• For the different fixed values of x, the distributions of \nthe corresponding y values all have the same standard \ndeviation. (This is violated if part of the scatterplot \nshows points very close to the regression line while \nanother portion of the scatterplot shows points that are \nmuch farther away from the regression line. See the \ndiscussion of residual plots in Part 2 of this section.)\n• For the different fixed values of x, the distributions of \nthe corresponding y values have means that lie along \nthe same straight line.\nThe methods of this section are not seriously affected if \ndepartures from normal distributions and equal standard \ndeviations are not too extreme.\nFORMULA 10-3\nSlope: \nb1 = r \nsy\nsx\nwhere r is the linear correlation coefficient, sy is the \nstandard deviation of the y values, and sx is the stan-\ndard deviation of the x values.\nFORMULA 10-4\ny-intercept: b0 = y - b1x\nThe slope b1 and y-intercept b0 can also be found using the following formulas that are useful for manual calculations or \ncomputer programs:\nb1 = n1Σxy2 - 1Σx2 1Σy2\nn1Σx22 - 1Σx2 2\n  b0 = 1Σy2 1Σx22 - 1Σx2 1Σxy2\nn1Σx22 - 1Σx2 2\nRounding the Slope b1 and the y-Intercept b0\nRound b1 and b0 to three significant digits. It’s difficult to provide a simple universal rule for rounding values of b1 and b0, \nbut this rule will work for most situations in this book. (Depending on how you round, this book’s answers to examples \nand exercises may be slightly different from your answers.)\n\n464 \nCHAPTER 10 Correlation and Regression\nEXAMPLE 1  Using Technology to Find the Regression Equation\nRefer to the sample data given in Table 10-1 on page 443 in the Chapter Problem. \nUse technology to find the equation of the regression line in which the explanatory \nvariable (or x variable) is pulse rate and the response variable (or y variable) is the \ncorresponding white blood cell count.\nSOLUTION\nREQUIREMENT CHECK (1) The data are assumed to be a simple random sample.  \n(2) Figure 10-1 is a scatterplot of the data. It is very questionable whether the points \nroughly follow a straight-line pattern. (3) There are no outliers. We will proceed as \nif the requirements are satisfied. \nTechnology The use of technology is recommended for finding the equation of a \nregression line. Shown below are the results from different technologies. Some tech-\nnologies provide the actual equation, and some technologies list the values of the \ny-intercept and the slope. All of these technologies show that the regression equa-\ntion can be expressed as yn = 3.02 + 0.0602x, where yn is the predicted white blood \ncell count and x is the pulse rate.\nStatdisk\nExcel (XLSTAT)\nMinitab\nTI-83 , 84 Plus\nStatCrunch\nSPSS\nJMP\nWe should know that the regression equation is an estimate of the true  \nregression equation for the population of paired data. This estimate is based on one \nparticular set of sample data, but another sample drawn from the same population \nwould probably lead to a slightly different equation.\nPostponing Death\nSeveral stud-\nies addressed \nthe ability \nof people to \npostpone their \ndeath until \nafter an impor-\ntant event. For example, sociolo-\ngist David Phillips analyzed death \nrates of Jewish men who died \nnear Passover, and he found \nthat the death rate dropped \ndramatically in the week before \nPassover, but rose the week \nafter. Other researchers of cancer \npatients concluded that there is \n“no pattern to support the con-\ncept that ‘death takes a holiday.’” \n(See “Holidays, Birthdays, and \nPostponement of Cancer Death,” \nby Young and Hade, Journal of \nthe American Medical Associa-\ntion, Vol. 292, No. 24.) Based \non records of 1.3 million deaths, \nthis more recent study found no \nrelationship between the time of \ndeath and Christmas, Thanksgiv-\ning, or the person’s birthday. The \nfindings were disputed by David \nPhillips, who said that the study \nfocused on cancer patients, \nbut they are least likely to have \npsychosomatic effects.\n\n10-2 Regression \n465\nEXAMPLE 2   Using Manual Calculations to Find the  \nRegression Equation\nRefer to the sample data given in Table 10-1 on page 443 in the Chapter Problem. \nUse Formulas 10-3 and 10-4 to find the equation of the regression line in which the \nexplanatory variable (or x variable) is pulse rate and the response variable (or y vari-\nable) is the corresponding white blood cell count.\nSOLUTION\nREQUIREMENT CHECK The requirements are addressed in Example 1. \nWe begin by finding the slope b1 using Formula 10-3 as follows (with extra dig-\nits included for greater accuracy). Remember, r is the linear correlation coefficient, \nsy is the standard deviation of the sample y values, and sx is the standard deviation of \nthe sample x values.\nb1 = r \nsy\nsx\n= 0.405037 # 1.916246\n12.884099 = 0.060241\nAfter finding the slope b1, we can now use Formula 10-4 to find the y-intercept as \nfollows:\nb0 = y - b1x = 7.72 - 10.0602412178.02 = 3.021202\nAfter rounding, the slope is b1 = 0.0602 and the y-intercept is b0 = 3.02. We  \ncan now express the regression equation as yn = 3.02 + 0.0602x, where yn is the \npredicted white blood cell count and x is the pulse rate.\nEXAMPLE 3  Graphing the Regression Line\nGraph the regression equation yn = 3.02 + 0.0602x (found in Examples 1 and 2) \non the scatterplot of the pulse and white blood cell count data from Table 10-1 \nand examine the graph to subjectively determine how well the regression line fits \nthe data.\nSOLUTION\nShown below is the Minitab display of the scatterplot with the graph of the regression \nline included. We can see that the regression line does not fit the points very well.\n\n466 \nCHAPTER 10 Correlation and Regression\nMaking Predictions\nRegression equations are often useful for predicting the value of one variable, given \nsome specific value of the other variable. When making predictions, we should \nconsider the following:\n1. Bad Model: If the regression equation does not appear to be useful for making \npredictions, don’t use the regression equation for making predictions. For bad \nmodels, the best predicted value of a variable is simply its sample mean.\n2. Good Model: Use the regression equation for predictions only if the graph of \nthe regression line on the scatterplot confirms that the regression line fits the \npoints reasonably well.\n3. Correlation: Use the regression equation for predictions only if the linear cor-\nrelation coefficient r indicates that there is a linear correlation between the two \nvariables (as described in Section 10-1).\n4. Scope: Use the regression line for predictions only if the data do not go \nmuch beyond the scope of the available sample data. (Predicting too far \nbeyond the scope of the available sample data is called extrapolation, and it \ncould result in bad predictions.)\nFigure 10-5 summarizes a strategy for predicting values of a variable y when \ngiven some value of x. Figure 10-5 shows that if the regression equation is a good \nmodel, then we substitute the value of x into the regression equation to find the pre-\ndicted value of y. However, if the regression equation is not a good model, the best \npredicted value of y is simply y, the mean of the y values. Remember, this strategy ap-\nplies to linear patterns of points in a scatterplot. If the scatterplot shows a pattern that \nis nonlinear (not a straight-line) pattern, other methods apply.\nIs the regression equation a good model?\n \n• The regression line graphed in the scatterplot\n \n shows that the line ﬁts the points well.\n \n• r indicates that there is a linear correlation.\n \n• The prediction is not much beyond the scope\n \n of the available sample data.\nStrategy for Predicting Values of y\nYes.\nThe regression\nequation is a\ngood model.\nNo.\nThe regression\nequation is not\na good model.\nSubstitute the given value of x\ninto the regression equation\ny 5 b0 1 b1x\nRegardless of the value of x,\nthe best predicted value of y is\nthe value of y (the mean of the \ny values).\nˆ\nFIGURE 10-5 Recommended Strategy for Predicting Values of y\nEXAMPLE 4  Making Predictions\na. Use the ﬁve pairs of pulse rates and white blood cell counts from Table 10-1 \non page 463 to predict the white blood cell count for an adult female with a \npulse rate of 80 beats per minute.\n \nb. Use the pulse rates and white blood cell counts for females in Data Set 1 \n“Body Data” in Appendix B to predict the white blood cell count for an adult \nM\nR\nso\nc\nClinical Trial Cut Short\nWhat do you \ndo when \nyou’re testing \na new treat-\nment and, \nbefore your \nstudy ends, \nyou find that it is clearly effec-\ntive? You should cut the study \nshort and inform all participants \nof the treatment’s effectiveness. \nThis happened when hydroxy-\nurea was tested as a treatment \nfor sickle cell anemia. The study \nwas scheduled to last about  \n40 months, but the effectiveness \nof the treatment became obvious \nand the study was stopped after \n36 months. (See “Trial Halted \nas Sickle Cell Treatment Proves \nItself,” by Charles Marwick, \nJournal of the American Medical \nAssociation, Vol. 273, No. 8.)\n\n10-2 Regression \n467\nfemale with a pulse rate of 80 beats per minute. This data set includes 147 \npairs of values, and the linear correlation coeﬃcient is r = 0.221 with a  \nP-value of 0.007. Also, the regression equation is yn = 4.06 + 0.0345x.\nSOLUTION\na. Bad Model: Use y for Predictions. The regression line does not ﬁt the points \nwell, as shown in Example 3. Also, there does not appear to be a linear  \ncorrelation between pulse rates and white blood cell counts as shown in \nSection 10-1. Because the regression equation is not a good model, the best \npredicted white blood cell count is y = 7.72, which is the mean of the ﬁve \nwhite blood cell counts from Table 10-1.\n \nb. Good Model: Use the Regression Equation for Predictions. Because the \nregression equation yn = 4.06 + 0.0345x is a good model, substitute x = 80 \ninto the equation to get the predicted white blood cell count of 6.8.\nINTERPRETATION\nNote that in part (a), the paired data result in a poor regression model, so the best \npredicted white blood cell count is the sample mean of the five white blood cell \ncounts: y = 7.72. However, in part (b) there is a linear correlation between pulse \nrates and white blood cell counts, so the best predicted value is found by substitut-\ning x = 80 into the regression equation.\nKey point: Use the regression equation for predictions only if it is a good \nmodel. If the regression equation is not a good model, use the predicted value of y.\nPART 2  Beyond the Basics of Regression \nIn Part 2 we consider the concept of marginal change, which is helpful in interpreting \na regression equation; then we consider the effects of outliers and special points called \ninfluential points. We also consider residual plots.\nInterpreting the Regression Equation: Marginal Change\nWe can use the regression equation to see the effect on one variable when the other \nvariable changes by some specific amount.\nDEFINITION\nIn working with two variables related by a regression equation, the marginal \nchange in a variable is the amount that it changes when the other variable changes \nby exactly one unit. The slope b1 in the regression equation represents the marginal \nchange in y that occurs when x changes by one unit.\nLet’s consider the 147 pairs of pulse rates and white blood cell counts for females \nfrom Data Set 1 “Body Data” in Appendix B. Those 147 pairs of data result in this \nregression equation: yn = 4.06 + 0.0345x. The slope of 0.0345 tells us that if we in-\ncrease x (pulse rate) by 1 (beat per minute), the predicted white blood cell count will \nincrease by 0.0345. That is, for every additional 1 beat per minute increase in pulse \nrate, we expect the white blood cell count to increase by 0.0345.\n\n468 \nCHAPTER 10 Correlation and Regression\nOutliers and Influential Points\nA correlation>regression analysis of bivariate (paired) data should include an investi-\ngation of outliers and influential points, defined as follows.\nDEFINITIONS\nIn a scatterplot, an outlier is a point lying far away from the other data points.\nPaired sample data may include one or more influential points, which are points \nthat strongly affect the graph of the regression line.\nTo determine whether a point is an outlier, examine the scatterplot to see if the \npoint is far away from the others. Here’s how to determine whether a point is an influ-\nential point: First graph the regression line resulting from the data with the point in-\ncluded, then graph the regression line resulting from the data with the point excluded. \nIf the regression line changes by a considerable amount, the point is influential.\nEXAMPLE 5  Influential Point\nConsider the 147 pairs of pulse rates and white blood cell counts for adult females \nfrom Data Set 1 “Body Data” in Appendix B. The scatterplot located to the left be-\nlow shows the regression line. If we include an additional pair of data, x = 30 and \ny = 100, we get the regression line shown to the right below. The additional point \n(30, 100) is an influential point because the graph of the regression line did change \nconsiderably, as shown by the regression line located to the right below. Compare the \ntwo graphs to see clearly that the addition of this one pair of values has a very dra-\nmatic effect on the regression line, so that the additional point (30, 100) is an influen-\ntial point. The additional point is also an outlier because it is far from the other points.\nPulse Rates and White Blood Cell  \nCounts for Females from Table 10-1\nPulse Rates and White Blood Cell  \nCounts with Additional Point: (30, 100)\nResiduals and the Least-Squares Property\nWe stated that the regression equation represents the straight line that “best” fits the \ndata. The criterion to determine the line that is better than all others is based on the \nvertical distances between the original data points and the regression line. Such dis-\ntances are called residuals.\nDEFINITION\nFor a pair of sample x and y values, the residual is the difference between the  \nobserved sample value of y and the y value that is predicted by using the regres-\nsion equation. That is,\nResidual = 1observed y - predicted y2 = y - yn\n\n10-2 Regression \n469\nSo far, this definition hasn’t yet won any prizes for simplicity, but you can easily under-\nstand residuals by referring to Figure 10-6, which corresponds to the paired sample data \nshown in the margin. In Figure 10-6, the residuals are represented by the dashed lines.\nx\n8\n12\n20\n24\ny\n4\n24\n 8\n32\nThe paired data are plotted as points in Figure 10-6.\nConsider the sample point with coordinates of (8, 4). If we substitute x = 8 into the \nregression equation yn = 1 + x, we get a predicted value of yn = 9. But for x = 8, the ac-\ntual observed sample value is y = 4. The difference y - yn = 4 - 9 = -5 is a residual.\nThe regression equation represents the line that “best” fits the points according to \nthe following least-squares property.\n0\n0\n10\n20\n30\n40\n10\n20\n30\n40\nResidual = –5\nResidual = 11\nResidual = –13\nResidual = 7\ny\nx\ny = 1 + x\nˆ\nFIGURE 10-6  Residuals and Squares of Residuals\nDEFINITION\nA straight line satisfies the least-squares property if the sum of the squares of the \nresiduals is the smallest sum possible.\nFrom Figure 10-6, we see that the residuals are -5, 11,-13, and 7, so the sum of their \nsquares is\n1-52 2 + 112 + 1-132 2 + 72 = 364\nWe can visualize the least-squares property by referring to Figure 10-6, where the \nsquares of the residuals are represented by the shaded square areas. The sum of the shaded \nsquare areas is 364, which is the smallest sum possible. Use any other straight line, and the \nshaded squares will combine to produce an area larger than the combined shaded area of 364.\nFortunately, we need not deal directly with the least-squares property when we \nwant to find the equation of the regression line. Calculus has been used to build the \nleast-squares property into Formulas 10-3 and 10-4. Because the derivations of these \nformulas require calculus, we don’t include the derivations in this text.\nResidual Plots\nIn this section and the preceding section we listed simplified requirements for the ef-\nfective analyses of correlation and regression results. We noted that we should always \nbegin with a scatterplot, and we should verify that the pattern of points is approxi-\nmately a straight-line pattern. We should also consider outliers. A residual plot can be \nanother helpful tool for analyzing correlation and regression results and for checking \nthe requirements necessary for making inferences about correlation and regression.\n\n470 \nCHAPTER 10 Correlation and Regression\nDEFINITION\nA residual plot is a scatterplot of the (x, y) values after each of the y-coordinate \nvalues has been replaced by the residual value y - yn (where yn denotes the pre-\ndicted value of y). That is, a residual plot is a graph of the points 1x, y - yn2.\nTo construct a residual plot, draw a horizontal reference line through the residual value of \n0, then plot the paired values of 1x, y - yn2. Because the manual construction of residual \nplots can be tedious, the use of technology is strongly recommended. When analyzing a \nresidual plot, look for a pattern in the way the points are configured, and use these criteria:\n \n■The residual plot should not have any obvious pattern (not even a straight-line \npattern). (This lack of a pattern confirms that a scatterplot of the sample data is a \nstraight-line pattern instead of some other pattern.)\n \n■The residual plot should not become much wider (or thinner) when viewed from left \nto right. (This confirms the requirement that for the different fixed values of x, the \ndistributions of the corresponding y values all have the same standard deviation.)\nEXAMPLE 6  Residual Plot\nThe 147 pairs of pulse rates and white blood cell counts for females in Data Set 1 \n“Body Data” in Appendix B are used to obtain the accompanying Minitab-generated \nresidual plot. When the first sample x value of 80 is substituted into the regression \nequation of yn = 4.06 + 0.0345x (found in Examples 1 and 2), we get the  \npredicted value of yn = 6.8. For the first x value of 80, the actual corresponding y \nvalue is 8.7, so the value of the residual is\n1Observed y - predicted y2 = y - yn = 8.7 − 6.8 =  1.9\nUsing the x value of 80 and the residual of 1.9, we get the coordinates of the \npoint (80, 1.9), which is one of the points in the residual plot shown here.\nMinitab\nSee the three residual plots on the top of the next page.\n \n■Leftmost Residual Plot: This graph suggests that the regression equation is a \ngood model.\n \n■Middle Residual Plot: This graph shows a distinct pattern, suggesting that the \nsample data do not follow a straight-line pattern as required.\n \n■Rightmost Residual Plot: This graph becomes thicker, which suggests that the \nrequirement of equal standard deviations is violated.\n\n10-2 Regression \n471\nResidual Plot Suggesting That the  \nRegression Equation Is a Good Model\nResidual Plot with an Obvious Pattern, \nSuggesting That the Regression  \nEquation Is Not a Good Model\nResidual Plot That Becomes Wider,  \nSuggesting That the Regression  \nEquation Is Not a Good Model\nStatistical Literacy and Critical Thinking\n1. Notation Different patients are randomly selected and measured for pulse rate and body \ntemperature. Using technology with x representing the pulse rates and y representing tempera-\ntures, we find that the regression equation has a slope of -0.001 and a y-intercept of 98.3.\na. What is the equation of the regression line?\nb. What does the symbol yn represent?\n2. Notation What is the difference between the regression equation yn = b0 + b1x and the re-\ngression equation y = b0 + b1x?\n3. Best-Fit Line\na. What is a residual?\nb. In what sense is the regression line the straight line that “best” fits the points in a scatterplot?\n4. Correlation and Slope What is the relationship between the linear correlation coefficient r \nand the slope b1 of a regression line?\nMaking Predictions. In Exercises 5–8, let the predictor variable x be the first variable \ngiven. Use the given data to find the regression equation and the best predicted value of the \nresponse variable. Be sure to follow the prediction procedure summarized in Figure 10-5 on \npage 466. Use a 0.05 significance level.\n5. Arm Circumference and Height Arm circumferences (cm) and heights (cm) are mea-\nsured from randomly selected adult females (from Data Set 1 “Body Data”). The 147 pairs \nof measurements yield x = 32.49 cm, y = 161.69 cm, r = 0.066, P-value = 0.428, and \nyn = 159 + 0.0916x. Find the best predicted value of yn (height) given an adult female with an \narm circumference of 40.0 cm.\n6. Bear Measurements Head widths (in.) and weights (lb) were measured for 20 randomly \nselected bears (from Data Set 11 “Bear Measurements”). The 20 pairs of measurements yield \nx = 6.9 in., y = 214.3 lb, r = 0.879, P-value = 0.000, and yn = -212 + 61.9x. Find the \nbest predicted value of yn (weight) given a bear with a head width of 6.5 in.\n7. Height and Weight Heights (cm) and weights (kg) are measured for 100 randomly se-\nlected adult males (from Data Set 1 “Body Data”). The 100 pairs of measurements yield \nx = 173.79 cm, y = 85.93 kg, r = 0.418, P-value = 0.000, and yn = -106 + 1.10x. Find \nthe best predicted value of yn (weight) given an adult male who is 180 cm tall.\n10-2 Basic Skills and Concepts\nRegression\nAccess tech instructions, videos, and data sets at www.TriolaStats.com\nTECH CENTER \n\n472 \nCHAPTER 10 Correlation and Regression\n8. White BCCs and Systolic BP White blood cell counts (BCCs) and systolic blood pres-\nsure (BP) amounts are measured for 50 randomly selected adult males (from Data Set 1 “Body \nData”). The 50 pairs of measurements yield x = 125.4 mm Hg, y = 6.75 (1000 cells>mL), \nr = 0.055, P-value = 0.702, and yn = 5.66 + 0.009x. Find the best predicted value of yn\n(white blood cell count) for an adult male with systolic blood pressure of 150 mm Hg.\nFinding the Equation of the Regression Line. In Exercises 9 and 10, use the given \ndata to find the equation of the regression line. Examine the scatterplot and identify a  \ncharacteristic of the data that is ignored by the regression line.\n9.  \nx\n10\n8\n13\n9\n11\n14\n6\n4\n12\n7\n5\ny\n9.14\n8.14\n8.74\n8.77\n9.26\n8.10\n6.13\n3.10\n9.13\n7.26\n4.74\n10. \nx\n10\n8\n13\n9\n11\n14\n6\n4\n12\n7\n5\ny\n7.46\n6.77\n12.74\n7.11\n7.81\n8.84\n6.08\n5.39\n8.15\n6.42\n5.73\n11. Effects of an Outlier Refer to the Minitab-generated scatterplot given in Exercise 11 of \nSection 10-1 on page 458.\na. Using the pairs of values for all 10 points, find the equation of the regression line.\nb. After removing the point with coordinates (10, 10), use the pairs of values for the remaining \n9 points and find the equation of the regression line.\nc. Compare the results from parts (a) and (b).\n12. Effects of Clusters Refer to the Minitab-generated scatterplot given in Exercise 12 of \nSection 10-1 on page 459.\na. Using the pairs of values for all 8 points, find the equation of the regression line.\nb. Using only the pairs of values for the 4 points in the lower left corner, find the equation of \nthe regression line.\nc. Using only the pairs of values for the 4 points in the upper right corner, find the equation of \nthe regression line.\nd. Compare the results from parts (a), (b), and (c).\nRegression and Predictions. Exercises 13–24 use the same data sets as Exercises 13–24 \nin Section 10-1. In each case, find the regression equation, letting the first variable be the \npredictor (x) variable. Find the indicated predicted value by following the prediction proce-\ndure summarized in Figure 10-5 on page 466.\n13. Brain Volume and IQ Use the following brain volumes (x) and IQ scores (y). If a subject \nhas a brain volume of 1200 cm3, what is the best predicted IQ score?\nIQ\n87\n101\n103\n96\n101\n96\n93\n88\n97\n114\n113\nBrain \nVolume\n \n1027\n \n1281\n \n1051\n \n1079\n \n1173\n \n1079\n \n1067\n \n1104\n \n1029\n \n1100\n \n1204\nBody \nWeight\n \n58.514\n \n63.958\n \n133.358\n \n107.503\n \n61.236\n \n61.236\n \n83.916\n \n79.38\n \n81.648\n \n88.452\n \n79.38\n14. Weight and IQ Use the weights (x) and IQ scores (y) from the preceding exercise. If a sub-\nject weighs 79.380 kg, what is the best predicted IQ score? How does it compare to the actual \nIQ score of 88 for the subject who weighed 79.380 kg?\n15. Predicting Height Use the shoe print lengths and heights to find the best predicted height \nof a male who has a shoe print length of 31.3 cm. Would the result be helpful to police crime \nscene investigators in trying to describe the male?\nShoe Print (cm)\n 29.7\n 29.7\n 31.4\n 31.8\n 27.6\nFoot Length (cm)\n 25.7\n 25.4\n 27.9\n 26.7\n 25.1\nHeight (cm)\n175.3\n177.8\n185.4\n175.3\n172.7\n\n10-2 Regression \n473\n16. Predicting Height Use the foot lengths and heights from the preceding exercise to find the \nbest predicted height of a male who has a foot length of 28 cm. Would the result be helpful to \npolice crime scene investigators in trying to describe the male?\n17. Lemons and Car Crashes Using the listed lemon>crash data, find the best predicted \ncrash fatality rate for a year in which there are 500 metric tons of lemon imports. Is the predic-\ntion worthwhile?\nLemon Imports\n230\n265\n358\n480\n530\nCrash Fatality Rate\n15.9\n15.7\n15.4\n15.3\n14.9\n18. Crickets and Temperature Find the best predicted temperature at a time when a cricket \nchirps 3000 times in 1 minute. What is wrong with this predicted temperature?\nChirps in 1 min\n882\n1188\n1104\n864\n1200\n1032\n960\n900\nTemperature 1°F2\n69.7\n93.3\n84.3\n76.3\n88.6\n82.6\n71.6\n79.6\n19. Pulse Rate and Systolic Blood Pressure Use the following pulse rates and systolic \nblood pressures. If a subject has a pulse rate of 80 beats per minute, what is the best predicted \nsystolic blood pressure?\nPulse\n 86\n 72\n 82\n 82\n 64\n68\n 70\n 78\n 96\n 72\n 60\n 98\nSystolic\n126\n104\n130\n106\n158\n96\n156\n112\n122\n114\n102\n126\nDiastolic\n 70\n 66\n 74\n 64\n 74\n52\n 90\n 70\n 68\n 74\n 60\n 68\n20. Systolic and Diastolic Blood Pressure Use the systolic and diastolic blood pressures \nfrom the preceding exercise. If a female has a systolic blood pressure of 120 mm Hg, what is \nthe best predicted diastolic blood pressure?\n21. Weighing Seals with a Camera Using the listed width>weight data, find the best pre-\ndicted weight of a seal if the overhead width measured from a photograph is 2 cm. Can the \nprediction be correct? If not, what is wrong?\nOverhead Width\n7.2\n7.4\n9.8\n9.4\n8.8\n8.4\nWeight\n116\n154\n245\n202\n200\n191\n22. Manatees Use the listed boat>manatee data. In a year not included in the data below, there \nwere 970,000 registered pleasure boats in Florida. Find the best predicted number of manatee \nfatalities resulting from encounters with boats. Is the result reasonably close to 79, which was \nthe actual number of manatee fatalities?\nPleasure Boats\n99\n99\n97\n95\n90\n90\n87\n90\n90\nManatee Fatalities\n92\n73\n90\n97\n83\n88\n81\n73\n68\n23. POTUS Using the president>opponent heights, find the best predicted height of an \nopponent of a president who is 190 cm tall. Does it appear that heights of opponents can be \npredicted from the heights of the presidents?\nPresident\n178\n182\n188\n175\n179\n183\n192\n182\n177\n185\n188\n188\n183\n188\nOpponent\n180\n180\n182\n173\n178\n182\n180\n180\n183\n177\n173\n188\n185\n175\n24. Tree Circumference and Height Using the circumference>height data, find the best pre-\ndicted height of a tree with a circumference of 5.0 feet. What is a big advantage of being able to \npredict height given a known circumference?\nCircumference\n1.8\n1.9\n1.8\n2.4\n5.1\n3.1\n5.5\n5.1\n8.3\n13.7\n5.3\n4.9\nHeight\n21.0\n33.5\n24.6\n40.7\n73.2\n24.9\n40.4\n45.3\n53.5\n93.8\n64.0\n62.7\n\n474 \nCHAPTER 10 Correlation and Regression\nLarge Data Sets. Exercises 25–32 use the same Appendix B data sets as Exercises 25–32 \nin Section 10-1. In each case, find the regression equation, letting the first variable be the \npredictor (x) variable. Find the indicated predicted values following the prediction proce-\ndure summarized in Figure 10-5 on page 466.\n25. Brain Volume and IQ Repeat Exercise 13 using all of the brain volumes and IQ scores in \nData Set 9 “IQ and Brain Size” in Appendix B.\n26. Weight and IQ Repeat Exercise 14 “Weight and IQ” using all of the weights and IQ scores \nin Data Set 9 “IQ and Brain Size” in Appendix B.\n27. Predicting Height Use the shoe print lengths and heights of the 19 males from Data Set 7 \n“Foot and Height.” Find the best predicted height of a male who has a shoe print length of 31.3 cm.\n28. Predicting Height Use the foot lengths and heights from the 19 males in Data Set 7 “Foot \nand Height.” Find the best predicted height of a male who has a foot length of 28 cm.\n29. Pulse Rate and Blood Pressure Use all of the pulse rates and systolic blood pressure \namounts for adult females in Data Set 1 “Body Data” in Appendix B. If a subject has a pulse \nrate of 80 beats per minute, what is the best predicted systolic blood pressure?\n30. Blood Pressure Use the systolic and diastolic blood pressures from the females in Data \nSet 1 “Body Data” in Appendix B. If a female has a systolic blood pressure of 120 mm Hg, \nwhat is the best predicted diastolic blood pressure?\n31. Audiometry Use the right ear threshold measurements and the corresponding left ear \nthreshold measurements from Data Set 4 “Audiometry” in Appendix B. What is the best pre-\ndicted threshold measurement for the left ear given a measurement of 20 for the right ear?\n32. Vision Use the measurements of visual acuity from the right eye and left eye as listed in \nData Set 5 “Vision” in Appendix B. What is the best predicted measurement for the left ear \ngiven a reading of 50 for the right ear?\n10-2 Beyond the Basics\n33. Least-Squares Property According to the least-squares property, the regression line \nminimizes the sum of the squares of the residuals. Refer to the data in Table 10-1 on page 443.\na. Find the sum of squares of the residuals.\nb. Show that the regression equation yn = 3.00 + 0.0500x results in a larger sum of squares of \nresiduals.\nKey Concept In Section 10-2 we presented a method for using a regression equa-\ntion to find a predicted value of y, but it would be great to have a way of determining \nthe accuracy of such predictions. In this section we introduce the prediction interval, \nwhich is an interval estimate of a predicted value of y. See the following definitions \nfor the distinction between confidence interval and prediction interval.\n10-3 \nPrediction Intervals and Variation\nDEFINITIONS\nA prediction interval is a range of values used to estimate a variable (such as a \npredicted value of y in a regression equation).\nA confidence interval is a range of values used to estimate a population param-\neter (such as m or p or s).\n\n10-3 Prediction Intervals and Variation \n475\nIn Example 4(b) from the preceding section, we showed that when using 147 \npairs of pulse rates and white blood cell counts for females, the regression equation is \nyn = 4.06 + 0.0345x. Given a female pulse rate of 80 (x = 80), the best predicted white \nblood cell count is 6.8 (which is found by substituting x = 80 in the regression equation). \nFor x = 80, the “best” predicted white blood cell count is 6.8, but we have no sense of the \naccuracy of that estimate, so we need an interval estimate. A prediction interval estimate of \na predicted value yn can be found using the components in the following Key Elements box. \nGiven the nature of the calculations, the use of technology is strongly recommended.\nPrediction Intervals\nObjective\nFind a prediction interval, which is an interval estimate of a predicted value of y.\nRequirement\nFor each fixed value of x, the corresponding sample values of y are normally distributed about the regression line, and \nthose normal distributions have the same variance.\nFormulas for Creating a Prediction Interval\nGiven a fixed and known value x0, the prediction interval for an individual y value is\nyn - E 6 y 6 yn + E\nwhere the margin of error is\nE = ta>2 seB1 + 1\nn +\nn1x0 - x 2 2\nn1Σx22 - 1Σx2 2\nand x0 is a given value of x, ta>2 has n − 2 degrees of free-\ndom, and se is the standard error of estimate found from \nFormula 10-5 or Formula 10-6. (The standard error of es-\ntimate se is a measure of variation of the residuals, which \nare the differences between the observed sample y values \nand the predicted values yn that are found from the regres-\nsion equation.)\nKEY ELEMENTS\nFORMULA 10-5 \n \n \n se = B\nΣ1 y - yn2 2\nn - 2\nFORMULA  10-6     se = B\nΣy2 - b0Σy - b1Σxy\nn - 2\n(This is an equivalent form of Formula 10-5 that is \ngood for manual calculations.)\nEXAMPLE 1   Pulse Rates and White Blood Cell Counts:  \nFinding a Prediction Interval\nFor the 147 pairs of pulse rates and white blood cell counts for females from Data \nSet 1 “Body Data” in Appendix B, we found that there is sufficient evidence to sup-\nport the claim of a linear correlation between those two variables, and the regression \nequation is yn = 4.06 + 0.0345x. For a female with a pulse rate of 80, the best pre-\ndicted white blood cell count is 6.8 (found by substituting x = 80 in the regression \nequation). For a female with pulse rate of 80, construct a 95% prediction interval \nfor the white blood cell count.\ncontinued\n\n476 \nCHAPTER 10 Correlation and Regression\nSOLUTION\nThe accompanying StatCrunch and Minitab displays provide the 95% prediction \ninterval, which is 3.0 6 y 6 10.6 when rounded.\nMinitab\nStatCrunch\nThe same 95% prediction interval could be manually calculated using these components:\nx0 = 80 (given)\nse = 1.92241 (provided by many technologies, including Statdisk, Minitab,  \n   Excel, StatCrunch, and TI-83>84 Plus calculator)\nyn = 6.82624 (predicted value of y found by substituting x = 80 into the  \n  regression equation)\nta>2 = 1.976 (with df = 145 and an area of 0.05 in two tails)\nn = 147, x = 74.04082, Σx = 10,884, Σx2 = 828,832\nINTERPRETATION\nThe 95% prediction interval is 3.0 6 y 6 10.6. This means that if we select a \nrandom female with a pulse rate of 80 (x = 80), we have 95% confidence that the \nlimits of 3.0 and 10.6 contain the white blood cell count. That is a wide range of \nvalues. The prediction interval would be much narrower and our estimated white \nblood cell count would be much better if the linear correlation were much stronger.\nExplained and Unexplained Variation\nAssume that we have a sample of paired data having the following properties shown \nin Figure 10-7:\n \n■There is sufficient evidence to support the claim of a linear correlation  \nbetween x and y.\n \n■The equation of the regression line is yn = 3 + 2x.\n \n■The mean of the y values is given by y = 9.\n \n■One of the pairs of sample data is x = 5 and y = 19.\n \n■The point (5, 13) is one of the points on the regression line, because substituting \nx = 5 into the regression equation of yn = 3 + 2x yields yn = 13.\nFigure 10-7 shows that the point (5, 13) lies on the regression line, but the point \n(5, 19) from the original data set does not lie on the regression line. If we completely ignore \ncorrelation and regression concepts and want to predict a value of y given a value of x \nand a collection of paired (x, y) data, our best guess would be the mean y = 9. But in \nthis case there is a linear correlation between x and y, so a better way to predict the value \nof y when x = 5 is to substitute x = 5 into the regression equation to get yn = 13. We \ncan explain the discrepancy between y = 9 and yn = 13 by noting that there is a linear \nrelationship best described by the regression line. Consequently, when x = 5, the pre-\ndicted value of y is 13, not the mean value of 9. For x = 5, the predicted value of y is 13, \n\n10-3 Prediction Intervals and Variation \n477\nbut the observed sample value of y is actually 19. The discrepancy between yn = 13 and \ny = 19 cannot be explained by the regression line, and it is called a residual or unex-\nplained deviation, which can be expressed in the general format of y - yn.\nAs in Section 3-2 where we defined the standard deviation, we again consider \na deviation to be a difference between a value and the mean. (In this case, the \nmean is y = 9.) Examine Figure 10-7 carefully and note these specific deviations \nfrom y = 9:\nTotal deviation 1from y = 92 of the point 15, 192 = y - y = 19 - 9 = 10\nExplained deviation 1from y = 92 of the point 15, 192 = yn - y = 13 - 9 = 4\nUnexplained deviation 1from y = 92 of the point 15, 192 = y - yn = 19 - 13 = 6\nThese deviations from the mean are generalized and formally defined as follows.\nExplained\ndeviation\n(y – y)\ny = 3 + 2x\n0\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n0\n1\n2\n3\n4\n5\n6\n7\n8\n9\n(5, 9)\n(5, 13)\n(5, 19)\nTotal\ndeviation\n(y – y)\nUnexplained\ndeviation\n(y – y)\ny = 9\nx\ny\nˆ\nˆ\nˆ\nFIGURE 10-7 Total, Explained, and Unexplained Deviation\nDEFINITIONS\nAssume that we have a collection of paired data containing the sample point (x, y), \nthat yn is the predicted value of y (obtained by using the regression equation), and \nthat the mean of the sample y values is y.\nThe total deviation of (x, y) is the vertical distance y - y, which is the distance  \nbetween the point (x, y) and the horizontal line passing through the sample mean y.\nThe explained deviation is the vertical distance yn - y, which is the distance be-\ntween the predicted y value and the horizontal line passing through the sample \nmean y.\nThe unexplained deviation is the vertical distance y - yn, which is the vertical dis-\ntance between the point (x, y) and the regression line. (The distance y - yn is also \ncalled a residual, as defined in Section 10-2.)\nIn Figure 10-7 we can see the following relationship for an individual point (x, y):\n1total deviation2 = 1explained deviation2 + 1unexplained deviation2\n1y - y2   =    \n1yn - y2    +     1y - yn2\nIs It Ethical to Experiment \nwith Prisoners?\nThere was a \ntime when \ncompanies were \nallowed to con-\nduct research \non prisoners. \nFor example, \nbetween 1962 and 1966,  \n33 pharmaceutical companies \ntested 153 experimental drugs on \nprisoners at Holmesburg Prison in \nPhiladelphia (based on data from \n“Biomedical Research Involving \nPrisoners,” by Lawrence Gostin, \nJournal of the American Medical \nAssociation, Vol. 297, No. 7).\nThe Common Rule has been \nestablished in the United States \nas the standard of ethics for bio-\nmedical and behavioral research \ninvolving human subjects. Central \nto the Common Rule are these \nrequirements: (1) Participating \nsubjects are selected equitably \nand give their fully informed, fully \nvoluntary written consent; (2) pro-\nposed research must be reviewed \nby an independent oversight \ngroup and approved only if risks \nto subjects have been minimized \nand are reasonable in relation to \nanticipated benefits, if any, to the \nsubjects, and the importance of \nthe knowledge that may reason-\nably be expected to result. The \ndetailed text of the Common Rule \ncan be found on the U.S. Depart-\nment of Health & Human Services \nwebsite at www.hhs.gov.\n\n478 \nCHAPTER 10 Correlation and Regression\nThe previous expression involves deviations away from the mean, and it applies to any \none particular point (x, y). If we sum the squares of deviations using all points (x, y), we \nget amounts of variation. The same relationship applies to the sums of squares shown in \nFormula 10-7, even though the expression is not algebraically equivalent to Formula 10-7. \nIn Formula 10-7, the total variation is the sum of the squares of the total deviation values, \nthe explained variation is the sum of the squares of the explained deviation values, and the \nunexplained variation is the sum of the squares of the unexplained deviation values.\nFORMULA 10-7\n1total variation2 = 1explained variation2 + 1unexplained variation2\nΣ1y - y2 2  =   \nΣ1yn - y2 2    +    \nΣ1y - yn2 2\nCoefficient of Determination\nIn Section 10-1 we saw that the linear correlation coefficient r can be used to find the \nproportion of the total variation in y that can be explained by the linear correlation. \nThis statement was made in Section 10-1:\nThe value of r2 is the proportion of the variation in y that is explained by the \nlinear relationship between x and y.\nThis statement about the explained variation is formalized with the following definition.\nDEFINITION\nThe coefficient of determination is the proportion of the variation in y that is  \nexplained by the regression line. It is computed as\nr 2 = explained variation\ntotal variation\nWe can compute r2 by using the definition just given with Formula 10-7, or we \ncan simply square the linear correlation coefficient r. Go with squaring r.\nEXAMPLE 2   Pulse Rates and White Blood Cell Counts:  \nFinding a Coefficient of Determination\nIf we use the 147 pairs of pulse rates and white blood cell counts of females in  \nData Set 1 “Body Data” in Appendix B, we find that the linear correlation coeffi-\ncient is r = 0.221. Find the coefficient of determination. Also, find the percentage \nof the total variation in y (white blood cell count) that can be explained by the linear \ncorrelation between pulse rate and white blood cell count.\nSolution\nWith r = 0.221 the coefficient of determination is r2 = 0.049.\nINTERPRETATION\nBecause r2 is the proportion of total variation that can be explained, we conclude \nthat 4.9% of the total variation in the white blood cell count can be explained by \npulse rate, and the other 95.1% cannot be explained by pulse rate. The other 95.1% \nmight be explained by some other factors and>or random variation.\n\n10-3 Prediction Intervals and Variation \n479\nStatistical Literacy and Critical Thinking\n1. se Notation Using Data Set 1 “Body Data” in Appendix B, if we let the predictor variable \nx represent heights of males and let the response variable y represent weights of males, the \nsample of 153 heights and weights results in se = 16.27555 cm. In your own words, describe \nwhat that value of se represents.\n2. Prediction Interval Using the heights and weights described in Exercise 1, a height of \n180 cm is used to find that the predicted weight is 91.3 kg, and the 95% prediction interval \nis (59.0 kg, 123.6 kg). Write a statement that interprets that prediction interval. What is the \nmajor advantage of using a prediction interval instead of simply using the predicted weight of \n91.3 kg? Why is the terminology of prediction interval used instead of confidence interval?\n3. Coefficient of Determination Using the heights and weights described in Exercise 1, the \nlinear correlation coefficient r is 0.394. Find the value of the coefficient of determination. What \npractical information does the coefficient of determination provide?\n4. Standard Error of Estimate A random sample of 118 different female statistics students \nis obtained, and their weights are measured in kilograms and in pounds. Using the 118 paired \nweights (weight in kg, weight in lb), what is the value of se? For a female statistics student who \nweighs 100 lb, the predicted weight in kilograms is 45.4 kg. What is the 95% prediction interval?\nInterpreting the Coefficient of Determination. In Exercises 5–8, use the value of the  \nlinear correlation coefficient r to find the coefficient of determination and the percentage of \nthe total variation that can be explained by the linear relationship between the two variables.\n5. Crickets and Temperature r = 0.874 (x = number of cricket chirps in 1 minute, \ny = temperature in oF)\n6. Weight , Waist r = 0.885 1x = weight of male, y = waist size of male2\n7. Bear Neck Size and Weight r = 0.934 (x = neck size, y = weight)\n8. Bears r = 0.783 1x = head width of a bear, y = weight of a bear2\nInterpreting a Computer Display. In Exercises 9–12, refer to the display obtained by using \nthe paired data consisting of Florida registered boats (tens of thousands) and numbers  \nof manatee deaths from encounters with boats in Florida for different recent years (from  \nData Set 12 in Appendix B). Along with the paired boat, manatee sample data, StatCrunch was \nalso given the value of 85 (tens of thousands) boats to be used for predicting manatee fatalities.\n10-3 Basic Skills and Concepts\nStatCrunch\n9. Testing for Correlation Use the information provided in the display to determine the value \nof the linear correlation coefficient. Is there sufficient evidence to support a claim of a linear \ncorrelation between numbers of registered boats and numbers of manatee deaths from encoun-\nters with boats?\nPrediction Intervals\nAccess tech instructions, videos, and data sets at www.TriolaStats.com\nTECH CENTER \n\n480 \nCHAPTER 10 Correlation and Regression\n10. Identifying Total Variation What percentage of the total variation in manatee fatalities \ncan be explained by the linear correlation between registered boats and manatee fatalities?\n11. Predicting Manatee Fatalities Using x = 85 (for 850,000 registered boats), what is the \nsingle value that is the best predicted number of manatee fatalities resulting from encounters \nwith boats?\n12. Finding a Prediction Interval For a year with 850,000 (x = 85) registered boats in \nFlorida, identify the 95% prediction interval estimate of the number of manatee fatalities result-\ning from encounters with boats. Write a statement interpreting that interval.\nFinding a Prediction Interval. In Exercises 13–16, use the paired data consisting of \nregistered Florida boats (tens of thousands) and manatee fatalities from boat encounters \nlisted in Data Set 12 “Manatee Deaths” in Appendix B. Let x represent number of regis-\ntered boats and let y represent the corresponding number of manatee deaths. Use the given \nnumber of registered boats and the given confidence level to construct a prediction interval \nestimate of manatee deaths.\n13. Boats Use x = 85 (for 850,000 registered boats) with a 99% confidence level.\n14. Boats Use x = 98 (for 980,000 registered boats) with a 95% confidence level.\n15. Boats Use x = 96 (for 960,000 registered boats) with a 95% confidence level.\n16. Boats Use x = 87 (for 870,000 registered boats) with a 99% confidence level.\nVariation and Prediction Intervals. In Exercises 17–20, find the (a) explained varia-\ntion, (b) unexplained variation, and (c) indicated prediction interval. In each case, there is \nsufficient evidence to support a claim of a linear correlation, so it is reasonable to use the \nregression equation when making predictions.\n17. Blood Pressure The table below lists systolic blood pressures (mm Hg) and diastolic blood \npressures (mm Hg) of adult females (from Data Set 1 “Body Data” in Appendix B). For the pre-\ndiction interval, use a systolic blood pressure of 120 mm Hg and use a 95% confidence level.\nSystolic\n126\n104\n130\n106\n158\n96\n156\n112\n122\n114\n102\n126\nDiastolic\n 70\n 66\n 74\n 64\n 74\n52\n 90\n 70\n 68\n 74\n 60\n 68\n18. Tree Circumference and Height The table below lists circumferences (in feet) and the \nheights (in feet) of trees in Marshall, Minnesota (based on data from “Tree Measurements,” \nby Stanley Rice, American Biology Teacher, Vol. 61, No. 9). For the prediction interval, use a \ncircumference of 4.0 ft and use a 99% confidence level. Comment on the range of values in the \nprediction interval.\nCircumference\n1.8\n1.9\n1.8\n2.4\n5.1\n3.1\n5.5\n5.1\n8.3\n13.7\n5.3\n4.9\nHeight\n21.0\n33.5\n24.6\n40.7\n73.2\n24.9\n40.4\n45.3\n53.5\n93.8\n64.0\n62.7\n19. Crickets and Temperature The table below lists numbers of cricket chirps in 1 minute \nand the temperature in oF. For the prediction interval, use 1000 chirps in 1 minute and use a \n90% confidence level.\nChirps in 1 min\n882\n1188\n1104\n864\n1200\n1032\n960\n900\nTemperature 1°F2\n69.7\n93.3\n84.3\n76.3\n88.6\n82.6\n71.6\n79.6\n20. Weighing Seals with a Camera The table below lists overhead widths (cm) of seals \nmeasured from photographs and the weights (kg) of the seals (based on “Mass Estimation of \nWeddell Seals Using Techniques of Photogrammetry,” by R. Garrott of Montana State Univer-\nsity). For the prediction interval, use a 99% confidence level with an overhead width of 9.0 cm.\nOverhead Width\n7.2\n7.4\n9.8\n9.4\n8.8\n8.4\nWeight\n116\n154\n245\n202\n200\n191\n\n10-4 Multiple Regression \n481\n21. Confidence Interval for Mean Predicted Value Example 1 in this section illustrated the \nprocedure for finding a prediction interval for an individual value of y. When using a specific \nvalue x0 for predicting the mean of all values of y, the confidence interval is as follows:\nyn - E 6 y 6 yn + E\nwhere\nE =  ta>2 # se B\n1\nn +\nn1x0 - x2 2\nn1Σx22 - 1Σx2 2\nThe critical value ta>2 is found with n - 2 degrees of freedom. Using the 147 pairs of pulse \nrates and white blood cell counts of females in Data Set 1 “Body Data” in Appendix B, find a \n95% confidence interval estimate of the mean white blood cell count given that a female has a \npulse rate of (a) 80 beats per minute and (b) 70 beats per minute.\n10-3 Beyond the Basics\nKey Concept So far in this chapter we have discussed the linear correlation between \ntwo variables, but this section presents methods for analyzing a linear relationship \nwith more than two variables. We focus on these two key elements: (1) finding the \nmultiple regression equation and (2) using the value of adjusted R2 and the P-value as \nmeasures of how well the multiple regression equation fits the sample data. Because \nthe required calculations are so difficult, manual calculations are impractical, so this \nsection emphasizes the use and interpretation of results from technology.\nAs in the preceding sections of this chapter, we will consider linear relationships \nonly. The following multiple regression equation describes linear relationships involv-\ning more than two variables.\n10-4 \nMultiple Regression\nDEFINITION\nA multiple regression equation expresses a linear relationship between a response \nvariable y and two or more predictor variables (x1, x2, . . . , xk). The general form of a \nmultiple regression equation obtained from sample data is\nyn = b0 + b1x1 + b2x2 + g + bkxk\nThe following Key Elements box includes the key components of this section. \nFor notation, see that the coefficients b0, b1, b2, c, bk are sample statistics used to \nestimate the corresponding population parameters b0, b1, b2, c, bk. Also, note that \nthe multiple regression equation is a natural extension of the format yn = b0 + b1x1\nused in Section 10-2 for regression equations with a single independent variable x1. \nIn Section 10-2, it would have been reasonable to question why we didn’t use the \nmore common and familiar format of y = mx + b, and we can now see that using \nyn = b0 + b1x1 allows us to easily extend that format to include additional predictor \nvariables.\n\n482 \nCHAPTER 10 Correlation and Regression\nFinding a Multiple Regression Equation\nObjective\nUse sample matched data from three or more variables to find a multiple regression equation that is useful for predicting \nvalues of the response variable y.\nNotation\nyn = b0 + b1x1 + b2x2 + g + bk xk (multiple regression equation found from sample data)\ny = b0 + b1x1 + b2x2 + g + bk xk (multiple regression equation for the population of data)\nyn = predicted value of y (computed using the multiple regression equation)\nk = number of predictor variables (also called independent variables or x variables)\nn = sample size (number of values for any one of the variables)\nRequirements\nFor any specific set of x values, the regression equation is associated with a random error often denoted by e. We assume \nthat such errors are normally distributed with a mean of 0 and a standard deviation of s and that the random errors are \nindependent.\nProcedure for Finding a Multiple Regression Equation\nManual calculations are not practical, so technology must be used.\nKEY ELEMENTS\nEXAMPLE 1  Predicting Weight\nData Set 1 “Body Data” includes heights (cm), waist circumferences (cm), and \nweights (kg) from a sample of 153 males. Find the multiple regression equation in \nwhich the response variable (y) is the weight of a male and the predictor variables \nare height (x1) and waist circumference (x2).\nSOLUTION\nUsing Statdisk with the sample data in Data Set 1 “Body Data,” we obtain the  \nresults shown in the display on the top of the next page. The coefficients b0, b1, and \nb2 are used in the multiple regression equation:\n  yn = -149 + 0.769x1 + 1.01x2\nor \nWeight = -149 + 0.769 Height + 1.01 Waist\nThe obvious advantage of the second format above is that it is easier to keep track \nof the roles that the variables play.\n\n10-4 Multiple Regression \n483\nStatdisk\nIf a multiple regression equation fits the sample data well, it can be used for predic-\ntions. For example, if we determine that the multiple regression equation in Example 1 is \nsuitable for predictions, we can use the height and waist circumference of a male to predict \nhis weight. But how do we determine whether the multiple regression equation fits the \nsample data well? Two very helpful tools are the values of adjusted R2 and the P-value.\nR2 and Adjusted R2\nR2 denotes the multiple coefficient of determination, which is a measure of how well \nthe multiple regression equation fits the sample data. A perfect fit would result in R2 = 1,\nand a very good fit results in a value near 1. A very poor fit results in a value of R2 close \nto 0. The value of R2 = 0.878 (“Coeff of Det, R2”) in the Statdisk display for Example 1 \nindicates that 87.8% of the variation in weights of males can be explained by their heights \nand waist circumferences. However, the multiple coefficient of determination R2 has a se-\nrious flaw: As more variables are included, R2 increases. (R2 could remain the same, but it \nusually increases.) The largest R2 is obtained by simply including all of the available vari-\nables, but the best multiple regression equation does not necessarily use all of the available \nvariables. Because of that flaw, it is better to use the adjusted coefficient of determination, \nwhich is R2 adjusted for the number of variables and the sample size.\nDEFINITION\nThe adjusted coefficient of determination is the multiple coefficient of determina-\ntion R2 modified to account for the number of variables and the sample size. It is \ncalculated by using Formula 10-8.\nFORMULA 10-8\nAdjusted R2 = 1 -\n1n - 12\n3n - 1k + 12 4 11 - R22\nwhere\n n = sample size\n k = number of predictor 1x2 variables\n\n484 \nCHAPTER 10 Correlation and Regression\nThe preceding Statdisk display shows the adjusted coefficient of determination as \n“Adjusted R^2” = 0.877 (rounded). If we use Formula 10-8 with R2 = 0.8783478,\nn = 153, and k = 2, we get adjusted R2 = 0.877 (rounded). When comparing this \nmultiple regression equation to others, it is better to use the adjusted R2 of 0.877. \nWhen considering the adjusted R2 of 0.877 by itself, we see that it is fairly high (close \nto 1), suggesting that the regression equation is a good fit with the sample data.\nP-Value\nThe P-value is a measure of the overall significance of the multiple regression equa-\ntion. The displayed P-value of 0 (rounded) is small, indicating that the multiple re-\ngression equation has good overall significance and is usable for predictions. We can \npredict weights of males based on their heights and waist circumferences. Like the \nadjusted R2, this P-value is a good measure of how well the equation fits the sample \ndata. The P-value results from a test of the null hypothesis that b1 = b2 = 0. Rejec-\ntion of b1 = b2 = 0 implies that at least one of b1 and b2 is not 0, indicating that this \nregression equation is effective in predicting weights of males. A complete analysis \nof results might include other important elements, such as the significance of the in-\ndividual coefficients, but we are keeping things simple (!) by limiting our discussion \nto the three key components—multiple regression equation, adjusted R2, and P-value.\nFinding the Best Multiple Regression Equation\nWhen trying to find the best multiple regression equation, we should not necessarily \ninclude all of the available predictor variables. Finding the best multiple regression \nequation requires abundant use of judgment and common sense, and there is no exact \nand automatic procedure that can be used to find the best multiple regression equa-\ntion. Determination of the best multiple regression equation is often quite difficult and \nis beyond the scope of this section, but the following guidelines are helpful.\nGuidelines for Finding the Best Multiple Regression Equation\n1. Use common sense and practical considerations to include or exclude vari-\nables. For example, when trying to find a good multiple regression equation for \npredicting the height of a daughter, we should exclude the height of the physi-\ncian who delivered the daughter, because that height is obviously irrelevant.\n2. Consider the P-value.  Select an equation having overall significance, as deter-\nmined by a low P-value found in the technology results display.\n3. Consider equations with high values of adjusted R2, and try to include \nonly a few variables. Instead of including almost every available variable, \ntry to include relatively few predictor (x) variables. Use these guidelines:\n \n■Select an equation having a value of adjusted R2 with this property: If an \nadditional predictor variable is included, the value of adjusted R2 does not \nincrease very much.\n \n■For a particular number of predictor (x) variables, select the equation with the \nlargest value of adjusted R2.\n \n■In excluding predictor (x) variables that don’t have much of an effect on the \nresponse (y) variable, it might be helpful to find the linear correlation coef-\nficient r for each pair of variables being considered. If two predictor values \nhave a very high linear correlation coefficient (called multicollinearity), there \nis no need to include them both, and we should exclude the variable with the \nlower value of adjusted R2.\nThe following example illustrates that common sense and critical thinking are es-\nsential tools for effective use of methods of statistics.\n\n10-4 Multiple Regression \n485\nTABLE 10-4 Selected Results from Data Set 7 “Foot and Height” in Appendix B\nPredictor Variables\nAdjusted R2\nP-Value\nAge\n0.1772\n0.004\nd Not best: Adjusted R2 is far less than \n0.7014 for Foot Length.\nFoot Length\n0.7014\n0.000\nd Best: High adjusted R2 and lowest \nP-value.\nShoe Print Length\n0.6520\n0.000\nd Not best: Adjusted R2 is less than \n0.7014 for Foot Length.\nFoot Length>Shoe \nPrint Length\n0.7484\n0.000\nd Not best: The adjusted R2 value is not \nvery much higher than 0.7014 for the single \nvariable of Foot Length.\nAge>Foot Length>\nShoe Print Length>\nShoe Size\n0.7585\n0.000\nd Not best: There are other cases using \nfewer variables with adjusted R2 that are \nnot too much smaller.\nEXAMPLE 2  Predicting Height from Footprint Evidence\nData Set 7 “Foot and Height” in Appendix B includes the age, foot length, shoe \nprint length, shoe size, and height for each of 40 different subjects. Using those \nsample data, find the regression equation that is best for predicting height. Is the \n“best” regression equation a good equation for predicting height?\nSOLUTION\nUsing the response variable of height and possible predictor variables of age, foot \nlength, shoe print length, and shoe size, there are 15 different possible combinations \nof predictor variables. Table 10-4 includes key results from five of those combinations. \nBlind and thoughtless application of regression methods would suggest that the best \nregression equation uses all four of the predictor variables, because that combination \nyields the highest adjusted R2 value of 0.7585. However, given the objective of using \nevidence to estimate the height of a suspect, we use critical thinking as follows.\n \n1. Delete the variable of age, because criminals rarely leave evidence identifying \ntheir ages.\n \n2. Delete the variable of shoe size, because it is really a rounded form of  \nfoot length.\n \n3. For the remaining variables of foot length and shoe print length, use only foot \nlength because its adjusted R2 value of 0.7014 is greater than 0.6520 for shoe \nprint length, and it is not very much less than the adjusted R2 value of 0.7484 \nfor both foot length and shoe print length. In this case, it is better to use one \npredictor variable instead of two.\n \n4. Although it appears that the use of the single variable of foot length is best, \nwe also note that criminals usually wear shoes, so shoe print lengths are more \nlikely to be found than foot lengths.\nINTERPRETATION\nBlind use of regression methods suggests that when estimating the height of a sub-\nject, we should use all of the available data by including all four predictor variables \nof age, foot length, shoe print length, and shoe size, but other practical consider-\nations suggest that it is best to use the single predictor variable of foot length. So the \nbest regression equation appears to be this: Height = 64.1 + 4.29 (Foot Length). \nHowever, given that criminals usually wear shoes, it is best to use the single predictor \ncontinued\n\n486 \nCHAPTER 10 Correlation and Regression\nvariable of shoe print length, so the best practical regression equation appears to be \nthis: Height = 80.9 + 3.22 (Shoe Print Length). The P-value of 0.000 suggests that \nthe regression equation yields a good model for estimating height.\nBecause the results of this example are based on sample data from only 40 \nsubjects, estimates of heights will not be very accurate. As is usually the case, better \nresults could be obtained by using larger samples.\nTests of Regression Coefficients The preceding guidelines for finding the best \nmultiple regression equation are based on the adjusted R2 and the P-value, but we \ncould also conduct individual hypothesis tests based on values of the regression coef-\nficients. Consider the regression coefficient of b1. A test of the null hypothesis b1 = 0\ncan tell us whether the corresponding predictor variable should be included in the \nregression equation. Rejection of b1 = 0 suggests that b1 has a nonzero value and is \ntherefore helpful for predicting the value of the response variable. Procedures for such \ntests are described in Exercise 17.\nPredictions With Multiple Regression\nWhen we discussed regression in Section 10-2, we listed (on page 466) four points \nto consider when using regression equations to make predictions. These same points \nshould be considered when using multiple regression equations.\nStatistical Literacy and Critical Thinking \n1. Terminology Using the lengths (in.), chest sizes (in.), and weights (lb) of bears from Data \nSet 11 “Bear Measurements” in Appendix B, we get this regression equation: Weight =\n-274 + 0.426 Length + 12.1 Chest Size. Identify the response and predictor variables.\n2. Best Multiple Regression Equation For the regression equation given in Exercise 1, the \nP-value is 0.000 and the adjusted R2 value is 0.925. If we were to include an additional predic-\ntor variable of neck size (in.), the P-value becomes 0.000 and the adjusted R2 becomes 0.933. \nGiven that the adjusted R2 value of 0.933 is larger than 0.925, is it better to use the regression \nequation with the three predictor variables of length, chest size, and neck size? Explain.\n3. Adjusted Coefficient of Determination For Exercise 2, why is it better to use values of \nadjusted R2 instead of simply using values of R2?\n4. Interpreting R2 For the multiple regression equation given in Exercise 1, we get \nR2 = 0.928. What does that value tell us?\nInterpreting a Computer Display. In Exercises 5–8, we want to consider the correlation \nbetween heights of fathers and mothers and the heights of their sons. Refer to the following \nStatCrunch display and answer the given questions or identify the indicated items.  \nThe display is based on Data Set 6 “Family Heights” in Appendix B.\n10-4 Basic Skills and Concepts\nMultiple Regression\nAccess tech instructions, videos, and data sets at www.TriolaStats.com\nTECH CENTER \n\n10-4 Multiple Regression \n487\n5. Height of Son Identify the multiple regression equation that expresses the height of a son in \nterms of the height of his father and mother.\n6. Height of Son Identify the following:\na. The P-value corresponding to the overall significance of the multiple regression equation\nb. The value of the multiple coefficient of determination R2\nc. The adjusted value of R2\n7. Height of Son Should the multiple regression equation be used for predicting the height of \na son based on the height of his father and mother? Why or why not?\n8. Height of Son A son will be born to a father who is 70 in. tall and a mother who is 60 in. \ntall. Use the multiple regression equation to predict the height of the son. Is the result likely to \nbe a good predicted value? Why or why not?\nPredicting Weights of Males. In Exercises 9–12, refer to the accompanying table, which \nwas obtained by using the data for males in Data Set 1 “Body Data” in Appendix B. The \nresponse (y) variable is weight (kg), and the predictor (x) variables are HT (height in cm), \nWAIST (waist circumference in cm), and ARM (arm circumference in cm).\nPredictor (x) Variables\nP-Value\nR2\nAdjusted R2\nRegression Equation\nHT, WAIST, ARM\n0.000\n0.941\n0.939\nyn = -147 + 0.632 HT +\n0.697 WAIST + 1.58 ARM\nHT, WAIST\n0.000\n0.878\n0.877\nyn = -149 + 0.769 HT + 1.01 WAIST\nHT, ARM\n0.000\n0.777\n0.774\nyn = -124 + 0.541 HT + 3.44 ARM\nWAIST, ARM\n0.000\n0.879\n0.878\nyn = -45.0 + 0.659 WAIST + 1.92 ARM\nHT\n0.000\n0.155\n0.150\nyn = -85.1 + 0.980 HT\nWAIST\n0.000\n0.784\n0.782\nyn = -19.1 + 1.05 WAIST\nARM\n0.000\n0.732\n0.731\nyn = -37.1 + 3.65 ARM\n9. If only one predictor (x) variable is used to predict weight, which single variable is best? Why?\n10. If exactly two predictor (x) variables are to be used to predict weight, which two variables \nshould be chosen? Why?\n11. Which regression equation is best for predicting the weight? Why?\n12. If a male has a height of 186 cm, a waist circumference of 107.8 cm, and an arm circumfer-\nence of 37.0 cm, what is the best predicted weight? Is that predicted value likely to be a good \nestimate? Is that predicted value likely to be very accurate?\n\n488 \nCHAPTER 10 Correlation and Regression\nAppendix B Data Sets. In Exercises 13–16, refer to the indicated data set in Appendix B \nand use technology to obtain results.\n13. Predicting Nicotine in Cigarettes Refer to Data Set 15 “Cigarette Contents” in \nAppendix B and use the tar, nicotine, and CO amounts for the cigarettes that are 100 mm \nlong, filtered, nonmenthol, and nonlight (the last set of measurements). Find the best regression \nequation for predicting the amount of nicotine in a cigarette using the predictor variables of (1) \ntar; (2) carbon monoxide; (3) tar and carbon monoxide. Why is it best? Is the best regression \nequation a good regression equation for predicting the nicotine content? Why or why not?\n14. Predicting Nicotine in Cigarettes Repeat the preceding exercise using the sample data \nfrom the Menthol cigarettes listed in Data Set 15 in Appendix B.\n15. Predicting IQ Score Refer to Data Set 9 “IQ and Brain Size” in Appendix B and find the \nbest regression equation with IQ score as the response (y) variable. Use predictor variables of \nbrain volume and>or body weight. Why is this equation best? Based on these results, can we \npredict someone’s IQ score if we know their brain volume and body weight? Based on these \nresults, does it appear that people with larger brains have higher IQ scores?\n16. Full IQ Score Refer to Data Set 8 “IQ and Lead” in Appendix B and find the best regres-\nsion equation with IQF (full IQ score) as the response (y) variable. Use predictor variables of \nIQV (verbal IQ score) and IQP (performance IQ score). Why is this equation best? Based on \nthese results, can we predict someone’s full IQ score if we know their verbal IQ score and their \nperformance IQ score? Is such a prediction likely to be very accurate?\n10-4 Beyond the Basics\n17. Testing Hypotheses About Regression Coefficients If the coefficient b1 has a nonzero \nvalue, then it is helpful in predicting the value of the response variable. If b1 = 0, it is not helpful \nin predicting the value of the response variable and can be eliminated from the regression equation. \nTo test the claim that b1 = 0 use the test statistic t = 1b1 - 02>sb1. Critical values or P-values \ncan be found using the t distribution with n - 1k + 12 degrees of freedom, where k is the number \nof predictor (x) variables and n is the number of observations in the sample. The standard error sb1 \nis often provided by software. For example, see the accompanying StatCrunch display for \nExample 1, which shows that sb1 = 0.071141412 (found in the column with the heading of “Std. \nErr.” and the row corresponding to the first predictor variable of height). Use the sample data in \nData Set 1 “Body Data” and the StatCrunch display to test the claim that b1 = 0. Also test the \nclaim that b2 = 0. What do the results imply about the regression equation?\n18. Confidence Intervals for Regression Coefficients A confidence interval for the \nregression coefficient b1 is expressed as\nb1 - E 6 b1 6 b1 + E\nwhere\nE = ta>2sb1\nThe critical t score is found using n - (k + 1) degrees of freedom, where k, n, and sb1 are de-\nscribed in Exercise 17. Using the sample data from Example 1, n = 153 and k = 2, so df = 150 \nand the critical t scores are {1.976 for a 95% confidence level. Use the sample data for Example 1, \nthe Statdisk display in Example 1 on page 483, and the StatCrunch display in Exercise 17 to con-\nstruct 95% confidence interval estimates of b1 (the coefficient for the variable representing height) \nand b2 (the coefficient for the variable representing waist circumference). Does either confidence \ninterval include 0, suggesting that the variable be eliminated from the regression equation?\n\n10-5 Dummy Variables and Logistic Regression \n489\nSo far in this chapter, all variables have represented continuous data, but many situa-\ntions involve a variable with only two possible qualitative values (such as male>female \nor dead>alive or cured>not cured). To obtain regression equations that include such \nvariables, we must somehow assign numbers to the two different categories. A com-\nmon procedure is to represent the two possible values by 0 and 1, where 0 represents a \n“failure” and 1 represents a “success.” For disease outcomes, 1 is often used to repre-\nsent the event of the disease or death, and 0 is used to represent the nonevent.\n10-5 \nDummy Variables and Logistic Regression\nDEFINITION\nA dummy variable is a variable having only the values of 0 and 1 that are used to \nrepresent the two different categories of a qualitative variable.\nThe word “dummy” is used because the variable does not actually have any quanti-\ntative value, but we use it as a substitute to represent the different categories of the \nqualitative variable.\nDummy Variable as a Predictor Variable\nProcedures of regression analysis differ dramatically depending on whether the \ndummy variable is a predictor (x) variable or the response (y) variable. If we include \na dummy variable as another predictor (x) variable, we can use the same methods of \nSection 10-4, as illustrated in Example 1.\nEXAMPLE 1  Using a Dummy Variable as a Predictor Variable\nTable 10-5 on the next page is adapted from Data Set 6 “Family Heights” and it \nis in a more convenient format for this example. Use the dummy variable of sex \n(coded as 0 = female, 1 = male). Given that a father is 69 in. tall and a mother is \n63 in. tall, find the multiple regression equation and use it to predict the height of \n(a) a daughter and (b) a son.\nSOLUTION\nUsing the methods of multiple regression from Section 10-4 with technology, we get \nthis regression equation:\nHeight of Child = 36.5 - 0.0336 1Height of Father2 +  \n        0.461 1Height of Mother2 + 6.14 1Sex2 \nwhere the value of the dummy variable of sex is 0 for a daughter or 1 for a son.\n \na. To ﬁnd the predicted height of a daughter, we substitute 0 for the sex variable, \nand we also substitute 69 in. for the father’s height and 63 in. for the mother’s \nheight. The result is a predicted height of 63.2 in. for a daughter.\n \nb. To ﬁnd the predicted height of a son, we substitute 1 for the sex variable, and \nwe also substitute 69 in. for the father’s height and 63 in. for the mother’s \nheight. The result is a predicted height of 69.4 in. for a son.\nThe coefficient of 6.14 in the regression equation shows that when given the height \nof a father and the height of a mother, a son will have a predicted height that is  \n6.14 in. more than the height of a daughter.\ncontinued\n\n490 \nCHAPTER 10 Correlation and Regression\nDummy Variable as a Response Variable: Logistic Regression\nIn Example 1, we could use the same methods of Section 10-4 because the dummy \nvariable of sex is a predictor variable. However, if the dummy variable is the response \n(y) variable, we cannot use the methods of Section 10-4, and we should use a different \nmethod known as logistic regression.\nDEFINITION\nLogistic regression is a procedure used for finding a regression equation in which \nthe response variable is a dummy variable.\nDummy response variables are common in clinical research where the response \nvariable might be the yes>no indication for the occurrence of a disease such as diabe-\ntes, cancer, hypertension, or chronic kidney disease. Other dummy response variables \ninclude yes>no values for hospitalization, death, or need of a kidney transplant. As \nwith dummy predictor variables, dummy response variables are typically coded as 0 \nand 1. For example, the response variable of “hospitalization” could be coded as 1 for \npatients who were hospitalized and 0 for patients who were not hospitalized.\nSimple Logistic Regression We use simple logistic regression when these condi-\ntions are met:\n \n■There is a single predictor x variable.\n \n■The sample y data have values of 0 and 1.\nTABLE 10-5 Heights (in inches) of Fathers, Mothers, and Their Children\nHeight of Father\nHeight of Mother\nHeight of Child\nSex of Child (1 = Male)\n66.5\n62.5\n70.0\n1\n70.0\n64.0\n68.0\n1\n67.0\n65.0\n69.7\n1\n68.7\n70.5\n71.0\n1\n69.5\n66.0\n71.0\n1\n70.0\n65.0\n73.0\n1\n69.0\n66.0\n70.0\n1\n68.5\n67.0\n73.0\n1\n65.5\n60.0\n68.0\n1\n69.5\n66.5\n70.5\n1\n70.5\n63.0\n64.5\n0\n71.0\n65.0\n62.0\n0\n70.5\n62.0\n60.0\n0\n66.0\n66.0\n67.0\n0\n68.0\n61.0\n63.5\n0\n68.0\n63.0\n63.0\n0\n71.0\n62.0\n64.5\n0\n65.5\n63.0\n63.5\n0\n64.0\n60.0\n60.0\n0\n71.0\n63.0\n63.5\n0\n\n10-5 Dummy Variables and Logistic Regression \n491\nInstead of yielding predicted values of y itself, the method of simple logistic regres-\nsion yields an equation with the following format:\n ln a\np\n1 - p b = b0 + b1x\nIn the above expression, p is the probability that y = 1. Given a specific value for x, \nwe can solve for p by first substituting that x value in the right side of the above equa-\ntion to obtain a value v; then we can solve for p by evaluating the following, where \ne = 2.71828:\np =\nev\n1 + ev\nEXAMPLE 2  Simple Logistic Regression\nUse the paired height>gender data from Data Set 1 “Body Data” to find the simple \nlogistic regression equation, and let the response variable (y) be gender with \n0 = female and 1 = male. Then find the probability that a person with a height of \n190 cm (or 74.8 in.) is a male.\nSOLUTION  \nWe can use technology with the gender>height data to find this equation:\n ln a\np\n1 - pb = -40.6 + 0.2421Height2\nGiven a height of x = 190 cm, we substitute that value in the right side of the \nabove equation to get the value v = -40.6 + 0.242(190) = 5.38. We can now \nsolve for p as follows (using e = 2.71828):\np =\nev\n1 + ev =\ne5.38\n1 + e5.38 = 0.995\nOn the basis of this simple logistic regression model, a person with a height of  \n190 cm (or 74.8 in.) has a probability of 0.995 of being a male.\nThe ratio p>(1 - p) is the odds in favor of y = 1 (as defined in Section 4-4), \nand ln(p>(1 - p)) is the natural logarithm of the odds that y = 1. It is the natural \nlogarithm of those odds that are assumed to be linear in x, but the relationship between \nx and p is a curve that is bounded between 0 and 1, as shown in Figure 10-8 on the next \npage. Figure 10-8 uses the same gender>height data from Example 2. The simple logis-\ntic regression curve takes the shape of a stretched-out “S.” See that as x gets smaller, the \ncurve gets closer to 0, but never quite reaches it. Similarly, as x increases, the curve gets \ncloser to 1. The simple logistic regression curve can be thought of as representing prob-\nabilities that y = 1 (male) for each possible value of x (height). In this particular case, x \nand y have a positive relationship, so that as height x increases, the probability of a male \n(y = 1) also increases. This also implies that b1 7 0. If x and y had a negative rela-\ntionship, then the curve would be an inverted S shape; and as x increases, the probabil-\nity that y = 1 would decrease.\n\n492 \nCHAPTER 10 Correlation and Regression\nMultiple Logistic Regression\nWe use multiple logistic regression when there is a dummy response variable and more \nthan one predictor variable. Instead of yielding predicted values of y itself, the method of \nmultiple logistic regression yields an equation with the following format:\n ln a\np\n1 - p b = b0 + b1x1 + b2x2 + c + bkxk\nIn the above expression, p is the probability that y = 1. Given specific values for the \ndifferent x predictor variables, we can solve for p by first substituting those values in \nthe right side of the above equation to obtain a value v; then we can solve for p by \nevaluating the following:\np =\nev\n1 + ev\nFIGURE 10-8 Simple Logistic Regression Curve\nEXAMPLE 3  Multiple Logistic Regression\nLet a sample data set consist of the heights (cm) and arm circumferences (cm) of \nwomen and men as listed in Data Set 1 “Body Data” in Appendix B, and let the  \nresponse y variable represent gender (0 = female, 1 = male). With this list of  \ngenders, heights, and arm circumferences, logistic regression could be used with \nsoftware to obtain this model:\nln a\np\n1 - p b = -40.6 + 0.2421HT2 + 0.001291ArmCirc2\nIn the expression above, p is the probability of a male, so a value of p close to  \n1 indicates that the person is likely a male, and a value of p close to 0 indicates  \nthat the person is not likely a male (so the person is likely to be a female). See the \nfollowing two sets of results.\n \n■If we use the model above and substitute a height of 183 cm (or 72.0 in.) and an \narm circumference of 33 cm (or 13.0 in.), we can solve for p to get p = 0.977, \nindicating that such a large person has a 97.7% chance of being a male.\n \n■In contrast, a small person with a height of 150 cm (or 59.1 in.) and an arm cir-\ncumference of 20 cm (or 7.9 in.) results in a probability of p = 0.014, indicat-\ning that such a small person is very unlikely to be a male.\n\n10-5 Dummy Variables and Logistic Regression \n493\nIn clinical research, there is much interest in finding biomarkers that are good pre-\ndictors of disease. In particular, if it is hypothesized that some new biomarker might \nimprove predictions, one method of testing this hypothesis is to include the biomarker \nas one of the variables in a multiple logistic regression model. The other predictors in \nthe model could be established risk factors, such as age and sex. If the new biomarker \nadds predictive value, then its coefficient in the logistic regression model should be \ndifferent from 0. See Example 4.\nEXAMPLE 4  Multiple Logistic Regression\nResearchers were interested in determining whether “distortion product otoacoustic \nemissions” (DPOAEs) were a useful tool for identification of hearing impairment in \nnewborns. The dummy response variable was hearing impairment (1 = impaired,  \n0 = not impaired), as defined from a gold standard test when the infants were at  \nleast 8 months of age. The multiple logistic regression model included DPOAE  \n(a continuous variable), age (weeks), and sex (0 = female, 1 = male) as predictor \nvariables. Use of multiple logistic regression yielded the following model (based  \non data from “Identification of Neonatal Hearing Impairment,” by Norton et al.,  \nEar and Hearing, Vol. 21):\n ln a\np\n1 - pb = 3.84 - 0.061DPOAE2 + 0.021Sex2 - 0.021Age2\nIn the expression above, p is the probability of hearing impairment. We can obtain \nP-values from statistical software packages, and the above equation resulted in the \nfollowing P-values:\nVariable \nP-Value\nDPOAE \n60.01\nSex \n \n 0.91\nAge \n \n 0.4\nThe P-value for the variable DPOAE is very small, which shows strong evidence \nagainst the null hypothesis that DPOAE is not a predictor of impairment. It appears \nthat DPOAE might be a useful test of hearing impairment in newborns. For the \nvariable Sex, the P-value of 0.91 indicates that we do not have sufficient evidence to \nsupport the claim that sex is a predictor of impairment. Similarly, Age was also not \na statistically significant predictor.\nWhy can’t we use the same regression methods from the preceding sections \nwhen the dummy variable is the response variable? Suppose we have one inde-\npendent variable, and we use the methods of Section 10-2 to find a linear regres-\nsion equation using sample data for which the values of y are all 0’s and 1’s. There \nis nothing that prevents some of the predicted y values from being greater than 1 or \nless than 0, but that would be inconsistent with the requirement that probabilities \nmust be between 0 and 1. See Figure 10-9 on the following page, which shows a \ncontinuous predictor variable x (height) plotted against a dummy response variable \ny (gender with values of 0 = female and 1 = male). Figure 10-9 uses the same \ngender>height data from Example 2. The straight regression line in Figure 10-9 re-\nsults from using the methods of linear regression in Section 10-2. See that the line \n\n494 \nCHAPTER 10 Correlation and Regression\ndips below 0 for small values of x and it rises above 1 for large values of x. These \nresults violate the requirement that probability values must be between 0 and 1. \nThe straight line from linear regression is not a good model here. The S curve from \nlogistic regression (Figure 10-8) is a far better model.\nAssessing the Quality of Predictions When assessing the quality of predictions made \nwith logistic regression, one consideration might be the P-value for the overall sig-\nnificance of the regression equation. Another approach might be use of the Hosmer-\nLemeshow test, which assesses whether the model is calibrated well, which means \nthat the observed risks from the sample data match the predicted risks (or probabili-\nties). But in addition to being well calibrated, the model should discriminate between \nobservations at high risk and those at low risk. The area under the curve (AUC) of a \nreceiver operating characteristic (ROC) curve is also used as a measure of the qual-\nity of the model. These and other more detailed methods are included in many books \ndevoted to logistic regression.\nFIGURE 10-9  Linear Regression Line with a Dummy  \nResponse Variable\nStatistical Literacy and Critical Thinking \n1. Dummy Variable What is a dummy variable?\n2. Logistic Regression What is the fundamental difference between logistic regression and \nlinear regression?\n3. Simple Logistic Regression How is simple logistic regression different from multiple \nlogistic regression?\n4. True or False Determine whether this statement is true or false: If a multiple regression \nequation has a continuous response variable and three predictor variables, including one that is \na dummy variable, then we must use methods of logistic regression because a dummy variable \nis included.\n10-5 Basic Skills and Concepts\n\n10-5 Dummy Variables and Logistic Regression \n495\nIn Exercises 5–8, use the following logistic regression equation found from Data Set 11 \n“Bear Measurements” in Appendix B. The value of p is the probability that the bear is male.\nln a\np\n1 - pb = 2.40 - 0.05531Length2 + 0.008261Weight2\n5. Bears Identify the predictor and response variables. Which of these are dummy variables?\n6. Bears The given regression equation has an overall P-value of 0.218. What does that sug-\ngest about the quality of predictions made using the regression equation?\n7. Bears Use a length of 60 in. and a weight of 300 lb to find the probability that the bear is a \nmale. Also, what is the probability that the bear is a female?\n8. Bears Use a length of 40 in. and a weight of 50 lb to find the probability that the bear is \na male. What is the probability that the bear is a female? Considering the given length and \nweight, what do we know about this bear?\n9. Weight of a Bear Refer to Data Set 11 “Bear Measurements” in Appendix B and use the \nsex, age, and weight of the bears. For sex, let 0 represent female and let 1 represent male. Let-\nting the response (y) variable represent weight, use the variable of age and the dummy variable \nof sex to find the multiple regression equation. Use the equation to find the predicted weight of \na bear with the characteristics given below. Does sex appear to have much of an effect on the \nweight of a bear?\na. Female bear that is 20 years of age\nb. Male bear that is 20 years of age\n10. Sex, Height, and Weight Refer to Data Set 1 “Body Data” in Appendix B and use the sex, \nheight, and weight of the human subjects. Letting the response (y) variable represent weight, \nuse the dummy variable of sex and use the height to find the multiple regression equation. Use \nthe equation to find the predicted weight of a subject with the characteristics given below. Do \nthe results make sense?\na. Female with a height of 170 cm\nb. Male with a height of 170 cm\n11. Sex, Height, and Weight Refer to Data Set 1 “Body Data” in Appendix B and use the \nsex, height, and weight of the human subjects. Letting the response (y) variable represent sex \n(0 = female, 1 = male), use the variables of height and weight to find the multiple regression \nequation. Use the equation to find the probability that the subject is a male, given that the sub-\nject has a height of 170 cm and a weight of 90 kg.\n12. Sex, Height, and Pulse Rate Refer to Data Set 1 “Body Data” in Appendix B and use the \nsex, height, and pulse rate of the human subjects. Letting the response (y) variable represent sex \n(0 = female, 1 = male), use the variables of height and pulse rate to find the multiple regres-\nsion equation. Use the equation to find the probability that the subject is a male, given that the \nsubject has a height of 170 cm and a pulse rate of 60 beats per minute. Do higher pulse rates \nmake males more likely or less likely?\n13. Sex, Foot Length, and Height Refer to Data Set 7 “Foot and Height” in Appendix B and \nuse the sex, foot length, and height of the subjects. Letting the response (y) variable represent \nsex (0 = female, 1 = male), use the variables of foot length and height to find the multiple \nregression equation. Use the equation to find the probability that the subject is a male, given \nthat the subject has a foot length of 28 cm and a height of 190 cm.\n14. Sex, Shoe Size, and Height Refer to Data Set 7 “Foot and Height” in Appendix B and \nuse the sex, shoe size, and height of the subjects. Letting the response (y) variable represent sex \n(0 = female, 1 = male), use the variables of shoe size and height to find the multiple regres-\nsion equation. Use the equation to find the probability that the subject is a male, given that the \nsubject has a shoe size of 9 and a height of 170 cm. Are predictions of sex made using shoe size \nand height likely to be more or less accurate than predictions of sex made using foot length and \nheight (as in the preceding exercise)?\n\n496 \nCHAPTER 10 Correlation and Regression\nThe following exercises are based on the following sample data consisting of systolic blood \npressure measurements (in mm Hg) obtained from the same woman (based on data from \n“Consistency of Blood Pressure Differences Between the Left and Right Arms,” by Eguchi \net al., Archives of Internal Medicine, Vol. 167).\nRight Arm\n102\n101\n 94\n 79\n 79\nLeft Arm\n175\n169\n182\n146\n144\n1. Conclusion The linear correlation coefficient r is found to be 0.867, the P-value is 0.057, \nand the critical values for a 0.05 significance level are {0.878. If you are using a 0.05 signifi-\ncance level, what should you conclude?\n2. Switched Variables Which of the following change if the two variables of right arm and \nleft arm blood pressure measurements are switched: the value of r = 0.867, the P-value of \n0.057, the critical values of {0.878?\n3. Change in Scale Exercise 1 stated that r is found to be 0.867. How does the value of r \nchange if the scale for the right arm measurements is changed from mm Hg to in. Hg, so that all \nof the values for the right arm are multiplied by 0.0394?\n4. Values of r If you had computed the value of the linear correlation coefficient to be 1.500, \nwhat should you conclude?\n5. Predictions The sample data result in a linear correlation coefficient of r = 0.867 and the \nregression equation yn = 43.6 + 1.31x. What is the best predicted value for the left arm given \nthat the measurement for the right arm is 100 mm Hg?\n6. Predictions Repeat the preceding exercise, assuming that the linear correlation coefficient \nfor the paired sample data is r = 0.997.\n7. Explained Variation Given that the linear correlation coefficient r is found to be 0.867, \nwhat is the proportion of the variation in left arm measurements that is explained by the rela-\ntionship between the right and left arm measurements?\n8. Linear Correlation and Relationships True or false: If there is no linear correlation be-\ntween right arm measurements and left arm measurements, then those two variables are not \nrelated in any way.\n9. Causality True or false: If the sample data lead us to conclude that there is sufficient evi-\ndence to support the claim of a linear correlation between right and left arm measurements, \nthen we could also conclude that increases in right arm measurements cause increases in left \narm measurements.\n10. Interpreting Scatterplot If the sample data were to result in the scatterplot shown here, \nwhat is the value of the linear correlation coefficient r?\nChapter Quick Quiz\n\n1. Cigarette Tar and Nicotine The table below lists measured amounts (mg) of tar, carbon \nmonoxide (CO), and nicotine in king size cigarettes of different brands (from Data Set 15 \n“Cigarette Contents”).\na. Is there is sufficient evidence to support a claim of a linear correlation between tar and nicotine?\nb. What percentage of the variation in nicotine can be explained by the linear correlation \nbetween nicotine and tar?\nc. Letting y represent the amount of nicotine and letting x represent the amount of tar, identify \nthe regression equation.\nd. The Raleigh brand king size cigarette is not included in the table, and it has 23 mg of tar. \nWhat is the best predicted amount of nicotine? How does the predicted amount compare to the \nactual amount of 1.3 mg of nicotine?\nTar\n25\n27\n20\n24\n20\n20\n21\n24\nCO\n18\n16\n16\n16\n16\n16\n14\n17\nNicotine\n1.5\n1.7\n1.1\n1.6\n1.1\n1.0\n1.2\n1.4\n2. Cigarette Nicotine and Carbon Monoxide Refer to the table of data given in Exercise 1 \nand use the amounts of nicotine and carbon monoxide (CO).\na. Construct a scatterplot using nicotine for the x scale or horizontal axis. What does the scat-\nterplot suggest about a linear correlation between amounts of nicotine and carbon monoxide?\nb. Find the value of the linear correlation coefficient and determine whether there is sufficient evi-\ndence to support a claim of a linear correlation between amounts of nicotine and carbon monoxide.\nc. Letting y represent the amount of carbon monoxide and letting x represent the amount of \nnicotine, find the regression equation.\nd. The Raleigh brand king size cigarette is not included in the table, and it has 1.3 mg of nico-\ntine. What is the best predicted amount of carbon monoxide? How does the predicted amount \ncompare to the actual amount of 15 mg of carbon monoxide?\n3. Cigarette Tar and Carbon Monoxide Refer to the table of data given in Exercise 1 and \nuse the amounts of tar and carbon monoxide.\na. Construct a scatterplot using the horizontal scale to represent the amount of tar. What does \nthe scatterplot suggest?\nb. Does the scatterplot show eight points corresponding to the eight pairs of sample data? If \nnot, why not?\nc. Find the value of the linear correlation coefficient and determine whether there is sufficient \nevidence to support a claim of a linear correlation between amount of tar and amount of carbon \nmonoxide.\nd. Letting y represent amount of carbon monoxide and letting x represent amount of tar, find \nthe regression equation.\ne. The Raleigh brand king size cigarette is not included in the table, and it has 23 mg of tar. \nWhat is the best predicted amount of carbon monoxide? How does the predicted amount com-\npare to the actual amount of 15 mg of carbon monoxide?\n4. Multiple Regression with Cigarettes Use the sample data given in Exercise 1 “Cigarette \nTar and Nicotine.”\na. Find the multiple regression equation with the response (y) variable of amount of nicotine \nand predictor (x) variables of amounts of tar and carbon monoxide.\nReview Exercises\nCHAPTER 10 Review Exercises \n497\ncontinued\n\n498 \nCHAPTER 10 Correlation and Regression\nb. Identify the value of the multiple coefficient of determination R2, the adjusted R2, and the \nP-value representing the overall significance of the multiple regression equation.\nc. Use a 0.05 significance level and determine whether the regression equation can be used to \npredict the amount of nicotine given the amounts of tar and carbon monoxide.\nd. The Raleigh brand king size cigarette is not included in the table, and it has 23 mg of tar \nand 15 mg of carbon monoxide. What is the best predicted amount of nicotine? How does the \npredicted amount compare to the actual amount of 1.3 mg of nicotine?\n5. Bacteria Growth In an experiment, the numbers of bacteria in a controlled environment are \nrecorded over time. The table below lists the time (days) that has lapsed and the population size \n(thousands). What do you conclude about the relationship between time and population size? \nWhat horrible mistake would be easy to make if the analysis is conducted without a scatterplot?\nTime (days)\n1\n3\n5\n7\n9\n11\n13\n15\n17\n19\nPopulation (thousands)\n0.1\n1.8\n3.2\n4.0\n4.6\n4.8\n4.7\n4.2\n3.4\n2.2\n6. Logistic Regression with Smoking and Body Temperature Refer to Data Set 2 “Body \nTemperatures” in Appendix B and use the body temperatures at 8 AM on Day 1 and at 12 AM \non Day 1. Let the response variable be whether the subject smokes (1 = smokes, 0 = does not \nsmoke). Find the multiple regression equation. Use the equation to find the probability that the \nsubject smokes, given that the 8 AM body temperature and the 12 AM body temperature are \nboth 98.25oF. Use the P-value for the multiple regression equation to determine whether the \npredicted value is likely to be fairly accurate.\nEffectiveness of Diet. Listed below are weights (lb) of subjects before and after the Zone \ndiet. (Data are based on results from “Comparison of the Atkins, Ornish, Weight Watchers, \nand Zone Diets for Weight Loss and Heart Disease Risk Reduction,” by Dansinger et al.,  \nJournal of the American Medical Association, Vol. 293, No. 1.) Use the data for Exercises 1–5.\nBefore\n183\n212\n177\n209\n155\n162\n167\n170\nAfter\n179\n198\n180\n208\n159\n155\n164\n166\n1. Diet Clinical Trial: Statistics Find the mean and standard deviation of the “before-after” \ndifferences.\n2. Diet Clinical Trial: z Score Using only the weights before the diet, identify the highest \nweight and convert it to a z score. In the context of these sample data, is that highest value \n“significantly” high? Why or why not?\n3. Diet Clinical Trial: Hypothesis Test Use a 0.05 significance level to test the claim that the \ndiet is effective.\n4. Diet Clinical Trial: Confidence Interval Construct a 95% confidence interval estimate of the \nmean weight of subjects before the diet. Write a brief statement interpreting the confidence interval.\n5. Diet Clinical Trial: Correlation Use the before>after weights listed above.\na. Test for a correlation between the before and after weights.\nb. If each subject were to weigh exactly the same after the diet as before, what would be the \nvalue of the linear correlation coefficient?\nc. If all subjects were to lose 5% of their weight from the diet, what would be the value of the \nlinear correlation coefficient found from the before>after weights?\nd. What do the preceding results suggest about the suitability of correlation as a tool for testing \nthe effectiveness of the diet?\nCumulative Review Exercises\n\n6. Birth Weights Birth weights in the United States are normally distributed with a mean of \n3420 g and a standard deviation of 495 g.\na. What percentage of babies are born with a weight greater than 3500 g?\nb. Find P10, which is the 10th percentile.\nc. The Rockland Medical Center requires special treatment for babies that are less than \n2450 g (significantly underweight) or more than 4390 g (significantly overweight). What is the \npercentage of babies who require special treatment? Under these conditions, do many babies \nrequire special treatment?\n7. Measuring Lung Volumes In a study of techniques used to measure lung volumes, physi-\nological data were collected for 10 subjects. The values given in the accompanying table are in \nliters, representing the measured forced vital capacities of the 10 subjects in a sitting position \nand in a supine (lying) position (based on data from “Validation of Esophageal Balloon Tech-\nnique at Different Lung Volumes and Postures,” by Baydur et al., Journal of Applied Physiol-\nogy, Vol. 62, No. 1). The issue we want to investigate is whether the position (sitting or supine) \nhas an effect on the measured values.\na. If we test for a correlation between the sitting values and the supine values, will the result \nallow us to determine whether the position (sitting or supine) has an effect on the measured \nvalues? Why or why not?\nb. Use an appropriate test for the claim that the position has no effect, so the mean difference is zero.\nSubject\nA\nB\nC\nD\nE\nF\nG\nH\nI\nJ\nSitting\n4.66\n5.70\n5.37\n3.34\n3.77\n7.43\n4.15\n6.21\n5.90\n5.77\nSupine\n4.63\n6.34\n5.72\n3.23\n3.60\n6.96\n3.66\n5.81\n5.61\n5.33\n8. Cell Phones and Crashes: Analyzing a News Report In an article from the Associated \nPress, it was reported that researchers “randomly selected 100 New York motorists who had \nbeen in an accident and 100 who had not. Of those in accidents, 13.7 percent owned a cellular \nphone, while just 10.6 percent of the accident-free drivers had a phone in the car.” Identify the \nmost notable feature of these results.\nData Set 1 “Body Data” from Appendix B includes low-density lipoprotein (LDL) and high-\ndensity lipoprotein (HDL) cholesterol measurements from 300 subjects. Download the data set \n(from www.TriolaStats.com) and proceed to generate a scatterplot and results from correlation \nand regression. Is there a linear correlation between HDL and LDL? What is the equation of the \nregression line? If the measurements are separated according to gender, do the results change \nvery much? Write a brief report and include appropriate results from technology.\nTechnology Project\nCHAPTER 10 Technology Project \n499\n\n500 \nCHAPTER 10 Correlation and Regression\nCooperative Group Activities\n1. In-class activity For each student in the class, measure shoe print length and height. Test \nfor a linear correlation and identify the equation of the regression line. Measure the shoe print \nlength of the professor and use it to estimate his or her height. How close is the estimated \nheight to the actual height?\n2. In-class activity Divide into groups of 8 to 12 people. For each group member, measure the \nheight and also measure his or her navel height, which is the height from the floor to the navel. \nIs there a correlation between height and navel height? If so, find the regression equation with \nheight expressed in terms of navel height. According to one theory, the average person’s ratio \nof height to navel height is the golden ratio: 11 + 252>2 ≈1.6. Does this theory appear to \nbe reasonably accurate?\n3. In-class activity Divide into groups of 8 to 12 people. For each group member, measure \nheight and arm span. For the arm span, the subject should stand with arms extended like the \nwings on an airplane. Using the paired sample data, is there a correlation between height and \narm span? If so, find the regression equation with height expressed in terms of arm span. Can \narm span be used as a reasonably good predictor of height?\nFROM DATA TO DECISION\nCritical Thinking: Is the pain medicine Duragesic  \neffective in reducing pain?\nListed below are measures of pain intensity before and after \nusing the drug Duragesic (fentanyl) (based on data from \nJanssen Pharmaceutical Products, L.P.). The data are listed in \norder by row, and corresponding measures are from the same \nsubject before and after treatment. For example, the first \nsubject had a measure of 1.2 before treatment and a measure \nof 0.4 after treatment. Each pair of measurements is from \none subject, and the intensity of pain was measured using the \nstandard visual analog score. A higher score corresponds to \nhigher pain intensity.\nPain Intensity Before Duragesic Treatment\n1.2\n1.3\n1.5\n1.6\n8.0\n3.4\n3.5\n2.8\n2.6\n2.2\n3.0\n7.1\n2.3\n2.1\n3.4\n6.4\n5.0\n4.2\n2.8\n3.9\n5.2\n6.9\n6.9\n5.0\n5.5\n6.0\n5.5\n8.6\n9.4\n10.0\n7.6\nPain Intensity After Duragesic Treatment\n0.4\n1.4\n1.8\n2.9\n6.0\n1.4\n0.7\n3.9\n0.9\n1.8\n0.9\n9.3\n8.0\n6.8\n2.3\n0.4\n0.7\n1.2\n4.5\n2.0\n1.6\n2.0\n2.0\n6.8\n6.6\n4.1\n4.6\n2.9\n5.4\n4.8\n4.1\nAnalyzing the Results\n1. Correlation Use the given data to construct a scatterplot, \nthen use the methods of Section 10-1 to test for a linear cor-\nrelation between the pain intensity before and after treatment. \nIf there does appear to be a linear correlation, can we con-\nclude that the drug treatment is effective?\n2. Regression Use the given data to find the equation of \nthe regression line. Let the response (y) variable be the pain \nintensity after treatment. What would be the equation of the \nregression line for a treatment having absolutely no effect?\n3. Two Independent Samples The methods of Section 9-2  \ncan be used to test the claim that two populations have the \nsame mean. Identify the specific claim that the treatment is \neffective, then use the methods of Section 9-2 to test that \nclaim. The methods of Section 9-2 are based on the require-\nment that the samples are independent. Are they independent \nin this case?\n4. Matched Pairs The methods of Section 9-3 can be  \nused to test a claim about matched data. Identify the specific \nclaim that the treatment is effective, then use the methods of \nSection 9-3 to test that claim.\n5. Best Method? Which of the preceding results is best for \ndetermining whether the drug treatment is effective in re-\nducing pain? Based on the preceding results, does the drug \nappear to be effective?\n\n4. In-class activity Divide into groups of 8 to 12 people. For each group member, use a string \nand ruler to measure head circumference and forearm length. Is there a relationship between \nthese two variables? If so, what is it?\n5. In-class activity Use a ruler as a device for measuring reaction time. One person should \nsuspend the ruler by holding it at the top while the subject holds his or her thumb and fore-\nfinger at the bottom edge ready to catch the ruler when it is released. Record the distance that \nthe ruler falls before it is caught. Convert that distance to the time (in seconds) that it took the \nsubject to react and catch the ruler. (If the distance is measured in inches, use t = 2d>192. If \nthe distance is measured in centimeters, use t = 2d>487.68.) Test each subject once with the \nright hand and once with the left hand, and record the paired data. Test for a correlation. Find \nthe equation of the regression line. Does the equation of the regression line suggest that the \ndominant hand has a faster reaction time?\n6. In-class activity Divide into groups of 8 to 12 people. Record the pulse rate of each group \nmember while he or she is seated. Then record the pulse rate of each group member while he or \nshe is standing. Is there a relationship between sitting and standing pulse rate? If so, what is it?\n7. In-class activity Divide into groups of three or four people. Appendix B includes many \ndata sets not yet used in examples or exercises in this chapter. Search Appendix B for a pair of \nvariables of interest, then investigate correlation and regression. State your conclusions and try \nto identify practical applications.\n8. Out-of-class activity Divide into groups of three or four people. Investigate the relation-\nship between two variables by collecting your own paired sample data and use the methods \nof this chapter to determine whether there is a significant linear correlation. Also identify the \nregression equation and describe a procedure for predicting values of one of the variables when \ngiven values of the other variable. Suggested topics:\n• Is there a relationship between taste and cost of different brands of chocolate chip cookies (or \ncolas)? Taste can be measured on some number scale, such as 1 to 10.\n• Is there a relationship between salaries of professional baseball (or basketball, or football) \nplayers and their season achievements?\n• Is there a relationship between student grade-point averages and the amount of television \nwatched? If so, what is it?\nCHAPTER 10 Cooperative Group Activities \n501\n\n502\nGoodness-of-Fit\nContingency Tables\n11-1\n11-2\nWhich Treatment Is Best?\nCHAPTER \nPROBLEM\nGoodness-of-Fit and \nContingency Tables\nThe options for treating a stress fracture in a foot bone  \ninclude surgery, applying a weight-bearing cast, applying a \nnon–weight-bearing cast for six weeks, and applying a  \nnon–weight-bearing cast for less than six weeks.\nTable 11-1 is a contingency table with four rows and two \ncolumns. The cells of the table contain frequency counts. The \nrow variable identifies the treatment used for a stress fracture \nin a foot bone, and the column variable identifies the outcome \nas a success or failure. The table is based on data from  \n“Management of Tarsal Navicular Stress Fractures: Conserva-\ntive Versus Surgical Treatment: A Meta-Analysis,” by Torc  \net al., American Journal of Sports Medicine, Vol. 38, No. 5. In \nthis chapter we will use the data in Table 11-1 to address  \nthese questions:\n11 \n\n• Do the four different treatments have different rates of  \nsuccess?\n• Is there a treatment that is best?\n• Should surgery be recommended for treating a stress  \nfracture in a foot bone?\nTABLE 11-1 Treatments for Stress Fracture in a Foot Bone\nSuccess\nFailure\nSurgery\n54\n12\nWeight-Bearing Cast\n41\n51\nNon–Weight-Bearing Cast for 6 Weeks\n70\n 3\nNon–Weight-Bearing Cast for Less  \nThan 6 Weeks\n \n17\n \n 5\nChapters 7 and 8 introduced important methods of inferential statistics, including con-\nfidence intervals for estimating population parameters (Chapter 7) and methods for \ntesting hypotheses or claims (Chapter 8). We then considered inferences involving two \npopulations (Chapter 9) and correlation>regression with paired data (Chapter 10). In \nthis chapter we use statistical methods for analyzing categorical (or qualitative, or at-\ntribute) data that can be partitioned into different cells. The methods of this chapter use \nthe same x2 (chi-square) distribution that was introduced in Section 7-3 and again in \nSection 8-4. See Section 7-3 or Section 8-4 for a quick review of properties of the x2 \ndistribution. Here are the chapter objectives:\nGoodness-of-Fit\n• Use frequency counts of categorical data partitioned into different categories and \ndetermine whether the data fit some claimed distribution.\nContingency Tables\n• Use categorical data summarized as frequencies in a two-way table with at least two \nrows and at least two columns to conduct a formal test of independence between \nthe row variable and column variable.\n• Be able to conduct a formal test of a claim that different populations have the same \nproportions of some characteristics.\n11-1\n11-2\nCHAPTER OBJECTIVES\nChapters 7 and 8 introduced important methods of inferential statistics, including con-\nfidence intervals for estimating population parameters (Chapter 7) and methods for \ntesting hypotheses or claims (Chapter 8). We then considered inferences involving two\npopulations (Chapter 9) and correlation>regression with paired data (Chapter 10). In\nthis chapter we use statistical methods for analyzing categorical (or qualitative, or at-\ntribute) data that can be partitioned into different cells. The methods of this chapter use \nthe same x2 (chi-square) distribution that was introduced in Section 7-3 and again in\nSection 8-4. See Section 7-3 or Section 8-4 for a quick review of properties of the x2\ndistribution. Here are the chapter objectives:\nGoodness-of-Fit\n• Use frequency counts of categorical data partitioned into different categories and\ndetermine whether the data fit some claimed distribution.\nContingency Tables\n• Use categorical data summarized as frequencies in a two-way table with at least two \nrows and at least two columns to conduct a formal test of independence between\nthe row variable and column variable.\n• Be able to conduct a formal test of a claim that different populations have the same\nproportions of some characteristics.\nS\nKey Concept By “goodness-of-fit” we mean that sample data consisting of observed \nfrequency counts arranged in a single row or column (called a one-way frequency \ntable) agree with some particular distribution (such as normal or uniform) being con-\nsidered. We will use a hypothesis test for the claim that the observed frequency counts \nagree with the claimed distribution.\n11-1 \nGoodness-of-Fit\n11-1 Goodness-of-Fit \n503\nDEFINITION\nA goodness-of-fit test is used to test the hypothesis that an observed frequency \ndistribution fits (or conforms to) some claimed distribution.\n\n504 \nCHAPTER 11 Goodness-of-Fit and Contingency Tables\nTesting for Goodness-of-Fit\nObjective\nConduct a goodness-of-fit test, which is a hypothesis test to determine whether a single row (or column) of frequency \ncounts agrees with some specific distribution (such as uniform or normal).\nNotation\nO represents the observed frequency of an outcome, found from the sample data.\nE represents the expected frequency of an outcome, found by assuming that the distribution is as claimed.\nk represents the number of different categories or cells.\nn represents the total number of trials (or the total of observed sample values).\np represents the probability that a sample value falls within a particular category\nRequirements\n1. The data have been randomly selected.\n2. The sample data consist of frequency counts for each of the different categories.\n3. For each category, the expected frequency is at least 5. (The expected frequency for a category is the frequency that \nwould occur if the data actually have the distribution that is being claimed. There is no requirement that the observed \nfrequency for each category must be at least 5.)\nNull and Alternative Hypotheses\nH0: The frequency counts agree with the claimed distribution.\nH1: The frequency counts do not agree with the claimed distribution.\nTest Statistic for Goodness-of-Fit Tests\nx2 = a\n(O - E)2\nE\nP-values: P-values are typically provided by technology, or a range of P-values can be found from Table A-4.\nCritical values:\n1. Critical values are found in Table A-4 by using k − 1 degrees of freedom, where k is the number of categories.\n2. Goodness-of-fit hypothesis tests are always right-tailed.\nKEY ELEMENTS \nFinding Expected Frequencies\nConducting a goodness-of-fit test requires that we identify the observed frequencies \ndenoted by O, then find the frequencies expected (denoted by E) with the claimed \ndistribution. There are two different approaches for finding expected frequencies E:\n \n■If the expected frequencies are all equal: Calculate E = n,k.\n \n■If the expected frequencies are not all equal: Calculate E = np for each  \nindividual category.\nAs good as these two preceding formulas for E might be, it is better to use an \ninformal approach by simply asking, “How can the observed frequencies be split up \n\n11-1 Goodness-of-Fit \n505\namong the different categories so that there is perfect agreement with the claimed \ndistribution?” Also, note that the observed frequencies are all whole numbers because \nthey represent actual counts, but the expected frequencies need not be whole numbers.\nExamples:\na. Equally Likely A single die is rolled 45 times with the following results.  \nAssuming that the die is fair and all outcomes are equally likely, ﬁnd the  \nexpected frequency E for each empty cell.\nOutcome\n 1\n2\n 3\n4\n5\n6\nObserved Frequency O\n13\n6\n12\n9\n3\n2\nExpected Frequency E\nWith n = 45 outcomes and k = 6 categories, the expected frequency for each \ncell is the same: E = n>k = 45>6 = 7.5. If the die is fair and the outcomes are \nall equally likely, we expect that each outcome should occur about 7.5 times.\n \nb. Not Equally Likely Using the same results from part (a), suppose that we claim \nthat instead of being fair, the die is loaded so that the outcome of 1 occurs 50% \nof the time and the other ﬁve outcomes occur 10% of the time. The probabilities \nare listed in the second row below. Using n = 45 and the probabilities listed \nbelow, we ﬁnd that for the ﬁrst cell, E = np = (45)(0.5) = 22.5. Each of the \nother ﬁve cells will have the expected value of E = np = (45)(0.1) = 4.5.\nOutcome\n1\n2\n3\n4\n5\n6\nProbability\n0.5\n0.1\n0.1\n0.1\n0.1\n0.1\nObserved Frequency O\n13\n6\n12\n9\n3\n2\nExpected Frequency E\n22.5\n4.5\n4.5\n4.5\n4.5\n4.5\nMeasuring Disagreement with the Claimed Distribution\nWe know that sample frequencies typically differ somewhat from the values we theo-\nretically expect, so we consider the key question:\nAre the diﬀerences between the actual observed frequencies O and the  \ntheoretically expected frequencies E signiﬁcant?\nTo measure the discrepancy between the O and E values, we use the test statistic given \nin the preceding Key Elements box. (Later we will explain how this test statistic was \ndeveloped, but it has differences of O - E as a key component.)\nx2 = a\n(O - E)2\nE\nThe x2 test statistic is based on differences between the observed and expected \nvalues. If the observed and expected values are close, the x2 test statistic will be small \nand the P-value will be large. If the observed and expected frequencies are far apart, \nthe x2 test statistic will be large and the P-value will be small. Figure 11-1 on the \nnext page summarizes this relationship. The hypothesis tests of this section are always \nright-tailed, because the critical value and critical region are located at the extreme \nright of the distribution. If confused, just remember this mnemonic:\n“If the P is low, the null must go.”\n(If the P-value is small, reject the null hypothesis that the distribution is  \nas claimed.)\nd\ne\ns.\nWhich Car Seats  \nAre Safest?\nMany people \nbelieve that the \nback seat of a \ncar is the safest \nplace to sit, but \nis it? Univer-\nsity of Buffalo \nresearchers analyzed more than \n60,000 fatal car crashes and \nfound that the middle back seat \nis the safest place to sit in a \ncar. They found that sitting in \nthat seat makes a passenger \n86% more likely to survive than \nthose who sit in the front seats, \nand they are 25% more likely to \nsurvive than those sitting in either \nof the back seats nearest the \nwindows. An analysis of seat belt \nuse showed that when not wear-\ning a seat belt in the back seat, \npassengers are three times more \nlikely to die in a crash than those \nwearing seat belts in that same \nseat. Passengers concerned with \nsafety should sit in the middle \nback seat and wear a seat belt.\n\n506 \nCHAPTER 11 Goodness-of-Fit and Contingency Tables\nGood ﬁt with assumed\ndistribution\nNot a good ﬁt with\nassumed distribution\nCompare the observed O\nvalues to the corresponding\nexpected E values.\nOs and Es\nare close\nOs and Es\nare far apart\n“If the P is low,\nthe null must go.”\nFail to reject H0\nReject H0\nSmall x2 value, large P-value\nLarge x2 value, small P-value\nx2 here\nx2 here\nFIGURE 11-1  Relationships Among the X2 Test Statistic,  \nP-Value, and Goodness-of-Fit\nEXAMPLE 1  Last Digits of Weights\nA random sample of 100 weights of Californians is obtained, and the last digits of those \nweights are summarized in Table 11-2 (based on data from the California Department \nof Public Health). When obtaining weights of subjects, it is extremely important to actu-\nally measure their weights instead of asking them to report their weights. By analyzing \nthe last digits of weights, researchers can verify that they were obtained through actual \nmeasurements instead of being reported. When people report weights, they tend to \nround down and they often round way down, so a weight of 197 lb might be rounded \nand reported as a more desirable 170 lb. Reported weights tend to have many last digits \nconsisting of 0 or 5. In contrast, if people are actually weighed, the weights tend to have \nlast digits that are uniformly distributed, with 0, 1, 2, . . . , 9 all occurring with roughly \nthe same frequencies. We could subjectively examine the frequencies in Table 11-2 to \nsee that the digits of 0 and 5 do seem to occur much more often than the other digits, but \nwe will proceed with a formal hypothesis test to reinforce that subjective conclusion.\nTest the claim that the sample is from a population of weights in which the \nlast digits do not occur with the same frequency. Based on the results, what can we \nconclude about the procedure used to obtain the weights?\nSOLUTION\nREQUIREMENT CHECK (1) The data come from randomly selected subjects. (2) The \ndata do consist of frequency counts, as shown in Table 11-2. (3) With 100 sample \nvalues and 10 categories that are claimed to be equally likely, each expected fre-\nquency is 10, so each expected frequency does satisfy the requirement of being a \nvalue of at least 5. All of the requirements are satisfied. \nThe claim that the digits do not occur with the same frequency is equivalent  \nto the claim that the relative frequencies or probabilities of the 10 cells (p0, p1, . . . , \np9) are not all equal. (This is equivalent to testing the claim that the distribution of \ndigits is not a uniform distribution.)\nTABLE 11-2  \nLast Digits of Weights\nLast Digit\nFrequency\n0\n46\n1\n1\n2\n2\n3\n3\n4\n3\n5\n30\n6\n4\n7\n0\n8\n8\n9\n3\n\n11-1 Goodness-of-Fit \n507\nStep 1: The original claim is that the digits do not occur with the same frequency. \nThat is, at least one of the probabilities p0, p1, . . ., p9 is different from the others.\nStep 2: If the original claim is false, then all of the probabilities are the same. That \nis, p0 = p1 = p2 = p3 = p4 = p5 = p6 = p7 = p8 = p9.\nStep 3: The null hypothesis must contain the condition of equality, so we have\nH0: p0 = p1 = p2 = p3 = p4 = p5 = p6 = p7 = p8 = p9\nH1: At least one of the probabilities is diﬀerent from the others.\nStep 4: No significance level was specified, so we select the common choice of \na = 0.05.\nStep 5: Because we are testing a claim about the distribution of the last digits being \na uniform distribution (with all of the digits having the same probability), we use \nthe goodness-of-fit test described in this section. The x2 distribution is used with \nthe test statistic given in the preceding Key Elements box.\nStep 6: The observed frequencies O are listed in Table 11-2. Each corresponding \nexpected frequency E is equal to 10 (because the 100 digits would be uniformly \ndistributed among the 10 categories). The Excel add-in XLSTAT is used to ob-\ntain the results shown in the accompanying screen display, and Table 11-3 on the \nnext page shows the manual computation of the x2 test statistic. The test statistic \nis x2 = 212.800. The critical value is x2 = 16.919 (found in Table A-4 with \na = 0.05 in the right tail and degrees of freedom equal to k - 1 = 9). The P-value \nis less than 0.0001. The test statistic and critical value are shown in Figure 11-2.\nStep 7: If we use the P-value method of testing hypotheses, we see that the P-value \nis small (less than 0.0001), so we reject the null hypothesis. If we use the critical \nvalue method of testing hypotheses, Figure 11-2 shows that the test statistic falls in \nthe critical region, so there is sufficient evidence to reject the null hypothesis.\nStep 8: There is sufficient evidence to support the claim that the last digits do not \noccur with the same relative frequency.\nXLSTAT\nReject\np0 5 p15 • • • 5 p9\nFail to reject\np0 5 p15 • • • 5 p9\n0\n \nCritical Value:\nx2 5 16.919\nCritical\nRegion\nTest Statistic:\nx2 5 212.800\nFIGURE 11-2  Test of p0 = p1 = p2 = p3 = p4 = p5 =  \np6 = p7 = p8 = p9\n\n508 \nCHAPTER 11 Goodness-of-Fit and Contingency Tables\nTABLE 11-3 Calculating the x2 Test Statistic for the Last Digits of Weights\n \nLast Digit\n \nObserved Frequency O\n \nExpected Frequency E\n \nO −E\n(O −E)2\n(O −E )2\nE\n0\n46\n10\n   36\n1296\n129.6\n1\n1\n10\n  -9\n  81\n8.1\n2\n2\n10\n  -8\n  64\n6.4\n3\n3\n10\n  -7\n  49\n4.9\n4\n3\n10\n  -7\n  49\n4.9\n5\n30\n10\n   20\n 400\n40.0\n6\n4\n10\n  -6\n  36\n3.6\n7\n0\n10\n-10\n 100\n10.0\n8\n8\n10\n  -2\n   4\n0.4\n9\n3\n10\n  -7\n  49\n4.9\nx2 = a\n1O - E 2 2\nE\n= 212.8\nINTERPRETATION\nThis goodness-of-fit test suggests that the last digits do not provide a good fit with \nthe claimed uniform distribution of equally likely frequencies. Instead of actually \nweighing the subjects, it appears that the subjects reported their weights. In fact, \nthe weights are from the California Health Interview Survey (CHIS), and the title of \nthat survey indicates that subjects were interviewed, not measured. Because those \nweights are reported, the reliability of the data is very questionable.\nExample 1 involves a situation in which the expected frequencies E for the dif-\nferent categories are all equal. The methods of this section can also be used when the \nexpected frequencies are different, as in Example 2.\nEXAMPLE 2  Benford’s Law and Ultrasound Images\nAccording to Benford’s law, a variety of different data sets include numbers with lead-\ning (first) digits that follow the distribution shown in the first two rows of Table 11-4. \nData sets that tend to follow Benford’s law include a class of errors in clinical trials, \nas well as magnitudes of gradients from magnetic resonance imaging (MRI) scans, \ncomputed tomography (CT) scans, and ultrasound images. (A gradient in an image \nis a change in intensity or color along with a direction. The magnitude of a gradient \nincludes only the amount of change without a direction.)\nThe bottom row of Table 11-4 lists the frequencies of leading digits of the mag-\nnitudes of gradients from an ultrasound image. Do the frequencies of leading digits \nin the bottom row appear to fit the distribution of Benford’s law, as expected, or does \nit appear that the image has been corrupted with a substantial amount of “noise” be-\ncause the leading digits do not fit the distribution of Benford’s law? (There are meth-\nods for using Benford’s law to enhance images that have been corrupted with noise.)\nTABLE 11-4 Leading Digits of Magnitudes of Ultrasound Image Gradients\nLeading Digit\n1\n2\n3\n4\n5\n6\n7\n8\n9\nBenford’s Law: Distribution \nof Leading Digits\n \n30.1%\n \n17.6%\n \n12.5%\n \n9.7%\n \n7.9%\n \n6.7%\n \n5.8%\n \n5.1%\n \n4.6%\nLeading Digits of Magni-\ntudes of Gradients in an \nUltrasound Image\n \n \n69\n \n \n40\n \n \n42\n \n \n26\n \n \n25\n \n \n16\n \n \n16\n \n \n17\n \n \n20\nSafest Seats in a \nCommercial Jet\nA study by \naviation writer \nand researcher \nDavid Noland \nshowed that \nsitting farther \nback in a \ncommercial jet will increase your \nchances of surviving in the event \nof a crash. The study suggests \nthat the chance of surviving is \nnot the same for each seat, so a \ngoodness-of-fit test would lead \nto rejection of the null hypothesis \nthat every seat has the same \nprobability of a passenger surviv-\ning. Records from the 20 com-\nmercial jet crashes that occurred \nsince 1971 were analyzed. It was \nfound that if you sit in business \nor first class, you have a 49% \nchance of surviving a crash; if \nyou sit in coach over the wing \nor ahead of the wing, you have \na 56% chance of surviving; and \nif you sit in the back behind the \nwing, you have a 69% chance of \nsurviving.\nIn commenting on this study, \nDavid Noland stated that he does \nnot seek a rear seat when he \nflies. He says that because the \nchance of a crash is so small, \nhe doesn’t worry about where \nhe sits, but he prefers a window \nseat.\n\n11-1 Goodness-of-Fit \n509\nSOLUTION\nREQUIREMENT CHECK (1) The sample data are randomly selected from a larger popu-\nlation. (2) The sample data do consist of frequency counts. (3) Each expected fre-\nquency is at least 5. The lowest expected frequency is 271 * 0.046 = 12.466. All \nof the requirements are satisfied. \nStep 1: The original claim is that the leading digits fit the distribution given as  \nBenford’s law. Using subscripts corresponding to the leading digits, we can express \nthis claim as p1 = 0.301 and p2 = 0.176 and p3 = 0.125 and . . . and p9 = 0.046.\nStep 2: If the original claim is false, then at least one of the proportions does not \nhave the value as claimed.\nStep 3: The null hypothesis must contain the condition of equality, so we have\nH0: p1 = 0.301 and p2 = 0.176 and p3 = 0.125 and c and p9 = 0.046.\n  H1: At least one of the proportions is not equal to the given claimed value.\nStep 4: The significance level is not specified, so we use the common choice of \na = 0.05.\nStep 5: Because we are testing a claim that the distribution of leading digits fits  \nthe distribution given by Benford’s law, we use the goodness-of-fit test described \nin this section. The x2 distribution is used with the test statistic given earlier in the \npreceding Key Elements box.\nStep 6: Table 11-5 shows the calculations of the components of the x2 test statistic \nfor the leading digits of 1 and 2. If we include all nine leading digits, we get the test \nstatistic of x2 = 11.2792, as shown in the accompanying TI-84 Plus calculator dis-\nplay. The critical value is x2 = 15.507 (found in Table A-4 with a = 0.05 in the \nright tail and degrees of freedom equal to k - 1 = 8). The TI-84 Plus C calculator \ndisplay shows the value of the test statistic as well as the P-value of 0.186. (The en-\ntire bottom row of the display can be viewed by scrolling to the right. CNTRB is an \nabbreviated form of “contribution,” and the values are the individual contributions \nto the total value of the x2 test statistic.)\nTABLE 11-5 Calculating the x2 Test Statistic for Leading Digits in Table 11-4\n \nLeading Digit\nObserved  \nFrequency O\nExpected Frequency \nE = np\n \nO −E\n \n(O −E)2\n(O −E )2\nE\n1\n69\n271 # 0.301 = 81.5710\n-12.5710\n158.0300\n1.9373\n2\n40\n271 # 0.176 = 47.6960   -7.6960\n  59.2284\n1.2418\nStep 7: The P-value of 0.186 is greater than the significance level of 0.05, so there \nis not sufficient evidence to reject the null hypothesis. (Also, the test statistic of \nx2 = 11.2792 does not fall in the critical region bounded by the critical value of \n15.507, so there is not sufficient evidence to reject the null hypothesis.)\nStep 8: There is not sufficient evidence to warrant rejection of the claim that the \n271 leading digits fit the distribution given by Benford’s law.\nINTERPRETATION\nThe sample of leading digits does not provide enough evidence to conclude that the \nBenford’s law distribution is not being followed. There is not sufficient evidence to \nsupport a conclusion that the ultrasound image has been corrupted with a substantial \namount of “noise.”\nTI-84 Plus C\nu-\nMendel’s Data Falsified?\nBecause some \nof Mendel’s data \nfrom his famous \ngenetics experi-\nments seemed \ntoo perfect to be \ntrue, statistician \nR. A. Fisher concluded that the \ndata were probably falsified. He \nused a chi-square distribution to \nshow that when a test statistic \nis extremely far to the left and \nresults in a P-value very close to \n1, the sample data fit the claimed \ndistribution almost perfectly, and \nthis is evidence that the sample \ndata have not been randomly \nselected. It has been suggested \nthat Mendel’s gardener knew \nwhat results Mendel’s theory \npredicted, and subsequently \nadjusted results to fit that theory.\nIra Pilgrim wrote in The Journal \nof Heredity that this use of the \nchi-square distribution is not \nappropriate. He notes that the \nquestion is not about goodness-\nof-fit with a particular distribution, \nbut whether the data are from \na sample that is truly random. \nPilgrim used the binomial prob-\nability formula to find the prob-\nabilities of the results obtained \nin Mendel’s experiments. Based \non his results, Pilgrim concludes \nthat “there is no reason whatever \nto question Mendel’s honesty.” It \nappears that Mendel’s results are \nnot too good to be true, and they \ncould have been obtained from a \ntruly random process.\n\n510 \nCHAPTER 11 Goodness-of-Fit and Contingency Tables\nIn Figure 11-3 we use a green line to graph the expected proportions given by \nBenford’s law (as in Table 11-4) along with a red line for the observed proportions from \nTable 11-4. Figure 11-3 allows us to visualize the “goodness-of-fit” between the distri-\nbution given by Benford’s law and the frequencies that were observed. In Figure 11-3, \nthe green and red lines agree reasonably well, so it appears that the observed data fit the \nexpected values reasonably well.\nRationale for the Test Statistic Examples 1 and 2 show that the x2 test statistic is a \nmeasure of the discrepancy between observed and expected frequencies. Simply sum-\nming the differences O - E between observed and expected values tells us nothing, \nbecause that sum is always 0. Squaring the O - E gives us a better statistic. (The rea-\nsons for squaring the O - E values are essentially the same as the reasons for squar-\ning the x - x values in the formula for standard deviation.) The value of Σ(O - E)2\nmeasures only the magnitude of the differences, but we need to find the magnitude of \nthe differences relative to what was expected. We need a type of average instead of a \ncumulative total. This relative magnitude is found through division by the expected \nfrequencies, as in the test statistic.\nThe theoretical distribution of Σ(O - E)2>E is a discrete distribution because \nthe number of possible values is finite. The distribution can be approximated by a \nchi-square distribution, which is continuous. This approximation is generally con-\nsidered acceptable, provided that all expected values E are at least 5. (There are \nways of circumventing the problem of an expected frequency that is less than 5, \nsuch as combining some categories so that all expected frequencies are at least 5. \nAlso, there are different procedures that can be used when not all expected fre-\nquencies are at least 5.)\nThe number of degrees of freedom reflects the fact that we can freely as-\nsign frequencies to k - 1 categories before the frequency for every category is \ndetermined. (Although we say that we can “freely” assign frequencies to k - 1\ncategories, we cannot have negative frequencies, nor can we have frequencies so \nlarge that their sum exceeds the total of the observed frequencies for all catego-\nries combined.)\nFIGURE 11-3  Observed Proportions and Propor-\ntions Expected with Benford’s Law\nGoodness-of-Fit Test\nAccess tech instructions, videos, and data sets at www.TriolaStats.com\nTECH CENTER \n\n11-1 Goodness-of-Fit \n511\nStatistical Literacy and Critical Thinking\n1. Hospital Cybersecurity The table below lists leading digits of 317 inter-arrival Internet \ntraffic times for a hospital computer along with the frequencies of leading digits expected with \nBenford’s law.\na. Identify the notation used for observed and expected values.\nb. Identify the observed and expected values for the leading digit of 2.\nc. Use the results from part (b) to find the contribution to the x2 test statistic from the category \nrepresenting the leading digit of 2.\nLeading Digit\n1\n2\n3\n4\n5\n6\n7\n8\n9\nBenford’s Law\n30.1%\n17.6%\n12.5%\n9.7%\n7.9%\n6.7%\n5.8%\n5.1%\n4.6%\nLeading Digits of  \nInter-Arrival Traffic Times\n \n76\n \n62\n \n29\n \n33\n \n19\n \n27\n \n28\n \n21\n \n22\n2. Hospital Cybersecurity When using the data from Exercise 1 to test for goodness-of-fit \nwith the distribution described by Benford’s law, identify the null and alternative hypotheses.\n3. Hospital Cybersecurity The accompanying Statdisk results shown in the margin are \n obtained from the data given in Exercise 1. What should be concluded when testing the claim \nthat the leading digits have a distribution that fits well with Benford’s law?\n4. Hospital Cybersecurity What do the results from the preceding exercises suggest about the \npossibility that the computer has been hacked? Is there any corrective action that should be taken?\nIn Exercises 5–20, conduct the hypothesis test and provide the test statistic and the P-value, \nand , or critical value, and state the conclusion.\n5. Occupational Injuries Randomly selected non-fatal occupational injuries and illnesses are \ncategorized according to the day of the week that they first occurred, and the results are listed \nbelow (based on data from the Bureau of Labor Statistics). Use a 0.05 significance level to test \nthe claim that such injuries and illnesses occur with equal frequency on the different days of \nthe week.\nDay\nMon.\nTues.\nWed.\nThurs.\nFri.\nNumber\n23\n23\n21\n21\n19\n6. Deaths from Car Crashes Randomly selected deaths from car crashes were obtained, \nand the results are included in the table below (based on data from the Insurance Institute for \nHighway Safety). Use a 0.05 significance level to test the claim that car crash fatalities occur \nwith equal frequency on the different days of the week. How might the results be explained? \nWhy does there appear to be an exceptionally large number of car crash fatalities on Saturday?\nDay\nSun.\nMon.\nTues.\nWed.\nThurs.\nFri.\nSat.\nNumber of Fatalities\n132\n98\n95\n98\n105\n133\n158\n7. Motorcycle Fatalities Randomly selected deaths of motorcycle riders are summarized in \nthe table below (based on data from the Insurance Institute for Highway Safety). Use a 0.05 \nsignificance level to test the claim that such fatalities occur with equal frequency in the differ-\nent months. How might the results be explained?\nMonth\nJan.\nFeb.\nMarch\nApril\nMay\nJune\nJuly\nAug.\nSept.\nOct.\nNov.\nDec.\nNumber\n6\n8\n10\n16\n22\n28\n24\n28\n26\n14\n10\n8\n11-1 Basic Skills and Concepts \n\n512 \nCHAPTER 11 Goodness-of-Fit and Contingency Tables\n8. Flat Tire and Missed Class A classic story involves four carpooling students who missed \na test and gave as an excuse a flat tire. On the makeup test, the instructor asked the students to \nidentify the particular tire that went flat. If they really didn’t have a flat tire, would they be able \nto identify the same tire? One of the authors asked 41 other students to identify the tire they \nwould select. The results are listed in the following table (except for one student who selected \nthe spare). Use a 0.05 significance level to test the author’s claim that the results fit a uniform \ndistribution. What does the result suggest about the likelihood of four students identifying the \nsame tire when they really didn’t have a flat?\nTire\nLeft Front\nRight Front\nLeft Rear\nRight Rear\nNumber Selected\n11\n15\n8\n6\n9. Baseball Player Births In his book Outliers, author Malcolm Gladwell argues that more \nbaseball players have birthdates in the months immediately following July 31, because that was \nthe age cutoff date for nonschool baseball leagues. Here is a sample of frequency counts of \nmonths of birthdates of American-born Major League Baseball players starting with January: \n387, 329, 366, 344, 336, 313, 313, 503, 421, 434, 398, 371. Using a 0.05 significance level, is \nthere sufficient evidence to warrant rejection of the claim that American-born Major League \nBaseball players are born in different months with the same frequency? Do the sample values \nappear to support Gladwell’s claim?\n10. Genetics The Advanced Placement Biology class at Mount Pearl Senior High School con-\nducted genetics experiments with fruit flies, and the results in the following table are based on \nthe results that they obtained. Use a 0.05 significance level to test the claim that the observed \nfrequencies agree with the proportions that were expected according to principles of genetics.\n \nCharacteristic\nRed Eye,  \nNormal Wing\nSepia Eye,  \nNormal Wing\nRed Eye,  \nVestigial Wing\nSepia Eye,  \nVestigial Wing\nFrequency\n59\n15\n2\n4\nExpected Proportion\n9>16\n3>16\n3>16\n1>16\n11. Eye Color A researcher has developed a theoretical model for predicting eye color. After \nexamining a random sample of parents, she predicts the eye color of the first child. The table \nbelow lists the eye colors of offspring. On the basis of her theory, she predicted that 87% of the \noffspring would have brown eyes, 8% would have blue eyes, and 5% would have green eyes. \nUse a 0.05 significance level to test the claim that the actual frequencies correspond to her pre-\ndicted distribution.\nBrown Eyes\nBlue Eyes\nGreen Eyes\nFrequency\n132\n17\n0\n12. Genotypes Based on the genotypes of parents, offspring are expected to have genotypes \ndistributed in such a way that 25% have genotypes denoted by AA, 50% have genotypes de-\nnoted by Aa, and 25% have genotypes denoted by aa. When 145 offspring are obtained, it is \nfound that 20 of them have AA genotypes, 90 have Aa genotypes, and 35 have aa genotypes. \nTest the claim that the observed genotype offspring frequencies fit the expected distribution of \n25% for AA, 50% for Aa, and 25% for aa. Use a significance level of 0.05.\n13. Bias in Clinical Trials Researchers investigated the issue of race and equality of access \nto clinical trials. The table on the top of the next page shows the population distribution and \nthe numbers of participants in clinical trials involving lung cancer (based on data from “Par-\nticipation in Cancer Clinical Trials,” by Murthy, Krumholz, and Gross, Journal of the American \nMedical Association, Vol. 291, No. 22). Use a 0.01 significance level to test the claim that the \ndistribution of clinical trial participants fits well with the population distribution. Is there a race>\nethnic group that appears to be very underrepresented?\n\n11-1 Goodness-of-Fit \n513\nRace, ethnicity\nWhite  \nnon-Hispanic\n \nHispanic\n \nBlack\nAsian, Pacific \nIslander\nAmerican Indian,\nAlaskan Native\nDistribution of  \nPopulation\n \n75.6%\n \n9.1%\n \n10.8%\n \n3.8%\n \n0.7%\nNumber in Lung  \nCancer Clinical Trials\n \n3855\n \n60\n \n316\n \n54\n \n12\n14. Mendelian Genetics Experiments are conducted with hybrids of two types of peas. If \nthe offspring follow Mendel’s theory of inheritance, the seeds that are produced are yellow \nsmooth, green smooth, yellow wrinkled, and green wrinkled, and they should occur in the ratio \nof 9:3:3:1, respectively. An experiment is designed to test Mendel’s theory, with the result that \nthe offspring seeds consist of 307 that are yellow smooth, 77 that are green smooth, 98 that are \nyellow wrinkled, and 18 that are green wrinkled. Use a 0.05 significance level to test the claim \nthat the results contradict Mendel’s theory.\nBenford’s Law. According to Benford’s law, a variety of different data sets include numbers \nwith leading (first) digits that follow the distribution shown in the table below. In Exercises 15 \nand 16, test for goodness-of-fit with the distribution described by Benford’s law.\nLeading Digit\n1\n2\n3\n4\n5\n6\n7\n8\n9\nBenford’s Law: Distribution \nof Leading Digits\n \n30.1%\n \n17.6%\n \n12.5%\n \n9.7%\n \n7.9%\n \n6.7%\n \n5.8%\n \n5.1%\n \n4.6%\n15. MRI When analyzing the leading digits of the magnitudes of gradients from an MRI (mag-\nnetic resonance image) of a patient, the frequencies were found to be 0, 15, 0, 76, 479, 183, \n8, 23, and 0, and those digits correspond to the leading digits of 1, 2, 3, 4, 5, 6, 7, 8, and 9, \nrespectively. Use a 0.01 significance level to test for goodness-of-fit with Benford’s law. Do \nthe leading digits appear to fit the distribution of Benford’s law, as expected, or does it ap-\npear that the image has been corrupted because the leading digits do not fit the distribution of \nBenford’s law?\n16. CT Scan When analyzing the leading digits of the magnitudes of gradients from a CT im-\nage, the frequencies were found to be 83, 58, 27, 21, 21, 21, 6, 4, 9, and those digits correspond \nto the leading digits of 1, 2, 3, 4, 5, 6, 7, 8, and 9, respectively. Use a 0.01 significance level to \ntest for goodness-of-fit with Benford’s law. Do the leading digits appear to fit the distribution \nof Benford’s law, as expected, or does it appear that the image has been corrupted because the \nleading digits do not fit the distribution of Benford’s law? Does the conclusion change if the \nsignificance level is 0.05?\nExercises 17 and 18 are based on data sets included in Appendix B. The complete data sets \ncan be found at www.TriolaStats.com.\n17. Admissions for Birth Data Set 3 “Births” includes the days of the weeks that prospec-\ntive mothers were admitted to a hospital to give birth. A physician claims that because many \nbirths are induced or involve cesarean section, they are scheduled for days other than Saturday \nor Sunday, so births do not occur on the seven different days of the week with equal frequency. \nUse a 0.01 significance level to test that claim.\n18. Discharges After Birth Data Set 3 “Births” includes the days of the weeks that newborn \nbabies were discharged from the hospital. A hospital administrator claims that such discharges \noccur on the seven different days of the week with equal frequency. Use a 0.01 significance \nlevel to test that claim.\n\n514 \nCHAPTER 11 Goodness-of-Fit and Contingency Tables\n11-1 Beyond the Basics \n19. Testing Goodness-of-Fit with a Normal Distribution Refer to Data Set 1 “Body Data” \nin Appendix B for the heights of females.\nHeight (cm)\nLess than 155.45\n155.45 - 162.05\n162.05 - 168.65\nGreater than 168.65\nFrequency\na. Enter the observed frequencies in the table above.\nb. Assuming a normal distribution with mean and standard deviation given by the sample mean \nand standard deviation, use the methods of Chapter 6 to find the probability of a randomly \nselected height belonging to each class.\nc. Using the probabilities found in part (b), find the expected frequency for each category.\nd. Use a 0.01 significance level to test the claim that the heights were randomly selected from \na normally distributed population. Does the goodness-of-fit test suggest that the data are from a \nnormally distributed population?\nKey Concept We now consider methods for analyzing contingency tables (or two-\nway frequency tables), which include frequency counts for categorical data arranged \nin a table with at least two rows and at least two columns. In Part 1 of this section, \nwe present a method for conducting a hypothesis test of the null hypothesis that the \nrow and column variables are independent of each other. This test of independence is \nwidely used in real-world applications. In Part 2, we will consider three variations of \nthe basic method presented in Part 1: (1) test of homogeneity, (2) Fisher’s exact test, \nand (3) McNemar’s test for matched pairs.\nPART 1\n Basic Concepts of Testing for Independence \nIn this section we use standard statistical methods to analyze frequency counts in a \ncontingency table (or two-way frequency table).\n11-2 \nContingency Tables\nDEFINITION\nA contingency table (or two-way frequency table) is a table consisting of frequency \ncounts of categorical data corresponding to two different variables. (One variable is \nused to categorize rows, and a second variable is used to categorize columns.)\nThe word contingent has a few different meanings, one of which refers to a de-\npendence on some other factor. We use the term contingency table because we test for \nindependence between the row and column variables. We first define a test of indepen-\ndence and we provide key elements of the test in the Key Elements box that follows.\nDEFINITION\nIn a test of independence, we test the null hypothesis that in a contingency table, \nthe row and column variables are independent. (That is, there is no dependency \nbetween the row variable and the column variable.)\n\n11-2 Contingency Tables \n515\nContingency Table\nObjective\nConduct a hypothesis test of independence between the row variable and column variable in a contingency table.\nNotation\nO represents the observed frequency in a cell of a contingency table.\nE represents the expected frequency in a cell, found by assuming that the row and column variables are independent.\nr represents the number of rows in a contingency table (not including labels or row totals).\nc represents the number of columns in a contingency table (not including labels or columns totals).\nRequirements\n1. The sample data are randomly selected.\n2. The sample data are represented as frequency counts in a two-way table.\n3. For every cell in the contingency table, the expected frequency E is at least 5. (There is no requirement that every  \nobserved frequency must be at least 5.)\nKEY ELEMENTS \nNull and Alternative Hypotheses\nThe null and alternative hypotheses are as follows:\nH0: The row and column variables are independent.\nH1: The row and column variables are dependent.\nTest Statistic for a Test of Independence\nx2 = a\n1O - E2 2\nE\nwhere O is the observed frequency in a cell and E is the \nexpected frequency in a cell that is found by evaluating\nE = 1row total21column total2\n1grand total2\nP-values\nP-values are typically provided by technology, or a range of P-values can be found from Table A-4.\nCritical values\n1. The critical values are found in Table A-4 using\nDegrees of freedom = 1r −12 1c −12\nwhere r is the number of rows and c is the number of columns.\n2. Tests of independence with a contingency table are always right-tailed.\nThe distribution of the test statistic x2 can be approximated by the chi-square \ndistribution, provided that all cells have expected frequencies that are at least 5. \nThe number of degrees of freedom (r - 1)(c - 1) reflects the fact that because \nwe know the total of all frequencies in a contingency table, we can freely assign \nfrequencies to only r - 1 rows and c - 1 columns before the frequency for every \ncell is determined. However, we cannot have negative frequencies or frequencies so \nlarge that any row (or column) sum exceeds the total of the observed frequencies for \nthat row (or column).\n\n516 \nCHAPTER 11 Goodness-of-Fit and Contingency Tables\nFinding Expected Values E\nAn individual expected frequency E for a cell can be found by simply multiplying the \ntotal of the row frequencies by the total of the column frequencies, then dividing by \nthe grand total of all frequencies, as shown in Example 1.\nE = 1row total21column total2\n1grand total2\nCompare the observed O\nvalues to the corresponding\nexpected E values.\nOs and Es\nare close\nOs and Es\nare far apart\n“If the P is low,\nindependence\nmust go.”\nFail to reject\nindependence\nReject\nindependence\nSmall x2 value, large P-value\nLarge x2 value, small P-value\nx2 here\nx2 here\nFIGURE 11-4  Relationships Among Key Components in a  \nTest of Independence\nEXAMPLE 1  Finding Expected Frequency\nTable 11-1 from the Chapter Problem (reproduced on the top of the next page) is a \ncontingency table with four rows and two columns. The cells of the table contain \nfrequency counts. The frequency counts are the observed values and the expected \nvalues are shown in parentheses. The row variable identifies the treatment used for \na stress fracture in a foot bone, and the column variable identifies the outcome as \na success or failure (based on data from “Surgery Unfounded for Tarsal Navicular \nStress Fracture,” by Bruce Jancin, Internal Medicine News, Vol. 42, No. 14). Refer \nto Table 11-1 and find the expected frequency for the cell in the first row and first \ncolumn, where the observed frequency is 54.\nObserved and Expected Frequencies The test statistic allows us to measure the \namount of disagreement between the frequencies actually observed and those that \nwe would theoretically expect when the two variables are independent. Large values \nof the x2 test statistic are in the rightmost region of the chi-square distribution, and \nthey reflect significant differences between observed and expected frequencies. As in \nSection 11-1, if observed and expected frequencies are close, the x2 test statistic will \nbe small and the P-value will be large. If observed and expected frequencies are far \napart, the x2 test statistic will be large and the P-value will be small. These relation-\nships are summarized and illustrated in Figure 11-4.\n\n11-2 Contingency Tables \n517\nSOLUTION\nTABLE 11-1 Treatments for Stress Fracture in a Foot Bone\nSuccess\nFailure\nSurgery\n54 (E = 47.478)\n12 (E = 18.522)\nWeight-Bearing Cast\n41 (E = 66.182)\n51 (E = 25.818)\nNon–Weight-Bearing Cast for 6 Weeks\n70 (E = 52.514)\n3 (E = 20.486)\nNon–Weight-Bearing Cast for Less Than 6 Weeks\n17 (E = 15.826)\n5 (E = 6.174)\nThe first cell lies in the first row (with a total row frequency of 66) and the first \ncolumn (with total column frequency of 182). The “grand total” is the sum of all fre-\nquencies in the table, which is 253. The expected frequency of the first cell is\nE = 1row total21column total2\n1grand total2\n= 166211822\n253\n= 47.478\nINTERPRETATION\nWe know that the first cell has an observed frequency of O = 54 and an expected \nfrequency of E = 47.478. We can interpret the expected value by stating that if \nwe assume that success is independent of the treatment, then we expect to find that \n47.478 of the subjects would be treated with surgery and that treatment would be \nsuccessful. There is a discrepancy between O = 54 and E = 47.478, and such  \ndiscrepancies are key components of the test statistic that is a collective measure  \nof the overall disagreement between the observed frequencies and the frequencies \nexpected with independence between the row and column variables.\nExample 2 illustrates the procedure for conducting a hypothesis test of independence \nbetween the row and column variables in a contingency table.\nEXAMPLE 2   Does the Choice of Treatment for a Fracture  \nAffect Success?\nUse the data from Table 11-1 with a 0.05 significance level to test the claim that \nsuccess of the treatment is independent of the type of treatment. What does the  \nresult indicate about the increasing trend to use surgery?\nSOLUTION\nREQUIREMENT CHECK (1) On the basis of the study description, we will treat the  \nsubjects as being randomly selected and randomly assigned to the different treat-\nment groups. (2) The results are expressed as frequency counts in Table 11-1.  \n(3) The expected frequencies are all at least 5. (The lowest expected frequency  \nis 6.174.) The requirements are satisfied. \nThe null hypothesis and alternative hypothesis are as follows:\nH0: Success is independent of the treatment.\n H1: Success and the treatment are dependent.\nThe significance level is a = 0.05.\nBecause the data in Table 11-1 are in the form of a contingency table, we use \nthe x2 distribution with this test statistic:\nAlternative to  \nClinical Trials\nRheumatolo-\ngist Jenni-\nfer Frankovich \ndiagnosed a \npatient with \nlupus, but \nshe noticed a \nspecific combination of symp-\ntoms that had led to blood clots \nin the past. Her colleagues at \nthe Stanford Packard Children’s \nHospital recommended that she \nnot treat with anti-clotting drugs, \nso she did research but could \nfind no relevant studies. She then \nretrieved the data from all lupus \npatients treated in the hospital \nover the last five years and used \nbasic statistics to find that her \npatient did have a higher risk \nof blood clots, so she then pro-\nceeded to treat with anti-clotting \ndrugs. A randomized clinical \ntrial with treatment and placebo \ngroups would be better, but such \ntrials are rarely conducted for \nsuch specific complications.\ncontinued\n\n518 \nCHAPTER 11 Goodness-of-Fit and Contingency Tables\n x2 = a\n1O - E2 2\nE\n= 154 - 47.4782 2\n47.478\n+ g + 15 - 6.1742 2\n6.174\n = 58.393\nP-Value from Technology If using technology, results typically include the  \nx2 test statistic and the P-value. For example, see the accompanying XLSTAT dis-\nplay showing the test statistic is x2 = 58.393 and the P-value is less than 0.0001.\nP-Value from Table A-4 If using Table A-4 instead of technology, first find the number \nof degrees of freedom: (r - 1)(c - 1) = (4 - 1)(2 - 1) = 3 degrees of freedom. \nBecause the test statistic of x2 = 58.393 exceeds the highest value (12.838) in Table A-4 \nfor the row corresponding to 3 degrees of freedom, we know that P-value 6 0.005.\nBecause the P-value is less than the significance level of 0.05, we reject the null \nhypothesis of independence between success and treatment.\nCritical Value If using the critical value method of hypothesis testing, the critical \nvalue of x2 = 7.815 is found from Table A-4 with a = 0.05 in the right tail and the \nnumber of degrees of freedom given by (r - 1)(c - 1) = (4 - 1)(2 - 1) = 3. \nThe test statistic and critical value are shown in Figure 11-5. Because the test statis-\ntic does fall within the critical region, we reject the null hypothesis of independence \nbetween success and treatment.\nXLSTAT\nCritical\nRegion\n0\nFail to reject\nindependence.\nReject\nindependence.\nTest Statistic:\nx2 5 58.393\nCritical Value:\nx2 5 7.815\nFIGURE 11-5 X2 Test of Independence\nINTERPRETATION\nIt appears that success is dependent on the treatment. Although the results of this \ntest do not tell us which treatment is best, we can calculate from Table 11-1 that \nthe success rates are 81.8%, 44.6%, 95.9%, and 77.3%. This suggests that the best \ntreatment is to use a non–weight-bearing cast for 6 weeks. These results suggest \nthat the increasing use of surgery is a treatment strategy that is not supported by the \nevidence.\n\n11-2 Contingency Tables \n519\nRationale for Expected Frequencies E To better understand expected frequen-\ncies, pretend that we know only the row and column totals in Table 11-1. Let’s assume \nthat the row and column variables are independent and that 1 of the 253 study subjects \nis randomly selected. The probability of getting someone counted in the first cell of \nTable 11-1 is found as follows:\nP1surgery2 = 66>253 and P1success2 = 182>253\nIf the row and column variables are independent as we are assuming, we can use the \nmultiplication rule for independent events (see Section 4-2) as follows:\nP1surgery treatment and success2 = 66\n253 # 182\n253 = 0.187661\nWith a probability of 0.187661 for the first cell, we expect that among 253 subjects, \nthere are 253 # 0.187661 = 47.478 subjects in the first cell. If we generalize these \ncalculations, we get the following:\nExpected frequency E = 1grand total2 # 1row total2\n1grand total2 # 1column total2\n1grand total2\nThis expression can be simplified to\nE = 1row total21column total2\n1grand total2\nPART 2\n  Test of Homogeneity, Fisher’s Exact Test, \nand McNemar’s Test for Matched Pairs\nTest of Homogeneity\nIn Part 1 of this section, we focused on the test of independence between the row and \ncolumn variables in a contingency table. In Part 1, the sample data are from one popu-\nlation, and individual sample results are categorized with the row and column vari-\nables. In a chi-square test of homogeneity, we have samples randomly selected from \ndifferent populations, and we want to determine whether those populations have the \nsame proportions of some characteristic being considered. (The word homogeneous \nmeans “having the same quality,” and in this context, we are testing to determine \nwhether the proportions are the same.) Section 9-1 presented a procedure for testing a \nclaim about two populations with categorical data having two possible outcomes, but \na chi-square test of homogeneity allows us to use two or more populations with out-\ncomes from several categories.\nDEFINITION\nA chi-square test of homogeneity is a test of the claim that different populations \nhave the same proportions of some characteristics.\nSampling from Different Populations In a typical test of independence as de-\nscribed in Part 1 of this section, sample subjects are randomly selected from one \npopulation (such as people treated for stress fractures in a foot bone) and values of \ndifferent variables are observed (such as success>failure for people receiving differ-\nent treatments). In a typical chi-square test of homogeneity, subjects are randomly \nselected from the different populations separately.\n\n520 \nCHAPTER 11 Goodness-of-Fit and Contingency Tables\nProcedure In conducting a test of homogeneity, we can use the same notation, require-\nments, test statistic, critical value, and procedures given in the Key Elements box from \nPart 1 on page 515 of this section, with this exception: Instead of testing the null hypoth-\nesis of independence between the row and column variables, we test the null hypothesis \nthat the different populations have the same proportion of some characteristic.\nFisher’s Exact Test\nThe procedures for testing hypotheses with contingency tables have the requirement \nthat every cell must have an expected frequency of at least 5. This requirement is neces-\nsary for the x2 distribution to be a suitable approximation to the exact distribution of the \nx2 test statistic. Fisher’s exact test is often used for a 2 * 2 contingency table with one or \nmore expected frequencies that are below 5. Fisher’s exact test provides an exact P-value \nand does not require an approximation technique. Because the calculations are quite com-\nplex, it’s a good idea to use technology when using Fisher’s exact test. Statdisk, Minitab, \nXLSTAT, and StatCrunch all have the ability to perform Fisher’s exact test.\nEXAMPLE 3  Does Yawning Cause Others to Yawn?\nThe MythBusters show on the Discovery Channel tested the theory that when some-\none yawns, others are more likely to yawn. The results are summarized in Table 11-6. \nThe methods of Part 1 in this section should not be used because one of the cells has \nan expected frequency of 4.480, which violates the requirement that every cell must \nhave an expected frequency E of at least 5. Using Fisher’s exact test results in a  \nP-value of 0.513, so there is not sufficient evidence to support the myth that people \nexposed to yawning actually yawn more than those not exposed to yawning. (For  \ntesting the claim of no difference, the P-value is 1.000, indicating that there is not a \nsignificant difference between the two groups.)\nTABLE 11-6 Yawning Theory Experiment\nSubject Exposed to Yawning?\nYes\nNo\nDid Subject Yawn?\nYes\n10\n 4\nNo\n24\n12\nMcNemar’s Test for Matched Pairs\nThe methods in Part 1 of this section are based on independent data. For 2 * 2 ta-\nbles consisting of frequency counts that result from matched pairs, the frequency \ncounts within each matched pair are not independent and, for such cases, we can use \nMcNemar’s test of the null hypothesis that the frequencies from the discordant (different) \ncategories occur in the same proportion.\nTable 11-7 shows a general format for summarizing results from data consisting \nof frequency counts from matched pairs. Table 11-7 refers to two different treatments \n(such as two different eye drop solutions) applied to two different parts of each subject \n(such as left eye and right eye). We should be careful when reading a table such as \nTable 11-7. If a = 100, then 100 subjects were cured with both treatments. If b = 50 \nin Table 11-7, then each of 50 subjects had no cure with treatment X but they were \neach cured with treatment Y. The total number of subjects is a + b + c + d, and \neach of those subjects yields results from each of two parts of a matched pair. Remem-\nber, the entries in Table 11-7 are frequency counts of subjects, not the total number of \nindividual components in the matched pairs. If 500 people have each eye treated with \ntwo different ointments, the value of a + b + c + d is 500 (the number of subjects), \nnot 1000 (the number of treated eyes).\nP\nm\nP\ne\nPolls and Psychologists\nPoll results \ncan be \ndramatically \naffected by \nthe wording of \nquestions. A \nphrase such \nas “over the last few years” is \ninterpreted differently by different \npeople. Over the last few years \n(actually, since 1980), survey \nresearchers and psychologists \nhave been working together to \nimprove surveys by decreasing \nbias and increasing accuracy. In \none case, psychologists studied \nthe finding that 10 to 15 percent \nof those surveyed say they voted \nin the last election when they \ndid not. They experimented with \ntheories of faulty memory, a \ndesire to be viewed as respon-\nsible, and a tendency of those \nwho usually vote to say that they \nvoted in the most recent election, \neven if they did not. Only the last \ntheory was actually found to be \npart of the problem.\n\n11-2 Contingency Tables \n521\nTABLE 11-7 2 * 2 Table with Frequency Counts from Matched Pairs\nTreatment X\nCured\nNot Cured\nTreatment Y\nCured\na\nb\nNot Cured\nc\nd\nMcNemar’s test requires that for a table such as Table 11-7, the frequencies are such \nthat b + c Ú 10. The test is a right-tailed chi-square test with the following test statistic:\nx2 = 1 \u001eb - c \u001e - 12 2\nb + c\nP-values are typically provided by software, and critical values can be found in \nTable A-4 using 1 degree of freedom. Caution: When applying McNemar’s test, be \ncareful to use only the two frequency counts from discordant (different) pairs, such as \nthe frequency b in Table 11-7 (with different pairs of cured>not cured) and frequency \nc in Table 11-7 (with different pairs of not cured>cured).\nEXAMPLE 4  Are Hip Protectors Effective?\nA randomized controlled trial was designed to test the effectiveness of hip protectors \nin preventing hip fractures in the elderly. Nursing home residents each wore protec-\ntion on one hip, but not the other. Results are summarized in Table 11-8 (based on \ndata from Journal of the American Medical Association). McNemar’s test can be \nused to test the null hypothesis that the following two proportions are the same:\n \n■The proportion of subjects with no hip fracture on the protected hip and a hip \nfracture on the unprotected hip.\n \n■The proportion of subjects with a hip fracture on the protected hip and no hip \nfracture on the unprotected hip.\nUsing the discordant (different) pairs with the general format from Table 11-7, we \nhave b = 10 and c = 15, so the test statistic is calculated as follows:\nx2 = 1 \u001eb - c \u001e - 12 2\nb + c\n= 1 \u001e10 - 15\u001e - 12 2\n10 + 15\n= 0.640\nWith a 0.05 significance level and degrees of freedom given by df = 1, we refer to \nTable A-4 to find the critical value of x2 = 3.841 for this right-tailed test. The test \nstatistic of x2 = 0.640 does not exceed the critical value of x2 = 3.841, so we fail \nto reject the null hypothesis. (Also, the P-value is 0.424, which is greater than 0.05, \nindicating that we fail to reject the null hypothesis.) The proportion of hip fractures \nwith the protectors worn is not significantly different from the proportion of hip \nfractures without the protectors worn. The hip protectors do not appear to be effec-\ntive in preventing hip fractures.\nTABLE 11-8 Randomized Controlled Trial of Hip Protectors\nNo Hip Protector Worn\nNo Hip Fracture\nHip Fracture\nHip Protector Worn\nNo Hip Fracture\n309\n10\nHip Fracture\n 15\n 2\nContingency Tables\nAccess tech instructions, videos, and data sets at www.TriolaStats.com\nTECH CENTER \n\n522 \nCHAPTER 11 Goodness-of-Fit and Contingency Tables\nStatistical Literacy and Critical Thinking\n1. Handedness and Cell Phone Use The accompanying table is from a study conducted \nwith the stated objective of addressing cell phone safety by understanding why we use a partic-\nular ear for cell phone use. (See “Hemispheric Dominance and Cell Phone Use,” by Seidman, \nSiegel, Shah, and Bowyer, JAMA Otolaryngology—Head & Neck Surgery, Vol. 139, No. 5.) \nThe goal was to determine whether the ear choice is associated with auditory or language brain \nhemispheric dominance. Assume that we want to test the claim that handedness and cell phone \near preference are independent of each other.\na. Use the data in the table to find the expected value for the cell that has an observed fre-\nquency of 3. Round the result to three decimal places.\nb. What does the expected value indicate about the requirements for the hypothesis test?\nEar Preference for Cell Phone Use\nRight Ear\nLeft Ear\nNo Preference\nRight-Handed\n436\n166\n40\nLeft-Handed\n 16\n 50\n 3\n2. Hypotheses Refer to the data given in Exercise 1 and assume that the requirements are all \nsatisfied and we want to conduct a hypothesis test of independence using the methods of this \nsection. Identify the null and alternative hypotheses.\n3. Hypothesis Test The accompanying TI-83>84 Plus calculator display results from the \nhypothesis test described in Exercise 1. Assume that the hypothesis test requirements are all \nsatisfied. Identify the test statistic and the P-value (expressed in standard form and rounded to \nthree decimal places), and then state the conclusion about the null hypothesis.\n4. Right-Tailed, Left-Tailed, Two-Tailed Is the hypothesis test described in Exercise 1 \nright-tailed, left-tailed, or two-tailed? Explain your choice.\nIn Exercises 5–20, test the given claim.\n5. Splint or Surgery? A randomized controlled trial was designed to compare the effective-\nness of splinting versus surgery in the treatment of carpal tunnel syndrome. Results are given in \nthe table below (based on data from “Splinting vs. Surgery in the Treatment of Carpal Tunnel \nSyndrome,” by Gerritsen et al., Journal of the American Medical Association, Vol. 288, No. 10). \nThe results are based on evaluations made one year after the treatment. Using a 0.01 signifi-\ncance level, test the claim that success is independent of the type of treatment. What do the \nresults suggest about treating carpal tunnel syndrome?\nSuccessful Treatment\nUnsuccessful Treatment\nSplint Treatment\n60\n23\nSurgery Treatment\n67\n 6\n6. Texting and Drinking In a study of high school students at least 16 years of age, researchers \nobtained survey results summarized in the accompanying table (based on data from “Texting \nWhile Driving and Other Risky Motor Vehicle Behaviors Among U. S. High School Students,” \nby O’Malley, Shults, and Eaton, Pediatrics, Vol. 131, No. 6). Use a 0.05 significance level to test \nthe claim of independence between texting while driving and driving when drinking alcohol. \nAre those two risky behaviors independent of each other?\nDrove When Drinking Alcohol?\nYes\nNo\nTexted While Driving\n731\n3054\nNo Texting While Driving\n156\n4564\n11-2 Basic Skills and Concepts\n\n11-2 Contingency Tables \n523\n7. Tooth Fillings and Adverse Health Conditions The table below shows results from a \nstudy in which some dental patients were treated with amalgam restorations and others were \ntreated with composite restorations that do not contain mercury (based on data from “Neuro-\npsychological and Renal Effects of Dental Amalgam in Children,” by Bellinger et al., Journal \nof the American Medical Association, Vol. 295, No. 15). Use a 0.05 significance level to test \nfor independence between the type of restoration and the presence of any adverse health condi-\ntions. Do amalgam restorations appear to affect health conditions?\nAmalgam\nComposite\nAdverse Health Condition Reported\n135\n145\nNo Adverse Health Condition Reported\n132\n122\n8. Tooth Fillings and Sensory Disorders In recent years, concerns have been expressed \nabout adverse health effects from amalgam dental restorations, which include mercury. The \ntable below shows results from a study in which some patients were treated with amalgam \nrestorations and others were treated with composite restorations that do not contain mercury \n(based on data from “Neuropsychological and Renal Effects of Dental Amalgam in Children,” \nby Bellinger et al., Journal of the American Medical Association, Vol. 295, No. 15). Use a 0.05 \nsignificance level to test for independence between the type of restoration and sensory disor-\nders. Do amalgam restorations appear to affect sensory disorders?\nAmalgam\nComposite\nSensory Disorder\n 36\n 28\nNo Sensory Disorder\n231\n239\n9. Can Dogs Detect Cancer? An experiment was conducted to test the ability of dogs to detect \nbladder cancer. Dogs were tested with urine samples from bladder cancer patients and people in \na control group who did not have bladder cancer. Results are given in the table below (based on \ndata from the New York Times). Using a 0.01 significance level, test the claim that the source of \nthe sample (healthy or with bladder cancer) is independent of the dog’s selections. What do the \nresults suggest about the ability of dogs to detect bladder cancer? If the dogs did significantly \nbetter than random guessing, did they do well enough to be used for accurate diagnoses?\nSample from Subject  \nWith Bladder Cancer\nSample from Subject  \nWithout Bladder Cancer\nDog Identified Subject as Cancerous\n22\n 32\nDog Did Not Identify Subject as \nCancerous\n \n32\n \n282\n10. Lie Detector The table below includes results from polygraph (lie detector) experi-\nments conducted by researchers Charles R. Honts (Boise State University) and Gordon H. \nBarland (Department of Defense Polygraph Institute). In each case, it was known if the sub-\nject lied or did not lie, so the table indicates when the polygraph test was correct. Use a 0.05 \nsignificance level to test the claim that whether a subject lies is independent of the poly-\ngraph test indication. Do the results suggest that polygraphs are effective in distinguishing \nbetween truths and lies?\nDid the Subject Actually Lie?\nNo (Did Not Lie)\nYes (Lied)\nPolygraph Test Indicated that \nthe Subject Lied.\n \n15\n \n42\nPolygraph Test Indicated that \nthe Subject Did Not Lie.\n \n32\n \n 9\n11. Clinical Trial of Chantix Chantix (varenicline) is a drug used as an aid for those who want \nto stop smoking. The adverse reaction of nausea has been studied in clinical trials, and the table \nbelow summarizes results (based on data from Pfizer). Use a 0.01 significance level to test the \ncontinued\n\n524 \nCHAPTER 11 Goodness-of-Fit and Contingency Tables\nclaim that nausea is independent of whether the subject took a placebo or Chantix. Does nausea \nappear to be a concern for those using Chantix?\nPlacebo\nChantix\nNausea\n 10\n 30\nNo Nausea\n795\n791\n12. Is the Vaccine Effective? In a USA Today article about an experimental vaccine for chil-\ndren, the following statement was presented: “In a trial involving 1602 children, only 14 (1%) \nof the 1070 who received the vaccine developed the flu, compared with 95 (18%) of the 532 \nwho got a placebo.” The data are shown in the table below. Use a 0.05 significance level to \ntest for independence between the variable of treatment (vaccine or placebo) and the variable \nrepresenting flu (developed flu, did not develop flu). Does the vaccine appear to be effective?\nDeveloped Flu?\nYes\nNo\nVaccine Treatment\n14\n1056\nPlacebo\n95\n 437\n13. Texting and Seat Belt Use In a study of high school students at least 16 years of age, \nresearchers obtained survey results summarized in the accompanying table (based on data from \n“Texting While Driving and Other Risky Motor Vehicle Behaviors Among U. S. High School \nStudents,” by O’Malley, Shults, and Eaton, Pediatrics, Vol. 131, No. 6). Use a 0.05 significance \nlevel to test the claim of independence between texting while driving and irregular seat belt \nuse. Are those two risky behaviors independent of each other?\nIrregular Seat Belt Use?\nYes\nNo\nTexted While Driving\n1737\n2048\nNo Texting While Driving\n1945\n2775\n14. Unusual Patient Deaths Alert nurses at the Veteran’s Affairs Medical Center in \nNorthampton, Massachusetts, noticed an unusually high number of deaths at times when an-\nother nurse, Kristen Gilbert, was working. Those same nurses later noticed missing supplies of \nthe drug epinephrine, which is a synthetic adrenaline that stimulates the heart. Kristen Gilbert \nwas arrested and charged with four counts of murder and two counts of attempted murder. \nWhen seeking a grand jury indictment, prosecutors provided a key piece of evidence consisting \nof the table below. Use a 0.01 significance level to test the defense claim that deaths on shifts \nare independent of whether Gilbert was working. What does the result suggest about the guilt \nor innocence of Gilbert?\nShifts With a Death\nShifts Without a Death\nGilbert Was Working\n40\n 217\nGilbert Was Not Working\n34\n1350\n15. Clinical Trial of Campral Campral (acamprosate) is a drug used to help patients continue their \nabstinence from the use of alcohol. Adverse reactions of Campral have been studied in clinical trials, \nand the table below summarizes results for digestive system effects among patients from different \ntreatment groups (based on data from Forest Pharmaceuticals, Inc.). Use a 0.01 significance level \nto test the claim that experiencing an adverse reaction in the digestive system is independent of the \ntreatment group. Does Campral treatment appear to have an effect on the digestive system?\nPlacebo\nCampral 1332 mg\nCampral 1998 mg\nAdverse Effect on Digestive System\n 344\n 89\n 8\nNo Effect on Digestive System\n1362\n774\n71\n\n11-2 Contingency Tables \n525\n16. Clinical Trial of Lipitor Lipitor is the trade name of the drug atorvastatin, which is used \nto reduce cholesterol in patients. This is the largest-selling drug in the world, with $13 billion \nin sales for a recent year. Adverse reactions have been studied in clinical trials, and the table \nbelow summarizes results for infections in patients from different treatment groups (based on \ndata from Parke-Davis). Use a 0.05 significance level to test the claim that getting an infection \nis independent of the treatment. Does the atorvastatin treatment appear to have an effect on \ninfections?\nPlacebo\nAtorvastatin 10 mg\nAtorvastatin 40 mg\nAtorvastatin 80 mg\nInfection\n 27\n 89\n 8\n 7\nNo Infection\n243\n774\n71\n87\n17. Is Seat Belt Use Independent of Cigarette Smoking? A study of seat belt users and \nnonusers yielded the randomly selected sample data summarized in the given table (based \non data from “What Kinds of People Do Not Use Seat Belts?” by Helsing and Comstock, \nAmerican Journal of Public Health, Vol. 67, No. 11). Test the claim that the amount of smok-\ning is independent of seat belt use. A plausible theory is that people who smoke more are less \nconcerned about their health and safety and are therefore less inclined to wear seat belts. Is this \ntheory supported by the sample data?\nNumber of Cigarettes Smoked per Day\n0\n1–14\n15–34\n35 and over\nWear Seat Belts\n175\n20\n42\n6\nDon’t Wear Seat Belts\n149\n17\n41\n9\n18. Clinical Trial of Echinacea In a clinical trial of the effectiveness of echinacea for pre-\nventing colds, the results in the table below were obtained (based on data from “An Evalua-\ntion of Echinacea Angustifolia in Experimental Rhinovirus Infections,” by Turner et al., New \nEngland Journal of Medicine, Vol. 353, No. 4). Use a 0.05 significance level to test the claim \nthat getting a cold is independent of the treatment group. What do the results suggest about the \neffectiveness of echinacea as a prevention against colds?\nTreatment Group\nPlacebo\nEchinacea: 20% Extract\nEchinacea: 60% Extract\nGot a Cold\n88\n48\n42\nDid Not Get a Cold\n15\n 4\n10\n19. Injuries and Motorcycle Helmet Color A case-control (or retrospective) study was \nconducted to investigate a relationship between the colors of helmets worn by motorcycle \ndrivers and whether they are injured or killed in a crash. Results are given in the table below \n(based on data from “Motorcycle Rider Conspicuity and Crash Related Injury: Case-Control \nStudy,” by Wells et al., BMJ USA, Vol. 4). Test the claim that injuries are independent of \nhelmet color. Should motorcycle drivers choose helmets with a particular color? If so, which \ncolor appears best?\nColor of Helmet\nBlack\nWhite\nYellow, Orange\nRed\nBlue\nControls (not injured)\n491\n377\n31\n170\n55\nCases (injured or killed)\n213\n112\n 8\n 70\n26\n20. Baseball Player Births In his book Outliers, author Malcolm Gladwell argues that more \nAmerican-born baseball players have birthdates in the months immediately following July \n31 because that was the age cutoff date for nonschool baseball leagues. The table below lists \nmonths of births for a sample of American-born baseball players and foreign-born baseball \nplayers. Using a 0.05 significance level, is there sufficient evidence to warrant rejection of the \ncontinued\n\n526 \nCHAPTER 11 Goodness-of-Fit and Contingency Tables\nclaim that months of births of baseball players are independent of whether they are born in \nAmerica? Do the data appear to support Gladwell’s claim?\nJan.\nFeb.\nMarch\nApril\nMay\nJune\nJuly\nAug.\nSept.\nOct.\nNov.\nDec.\nBorn in \nAmerica\n \n387\n \n329\n \n366\n \n344\n \n336\n \n313\n \n313\n \n503\n \n421\n \n434\n \n398\n \n371\nForeign Born\n101\n 82\n 85\n 82\n 94\n 83\n 59\n 91\n 70\n100\n103\n 82\n21. Equivalent Tests A x2 test involving a 2 * 2 table is equivalent to the test for the dif-\nference between two proportions, as described in Section 9-1. Using the claim and table in \nExercise 5 “Splint or Surgery?” verify that the x2 test statistic and the z test statistic (found \nfrom the test of equality of two proportions) are related as follows: z2 = x2. Also show that the \ncritical values have that same relationship.\n22. Using Yates’s Correction for Continuity The chi-square distribution is continuous, \nwhereas the test statistic used in this section is discrete. Some statisticians use Yates’s correc-\ntion for continuity in cells with an expected frequency of less than 10 or in all cells of a contin-\ngency table with two rows and two columns. With Yates’s correction, we replace\na\n1O - E2 2\nE\n with a\n1 \u001dO - E \u001d - 0.52 2\nE\nGiven the contingency table in Exercise 5 “Splint or Surgery?” find the value of the x2 test \nstatistic using Yates’s correction in all cells. What effect does Yates’s correction have?\n11-2 Beyond the Basics\nChapter Quick Quiz\nExercises 1–5 refer to the sample data in the following table, which summarizes the last \ndigits of the heights (cm) of 300 randomly selected subjects (from Data Set 1 “Body Data”). \nAssume that we want to use a 0.05 significance level to test the claim that the data are from \na population having the property that the last digits are all equally likely.\nLast Digit\n 0\n 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\nFrequency\n30\n35\n24\n25\n35\n36\n37\n27\n27\n24\n1. What are the null and alternative hypotheses corresponding to the stated claim?\n2. When testing the claim in Exercise 1, what are the observed and expected frequencies for the \nlast digit of 7?\n3. Is the hypothesis test left-tailed, right-tailed, or two-tailed?\n4. If using a 0.05 significance level to test the stated claim, find the number of degrees of freedom.\n5. Given that the P-value for the hypothesis test is 0.501, what do you conclude? Does it appear \nthat the heights were obtained through measurement or that the subjects reported their heights?\nQuestions 6–10 refer to the sample data in the following table, which describes the fate of \nthe passengers and crew aboard the Titanic when it sank on April 15, 1912. Assume that the \ndata are a sample from a large population and we want to use a 0.05 significance level to test \nthe claim that surviving is independent of whether the person is a man, woman, boy, or girl.\nMen\nWomen\nBoys\nGirls\nSurvived\n 332\n318\n29\n27\nDied\n1360\n104\n35\n18\n\n6. Identify the null and alternative hypotheses corresponding to the stated claim.\n7. What distribution is used to test the stated claim (normal, t, F, chi-square, uniform)?\n8. Is the hypothesis test left-tailed, right-tailed, or two-tailed?\n9. Find the number of degrees of freedom.\n10. Given that the P-value for the hypothesis test is 0.0000 when rounded to four decimal \nplaces, what do you conclude? What do the results indicate about the rule that women and chil-\ndren should be the first to be saved?\n1.  Weather-Related Deaths For a recent year, the numbers of weather-related deaths for \neach month are 28, 17, 12, 24, 88, 61, 104, 32, 20, 13, 26, 25 (listed in order beginning with \nJanuary). Use a 0.01 significance level to test the claim that weather-related deaths occur in the \ndifferent months with the same frequency. Provide an explanation for the result.\n2. Norovirus on Cruise Ships The Queen Elizabeth II cruise ship and Royal Caribbean’s \nFreedom of the Seas cruise ship both experienced outbreaks of norovirus infection within two \nmonths of each other. Results are shown in the table below. Use a 0.05 significance level to test \nthe claim that getting norovirus infection is independent of the ship. Based on these results, \ndoes it appear that an outbreak of norovirus infection has the same effect on different ships?\nNorovirus Infection\nNo Norovirus Infection\nQueen Elizabeth II\n276\n1376\nFreedom of the Seas\n338\n3485\n3. NYC Homicides For a recent year, the following are the numbers of homicides that occurred \neach month in New York City, starting with January: 38, 30, 46, 40, 46, 49, 47, 50, 50, 42, 37, \nand 37. Use a 0.05 significance level to test the claim that homicides in New York City are \nequally likely for each of the 12 months. Is there sufficient evidence to support the police com-\nmissioner’s claim that homicides occur more often in the summer when the weather is warmer?\n4.  Genetics and Handedness In a study of left-handedness as a possible inherited trait, \nthe data in the table below were obtained (based on data from “Why Are Some People Left-\nHanded? An Evolutionary Perspective,” by Laurens and Faurie, Philosophical Transactions, \nVol. 364). Use a 0.01 significance level to test the claim that left-handedness is independent of \nparental handedness. What do the results suggest about the inheritability of left-handedness?\nParental Handedness\nOffspring Left-Handed?\nFather, Mother\nYes\nNo\nRight>Right\n5360\n50,928\nRight>Left\n 767\n   2736\nLeft>Right\n 741\n   3667\nLeft>Left\n  94\n    289\n5. Car Crashes and Age Brackets Among drivers who have had a car crash in the last year, \n88 are randomly selected and categorized by age, with the results listed in the accompanying \ntable (based on data from the Insurance Information Institute). If all ages have the same crash \nrate, we would expect (because of the age distribution of licensed drivers) the given categories \nto have 16%, 44%, 27%, and 13% of the subjects, respectively. At the 0.05 significance level, \ntest the claim that the distribution of crashes conforms to the distribution of ages. Does any age \ngroup appear to have a disproportionate number of crashes?\nAge\nUnder 25\n25–44\n45–64\nOver 64\nDrivers\n36\n21\n12\n19\nReview Exercises\nCHAPTER 11 Review Exercises \n527\n\n528 \nCHAPTER 11 Goodness-of-Fit and Contingency Tables\n1.  ICU Patients Listed below are the ages of randomly selected patients in intensive care \nunits (ICUs) (based on data from “A Multifaceted Intervention for Quality Improvement in a \nNetwork of Intensive Care Units,” by Scales et al., Journal of the American Medical Association, \nVol. 305, No. 4). Find the mean, median, standard deviation, and variance. Based on the results, \nis an age of 16 years significantly low? Why or why not?\n38 64 35 67 42 29 68 62 74 58\n2. ICU Patients Use the sample of ages from Exercise 1 to construct a 95% confidence in-\nterval estimate of the mean age of the population of ICU patients. Do the confidence interval \nlimits contain the value of 65.0 years that was found from a sample of 9269 ICU patients?\n3. Bicycle Helmets A study was conducted of 531 persons injured in bicycle crashes, and \nrandomly selected sample results are summarized in the accompanying table (based on results \nfrom “A Case-Control Study of the Effectiveness of Bicycle Safety Helmets in Preventing Fa-\ncial Injury,” by Thompson et al., American Journal of Public Health, Vol. 80, No. 12). Use a \n0.05 significance level to test the claim that wearing a helmet has no effect on whether facial \ninjuries are received. Based on these results, does a helmet seem to be effective in helping to \nprevent facial injuries in a crash?\nHelmet Worn\nNo Helmet\nFacial Injuries Received\n30\n182\nAll Injuries Nonfacial\n83\n236\n4. Bicycle Helmets Use the data in the table from Cumulative Review Exercise 3 and assume \nthat random selections are made from the 531 people included in the study.\na. Find the probability that if 1 of the 531 subjects is randomly selected, the result is someone \nwho had only nonfacial injuries or was someone who wore a helmet.\nb. Find the probability that if two different subjects are randomly selected, they are both sub-\njects who wore a helmet.\nc. Find the probability that if a subject is randomly selected, the result is someone who did not \nwear a helmet.\n5. Forward Grip Reach and Ergonomics When designing instrument controls, car dash-\nboards, and aircraft cockpits, we must consider the forward grip reach of women. Women have \nnormally distributed forward grip reaches with a mean of 686 mm and a standard deviation of \n34 mm (based on anthropometric survey data from Gordon, Churchill, et al.).\na. If a car dashboard is positioned so that it can be reached by 95% of women, what is the \nshortest forward grip reach that can access the dashboard?\nb. If a car dashboard is positioned so that it can be reached by women with a grip reach greater \nthan 650 mm, what percentage of women cannot reach the dashboard? Is that percentage too high?\nc. Find the probability that 16 randomly selected women have forward grip reaches with a \nmean greater than 680 mm. Does this result have any effect on the design?\n6. Diastolic BP and Height The table below lists diastolic blood pressure (BP) measurements \n(mm Hg) and height (cm) of randomly selected males from Data Set 1 “Body Data” in Appendix B. \nIdentify the analysis that should be conducted, then conduct that analysis.\nDiastolic BP\n70.0\n58.0\n40.0\n66\n66.0\n82.0\nHeight\n180.4\n166.3\n181.1\n170\n180.8\n174.7\nCumulative Review Exercises\n\nUse any software package or calculator capable of generating equally likely random digits be-\ntween 0 and 9 inclusive. Generate 5000 digits and record the results in the accompanying table. \nUse a 0.05 significance level to test the claim that the sample digits come from a population \nwith a uniform distribution with all digits being equally likely. Does the random number gen-\nerator appear to be working as it should?\nDigit\n0\n1\n2\n3\n4\n5\n6\n7\n8\n9\nFrequency\nTechnology Project\nFROM DATA TO DECISION\nCritical Thinking: Determining Whether a  \nVaccine Is Effective\nThe largest public health experiment involved 401,974 chil-\ndren who were randomly assigned to two groups. In one \ngroup, 201,229 children were given a placebo. In the other \ngroup, 200,745 children were treated with the Salk vaccine \ndesigned to prevent polio. Among the children in the placebo \ngroup, 115 developed polio, and among the children in the \nSalk vaccine treatment group, 33 developed polio.\nAnalyzing the Results\na. The experiment was a “double blind” experiment. What \ndoes that mean?\nb. Informally compare the results. Does it appear that the \nSalk vaccine is effective? Why or why not?\nc. Use the methods of Section 9-1 to determine whether there \nis sufficient evidence to support a claim that the Salk vaccine \nis effective. Does it appear that the Salk vaccine is effective? \nWhy or why not?\nd. Use the methods of Section 11-2 to determine whether \nthe treatment (vaccine or placebo) is independent of devel-\noping polio.\ne. Compare the results from parts (c) and (d).\n1.  Out-of-class activity Divide into groups of four or five students. Each group member \nshould survey at least 15 male students and 15 female students at the same college by asking \nthis question: If you were to make up an absence excuse of a flat tire, which tire would you say \nwent flat if the instructor asked? (See Exercise 8 in Section 11-1.) Ask the subject to write the \nresponses on an index card, and also record the gender of the subject and whether the subject \nwrote with the right or left hand. Use the methods of this chapter to analyze the data collected. \nInclude these claims:\n• The four possible choices for a flat tire are selected with equal frequency.\n• The tire identified as being flat is independent of the gender of the subject.\n• The tire identified as being flat is independent of whether the subject is right- or left-handed.\n• Gender is independent of whether the subject is right- or left-handed.\n2.  Out-of-class activity Divide into groups of four or five students. Each group member \nshould select about 15 other students and first ask them to “randomly” select four digits each. \nAfter the four digits have been recorded, ask each subject to write the last four digits of his or \nher Social Security number (for security, write these digits in any order). Take the “random” \nsample results of individual digits and mix them into one big sample, then mix the individual \nSocial Security digits into a second big sample. Using the “random” sample set, test the claim \nCooperative Group Activities\nCHAPTER 11 Cooperative Group Activities \n529\ncontinued\n\n530 \nCHAPTER 11 Goodness-of-Fit and Contingency Tables\nthat students select digits randomly. Then use the Social Security digits to test the claim that \nthey come from a population of random digits. Compare the results. Does it appear that stu-\ndents can randomly select digits? Are they likely to select any digits more often than others? \nAre they likely to select any digits less often than others? Do the last digits of Social Security \nnumbers appear to be randomly selected?\n3. In-class activity Divide into groups of three or four students. Each group should be given \na die along with the instruction that it should be tested for “fairness.” Is the die fair or is it \nbiased? Describe the analysis and results.\n4. Out-of-class activity Divide into groups of two or three students. The analysis of last digits \nof data can sometimes reveal whether values are the results of actual measurements or whether \nthey are reported estimates. Find the numbers of active physicians in each state, then analyze \nthe last digits to determine whether those numbers appear to be actual counts or whether they \nappear to be reported estimates.\n5. Out-of-class activity Divide into groups of four or five students. Example 2 in Section 11-1 \nnoted that according to Benford’s law, a variety of different data sets include numbers with \nleading (first) digits that follow the distribution shown in the table below. Collect original data \nand use the methods of Section 11-1 to support or refute the claim that the data conform rea-\nsonably well to Benford’s law. Here are some suggestions: (1) leading digits of the numbers of \nactive physicians in each of the states; (2) leading digits of smartphone passcodes; (3) leading \ndigits of the numbers of Facebook friends.\nLeading Digit\n1\n2\n3\n4\n5\n6\n7\n8\n9\nBenford’s Law\n30.1%\n17.6%\n12.5%\n9.7%\n7.9%\n6.7%\n5.8%\n5.1%\n4.6%\n\n531\nAn important environment>health study involved children \nwho lived within 7 km (about 4 miles) of a large ore smelter in \nEl Paso, Texas. A smelter is used to melt the ore in order to \nseparate the metals in it. Because the smelter emitted lead pol-\nlution, there was concern that these children would somehow \nsuffer. The focus of this Chapter Problem is to investigate the \npossible effect of lead exposure on “performance” IQ scores \nas measured by the Wechsler intelligence scale. (A full IQ \nscore is a combination of a performance IQ score and a verbal \nIQ score. The performance test includes components such as \npicture analysis, picture arrangement, and matching patterns.)\nData from the study are included in Data Set 8 “IQ and \nLead” in Appendix B. Based on measured blood lead levels, \nthe children were partitioned into a low lead level group, a \nDoes Exposure to Lead Affect IQ Scores of Children?\nCHAPTER \nPROBLEM\nOne-Way ANOVA\nTwo-Way ANOVA\n12-1\n12-2\n12 \nAnalysis of Variance\n\nis somewhat higher than the means of the medium and high \ngroups. The boxplots all overlap, so differences do not appear to \nbe dramatic. But we need more formal methods that allow us to \nrecognize any significant differences. We could use the methods \nof Section 9-2 to compare means from samples collected from \ntwo different populations, but here we need to compare means \nfrom samples collected from three different populations. When \nwe have samples from three or more populations, we can test for \nequality of the population means by using the method of analysis \nof variance, to be introduced in Section 12-1. In Section 12-1, \nwe will use analysis of variance to test the claim that the three \nsamples are from populations with the same mean.\nmedium lead level group, or a high lead level group. (See Data \nSet 8 for the specific blood lead level cutoff values.) The per-\nformance IQ scores are included in Table 12-1 (based on data \nfrom “Neuropsychological Dysfunction in Children with Chronic \nLow-Level Lead Absorption,” by P. J. Landrigan, R. H. Whitworth, \nR. W. Baloh, N. W. Staehling, W. F. Barthel, and B. F. Rosenblum, \nLancet, Vol. 1, Issue 7909).\nBefore jumping into the application of a particular statistical \nmethod, we should first explore the data. Sample statistics are \nincluded in the table below. Also refer to the following boxplots \nof the three sets of performance IQ scores. Informal and sub-\njective comparisons show that the low group has a mean that \nTABLE 12-1  Performance IQ Scores of Children\nLow Blood Lead Level\n  85\n  90\n107\n  85\n100\n  97\n101\n  64\n111\n100\n  76\n136\n100\n  90\n135\n104\n149\n  99\n107\n  99\n113\n104\n101\n111\n118\n  99\n122\n  87\n118\n113\n128\n121\n111\n104\n  51\n100\n113\n  82\n146\n107\n  83\n108\n  93\n114\n113\n  94\n106\n  92\n  79\n129\n114\n  99\n110\n  90\n  85\n  94\n127\n101\n  99\n113\n  80\n115\n  85\n112\n112\n  92\n  97\n  97\n  91\n105\n  84\n  95\n108\n118\n118\n  86\n  89\n100\nMedium Blood Lead Level\n  78\n  97\n107\n  80\n  90\n  83\n101\n121\n108\n100\n110\n111\n  97\n  51\n  94\n  80\n101\n  92\n100\n  77\n108\n  85\nHigh Blood Lead Level\n  93\n100\n  97\n  79\n  97\n  71\n111\n  99\n  85\n  99\n  97\n111\n104\n  93\n  90\n107\n108\n  78\n  95\n  78\n  86\nLow Blood Lead Level\nMedium Blood Lead Level\nHigh Blood Lead Level\nSample Size n\n78\n22\n21\nx\n102.7\n   94.1\n   94.2\ns\n  16.8\n   15.5\n   11.4\nDistribution\nApproximately normal\nApproximately normal\nApproximately normal\n \nOutliers\nPotential low outlier of 51 and high outliers of 146 and \n149, but they are not very far from the other data values.\n \nNone\n \nNone\nMinitab Boxplots of Performance IQ Scores\n532\t\nCHAPTER 12  Analysis of Variance\n\nSection 9-2 includes methods for testing equality of means from two independent \npopulations, but this chapter presents a method for testing equality of three or more \npopulation means. Here are the chapter objectives:\nOne-Way ANOVA\n•\t Apply the method of one-way analysis of variance to conduct a hypothesis test of \nequality of three or more population means. The focus of this section is the interpre-\ntation of results from technology.\nTwo-Way ANOVA\n•\t Analyze sample data from populations separated into categories using two charac-\nteristics (or factors), such as gender and eye color.\n•\t Apply the method of two-way analysis of variance to the following: (1) test for an \ninteraction between two factors, (2) test for an effect from the row factor, and (3) test \nfor an effect from the column factor. The focus of this section is the interpretation of \nresults from technology.\n12-1\n12-2\nCHAPTER OBJECTIVES\nKey Concept In this section we introduce the method of one-way analysis of vari-\nance, which is used for tests of hypotheses that three or more populations have means \nthat are all equal, as in H0: m1 = m2 = m3. Because the calculations are very compli-\ncated, we emphasize the interpretation of results obtained by using technology.\nF Distribution\nThe analysis of variance (ANOVA) methods of this chapter require the F distribution, \nwhich was first introduced in Section 9-4. In Section 9-4 we noted that the F distribu-\ntion has the following properties (see Figure 12-1):\nThere is a different F distribution for each different pair of degrees of freedom for \nnumerator and denominator.\n1.\t The F distribution is not symmetric. It is skewed right.\n2.\t Values of a variable with the F distribution cannot be negative.\n3.\t The exact shape of the F distribution depends on the two different degrees \nof freedom.\n\t 12-1\t\nOne-Way ANOVA\n\t\n12-1  One-Way ANOVA\t\n533\n0\nNot symmetric\n(skewed to the right)\nF\nNonnegative \nvalues only\na\nValue of F 5\ns1\n2\n2\ns2\nFIGURE 12-1  F Distribution\n\n534\t\nCHAPTER 12  Analysis of Variance\nPART 1\n  Basics of One-Way Analysis of Variance \nWhen testing for equality of three or more population means, use the method of \none-way analysis of variance.\nDEFINITION\nOne-way analysis of variance (ANOVA) is a method of testing the equality of \nthree or more population means by analyzing sample variances. One-way analysis \nof variance is used with data categorized with one factor (or treatment), so there \nis one characteristic used to separate the sample data into the different categories.\nThe term treatment is used because early applications of analysis of variance \ninvolved agricultural experiments in which different plots of farmland were treated \nwith different fertilizers, seed types, insecticides, and so on. Table 12-1 uses the one \n“treatment” (or factor) of blood lead level. That factor has three different categories: \nlow, medium, and high blood lead levels (as defined in Data Set 8 in Appendix B).\nOne-Way Analysis of Variance for Testing Equality of Three or More Population Means\nObjective\nUse samples from three or more different populations to test a claim that the populations all have the same mean.\nRequirements\n1.\t The populations have distributions that are approxi-\nmately normal. (This is a loose requirement, because \nthe method works well unless a population has a dis-\ntribution that is very far from normal. If a population \ndoes have a distribution that is far from normal, use the \nKruskal-Wallis test described in Section 13-5.)\n2.\t The populations have the same variance s2 (or stan-\ndard deviation s). This is a loose requirement, because \nthe method works well unless the population vari-\nances differ by large amounts. Statistician George E. P. \nBox showed that as long as the sample sizes are equal \n(or nearly equal), the largest variance can be up to nine \ntimes the smallest variance and the results of ANOVA \nwill continue to be essentially reliable.\n3.\t The samples are simple random samples of quantitative \ndata.\n4.\t The samples are independent of each other. (The sam-\nples are not matched or paired in any way.)\n5.\t The different samples are from populations that are cat-\negorized in only one way.\nKEY ELEMENTS \nProcedure for Testing H0: M1 = M2 = M3 = P = Mk\n1.\t Use technology to obtain results that include the test \nstatistic and P-value.\n2.\t Identify the P-value from the display. (The ANOVA \ntest is right-tailed because only large values of the test \nstatistic cause us to reject equality of the population \nmeans.)\n3.\t Form a conclusion based on these criteria that use the \nsignificance level a:\n\t •\t Reject: If the P-value … a, reject the null hypoth-\nesis of equal means and conclude that at least one of \nthe population means is different from the others.\n\t •\t Fail to Reject: If the P-value 7 a, fail to reject the \nnull hypothesis of equal means.\n\n\t\n12-1  One-Way ANOVA\t\n535\nBecause the calculations required for one-way analysis of variance are messy, we \nrecommend using technology with this study strategy:\n1.\t Understand that a small P-value (such as 0.05 or less) leads to rejection of the \nnull hypothesis of equal means. (“If the P is low, the null must go.”) With a \nlarge P-value (such as greater than 0.05), fail to reject the null hypothesis of \nequal means.\n2.\t Develop an understanding of the underlying rationale by studying the  \nexamples in this section.\nEXAMPLE 1   Lead and Performance IQ Scores\nUse the performance IQ scores listed in Table 12-1 and a significance level of \na = 0.05 to test the claim that the three samples come from populations with \nmeans that are all equal.\nSOLUTION\nREQUIREMENT CHECK  (1) Based on the three samples listed in Table 12-1, the three \npopulations appear to have distributions that are approximately normal, as indicated \nby normal quantile plots. (2) The three samples in Table 12-1 have standard devia-\ntions that are not dramatically different, so the three population variances appear to \nbe about the same. (3) On the basis of the study design, we can treat the samples as \nsimple random samples. (4) The samples are independent of each other; the perfor-\nmance IQ scores are not matched in any way. (5) The three samples are from popu-\nlations categorized according to the single factor of lead level (low, medium, high). \nThe requirements are satisfied. \nThe null hypothesis and the alternative hypothesis are as follows:\nH0: m1 = m2 = m3\nH1: At least one of the means is different from the others\nThe significance level is a = 0.05.\nStep 1: Use technology to obtain ANOVA results, such as one of those shown in \nthe following seven displays.\nStatdisk\nMinitab\ncontinued\nTI-83, 84 Plus\n\n536\t\nCHAPTER 12  Analysis of Variance\nHow Is the P-Value Related to the Test Statistic?  Larger values of the test sta-\ntistic result in smaller P-values, so the ANOVA test is right-tailed. Figure 12-2 shows \nthe relationship between the F test statistic and the P-value. Assuming that the popula-\ntions have the same variance s2 (as required for the test), the F test statistic is the ratio \nof these two estimates of s2: (1) variation between samples (based on variation among \nsample means); and (2) variation within samples (based on the sample variances).\nStep 2: In addition to the test statistic of F = 4.0711, the displays all show that the \nP-value is 0.020 when rounded.\nStep 3: Because the P-value of 0.020 is less than the significance level of a = 0.05, \nwe reject the null hypothesis of equal means. (If the P is low, the null must go.)\nINTERPRETATION\nThere is sufficient evidence to warrant rejection of the claim that the three samples \ncome from populations with means that are all equal. Using the samples of mea-\nsurements listed in Table 12-1, we conclude that those values come from popula-\ntions having means that are not all the same. On the basis of this ANOVA test, we \ncannot conclude that any particular mean is different from the others, but we can \ninformally note that the sample mean for the low blood lead group is higher than \nthe means for the medium and high blood lead groups. It appears that greater blood \nlead levels are associated with lower performance IQ scores.\nExcel\nStatCrunch\nSPSS\nJMP\nCAUTION  When we conclude that there is sufficient evidence to reject the claim of \nequal population means, we cannot conclude from ANOVA that any particular mean \nis different from the others. (There are several other methods that can be used to \nidentify the specific means that are different, and some of them are discussed in \nPart 2 of this section.)\nWhy 0.05?\nIn 1925,  \nR. A. Fisher \npublished \na book that \nintroduced \nthe method \nof analysis of \nvariance, and he needed a table \nof critical values based on nu-\nmerator degrees of freedom and \ndenominator degrees of freedom, \nas in Table A-5 in Appendix A. \nBecause the table uses two dif-\nferent degrees of freedom, it be-\ncomes very long if many different \ncritical values are used, so Fisher \nincluded a table using 0.05 only. \nIn a later edition he also included \nthe significance level of 0.01.\nStephen Stigler, a notable \nhistorian of statistics, wrote in \nChance magazine that the choice \nof a significance level of 0.05 is \na convenient round number that \nis somewhat arbitrary. Although \nit is arbitrary, the choice of 0.05 \naccomplishes the following \nimportant goals. (1) The value of \na 0.05 significance level results in \nsample sizes that are reasonable \nand not too large. (2) The choice \nof 0.05 is large enough to give us \na reasonable chance of identify-\ning important effects (by correctly \nrejecting a null hypothesis of no \neffect when there really is an ef-\nfect). (3) The choice of 0.05 is not \nso small that it forces us to miss \nimportant effects (by making the \nmistake of failing to reject a null \nhypothesis of no effect when \nthere really is an effect).\nTable A-5  F Distribution (a  =  0\n1\n2\n1 \n647.79 \n799.50\n2 \n38.506 \n39.00\n3 \n17.443 \n16.04\n4 \n12.218 \n10.6\n0 007\n8.4\n\n\t\n12-1  One-Way ANOVA\t\n537\nTest Statistic for One-Way ANOVA\nF = variance between samples\nvariance within samples\nThe numerator of the F test statistic measures variation between sample means. The \nestimate of variance in the denominator depends only on the sample variances and is \nnot affected by differences among the sample means. Consequently, sample means \nthat are close in value to each other result in a small F test statistic and a large P-value, \nso we conclude that there are no significant differences among the sample means. \nSample means that are very far apart in value result in a large F test statistic and a \nsmall P-value, so we reject the claim of equal means.\nWhy Not Just Test Two Samples at a Time?  If we want to test for equality among three \nor more population means, why do we need a new procedure when we can test for equality \nof two means using the methods presented in Section 9-2? For example, if we want to use the \nsample data from Table 12-1 to test the claim that the three populations have the same mean, \nwhy not simply pair them off and test two at a time by testing H0: m1 = m2, H0: m2 = m3, \nand H0: m1 = m3? For the data in Table 12-1, the approach of testing equality of two means \nat a time requires three different hypothesis tests. If we use a 0.05 significance level for each \nof those three hypothesis tests, the actual overall confidence level could be as low as 0.953 (or \n0.857). In general, as we increase the number of individual tests of significance, we increase \nthe risk of finding a difference by chance alone (instead of a real difference in the means). \nThe risk of a type I error—finding a difference in one of the pairs when no such difference \nactually exists—is far too high. The method of analysis of variance helps us avoid that par-\nticular pitfall (rejecting a true null hypothesis) by using one test for equality of several means, \ninstead of several tests that each compare two means at a time.\nSample means\nare all close\nAt least one sample\nmean is very diﬀerent\nFail to reject equality of\npopulation means\nReject equality of\npopulation means\nSmall F test statistic,\nlarge P-value\nLarge F test statistic,\nsmall P-value\nF here\nF here\nFIGURE 12-2  \u0007Relationship Between the F Test Statistic  \nand the P-Value\nCAUTION  When testing for equality of three or more populations, use analysis \nof variance. (Using multiple hypothesis tests with two samples at a time could \nadversely affect the confidence level.)\nPART 2   \u0007Calculations and Identifying Means  \nThat Are Different \nCalculating the Test Statistic F with Equal Sample Sizes n\nTable 12-2 on the next page can be very helpful in understanding the methods of \nANOVA. In Table 12-2, compare Data Set A to Data Set B to see that Data Set A is \n\n538\t\nCHAPTER 12  Analysis of Variance\nTABLE 12-2  Effect of a Mean on the F Test Statistic\nData Set A\nData Set B\nSample 1\nSample 2\nSample 3\nSample 1\nSample 2\nSample 3\n7\n6\n4\n17\n6\n4\n3\n5\n7\n13\n5\n7\n6\n5\n6\n16\n5\n6\n6\n8\n7\n16\n8\n7\nn1 = 4\nn2 = 4\nn3 = 4\nn1 = 4\nn2 = 4\nn3 = 4\n   x1 = 5.5\n   x2 = 6.0\n   x3 = 6.0\n     x1 = 15.5\n   x2 = 6.0\n   x3 = 6.0\n   s2\n1 = 3.0\n   s2\n2 = 2.0\n   s2\n3 = 2.0\n   s2\n1 = 3.0\n   s2\n2 = 2.0\n   s2\n3 = 2.0\nData Set A\nData Set B\nStep 1: Variance \nbetween samples\nnsx\n2 = 4(0.0833) = 0.3332\nnsx\n2 = 4(30.0833) = 120.3332\nStep 2: Variance \nwithin samples\ns 2\np = 3.0 + 2.0 + 2.0\n3\n= 2.3333\ns2\np = 3.0 + 2.0 + 2.0\n3\n= 2.3333\nStep 3:  \nF test statistic\nF = nsx\n2\ns 2\np\n= 0.3332\n2.3333 = 0.1428\nF = nsx\n2\ns 2\np\n= 120.3332\n2.3333\n= 51.5721\nP-value\nP-value = 0.8688\nP-value = 0.0000118\nAdd 10 to data in Sample 1\nthe same as Data Set B with this notable exception: The Sample 1 values each differ \nby 10. If the data sets all have the same sample size (as in n = 4 for Table 12-2), the \nfollowing calculations aren’t too difficult, as shown here.\nStep 1: Find the Variance Between Samples\nCalculate the variance between samples by evaluating ns2\nx where s2\nx is the variance of \nthe sample means and n is the size of each of the samples. That is, consider the sample \nmeans to be an ordinary set of values and calculate the variance. (From the central \nlimit theorem, sx = s> 1n can be solved for s to get s = 1n # sx, so that we can \nestimate s2 with ns2\nx.) For example, the sample means for Data Set A in Table 12-2 \nare 5.5, 6.0, and 6.0, and these three values have a variance of s2\nx = 0.0833, so that\nvariance between samples = ns2\nx = 410.08332 = 0.3332\nStep 2: Find the Variance Within Samples\nEstimate the variance within samples by calculating s2\np, which is the pooled vari-\nance obtained by finding the mean of the sample variances. The sample variances in \nTable 12-2 are 3.0, 2.0, and 2.0, so that\nvariance within samples = s2\np = 3.0 + 2.0 + 2.0\n3\n= 2.3333\nStep 3: Calculate the Test Statistic \nEvaluate the F test statistic as follows:\nF = variance between samples\nvariance within samples\n= ns2\nx\ns2\np\n= 0.3332\n2.3333 = 0.1428\n\n\t\n12-1  One-Way ANOVA\t\n539\nFinding the Critical Value\nThe critical value of F is found by assuming a right-tailed test because large values of \nF correspond to significant differences among means. With k samples each having n \nvalues, the numbers of degrees of freedom are as follows.\nDegrees of Freedom 1using k = number of samples and n = sample size2\nNumerator degrees of freedom = k - 1\nDenominator degrees of freedom = k1n - 12\nFor Data Set A in Table 12-2, k = 3 and n = 4, so the degrees of freedom are 2 for \nthe numerator and 314 - 12 = 9 for the denominator. With a = 0.05, 2 degrees of \nfreedom for the numerator, and 9 degrees of freedom for the denominator, the criti-\ncal F value from Table A-5 is 4.2565. If we were to use the critical value method of \nhypothesis testing with Data Set A in Table 12-2, we would see that this right-tailed \ntest has a test statistic of F = 0.1428 and a critical value of F = 4.2565, so the test \nstatistic is not in the critical region. We therefore fail to reject the null hypothesis of \nequal means.\nUnderstanding the Effect of a Mean on the F Test Statistic  To really under-\nstand how the method of analysis of variance works, consider Data Set A and Data Set \nB in Table 12-2 and note the following.\n■\n■The three samples in Data Set A are identical to the three samples in Data Set B, \nexcept for this: Each value in Sample 1 of Data Set B is 10 more than the corre-\nsponding value in Data Set A.\n■\n■Adding 10 to each data value in the first sample of Data Set A has a significant \neffect on the test statistic, with F changing from 0.1428 to 51.5721.\n■\n■Adding 10 to each data value in the first sample of Data Set A has a dramatic \neffect on the P-value, which changes from 0.8688 (not significant) to 0.0000118 \n(significant).\n■\n■The three sample means in Data Set A (5.5, 6.0, 6.0) are very close, but the \nsample means in Data Set B (15.5, 6.0, 6.0) are not close.\n■\n■The three sample variances in Data Set A are identical to those in Data Set B.\n■\n■The variance between samples in Data Set A is 0.3332, but for Data Set B it is \n120.3332 (indicating that the sample means in B are farther apart).\n■\n■The variance within samples is 2.3333 in both Data Set A and Data Set B, be-\ncause the variance within a sample isn’t affected when we add a constant to every \nsample value. The change in the F test statistic and the P-value is attributable \nonly to the change in x1. This illustrates the key point underlying the method of \none-way analysis of variance:\nThe F test statistic is very sensitive to sample means, even though it is \nobtained through two different estimates of the common population \nvariance.\nCalculations with Unequal Sample Sizes\nWhile the calculations for cases with equal sample sizes are somewhat reasonable, \nthey become much more complicated when the sample sizes are not all the same, but \nthe same basic reasoning applies. Instead of providing the relevant messy formulas \nrequired for cases with unequal sample sizes, we wisely and conveniently assume that \n\n540\t\nCHAPTER 12  Analysis of Variance\ntechnology should be used to obtain the P-value for the analysis of variance. We be-\ncome unencumbered by complex computations and we can focus on checking require-\nments and interpreting results.\nWe calculate an F test statistic that is the ratio of two different estimates of the \ncommon population variance s2. With unequal sample sizes, we must use weighted \nmeasures that take the sample sizes into account. The test statistic is essentially the \nsame as the one given earlier, and its interpretation is also the same as described earlier.\nDesigning Experiments\nWith one-way (or single-factor) analysis of variance, we use one factor as the basis \nfor partitioning the data into different categories. If we conclude that the differences \namong the means are significant, we can’t be absolutely sure that the differences can \nbe explained by the factor being used. It is possible that the variation of some other \nunknown factor is responsible. One way to reduce the effect of the extraneous fac-\ntors is to design the experiment so that it has a completely randomized design, in \nwhich each sample value is given the same chance of belonging to the different factor \ngroups. For example, you might assign subjects to two different treatment groups and \na third placebo group through a process of random selection equivalent to picking \nslips of paper from a bowl. Another way to reduce the effect of extraneous factors is \nto use a rigorously controlled design, in which sample values are carefully chosen \nso that all other factors have no variability. In general, good results require that the \nexperiment be carefully designed and executed.\nIdentifying Which Means Are Different\nAfter conducting an analysis of variance test, we might conclude that there is suf-\nficient evidence to reject a claim of equal population means, but we cannot conclude \nfrom ANOVA that any particular means are different from the others. There are sev-\neral formal and informal procedures that can be used to identify the specific means \nthat are different. Here are two informal methods for comparing means:\n■\n■Construct boxplots of the different samples and examine any overlap to see if one \nor more of the boxplots is very different from the others.\n■\n■Construct confidence interval estimates of the means for each of the different \nsamples, then compare those confidence intervals to see if one or more of them \ndoes not overlap with the others.\nThere are several formal procedures for identifying which means are different. \nSome of the tests, called range tests, allow us to identify subsets of means that are not \nsignificantly different from each other. Other tests, called multiple comparison tests, \nuse pairs of means, but they make adjustments to overcome the problem of having a \nconfidence level that increases as the number of individual tests increases. There is no \nconsensus on which test is best, but some of the more common tests are the Duncan \ntest, Student-Newman-Keuls test (or SNK test), Tukey test (or Tukey honestly signifi-\ncant difference test), Scheffé test, Dunnett test, least significant difference test, and the \nBonferroni test. Let’s consider the Bonferroni test to see one example of a multiple \ncomparison test. Here is the procedure.\nBonferroni Multiple Comparison Test\nStep 1:\t \u0007Do a separate t test for each pair of samples, but make the adjustments de-\nscribed in the following steps.\n\n\t\n12-1  One-Way ANOVA\t\n541\nStep 2:\t \u0007For an estimate of the variance s2 that is common to all of the involved \npopulations, use the value of MS(error), which uses all of the available \nsample data. The value of MS(error) is typically obtained when conducting \nthe analysis of variance test. Using the value of MS(error), calculate the \nvalue of the test statistic t, as shown below. The particular test statistic cal-\nculated below is based on the choice of Sample 1 and Sample 2; change the \nsubscripts and use another pair of samples until all of the different possible \npairs of samples have been tested.\nt =\nx1 - x2\nBMS1error2 # a 1\nn1\n+ 1\nn2\nb\nStep 3:\t \u0007After calculating the value of the test statistic t for a particular pair of sam-\nples, find either the critical t value or the P-value, but make the following \nadjustment so that the overall significance level does not increase.\n\t\n\u0007P-Value: Use the test statistic t with df = N - k, where N is the total \nnumber of sample values and k is the number of samples, and find the  \nP-value using technology or Table A-3, but adjust the P-value by multiply-\ning it by the number of different possible pairings of two samples. (For \nexample, with three samples, there are three different possible pairings, so \nadjust the P-value by multiplying it by 3.)\n\t\n\u0007Critical Value: When finding the critical value, adjust the significance \nlevel a by dividing it by the number of different possible pairings of two \nsamples. (For example, with three samples, there are three different  \npossible pairings, so adjust the significance level by dividing it by 3.)\nNote that in Step 3 of the preceding Bonferroni procedure, either an individual test is \nconducted with a much lower significance level or the P-value is greatly increased. \nRejection of equality of means therefore requires differences that are much farther \napart. This adjustment in Step 3 compensates for the fact that we are doing several \ntests instead of only one test.\nEXAMPLE 2   Bonferroni Test\nExample 1 in this section used analysis of variance with the sample data in Table 12-1. \nWe concluded that there is sufficient evidence to warrant rejection of the claim \nof equal means. Use the Bonferroni test with a 0.05 significance level to identify \nwhich mean is different from the others.\nSOLUTION  \nThe Bonferroni test requires a separate t test for each of three different possible pair \nof samples. Here are the null hypotheses to be tested:\nH0\n : m1 = m2  H0\n : m1 = m3  H0\n : m2 = m3\nWe begin with H0: m1 = m2. Using the sample data given in Table 12-1 and \ncarrying some extra decimal places for greater accuracy in the calculations, we have \nn1 = 78 and x1 = 102.705128. Also, n2 = 22 and x2 = 94.136364. From the tech-\nnology results shown in Example 1 we also know that MS(error) = 248.424127.\ncontinued\n\n542\t\nCHAPTER 12  Analysis of Variance\nWe now evaluate the test statistic using the unrounded sample means:\n t =\nx1 - x2\nBMS1error2 #  a 1\nn1\n+ 1\nn2\nb\n =\n102.705128 - 94.136364\nB248.424127 #  a 1\n78 + 1\n22b\n= 2.252\nThe number of degrees of freedom is df = N - k = 121 - 3 = 118. (N = 121 \nbecause there are 121 different sample values in all three samples combined, and \nk = 3 because there are three different samples.) With a test statistic of t = 2.252 \nand with df = 118, the two-tailed P-value is 0.026172, but we adjust this P-value \nby multiplying it by 3 (the number of different possible pairs of samples) to get a \nfinal P-value of 0.078516, or 0.079 when rounded. Because this P-value is not small \n(less than 0.05), we fail to reject the null hypothesis. It appears that Samples 1 and 2 \ndo not have significantly different means.\nInstead of continuing with separate hypothesis tests for the other two pairings, see \nthe SPSS display showing all of the Bonferroni test results. In these results, low lead \nlevels are represented by 1, medium levels are represented by 2, and high levels are \nrepresented by 3. (The first row of numerical results corresponds to the results found \nhere; see the value of 0.079, which was previously calculated.) The display shows that \nthe pairing of low>high yields a P-value of 0.090, so there is not a significant differ-\nence between the means from the low and high blood lead levels. Also, the SPSS dis-\nplay shows that the pairing of medium>high yields a P-value of 1.000, so there is not a \nsignificant difference between the means from the medium and high blood lead levels.\nSPSS Bonferroni Results\nINTERPRETATION  \nAlthough the analysis of variance test tells us that at least one of the means is different \nfrom the others, the Bonferroni test results do not identify any one particular sample \nmean that is significantly different from the others. In the original article discussing \nthese results, the authors state that “our findings indicate that a chronic absorption of \nparticulate lead . . . may result in subtle but statistically significant impairment in the \nnon-verbal cognitive and perceptual motor skills measured by the performance scale of \nthe Wechsler intelligence tests.” That statement confirms these results: From analysis of \nvariance we know that at least one mean is different from the others, but the Bonferroni \ntest failed to identify any one particular mean as being significantly different [although \nthe sample means of 102.7 (low blood lead level), 94.1 (medium blood lead level), and \n94.2 (high blood lead level) suggest that medium and high blood lead levels seem to be \nassociated with lower mean performance IQ scores than the low blood level group].\n\n\t\n12-1  One-Way ANOVA\t\n543\nStatistical Literacy and Critical Thinking \nIn Exercises 1–4, use the following listed chest deceleration measurements (in g, where g \nis the force of gravity) from samples of small, midsize, and large cars. (The data are from \nthe National Highway Traffic Safety Administration.) Also shown are the SPSS results for \nanalysis of variance. Assume that we plan to use a 0.05 significance level to test the claim \nthat the different size categories have the same mean chest deceleration in the standard \ncrash test.\n12-1  Basic Skills and Concepts\nChest Deceleration Measurements (g) from a Standard Crash Test\nSmall\n44\n39\n37\n54\n39\n44\n42\nMidsize\n36\n53\n43\n42\n52\n49\n41\nLarge\n32\n45\n41\n38\n37\n38\n33\nSPSS\n1. ANOVA\na. What characteristic of the data above indicates that we should use one-way analysis of variance?\nb. If the objective is to test the claim that the three size categories have the same mean chest \ndeceleration, why is the method referred to as analysis of variance?\n2. Why Not Test Two at a Time? Refer to the sample data given in Exercise 1. If we want \nto test for equality of the three means, why don’t we use three separate hypothesis tests for \nm1 = m2, m1 = m3, and m2 = m3?\n3. Test Statistic What is the value of the test statistic? What distribution is used with the test \nstatistic?\n4. P-Value If we use a 0.05 significance level in analysis of variance with the sample data \ngiven in Exercise 1, what is the P-value? What should we conclude?\nIn Exercises 5–16, use analysis of variance for the indicated test.\n5. Lead and Verbal IQ Scores Example 1 used measured performance IQ scores for three \ndifferent blood lead levels. If we use the same three categories of blood lead levels with mea-\nsured verbal IQ scores, we get the accompanying Minitab display. (The data are listed in Data \nSet 8 “IQ and Lead” in Appendix B.) Using a 0.05 significance level, test the claim that the \nthree categories of blood lead level have the same mean verbal IQ score. Does exposure to lead \nappear to have an effect on verbal IQ scores?\nMinitab\nOne-Way Analysis of Variance\nAccess tech instructions, videos, and data sets at www.TriolaStats.com\nTECH CENTER \n\n544\t\nCHAPTER 12  Analysis of Variance\n6. Lead and Full IQ Scores Example 1 used measured performance IQ scores for three dif-\nferent blood lead levels. If we use the same three categories of blood lead levels with the full IQ \nscores, we get the accompanying Excel display. Using a 0.05 significance level, test the claim \nthat the three categories of blood lead level have the same mean full IQ score. Does it appear \nthat exposure to lead has an effect on full IQ scores?\nExcel\n7. Head Injury Crash Test Data Exercises 1–4 use chest deceleration data for three different \nsize categories (small, midsize, large). If we use the head injury measurements (in HIC, which \nis a standard head injury criterion) with the same three size categories, we get the SPSS results \nshown here. Using a 0.05 significance level, test the claim that the three size categories have \nthe same mean head injury measurement. Does the size of a car appear to affect head injuries?\nSPSS\n8. Birth Weights Data Set 3 “Births” lists birth weights from babies born at four different hospi-\ntals. After partitioning the birth weights according to the hospital, we get the StatCrunch display \nshown here. Use a 0.05 significance level to test the claim that the different hospitals have the same \nmean birth weights. Do birth weights appear to be the same at these four hospitals?\nStatCrunch\n9. Male Pulse Rates and Age Using the pulse rates of males from Data Set 1 “Body Data” in \nAppendix B after they are partitioned into the three age brackets of 18–25, 26–40, and 41–80, \nwe get the following SPSS display. Using a 0.05 significance level, test the claim that males \nfrom the three age brackets have the same mean pulse rate. What do you conclude?\n10. Female Pulse Rates and Age Using the pulse rates of females from Data Set 1 “Body \nData” in Appendix B after they are partitioned into the three age brackets of 18–25, 26–40, and \n41–80, we get the following Statdisk display. Using a 0.05 significance level, test the claim that \nfemales from the three age brackets have the same mean pulse rate. What do you conclude?\nStatdisk\n\n\t\n12-1  One-Way ANOVA\t\n545\n11. Pelvis Injury Crash Test Data Exercises 1–4 use chest deceleration data for three differ-\nent size categories (small, midsize, large). If we use the pelvis injury measurements (g) with \nthe same three size categories, we get the XLSTAT results shown here. Using a 0.05 signifi-\ncance level, test the claim that the three size categories have the same mean pelvis injury mea-\nsurement. Does the size of a car appear to affect pelvis injuries?\nXLSTAT\n12. Arsenic in Rice Listed below are amounts of arsenic in samples of brown rice from three \ndifferent states. The amounts are in micrograms of arsenic and all samples have the same serv-\ning size. The data are from the Food and Drug Administration. Use a 0.05 significance level to \ntest the claim that the three samples are from populations with the same mean. Do the amounts \nof arsenic appear to be different in the different states? Given that the amounts of arsenic in the \nsamples from Texas have the highest mean, can we conclude that brown rice from Texas poses \nthe greatest health problem?\nArkansas\n4.8\n4.9\n5.0\n5.4\n5.4\n5.4\n5.6\n5.6\n5.6\n5.9\n6.0\n6.1\nCalifornia\n1.5\n3.7\n4.0\n4.5\n4.9\n5.1\n5.3\n5.4\n5.4\n5.5\n5.6\n5.6\nTexas\n5.6\n5.8\n6.6\n6.9\n6.9\n6.9\n7.1\n7.3\n7.5\n7.6\n7.7\n7.7\n13. Poplar Tree Weights Weights (kg) of poplar trees were obtained from trees planted in a \nrich and moist region. The trees were given different treatments identified in the table below. \n(The data are from Data Set 18 in Appendix B, and they were obtained from a study conducted \nby researchers at Pennsylvania State University and were provided by Minitab, Inc.) Use a 0.05 \nsignificance level to test the claim that the four treatment categories yield poplar trees with the \nsame mean weight. Is there a treatment that appears to be most effective?\nNo Treatment\nFertilizer\nIrrigation\nFertilizer and Irrigation\n1.21\n0.94\n0.07\n0.85\n0.57\n0.87\n0.66\n1.78\n0.56\n0.46\n0.10\n1.47\n0.13\n0.58\n0.82\n2.25\n1.30\n1.03\n0.94\n1.64\n14. Poplar Tree Weights Weights (kg) of poplar trees were obtained from trees planted in a \nsandy and dry region. The trees were given different treatments identified in the table below. (The \ndata are from Data Set 18 in Appendix B, and they were obtained from a study conducted by \nresearchers at Pennsylvania State University and were provided by Minitab, Inc.) Use a 0.05 sig-\nnificance level to test the claim that the four treatment categories yield poplar trees with the same \nmean weight. Is there a treatment that appears to be most effective in the sandy and dry region?\nNo Treatment\nFertilizer\nIrrigation\nFertilizer and Irrigation\n0.24\n0.92\n0.96\n1.07\n1.69\n0.07\n1.43\n1.63\n1.23\n0.56\n1.26\n1.39\n0.99\n1.74\n1.57\n0.49\n1.80\n1.13\n0.72\n0.95\nIn Exercises 15 and 16, use the data set in Appendix B.\n15. Nicotine in Cigarettes Refer to Data Set 15 “Cigarette Contents” in Appendix B and use \nthe amounts of nicotine (mg per cigarette) in the king-size cigarettes, the 100-mm menthol \ncigarettes, and the 100-mm nonmenthol cigarettes. The king-size cigarettes are nonfiltered, \ncontinued\n\n546\t\nCHAPTER 12  Analysis of Variance\nnonmenthol, and nonlight. The 100-mm menthol cigarettes are filtered and nonlight. The \n100-mm nonmenthol cigarettes are filtered and nonlight. Use a 0.05 significance level to test \nthe claim that the three categories of cigarettes yield the same mean amount of nicotine. Given \nthat only the king-size cigarettes are not filtered, do the filters appear to make a difference?\n16. Secondhand Smoke Refer to Data Set 14 “Passive and Active Smoke” in Appendix B \nand use the measured serum cotinine levels (in mg>mL) from the three groups of subjects \n(smokers, nonsmokers exposed to tobacco smoke, and nonsmokers not exposed to tobacco \nsmoke). When nicotine is absorbed by the body, cotinine is produced. Use a 0.05 significance \nlevel to test the claim that the three samples are from populations with the same mean. What do \nthe results suggest about the effects of secondhand smoke?\n17. Tukey Test A display of the Bonferroni test results from Table 12-1 (which is part of the \nChapter Problem) is provided on page 542. Shown here is the SPSS-generated display of re-\nsults from the Tukey test using the same data. Compare the Tukey test results to those from the \nBonferroni test.\n12-1  Beyond the Basics\nSPSS\n18. Bonferroni Test Exercise 13 lists weights (kg) of poplar trees obtained from trees planted \nin a rich and moist region. Shown below are partial results from using the Bonferroni test with \nthe sample data.\na. Use a 0.05 significance level to test the claim that the different treatments result in the same \nmean weight.\nb. What do the displayed Bonferroni SPSS results tell us?\nc. Use the Bonferroni test procedure with a 0.05 significance level to test for a significant dif-\nference between the mean amount of the irrigation treatment group and the group treated with \nboth fertilizer and irrigation. Identify the test statistic and either the P-value or critical values. \nWhat do the results indicate?\nBonferroni Results from SPSS\n\n\t\n12-2  Two-Way ANOVA\t\n547\nKey Concept Section 12-1 considered data partitioned using one factor, but this sec-\ntion describes the method of two-way analysis of variance, which is used with data \npartitioned into categories according to two factors. The method of this section re-\nquires that we first test for an interaction between the two factors, then we test for an \neffect from the row factor and we test for an effect from the column factor.\nTable 12-3 is an example of pulse rate (beats per minute) data categorized with \ntwo factors:\n1.\t Age Bracket (years): One factor is age bracket (18–29, 30–49, 50–80).\n2.\t Gender: The second factor is gender (female, male).\nThe subcategories in Table 12-3 are called cells, so Table 12-3 has six cells containing \nten values each.\nIn analyzing the sample data in Table 12-3, we have already discussed one-way \nanalysis of variance for a single factor, so it might seem reasonable to simply proceed \nwith one-way ANOVA for the factor of age bracket and another one-way ANOVA for \nthe factor of gender, but that approach wastes information and totally ignores a very \nimportant feature: the possible effect of an interaction between the two factors.\n\t 12-2\t\nTwo-Way ANOVA\nDEFINITION\nThere is an interaction between two factors if the effect of one of the factors \nchanges for different categories of the other factor.\nTABLE 12-3  Pulse Rates with Two Factors: Age Bracket and Gender\nFemale\nMale\n18–29\n104   82   80   78   80   84   82   66   70     78\n72     64   72   64   64   70   72   64   54   52\n30–49\n  66   74   96   86   98   88   82   72   80     80\n80     90   58   74   96   72   58   66   80   92\n50–80\n  94   72   82   86   72   90   64   72   72   100\n54   102   52   52   62   82   82   60   52   74\nAs an example of an interaction between two factors, consider food pairings. \nPeanut butter and jelly interact well, but ketchup and ice cream interact in a way that \nresults in a bad taste, so we rarely see someone eating ice cream topped with ketchup. \nPhysicians must be careful to avoid prescribing drugs with interactions that produce \nadverse effects. It was found that the antifungal drug Nizoral (ketoconazole) inter-\nacted with the antihistamine drug Seldane (terfenadine) in such a way that Seldane \nwas not metabolized properly, causing abnormal heart rhythms in some patients. \nSeldane was subsequently removed from the market. In general, consider an interaction \neffect to be an effect due to the combination of the two factors.\nExplore Data with Means and an Interaction Graph\nLet’s explore the data in Table 12-3 by calculating the mean for each cell and by con-\nstructing a graph. The individual cell means are shown in Table 12-4 on the next page. \nThose means vary from a low of 64.8 to a high of 82.2, so they vary considerably. \n­Figure 12-3 on the next page is an interaction graph, which shows graphs of those \nmeans. We can interpret an interaction graph as follows:\n\n548\t\nCHAPTER 12  Analysis of Variance\n■\n■Interaction Effect: An interaction effect is suggested when line segments are far \nfrom being parallel.\n■\n■No Interaction Effect: If the line segments are approximately parallel, as in  \nFigure 12-3, it appears that the different categories of a variable have the same \neffect for the different categories of the other variable, so there does not appear to \nbe an interaction effect.\nTABLE 12-4  Means of Cells  \nfrom Table 12-3\nFemale\nMale\n18–29\n80.4\n64.8\n30–49\n82.2\n76.6\n50–80\n80.4\n67.2\nFIGURE 12-3  \u0007Interaction Graph of Age Bracket and \nGender: Means from Table 12-4\nInstead of relying only on subjective judgments made by examining the means in \nTable 12-4 and the interaction graph in Figure 12-3, we will proceed with the more \nobjective procedure of two-way analysis of variance. Here are the requirements and \nbasic procedure for two-way analysis of variance (ANOVA). The procedure is also \nsummarized in Figure 12-4, which follows the Key Elements box.\nTwo-Way Analysis of Variance\nObjective\nWith sample data categorized with two factors (a row variable and a column variable), use two-way analysis of variance \nto conduct the following three tests:\n1.\t Test for an effect from an interaction between the row factor and the column factor.\n2.\t Test for an effect from the row factor.\n3.\t Test for an effect from the column factor.\nRequirements\n1.\t Normality For each cell, the sample values come from \na population with a distribution that is approximately \nnormal. (This procedure is robust against reasonable  \ndepartures from normal distributions.)\n2.\t Variation The populations have the same variance s2 \n(or standard deviation s). (This procedure is robust \nagainst reasonable departures from the requirement of \nequal variances.)\nKEY ELEMENTS \n\n\t\n12-2  Two-Way ANOVA\t\n549\n3.\t Sampling The samples are simple random samples of \nquantitative data.\n4.\t Independence The samples are independent of each \nother. (This procedure does not apply to samples lack-\ning independence.)\n5.\t Two-Way The sample values are categorized two ways. \n(This is the basis for the name of the method: two-way \nanalysis of variance.)\n6.\t Balanced Design All of the cells have the same number \nof sample values. (This is called a balanced design. \nThis section does not include methods for a design that \nis not balanced.)\nProcedure for Two-Way ANOVA (See Figure 12-4)\nStep 1: Interaction Effect: In two-way analysis of variance, begin by testing the null hypothesis that there is no interac-\ntion between the two factors. Use technology to find the P-value corresponding to the following test statistic:\nF = MS1interaction2\nMS1error2\nConclusion:\n\t•\t Reject: If the P-value corresponding to the above test \nstatistic is small (such as less than or equal to 0.05),  \nreject the null hypothesis of no interaction. Conclude \nthat there is an interaction effect.\n\t•\t Fail to Reject: If the P-value is large (such as greater \nthan 0.05), fail to reject the null hypothesis of no inter-\naction between the two factors. Conclude that there is \nno interaction effect.\nStep 2: Row, Column Effects: If we conclude that there is an interaction effect, then we should stop now; we should \nnot proceed with the two additional tests. (If there is an interaction between factors, we shouldn’t consider the effects of \neither factor without considering those of the other.)\nIf we conclude that there is no interaction effect, then we should proceed with the following two hypoth-\nesis tests.\nRow Factor\nFor the row factor, test the null hypothesis H0: There are no effects from the row factor (that is, the row values are from \npopulations with the same mean). Find the P-value corresponding to the test statistic F = MS1row2>MS1error2.\nConclusion:\n\t•\t Reject: If the P-value corresponding to the test statistic \nis small (such as less than or equal to 0.05), reject the \nnull hypothesis of no effect from the row factor. Con-\nclude that there is an effect from the row factor.\n\t•\t Fail to Reject: If the P-value is large (such as greater \nthan 0.05), fail to reject the null hypothesis of no effect \nfrom the row factor. Conclude that there is no effect \nfrom the row factor.\nColumn Factor\nFor the column factor, test the null hypothesis H0: There are no effects from the column factor (that is, the column values are \nfrom populations with the same mean). Find the P-value corresponding to the test statistic F = MS(column)>MS(error).\nConclusion:\n\t•\t Reject: If the P-value corresponding to the test statistic \nis small (such as less than or equal to 0.05), reject the \nnull hypothesis of no effect from the column factor. \nConclude that there is an effect from the column factor.\n\t•\t Fail to Reject: If the P-value is large (such as greater \nthan 0.05), fail to reject the null hypothesis of no effect \nfrom the column factor. Conclude that there is no effect \nfrom the column factor.\n\n550\t\nCHAPTER 12  Analysis of Variance\nNo\n(Fail to reject H0 of\nno interaction eﬀect.)\nYes\n(Reject H0 of\nno interaction\neﬀect.)\nStart\nStop. Don’t consider the\neﬀects of either factor\nwithout considering the\neﬀects of the other.\nIs there an eﬀect\ndue to interaction between\nthe two factors?\nTest for eﬀect from row factor using the P-value \nfor the test statistic \nIf the P-value is small (such as less than 0.05), \nconclude that there is an eﬀect from the \nrow factor.\nF 5\nMS (row factor)\nMS (error)\nTest for eﬀect from column factor using the \nP-value for the test statistic \nIf the P-value is small (such as less than 0.05), \nconclude that there is an eﬀect from the \ncolumn factor.\nF 5\nMS (column factor)\nMS (error)\nTest for an interaction between the two factors. \nUse the P-value for the test statistic \nIf the P-value is small (such as less than 0.05), \nconclude that there is an interaction eﬀect.\nF 5\nMS (interaction)\nMS (error)\nFIGURE 12-4  Procedure for Two-Way Analysis of Variance\nEXAMPLE 1   Pulse Rates\nGiven the pulse rates in Table 12-3 on page 547 (from Data Set 1 “Body Data” in \nAppendix B), use two-way analysis of variance to test for an interaction effect, an \neffect from the row factor of age bracket, and an effect from the column factor of \ngender. Use a 0.05 significance level.\nSOLUTION\nREQUIREMENT CHECK  (1) For each cell, the sample values appear to be from a popu-\nlation with a distribution that is approximately normal, as indicated by normal quan-\ntile plots. (2) The variances of the cells (100.3, 51.7, 103.5, 183.2, 138.5, 293.5)  \ndiffer considerably, but the test is robust against departures from equal variances. \n\n\t\n12-2  Two-Way ANOVA\t\n551\n(3) The samples are simple random samples of subjects. (4) The samples are inde-\npendent of each other; the subjects are not matched in any way. (5) The sample val-\nues are categorized in two ways (age bracket and gender). (6) All of the cells have \nthe same number (ten) of sample values. The requirements are satisfied. \nThe calculations are quite involved, so we use technology. The StatCrunch  \ntwo-way analysis of variance display for the data in Table 12-3 is shown here.\nStatCrunch\nStep 1: Interaction Effect: We begin by testing the null hypothesis that there is no \ninteraction between the two factors. Using StatCrunch for the data in Table 12-3, \nwe get the results shown in the preceding StatCrunch display and we can see that \nthe test statistic for the interaction is F = 0.9391 (rounded). This test statistic can \nbe calculated as follows:\nF = MS1interaction2\nMS1error2\n= 136.26667\n145.11111 = 0.9391\nInterpretation: The corresponding P-value is shown in the StatCrunch display as \n0.3973, so we fail to reject the null hypothesis of no interaction between the two \nfactors. It does not appear that pulse rates are affected by an interaction between \nage bracket (18–29, 30–49, 50–80) and gender. There does not appear to be an  \ninteraction effect.\nStep 2: Row, Column Effects: Because there does not appear to be an interaction \neffect, we proceed to test for effects from the row and column factors. The two  \nhypothesis tests use these null hypotheses:\nH0: There are no effects from the row factor (that is, the row values\n are from populations with equal means).\nH0: There are no effects from the column factor (that is, the column values\n are from populations with equal means).\nRow Factor: For the row factor (age bracket), we refer to the preceding StatCrunch \ndisplay of results to see that the test statistic for the row factor is F = 1.81856 \n(rounded). This test statistic can be calculated as follows:\nF = MS1age bracket2\nMS1error2\n= 263.46667\n145.11111 = 1.8156\nConclusion: The corresponding P-value is shown in the StatCrunch display as \n0.1725. Because that P-value is greater than the significance level of 0.05, we fail to \nreject the null hypothesis of no effects from age bracket. That is, pulse rates do not \nappear to be affected by the age bracket.\nColumn Factor: For the column factor (gender), we refer to the preceding  \nStatCrunch display of results to see that the test statistic for the column factor is  \nF = 13.5914 (rounded). This test statistic can be calculated as follows:\ncontinued\n\n552\t\nCHAPTER 12  Analysis of Variance\nF = MS1gender2\nMS1error2\n= 1972.2667\n145.11111 = 13.5914\nConclusion: The corresponding P-value is shown in the StatCrunch display as 0.0005. \nBecause that P-value is less than the significance level of 0.05, we reject the null hy-\npothesis of no effects from gender. Pulse rates do appear to be affected by gender.\nINTERPRETATION\nOn the basis of the sample data in Table 12-3, we conclude that pulse rates appear \nto be affected by gender, but not by age bracket and not by an interaction between \nage bracket and gender.\nStatistical Literacy and Critical Thinking\n1. Two-Way ANOVA The pulse rates in Table 12-3 from Example 1 are reproduced below with \nfabricated data (in red) used for the pulse rates of females aged 30–49. What characteristic of \nthe data suggests that the appropriate method of analysis is two-way analysis of variance? That \nis, what is “two-way” about the data entered in this table?\nFemale\nMale\n18–29\n104   82   80   78   80   84   82   66   70     78\n72     64   72   64   64   70   72   64   54   52\n30–49\n  46   54   76   66   78   68   62   52   60     60\n80     90   58   74   96   72   58   66   80   92\n50–80\n  94   72   82   86   72   90   64   72   72   100\n54   102   52   52   62   82   82   60   52   74\n2. Two-Way ANOVA If we have a goal of using the data described in Exercise 1 to (1) de-\ntermine whether age bracket has an effect on pulse rates and (2) to determine whether gender \nhas an effect on pulse rates, should we use one-way analysis of variance for the two individual \ntests? Why or why not?\n3. Interaction\na. What is an interaction between two factors?\nb. In general, when using two-way analysis of variance, if we find that there is an interaction \neffect, how does that affect the procedure?\nc. Shown below is an interaction graph constructed from the data in Exercise 1. What does the \ngraph suggest?\n12-2  Basic Skills and Concepts\nTwo-Way Analysis of Variance\nAccess tech instructions, videos, and data sets at www.TriolaStats.com\nTECH CENTER \n\n\t\n12-2  Two-Way ANOVA\t\n553\n4. Balanced Design Does the table given in Exercise 1 constitute a balanced design? Why or \nwhy not?\n5. Pulse Rates If we use the data given in Exercise 1 with two-way analysis of variance, we \nget the accompanying display. What do you conclude?\nStatdisk\n6. Weights The weights (kg) in the following table are from Data Set 1 “Body Data.” Results \nfrom two-way analysis of variance are also shown. Use the displayed results and use a 0.05 \nsignificance level. What do you conclude?\nFemale\nMale\n18–29\n  63.4  57.8    52.6    46.9   61.7    61.5  \n  77.2  50.4    97.0    76.1\n71.6    64.9  144.9  96.4    80.7  84.4  \n63.9    79.0    99.4  64.1\n30–49\n110.5  84.6  133.3    90.2  125.7  105.3  \n115.5  75.3    92.8    57.7\n96.2    56.4  107.4  99.5    64.8  94.7  \n74.2  112.8    72.6  91.4\n50–80\n103.2  48.3    87.8  101.3   67.8    45.2 \n  79.8  60.1    68.5    43.3\n84.8  127.5    89.9  75.3  110.2  72.3  \n77.2    86.5    71.3  73.1\nStatCrunch\n7. Heights The heights (cm) in the following table are from Data Set 1 “Body Data.” Results \nfrom two-way analysis of variance are also shown. Use the displayed results and use a 0.05 \nsignificance level. What do you conclude?\nFemale\nMale\n18–29\n161.2  170.2  162.9  155.5  168.0\n153.3  152.0  154.9  157.4  159.5\n172.8  178.7  183.1  175.9  161.8\n177.5  170.5  180.1  178.6  178.5\n30–49\n169.1  170.6  171.1  159.6  169.8\n169.5  156.5  164.0  164.8  155.6\n170.1  165.4  178.5  168.5  180.3\n178.2  174.4  174.6  162.8  174.4\n50–80\n146.7  160.9  163.3  176.1  163.1\n151.6  164.7  153.3  160.3  134.5\n181.9  166.6  171.7  170.0  169.1\n182.9  176.3  166.7  166.3  160.5\nXLSTAT\n8. Cholesterol Levels The following table lists measured cholesterol levels of randomly \nselected subjects. Results from two-way analysis of variance are shown on the top of the next \npage. Use a 0.05 significance level. Are cholesterol levels affected by an interaction between sex \nand age? Are cholesterol levels affected by sex? Are cholesterol levels affected by age?\nAge\nUnder 30\n30–50\nOver 50\nMale\n265  303  1252  230  957\n702  277  176  416  120\n  75  189  288  578    31\nFemale\n325  112      62  301  223\n146  173  149  462    94\n254  384  318  600  309\ncontinued\n\n554\t\nCHAPTER 12  Analysis of Variance\n9. Measuring Self-Esteem The following table lists measures of self-esteem obtained from a \nstudent project as supervised by Jannay Morrow at Vassar College (based on data from Richard \nLowry). The objective of the project was to study how levels of self-esteem in subjects relate \nto their perceptions of self-esteem in other target people who were described in writing. Self-\nesteem levels were measured using the Coopersmith Self-Esteem Inventory, and the test here \nworks well even though the data are at the ordinal level of measurement. Use a 0.05 signifi-\ncance level and apply the methods of two-way analysis of variance. What do you conclude?\nSubject’s Self-Esteem\nLow\nMedium\nHigh\nTarget’s Self-Esteem\nLow\n4  4  3  5\n4  4  5  4\n2  4  4  2\n3  3  3  4\n4  2  4  4\n1  2  2  3\n3  1  3  3\n3  5  3  2\n3  3  3  3\nHigh\n2  2  4  2\n2  3  2  4\n2  2  2  3\n4  3  1  2\n1  3  2  4\n3  1  1  4\n3  2  3  2\n3  4  3  4\n4  3  3  4\n10. Smoking, Gender, and Body Temperature The table below lists body temperatures \n(oF) obtained from randomly selected subjects (based on Data Set 2 “Body Temperatures” in \nAppendix B). Using a 0.05 significance level, test for an interaction between gender and smok-\ning, test for an effect from gender, and test for an effect from smoking. What do you conclude?\nSmokes\nDoes Not Smoke\nMale\n98.8  97.6  98.0  98.5\n98.4  97.8  98.0  97.0\nFemale\n98.0  98.5  98.3  98.7\n97.7  98.0  98.2  99.1\nMinitab\n12-2  Beyond the Basics\n11. Transformations of Data Example 1 illustrated the use of two-way ANOVA to analyze \nthe sample data in Table 12-3 on page 547. How are the results affected in each of the follow-\ning cases?\na. The same constant is added to each sample value.\nb. Each sample value is multiplied by the same nonzero constant.\nc. The format of the table is transposed so that the row and column factors are interchanged.\nd. The first sample value in the first cell is changed so that it becomes an outlier.\n1.  ANOVA Listed on the top of the next page are skull breadths obtained from skulls of \nEgyptian males from three different epochs (based on data from Ancient Races of the Thebaid, \nby Thomson and Randall-Maciver). Assume that we plan to use analysis of variance with a \n0.05 significance level to test the claim that the different epochs have mean skull breadths that \nare not all the same. The results from XLSTAT are shown on the next page. What characteristic \nof the data indicates that we should use one-way analysis of variance?\nChapter Quick Quiz\n\n2. Null and Alternative Hypotheses For the hypothesis test described in Exercise 1, identify \nthe null hypothesis and the alternative hypothesis.\n3. Test Statistic Identify the value of the test statistic in the display included with Exercise 1. \nIn general, do larger test statistics result in larger P-values, smaller P-values, or P-values that \nare unrelated to the value of the test statistic?\n4. Conclusions If the test described in Exercise 1 is conducted with a 0.05 significance level, \nwhat should be concluded about the null hypothesis? What do the results suggest about the data?\n5. Type of Test Is the hypothesis test described in Exercise 1 left-tailed, right-tailed or two-\ntailed? Are all one-way analysis of variance tests left-tailed, right-tailed, or two-tailed?\n6. Which Mean Is Different? For the three samples described in Exercise 1, if we use analysis \nof variance and reach a conclusion to reject equality of the three population means, can we then \nconclude that any of the specific populations has a mean that is different from the others?\n7. One vs Two What is the fundamental difference between one-way analysis of variance and \ntwo-way analysis of variance?\nHead Injuries in Car Crashes.  In Exercises 8–10, use the accompanying data and cor-\nresponding display that results from head injury measurements from dummies in car crash \ntests. The measurements are in HIC (head injury criterion) units.\nSize of Car\nSmall\nMedium\nLarge\nForeign\n290\n245\n342\n544\n502\n698\n501\n393\n332\nDomestic\n406\n474\n216\n371\n368\n335\n376\n349\n169\nMinitab\n8. Interaction Test the null hypothesis that head injury measurements are not affected by an \ninteraction between the type of car (foreign, domestic) and size of the car (small, medium \nlarge). What do you conclude?\n9. Effect from Type of Car Assume that head injury measurements are not affected by an interac-\ntion between type of car (foreign, domestic) and size of car (small, medium, large). Is there suffi-\ncient evidence to support the claim that the type of car has an effect on head injury measurements?\n10. Effect from Size of Car Assume that head injury measurements are not affected by an \ninteraction between type of car (foreign, domestic) and size of car (small, medium, large). Is \nthere sufficient evidence to support the claim that the size of the car (small, medium, large) has \nan effect on head injury measurements?\n\t\nCHAPTER 12  Chapter Quick Quiz\t\n555\n400 B.C.\n131\n138\n125\n129\n132\n135\n132\n134\n138\n1850 B.C.\n129\n134\n136\n137\n137\n129\n136\n138\n134\n150 A.D.\n128\n138\n136\n139\n141\n142\n137\n145\n137\n\n556\t\nCHAPTER 12  Analysis of Variance\n1. Baseline Characteristics Experiments and clinical trials with different treatment groups \ncommonly include “baseline characteristics,” which constitute information about the charac-\nteristics of the different treatment groups. In a study of four different weight loss programs, \neach program had 40 subjects. The means and standard deviations of the ages in each group are \nas follows: Atkins (x = 47 years, s = 12 years); Zone (x = 51 years, s = 9 years); Weight \nWatchers (x = 49 years, s = 10 years); Ornish (x = 49 years, s = 12 years). These statistics \nare listed along with a P-value of 0.41. These results are from “Comparison of the Atkins, Or-\nnish, Weight Watchers, and Zone Diets for Weight Loss and Heart Disease Risk Reduction,” by \nDansinger et al., Journal of the American Medical Association, Vol. 293, No. 1.\na. How many variables are used to categorize the sample data consisting of the ages of the \nsubjects?\nb. What specific method is used to find the P-value of 0.41?\nc. What does the P-value of 0.41 indicate about the baseline characteristic of age?\nd. What would a small P-value (such as 0.001) indicate about the ages, and how would that \naffect the results of the study?\n2. Tar in Cigarettes Listed below are amounts of tar (mg per cigarette) in king-size cigarettes, \n100-mm menthol cigarettes, and 100-mm nonmenthol cigarettes (from Data Set 15 “Cigarette \nContents” in Appendix B). The king-size cigarettes are nonfiltered, nonmenthol, and nonlight. \nThe 100-mm menthol cigarettes are filtered and nonlight. The 100-mm nonmenthol cigarettes \nare filtered and nonlight. Use a 0.05 significance level to test the claim that the three categories \nof cigarettes yield the same mean amount of tar. Given that only the king-size cigarettes are not \nfiltered, do the filters appear to make a difference?\nKing\n20\n27\n27\n20\n20\n24\n20\n23\n20\n22\n20\n20\n20\n20\n20\n10\n24\n20\n21\n25\n23\n20\n22\n20\n20\nMenthol\n16\n13\n16\n  9\n14\n13\n12\n14\n14\n13\n13\n16\n13\n13\n18\n  9\n19\n  2\n13\n14\n14\n15\n16\n  6\n  8\nOne Hundred\n  5\n16\n17\n13\n13\n14\n15\n15\n15\n  9\n13\n13\n13\n15\n  2\n15\n15\n13\n14\n15\n16\n15\n  7\n17\n15\n3. Car Crash Tests When car crash tests were conducted, data were collected that consist of \ncrash test loads (pounds) on the left femur and right femur. When those loads are partitioned into \nthe three car size categories of small, midsize, and large, the two-way analysis of results from \nXLSTAT are as shown below. (The row factor of femur has the two values of left femur and right \nfemur, and the column factor of size has the three values of small, midsize, and large.) Use a 0.05 \nsignificance level to apply the methods of two-way analysis of variance. What do you conclude?\nReview Exercises\n4. Smoking, Body Temperature, Gender The table below lists body temperatures obtained \nfrom randomly selected subjects (based on Data Set 2 “Body Temperatures” in Appendix B). \nThe temperatures are categorized according to gender and whether the subject smokes. Using \na 0.05 significance level, test for an interaction between gender and smoking, test for an effect \nfrom gender, and test for an effect from smoking. What do you conclude?\nSmokes\nDoes Not Smoke\nMale\n98.4  98.4  99.4  98.6\n98.0  98.0  98.8  97.0\nFemale\n98.8  98.0  98.7  98.4\n97.7  98.0  98.2  99.1\n\nIn Exercises 1–5, refer to the following list of numbers of years that U.S. presidents, popes, \nand British monarchs lived after their inauguration, election, or coronation, respectively. \n(As of this writing, the last president is Gerald Ford, the last pope is John Paul II, and the \nlast British monarch is George VI.) Assume that the data are samples randomly selected \nfrom larger populations.\nPresidents\n10\n29\n26\n28\n15\n23\n17\n25\n  0\n20\n  4\n  1\n24\n16\n12\n  4\n10\n17\n16\n  0\n  7\n24\n12\n  4\n18\n21\n11\n  2\n  9\n36\n12\n28\n  3\n16\n  9\n25\n23\n32\nPopes\n  2\n  9\n21\n  3\n  6\n10\n18\n11\n  6\n25\n23\n  6\n  2\n15\n32\n25\n11\n  8\n17\n19\n  5\n15\n  0\n26\nMonarchs\n17\n  6\n13\n12\n13\n33\n59\n10\n  7\n63\n  9\n25\n36\n15\n1. Descriptive Statistics Include appropriate units in all answers.\na. Find the mean for each of the three groups.\nb. Find the standard deviation for each of the three groups.\nc. Find the variance for each of the three groups.\nd. What is the level of measurement of the data (nominal, ordinal, interval, ratio)?\n2. Comparing Two Means Treating the data as samples from larger populations, test the claim \nthat there is a difference between the mean for presidents and the mean for British monarchs.\n3. Normality Assessment Use the longevity times for presidents and determine whether they \nappear to come from a population having a normal distribution. Explain why the distribution \ndoes or does not appear to be normal.\n4. Confidence Interval Use the longevity times for presidents and construct a 95% confi-\ndence interval estimate of the population mean. Write a brief statement interpreting the confi-\ndence interval.\n5. ANOVA The display below results from using the one-way analysis of variance test with the \nthree samples.\na. What is the null hypothesis?\nb. Assuming a 0.05 significance level, what conclusion is indicated by the displayed results?\nCumulative Review Exercises\nMinitab\n6. Freshman 15: Correlation, Regression Listed below are weights (kg) of eight male col-\nlege students in September and April of their freshman year (from Data Set 10 “Freshman 15” \nin Appendix B).\na. Test for a linear correlation between September weights and the subsequent April weights.\nb. Find the equation of the regression line.\nc. Find the best predicted April weight for a male freshman student given that his weight in \nSeptember is 94 kg. How does that result compare to an actual male student who weighed \n94 kg in September and 105 kg in April?\nSeptember\n72\n97\n74\n93\n59\n54\n73\n77\nApril\n59\n86\n69\n88\n55\n56\n75\n79\n\t\nCHAPTER 12  Cumulative Review Exercises\t\n557\n\n558\t\nCHAPTER 12  Analysis of Variance\n7. Platelets: Normal Distribution Assume that adult females have blood platelet counts that \nare normally distributed with a mean of 280 and a standard deviation of 65. (All units are in \n1000 cells>mL.)\na. Find the probability that a randomly selected adult female has a platelet count greater than 345.\nb. Find the probability that a randomly selected adult female has a platelet count between 215 \nand 345.\nc. If 25 adult females are randomly selected, find the probability that the mean of their platelet \ncounts is less than 319.\nd. Find the value of P80, the 80th percentile.\n8. Health Benefits USA Today reported on an Adecco Staffing survey of 1000 randomly se-\nlected adults. Among those respondents, 20% chose health benefits as being most important to \ntheir job.\na. What is the number of respondents who chose health benefits as being most important to their job?\nb. Construct a 95% interval estimate of the proportion of all adults who choose health benefits \nas being most important to their job.\nc. Based on the result from part (b), can we safely conclude that the true proportion is different \nfrom 1>4? Why?\n9. Blue Genes Some couples have genetic characteristics configured so that one-quarter of \nall their offspring have blue eyes. A study is conducted of 100 couples believed to have those \ncharacteristics, with the result that 19 of their 100 offspring have blue eyes. Assuming that one-\nquarter of all offspring have blue eyes, estimate the probability that among 100 offspring, 19 or \nfewer have blue eyes. Based on that probability, does it seem that the one-quarter rate is wrong? \nWhy or why not?\n10. Firearm Injuries The table below lists numbers of firearm injuries arranged according \nto circumstances and whether the firearm was a handgun or a rifle or shotgun (based on data \nfrom “Hospitalization Charges, Costs, and Income for Firearm-Related Injuries at a Univer-\nsity Trauma Center,” by Kizer et al., Journal of the American Medical Association, Vol. 273, \nNo. 22). Use a 0.05 significance level to test the claim that the injury category is independent \nof the type of weapon.\nUnintentional\nSelf-Inflicted\nAssault\nHandgun\n31\n35\n162\nRifle or Shotgun\n13\n7\n  67\nDoes Weight Change with Age? Refer to Data Set 1 “Body Data” in Appendix B and use \nthe weights of males partitioned into the three different age brackets of 18–25, 26–40, and \n41–80. Use the methods of this chapter to test the claim that men in those three age brackets \nhave the same mean weight.\nSorting One challenge in this project is identifying the weights of men in the three age \nbrackets. First, use the sort feature of your technology to sort all of the columns using Gender \nas the basis for sorting. You can then delete all of the rows representing females. Then sort all \nof the columns using Age as the basis for sorting. It will then be much easier to identify the \nweights in the different age brackets.\nTechnology Project\n\nFROM DATA TO DECISION\nCritical Thinking: Is Lipitor Effective in Lowering  \nLDL Cholesterol?\nWith sales of Lipitor exceeding $13 billion each year, it has \nbeen the best-selling drug ever. One of the authors asked \nPfizer for original data from clinical drug trials of Lipitor, \nbut Pfizer declined to provide the data. The data shown are \nbased on results given in a Parke-Davis memo from David \nG. Orloff, M.D., the medical team leader in the clinical trials. \nThe data refer to atorvastatin, and Lipitor is the trade name \nof atorvastatin. Low-density lipoprotein (LDL) cholesterol \nis considered the bad cholesterol, so a subject’s condition is \ngenerally improved if the LDL cholesterol is lowered. The \nchanges in LDL cholesterol listed in the table are measured \nin mg>dL. Note that when compared to baseline values, \nnegative values in the following data indicate that the LDL \ncholesterol has been lowered.\nChanges in LDL Cholesterol from Baseline Values  \n(a negative value represents a decrease)\nPlacebo Group:\n  -3    5    6    -2   -7    8     5   -6    -1    7   -4    3\nGroup treated with 10 mg of atorvastatin:\n-28 -27 -23 -25 -27 -29 -22 -22 -26 -23 -23  \n-22 -24 -21 -25 -26 -23 -24 -23 -22 -22 -20 -29 \n-29 -27 -24 -28 -26 -22 -26 -23 -26 -25 -29 -27 \n-27 -23\nGroup treated with 20 mg of atorvastatin:\n-28 -32 -29 -39 -31 -35 -25 -36 -35 -26 -29  \n-34 -30\nGroup treated with 80 mg of atorvastatin:\n-42 -41 -38 -42 -41 -41 -40 -44 -32 -37 -41  \n-37 -34 -31\nCooperative Group Activities\n1. Out-of-class activity Flesch Reading Ease scores and Flesch-Kincaid Grade Level scores mea-\nsure readability of text. Some programs, such as Microsoft Word, include features that allow you to \nautomatically obtain readability scores. Divide into groups of three or four students. Using samples \nof writing from Journal of the American Medical Association, the American Journal of Nursing, \nand the American Journal of Public Health, obtain readability scores for ten samples of text from \neach source. Use the methods of this chapter to determine whether there are any differences.\n2. In-class activity Divide the class into three groups. One group should record the pulse rate \nof each member while he or she remains seated. The second group should record the pulse rate \nof each member while he or she is standing. The third group should record the pulse rate of \neach member immediately after he or she stands and sits 10 times. Analyze the results. What do \nthe results indicate?\n3. Out-of-class activity Biographyonline.net includes information on the lives of notable art-\nists, politicians, scientists, actors, and others. Design and conduct an observational study that \nbegins with choosing samples from select groups, followed by a comparison of life spans of \npeople from the different groups. Do any particular groups appear to have life spans that are \ndifferent from those of other groups? Can you explain such differences?\n4. Out-of-class activity Divide into groups of three or four students. Each group should survey \nother students at the same college by asking them to identify their major and gender. You might in-\nclude other factors, such as employment (none, part-time, full-time) and age (under 21, 21–30, over \n30). For each surveyed subject, determine the number of Twitter followers or Facebook friends.\n• Does gender appear to have an effect on the number of followers>friends?\n• Does major have an effect on the number of followers>friends?\n• Does an interaction between gender and major have an effect on the number of followers>friends?\n\t\nCHAPTER 12  Cooperative Group Activities\t\n559\nAnalyzing the Results\nAnalyze the data. Does it appear that atorvastatin treatment \nhas an effect? If atorvastatin treatment does have an effect, is \nit the desired effect? Does it appear that larger doses of ator-\nvastatin treatment result in greater beneficial effects? Write a \nbrief report summarizing your findings and include specific \nstatistical tests and results.\n\n560\nBasics of Nonparametric \nTests\nSign Test\nWilcoxon Signed-Ranks \nTest for Matched Pairs\nWilcoxon Rank-Sum Test \nfor Two Independent \nSamples\nKruskal-Wallis Test for \nThree or More Samples\nRank Correlation\n13-1\n13-2\n13-3\n13-4\n13-5\n13-6\nEffects of Second-Hand Smoke\nCHAPTER \nPROBLEM\nNonparametric Tests\nData Set 14 in Appendix B includes measured cotinine levels \n(ng>mL) of subjects from three different groups: (1) smokers; \n(2) nonsmokers who are exposed to tobacco smoke; and  \n(3) nonsmokers not exposed to tobacco smoke. Cotinine is a \nmetabolite of nicotine, meaning that when nicotine is absorbed \nby the body, cotinine is produced. We want to test the claim \nthat the three different groups have different levels of cotinine. \nThis seems like a good application of the method of one-way \nanalysis of variance that was presented in Section 12-1. How-\never, if we check the requirements for analysis of variance, we \nfind that the three samples should be from populations having \ndistributions that are approximately normal. The accompanying \nnormal quantile plot results from the sample of cotinine levels \nmeasured from the third group: nonsmokers not exposed to \n13 \n\nsmoke. The normality requirement for analysis of variance is a \nloose requirement, but the normal quantile plot suggests a dra-\nmatic departure from normality, so the normality requirement \ndoes not appear to be met.\nThis chapter presents “nonparametric” or “distribution-\nfree” methods that do not require normal or any other specific \ndistribution. This chapter will present a method that allows us \nto compare the cotinine levels in the three groups, even though \nthe three samples appear to be from populations with distribu-\ntions that are not normal. Nonparametric methods therefore \nprovide us with tools that often enable us to do an analysis that \nHere are the main objectives for Chapter 13:\nBasics of Nonparametric Tests\n• Develop the ability to describe the difference between parametric tests and  \nnonparametric tests.\n• Identify advantages and disadvantages of nonparametric tests.\n• Know how nonparametric tests are generally less efficient than the corresponding \nparametric tests.\n• Develop the ability to convert data into ranks.\nSign Test\n• Develop the ability to conduct a sign test for claims involving matched pairs of  \nsample data, or claims involving nominal data, or claims made about the median  \nof a population.\nWilcoxon Signed-Rank Test for Matched Pairs\n• Develop the ability to apply the Wilcoxon signed-ranks test for sample data consist-\ning of matched pairs.\nWilcoxon Rank-Sum Test for Two Independent Samples\n• Develop the ability to apply the Wilcoxon rank-sum test for sample data from two  \nindependent populations.\n13-1\n13-2\n13-3\n13-4\nChapter Objectives \n561\nCHAPTER OBJECTIVES\n3\n2.4\n1.8\n1.2\n0.6\n0\n-0.6\n-1.2\n-1.8\n-2.4\n-3\n0\n31\n62\n93\n124\n155\nX Values\nz score\n186\n217\n248\n279\n310\ncannot be done with parametric methods having requirements \nabout distributions.\n>>>\n\n562 \nCHAPTER 13 Nonparametric Tests\nThis chapter introduces methods of nonparametric tests, which do not have the \nstricter requirements of corresponding parametric tests, which are based on samples \nfrom populations with specific parameters such as m or s.\n13-1 \nBasics of Nonparametric Tests\nDEFINITIONS\nParametric tests have requirements about the distribution of the populations  \ninvolved; nonparametric (or distribution-free) tests do not require that samples \ncome from populations with normal distributions or any other particular distributions.\nMisleading Terminology The term distribution-free test correctly indicates that a \ntest does not require a particular distribution. The term nonparametric tests is mis-\nleading in the sense that it suggests that the tests are not based on a parameter, but \nthere are some nonparametric tests that are based on a parameter such as the median. \nDue to the widespread use of the term nonparametric test, we use that terminology, \nbut we define it to be a test that does not require a particular distribution.\nAdvantages and Disadvantages\nAdvantages of Nonparametric Tests\n1. Because nonparametric tests have less rigid requirements than parametric tests, \nthey can be applied to a wider variety of situations.\n2. Nonparametric tests can be applied to more data types than parametric \ntests. For example, nonparametric tests can be used with data consisting of \nranks, and they can be used with categorical data, such as genders of survey \nrespondents.\nDisadvantages of Nonparametric Tests\n1. Nonparametric tests tend to waste information because exact numerical data are \noften reduced to a qualitative form. For example, with the nonparametric sign \ntest (Section 13-2), weight losses by dieters are recorded simply as negative \nsigns, and the actual magnitudes of the weight losses are ignored.\nKruskal-Wallis Test for Three or More Samples\n• Develop the ability to apply the Kruskal-Wallis test for sample data from three or \nmore independent populations.\nRank Correlation\n• Develop the ability to compute the value of the rank correlation coefficient rs, and \nuse it to determine whether there is a correlation between two variables.\n13-5\n13-6\nKruskal-Wallis Test for Three or More Samples\n• Develop the ability to apply the Kruskal-Wallis test for sample data from three or \nmore independent populations.\nRank Correlation\n• Develop the ability to compute the value of the rank correlation coefficient rsrsr , and\nuse it to determine whether there is a correlation between two variables.\n\n13-1 Basics of Nonparametric Tests \n563\nRanks\nSections 13-2 through 13-6 use methods based on ranks, defined as follows.\nTABLE 13-1 Efficiency: Comparison of Parametric and Nonparametric Tests\nApplication\nParametric Test\nNonparametric Test\nEfficiency Rating  \nof Nonparametric  \nTest with Normal \nPopulations\nMatched pairs of \nsample data\nt test\nSign test or  \nWilcoxon signed-ranks test\n0.63 \n0.95\nTwo independent \nsamples\n \nt test\n \nWilcoxon rank-sum test\n \n0.95\nThree or more  \nindependent samples\nAnalysis of variance \n(F test)\n \nKruskal-Wallis test\n \n0.95\nCorrelation\nLinear correlation\nRank correlation test\n0.91\nDEFINITION\nData are sorted when they are arranged according to some criterion, such as \nsmallest to largest or best to worst. A rank is a number assigned to an individual \nsample item according to its order in the sorted list. The first item is assigned a \nrank of 1, the second item is assigned a rank of 2, and so on.\nHandling Ties Among Ranks If a tie in ranks occurs, one very common procedure is \nto find the mean of the ranks involved in the tie and then assign this mean rank to each \nof the tied items, as in the following example.\n2. Nonparametric tests are not as efficient as parametric tests, so a nonpara-\nmetric test generally needs stronger evidence (such as a larger sample or \ngreater differences) in order to reject a null hypothesis.\nEfficiency of Nonparametric Tests When the requirements of population dis-\ntributions are satisfied, nonparametric tests are generally less efficient than their \ncorresponding parametric tests. For example, Section 13-6 presents the concept of rank \ncorrelation, which has an efficiency rating of 0.91 when compared to linear correlation \nin Section 10-1. This means that with all other things being equal, the nonparametric \nrank correlation method in Section 13-6 requires 100 sample observations to achieve \nthe same results as 91 sample observations analyzed through the parametric linear \ncorrelation in Section 10-1, assuming the stricter requirements for using the para-\nmetric test are met. Table 13-1 lists nonparametric tests along with the corresponding \nparametric test and efficiency rating. Table 13-1 shows that several nonparamet-\nric tests have efficiency ratings above 0.90, so the lower efficiency might not be an \nimportant factor in choosing between parametric and nonparametric tests. However, \nbecause parametric tests do have higher efficiency ratings than their nonparamet-\nric counterparts, it’s generally better to use the parametric tests when their required \nassumptions are satisfied.\n\n564 \nCHAPTER 13 Nonparametric Tests\nKey Concept This section introduces the sign test, which involves converting data \nvalues to positive and negative signs, then testing to determine whether either sign \noccurs significantly more often than the other sign.\n13-2 \nSign Test\nDEFINITION\nThe sign test is a nonparametric (distribution-free) test that uses positive and  \nnegative signs to test different claims, including these:\n1. Claims involving matched pairs of sample data\n2. Claims involving nominal data with two categories\n3. Claims about the median of a single population\nBasic Concept of the Sign Test The basic idea underlying the sign test is to ana-\nlyze the frequencies of positive and negative signs to determine whether they are sig-\nnificantly different. For example, consider the results of clinical trials of the MicroSort \nmethod of gender selection. Among 726 couples who used the XSORT method in \ntrying to have a baby girl, 668 couples did have baby girls. Is 668 girls in 726 births \nsignificant? Common sense should suggest that 668 girls in 726 births is significant, \nbut what about 365 girls in 726 births? Or 400 girls in 726 births? The sign test allows \nus to determine when such results are significant. Figure 13-1 summarizes the sign \ntest procedure.\nFor consistency and simplicity, we will use a test statistic based on the number of \ntimes that the less frequent sign occurs.\nEXAMPLE 1  Handling Ties Among Ranks\nThe numbers 4, 5, 5, 5, 10, 11, 12, and 12 are given ranks of 1, 3, 3, 3, 5, 6, 7.5, and \n7.5, respectively. The table below illustrates the procedure for handling ties.\nSorted Data\nPreliminary Ranking\nRank\n4\n1\n1\n5\n5\n5\n2\n3\n4\n3\n3\n3\n10\n5\n5\n11\n6\n6\n12\n12\n7\n8\n7.5\n7.5\n$1%1&\n$1%1&\nMean is 3.\nf\nf Mean is 7.5.\n\nYes\nStart\nDo the sample\ndata contradict \nH1?\nIs n ◊ 25?\nConvert the test statistic x to\nthe test statistic\n(x 1 0.5) 2 (n/2)\nÏn/2\nFind the critical z value(s) from\nTable A-2 in the usual way.\nFind the critical value \nfrom Table A-7.\nIs the \ntest statistic\nless than or equal \nto the critical \nvalue(s)?\nFail to reject the null\nhypothesis.\nReject the null\nhypothesis.\nNo\nNo\nNo\nYes\nYes\nAssign positive and negative signs\nand discard any zeros.\nLet n equal the total number of signs.\nLet the test statistic x equal the \nnumber of the less frequent sign.\nz 5\nFIGURE 13-1 Sign Test Procedure\n13-2 Sign Test \n565\n\n566 \nCHAPTER 13 Nonparametric Tests\nSign Test\nObjective\nUse positive and negative signs to test a claim falling into one of the following three categories:\n1. Matched Pairs \n  •  Subtract the second value in each pair from the first, \nrecord the sign of the difference, and ignore any 0s.\nKEY ELEMENTS \n2. Nominal Data with Two Categories \n  •  Represent each member of one category by a posi-\ntive sign and represent each member of the other \ncategory by a negative sign.\n3. Median of a Single Population \n  •  Subtract the median from each sample value, re-\ncord the sign of the difference, and ignore any 0s.\nNotation\nx = the number of times the less frequent sign occurs\nn = the total number of positive and negative signs combined\nRequirements\nThe sample data are a simple random sample.\nNote: There is no requirement that the sample data come from a population with a particular distribution, such as a  \nnormal distribution.\nTest Statistic\nIf n … 25: Test statistic is x = the number of times the less frequent sign occurs.\nIf n 7 25: Test statistic is\nz =\n1x + 0.52 - an\n2b\n2n\n2\nP-Values\nP-values are often provided by technology, or P-values can often be found using the z test statistic.\nCritical Values\n1. If n … 25, critical x values are found in Table A-7.\n2. If n 7 25, critical z values are found in Table A-2.\nHint: Because z is based on the less frequent sign, all one-sided tests are treated as if they were left-tailed tests.\nCAUTION When using the sign test in a one-tailed test, be very careful to avoid \nmaking the wrong conclusion when one sign occurs significantly more often or \nsignificantly less often than the other sign but the sample data contradict the \nalternative hypothesis. A sample of 7% boys can never be used to support  \nthe claim that boys occur more than 50% of the time, as in Example 1.\n\n13-2 Sign Test \n567\nEXAMPLE 1  Data Contradicting the Alternative Hypothesis \nAmong 945 couples who used the XSORT method of gender selection, 66 had boys, \nso the sample proportion of boys is 66>945, or 0.0698 (based on data from the  \nGenetics & IVF Institute). Consider the claim that the XSORT method of gender  \nselection increases the likelihood of baby boys so that the probability of a boy is \np 7 0.5. This claim of p 7 0.5 becomes the alternative hypothesis.\nUsing common sense, we see that with a sample proportion of boys of 0.0698, \nwe can never support a claim that p 7 0.5. (We would need a sample proportion  \nof boys greater than 0.5 by a significant amount.) Here, the sample proportion of  \n66>945, or 0.0698, contradicts the alternative hypothesis because it is not greater \nthan 0.5.\nINTERPRETATION\nAn alternative hypothesis can never be supported with data that contradict it. The \nsign test will show that 66 boys in 945 births is significant, but it is significant in  \nthe wrong direction. We can never support a claim that p 7 0.5 with a sample  \nproportion of 66>945, or 0.0698, which is less than 0.5.\nClaims About Matched Pairs\nWhen using the sign test with data that are matched pairs, we convert the raw data to \npositive and negative signs as follows:\n1. Subtract each value of the second variable from the corresponding value of the \nfirst variable.\n2. Record only the sign of the difference found in Step 1. Exclude ties by  \ndeleting any matched pairs in which both values are equal.\nThe main concept underlying this use of the sign test is as follows:\nIf the two sets of data have equal medians, the number of positive signs \nshould be approximately equal to the number of negative signs.\nEXAMPLE 2  Freshman Weight Gain\nTable 13-2 includes some of the weights listed in Data Set 10 in Appendix B. Those \nweights were measured from college students in September and April of their fresh-\nman year. Use the sample data in Table 13-2 to test the claim that there is no differ-\nence between the September weights and the April weights. Use the sign test with a \n0.05 significance level.\nTABLE 13-2 Weight (kg) Measurements of Students in Their Freshman Year\nSeptember Weight\n67\n53\n64\n74\n67\n70\n55\n74\n62\n57\nApril Weight\n66\n52\n68\n77\n67\n71\n60\n82\n65\n58\nSign of Difference\n+\n+\n-\n-\n0\n-\n-\n-\n-\n-\nSOLUTION\nREQUIREMENT CHECK The only requirement of the sign test is that the sample data \nare a simple random sample. Instead of being a simple random sample of selected \nstudents, all subjects volunteered for the study, so the requirement is not satisfied. \nThis limitation is cited in the journal article describing the results of the study. We \nwill proceed as if the requirement of a simple random sample is satisfied. \ncontinued\n\n568 \nCHAPTER 13 Nonparametric Tests\nIf there is no difference between the April weights and the corresponding  \nSeptember weights, the numbers of positive and negative signs should be approxi-\nmately equal. In Table 13-2 we have 7 negative signs, 2 positive signs, and 1 differ-\nence of 0. The sign test tells us whether the numbers of positive and negative signs \nare approximately equal.\nThe null hypothesis is the claim of no difference between the April weights and \nthe September weights, and the alternative hypothesis is the claim that there is a \ndifference.\nH0: There is no difference. (The median of the differences is equal to 0.)\nH1: There is a difference. (The median of the differences is not equal to 0.)\nFollowing the sign test procedure summarized in Figure 13-1, we let n = 9 (the  \ntotal number of signs) and we let x = 2 (the number of the less frequent sign, or  \nthe smaller of 2 and 7).\nThe sample data do not contradict H1, because there is a difference between the \n2 positive signs and the 7 negative signs. The sample data show a difference, and we \nneed to continue with the test to determine whether that difference is significant.\nTest Statistic Because n … 25, the test statistic is x = 2 and we do not convert \nx to a z score.\nCritical Value Figure 13-1 shows that with n = 9, we should proceed to find \nthe critical value from Table A-7. We refer to Table A-7, where the critical value of \n1 is found for n = 9 and a = 0.05 in two tails.\nConclusion With a test statistic of x = 2 and a critical value of 1, we fail to \nreject the null hypothesis of no difference. (See Note 2 included with Table A-7: \n“Reject the null hypothesis if the number of the less frequent sign x is less than or \nequal to the value in the table.” Because x = 2 is not less than or equal to the criti-\ncal value of 1, we fail to reject the null hypothesis.) There is not sufficient evidence \nto warrant rejection of the claim that the median of the differences is equal to 0.\nINTERPRETATION\nWe conclude that the September and April weights appear to be about the same.  \n[If we use the parametric t test for matched pairs (Section 9-3), we conclude that the \nmean difference is not zero, so the September weights and April weights appear to \nbe different.]\nThe conclusion should be qualified with the limitations noted in the article \nabout the study. Only Rutgers students were used, and study subjects were volun-\nteers instead of being a simple random sample.\nClaims Involving Nominal Data with Two Categories\nIn Chapter 1 we defined nominal data to be data that consist of names, labels, or cat-\negories only. The nature of nominal data limits the calculations that are possible, but \nwe can identify the proportion of the sample data that belong to a particular category, \nand we can test claims about the corresponding population proportion p. The follow-\ning example uses nominal data consisting of genders (girls>boys). The sign test is \nused by representing girls with positive 1+ 2 signs and boys with negative 1- 2 signs. \n(Those signs are chosen arbitrarily—honest.)\n\n13-2 Sign Test \n569\nEXAMPLE 3  Gender Selection\nThe Genetics & IVF Institute conducted a clinical trial of its methods for gender se-\nlection for babies. Before the clinical trials were concluded, 879 of 945 babies born \nto parents using the XSORT method of gender selection were girls. Use the sign test \nand a 0.05 significance level to test the claim that this method of gender selection is \neffective in increasing the likelihood of a baby girl.\nSOLUTION\nREQUIREMENT CHECK The only requirement is that the sample is a simple random \nsample. Based on the design of this experiment, we can assume that the sample data \nare a simple random sample. \nLet p denote the population proportion of baby girls. The claim that girls are \nmore likely with the XSORT method can be expressed as p 7 0.5, so the null and \nalternative hypotheses are as follows:\n H0: p = 0.5 1the proportion of girls is equal to 0.52\n H1: p 7 0.5 1girls are more likely2\nDenoting girls by positive signs 1+ 2 and boys by negative signs 1- 2, we have 879 \npositive signs and 66 negative signs. Using the sign test procedure summarized in \nFigure 13-1, we let the test statistic x be the smaller of 879 and 66, so x = 66 boys. \nInstead of trying to determine whether 879 girls is high enough to be significantly \nhigh, we proceed with the equivalent goal of trying to determine whether 66 boys is \nlow enough to be significantly low, so we treat the test as a left-tailed test.\nThe sample data do not contradict the alternative hypothesis because the sample \nproportion of girls is 879>945, or 0.930, which is greater than 0.5, as in the above \nalternative hypothesis. Continuing with the procedure in Figure 13-1, we note that \nthe value of n = 945 is greater than 25, so the test statistic x = 66 is converted  \n(using a correction for continuity) to the test statistic z as follows:\n z =\n1x + 0.52 - an\n2b\n2n\n2\n =\n166 + 0.52 - a945\n2 b\n2945\n2\n= -26.41\nP-Value We could use the test statistic of z = -26.41 to find the left-tailed P-value \nof 0.0000 (Table: 0.0001), and that low P-value causes us to reject the null hypothesis.\nCritical Value With a = 0.05 in a left-tailed test, the critical value is z = -1.645.\nConclusion Figure 13-2 shows that the test statistic z = -26.41 is in the critical \nregion bounded by z = -1.645, so we reject the null hypothesis that the proportion \nof girls is equal to 0.5. There is sufficient sample evidence to support the claim that \ngirls are more likely with the XSORT method.\ncontinued\n\n570 \nCHAPTER 13 Nonparametric Tests\nINTERPRETATION\nThe XSORT method of gender selection does appear to be associated with an  \nincrease in the likelihood of a girl, so this method appears to be effective (but this  \nhypothesis test does not prove that the XSORT method is the cause of the increase).\nz 5 0\nReject\np 5 0.5\nFail to reject\np 5 0.5\nSample data:\nz 5 –26.41\nz 5 21.645\nFIGURE 13-2  Testing Effectiveness of the XSORT  \nGender Selection Method\nClaims About the Median of a Single Population\nThe next example illustrates the procedure for using the sign test in testing a claim \nabout the median of a single population. See how the negative and positive signs are \nbased on the claimed value of the median.\nEXAMPLE 4  Body Temperatures\nData Set 2 in Appendix B includes measured body temperatures of adults. Use  \nthe 106 temperatures listed for 12 AM on Day 2 with the sign test to test the claim \nthat the median is less than 98.6°F. Of the 106 subjects, 68 had temperatures  \nbelow 98.6°F, 23 had temperatures above 98.6°F, and 15 had temperatures equal  \nto 98.6°F.\nSOLUTION\nREQUIREMENT CHECK The only requirement is that the sample is a simple random \nsample. Based on the design of this experiment, we assume that the sample data are \na simple random sample. \nThe claim that the median is less than 98.6°F is the alternative hypothesis, \nwhile the null hypothesis is the claim that the median is equal to 98.6°F.\nH0: Median is equal to 98.6°F. 1median = 98.6°F2\nH1: Median is less than 98.6°F. 1median 6  98.6°F2\nFollowing the procedure outlined in Figure 13-1, we use a negative sign to represent \neach temperature below 98.6°F, and we use a positive sign for each temperature \nabove 98.6°F. We discard the 15 data values of 98.6°F, since they result in dif-\nferences of zero. We have 68 negative signs and 23 positive signs, so n = 91 and \nx = 23 (the number of the less frequent sign). The sample data do not contradict \nthe alternative hypothesis, because most of the 91 temperatures are below 98.6°F.\n\n13-2 Sign Test \n571\nTest Statistic The value of n exceeds 25, so we convert the test statistic x to the test \nstatistic z:\n z =\n1 x + 0.52 - an\n2b\n2n\n2\n =\n123 + 0.52 - a91\n2 b\n291\n2\n= -4.61\nP-Value In this left-tailed test, the test statistic of z = -4.61 yields a P-value of \n0.0000 (Table: 0.0001).\nCritical Value In this left-tailed test with a = 0.05, we use Table A-2 to get the \ncritical z value of -1.645.\nConclusion Using either the low P-value of 0.000 or the fact that the test statistic of \nz = -4.61 is within the critical region as shown in Figure 13-3, we reject the null \nhypothesis.\nz 5 0\nReject\nMedian 5 98.68\nFail to reject\nMedian 5 98.68\nSample data:\nz 5 24.61\nz 5 21.645\nFIGURE 13-3  Testing the Claim That the Median  \nIs Less Than 98.6°F\nINTERPRETATION\nThere is sufficient sample evidence to support the claim that the median body  \ntemperature of healthy adults is less than 98.6°F. It is not equal to 98.6, as is com-\nmonly believed.\nNonparametric vs. Parametric In Example 4, the sign test of the claim that the \nmedian is below 98.6°F results in a test statistic of z = -4.61 and a P-value of \n0.00000202. However, a parametric test of the claim that m 6 98.6°F results in a \ntest statistic of t = -6.611 with a P-value of 0.000000000813. Because the P-value \nfrom the sign test is not as low as the P-value from the parametric test, we see that the \nsign test isn’t as sensitive as the parametric test. Both tests lead to rejection of the null \nhypothesis, but the sign test doesn’t consider the sample data to be as extreme, partly \nbecause the sign test uses only information about the direction of the data, ignoring \nthe magnitudes of the data values. The next section introduces the Wilcoxon signed-\nranks test, which largely overcomes that disadvantage.\n\n572 \nCHAPTER 13 Nonparametric Tests\nRationale for the Test Statistic Used When n + 25 When finding critical values \nfor the sign test, we use Table A-7 only for n up to 25. When n 7 25, the test statistic \nz is based on a normal approximation to the binomial probability distribution with \np = q = 1>2. In Section 6-6 we saw that the normal approximation to the binomial \ndistribution is acceptable when both np Ú 5 and nq Ú 5. In Section 5-2 we saw that \nm = np and s = 1npq for binomial probability distributions. Because this sign test \nassumes that p = q = 1>2, we meet the np Ú 5 and nq Ú 5 prerequisites whenever \nn Ú 10. Also, with the assumption that p = q = 1>2, we get m = np = n>2 and \ns = 1npq = 1n>4 = 1n>2, so the standard z score\nz = x - m\ns\nbecomes\nz =\nx - an\n2b\n2n\n2\nWe replace x by x + 0.5 as a correction for continuity. That is, the values of x are \ndiscrete, but since we are using a continuous probability distribution, a discrete value \nsuch as 10 is actually represented by the interval from 9.5 to 10.5. Because x repre-\nsents the less frequent sign, we act conservatively by concerning ourselves only with \nx + 0.5; we get the test statistic z shown below and in the Key Elements box.\nz =\n1 x + 0.52 - an\n2b\n2n\n2\nStatistical Literacy and Critical Thinking\n1. Sign Test for Body Temperatures The table below lists body temperatures of five sub-\njects at 8 AM and at 12 AM (from Data Set 2 in Appendix B). The data are matched pairs be-\ncause each pair of temperatures is measured from the same person. Assume that we plan to use \nthe sign test to test the claim of no difference between body temperatures at 8 AM and 12 AM.\na. What requirements must be satisfied for this test?\nb. Is there any requirement that the samples must be from populations having a normal distri-\nbution or any other specific distribution?\nc. In what sense is this sign test a “distribution-free test”?\nTemperature (oF) at 8 AM\n98.0\n97.6\n97.2\n98.0\n97.0\n98.0\nTemperature (oF) at 12 AM\n97.0\n98.8\n97.6\n98.0\n97.7\n98.8\n2. Identifying Signs For the sign test described in Exercise 1, identify the number of positive \nsigns, the number of negative signs, the number of ties, the sample size n that is used for the \nsign test, and the value of the test statistic.\n13-2 Basic Skills and Concepts \nSign Test\nAccess tech instructions, videos, and data sets at www.TriolaStats.com\nTECH CENTER\n\n13-2 Sign Test \n573\n3. Contradicting H1 An important step in conducting the sign test is to determine whether the \nsample data contradict the alternative hypothesis H1. For the sign test described in Exercise 1, \nidentify the null hypothesis and the alternative hypothesis, and explain how the sample data \ncontradict or do not contradict the alternative hypothesis.\n4. Efficiency of the Sign Test Refer to Table 13-1 on page 563 and identify the efficiency of \nthe sign test. What does that value tell us about the sign test?\nMatched Pairs. In Exercises 5–8, use the sign test for the data consisting of matched pairs.\n5. Heights of Mothers and Daughters Listed below are heights (in.) of mothers and their \nfirst daughters. The data are from a journal kept by Francis Galton. (The data are from Data Set \n6 “Family Heights.”) Use a 0.05 significance level to test the claim of no difference in heights \nbetween mothers and their first daughters.\nHeight of Mother\n68.0\n60\n61.0\n63.5\n69\n64.0\n69\n64\n63.5\n66\nHeight of Daughter\n68.5\n60\n63.5\n67.5\n68\n65.5\n69\n68\n64.5\n63\n6. Heights of Fathers and Sons Listed below are heights (in.) of fathers and their first sons. \nThe data are from a journal kept by Francis Galton. (The data are from Data Set 6 “Family \nHeights.”) Use a 0.05 significance level to test the claim that there is no difference in heights \nbetween fathers and their first sons.\nHeight of Father\n72\n66\n69\n70\n70\n70\n70\n75\n68.2\n65\nHeight of Son\n73\n68\n68\n71\n70\n70\n71\n71\n70.0\n63\n7. Friday the 13th Researchers collected data on the numbers of hospital admissions resulting \nfrom motor vehicle crashes, and results are given below for Fridays on the 6th of a month and \nFridays on the following 13th of the same month (based on data from “Is Friday the 13th Bad \nfor Your Health?” by Scanlon et al., British Medical Journal, Vol. 307, as listed in the Data and \nStory Line online resource of data sets). Test the claim that when the 13th day of a month falls \non a Friday, the numbers of hospital admissions from motor vehicle crashes are not affected.\nFriday the 6th\n 9\n 6\n11\n11\n3\n 5\nFriday the 13th\n13\n12\n14\n10\n4\n12\n8. Before, After Treatment Results Captopril is a drug designed to lower systolic blood \npressure. When subjects were treated with this drug, their systolic blood pressure readings \n(in mm Hg) were measured before and after the drug was taken. Results are given in the ac-\ncompanying table (based on data from “Essential Hypertension: Effect of an Oral Inhibitor of \nAngiotensin-Converting Enzyme,” by MacGregor et al., British Medical Journal, Vol. 2). \nUsing a 0.01 significance level, is there sufficient evidence to support the claim that captopril \nhas an effect on systolic blood pressure?\nSubject\nA\nB\nC\nD\nE\nF\nG\nH\nI\nJ\nK\nL\nBefore\n200\n174\n198\n170\n179\n182\n193\n209\n185\n155\n169\n210\nAfter\n191\n170\n177\n167\n159\n151\n176\n183\n159\n145\n146\n177\nNominal Data. In Exercises 9–12, use the sign test for the claims involving nominal data.\n9. Stem Cell Survey Newsweek conducted a poll in which respondents were asked if they “fa-\nvor or oppose using federal tax dollars to fund medical research using stem cells obtained from \nhuman embryos.” Of those polled, 481 were in favor, 401 were opposed, and 120 were unsure. \nUse a 0.01 significance level to test the claim that there is no difference between the propor-\ntions of those opposed and those in favor.\n10. Medical Malpractice In a study of 1228 randomly selected medical malpractice lawsuits, \nit was found that 856 of them were dropped or dismissed (based on data from the Physicians \nInsurers Association of America). Use a 0.01 significance level to test the claim that there is a \ndifference between the rate of medical malpractice lawsuits that go to trial and the rate of such \nlawsuits that are dropped or dismissed.\n\n574 \nCHAPTER 13 Nonparametric Tests\n11. Births A random sample of 860 births in New York State included 426 boys and 434 girls. \nUse a 0.05 significance level to test the claim that when babies are born, boys and girls are \nequally likely.\n12. Touch Therapy At the age of 9, Emily Rosa tested professional touch therapists to see if \nthey could sense her energy field. She flipped a coin to select either her right hand or her left \nhand; then she asked the therapists to identify the selected hand by placing their hand just under \nEmily’s hand without seeing it and without touching it. Among 280 trials, the touch therapists \nwere correct 123 times and wrong the other times (based on data in “A Close Look at Thera-\npeutic Touch,” Journal of the American Medical Association, Vol. 279, No. 13). Use a 0.01 \nsignificance level to test the claim that the touch therapists make their selections with a method \nequivalent to random guesses. Based on the results, does it appear that therapists are effective \nat identifying the correct hand?\nAppendix B Data Sets. In Exercises 13–16, refer to the indicated data set in Appendix B \nand use the sign test for the claim about the median of a population.\n13. IQ Scores Use the 20 IQ scores listed in Data Set 9 “IQ and Brain Size” and test the claim \nthat they are from a population with a median IQ score of 100. Use a 0.05 significance level.\n14. IQ Scores and Lead Exposure Use the full IQ scores for the group with low lead expo-\nsure in Data Set 8 “IQ and Lead.” Test the claim that they are from a population with a median \nIQ score of 100. Use a 0.01 significance level.\n15. Diastolic Blood Pressure Use the complete list of diastolic blood pressure measure-\nments from Data Set 1 “Body Data” and test the claim that they are from a population with a \nmedian equal to 72. Use a 0.05 significance level.\n16. Systolic Blood Pressure Use the complete list of systolic blood pressure measurements \nfrom Data Set 1 “Body Data” and test the claim that they are from a population with a median \nequal to 125. Use a 0.05 significance level.\n13-2 Beyond the Basics \n17. Procedures for Handling Ties In the sign test procedure described in this section, we \nexclude ties (represented by 0 instead of a sign of + or -). Here is a second approach: Treat \nhalf of the 0s as positive signs and half as negative signs. (If the number of 0s is odd, exclude \none so that they can be divided equally.) Here is a third approach: For two-tailed tests make \nhalf of the 0s positive and half negative, and for one-tailed tests make all 0s either positive or \nnegative, whichever supports the null hypothesis. Repeat Example 4 “Body Temperatures” us-\ning the second and third approaches to handling ties. Do the different approaches lead to very \ndifferent test statistics, P-values, and conclusions?\n18. Finding Critical Values Table A-7 lists critical values for limited choices of a. Use Table A-1 \nto add a new column in Table A-7 (from n = 1 to n = 8) that represents a significance level \nof 0.03 in one tail or 0.06 in two tails. For any particular n, use p = 0.5, because the sign test \nrequires the assumption that P(positive sign) = P(negative sign) = 0.5. The probability of \nx or fewer like signs is the sum of the probabilities for values up to and including x.\n\n13-3 Wilcoxon Signed-Ranks Test for Matched Pairs \n575\nKey Concept This section introduces the Wilcoxon signed-ranks test, which begins \nwith the conversion of the sample data into ranks. This test can be used for the two \ndifferent applications described in the following definition.\n \n13-3\n \n Wilcoxon Signed-Ranks Test for \nMatched Pairs\nDEFINITION\nThe Wilcoxon signed-ranks test is a nonparametric test that uses ranks for these \napplications:\n1. Testing a claim that a population of matched pairs has the property that the \nmatched pairs have differences with a median equal to zero\n2. Testing a claim that a single population of individual values has a median equal \nto some claimed value\nWhen testing a claimed value of a median for a population of individual values, we \ncreate matched pairs by pairing each sample value with the claimed median, so the \nsame procedure is used for both of the applications above.\nClaims Involving Matched Pairs\nThe sign test (Section 13-2) can be used with matched pairs, but the sign test uses only \nthe signs of the differences. By using ranks instead of signs, the Wilcoxon signed-\nranks test takes the magnitudes of the differences into account, so it includes and uses \nmore information than the sign test and therefore tends to yield conclusions that better \nreflect the true nature of the data.\nWilcoxon Signed-Ranks Test\nObjective: Use the Wilcoxon signed-ranks test for the following tests:\n • Matched Pairs: Test the claim that a population of \nmatched pairs has the property that the matched pairs \nhave differences with a median equal to zero.\n • One Population of Individual Values: Test the \nclaim that a population has a median equal to some \nclaimed value. (By pairing each sample value with the \nclaimed median, we again work with matched pairs.)\nNotation\nT = the smaller of the following two sums:\n1. The sum of the positive ranks of the nonzero  \ndifferences d\n2. The absolute value of the sum of the negative ranks of \nthe nonzero differences d\n(Details for evaluating T are given in the procedure following this Key Elements box.)\nKEY ELEMENTS \ncontinued\n\n576 \nCHAPTER 13 Nonparametric Tests\nRequirements\n1. The data are a simple random sample.\n2. The population of differences has a distribution that \nis approximately symmetric, meaning that the left half \nof its histogram is roughly a mirror image of its right \nhalf. (For a sample of matched pairs, obtain differences \nby subtracting the second value from the first value in \neach pair; for a sample of individual values, obtain dif-\nferences by subtracting the value of the claimed median \nfrom each sample value.)\nNote: There is no requirement that the data have a normal \ndistribution.\nTest Statistic\nIf n … 30, the test statistic is T.\nIf n 7 30, the test statistic is z =\nT - n1n + 12\n4\nB\nn1n + 1212n + 12\n24\nP-Values\nP-values are often provided by technology or P-values can be found using the z test statistic and Table A-2.\nCritical Values\n1. If n … 30, the critical T value is found in Table A-8.\n2. If n 7 30, the critical z values are found in Table A-2.\nThe following procedure requires that you sort data, then assign ranks. When working \nwith larger data sets, sorting and ranking become tedious, but technology can be used \nto automate that process. Stemplots can also be very helpful in sorting data.\nWilcoxon Signed-Ranks Procedure To see how the following steps are applied, \nrefer to the sample of matched pairs listed in the first two rows of Table 13-3. Assume \nthat we want to test the null hypothesis that the matched pairs are from a population of \nmatched pairs with differences having a median equal to zero.\nTABLE 13-3 Weights (kg) of Students in Their Freshman Year\nSeptember weight\n 67\n 53\n 64\n   74\n67\n   70\n 55\n 74\n   62\n   57\nApril weight\n 66\n 52\n 68\n   77\n67\n   71\n 60\n 82\n   65\n   58\nd (difference)\n   1\n   1\n-4\n   -3\n 0\n   -1\n-5\n-8\n   -3\n   -1\nRank of |d|\n2.5\n2.5\n  7\n   5.5\n   2.5\n  8\n  9\n   5.5\n   2.5\nSigned rank\n2.5\n2.5\n-7\n-5.5\n-2.5\n-8\n-9\n-5.5\n-2.5\nStep 1:  For each pair of data, find the difference d by subtracting the second value \nfrom the first value. Discard any pairs that have a difference of 0.\n \n EXAMPLE: The third row of Table 13-3 lists the differences found by sub-\ntracting the April weights from the corresponding September weights.\nStep 2:  Ignore the signs of the differences, then sort the differences from lowest to \nhighest and replace the differences by the corresponding rank value (as  \ndescribed in Section 13-1). When differences have the same numerical \nvalue, assign to them the mean of the ranks involved in the tie.\n\n13-3 Wilcoxon Signed-Ranks Test for Matched Pairs \n577\nEXAMPLE: The fourth row of Table 13-3 shows the ranks of the values of \n\u001ed\u001e. Consider the d values of 1, 1, -1, -1. If we ignore their signs, they are \ntied for the rank values of 1, 2, 3, 4, so they are each assigned a rank of 2.5, \nwhich is the mean of the ranks involved in the tie (or the mean of 1, 2, 3, 4).\nStep 3:  Attach to each rank the sign of the difference from which it came. That is, \ninsert the signs that were ignored in Step 2.\n \n EXAMPLE: The bottom row of Table 13-3 lists the same ranks found in the \nfourth row, but the signs of the differences shown in the third row are inserted.\nStep 4:  Find the sum of the ranks that are positive. Also find the absolute value of \nthe sum of the negative ranks.\n \n EXAMPLE: The bottom row of Table 13-3 lists the signed ranks. The sum \nof the positive ranks is 2.5 + 2.5 = 5. The sum of the negative ranks is \n(-7) + (-5.5) + (-2.5) + (-8) + (-9) + (-5.5) + (-2.5) = -40,  \nand the absolute value of this sum is 40. The two rank sums are 5 and 40.\nStep 5:  Let T be the smaller of the two sums found in Step 4. Either sum could be used, \nbut for a simplified procedure we arbitrarily select the smaller of the two sums.\n \n EXAMPLE: The data in Table 13-3 result in the rank sums of 5 and 40, so \nthe smaller of those two sums is 5.\nStep 6: Let n be the number of pairs of data for which the difference d is not 0.\n \n EXAMPLE: The data in Table 13-3 have 9 differences that are not 0, so n = 9.\nStep 7:  Determine the test statistic and critical values based on the sample size, as \nshown in the preceding Key Elements box.\n \n EXAMPLE: For the data in Table 13-3 the test statistic is T = 5. The sample \nsize is n = 9, so the critical value is found in Table A-8. Using a 0.05 sig-\nnificance level with a two-tailed test, the critical value from Table A-8 is 6.\nStep 8:  When forming the conclusion, reject the null hypothesis if the sample data lead \nto a test statistic that is in the critical region—that is, the test statistic is less than \nor equal to the critical value(s). Otherwise, fail to reject the null hypothesis.\n \n EXAMPLE: If the test statistic is T (instead of z), reject the null hypothesis if \nT is less than or equal to the critical value. Fail to reject the null hypothesis \nif T is greater than the critical value. Since T = 5 and the critical value is 6, \nwe reject the null hypothesis that the matched pairs are from a population of \nmatched pairs with differences having a median equal to zero.\nEXAMPLE 1  Freshman Weight Gain \nThe first two rows of Table 13-3 include some of the weights from Data Set 10 \n“Freshman 15” in Appendix B. Those weights were measured from college students \nin September and April of their freshman year. Use the sample data in the first  \ntwo rows of Table 13-3 to test the claim that there is no difference between the  \nSeptember weights and the April weights. Use the Wilcoxon signed-ranks test with \na 0.05 significance level.\nSOLUTION\nREQUIREMENT CHECK (1) The data should be a simple random sample. Instead \nof being a simple random sample of selected students, all subjects volunteered, \ncontinued\n\n578 \nCHAPTER 13 Nonparametric Tests\nand this is discussed in the journal article describing the results of the study. We \nwill proceed as if the requirement of a simple random sample is satisfied. (2) The \nhistogram of the differences in the third row of Table 13-3 is shown here. The left \nside of the graph should be roughly a mirror image of the right side, which does \nnot appear to be the case. But with only 9 differences, the difference between the \nleft and right sides is not too extreme, so we will consider this requirement to be \nsatisfied. \nThe null hypothesis is the claim of no difference between the April weights  \nand the September weights, and the alternative hypothesis is the claim that there is a \ndifference.\nH0: There is no difference. 1The median of the differences is equal to 0.2\nH1: There is a difference. 1The median of the differences is not equal to 0.2\nTest Statistic Because we are using the Wilcoxon signed-ranks test, the test statis-\ntic is calculated by using the eight-step procedure presented earlier in this section. \nThose steps include examples illustrating the calculation of the test statistic with the \nsample data in Table 13-3, and the result is the test statistic of T = 5.\nCritical Value The sample size is n = 9, so the critical value is found in Table A-8. \nUsing a 0.05 significance level with a two-tailed test, the critical value from Table A-8 \nis found to be 6.\nConclusion Table A-8 includes a note stating that we should reject the null  \nhypothesis if the test statistic T is less than or equal to the critical value. Because \nthe test statistic of T = 5 is less than the critical value of 6, we reject the null  \nhypothesis.\nINTERPRETATION\nWe conclude that the September and April weights do not appear to be about the \nsame. The large number of negative differences indicates that most students gained \nweight during their freshman year. The conclusion should be qualified with the limi-\ntations noted in the article about the study. Only Rutgers students were used, and \nstudy subjects were volunteers instead of being a simple random sample.\nIn Example 1, if we use the parametric t test for matched pairs (Section 9-3), we \nconclude that the mean difference is not zero, so the September weights and April \nweights appear to be different, as in Example 1. However, the sign test in Section 13-2 \nled to the conclusion of no difference. By using only positive and negative signs, the \nsign test did not use the magnitudes of the differences, but the Wilcoxon signed-ranks \ntest was more sensitive to those magnitudes through its use of ranks.\n\n13-3 Wilcoxon Signed-Ranks Test for Matched Pairs \n579\nClaims About the Median of a Single Population\nThe Wilcoxon signed-ranks test can also be used to test a claim that a single popula-\ntion has some claimed value of the median.\nWhen testing a claim about the median of a single population, create \nmatched pairs by pairing each sample value with the claimed value of \nthe median. The preceding procedure can then be used.\nEXAMPLE 2  Body Temperatures\nData Set 2 “Body Temperatures” in Appendix B includes measured body tempera-\ntures of adults. Use the 106 temperatures listed for 12 AM on Day 2 with the  \nWilcoxon signed-ranks test to test the claim that the median is less than 98.6°F.  \nUse a 0.05 significance level.\nSOLUTION\nREQUIREMENT CHECK (1) The design of the experiment that led to the data in Data \nSet 2 justifies treating the sample as a simple random sample. (2) The requirement \nof an approximately symmetric distribution of differences is satisfied, because a  \nhistogram of those differences is approximately symmetric. \nBy pairing each individual sample value with the median of 98.6°F, we are \nworking with matched pairs. Shown in the margin is the Statdisk display showing the \ntest statistic of  T = 661, which converts to the test statistic z = -5.67. (The display \nis from a two-tailed test; for this left-tailed test, the critical value is -1.645.) The test \nstatistic of z = -5.67 yields a P-value of 0.000, so we reject the null hypothesis that \nthe population of differences between body temperatures and the claimed median of \n98.6°F is zero. There is sufficient evidence to support the claim that the median body \ntemperature is less than 98.6°F. This is the same conclusion that results from the sign \ntest in Example 4 in Section 13-2.\nRationale: In Example 1, the unsigned ranks of 1 through 9 have a total of 45, so \nif there are no significant differences, each of the two signed-rank totals should be \naround 45 , 2, or 22.5. That is, the negative ranks and positive ranks should split up \nas 22.5–22.5 or something close, such as 24–21. Table A-8, the table of critical values, \nshows that at the 0.05 significance level with 9 pairs of data, the critical value is 6, so a \nsplit of 6–39 represents a significant departure from the null hypothesis, and any split \nthat is further apart will also represent a significant departure from the null hypothesis. \nConversely, splits like 7–38 do not represent significant departures from a 22.5–22.5 \nsplit, and they would not justify rejecting the null hypothesis. The Wilcoxon signed-\nranks test is based on the lower rank total, so instead of analyzing both numbers con-\nstituting the split, we consider only the lower number.\nThe sum of all the ranks 1 + 2 + 3 + g + n is equal to n1n + 12>2. If this \nrank sum is to be divided equally between two categories (positive and negative), each \nof the two totals should be near n1n + 12>4, which is half of n1n + 12>2. Recogni-\ntion of this principle helps us understand the test statistic used when n 7 30.\nStatdisk\nWilcoxon Signed-Ranks Test\nAccess tech instructions, videos, and data sets at www.TriolaStats.com\nTECH CENTER\n\n580 \nCHAPTER 13 Nonparametric Tests\n13-3 Basic Skills and Concepts \nStatistical Literacy and Critical Thinking\n1. Wilcoxon Signed-Ranks Test for Body Temperatures The table below lists body tem-\nperatures of seven subjects at 8 AM and at 12 AM (from Data Set 2 in Appendix B). The \ndata are matched pairs because each pair of temperatures is measured from the same person. \nAssume that we plan to use the Wilcoxon signed-ranks test to test the claim of no difference \nbetween body temperatures at 8 AM and 12 AM.\na. What requirements must be satisfied for this test?\nb. Is there any requirement that the samples must be from populations having a normal distri-\nbution or any other specific distribution?\nc. In what sense is this sign test a “distribution-free test”?\nTemperature (oF) at 8 AM\n98.0\n97.6\n97.2\n98.0\n97.0\n98.0\n98.2\nTemperature (oF) at 12 AM\n97.0\n98.8\n97.6\n98.0\n97.7\n98.8\n97.6\n2. Body Temperatures For the matched pairs listed in Exercise 1, identify the following \ncomponents used in the Wilcoxon signed-ranks test:\na. Differences d\nb. The ranks corresponding to the nonzero values of \u001ed\u001e\nc. The signed ranks\nd. The sum of the positive ranks and the sum of the absolute values of the negative ranks\ne. The value of the test statistic T\nf. The critical value of T (assuming a 0.05 significance level in a test of no difference between \nbody temperatures at 8 AM and 12 AM)\n3. Sign Test vs. Wilcoxon Signed-Ranks Test Using the data in Exercise 1, we can test \nfor no difference between body temperatures at 8 AM and 12 AM by using the sign test or the \nWilcoxon signed-ranks test. In what sense does the Wilcoxon signed-ranks test incorporate and \nuse more information than the sign test?\n4. Efficiency of the Wilcoxon Signed-Ranks Test Refer to Table 13-1 on page 563 and iden-\ntify the efficiency of the Wilcoxon signed-ranks test. What does that value tell us about the test?\nUsing the Wilcoxon Signed-Ranks Test. In Exercises 5–8, refer to the sample data for \nthe given exercises in Section 13-2 on page 573. Use the Wilcoxon signed-ranks test to test \nthe claim that the matched pairs have differences that come from a population with a  \nmedian equal to zero. Use a 0.05 significance level.\n5. Exercise 5 “Heights of Mothers and Daughters”\n6. Exercise 6 “Heights of Fathers and Sons”\n7. Exercise 7 “Friday the 13th”\n8. Exercise 8 “Before>After Treatment Results”\nClaim About a Median In Exercises 9–12, refer to the sample data from the given exer-\ncises in Section 13-2 on pages 573–574. Use the Wilcoxon signed-ranks test for the claim \nabout the median of a population.\n9. Exercise 13 “IQ Scores”\n10. Exercise 14 “IQ Scores and Lead Exposure”\n11. Exercise 15 “Diastolic Blood Pressure”\n12. Exercise 16 “Systolic Blood Pressure”\n\n13-4 Wilcoxon Rank-Sum Test for Two Independent Samples  \n581\n13-3 Beyond the Basics \n13. Rank Sums Exercise 12 uses body measurement data from Data Set 1 “Body Data” in \nAppendix B, and the sample size is 300.\na. If we have sample paired data with 300 nonzero differences, what are the smallest and larg-\nest possible values of T?\nb. If we have sample paired data with 300 nonzero differences, what is the expected value of T \nif the population consists of matched pairs with differences having a median of 0?\nc. If we have sample paired data with 300 nonzero differences and the sum of the positive ranks \nis 12,345, find the absolute value of the sum of the negative ranks.\nd. If we have sample paired data with n nonzero differences and one of the two rank sums is k, \nfind an expression for the other rank sum.\nCAUTION Don’t confuse the Wilcoxon rank-sum test for two independent samples \nwith the Wilcoxon signed-ranks test for matched pairs. Use “Internal Revenue \nService” as the mnemonic for IRS to remind yourself of “Independent: Rank Sum.”\nDEFINITION\nThe Wilcoxon rank-sum test is a nonparametric test that uses ranks of sample \ndata from two independent populations to test this null hypothesis:\nH0: Two independent samples come from populations with equal medians.\n(The alternative hypothesis H1 can be any one of the following three possibilities: \nThe two populations have different medians, or the first population has a median \ngreater than the median of the second population, or the first population has a  \nmedian less than the median of the second population.)\nKey Concept This section describes the Wilcoxon rank-sum test, which uses ranks of \nvalues from two independent samples to test the null hypothesis that the samples are \nfrom populations having equal medians. The Wilcoxon rank-sum test is equivalent to \nthe Mann-Whitney U test (see Exercise 13), which is included in some textbooks \nand technologies (such as Minitab, StatCrunch, and XLSTAT).\nHere is the basic idea underlying the Wilcoxon rank-sum test: If two samples \nare drawn from identical populations and the individual values are all ranked as one \ncombined collection of values, then the high and low ranks should fall evenly between \nthe two samples. If the low ranks are found predominantly in one sample and the high \nranks are found predominantly in the other sample, we have an indication that the two \npopulations have different medians.\nUnlike the parametric t tests for two independent samples in Section 9-2, the \nWilcoxon rank-sum test does not require normally distributed populations and it can \nbe used with data at the ordinal level of measurement, such as data consisting of ranks. \nIn Table 13-1 we noted that the Wilcoxon rank-sum test has a 0.95 efficiency rating \nwhen compared to the parametric test. Because this test has such a high efficiency \nrating and involves easier calculations, it is often preferred over the parametric t test, \neven when the requirement of normality is satisfied.\n \n13-4\n \n Wilcoxon Rank-Sum Test for Two  \nIndependent Samples\n\n582 \nCHAPTER 13 Nonparametric Tests\nWilcoxon Rank-Sum Test\nObjective\nUse the Wilcoxon rank-sum test with samples from two independent populations for the following null and alternative \nhypotheses:\nH0: The two samples come from populations with equal medians.\nH1:  The median of the first population is different from (or greater than, or less than) the median from \nthe second population.\nNotation\n n1 = size of Sample 1\n n2 = size of Sample 2\n R1 = sum of ranks for Sample 1\n R2 = sum of ranks for Sample 2\n R = same as R1 (sum of ranks for Sample 1)\n mR =  mean of the sample R values that is expected when \nthe two populations have equal medians\n sR =  standard deviation of the sample R values that \nis expected with two populations having equal \nmedians\nRequirements\n1. There are two independent simple random samples.\n2. Each of the two samples has more than 10 values. (For \nsamples with 10 or fewer values, special tables are \navailable in reference books, such as CRC Standard \nProbability and Statistics Tables and Formulae, pub-\nlished by CRC Press.)\nNote: There is no requirement that the two populations \nhave a normal distribution or any other particular distri-\nbution.\nKEY ELEMENTS \nTest Statistic\nz = R - mR\nsR\n n1 = size of the sample from which the rank sum R is found\n n2 = size of the other sample\n R = sum of ranks of the sample with size n1\nP-Values\nP-values can be found from technology or by using the z test statistic and Table A-2.\nCritical Values\nCritical values can be found in Table A-2 (because the test statistic is based on the normal distribution).\nProcedure for Finding the Value of the Test Statistic To see how the following \nsteps are applied, refer to the sample data listed in Table 13-4.\nStep 1:  Temporarily combine the two samples into one big sample, then replace \neach sample value with its rank. (The lowest value gets a rank of 1, the next \nlowest value gets a rank of 2, and so on. If values are tied, assign to them the \nmean of the ranks involved in the tie. See Section 13-1 for a description of \nranks and the procedure for handling ties.)\n where mR = n11n1 + n2 + 12\n2\n  and sR = B\nn1n21n1 + n2 + 12\n12\n\n13-4 Wilcoxon Rank-Sum Test for Two Independent Samples  \n583\nEXAMPLE: In Table 13-4, the ranks of the 23 sample pulse rates are shown \nin parentheses. The rank of 1 is assigned to the lowest value of 54. The next \nlowest values are 56 and 56; because they are tied for the ranks of 2 and 3, \nwe assign the rank of 2.5 to each of them.\nStep 2: Find the sum of the ranks for either one of the two samples.\n \n EXAMPLE: In Table 13-4, the sum of the ranks from the first sample is \n123.5. (That is, R1 = 4.5 + 11 + 19 + g + 6 = 123.5.)\nStep 3:  Calculate the value of the z test statistic as shown in the preceding Key  \nElements box, where either sample can be used as “Sample 1.” (If both sam-\nple sizes are greater than 10, then the sampling distribution of R is approxi-\nmately normal with mean mR and standard deviation sR, and the test statistic \nis as shown in the preceding Key Elements box.)\n \n EXAMPLE: Calculations of mR and sR and z are shown in Example 1,  \nwhich follows.\nTABLE 13-4 Pulse Rates  \n(Ranks in parentheses)\nMales\nFemales\n60 (4.5)\n78 (14)\n74 (11)\n80 (17)\n86 (19)\n68 (9)\n54 (1)\n56 (2.5)\n90 (20.5)\n76 (12)\n80 (17)\n78 (14)\n66 (7)\n78 (14)\n68 (9)\n90 (20.5)\n68 (9)\n96 (22)\n56 (2.5)\n60 (4.5)\n80 (17)\n98 (23)\n62 (6)\nn1 = 12\nn2 = 11\nR1 = 123.5\nR2 = 152.5\nEXAMPLE 1  Pulse Rates of Males and Females\nTable 13-4 lists pulse rates of samples of males and females (from Data Set 1 “Body \nData” in Appendix B). Use a 0.05 significance level to test the claim that males and \nfemales have the same median pulse rate.\nSOLUTION\nREQUIREMENT CHECK (1) The sample data are two independent simple random \nsamples. (2) The sample sizes are 12 and 11, so both sample sizes are greater than \n10. The requirements are satisfied. \nThe null and alternative hypotheses are as follows:\nH0: The median pulse rate of males is equal to the median pulse rate of females.\nH1:  The median pulse rate of males is different from the median pulse  \nrate of females.\nRank the combined list of all 23 pulse rates, beginning with a rank of 1 (assigned to \nthe lowest value of 54). The ranks corresponding to the individual sample values are \nshown in parentheses in Table 13-4. R denotes the sum of the ranks for the sample \nwe choose as Sample 1. If we choose the pulse rates of males as Sample 1, we get\nR = 4.5 + 11 + 19 + g + 6 = 123.5\nBecause there are pulse rates from 12 males, we have n1 = 12. Also, n2 = 11 be-\ncause there are pulse rates from 11 females. We can now find the values of mR and \nsR and the test statistic z.\n mR = n11n1 + n2 + 12\n2\n= 12112 + 11 + 12\n2\n= 144\n sR = B\nn1n21n1 + n2 + 12\n12\n= B\n11221112112 + 11 + 12\n12\n= 16.248\n z = R - mR\nsR\n= 123.5 - 144\n16.248\n= -1.26\nThe test is two-tailed because a large positive value of z would indicate that dispro-\nportionately more higher ranks are found in Sample 1, and a large negative value of \nz would indicate that disproportionately more lower ranks are found in Sample 1. In \ncontinued\n\n584 \nCHAPTER 13 Nonparametric Tests\neither case, we would have strong evidence against the claim that the two samples \ncome from populations with equal medians.\nThe significance of the test statistic z can be treated as in previous chapters. \nWe are testing (with a = 0.05) the hypothesis that the two populations have equal \nmedians, so we have a two-tailed test with test statistic z = -1.26. The P-value is \n0.2077 and the critical values are z = {1.96. We fail to reject the null hypothesis \nthat the populations of males and females have the same median.\nINTERPRETATION\nThere is not sufficient evidence to warrant rejection of the claim that males and \nfemales have the same median pulse rate. Based on the sample data given in  \nTable 13-4, it appears that males and females have pulse rates with the same median.\nIn Example 1, if we interchange the two sets of sample values and consider the \npulse rates of females to be the first sample, then R = 152.5, mR = 132, sR = 16.248,\nand z = 1.26, so the conclusion is exactly the same.\nEXAMPLE 2  Pulse Rates of Males and Females \nExample 1 uses 23 pulse rates, but if we use the 300 pulse rates from Data Set 1 in \nAppendix B, we get the accompanying display. We can see that the test statistic is  \nz = 3.22 (rounded). The test statistic falls in the critical region bounded by the \ncritical values of -1.96 and 1.96. Also, the test statistic of z = 3.22 can be used to \nfind that the P-value in this two-tailed test is 0.0013. We reject the null hypothesis \nof equal medians. Based on the larger sample of 300 subjects, it does appear that \nfemales and males have different median pulse rates.\nStatdisk\nStatistical Literacy and Critical Thinking\n1. Birth Weights Listed below are birth weights (g) from Data Set 3 “Births” in Appendix B. \nIf we use these data for the Wilcoxon rank-sum test with a two-tailed test, what is the null hy-\npothesis?\nGirl\n3500\n 800\n2400 4200 3100 2000 2900\n3300\n2800 2500 4000 3100 3000 3400\nBoy\n3900\n2800 3700 4000 3400 1600 3500\n3900\n3000 3200 3300\n 300\n2. Rank Sum When applying the Wilcoxon rank-sum test, what is the sum of the ranks for the \nsample of birth weights of girls?\n3. Requirements Refer to the sample data in Exercise 1. Assuming that the samples are ran-\ndom, are the requirements for the Wilcoxon rank-sum test satisfied? Explain.\n4. Efficiency Refer to Table 13-1 in Section 13-1 on page 563 and identify the efficiency of the \nWilcoxon rank-sum test. What does that value tell us about the test?\n13-4 Basic Skills and Concepts \nWilcoxon Rank-Sum Test\nAccess tech instructions, videos, and data sets at www.TriolaStats.com\nTECH CENTER\n\n13-4 Wilcoxon Rank-Sum Test for Two Independent Samples  \n585\nWilcoxon Rank-Sum Test. In Exercises 5–8, use the Wilcoxon rank-sum test.\n5. Birth Weights Use the sample data given in Exercise 1 and test the claim that girls and boys \nhave the same median birth weight. Use a 0.05 significance level.\n6. Radiation in Baby Teeth Listed below are amounts of strontium-90 (in millibecquerels, or \nmBq, per gram of calcium) in a simple random sample of baby teeth obtained from Pennsylvania \nresidents and New York residents born after 1979 (based on data from “An Unexpected Rise in \nStrontium-90 in U.S. Deciduous Teeth in the 1990s,” by Mangano et al., Science of the Total \nEnvironment). Use a 0.05 significance level to test the claim that the median amount of stron-\ntium-90 from Pennsylvania residents is the same as the median from New York residents.\nPennsylvania\n155\n142\n149\n130\n151\n163\n151\n142\n156\n133\n138\n161\nNew York\n133\n140\n142\n131\n134\n129\n128\n140\n140\n140\n137\n143\n7. Clinical Trials of Lipitor The sample data below are changes in low-density lipoprotein (LDL) \ncholesterol levels in clinical trials of Lipitor (atorvastatin). It was claimed that Lipitor had an effect \non LDL cholesterol. (The data are based on results given in a Parke-Davis memo from David G. Orl-\noff, M.D., the medical team leader for clinical trials of Lipitor. Pfizer declined to provide the original \ndata values.) Negative values represent decreases in LDL cholesterol. Use a 0.05 significance level to \ntest the claim that for those treated with 20 mg of atorvastatin and those treated with 80 mg of atorv-\nastatin, changes in LDL cholesterol have the same median. What do the results suggest?\nGroup treated with 20 mg atorvastatin:\n-28\n-32\n-29\n-39\n-31\n-35\n-25\n-36\n-35\n-26\n-29\n-34\n-30\nGroup treated with 80 mg atorvastatin:\n-42\n-41\n-38\n-42\n-41\n-41\n-40\n-44\n-32\n-37\n-41\n-37\n-34\n-31\n8. Blanking Out on Tests In a study of students blanking out on tests, the arrangement of test \nitems was studied for its effect on anxiety. The following scores are measures of “debilitating test \nanxiety” (based on data from “Item Arrangement, Cognitive Entry Characteristics, Sex and Test \nAnxiety as Predictors of Achievement in Examination Performance,” by Klimko, Journal of Ex-\nperimental Education, Vol. 52, No. 4). Is there sufficient evidence to support the claim that the two \nsamples are from populations with different medians? Is there sufficient evidence to support the \nclaim that the arrangement of the test items has an effect on the score? Use a 0.01 significance level.\nQuestions Arranged from Easy to Difficult\nQuestions Arranged from Difficult to Easy\n24.64\n39.29\n16.32\n32.83\n28.02\n33.62\n34.02\n26.63\n30.26\n33.31\n20.60\n21.13\n26.69\n28.90\n35.91\n26.68\n29.49\n35.32\n26.43\n24.23\n7.10\n32.86\n21.06\n27.24\n32.34\n29.34\n33.53\n28.89\n28.71\n31.73\n30.02\n21.96\n27.62\n42.91\n30.20\n32.54\n25.49\n38.81\n27.85\n30.29\n30.72\nAppendix B Data Sets. In Exercises 9–12, refer to the indicated data set in Appendix B \nand use the Wilcoxon rank-sum test.\n9. Birth Weights Repeat Exercise 5 “Birth Weights” using all of the birth weights given in \nData Set 3 “Births” in Appendix B.\n10. Cigarettes Refer to Data Set 15 “Cigarette Contents” in Appendix B for the amounts of \nnicotine (mg per cigarette) in the sample of king-size cigarettes, which are nonfiltered, non-\nmenthol, and nonlight, and for the amounts of nicotine in the 100-mm cigarettes, which are fil-\ntered, nonmenthol, and nonlight. Use a 0.01 significance level to test the claim that the median \namount of nicotine in the nonfiltered king-size cigarettes is greater than the median amount of \nnicotine in the 100-mm filtered cigarettes.\n11. IQ and Lead Exposure Data Set 8 “IQ and Lead” in Appendix B lists full IQ scores for \na random sample of subjects with “medium” lead levels in their blood and another random \nsample of subjects with “high” lead levels in their blood. Use a 0.05 significance level to test \ncontinued\n\n586 \nCHAPTER 13 Nonparametric Tests\nthe claim that subjects with medium lead levels have a higher median of the full IQ scores than \nsubjects with high lead levels. Does lead level appear to affect full IQ scores?\n12. IQ and Lead Exposure Data Set 8 “IQ and Lead” in Appendix B lists performance  \nIQ scores for a random sample of subjects with low lead levels in their blood and another ran-\ndom sample of subjects with high lead levels in their blood. Use a 0.05 significance level to test \nthe claim that subjects with low lead levels have a higher median of the performance IQ score \nthan those with high lead levels. Does lead exposure appear to have an adverse effect?\n13. Using the Mann-Whitney U Test The Mann-Whitney U test is equivalent to the Wil-\ncoxon rank-sum test for independent samples in the sense that they both apply to the same \nsituations and always lead to the same conclusions. In the Mann-Whitney U test we calculate\nz =\nU - n1n2\n2\nB\nn1n21n1 + n2 + 12\n12\nwhere\nU = n1n2 +\nn11n1 + 12\n2\n- R\nand R is the sum of the ranks for Sample 1. Use the pulse rates in Table 13-4 on page 583 in this \nsection to find the z test statistic for the Mann-Whitney U test. Compare this value to the z test \nstatistic found using the Wilcoxon rank-sum test.\n14. Finding Critical Values Assume that we have two treatments (A and B) that produce \nquantitative results, and we have only two observations for treatment A and two observations \nfor treatment B. We cannot use the Wilcoxon signed ranks test given in this section because \nboth sample sizes do not exceed 10.\n \nRank\nRank Sum for \nTreatment A\n1\n2\n3\n4\nA\nA\nB\nB\n3\na. Complete the accompanying table by listing the five rows corresponding to the other five \npossible outcomes, and enter the corresponding rank sums for treatment A.\nb. List the possible values of R and their corresponding probabilities. [Assume that the rows of \nthe table from part (a) are equally likely.]\nc. Is it possible, at the 0.10 significance level, to reject the null hypothesis that there is no \ndifference between treatments A and B? Explain.\n13-4 Beyond the Basics \nKey Concept This section describes the Kruskal-Wallis test, which uses ranks of data \nfrom three or more independent simple random samples to test the null hypothesis \nthat the samples come from populations with the same median.\nSection 12-1 described one-way analysis of variance (ANOVA) as a method for \ntesting the null hypothesis that three or more populations have the same mean, but \n13-5 \nKruskal-Wallis Test for Three or More Samples\n\n13-5 Kruskal-Wallis Test for Three or More Samples \n587\nANOVA requires that all of the involved populations have normal distributions. The \nKruskal-Wallis test for equal medians does not require normal distributions, so it is a \ndistribution-free or nonparametric test.\nDEFINITION\nThe Kruskal-Wallis test (also called the H test) is a nonparametric test that uses ranks \nof combined simple random samples from three or more independent populations to \ntest the null hypothesis that the populations have the same median. (The alternative  \nhypothesis is the claim that the populations have medians that are not all equal.)\nKruskal-Wallis Test\nObjective\nUse the Kruskal-Wallis test with simple random samples from three or more independent populations for the following:\nH0: The samples come from populations with the same median.\nH1: The samples come from populations with medians that are not all equal.\nNotation\n N =  total number of observations in all samples  \ncombined\n k = number of different samples\n R1 = sum of ranks for Sample 1\nn1 =  number of observations in Sample 1\nFor Sample 2, the sum of ranks is R2 and the number of \nobservations is n2, and similar notation is used for the \nother samples.\nRequirements\n1. We have at least three independent samples.\n2. Each sample has at least five observations. (If samples \nhave fewer than five observations, refer to special tables \nof critical values.)\nNote: There is no requirement that the populations have \na normal distribution or any other particular distribution.\nKEY ELEMENTS \nTest Statistic\nH =\n12\nN 1N + 12 aR2\n1\nn1\n+ R2\n2\nn2\n+ g + R2\nk\nnk\nb - 31N + 12\nP-Values\nP-values are often provided by technology. By using the test statistic H and the number of degrees of freedom (k − 1), \nTable A-4 can be used to find a range of values for the P-value.\nCritical Values\n1. The test is right-tailed and critical values can be found \nfrom technology or from the chi-square distribution in \nTable A-4.\n2. df = k - 1 (where df is the number of degrees of  \nfreedom and k is the number of different samples)\n\n588 \nCHAPTER 13 Nonparametric Tests\nProcedure for Finding the Value of the H Test Statistic To see how the follow-\ning steps are applied, refer to the sample data listed in Table 13-5. Table 13-5 includes \nonly some of the data in Data Set 14 “Passive and Active Smoke” in Appendix B. This \nshortened data set is more suitable for illustrating the method of the Kruskal-Wallis test.\nStep 1:  Temporarily combine all samples into one big sample and assign a rank to \neach sample value. (Sort the values from lowest to highest, and in cases of \nties, assign to each observation the mean of the ranks involved.)\n \n EXAMPLE: In Table 13-5, the numbers in parentheses are the ranks of the com-\nbined data set. There are ten values of 0 tied for the lowest ranks of 1 through \n10, so each of them is assigned a rank of 5.5, which is the mean of the integers \nfrom 1 through 10. Next, there are two values of 1 tied for ranks 11 and 12, so \neach of them is assigned a rank of 11.5. The next lowest number is 19, which is \nassigned the next rank of 13, and so on.\nStep 2: For each sample, find the sum of the ranks and find the sample size.\n \n EXAMPLE: In Table 13-5, the sum of the ranks from the first sample is 65, the \nsum of the ranks for the second sample is 67.5, and the sum of the ranks for the \nthird sample is 38.5.\nStep 3:  Calculate H using the results of Step 2 and the notation and test statistic \ngiven in the preceding Key Elements box.\n \nEXAMPLE: The test statistic is computed in Example 1.\nTABLE 13-5 Cotinine Levels (Ranks in parentheses)\nSmokers\nETS\nNOETS\n1 (11.5)\n384 (18)\n0 (5.5)\n0 (5.5)\n0 (5.5)\n0 (5.5)\n131 (15)\n69 (14)\n0 (5.5)\n173 (16)\n19 (13)\n0 (5.5)\n265 (17)\n1 (11.5)\n0 (5.5)\n0 (5.5)\n0 (5.5)\n0 (5.5)\nn1 = 5\nn2 = 6\nn3 = 7\nR1 = 65\nR2 = 67.5\nR3 = 38.5\nIn applying the Kruskal-Wallis test, we compute the test statistic H, which has a dis-\ntribution that can be approximated by the chi-square distribution provided that each \nsample has at least five observations. (For a quick review of the key features of the \nchi-square distribution, see Section 7-3.)\nThe H test statistic measures the variance of the rank sums R1, R2, . . . , Rk from \nthe different samples. If the ranks are distributed evenly among the sample groups, \nthen H should be a relatively small number. If the samples are very different, then the \nranks will be excessively low in some groups and high in others, with the net effect \nthat H will be large. Consequently, only large values of H lead to rejection of the null \nhypothesis that the samples come from identical populations. The Kruskal-Wallis test \nis therefore a right-tailed test.\n\n13-5 Kruskal-Wallis Test for Three or More Samples \n589\nEXAMPLE 1  Effect of Second-Hand Smoke \nTable 13-5 lists some of the data from Data Set 14 “Passive and Active Smoke”  \nin Appendix B. Use a 0.05 significance level to test the claim that the three samples \nof cotinine levels come from populations with medians that are all equal.\nSOLUTION\nREQUIREMENT CHECK (1) Each of the three samples is a simple random independent \nsample. (2) Each sample size is at least 5. The requirements are satisfied. \nThe null and alternative hypotheses are as follows:\nH0:  The populations of smokers, nonsmokers exposed to tobacco smoke (ETS), \nand nonsmokers not exposed to tobacco smoke have cotinine levels with \nthe same median.\nH1:  The three populations have medians that are not all the same.\nTest Statistic First combine all of the sample data and rank them, then find the sum \nof the ranks for each category. In Table 13-5, ranks are shown in parentheses next \nto the original sample values. Next, find the sample size (n) and sum of ranks (R) \nfor each sample. Those values are shown at the bottom of Table 13-5. Because the \ntotal number of observations is 18, we have N = 18. We can now evaluate the test \nstatistic as follows:\n H =\n12\nN1N + 12 aR2\n1\nn1\n+ R2\n2\nn2\n+ g + R2\nk\nnk\nb - 31N + 12\n =\n12\n18118 + 12 a652\n5\n+ 67.52\n6\n+ 38.52\n7\nb - 3118 + 12\n = 6.724\nCritical Value Because each sample has at least five observations, the distribution \nof H is approximately a chi-square distribution with k - 1 degrees of freedom. The \nnumber of samples is k = 3, so we have 3 - 1 = 2 degrees of freedom. Refer to \nTable A-4 to find the critical value of 5.991, which corresponds to 2 degrees of free-\ndom and a 0.05 significance level (with an area of 0.05 in the right tail). Figure 13-4 \nshows that the test statistic H = 6.724 does fall within the critical region bounded \nby 5.991, so we reject the null hypothesis of equal population medians.\nFigure 13-4 shows the test statistic of H = 6.724 and the critical value of \n5.991. (The chi-square distribution has the general shape shown in Figure 13-4 \n0\nCritical value:\n5.991\nTest statistic:\nH 5 6.724\n0.05\nFIGURE 13-4 Chi-Square Distribution for Example 1\ncontinued\n\n590 \nCHAPTER 13 Nonparametric Tests\nwhenever the number of degrees of freedom is 1 or 2.) The test statistic does fall in \nthe critical region, so we reject the null hypothesis of equal medians.\nINTERPRETATION\nThere is sufficient evidence to reject the claim that the three samples of cotinine  \nlevels come from populations with medians that are all equal. The population  \nmedians do appear to be significantly different.\nRationale: The Kruskal-Wallis H test statistic is the rank version of the F test statis-\ntic used in analysis of variance discussed in Chapter 12. When we deal with ranks R \ninstead of original values x, many components are predetermined. For example, the \nsum of all ranks can be expressed as N1N + 12>2, where N is the total number of \nvalues in all samples combined. The expression\nH =\n12\nN1N + 12 Σni1Ri - R2 2\nwhere\nRi = Ri\nni  and  R = ΣRi\nΣni\ncombines weighted variances of ranks to produce the H test statistic given here, and \nthis expression for H is algebraically equivalent to the expression for H given earlier \nas the test statistic.\nStatistical Literacy and Critical Thinking\n1. Effect of Lead on IQ Score Listed below are full IQ scores from simple random samples of \nsubjects with low lead exposure, medium lead exposure, and high lead exposure (from Data Set 8 in \nAppendix B). In using the Kruskal-Wallis test, we must rank all of the data combined; then we must \nfind the sum of the ranks for each sample. Find the sum of the ranks for each of the three samples.\nLow Lead Level\nMedium Lead Level\nHigh Lead Level\n70\n72\n82\n85\n90\n93\n86\n92\n85\n76\n71\n75\n84\n86\n85\n79\n2. Requirements Assume that we want to use the data from Exercise 1 with the Kruskal-\nWallis test. Are the requirements satisfied? Explain.\n3. Notation For the data given in Exercise 1, identify the values of n1, n2, n3, and N.\n4. Efficiency Refer to Table 13-1 on page 563 and identify the efficiency of the Kruskal-Wallis \ntest. What does that value tell us about the test?\n13-5 Basic Skills and Concepts \nKruskal-Wallis Test\nAccess tech instructions, videos, and data sets at www.TriolaStats.com\nTECH CENTER\n\n13-5 Kruskal-Wallis Test for Three or More Samples \n591\nUsing the Kruskal-Wallis Test. In Exercises 5–8, use the Kruskal-Wallis test.\n5. Chest Injury in a Car Crash Use the following listed chest deceleration measurements (in \ng, where g is the force of gravity) from samples of small, midsize, and large cars. Use a 0.05 \nsignificance level to test the claim that the different size categories have the same median chest \ndeceleration in the standard crash test. Do the data suggest that larger cars are safer?\nSmall\n44\n39\n37\n54\n39\n44\n42\nMidsize\n36\n53\n43\n42\n52\n49\n41\nLarge\n32\n45\n41\n38\n37\n38\n33\n6. Femur Injury in a Car Crash Listed below are measured loads (in lb) on the left femur of \ncrash test dummies. Use a 0.05 significance level to test the null hypothesis that the different \ncar categories have the same median. Do these data suggest that larger cars are safer?\nSmall Cars\n548\n782\n1188\n 707\n324\n320\n634\n501\n274\n437\nMedium Cars\n194\n280\n1076\n 411\n617\n133\n719\n656\n874\n445\nLarge Cars\n215\n937\n 953\n1636\n937\n472\n882\n562\n656\n433\n7. Arsenic in Rice Listed below are amounts of arsenic in samples of brown rice from three \ndifferent states. The amounts are in micrograms of arsenic and all samples have the same serv-\ning size. The data are from the Food and Drug Administration. Use a 0.01 significance level to \ntest the claim that the three samples are from populations with the same median.\nArkansas\n4.8\n4.9\n5.0\n5.4\n5.4\n5.4\n5.6\n5.6\n5.6\n5.9\n6.0\n6.1\nCalifornia\n1.5\n3.7\n4.0\n4.5\n4.9\n5.1\n5.3\n5.4\n5.4\n5.5\n5.6\n5.6\nTexas\n5.6\n5.8\n6.6\n6.9\n6.9\n6.9\n7.1\n7.3\n7.5\n7.6\n7.7\n7.7\n8. Triathlon Times Jeff Parent is a statistics instructor who participates in triathlons. Listed be-\nlow are times (in minutes and seconds) he recorded while riding a bicycle for five laps through \neach mile of a 3-mile loop. Use a 0.05 significance level to test the claim that the samples are \nfrom populations with the same median. What do the data suggest?\nMile 1\n3:15\n3:24\n3:23\n3:22\n3:21\nMile 2\n3:19\n3:22\n3:21\n3:17\n3:19\nMile 3\n3:34\n3:31\n3:29\n3:31\n3:29\nAppendix B Data Sets. In Exercises 9–12, use the Kruskal-Wallis test with the data set  \nin Appendix B.\n9. Passive and Active Smoke Data Set 14 “Passive and Active Smoke” in Appendix B lists \nmeasured cotinine levels from a sample of subjects who smoke, another sample of subjects \nwho do not smoke but are exposed to environmental tobacco smoke, and a third sample of sub-\njects who do not smoke and are not exposed to environmental tobacco smoke. Cotinine is pro-\nduced when the body absorbs nicotine. Use a 0.01 significance level to test the claim that the \nthree samples are from populations with the same median. What do the results suggest about a \nsmoker who argues that he absorbs as much nicotine as people who don’t smoke?\n10. IQ and Lead Exposure Refer to Data Set 8 “IQ and Lead” and use the measured perfor-\nmance IQ scores from the three different blood lead levels. Use a 0.05 significance level to test the \nclaim that the three categories of blood lead level have the same median performance IQ score.\n11. Nicotine in Cigarettes Refer to Data Set 15 “Cigarette Contents” in Appendix B and \nuse the amounts of nicotine (mg per cigarette) in the king-size cigarettes, the 100-mm men-\nthol cigarettes, and the 100-mm nonmenthol cigarettes. The king-size cigarettes are nonfil-\ntered, nonmenthol, and nonlight. The 100-mm menthol cigarettes are filtered and nonlight. The \n100-mm nonmenthol cigarettes are filtered and nonlight. Use a 0.05 significance level to test the \nclaim that the three categories of cigarettes yield the same median amount of nicotine. Given that \nonly the king-size cigarettes are not filtered, do the filters appear to make a difference?\n\n592 \nCHAPTER 13 Nonparametric Tests\n12. Tar in Cigarettes Refer to Data Set 15 “Cigarette Contents” in Appendix B and use the \namounts of tar (mg per cigarette) in the three categories of cigarettes described in Exercise 11. \nUse a 0.05 significance level to test the claim that the three categories of cigarettes yield the \nsame median amount of tar. Given that only the king-size cigarettes are not filtered, do the fil-\nters appear to make a difference?\n13-5 Beyond the Basics \n13. Correcting the H Test Statistic for Ties In using the Kruskal-Wallis test, there is a cor-\nrection factor that should be applied whenever there are many ties: Divide H by\n1 -\nΣT\nN3 - N\nFirst combine all of the sample data into one list, and then in that combined list, identify the \ndifferent groups of sample values that are tied. For each individual group of tied observations, \nidentify the number of sample values that are tied and designate that number as t, then calculate \nT = t3 - t. Next, add the T values to get ΣT. The value of N is the total number of observa-\ntions in all samples combined. Use this procedure to find the corrected value of H for Example 1 \nin this section on page 589. Does the corrected value of H differ substantially from the value \nfound in Example 1?\nKey Concept This section describes the nonparametric method of the rank correla-\ntion test, which uses ranks of paired data to test for an association between two vari-\nables. In Section 10-1, paired sample data were used to compute values for the linear \ncorrelation coefficient r, but in this section we use ranks as the basis for computing \nthe rank correlation coefficient rs. As in Chapter 10, we should begin an analysis of \npaired data by exploring with a scatterplot so that we can identify any patterns in the \ndata as well as outliers.\n13-6 \nRank Correlation\nDEFINITION\nThe rank correlation test (or Spearman’s rank correlation test) is a nonparametric \ntest that uses ranks of sample data consisting of matched pairs. It is used to test \nfor an association between two variables.\nWe use the notation rs for the rank correlation coefficient so that we don’t con-\nfuse it with the linear correlation coefficient r. The subscript s does not refer to a \nstandard deviation; it is used in honor of Charles Spearman (1863–1945), who origi-\nnated the rank correlation approach. In fact, rs is often called Spearman’s rank \ncorrelation coefficient. Key components of the rank correlation test are given in the \nfollowing Key Elements box, and the rank correlation procedure is summarized in \nFigure 13-5 on page 594.\n\n13-6 Rank Correlation \n593\nRank Correlation\nObjective\nCompute the rank correlation coefficient rs and use it to \ntest for an association between two variables. The null and \nalternative hypotheses are as follows:\nH0: rs = 0 (There is no correlation.)\nH1: rs ≠0 (There is a correlation.)\nNotation\nrs =  rank correlation coefficient for sample paired data \n(rs is a sample statistic)\nrs =  rank correlation coefficient for all the population \ndata (rs is a population parameter)\nn = number of pairs of sample data\nd =  difference between ranks for the two values within an \nindividual pair\nRequirements\n1. The paired data are a simple random sample.\n2. The data are ranks or can be converted to ranks.\nNote: Unlike the parametric methods of Section 10-1, \nthere is no requirement that the sample pairs of data have a \nbivariate normal distribution (as described in Section 10-1). \nThere is no requirement of a normal distribution for any \npopulation.\nTest Statistic\nWithin each sample, first convert the data to ranks, then \nfind the exact value of the rank correlation coefficient rs by \nusing Formula 10-1:\nKEY ELEMENTS \nFORMULA 10-1\nrs =\nn1Σxy2 - 1Σx21Σy2\n2n1Σx22 - 1Σx2 22n1Σy22 - 1Σy2 2\nFORMULA 13-1\nrs =\n{z\n2n - 1\n 1critical values for n 7 302\nSimpler Test Statistic if There Are No Ties: After con-\nverting the data in each sample to ranks, if there are no \nties among ranks for the first variable and there are no ties \namong ranks for the second variable, the exact value of the \ntest statistic can be calculated using Formula 10-1 or with \nthe following relatively simple formula, but it is probably \neasier to use Formula 10-1 with technology:\nrs = 1 -\n6Σd2\nn1n2 - 12\nP-Values\nP-values are sometimes provided by technology, but use them only if they result from Spearman’s rank correlation. (Do \nnot use P-values resulting from tests of linear correlation; see the “caution” on the top of page 595.)\nCritical Values\n1. If n … 30, critical values are found in Table A-9.\nwhere the value of z corresponds to the significance level. \n(For example, if a = 0.05, z = 1.96.)\n2. If n 7 30, critical values of rs are found  \nusing Formula 13-1.\n\n594 \nCHAPTER 13 Nonparametric Tests\nYes\nYes\nNo\nYes\nNo\nNo\nStart\nDoes either variable\nhave ties among \nits ranks?\nCalculate rs using  Formula 10-1 with\nthe ranks:\nrs 5\nnΣxy – (Σx) (Σy) \nÏn(Σx2) – (Σx)2 Ïn(Σy2) – (Σy)2\nFind the negative and\npositive  critical values\nof rs from  Table A-9.\nCalculate the diﬀerence d for each pair \nof ranks by subtracting the lower rank\nfrom the higher rank.\nSquare each diﬀerence d and then ﬁnd \nthe sum of those squares to get Σ(d2).\n• If rs is between the negative and positive critical values, fail to reject the null\n \nhypothesis rs 5 0 (no correlation).\n• If rs is not between the negative and positive critical values, reject the null hypothesis\n rs 5 0 and conclude that there is suﬃcient evidence to support a claim of a correlation.\nAre the n pairs of\ndata in the form of \nranks?\nCalculate the\ncritical values\nwhere z\ncorresponds\nto the\nsigniﬁcance level.\nIs n ◊ 30?\nComplete the computation of\nto get the test statistic.\nrs 5 1 2\n6Σd 2\nn(n2 – 1)\nrs 5 6\nÏn  – 1\nz\nConvert the data of the ﬁrst sample to \nranks from 1 to n and then do the same \nfor the second sample.\nFIGURE 13-5 Rank Correlation Procedure for Testing H0: Rs = 0\n\n13-6 Rank Correlation \n595\nAdvantages of Rank Correlation Rank correlation has these advantages over the \nparametric methods discussed in Chapter 10:\n1. Rank correlation can be used with paired data that are ranks or can be converted \nto ranks. Unlike the parametric methods of Chapter 10, the method of rank  \ncorrelation does not require a normal distribution for any population.\n2. Rank correlation can be used to detect some (not all) relationships that are \nnot linear.\nDisadvantage of Rank Correlation: Efficiency A minor disadvantage of rank \ncorrelation is its efficiency rating of 0.91, as described in Section 13-1. This efficiency \nrating shows that with all other circumstances being the same, the nonparametric ap-\nproach of rank correlation requires 100 pairs of sample data to achieve the same results \nas only 91 pairs of sample observations analyzed through the parametric approach, \nassuming that the stricter requirements of the parametric approach are met.\nCAUTION Do not use P-values from linear correlation for methods of  rank \ncorrelation. When working with data having ties among ranks, the rank correlation \ncoefficient rs can be calculated using Formula 10-1. Technology can be used \ninstead of manual calculations with Formula 10-1, but the displayed P-values from \nlinear correlation do not apply to the methods of rank correlation.\nEXAMPLE 1  Bacteria Growth\nAn experiment involves a growing population of bacteria. Table 13-6 lists randomly \nselected times (in hr) after the experiment is begun and the number of bacteria \npresent. Use a 0.05 significance level to test the claim that there is a correlation  \nbetween time and population size.\nSOLUTION\nREQUIREMENT CHECK The data are a simple random sample and can be converted  \nto ranks. \nThe null and alternative hypotheses are as follows:\nH0\n :  rs = 0 1no correlation2\nH1\n :  rs ≠0 1correlation2\nWe follow the rank correlation procedure summarized in Figure 13-5. The original \nvalues are not ranks, so we convert them to ranks and enter the results in Table 13-7. \n(Section 13-1 describes the procedure for converting scores into ranks.) \ncontinued\nDirect Link Between \nSmoking and Cancer\nWhen we find a \nstatistical cor-\nrelation between \ntwo variables, \nwe must be \nextremely \ncareful to avoid \nthe mistake of concluding that \nthere is a cause-effect link. The \ntobacco industry has consistently \nemphasized that correlation \ndoes not imply causality as they \ndenied that tobacco products \ncause cancer. However, Dr. David \nSidransky of Johns Hopkins \nUniversity and other researchers \nfound a direct physical link that \ninvolves mutations of a specific \ngene among smokers. Molecu-\nlar analysis of genetic changes \nallows researchers to determine \nwhether cigarette smoking is the \ncause of a cancer. (See “Associa-\ntion Between Cigarette Smoking \nand Mutation of the p53 Gene in \nSquamous-Cell Carcinoma of the \nHead and Neck,” by Brennan, \nBoyle, et al., New England  \nJournal of Medicine, Vol 332,  \nNo. 11.) Although statistical \nmethods cannot prove that \nsmoking causes cancer, statisti-\ncal methods can be used to iden-\ntify an association, and physical \nproof of causation can then be \nsought by researchers.\nTABLE 13-6 Number of Bacteria in a Growing Population\nTime (hours)\n6\n107\n109\n125\n126\n128\n133\n143\n177\n606\nPopulation Size\n2\n  3\n  4\n 10\n 16\n 29\n 35\n 38\n 41\n 45\nTABLE 13-7 Ranks from Table 13-6\nRanks of Times\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\nRanks of Populations\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\nDifference d\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\nd2\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n596 \nCHAPTER 13 Nonparametric Tests\nThere are no ties among the ranks for the times, nor are there ties among the ranks for \npopulation size, so we find the differences, d, then square them. Next we find the sum \nof the d2 values, which is 0 in this case. We now calculate the value of the test statistic:\n rs = 1 -\n6Σd2\nn1n2 - 12 = 1 -\n6102\n101102 - 12\n = 1 -\n0\n990 = 1\nWith n = 10, we use Table A-9 to get the critical values of {0.648. Finally, the \ntest statistic of rs = 1 is not between -0.648 and 0.648, so we reject the null \nhypothesis of rs = 0. There is sufficient evidence to support the claim that for bac-\nteria, there is a correlation between time and population size.\nDetecting a Nonlinear Pattern In Example 1, if we test for a linear correlation using \nthe methods of Section 10-1, we get a test statistic of r = 0.621 and critical values of \n-0.632 and 0.632, so we conclude that there is not sufficient evidence to support a claim \nof a linear correlation between time and population size. If we examine the accompanying \nscatterplot, we can see that the pattern of points is not a straight-line pattern. Example 1 \nillustrates this advantage of the nonparametric approach over the parametric approach:\nWith rank correlation, we can sometimes detect relationships that are \nnot linear.\nNonlinear Pattern\nEXAMPLE 2  Large Sample Case \nRefer to the measured systolic and diastolic blood pressure measurements of 147 \nrandomly selected females in Data Set 1 “Body Data” in Appendix B and use a 0.05 \nsignificance level to test the claim that among women, there is a correlation between \nsystolic blood pressure and diastolic blood pressure.\nSOLUTION\nREQUIREMENT CHECK The data are a simple random sample and can be converted to \nranks. \nTest Statistic The value of the rank correlation coefficient is rs = 0.354, which can \nbe found by using technology.\nCritical Values Because there are 147 pairs of data, we have n = 147. Because \nn exceeds 30, we find the critical values from Formula 13-1 instead of Table A-9. \nWith a = 0.05 in two tails, we let z = 1.96 to get the critical values of -0.162 and \n0.162, as shown below.\nrs =\n{z\n2n - 1\n=\n{1.96\n2147 - 1\n= {0.162\nThe test statistic of rs = 0.354 is not between the critical values of -0.162 and \n0.162, so we reject the null hypothesis of rs = 0. There is sufficient evidence to \nsupport the claim that among women, there is a correlation between systolic blood \npressure and diastolic blood pressure.\nRank Correlation\nAccess tech instructions, videos, and data sets at www.TriolaStats.com\nTECH CENTER\n\n13-6 Rank Correlation \n597\nStatistical Literacy and Critical Thinking\n1. Regression If the methods of this section are used with paired sample data, and the conclu-\nsion is that there is sufficient evidence to support the claim of a correlation between the two \nvariables, can we use the methods of Section 10-2 to find the regression equation that can be \nused for predictions? Why or why not?\n2. Level of Measurement Which of the levels of measurement (nominal, ordinal, interval, \nratio) describe data that cannot be used with the methods of rank correlation? Explain.\n3. Notation What do r, rs, r, and rs denote? Why is the subscript s used? Does the subscript s \nrepresent the same standard deviation s introduced in Section 3-2?\n4. Efficiency Refer to Table 13-1 on page 563 and identify the efficiency of the rank correla-\ntion test. What does that value tell us about the test?\nIn Exercises 5 and 6, use the scatterplot to find the value of the rank correlation coefficient \nrs and the critical values corresponding to a 0.05 significance level used to test the null  \nhypothesis of Rs = 0. Determine whether there is a correlation.\n13-6  Basic Skills and Concepts \n5. Ages and Heights of Trees \n6. Numbers of Waiting Patients and Patient Service Times\nTesting for Rank Correlation. In Exercises 7–10, use the rank correlation coefficient to \ntest for a correlation between the two variables. Use a significance level of A = 0.05.\n7. Crickets and Temperature The association between the temperature and the number of \ntimes a cricket chirps in 1 min was studied. Listed below are the numbers of chirps in 1 min \nand the corresponding temperatures in degrees Fahrenheit (based on data from The Song of \nInsects by George W. Pierce, Harvard University Press). Is there sufficient evidence to con-\nclude that there is a relationship between the number of chirps in 1 min and the temperature?\nChirps in 1 min\n 882\n1188\n1104\n 864\n1200\n1032\n 960\n 900\nTemperature (°F)\n69.7\n 93.3\n 84.3\n76.3\n 88.6\n 82.6\n71.6\n79.6\n8. Measuring Seals from Photos Listed below are the overhead widths (in cm) of seals \nmeasured from photographs and the weights of the seals (in kg). The data are based on \n“Mass Estimation of Weddell Seals Using Techniques of Photogrammetry,” by R. Garrott of \nMontana State University. The purpose of the study was to determine if weights of seals could \nbe determined from overhead photographs. Is there sufficient evidence to conclude that there is \na correlation between overhead widths of seals from photographs and the weights of the seals?\nOverhead Width (cm)\n 7.2\n 7.4\n 9.8\n 9.4\n 8.8\n 8.4\nWeight (kg)\n116\n154\n245\n202\n200\n191\n\n598 \nCHAPTER 13 Nonparametric Tests\n9. Smoking and Nicotine When nicotine is absorbed by the body, cotinine is produced. \nA measurement of cotinine in the body is therefore a good indicator of how much a person \nsmokes. Listed below are the reported numbers of cigarettes smoked per day and the measured \namounts of nicotine (in ng>ml). (The values are from randomly selected subjects in the Na-\ntional Health Examination Survey.) Is there a significant linear correlation? Explain the result.\nx (cigarettes, day)\n 60\n 10\n   4\n 15\n 10\n   1\n 20\n   8\n   7\n  10\n 10\n 20\ny (cotinine)\n179\n283\n75.6\n174\n209\n9.51\n350\n1.85\n43.4\n25.1\n408\n344\n10. Tree Circumference and Height Listed below are the circumferences (in feet) and the \nheights (in feet) of trees in Marshall, Minnesota (based on data from “Tree Measurements,” by \nStanley Rice, American Biology Teacher, Vol. 61, No. 9). Is there a correlation?\nx (circ.)\n 1.8\n 1.9\n 1.8\n 2.4\n 5.1\n 3.1\n 5.5\n 5.1\n 8.3\n13.7\n 5.3\n 4.9\n 3.7\n 3.8\ny (ht.)\n21.0\n33.5\n24.6\n40.7\n73.2\n24.9\n40.4\n45.3\n53.5\n93.8\n64.0\n62.7\n47.2\n44.3\nAppendix B Data Sets. In Exercises 11–14, use the data in Appendix B to test for rank \ncorrelation with a 0.05 significance level.\n11. Blood Pressure Refer to the measured systolic and diastolic blood pressure measure-\nments of 153 randomly selected males in Data Set 1 “Body Data” in Appendix B and use a \n0.05 significance level to test the claim that among men, there is a correlation between systolic \nblood pressure and diastolic blood pressure.\n12. IQ and Brain Volume Refer to Data Set 9 “IQ and Brain Size” in Appendix B and test for \na correlation between brain volume (cm3) and IQ score.\n13. Chest Sizes and Weights of Bears Refer to Data Set 11 “Bear Measurements” in \nAppendix B and test for a correlation between chest sizes and weights of bears.\n14. Head Lengths and Neck Sizes of Bears Refer to Data Set 11 “Bear Measurements” in \nAppendix B and test for a correlation between head lengths and neck sizes of bears.\n15. Finding Critical Values An alternative to using Table A–9 to find critical values for rank \ncorrelation is to compute them using this approximation:\nrs = {B\nt2\nt2 + n - 2\nHere, t is the critical t value from Table A-3 corresponding to the desired significance level and \nn - 2 degrees of freedom. Use this approximation to find critical values of rs for Exercise 11 \n“Blood Pressure.” How do the resulting critical values compare to the critical values that would \nbe found by using Formula 13-1 on page 593?\n13-6 Beyond the Basics \n1. Cell Phone Radiation Some of the nonparametric methods in this chapter use ranks of \ndata. Find the ranks corresponding to these measured cell phone radiation absorption rates \n(in W>kg): 1.18, 1.41, 1.49, 1.04, 1.45, 0.74, 0.89, 1.42, 1.45, 0.51, 1.38.\n2. Efficiency What does it mean when we say that the rank correlation test has an efficiency \nrating of 0.91 when compared to the parametric test for linear correlation?\nChapter Quick Quiz\n\n3. Nonparametric Tests\na. Which of the following terms is sometimes used instead of “nonparametric test”: normality \ntest; abnormality test; distribution-free test; last testament; test of patience?\nb. Why is the term that is the answer to part (a) better than “nonparametric test”?\n4. Foot Length, Height Listed below are foot lengths (cm) and heights (cm) of males from \nData Set 7 “Foot and Height” in Appendix B. Which method of nonparametric statistics should \nbe used? What characteristic of the data is investigated with this test?\nFoot Length\n 27.8\n 25.7\n 26.7\n 25.9\n 26.4\n 29.2\n 26.8\n 28.1\n 25.4\n 27.9\nHeight\n180.3\n175.3\n184.8\n177.8\n182.3\n185.4\n180.3\n175.3\n177.8\n185.4\n5. Foot Length, Height When analyzing the paired data in Exercise 4, are the P-values and \nconclusions from the nonparametric test and the parametric test always the same?\n6. Foot Length, Height For the sample data given in Exercise 4, identify at least one advan-\ntage of using the appropriate nonparametric test over the parametric test.\n7. Sign Test and Wilcoxon Signed-Ranks Test What is a major advantage of the Wilcoxon \nsigned-ranks test over the sign test when analyzing data consisting of matched pairs?\n8. Which Test? Three different physicians each rank the quality of 10 different medical stu-\ndent diagnoses. What method of this chapter can be used to test for agreement among the three \nphysicians?\n9. Which Test? Given the following configurations of sample data, identify the one that can \nbe used with the Wilcoxon rank-sum test: one sample of individual values; two independent \nsamples; four independent samples; matched pairs.\n10.  Which Test? Given the following configurations of sample data, identify the one that \ncan be used with the Wilcoxon signed-ranks test: two independent samples; four independent \nsamples; matched pairs.\nUsing Nonparametric Tests. In Exercises 1–8, use a 0.05 significance level with the  \nindicated test. If no particular test is specified, use the appropriate nonparametric test from \nthis chapter.\n1. Internet or Doctor In a survey of 2015 adults, 1108 said that they obtain medical informa-\ntion more often from the Internet than a doctor (based on a Merck survey). Test the claim that \nthe majority of adults obtain medical information more often from the Internet than a doctor.\n2. Patient Wait Times In a study of times (min) patients wait before checking in for a physi-\ncal, the following random sample of times was collected. Use the sign test to test the claim that \nthe sample is from a population with a median equal to 5 min. Use a 0.05 significance level.\n5 8 3 8 6 10 3 7 9 8 5 5 6 8 8 7 3 5 5 6 8 7 8 8 8 7\n3. Patient Wait Times Repeat the preceding exercise using the Wilcoxon signed-ranks test.\n4. Longevity of Presidents, Popes, Monarchs Listed on the top of the next page are num-\nbers of years that U.S. presidents, popes, and British monarchs lived after their inauguration, \nelection, or coronation, respectively. Assume that the data are samples randomly selected from \nlarger populations. Test the claim that the three samples are from populations with the same \nmedian.\nReview Exercises\nCHAPTER 13 Review Exercises \n599\n\n600 \nCHAPTER 13 Nonparametric Tests\nPresidents\n10\n29\n26\n28\n15\n23\n17\n25\n 0\n20\n 4\n 1\n24\n16\n12\n 4\n10\n17\n16\n 0\n 7\n24\n12\n 4\n18\n21\n11\n 2\n 9\n36\nPopes\n12\n28\n 3\n16\n 9\n25\n23\n32\n 2\n 9\n21\n 3\n 6\n10\n18\n11\n 6\n25\n23\n 6\n 2\n15\n32\n25\n11\n 8\n17\n19\n 5\n15\n 0\n26\nMonarchs\n17\n 6\n13\n12\n13\n33\n59\n10\n 7\n63\n 9\n25\n36\n15\n5. Chocolate Diet for a Nobel Prize The table below lists chocolate consumption (kg per \ncapita) and the numbers of Nobel Laureates (per 10 million people) for several different coun-\ntries. Is there a correlation between chocolate consumption and the rate of Nobel Laureates? \nHow could such a correlation be explained?\nChocolate\n11.6\n2.5\n 8.8\n3.7\n1.8\n 4.5\n 9.4\n3.6\n2.0\n3.6\n 6.4\nNobel\n12.7\n1.9\n12.7\n3.3\n1.5\n11.4\n25.5\n3.1\n1.9\n1.7\n31.9\n6. Skull Breadths and Archeology Listed below are skull breadths obtained from skulls of \nEgyptian males from three different epochs (based on data from Ancient Races of the Thebaid, \nby Thomson and Randall-Maciver). Test the claim that the samples are from populations with \nthe same median. Changes in head shape over time suggest that interbreeding occurred with \nimmigrant populations. Is interbreeding of cultures suggested by the data?\n4000 B.C.\n125\n129\n131\n132\n132\n134\n135\n138\n138\n1850 B.C.\n129\n129\n134\n134\n136\n137\n137\n138\n136\nA.D. 150\n128\n136\n137\n137\n138\n139\n141\n142\n145\n7. Skull Breadths and Archeology Refer to the preceding exercise and use only the skull \nbreadths from 4000 B.C. and A.D. 150. Use the Wilcoxon rank-sum test to test the claim that \nthe two samples are from populations with the same median.\n8. Student and U.S. News & World Report Rankings of Colleges Each year, U.S. News \n& World Report publishes rankings of colleges based on statistics such as admission rates, \ngraduation rates, class size, faculty–student ratio, faculty salaries, and peer ratings of adminis-\ntrators. Economists Christopher Avery, Mark Glickman, Caroline Minter Hoxby, and Andrew \nMetrick took an alternative approach of analyzing the college choices of 3240 high-achieving \nschool seniors. They examined the colleges that offered admission along with the colleges that \nthe students chose to attend. The table below lists rankings for a small sample of colleges. Find \nthe value of the rank correlation coefficient and use it to determine whether there is a correla-\ntion between the student rankings and the rankings of the magazine.\nStudent ranks\n1\n2\n3\n4\n5\n6\n7\n8\nU.S. News & World Report ranks\n1\n2\n5\n4\n7\n6\n3\n8\nIn Exercises 1–5, use the data listed below. The values are the numbers of credit hours taken \nin the current semester by full-time biostatistics students. The data are from students in one \nclass of one of the authors.\n15 15 13 16 12 15 18 16 15 14 16 15 17 12 15 15 14 14 12 12\n1. Descriptive Statistics Find the mean, median, standard deviation, variance, and range of the \nsample data. Given that the data are in credit hours, include the appropriate units in the results.\n2. Sampling and Data Type\na. Which of the following best describes the sample: simple random sample, voluntary re-\nsponse sample, convenience sample?\nCumulative Review Exercises\n\nb. Is it likely that the sample is representative of the population of all full-time college students?\nc. Are the data discrete or continuous?\nd. What is the level of measurement of the data (nominal, ordinal, interval, ratio)?\n3. Credit Hours: Hypothesis Test Use the given data to test the claim that the sample is from \na population with a mean greater than 14 credit hours.\n4. Credit Hours: Sign Test Use the given data to test the claim that the sample is from a popu-\nlation with a median greater than 14 credit hours. Use the sign test with a 0.05 significance level.\n5. Credit Hours: Confidence Interval Use the data to construct a 95% confidence interval \nestimate of the number of credit hours taken by the population of full-time students. Write a \nbrief statement that interprets the result.\n6. Drug Tests There is a 3.9% rate of positive drug test results among workers in the United \nStates (based on data from Quest Diagnostics). Assuming that this statistic is based on a sample \nof size 2000, construct a 95% confidence interval estimate of the percentage of positive drug \ntest results. Write a brief statement that interprets the confidence interval.\n7. Drug Tests Use the data from the preceding exercise and test the claim that the rate of \npositive drug test results among workers in the United States is greater than 3.0%. Use a 0.05 \nsignificance level.\n8. Sample Size Advances in technology are dramatically affecting different aspects of our \nlives. Many people now use the Internet for medical advice before seeing a physician. To help \naddress such issues, we want to estimate the percentage of adults in the United States who use \na computer at least once each day. Find the sample size needed to estimate that percentage. As-\nsume that we want 95% confidence that the sample percentage is within two percentage points \nof the true population percentage.\n9. Fear of Heights Among readers of a USA Today website, 285 chose to respond to this \nposted question: “Are you afraid of heights in tall buildings?” Among those who chose to re-\nspond, 46% answered “yes” and 54% answered “no.” Use a 0.05 significance level to test the \nclaim that the majority of the population is not afraid of heights in tall buildings. What is wrong \nwith this hypothesis test?\n10.  Cell Phones and Crashes: Analyzing Newspaper Report In an article from the \nAssociated Press, it was reported that researchers “randomly selected 100 New York motorists \nwho had been in an accident and 100 who had not been in an accident. Of those in accidents, \n13.7 percent owned a cellular phone, while just 10.6 percent of the accident-free drivers had a \nphone in the car.” What is wrong with these results?\nMethods of gender selection can be tested in experiments that involve the treatment of parents \nand the subsequent analysis of generated offspring. Instead of actually generating offspring, \nwe will use technology to simulate their generation. Use SPSS, SAS, Statdisk, Minitab, Excel, \na TI–83>84 Plus calculator, or any other technology to randomly generate 1000 values, each \nof which is 0 or 1. (Refer to the Chapter 4 Technology Project on pages 177–178 for the sum-\nmary of simulation functions.) Representing boys by 1 and girls by 0, we have a simulated \nsample of 1000 offspring. We can then use the sign test to determine whether boys and girls are \nequally likely. In this case, we are actually testing the technology for a bias in favor of either 0s \nor 1s. Generate the 1000 values, then use the sign test to analyze the results. Does the technol-\nogy appear to have a bias? Could you detect a bias using larger sample sizes?\nTechnology Project\nCHAPTER 13 Technology Project \n601\n\n602 \nCHAPTER 13 Nonparametric Tests\nFROM DATA TO DECISION\nCritical Thinking: Does geographic location affect \nbirth weights?\nData Set 3 “Births” in Appendix B lists birth weights from \nfour different hospitals with very different geographic loca-\ntions in New York State. We want to investigate an effect of \ngeographic location on birth weights.\nAnalysis\n• Which nonparametric test applies?\n• Identify the requirements for the appropriate nonparametric \ntest and determine if they are satisfied.\n• Apply the test and state conclusions.\nCooperative Group Activities\n1. In-class activity Divide into groups of 8 to 12 people. For each group member, measure his \nor her height and measure his or her arm span. For the arm span, the subject should stand with \narms extended, like the wings on an airplane. Divide the following tasks among subgroups of \nthree or four people.\na. Use rank correlation with the paired sample data to determine whether there is a correlation \nbetween height and arm span.\nb. Use the sign test to test for a difference between the two variables.\nc. Use the Wilcoxon signed-ranks test to test for a difference between the two variables.\n2. In-class activity Do Activity 1 using pulse rate instead of arm span. Measure pulse rates by \ncounting the number of heartbeats in 1 minute.\n3. Out-of-class activity Divide into groups of three or four students. Investigate the relation-\nship between two variables by collecting your own paired sample data and using the methods \nof Section 13-6 to determine whether there is a correlation. Suggested topics:\n• Is there a correlation between the lengths of men’s (or women’s) feet and their heights?\n• Is there a correlation between heights of fathers (or mothers) and heights of their first sons \n(or daughters)?\n4. Out-of-class activity Divide into groups of three or four. Survey other students by asking \nthem to identify their major and gender. For each surveyed subject, determine the number of \nTwitter followers or Facebook friends. Use the sample data to address these questions:\n• Do the numbers of Twitter followers or Facebook friends appear to be the same for both genders?\n• Do the numbers of Twitter followers or Facebook friends appear to be the same for the differ-\nent majors?\n5. In-class activity Divide into groups of 8 to 12 people. For each group member, measure \nthe person’s height and also measure his or her navel height, which is the height from the floor \nto the navel. Use the rank correlation coefficient to determine whether there is a correlation \nbetween height and navel height.\n6. In-class activity Divide into groups of three or four people. Appendix B includes many \ndata sets not yet addressed by the methods of this chapter. Search Appendix B for variables of \ninterest, then investigate using appropriate methods of nonparametric statistics. State your con-\nclusions and try to identify practical applications.\n\n603\nMedia often report clusters of diseases or deaths along with \nsuggestions that some underlying cause should be inves-\ntigated. For example, the Pittsburgh Post Gazette reported \nthat in 14 western Pennsylvania counties, there were 14,636 \nmore deaths from heart disease, respiratory disease, and lung \ncancer than would be expected under normal circumstances. \nMany residents suspect environmental pollution as a cause for \nthe cluster, but the presence of a cluster has not been estab-\nlished and questions remain.\nSuppose a different region has 5000 people who reach \ntheir 16th birthday and 25 of them die before their 17th birthday. \nParents, expressing understandable concern, claim that this \nnumber of deaths is significantly high and the causes of death \nshould be investigated as part of a comprehensive study. \nSurvival Analysis\nCHAPTER \nPROBLEM\nIs the Cluster of Deaths Significantly High?\nLife Tables\nKaplan-Meier Survival \nAnalysis\n14-1\n14-2\n14 \ncontinued\n\nOthers suggest that the number of deaths of 16-year-olds \nwill naturally vary from year to year. Some years have fewer \ndeaths than average, while other years have disproportionately \ngreater numbers of deaths, so that the 25 deaths is no cause \nfor concern.\nHow do we objectively address this issue? One essential \npiece of information is the death rate for people in this age \ngroup. That rate can be extracted from a life table, which can \nbe very helpful in situations such as the one presented here. \nWe will consider the different components of a life table, and \nwe will use a specific and real life table to address the ques-\ntions raised above.\nCHAPTER OBJECTIVES\nHere are the main objectives of this chapter:\nLife Tables\n• Develop the ability to use a life table for the analysis of mortality and longevity data.\nKaplan-Meier Survival Analysis\n• Develop the ability to construct and interpret tables and graphs of survival data us-\ning the Kaplan-Meier method for determining the probability of survival over periods \nof time.\n14-1\n14-2\nHere are the main objectives of this chapter:\nLife Tables\n• Develop the ability to use a life table for the analysis of mortality and longevity data.\nKaplan-Meier Survival Analysis\n• Develop the ability to construct and interpret tables and graphs of survival data us-\ning the Kaplan-Meier method for determining the probability of survival over periods\nof time.\nLife tables are routinely developed by government agencies and private companies, \nand their use is critical to a variety of different fields. Studies of wildlife populations \noften involve life tables. Insurance companies could not provide life insurance poli-\ncies without the information contained in life tables. A “term” life insurance policy \nis essentially a bet that a person will live or die within a certain time period, and the \namount of the bet (cost of the policy or the premium amount) must reflect the prob-\nability that the subject will live or die within that time period. Many professionals \nmonitor the health of the United States population, and their analyses often involve \nlife tables as the basis for such comparisons. Other policy planners need to know how \nlong people are expected to live, so that they can satisfy their health and financial \nneeds. For example, employees in the United States typically have funds contributed \nto a large Social Security account maintained by the government. It is intended that \nthese funds be used to provide financial support when employees age and retire. How-\never, as people tend to live longer, the payments continue for longer periods of time, \nand careful planning is required to ensure that future generations will continue to en-\njoy the benefits of the Social Security system. Such careful planning requires accurate \ninformation about changes in longevity—information that is available in life tables. \nLife tables therefore become key tools in many different applications.\n 14-1 \nLife Tables\n604 \nCHAPTER 14 Survival Analysis\n\n14-1 Life Tables \n605\nLife tables include information about death rates and longevity, but there are dif-\nferent types of life tables. A cohort (or generation) life table is a record of the actual \nobserved mortality experience for a particular group, such as everyone born in the \nyear 1960. Because cohort life tables require complete data collected over periods \nspanning decades of time, they aren’t very practical and are not commonly used. The \nmain focus of this section will be period life tables. In subsequent references to life \ntables, it is assumed that we are referring to period life tables defined as follows.\nDEFINITION\nA period (or current) life table describes mortality and longevity data for a  \nhypothetical (or “synthetic”) cohort, with the data computed with this assumption:\nThe conditions aﬀecting mortality in a particular basis year (such as 2010)  \nremain the same throughout the lives of everyone in the hypothetical cohort.\nA period life table shows the long-term results of mortality conditions that were \npresent during the particular basis year.\nTable 14-1 on the following two pages is an example of a period life table. Because \nTable 14-1 is a period life table for the United States for the year 2010, we know that it \nwas constructed with this important assumption: The death rates for the various age groups \nthat were in effect in the year 2010 continue to remain in effect during the entire lives of \nthe 100,000 hypothetical people assumed to be present at age 0. That is, we pretend that a \npopulation of 100,000 people is born in the year 2010, and they each live their entire lives \nin a world with the same constant death rates that were present in the year 2010.\nTable 14-1 was provided by the National Center for Health Statistics, and it is \nbased on actual data from the U.S. Census Bureau (for population estimates), the \nMedicare program (a government program providing financial support for health \ncare), and death certificates issued in different states. Actual mortality data were col-\nlected, but they were then used to describe the experience of 100,000 hypothetical \npeople.\nTable 14-1 describes 100,000 hypothetical people who are representative of the \ntotal population of the United States, including males and females of various races. \nBecause mortality experiences can be very different for various gender and race \ngroups, it is common to have tables for specific subgroups. As of this writing, pe-\nriod life tables were available for males, females, whites, white males, white females, \nblacks, black males, and black females. We do not provide these other tables, but they \nshould be used in place of Table 14-1 when appropriate. For example, if calculating \nthe cost of a term life insurance policy for a 19-year-old white male, more accurate \ninformation could be obtained from the period life table for white males than from \nTable 14-1, which includes the entire population.\n\nTABLE 14-1 Life Table for Total Population: U.S., 2010\n \n \n \n \nAge Interval\n \nProbability of \nDying  \nDuring the  \nInterval\n \nNumber  \nSurviving to  \nthe Beginning  \nof the Interval\n \n \nNumber of  \nDeaths During \nthe Interval\nPerson-Years Lived  \n(total time lived during  \nthe interval by those  \nalive at the beginning  \nof the interval)\nTotal Person-\nYears Lived  \n(in this and all \nsubsequent  \nintervals)\n \nExpected Remaining  \nLifetime (from the  \nbeginning of  \nthe interval)\n0–1\n0.006123\n100,000\n612\n99,465\n7,866,027\n78.7\n1–2\n0.000428\n99,388\n 43\n99,366\n7,766,561\n78.1\n2–3\n0.000275\n99,345\n 27\n99,331\n7,667,195\n77.2\n3–4\n0.000211\n99,318\n 21\n99,307\n7,567,864\n76.2\n4–5\n0.000158\n99,297\n 16\n99,289\n7,468,556\n75.2\n5–6\n0.000145\n99,281\n 14\n99,274\n7,369,267\n74.2\n6–7\n0.000128\n99,267\n 13\n99,260\n7,269,993\n73.2\n7–8\n0.000114\n99,254\n 11\n99,249\n7,170,733\n72.2\n8–9\n0.000100\n99,243\n 10\n99,238\n7,071,484\n71.3\n9–10\n0.000087\n99,233\n  9\n99,229\n6,972,246\n70.3\n10–11\n0.000079\n99,224\n  8\n99,220\n6,873,017\n69.3\n11–12\n0.000086\n99,216\n  9\n99,212\n6,773,797\n68.3\n12–13\n0.000116\n99,208\n 12\n99,202\n6,674,585\n67.3\n13–14\n0.000175\n99,196\n 17\n99,188\n6,575,383\n66.3\n14–15\n0.000252\n99,179\n 25\n99,167\n6,476,195\n65.3\n15–16\n0.000333\n99,154\n 33\n99,138\n6,377,028\n64.3\n16–17\n0.000412\n99,121\n 41\n99,101\n6,277,891\n63.3\n17–18\n0.000492\n99,080\n 49\n99,056\n6,178,790\n62.4\n18–19\n0.000573\n99,032\n 57\n99,003\n6,079,734\n61.4\n19–20\n0.000655\n98,975\n 65\n98,942\n5,980,731\n60.4\n20–21\n0.000744\n98,910\n 74\n98,873\n5,881,789\n59.5\n21–22\n0.000829\n98,836\n 82\n98,795\n5,782,916\n58.5\n22–23\n0.000892\n98,754\n 88\n98,710\n5,684,120\n57.6\n23–24\n0.000925\n98,666\n 91\n98,621\n5,585,410\n56.6\n24–25\n0.000934\n98,575\n 92\n98,529\n5,486,789\n55.7\n25–26\n0.000936\n98,483\n 92\n98,437\n5,388,260\n54.7\n26–27\n0.000943\n98,391\n 93\n98,344\n5,289,824\n53.8\n27–28\n0.000953\n98,298\n 94\n98,251\n5,191,479\n52.8\n28–29\n0.000971\n98,204\n 95\n98,157\n5,093,228\n51.9\n29–30\n0.000998\n98,109\n 98\n98,060\n4,995,071\n50.9\n30–31\n0.001029\n98,011\n101\n97,961\n4,897,011\n50.0\n31–32\n0.001063\n97,910\n104\n97,858\n4,799,051\n49.0\n32–33\n0.001099\n97,806\n108\n97,752\n4,701,193\n48.1\n33–34\n0.001137\n97,699\n111\n97,643\n4,603,440\n47.1\n34–35\n0.001180\n97,587\n115\n97,530\n4,505,797\n46.2\n35–36\n0.001235\n97,472\n120\n97,412\n4,408,267\n45.2\n36–37\n0.001302\n97,352\n127\n97,289\n4,310,855\n44.3\n37–38\n0.001377\n97,225\n134\n97,158\n4,213,567\n43.3\n38–39\n0.001461\n97,091\n142\n97,020\n4,116,408\n42.4\n39–40\n0.001557\n96,949\n151\n96,874\n4,019,388\n41.5\n40–41\n0.001663\n96,798\n161\n96,718\n3,922,514\n40.5\n41–42\n0.001793\n96,637\n173\n96,551\n3,825,796\n39.6\n42–43\n0.001962\n96,464\n189\n96,370\n3,729,245\n38.7\n43–44\n0.002177\n96,275\n210\n96,170\n3,632,875\n37.7\n44–45\n0.002423\n96,065\n233\n95,949\n3,536,705\n36.8\n45–46\n0.002676\n95,833\n256\n95,704\n3,440,756\n35.9\n46–47\n0.002931\n95,576\n280\n95,436\n3,345,052\n35.0\n47–48\n0.003205\n95,296\n305\n95,143\n3,249,616\n34.1\n48–49\n0.003505\n94,990\n333\n94,824\n3,154,473\n33.2\n49–50\n0.003830\n94,658\n363\n94,476\n3,059,649\n32.3\n50–51\n0.004177\n94,295\n394\n94,098\n2,965,173\n31.4\n\nFrom National Vital Statistics Reports, U.S. Department of Health and Human Services.\n \n \n \n \nAge Interval\n \nProbability of \nDying  \nDuring the  \nInterval\n \nNumber  \nSurviving to  \nthe Beginning  \nof the Interval\n \n \nNumber of  \nDeaths During \nthe Interval\nPerson-Years Lived  \n(total time lived during  \nthe interval by those  \nalive at the beginning  \nof the interval)\nTotal Person-\nYears Lived  \n(in this and all \nsubsequent  \nintervals)\n \nExpected Remaining  \nLifetime (from the  \nbeginning of  \nthe interval)\n51–52\n0.004535\n93,901\n426\n93,688\n2,871,075\n30.6\n52–53\n0.004903\n93,475\n458\n93,246\n2,777,386\n29.7\n53–54\n0.005284\n93,017\n491\n92,771\n2,684,140\n28.9\n54–55\n0.005684\n92,526\n526\n92,263\n2,591,369\n28.0\n55–56\n0.006117\n92,000\n563\n91,718\n2,499,106\n27.2\n56–57\n0.006589\n91,437\n603\n91,136\n2,407,388\n26.3\n57–58\n0.007095\n90,834\n644\n90,512\n2,316,253\n25.5\n58–59\n0.007626\n90,190\n688\n89,846\n2,225,741\n24.7\n59–60\n0.008180\n89,502\n732\n89,136\n2,135,895\n23.9\n60–61\n0.008767\n88,770\n778\n88,381\n2,046,759\n23.1\n61–62\n0.009397\n87,992\n827\n87,578\n1,958,378\n22.3\n62–63\n0.010085\n87,165\n879\n86,725\n1,870,800\n21.5\n63–64\n0.010863\n86,286\n937\n85,817\n1,784,075\n20.7\n64–65\n0.011758\n85,348\n1,004\n84,847\n1,698,258\n19.9\n65–66\n0.012810\n84,345\n1,080\n83,805\n1,613,411\n19.1\n66–67\n0.014011\n83,264\n1,167\n82,681\n1,529,606\n18.4\n67–68\n0.015290\n82,098\n1,255\n81,470\n1,446,925\n17.6\n68–69\n0.016601\n80,843\n1,342\n80,172\n1,365,455\n16.9\n69–70\n0.018005\n79,501\n1,431\n78,785\n1,285,283\n16.2\n70–71\n0.019548\n78,069\n1,526\n77,306\n1,206,499\n15.5\n71–72\n0.021294\n76,543\n1,630\n75,728\n1,129,192\n14.8\n72–73\n0.023275\n74,913\n1,744\n74,041\n1,053,464\n14.1\n73–74\n0.025528\n73,169\n1,868\n72,236\n979,423\n13.4\n74–75\n0.028061\n71,302\n2,001\n70,301\n907,188\n12.7\n75–76\n0.030820\n69,301\n2,136\n68,233\n836,886\n12.1\n76–77\n0.033775\n67,165\n2,268\n66,031\n768,654\n11.4\n77–78\n0.037252\n64,896\n2,418\n63,688\n702,623\n10.8\n78–79\n0.041136\n62,479\n2,570\n61,194\n638,935\n10.2\n79–80\n0.045411\n59,909\n2,721\n58,549\n577,741\n9.6\n80–81\n0.050146\n57,188\n2,868\n55,754\n519,193\n9.1\n81–82\n0.055445\n54,321\n3,012\n52,815\n463,438\n8.5\n82–83\n0.061272\n51,309\n3,144\n49,737\n410,624\n8.0\n83–84\n0.067764\n48,165\n3,264\n46,533\n360,887\n7.5\n84–85\n0.075818\n44,901\n3,404\n43,199\n314,354\n7.0\n85–86\n0.085319\n41,497\n3,540\n39,727\n271,155\n6.5\n86–87\n0.094975\n37,956\n3,605\n36,154\n231,429\n6.1\n87–88\n0.105525\n34,351\n3,625\n32,539\n195,275\n5.7\n88–89\n0.117007\n30,726\n3,595\n28,929\n162,736\n5.3\n89–90\n0.129450\n27,131\n3,512\n25,375\n133,807\n4.9\n90–91\n0.142873\n23,619\n3,375\n21,932\n108,432\n4.6\n91–92\n0.157280\n20,245\n3,184\n18,653\n86,500\n4.3\n92–93\n0.172661\n17,061\n2,946\n15,588\n67,847\n4.0\n93–94\n0.188988\n14,115\n2,668\n12,781\n52,259\n3.7\n94–95\n0.206214\n11,447\n2,361\n10,267\n39,478\n3.4\n95–96\n0.224274\n9,087\n2,038\n8,068\n29,211\n3.2\n96–97\n0.243080\n7,049\n1,713\n6,192\n21,144\n3.0\n97–98\n0.262527\n5,335\n1,401\n4,635\n14,951\n2.8\n98–99\n0.282492\n3,935\n1,112\n3,379\n10,316\n2.6\n99–100\n0.302838\n2,823\n855\n2,396\n6,937\n2.5\n100 and over\n1.000000\n1,968\n1,968\n4,542\n4,542\n2.3\n\n608 \nCHAPTER 14 Survival Analysis\nComponents of a Period Life Table\nThe seven columns in the period life Table 14-1 are described as follows.\nColumn 1: Age Interval The first column of Table 14-1 lists age categories. The first cat-\negory of 0–1 represents the age interval from birth to the first birthday. Note that some of \nthe other columns are based on the age at the beginning of the age interval. For example, \nthe last column lists expected ages, which are the expected remaining lifetime amounts \nmeasured from the beginning of the age interval. For the age interval of 0–1, the ex-\npected remaining lifetime is 78.7, which means that a newborn has an expected lifetime \nof 78.7 years. Also note that the age intervals overlap with a common value used for the \nupper boundary of one class as well as the lower boundary for the following class. When \nwe discussed frequency distributions in Chapter 2, we noted that the class limits should \nnot overlap, but the overlapping is not an important issue with period life tables. It would \nbe a very rare event to have someone die on the exact instant of the beginning of their \nbirth date, so we need not make adjustments for this event that will likely never occur.\nColumn 2: Probability of Dying The second column lists the probabilities of dy-\ning during the age interval listed in the first column. The first row of values shows \nthat there is a 0.006123 probability of someone dying between birth and their first \nbirthday. The second row shows that there is a 0.000428 probability of someone dy-\ning between their first birthday and their second birthday. These probabilities of death \nreflect the death rates for the various age groups that were observed in the year 2010.\nColumn 3: Number Surviving The third column lists the number of people alive at \nthe beginning of the age interval. Note that the first row lists the size of our hypotheti-\ncal population (100,000), and this value shows that there were 100,000 hypothetical \npeople who were born and alive at the beginning of the age interval from 0 to 1 year. \nThis number decreases as some of the hypothetical people have hypothetical deaths. \nThe second row shows that among the 100,000 hypothetical people who were born, \n99,388 of them are alive on their first birthday. The values in column 3 can be com-\nputed by using the death rates in column 2. For example, the first age interval of 0–1 \nhas a death rate of 0.006123, so we expect that 612.3 of the 100,000 people alive at \nbirth will die, leaving a population of 100,000 - 612.3 = 99,388 (rounded) people \nalive at the beginning of the second age interval of 1–2.\nColumn 4: Number of Deaths The fourth column shows the number of people who \ndied during the age interval in the column at the left. This value can be computed \nby multiplying the number of people alive at the beginning of the age interval (col-\numn 3) by the probability of dying during the age interval (column 2). For example, \nthe first row shows that 100,000 people were present at age 0 and the death rate for \nthose in the age interval of 0–1 is 0.006123, so we expect the number of deaths to be: \n100,000 * 0.006123 = 612 (rounded).\nColumn 5: Person-Years Lived This column lists the total time (in years) lived dur-\ning the age interval by those who were alive at the beginning of the age interval. \nFor example, the first row in column 5 has an entry of 99,465 (years), and this value \nshows that the 100,000 people who were present at age 0 lived a total of 99,465 years. \nIf none of those people had died, this entry would have been 100,000 years, but some \nof them did die, so the total is less than 100,000 years.\nColumn 6: Total Person-Years Lived The sixth column is somewhat similar to the \nfifth column in the sense that it lists the total number of years lived by those present \nat the beginning of the age interval, but column 5 lists the number of years lived dur-\ning the age interval, whereas column 6 lists the number of years lived during the age \ninterval and all of the following age intervals as well.\n\n14-1 Life Tables \n609\nColumn 7: Expected Remaining Lifetime The last column lists the expected re-\nmaining lifetime (in years), measured from the beginning of the age interval. For ex-\nample, the first row shows that the expected remaining lifetime is 78.7 years, so the \naverage expected lifetime of the 100,000 newborn people is 78.7 years. Each value in \nthe seventh column can be computed by dividing the total person-years lived (column \n6) by the number of people who were present at the beginning of the age interval. For \nexample, the age interval of 1–2 has an expected remaining lifetime of 78.1 years, and \nthe total person-years lived (column 6) divided by the number of people present at the \nbeginning of the age interval (column 3) yields 7,766,561 , 99,388 = 78.1 (rounded). \nAgain, we should remember that this assumes that the same mortality conditions \npresent in the year 2010 remain constant throughout the lifetimes of the 100,000 \nhypothetical people. We should also remember that Table 14-1 describes the total \npopulation, and expected remaining lifetime values will be different for different sub-\ngroups of genders and races.\nNotation: More formal mathematical notation is often used for the above compo-\nnents. For example, the age intervals can be expressed in general form as “x to x + 1,” \nthe probability of dying during an interval is expressed as qx, the number alive at the \nbeginning of an interval is expressed as lx, the number dying in an interval is ex-\npressed as dx, and so on. Such notation makes it easier to develop formulas describ-\ning components of the period life table. For example, the formula dx = qx # lx shows \nthat the number of deaths in an interval is equal to the probability of dying during the \ninterval multiplied by the number alive at the beginning of the interval. Also, such \nnotation is commonly used to describe the columns of a period life table. In Table 14-1, \nfor example, the original government report labels the columns with headings such \nas “probability of dying between ages x and x + 1” and “person-years lived between \nages x and x + 1.” The use of this more formal notation is not necessary for the pur-\nposes of this section, but this notation is commonly used in some fields.\nAbridged Life Table\nTable 14-1 is sometimes referred to as a complete life table, because it lists a separate \nrow of data for each year. An abridged life table uses age intervals for time periods \nlonger than one year. Age intervals of 5 years or 10 years are common in an abridged \nlife table.\nDEFINITION\nAn abridged life table is a life table in which the age intervals have been com-\nbined, so the age intervals are longer than one year. Age intervals of 5 years or  \n10 years are common.\nTable 14-2 is an abridged life table that condenses Table 14-1 by using age intervals of \n5 years. Table 14-2 was constructed by using the values found in Table 14-1.\n\n610 \nCHAPTER 14 Survival Analysis\nTABLE 14-2 Abridged Life Table for Total Population: U.S., 2010\n \n \n \n \n \nAge Interval\n \n \n \nProbability of  \nDying During  \nthe Interval\n \n \n \nNumber Surviving  \nto the Beginning of \nthe Interval\n \n \n \nNumber of  \nDeaths During \nthe Interval\nPerson-Years Lived  \n(total time lived  \nduring the interval  \nby those alive at the  \nbeginning of the  \ninterval)\n \nTotal Person- \nYears Lived  \n(in this and all  \nsubsequent  \nintervals)\n \nExpected  \nRemaining \nLifetime (from  \nthe beginning of  \nthe interval)\n0–5\n0.007190\n100,000\n719\n496,759\n7,866,027\n78.7\n5–10\n0.000573\n99,281\n57\n496,250\n7,369,267\n74.2\n10–15\n0.000708\n99,224\n70\n495,989\n6,873,017\n69.3\n15–20\n0.002463\n99,154\n244\n495,240\n6,377,028\n64.3\n20–25\n0.004317\n98,910\n427\n493,529\n5,881,789\n59.5\n25–30\n0.004791\n98,483\n472\n491,249\n5,388,260\n54.7\n30–35\n0.005497\n98,011\n539\n488,744\n4,897,011\n50.0\n35–40\n0.006913\n97,472\n674\n485,753\n4,408,267\n45.2\n40–45\n0.009979\n96,798\n966\n481,758\n3,922,514\n40.5\n45–50\n0.016044\n95,833\n1,538\n475,584\n3,440,756\n35.9\n50–55\n0.024343\n94,295\n2,295\n466,066\n2,965,173\n31.4\n55–60\n0.035106\n92,000\n3,230\n452,347\n2,499,106\n27.2\n60–65\n0.049847\n88,770\n4,425\n433,348\n2,046,759\n23.1\n65–70\n0.074406\n84,345\n6,276\n406,912\n1,613,411\n19.1\n70–75\n0.112315\n78,069\n8,768\n369,612\n1,206,499\n15.5\n75–80\n0.174782\n69,301\n12,113\n317,694\n836,886\n12.1\n80–85\n0.274384\n57,188\n15,692\n248,038\n519,193\n 9.1\n85–90\n0.430820\n41,497\n17,878\n162,723\n271,155\n 6.5\n90–95\n0.615282\n23,619\n14,532\n 79,220\n108,432\n 4.6\n95–100\n0.783397\n 9,087\n7,119\n 24,670\n29,211\n 3.2\n100+\n1.000000\n 1,968\n1,968\n  4,542\n4,542\n 2.3\nFrom National Vital Statistics Reports, U.S. Department of Health and Human Services.\nEXAMPLE 1\nExpected Remaining Life\nAn abridged life table is to be constructed using age intervals of 5 years. Use Table 14-1 \nto find the expected remaining lifetime for someone reaching their 25th birthday.\nSOLUTION\nFrom Table 14-1 we see that someone reaching their 25th birthday has an expected \nremaining lifetime of 54.7 years. In the abridged table, the expected remaining life-\ntime for someone reaching their 25th birthday will be the same value of 54.7 years, \nso the age interval of 25–30 will also have 54.7 years listed in the last column.\nEXAMPLE 2  Probability of Dying\nUse Table 14-1 on pages 606-607 to find the probability of a person dying between \nthe ages of 15 and 20.\nSOLUTION\nFrom Table 14-1 we see that there were 99,154 people alive on their 15th birthday, \nand there were 98,910 people alive on their 20th birthday. The probability of  surviving \n\n14-1 Life Tables \n611\nApplications of Life Tables\nThe following application is important because it relates to the Social Security pro-\ngram in the United States, and that program involves trillions of dollars.\nbetween the 15th and 20th birthdays is therefore 98,910>99,154 = 0.997539. Using \nthe rule of complements from Chapter 4, it follows that the probability of dying dur-\ning that interval is 1 - 0.997539 = 0.002461. (The abridged life table of Table 14-2 \nshows the entry of 0.002463.)\nEXAMPLE 3\nSocial Security\nAssume that there are 3,932,181 births in the United States this year (based on data \nfrom the U.S. National Center for Health Statistics). If the age for receiving full \nSocial Security payments is 67, how many of those born this year are expected to be \nalive on their 67th birthday?\nSOLUTION\nFrom Table 14-1 (pages 606-607), we see that among 100,000 people born, we ex-\npect that 82,098 of them will survive to their 67th birthday. It follows that the prob-\nability of someone surviving from birth to their 67th birthday is 0.82098. If each of \n3,932,181 newborn people has a 0.82098 probability of surviving to their 67th birth-\nday, the expected number of such survivors is 3,932,181 * 0.82098 = 3,228,242 \n(rounded). Such results are critically important for those professionals responsible \nfor effective administration of the Social Security program.\nAnother application is based on the property that a life table includes probabili-\nties, and they can be treated as the same probabilities used in preceding chapters of \nthis book. Consider the following example in which a hypothesis test is conducted \nwith a probability value found in Table 14-1.\nEXAMPLE 4  Hypothesis Test for Cluster of Deaths\nIn the Chapter Problem, we noted that for one region there are 5000 people who \nreach their 16th birthday. If 25 of them die before their 17th birthday, do we have \nsufficient evidence to conclude that this number of deaths is significantly high?\nSOLUTION\nFrom Table 14-1 (pages 606-607), we find that for the age interval of 16–17, the \nprobability of dying is 0.000412. However, the Chapter Problem refers to a region \nin which there were 25 deaths among 5000 people during the age interval from their \n16th birthday to their 17th birthday. For this region, the proportion of actual deaths \nis pn = x>n = 25>5000 = 0.005. We can proceed to test the claim that for this \nregion, the deaths are from a population with a death rate greater than the life table \nvalue of 0.000412. Using the methods of Chapter 8, we begin with the following \nnull and alternative hypotheses.\nH0: p = 0.000412\nH1: p 7 0.000412 1claim being tested2\ncontinued\n\n612 \nCHAPTER 14 Survival Analysis\nNo significance level was specified, so we will use the common value of a = 0.05. \nWe now proceed to find the test statistic (as in Section 8–2):\nz = pn - p\nA\npq\nn\n=\n0.005 - 0.000412\nA\n10.000412210.9995882\n5000\n= 15.99\nUsing the P-value approach, we can find that the test statistic of z = 15.99 corre-\nsponds to a P-value of 0.0000 (or 0.0001 if using Table A-2).\nBecause the P-value is less than 0.05, we reject the null hypothesis. There is \nsufficient evidence to support the claim that the proportion of deaths is significantly \ngreater than the proportion that is usually expected for this age interval. We should \nnote that this analysis assumed that p = 0.000412, which was found in Table 14-1. \nHowever, Table 14-1 was constructed under the assumption that the mortality condi-\ntions present in the year 2010 will remain constant throughout the lifetimes of the \nhypothetical population of 100,000 people. Also, Table 14-1 applies to a general \npopulation, so this analysis does not apply to specific subgroups.\nStatistical Literacy and Critical Thinking\n1. Types of Life Tables What is the difference between a cohort life table and a period life \ntable?\n2. Cohort and Period Life Tables Why are period life tables so much more practical than \ncohort life tables?\n3. Population Size Table 14-1 was constructed with the assumption that the initial population \nsize is 100,000. How are the values in the first row affected if a population size of 50,000 is \nused instead?\n4. Interpretation of Table Assume that someone was born on January 1, 2010, and that per-\nson is alive now. If we refer to Table 14-1 for his or her expected remaining lifetime, what basic \nassumption about the construction of Table 14-1 might make that value inaccurate?\nIn Exercises 5–8, refer to the accompanying life table for white females in the United States \nfor the year 2010.\n14-1 Basic Skills and Concepts\nLife Table for White Females: U.S., 2010\n \n \n \n \n \n \n \n \n \nAge Interval\n \n \n \n \n \n \nProbability \nof Dying \nDuring the \nInterval\n \n \n \n \nNumber \nSurviving \nto the  \nBeginning \nof the  \nInterval\n \n \n \n \n \n \nNumber  \nof Deaths \nDuring the \nInterval\nPerson- \nYears Lived \n(total time  \nlived during \nthe interval  \nby those  \nalive at the  \nbeginning  \nof the  \ninterval)\n \n \n \nTotal  \nPerson-\nYears  \nLived (in  \nthis and all  \nsubsequent  \nintervals)\n \n \n \nExpected \nRemaining \nLifetime \n(from the \nbeginning \nof the  \ninterval)\n0–1\n0.004710\n100,000\n471\n99,588\n8,128,871\n81.3\n1–2\n 99,529\n 38\n99,510\n8,029,283\n80.7\n2–3\n0.000204\n 99,491\n99,481\n7,929,773\n79.7\nFrom National Vital Statistics Reports, U.S. Department of Health and Human Services.\n\n14-1 Life Tables \n613\n5. Probability of Dying Find the missing value in the second column of the life table for \nwhite females.\n6. Finding the Number of Deaths Find the missing value in the fourth column of the life \ntable for white females.\n7. Finding Survival Rate Find the probability that a white female will live from birth to her \nsecond birthday.\n8. Constructing an Abridged Table Assume that you want to use the given life table for \nwhite females to construct an abridged table with 0–2 as the first age interval. Find the values \nin the first row of this abridged table.\n9. Probability of Surviving Using Table 14-1 on pages 606-607, find the probability that \nsomeone will survive from their 20th birthday to their 21st birthday. Given 5000 people who \nreach their 20th birthday, what is the expected number of people who survive to their 21st \nbirthday?\n10. Expected Remaining Lifetime Use Table 14-1 on pages 606-607 to find the following.\na. Find the expected remaining lifetime for a person who has just reached their 60th birthday, \nthen find the expected remaining lifetime for a person who has just reached their 61st birthday.\nb. Find the expected age at death of someone who has just reached their 60th birthday, and find \nthe expected age at death for someone who has just reached their 61st birthday.\nc. Why aren’t the two results from part (b) equal?\n11. Probability of Surviving Use Table 14-1 on pages 606-607 to find the probability that a \nperson will survive from their 16th birthday to their 66th birthday.\n12. Probability of Surviving Use Table 14-1 on pages 606-607 to find the probability that a \nperson will survive from their 21st birthday to their 80th birthday.\n13. Abridged Table Use Table 14-1 on pages 606-607 to find the probability of dying during \nthe following age intervals. Given that these age intervals are so close, why are the results so \ndifferent?\na. 0–2\nb. 2–4\n14. Abridged Table Use Table 14-1 on pages 606-607 to find the values in a row with an age \ninterval of 0–2.\n15. Abridged Table Use Table 14-1 on pages 606-607 to find the values in a row with an age \ninterval of 2–4.\n16. Abridged Table Use Table 14-1 on pages 606-607 to find the values in a row with an age \ninterval of 0–10.\n17. Hypothesis Test In one region, a researcher finds that among 12,500 people who survived \nto their 20th birthday, there are 15 deaths before they reached age 21. Using Table 14-1, test the \nclaim that this is a significantly high number of deaths. Use a 0.05 significance level.\n18. Hypothesis Test In one region, a researcher finds that among 6772 people who survived \nto their 50th birthday, there are 36 deaths before they reached age 51. Using Table 14-1, test the \nclaim that this is a significantly high number of deaths. Use a 0.05 significance level.\n19. Hypothesis Test In one region, a researcher finds that among 8774 people who survived \nto their 16th birthday, there are 147 deaths before they reached age 30. Using Table 14-1, test \nthe claim that this is a significantly high number of deaths. Use a 0.05 significance level.\n20. Hypothesis Test In one region, a researcher finds that among 4285 people who survived \nto their 60th birthday, there are 484 deaths before they reached age 70. Using Table 14-1, test \nthe claim that this is a significantly low number of deaths. Use a 0.05 significance level.\n\n614 \nCHAPTER 14 Survival Analysis\nKey Concept In this section we introduce the Kaplan-Meier method used to describe \nthe probability of surviving for a specific period of time. The life table method of \nsurvivor analysis introduced in Section 14-1 is based on fixed time intervals, but the \nKaplan-Meier method is based on intervals that vary according to the times of survival \nto some particular terminating event. Using the sample data, it is helpful to construct a \nKaplan-Meier cumulative survival curve.\nIn this context of survivor analysis, the term survivor does not necessarily mean \nliving. A patient might be considered a survivor if postoperative surgery did not re-\nquire a return to a physician or hospital. A patient trying to stop smoking might be \nconsidered a survivor as long as smoking has not resumed. A survivor might also be a \ncomputer hard drive that worked for some particular length of time.\n14-2 \nKaplan-Meier Survival Analysis\nDEFINITIONS\nIn survivor analysis, the time lapse from the beginning of observation to the time of \na terminating event is considered a survival time. Examples of a terminating event \ninclude death, divorce, or failure of a computer hard drive.\nA survivor is a subject that successfully lasted throughout a particular time period. \nExamples of survivors include people, marriages, or computer hard drives.\nDEFINITION\nThe Kaplan-Meier method is used to describe survival behavior for some specific \nevent, and it is based on varying survival time intervals for the terminating event being \nanalyzed. (Because cumulative probabilities are products of other individual probabili-\nties, the Kaplan-Meier method is sometimes called the product-limit method.)\nA common application of the Kaplan-Meier method is to study survival times of \npatients after they undergo some treatment, such as surgery. Some of the survival data \nin such a study is often lost because some of the surgery patients survive by living past \nthe end of the study and some patients move far away or no longer wish to be included \nin the study, or are dropped from the study for other reasons. The data for these pa-\ntients are referred to as censored data, defined as follows.\nDEFINITION\nSurvival times are censored data if the subjects survive past the end of the study \nor if they are dropped from the study for reasons not related to the terminating \nevent being studied.\nEXAMPLE 1  Medication Treatment for Smoking Cessation\nConsider an experimental medication tested with five smokers recruited for a smok-\ning cessation clinical trial. In this context, “surviving” means that the patient has not \nresumed smoking.\n\n14-2 Kaplan-Meier Survival Analysis \n615\nResults: The first patient disliked the taste of the medication and dropped out of \nthe study on the first day, so the data from this patient are censored. Despite using \nthe medication as directed, the remaining four patients resumed smoking after  \n3 days, 4 days, 7 days, and 21 days, respectively. See these survival data summa-\nrized in Table 14-3.\nTABLE 14-3 Medication Treatment: Survival Data and Kaplan-Meier Calculations\n1 \n \n \n \n \nDay\n2 \nStatus  \n0 = Censored  \n1 = Failed  \n(Resumed \nSmoking)\n3 \n \n \n \nNumber  \nof Patients\n4 \n \n \n \nPatients  \nNot Smoking\n5 \n \n \nProportion  \nof Patients  \nNot Smoking\n6 \n \nCumulative  \nProportion of  \nPatients Not  \nSmoking\n1\n0\n3\n1\n4\n3\n 3>4 = 0.75\n0.75\n4\n1\n3\n2\n2>3 = 0.667\n       0.5\n7\n1\n2\n1\n 1>2 = 0.5\n0.25\n21\n1\n1\n0\n0\n0\nHere are some relevant comments about the entries in Table 14-3.\nCensored Data The first row of data in Table 14-3 represents the subject who \ndropped out of the program, and the 0 in the first row is the code for censored data. \nNote that except for the entry of 0, the other columns in the row are empty. Remov-\ning the patient who dropped out does not affect the subsequent calculations except \nfor the reduction in the number of remaining survivors.\nSecond Row of Data:\n \n■The number 3 in the first column of the second row indicates that this patient \nresumed smoking 3 days after the start of the program. This patient “survived” \nfor 3 days.\n \n■The 1 in the second column is a code indicating that smoking was resumed.\n \n■The 4 in the third column shows 4 patients remaining in the program.\n \n■The 3 in the fourth column represents the number of remaining patients who \nhave “survived” in the sense that they are not smoking.\n \n■The proportion of 3/4 in the fifth column shows that 3 out of the 4 patients have \nsurvived (i.e., not smoking).\n \n■The proportion of 0.75 in the sixth column is the same proportion of 0.75 from \nthe fifth column, but for the remaining rows, the proportion in the sixth column \nwill be the product of the proportion from the fifth column and any preceding \nproportions in the fifth column. See below.\nSixth Column of Cumulative Proportions of Survivors:\n \n■First entry of 0.75: Same proportion from the fifth column.\n \n■Second entry of 0.5: Product of 0.667 (rounded) from the fifth column and the \npreceding entry of 0.75 in the fifth column. We get 0.667 * 0.75 = 0.5.\n \n■Third entry of 0.25: Product of 0.5 from the fifth column and the \npreceding entries of 0.667 and 0.75 from the fifth column. We get \n0.5 * 0.667 * 0.75 = 0.25.\n \n■Fourth entry of 0: Product of 0 from the fifth column and the preceding entries \nin the fifth column. We get 0 * 0.5 * 0.667 * 0.75 = 0.\n\n616 \nCHAPTER 14 Survival Analysis\nEXAMPLE 2\nCounseling Treatment for Smoking Cessation\nThe preceding Example 1 describes survival for five patients who were treated with \nmedication. In the same program, 10 different patients underwent counseling in the at-\ntempt to stop smoking, and the results from these patients are summarized in Table 14-4. \nThis counseling program was discontinued after 28 days. Table 14-4 is an example of \nsurvival data with Kaplan-Meier calculations. Note that in Table 14-4, the number of \npatients decreases when patients are censored, as indicated by 0 in column 2.\nTABLE 14-4 Counseling Treatment: Survival Data and Kaplan-Meier Calculations\n \n \n \n \nDay\nStatus  \n0 = Censored \n1 = Failed  \n(Resumed  \nSmoking)\n \n \n \nNumber of  \nPatients\n \n \n \nPatients Not  \nSmoking\n \n \nProportion of \nPatients Not  \nSmoking\n \nCumulative  \nProportion of  \nPatients Not  \nSmoking\n 2\n1\n10\n9\n9>10 = 0.9\n0.9\n 4\n1\n 9\n8\n8>9 = 0.889\n0.8\n 5\n0\n 8\n1\n 7\n6\n6>7 = 0.857\n0.686\n 9\n1\n 6\n5\n5>6 = 0.833\n0.571\n12\n0\n14\n1\n 4\n3\n 3>4 = 0.75\n0.429\n22\n1\n 3\n2\n2>3 = 0.667\n0.286\n24\n0\n28\n0\nEXAMPLE 3  Kaplan-Meier Cumulative Survival Curves\nAs interesting and revealing as Tables 14-3 and 14-4 might be (!), it is usually more \nhelpful to construct graphs that make it easier to understand the survivor data. See \nthe accompanying Kaplan-Meier cumulative survival curves in Figure 14-1 that \nincorporates the survivor data from Table 14-3 and Table 14-4. The graph is con-\nstructed by using the survival times (column 1) and the cumulative proportions of \npatients not smoking (column 6) from Table 14-3 and Table 14-4.\nFIGURE 14-1  Kaplan-Meier Cumulative  \nSurvival Curves\n\n14-2 Kaplan-Meier Survival Analysis \n617\nSurvival for a Specific Time Period We can use the cumulative survival curves \nin Figure 14-1 to estimate survival for a specific time period. For example, the prob-\nability of survival to 15 days is estimated to be 0.25 for the medication group and 0.43 \nfor the counseling group. (Use the graph to construct a vertical line at 15 days and \nidentify the intersection of that line with the curves, then estimate the heights at the \ntwo points of intersection.)\nSome technologies, such as Minitab, JMP, SPSS, and XLSTAT-Life, can auto-\nmatically generate Kaplan-Meier cumulative survival curves, and some technologies \ncan also include graphs representing confidence intervals around those curves.\nThe Kaplan-Meier cumulative survival curves in Figure 14-1 show that the \nproportions of survivors (patients who had not resumed smoking) with counsel-\ning are generally higher than the proportions of survivors with medication, so it \nbecomes clear that the counseling program had better results than the medication \nprogram. However, neither of the programs had very high rates of survivors, so \nneither program appears to be very effective in helping patients achieve success in \ntheir attempts to stop smoking.\nStatistical Literacy and Critical Thinking\n1. Survivor In the context of analyzing survivor data, what is a survivor? Is it somebody who \nsomehow managed to live through some time period?\n2. Censored Data In the context of analyzing survivor data, what are censored data?\n3. Kaplan-Meier Survival Analysis What is the main difference between a life table de-\nscribed in Section 14-1 and a table of survival data and Kaplan-Meier calculations as described \nin this section?\n4. Graph What is a Kaplan-Meier cumulative survival curve?\nIn Exercises 5–9, refer to the accompanying graph, which describes times of survival until \ndeath for three groups of older subjects. The subjects are partitioned into the three groups \naccording to gait speed, or how fast they can walk. At the beginning of the study, ten sub-\njects were identified with fast gait speeds, ten other subjects were identified with moder-\nate gait speeds, and ten more subjects were identified with slow gait speeds. Times (years) \nwere measured from the beginning of the study to the time of death. (Based on data from \n “Predicting Survival in Oldest People,” by Taekema et al., American Journal of Medicine.)\n14-2 Basic Skills and Concepts\n\n618 \nCHAPTER 14 Survival Analysis\n5. Conclusion A purpose of the study was to determine whether walking speed is an effective \npredictor of longevity among the oldest subjects. Which of the three curves do you think cor-\nresponds to each of the three groups (fast, moderate, slow). Provide a brief explanation.\n6. Probability The vertical scale represents probability values. Describe the event for which \nprobabilities are found. What do we know from the observation that the three curves all pro-\nceed downward as time progresses?\n7. Graphic Details \na. For the ten subjects in the group identified by the green curve, how much time elapsed be-\ntween the beginning of the study and the death of the first subject?\nb. For the ten subjects in the group identified by the red curve, how much time elapsed between \nthe beginning of the study and the death of the first subject?\n8. Survivors Did any of the slow walkers survive, or did they all die?\n9. Survival to Five Years Estimate the five-year survival rates for the three groups and com-\npare them. Do the data suggest that we can get older people to live longer by somehow getting \nthem to walk faster?\n10. Hospital Readmission Ten patients underwent surgery and were subsequently followed \nup for 14 days to determine whether they required readmission to a hospital. Readmission is \nconsidered a failure or terminating event. Complete the table. What do the last five 0’s in the \nsecond column indicate?\n \n \n \nDay\nStatus  \n0 = Censored  \n1 = Failed  \n(Readmitted)\n \n \nNumber  \nof Patients\n \n \nPatients Not  \nReadmitted\n \nProportion of \nPatients Not  \nReadmitted\nCumulative  \nProportion of \nPatients Not  \nReadmitted\n 2\n0\n 6\n1\n10\n1\n11\n1\n13\n1\n14\n0\n14\n0\n14\n0\n14\n0\n14\n0\n11. Graph of Cumulative Survival Construct the cumulative survival (probability) graph for \nthe completed table from Exercise 10.\n12. Blood Pressure For the purposes of a clinical trial, a patient was considered to have high \nblood pressure if the systolic blood pressure exceeded 140 mm Hg. Eight patients were treated \nfor their high blood pressure, and they were then followed up for 30 days. A failure of the \ntreatment was considered to be a terminating event consisting of a return of the systolic blood \npressure to a level that exceeded 140 mm Hg. Here are the results: One patient dropped out of \nthe study on day 2, the systolic blood pressure of a second patient returned to a high level on \nday 10, a third patient developed high blood pressure on day 12, and the remaining patients \nsustained systolic blood pressure levels below 140 mm Hg throughout the time of the clinical \ntrial. Construct a table containing survival data and Kaplan-Meier calculations.\n13. Graph of Cumulative Survival Construct the cumulative survival (probability) graph for \nthe completed table from Exercise 12. How many censored patient survival times are shown in \nthe graph?\n\n14. Graph of Cumulative Survival Refer to the accompanying cumulative survival graph. \nWhich is better: treatment or placebo? Estimate the five-year survival rates for the two groups, \nthen compare them. What does the graph suggest about the effectiveness of the treatment?\n1. Life Table or Survival Table Which tool would be better for estimating the probability that \na female of age 27 will live throughout her 28th year: life table or survival table with Kaplan-\nMeier calculations?\n2. Life Table or Survival Table Which tool would be better for estimating the probability that \nsomeone will live for at least 20 years after they start smoking: a life table or a survival table \nwith Kaplan-Meier calculations?\n3. Period Life Table What is a period life table?\n4. Cohort Life Table What is a cohort life table?\n5. Censored Data True or false: In survival analysis, censored data are records that have been \neliminated because they could potentially reveal the identities of subjects.\n6. Censored Data True or false: In survival analysis, if a subject survives for the entire dura-\ntion of the study, then the survival time for that subject is excluded.\n7. Survivor In survivor analysis, the term survivor always refers to a person who has lived \nsome specific amount of time.\n8. Period Life Table True or false: One disadvantage of a period life table is an assumption \nthat conditions affecting mortality will not change throughout the lives of everyone in a cohort.\n9. Survival Data Identify the missing entries in the bottom row of the following table of sur-\nvival data.\n \n \n \nDay\n \nStatus  \n0 = Censored  \n1 = Death\n \n \nNumber of  \nPatients\n \n \nPatients Not \nDead\n \nProportion of \nPatients Not  \nDead\nCumulative  \nProportion of  \nPatients Not \nDead\n1\n1\n3\n2\n2>3 = 0.667\n0.667\n5\n1\n2\n1\n 1>2 = 0.5\n0.333\n8\n1\nChapter Quick Quiz\nCHAPTER 14 Chapter Quick Quiz \n619\n\n620 \nCHAPTER 14 Survival Analysis\n10. Life Table Refer to the following portion of the life table taken from Table 14-1. Find the \nprobability that a randomly selected 19-year-old person will live one year. Express the result \nusing six significant digits.\n \n \n \n \n \n \nAge  \nInterval\n \n \n \n \nProbability  \nof Dying  \nDuring the  \nInterval\n \n \nNumber  \nSurviving  \nto the  \nBeginning  \nof the  \nInterval\n \n \n \n \nNumber  \nof Deaths  \nDuring the \nInterval\nPerson-Years \nLived (total \ntime lived  \nduring the  \ninterval by \nthose alive at \nthe beginning \nof the interval)\n \n \nTotal  \nPerson-Years \nLived (in this \nand all  \nsubsequent  \nintervals)\n \n \nExpected  \nRemaining  \nLifetime  \n(from the  \nbeginning of \nthe interval)\n19–20\n0.000655\n98,975\n65\n98,942\n5,980,731\n60.4\nIn Exercises 1–5, refer to the accompanying life table for Hispanic females in the United \nStates for the year 2010.\nReview Exercises\nLife Table for Hispanic Females: U.S., 2010\n \n \n \n \n \n \nAge  \nInterval\n \n \n \n \nProbability \nof Dying \nDuring the \nInterval\n \n \nNumber \nSurviving \nto the  \nBeginning \nof the  \nInterval\n \n \n \n \nNumber \nof Deaths \nDuring the \nInterval\nPerson-Years \nLived (total \ntime lived \n during the  \ninterval by \nthose alive at \nthe beginning \nof the interval)\n \nTotal  \nPerson-\nYears Lived \n(in this  \nand all \nsubsequent \nintervals)\n \nExpected \nRemaining \nLifetime \n(from the \nbeginning \nof the  \ninterval)\n0–1\n0.004729\n100,000\n473\n99,588\n8,382,303\n83.8\n1–2\n 99,527\n99,510\n8,282,715\n83.2\n2–3\n0.000194\n 99,492\n 19\n99,482\n8,183,206\n82.2\nFrom National Vital Statistics Reports, U.S. Department of Health and Human Services.\n1. Probability of Dying Find the missing value in the second column of the table.\n2. Finding the Number of Deaths Find the missing value in the fourth column of the table.\n3. Finding Survival Rate Find the probability that a Hispanic female will live from birth to \nher second birthday.\n4. Constructing an Abridged Table Assume that you want to use the given table for the \nconstruction of an abridged table with 0–2 as the first age interval. Find the values in the first \nrow of this abridged table.\n5. Expected Remaining Lifetime What is the expected remaining lifetime of a Hispanic fe-\nmale who was just born? What is the expected remaining lifetime of a Hispanic female who is \ncelebrating her first birthday? Compare those results and comment on the relationship between \nthem.\n6. Carpal Tunnel Syndrome For the purposes of a clinical trial, a patient undergoing surgery \nfor treatment of carpal tunnel syndrome was considered to survive if the patient had no retreat-\nments following surgery. Four patients underwent the surgery, and they were then followed up for \n30 days with these results: One patient required retreatment on day 3, a second patient required \nretreatment on day 12, a third patient required retreatment on day 20, and the fourth patient never \nrequired retreatment. Construct a table containing survival data and the Kaplan-Meier calculations.\n7. Graph of Cumulative Survival Construct the cumulative survival (probability) graph for \nthe completed table from Exercise 6.\n\n8. Graph of Cumulative Survival In the accompanying cumulative survival graph, which \ngroup had better overall success: the treatment group or the placebo group? What does the \ngraph suggest about the effectiveness of the treatment?\nIn Exercises 1–4, refer to the same life table used for Review Exercises 1–5.\n1. Hypothesis Test of Experimental Results In one region, a comprehensive community-\nwide program is implemented in an attempt to reduce the rate of mortality for young Hispanic \nfemales. Results from this program show that among 1328 births of Hispanic females, 1323 \nsurvived to their second birthday and 5 did not survive to their second birthday. Using the data \nin the life table for Hispanic females, test the claim that the program was effective in reducing \nthe mortality rate.\n2. Confidence Interval for Experimental Results Given the sample results from Cumula-\ntive Review Exercise 1, construct a 95% confidence interval for the survival rate (from birth to \nthe second birthday) for Hispanic females born in the region with the mortality reduction pro-\ngram in effect. Instead of using three significant digits, express the results with five significant \ndigits. What can be concluded about the fact that the confidence interval limits do (or do not) \ncontain the survival rate for Hispanic females, as suggested by the life table?\n3. Probability of Surviving If three different newborn Hispanic females are randomly se-\nlected, find the probability that they all survive to their first birthday.\n4. Probability of Surviving If four different newborn Hispanic females are randomly selected, \nfind the probability that at least one of them does not survive to her first birthday. Does this \nprobability apply to families in which there are four children, all of whom are Hispanic females?\n5. Internet Doctors In a survey of n = 2015 adults, 1108 of them said that they learn about medi-\ncal symptoms more often from the Internet than from their doctor (based on a MerckManuals.com \nreport). The accompanying graph was created to depict the results of the survey. Is the graph \nsomehow misleading? If so, how?\nCumulative Review Exercises\nCHAPTER 14 Cumulative Review Exercises \n621\n\n622 \nCHAPTER 14 Survival Analysis\n6. Heights Based on Data Set 1 “Body Data” in Appendix B, assume that heights of men are \nnormally distributed with a mean of 68.6 in. and a standard deviation of 2.8 in.\na. The U.S. Coast Guard requires that its men must have a height between 60 in. and 80 in. \nFind the percentage of men who satisfy that height requirement.\nb. Find the probability that 4 randomly selected men have heights with a mean greater than 70 in.\nTechnology Project\nIn Section 14-2 it was noted that some technologies, such as Minitab, JMP, SPSS, and XLSTAT-\nLife, can automatically generate Kaplan-Meier cumulative survival curves. Use a technology \ncapable of generating Kaplan-Meier cumulative survival curves and generate the graph corre-\nsponding to the following survival data for 20 patients who were treated with heart surgery. The \nstatus of 1 indicates that the patient required a follow-up treatment after the surgery; the status of \n0 represents a censored patient. Use the graph to estimate the seven-day survival rate, which is \nthe proportion of patients not requiring follow-up treatment.\nDay\n1\n5\n6\n9\n14\n23\n25\n27\n29\nStatus\n1\n1\n0\n1\n 1\n 1\n 1\n 0\n 1\nFROM DATA TO DECISION\nCritical Thinking: How do we reduce the high mortality rate among young black females?\nCompare the following life tables for black females and white females\nLife Tables for Females: U.S., 2010\n \n \n \n \n \nAge  \nInterval\n \n \n \n \nProbability of \nDying During \nthe Interval\n \n \n \nNumber  \nSurviving to \nthe Beginning \nof the Interval\n \n \n \n \nNumber of \nDeaths During \nthe Interval\nPerson-Years \nLived (total time \nlived during the \ninterval by those \nalive at the be-\nginning of the \ninterval)\n \n \nTotal Person-\nYears Lived \n(in this and all \nsubsequent \nintervals)\n \n \nExpected  \nRemaining Life-\ntime (from the \nbeginning of the \ninterval)\nBlack Females\n0–1\n0.010472\n100,000\n1,047\n99,075\n7,799,627\n78.0\n1–2\n0.000596\n 98,953\n59\n98,923\n7,700,551\n77.8\n2–3\n0.000339\n 98,894\n34\n98,877\n7,601,628\n76.9\nWhite Females\n0–1\n0.004710\n100,000\n471\n99,588\n8,128,871\n81.3\n1–2\n0.000382\n 99,529\n38\n99,510\n8,029,283\n80.7\n2–3\n0.000204\n 99,491\n20\n99,481\n7,929,773\n79.7\nFrom National Vital Statistics Reports, U.S. Department of Health and Human Services.\nAnalyze the Results\n1. What notable differences are apparent?\n2. Identify some reasons for the apparent differences.\n3. What are some steps that could be taken to effectively re-\nduce the high rate of mortality among young black females?\n4. What is a reasonable response to someone who argues that \na program for reducing mortality among young black females \nshould not be implemented because it discriminates on the \nbasis of race?\n\n1. In-class activity Table 14-1 on pages 606-607 describes the life and death experience of a \nhypothetical group of 100,000 people. That table was constructed using actual results obtained \nfrom a variety of different sources. Instead of using real sources of vital statistics, assume that \nthe death rate of some population is a constant 0.4 for each year. Construct as much of the life \ntable as possible. How many years will pass before none of the hypothetical population of \n100,000 people are alive?\n2. Out-of-class activity Repeat Cooperative Group Activity 1, but instead of using a constant \ndeath rate of 0.4 each year, use a computer or calculator to randomly generate the death rate for \neach year. For each year, generate a random number between 0 and 1, and assume that it is the \ndeath rate that applies to the particular year.\n3. Out-of-class activity Obtain Life Tables for Total Population: U.S. for years prior to 2010 \nand compare them. What are your observations? If differences exist, what do you think may \naccount for changes in these life tables over time?\nCooperative Group Activities\nCHAPTER 14 Cooperative Group Activities \n623\n\nThis page intentionally left blank\n\n625\nTables\nAPPENDIX A\nTABLE A-1  Binomial Probabilities\np\nn\nx\n.01\n.05\n.10\n.20\n.30\n.40\n.50\n.60\n.70\n.80\n.90\n.95\n.99\nx\n2\n0\n.980\n.903\n.810\n.640\n.490\n.360\n.250\n.160\n.090\n.040\n.010\n.003\n 0+\n0\n1\n.020\n.095\n.180\n.320\n.420\n.480\n.500\n.480\n.420\n.320\n.180\n.095\n.020\n1\n2\n 0+\n.003\n.010\n.040\n.090\n.160\n.250\n.360\n.490\n.640\n.810\n.903\n.980\n2\n3\n0\n.970\n.857\n.729\n.512\n.343\n.216\n.125\n.064\n.027\n.008\n.001\n 0+\n 0+\n0\n1\n.029\n.135\n.243\n.384\n.441\n.432\n.375\n.288\n.189\n.096\n.027\n.007\n 0+\n1\n2\n 0+\n.007\n.027\n.096\n.189\n.288\n.375\n.432\n.441\n.384\n.243\n.135\n.029\n2\n3\n 0+\n 0+\n.001\n.008\n.027\n.064\n.125\n.216\n.343\n.512\n.729\n.857\n.970\n3\n4\n0\n.961\n.815\n.656\n.410\n.240\n.130\n.063\n.026\n.008\n.002\n 0+\n 0+\n 0+\n0\n1\n.039\n.171\n.292\n.410\n.412\n.346\n.250\n.154\n.076\n.026\n.004\n 0+\n 0+\n1\n2\n.001\n.014\n.049\n.154\n.265\n.346\n.375\n.346\n.265\n.154\n.049\n.014\n.001\n2\n3\n 0+\n 0+\n.004\n.026\n.076\n.154\n.250\n.346\n.412\n.410\n.292\n.171\n.039\n3\n4\n 0+\n 0+\n 0+\n.002\n.008\n.026\n.063\n.130\n.240\n.410\n.656\n.815\n.961\n4\n5\n0\n.951\n.774\n.590\n.328\n.168\n.078\n.031\n.010\n.002\n 0+\n 0+\n 0+\n 0+\n0\n1\n.048\n.204\n.328\n.410\n.360\n.259\n.156\n.077\n.028\n.006\n 0+\n 0+\n 0+\n1\n2\n.001\n.021\n.073\n.205\n.309\n.346\n.313\n.230\n.132\n.051\n.008\n.001\n 0+\n2\n3\n 0+\n.001\n.008\n.051\n.132\n.230\n.313\n.346\n.309\n.205\n.073\n.021\n.001\n3\n4\n 0+\n 0+\n 0+\n.006\n.028\n.077\n.156\n.259\n.360\n.410\n.328\n.204\n.048\n4\n5\n 0+\n 0+\n 0+\n 0+\n.002\n.010\n.031\n.078\n.168\n.328\n.590\n.774\n.951\n5\n6\n0\n.941\n.735\n.531\n.262\n.118\n.047\n.016\n.004\n.001\n 0+\n 0+\n 0+\n 0+\n0\n1\n.057\n.232\n.354\n.393\n.303\n.187\n.094\n.037\n.010\n.002\n 0+\n 0+\n 0+\n1\n2\n.001\n.031\n.098\n.246\n.324\n.311\n.234\n.138\n.060\n.015\n.001\n 0+\n 0+\n2\n3\n0+\n.002\n.015\n.082\n.185\n.276\n.312\n.276\n.185\n.082\n.015\n.002\n 0+\n3\n4\n0+\n 0+\n.001\n.015\n.060\n.138\n.234\n.311\n.324\n.246\n.098\n.031\n.001\n4\n5\n 0+\n 0+\n 0+\n.002\n.010\n.037\n.094\n.187\n.303\n.393\n.354\n.232\n.057\n5\n6\n 0+\n 0+\n 0+\n 0+\n.001\n.004\n.016\n.047\n.118\n.262\n.531\n.735\n.941\n6\n7\n0\n.932\n.698\n.478\n.210\n.082\n.028\n.008\n.002\n 0+\n 0+\n 0+\n 0+\n 0+\n0\n1\n.066\n.257\n.372\n.367\n.247\n.131\n.055\n.017\n.004\n 0+\n 0+\n 0+\n 0+\n1\n2\n.002\n.041\n.124\n.275\n.318\n.261\n.164\n.077\n.025\n.004\n 0+\n 0+\n 0+\n2\n3\n 0+\n.004\n.023\n.115\n.227\n.290\n.273\n.194\n.097\n.029\n.003\n 0+\n 0+\n3\n4\n 0+\n 0+\n.003\n.029\n.097\n.194\n.273\n.290\n.227\n.115\n.023\n.004\n 0+\n4\n5\n 0+\n 0+\n 0+\n.004\n.025\n.077\n.164\n.261\n.318\n.275\n.124\n.041\n.002\n5\n6\n 0+\n 0+\n 0+\n 0+\n.004\n.017\n.055\n.131\n.247\n.367\n.372\n.257\n.066\n6\n7\n 0+\n 0+\n 0+\n 0+\n 0+\n.002\n.008\n.028\n.082\n.210\n.478\n.698\n.932\n7\n8\n0\n.923\n.663\n.430\n.168\n.058\n.017\n.004\n.001\n 0+\n 0+\n 0+\n 0+\n 0+\n0\n1\n.075\n.279\n.383\n.336\n.198\n.090\n.031\n.008\n.001\n 0+\n 0+\n 0+\n 0+\n1\n2\n.003\n.051\n.149\n.294\n.296\n.209\n.109\n.041\n.010\n.001\n 0+\n 0+\n 0+\n2\n3\n 0+\n.005\n.033\n.147\n.254\n.279\n.219\n.124\n.047\n.009\n 0+\n 0+\n 0+\n3\n4\n 0+\n 0+\n.005\n.046\n.136\n.232\n.273\n.232\n.136\n.046\n.005\n 0+\n 0+\n4\n5\n 0+\n 0+\n 0+\n.009\n.047\n.124\n.219\n.279\n.254\n.147\n.033\n.005\n 0+\n5\n6\n 0+\n 0+\n 0+\n.001\n.010\n.041\n.109\n.209\n.296\n.294\n.149\n.051\n.003\n6\n7\n 0+\n 0+\n 0+\n 0+\n.001\n.008\n.031\n.090\n.198\n.336\n.383\n.279\n.075\n7\n8\n 0+\n 0+\n 0+\n 0+\n 0+\n.001\n.004\n.017\n.058\n.168\n.430\n.663\n.923\n8\nNOTE: 0+ represents a positive probability value less than 0.0005.\nFrom Frederick C. Mosteller, Robert E. K. Rourke, and George B. Thomas, Jr., Probability with Statistical Applications, 2nd ed., © 1970. Reprinted and electronically \nreproduced by permission of Pearson Education, Inc., Upper Saddle River, New Jersey.\n\n626\t\nAPPENDIX A  Tables\nTABLE A-2  Standard Normal (z) Distribution: Cumulative Area from the LEFT\nz\n.00\n.01\n.02\n.03\n.04\n.05\n.06\n.07\n.08\n.09\n-3.50 and \nlower\n \n.0001\n-3.4\n.0003\n.0003\n.0003\n.0003\n.0003\n.0003\n.0003\n.0003\n.0003\n.0002\n-3.3\n.0005\n.0005\n.0005\n.0004\n.0004\n.0004\n.0004\n.0004\n.0004\n.0003\n-3.2\n.0007\n.0007\n.0006\n.0006\n.0006\n.0006\n.0006\n.0005\n.0005\n.0005\n-3.1\n.0010\n.0009\n.0009\n.0009\n.0008\n.0008\n.0008\n.0008\n.0007\n.0007\n-3.0\n.0013\n.0013\n.0013\n.0012\n.0012\n.0011\n.0011\n.0011\n.0010\n.0010\n-2.9\n.0019\n.0018\n.0018\n.0017\n.0016\n.0016\n.0015\n.0015\n.0014\n.0014\n-2.8\n.0026\n.0025\n.0024\n.0023\n.0023\n.0022\n.0021\n.0021\n.0020\n.0019\n-2.7\n.0035\n.0034\n.0033\n.0032\n.0031\n.0030\n.0029\n.0028\n.0027\n.0026\n-2.6\n.0047\n.0045\n.0044\n.0043\n.0041\n.0040\n.0039\n.0038\n.0037\n.0036\n-2.5\n.0062\n.0060\n.0059\n.0057\n.0055\n.0054\n.0052\n.0051\n.0049\n.0048\n-2.4\n.0082\n.0080\n.0078\n.0075\n.0073\n.0071\n.0069\n.0068\n.0066\n.0064\n-2.3\n.0107\n.0104\n.0102\n.0099\n.0096\n.0094\n.0091\n.0089\n.0087\n.0084\n-2.2\n.0139\n.0136\n.0132\n.0129\n.0125\n.0122\n.0119\n.0116\n.0113\n.0110\n-2.1\n.0179\n.0174\n.0170\n.0166\n.0162\n.0158\n.0154\n.0150\n.0146\n.0143\n-2.0\n.0228\n.0222\n.0217\n.0212\n.0207\n.0202\n.0197\n.0192\n.0188\n.0183\n-1.9\n.0287\n.0281\n.0274\n.0268\n.0262\n.0256\n.0250\n.0244\n.0239\n.0233\n-1.8\n.0359\n.0351\n.0344\n.0336\n.0329\n.0322\n.0314\n.0307\n.0301\n.0294\n-1.7\n.0446\n.0436\n.0427\n.0418\n.0409\n.0401\n.0392\n.0384\n.0375\n.0367\n-1.6\n.0548\n.0537\n.0526\n.0516\n.0505\n.0495\n.0485\n.0475\n.0465\n.0455\n-1.5\n.0668\n.0655\n.0643\n.0630\n.0618\n.0606\n.0594\n.0582\n.0571\n.0559\n-1.4\n.0808\n.0793\n.0778\n.0764\n.0749\n.0735\n.0721\n.0708\n.0694\n.0681\n-1.3\n.0968\n.0951\n.0934\n.0918\n.0901\n.0885\n.0869\n.0853\n.0838\n.0823\n-1.2\n.1151\n.1131\n.1112\n.1093\n.1075\n.1056\n.1038\n.1020\n.1003\n.0985\n-1.1\n.1357\n.1335\n.1314\n.1292\n.1271\n.1251\n.1230\n.1210\n.1190\n.1170\n-1.0\n.1587\n.1562\n.1539\n.1515\n.1492\n.1469\n.1446\n.1423\n.1401\n.1379\n-0.9\n.1841\n.1814\n.1788\n.1762\n.1736\n.1711\n.1685\n.1660\n.1635\n.1611\n-0.8\n.2119\n.2090\n.2061\n.2033\n.2005\n.1977\n.1949\n.1922\n.1894\n.1867\n-0.7\n.2420\n.2389\n.2358\n.2327\n.2296\n.2266\n.2236\n.2206\n.2177\n.2148\n-0.6\n.2743\n.2709\n.2676\n.2643\n.2611\n.2578\n.2546\n.2514\n.2483\n.2451\n-0.5\n.3085\n.3050\n.3015\n.2981\n.2946\n.2912\n.2877\n.2843\n.2810\n.2776\n-0.4\n.3446\n.3409\n.3372\n.3336\n.3300\n.3264\n.3228\n.3192\n.3156\n.3121\n-0.3\n.3821\n.3783\n.3745\n.3707\n.3669\n.3632\n.3594\n.3557\n.3520\n.3483\n-0.2\n.4207\n.4168\n.4129\n.4090\n.4052\n.4013\n.3974\n.3936\n.3897\n.3859\n-0.1\n.4602\n.4562\n.4522\n.4483\n.4443\n.4404\n.4364\n.4325\n.4286\n.4247\n-0.0\n.5000\n.4960\n.4920\n.4880\n.4840\n.4801\n.4761\n.4721\n.4681\n.4641\nNOTE: For values of z below -3.49, use 0.0001 for the area.\n*Use these common values that result from interpolation:\nNEGATIVE z Scores\nz Score\nArea\n-1.645\n0.0500\n-2.575\n0.0050\n(continued )\n0\nz\n*\n*\n\n\t\nAPPENDIX A  Tables\t\n627\nPOSITIVE z Scores\nTABLE A-2 (continued)  Cumulative Area from the LEFT\nz\n.00\n.01\n.02\n.03\n.04\n.05\n.06\n.07\n.08\n.09\n0.0\n.5000\n.5040\n.5080\n.5120\n.5160\n.5199\n.5239\n.5279\n.5319\n.5359\n0.1\n.5398\n.5438\n.5478\n.5517\n.5557\n.5596\n.5636\n.5675\n.5714\n.5753\n0.2\n.5793\n.5832\n.5871\n.5910\n.5948\n.5987\n.6026\n.6064\n.6103\n.6141\n0.3\n.6179\n.6217\n.6255\n.6293\n.6331\n.6368\n.6406\n.6443\n.6480\n.6517\n0.4\n.6554\n.6591\n.6628\n.6664\n.6700\n.6736\n.6772\n.6808\n.6844\n.6879\n0.5\n.6915\n.6950\n.6985\n.7019\n.7054\n.7088\n.7123\n.7157\n.7190\n.7224\n0.6\n.7257\n.7291\n.7324\n.7357\n.7389\n.7422\n.7454\n.7486\n.7517\n.7549\n0.7\n.7580\n.7611\n.7642\n.7673\n.7704\n.7734\n.7764\n.7794\n.7823\n.7852\n0.8\n.7881\n.7910\n.7939\n.7967\n.7995\n.8023\n.8051\n.8078\n.8106\n.8133\n0.9\n.8159\n.8186\n.8212\n.8238\n.8264\n.8289\n.8315\n.8340\n.8365\n.8389\n1.0\n.8413\n.8438\n.8461\n.8485\n.8508\n.8531\n.8554\n.8577\n.8599\n.8621\n1.1\n.8643\n.8665\n.8686\n.8708\n.8729\n.8749\n.8770\n.8790\n.8810\n.8830\n1.2\n.8849\n.8869\n.8888\n.8907\n.8925\n.8944\n.8962\n.8980\n.8997\n.9015\n1.3\n.9032\n.9049\n.9066\n.9082\n.9099\n.9115\n.9131\n.9147\n.9162\n.9177\n1.4\n.9192\n.9207\n.9222\n.9236\n.9251\n.9265\n.9279\n.9292\n.9306\n.9319\n1.5\n.9332\n.9345\n.9357\n.9370\n.9382\n.9394\n.9406\n.9418\n.9429\n.9441\n1.6\n.9452\n.9463\n.9474\n.9484\n.9495\n.9505\n.9515\n.9525\n.9535\n.9545\n1.7\n.9554\n.9564\n.9573\n.9582\n.9591\n.9599\n.9608\n.9616\n.9625\n.9633\n1.8\n.9641\n.9649\n.9656\n.9664\n.9671\n.9678\n.9686\n.9693\n.9699\n.9706\n1.9\n.9713\n.9719\n.9726\n.9732\n.9738\n.9744\n.9750\n.9756\n.9761\n.9767\n2.0\n.9772\n.9778\n.9783\n.9788\n.9793\n.9798\n.9803\n.9808\n.9812\n.9817\n2.1\n.9821\n.9826\n.9830\n.9834\n.9838\n.9842\n.9846\n.9850\n.9854\n.9857\n2.2\n.9861\n.9864\n.9868\n.9871\n.9875\n.9878\n.9881\n.9884\n.9887\n.9890\n2.3\n.9893\n.9896\n.9898\n.9901\n.9904\n.9906\n.9909\n.9911\n.9913\n.9916\n2.4\n.9918\n.9920\n.9922\n.9925\n.9927\n.9929\n.9931\n.9932\n.9934\n.9936\n2.5\n.9938\n.9940\n.9941\n.9943\n.9945\n.9946\n.9948\n.9949\n.9951\n.9952\n2.6\n.9953\n.9955\n.9956\n.9957\n.9959\n.9960\n.9961\n.9962\n.9963\n.9964\n2.7\n.9965\n.9966\n.9967\n.9968\n.9969\n.9970\n.9971\n.9972\n.9973\n.9974\n2.8\n.9974\n.9975\n.9976\n.9977\n.9977\n.9978\n.9979\n.9979\n.9980\n.9981\n2.9\n.9981\n.9982\n.9982\n.9983\n.9984\n.9984\n.9985\n.9985\n.9986\n.9986\n3.0\n.9987\n.9987\n.9987\n.9988\n.9988\n.9989\n.9989\n.9989\n.9990\n.9990\n3.1\n.9990\n.9991\n.9991\n.9991\n.9992\n.9992\n.9992\n.9992\n.9993\n.9993\n3.2\n.9993\n.9993\n.9994\n.9994\n.9994\n.9994\n.9994\n.9995\n.9995\n.9995\n3.3\n.9995\n.9995\n.9995\n.9996\n.9996\n.9996\n.9996\n.9996\n.9996\n.9997\n3.4\n.9997\n.9997\n.9997\n.9997\n.9997\n.9997\n.9997\n.9997\n.9997\n.9998\n3.50 and up\n.9999\nNOTE: For values of z above 3.49, use 0.9999 for the area.\n*Use these common values that result from interpolation:\nCommon Critical Values\nConfidence\nLevel\nCritical\nValue\n0.90\n1.645\n0.95\n1.96\n0.99\n2.575\nz Score\nArea\n1.645\n0.9500\n2.575\n0.9950\n*\n*\n0\nz\n\n628\t\nAPPENDIX A  Tables\nTABLE A-3  t Distribution: Critical t Values\n \n0.005\n \n0.01\nArea in One Tail \n0.025\n \n0.05\n \n0.10\nDegrees of \nFreedom\n \n0.01\n \n0.02\nArea in Two Tails \n0.05\n \n0.10\n \n0.20\n  1\n \n63.657\n    31.821\n    12.706\n6.314\n3.078\n  2\n9.925\n6.965\n4.303\n2.920\n1.886\n  3\n5.841\n4.541\n3.182\n2.353\n1.638\n  4\n4.604\n3.747\n2.776\n2.132\n1.533\n  5\n4.032\n3.365\n2.571\n2.015\n1.476\n  6\n3.707\n3.143\n2.447\n1.943\n1.440\n  7\n3.499\n2.998\n2.365\n1.895\n1.415\n  8\n3.355\n2.896\n2.306\n1.860\n1.397\n  9\n3.250\n2.821\n2.262\n1.833\n1.383\n10\n3.169\n2.764\n2.228\n1.812\n1.372\n11\n3.106\n2.718\n2.201\n1.796\n1.363\n12\n3.055\n2.681\n2.179\n1.782\n1.356\n13\n3.012\n2.650\n2.160\n1.771\n1.350\n14\n2.977\n2.624\n2.145\n1.761\n1.345\n15\n2.947\n2.602\n2.131\n1.753\n1.341\n16\n2.921\n2.583\n2.120\n1.746\n1.337\n17\n2.898\n2.567\n2.110\n1.740\n1.333\n18\n2.878\n2.552\n2.101\n1.734\n1.330\n19\n2.861\n2.539\n2.093\n1.729\n1.328\n20\n2.845\n2.528\n2.086\n1.725\n1.325\n21\n2.831\n2.518\n2.080\n1.721\n1.323\n22\n2.819\n2.508\n2.074\n1.717\n1.321\n23\n2.807\n2.500\n2.069\n1.714\n1.319\n24\n2.797\n2.492\n2.064\n1.711\n1.318\n25\n2.787\n2.485\n2.060\n1.708\n1.316\n26\n2.779\n2.479\n2.056\n1.706\n1.315\n27\n2.771\n2.473\n2.052\n1.703\n1.314\n28\n2.763\n2.467\n2.048\n1.701\n1.313\n29\n2.756\n2.462\n2.045\n1.699\n1.311\n30\n2.750\n2.457\n2.042\n1.697\n1.310\n31\n2.744\n2.453\n2.040\n1.696\n1.309\n32\n2.738\n2.449\n2.037\n1.694\n1.309\n33\n2.733\n2.445\n2.035\n1.692\n1.308\n34\n2.728\n2.441\n2.032\n1.691\n1.307\n35\n2.724\n2.438\n2.030\n1.690\n1.306\n36\n2.719\n2.434\n2.028\n1.688\n1.306\n37\n2.715\n2.431\n2.026\n1.687\n1.305\n38\n2.712\n2.429\n2.024\n1.686\n1.304\n39\n2.708\n2.426\n2.023\n1.685\n1.304\n40\n2.704\n2.423\n2.021\n1.684\n1.303\n45\n2.690\n2.412\n2.014\n1.679\n1.301\n50\n2.678\n2.403\n2.009\n1.676\n1.299\n60\n2.660\n2.390\n2.000\n1.671\n1.296\n70\n2.648\n2.381\n1.994\n1.667\n1.294\n80\n2.639\n2.374\n1.990\n1.664\n1.292\n90\n2.632\n2.368\n1.987\n1.662\n1.291\n100\n2.626\n2.364\n1.984\n1.660\n1.290\n200\n2.601\n2.345\n1.972\n1.653\n1.286\n300\n2.592\n2.339\n1.968\n1.650\n1.284\n400\n2.588\n2.336\n1.966\n1.649\n1.284\n500\n2.586\n2.334\n1.965\n1.648\n1.283\n1000\n2.581\n2.330\n1.962\n1.646\n1.282\n2000\n2.578\n2.328\n1.961\n1.646\n1.282\nLarge\n2.576\n2.326\n1.960\n1.645\n1.282\nCritical t value\n(negative)\na\nLeft tail\nCritical t value\n(positive)\na\nRight tail\nCritical t value\n(positive)\nCritical t value\n(negative)\na\u001f2\na\u001f2\nTwo tails\n\n\t\nAPPENDIX A  Tables\t\n629\nTABLE A-4  Chi-Square 1x22 Distribution\nArea to the Right of the Critical Value\nDegrees of \nFreedom\n \n  0.995\n \n0.99\n \n  0.975\n \n0.95\n \n0.90\n \n  0.10\n \n  0.05\n \n    0.025\n \n  0.01\n \n    0.005\n  1\n—\n—\n  0.001\n  0.004\n  0.016\n    2.706\n    3.841\n    5.024\n    6.635\n    7.879\n  2\n  0.010\n  0.020\n  0.051\n  0.103\n  0.211\n    4.605\n    5.991\n    7.378\n    9.210\n  10.597\n  3\n  0.072\n  0.115\n  0.216\n  0.352\n  0.584\n    6.251\n    7.815\n    9.348\n  11.345\n  12.838\n  4\n  0.207\n  0.297\n  0.484\n  0.711\n  1.064\n    7.779\n    9.488\n  11.143\n  13.277\n  14.860\n  5\n  0.412\n  0.554\n  0.831\n  1.145\n  1.610\n    9.236\n  11.071\n  12.833\n  15.086\n  16.750\n  6\n  0.676\n  0.872\n  1.237\n  1.635\n  2.204\n  10.645\n  12.592\n  14.449\n  16.812\n  18.548\n  7\n  0.989\n  1.239\n  1.690\n  2.167\n  2.833\n  12.017\n  14.067\n  16.013\n  18.475\n  20.278\n  8\n  1.344\n  1.646\n  2.180\n  2.733\n  3.490\n  13.362\n  15.507\n  17.535\n  20.090\n  21.955\n  9\n  1.735\n  2.088\n  2.700\n  3.325\n  4.168\n  14.684\n  16.919\n  19.023\n  21.666\n  23.589\n10\n  2.156\n  2.558\n  3.247\n  3.940\n  4.865\n  15.987\n  18.307\n  20.483\n  23.209\n  25.188\n11\n  2.603\n  3.053\n  3.816\n  4.575\n  5.578\n  17.275\n  19.675\n  21.920\n  24.725\n  26.757\n12\n  3.074\n  3.571\n  4.404\n  5.226\n  6.304\n  18.549\n  21.026\n  23.337\n  26.217\n  28.299\n13\n  3.565\n  4.107\n  5.009\n  5.892\n  7.042\n  19.812\n  22.362\n  24.736\n  27.688\n  29.819\n14\n  4.075\n  4.660\n  5.629\n  6.571\n  7.790\n  21.064\n  23.685\n  26.119\n  29.141\n  31.319\n15\n  4.601\n  5.229\n  6.262\n  7.261\n  8.547\n  22.307\n  24.996\n  27.488\n  30.578\n  32.801\n16\n  5.142\n  5.812\n  6.908\n  7.962\n  9.312\n  23.542\n  26.296\n  28.845\n  32.000\n  34.267\n17\n  5.697\n  6.408\n  7.564\n  8.672\n10.085\n  24.769\n  27.587\n  30.191\n  33.409\n  35.718\n18\n  6.265\n  7.015\n  8.231\n  9.390\n10.865\n  25.989\n  28.869\n  31.526\n  34.805\n  37.156\n19\n  6.844\n  7.633\n  8.907\n10.117\n11.651\n  27.204\n  30.144\n  32.852\n  36.191\n  38.582\n20\n  7.434\n  8.260\n  9.591\n10.851\n12.443\n  28.412\n  31.410\n  34.170\n  37.566\n  39.997\n21\n  8.034\n  8.897\n10.283\n11.591\n13.240\n  29.615\n  32.671\n  35.479\n  38.932\n  41.401\n22\n  8.643\n  9.542\n10.982\n12.338\n14.042\n  30.813\n  33.924\n  36.781\n  40.289\n  42.796\n23\n  9.260\n10.196\n11.689\n13.091\n14.848\n  32.007\n  35.172\n  38.076\n  41.638\n  44.181\n24\n  9.886\n10.856\n12.401\n13.848\n15.659\n  33.196\n  36.415\n  39.364\n  42.980\n  45.559\n25\n10.520\n11.524\n13.120\n14.611\n16.473\n  34.382\n  37.652\n  40.646\n  44.314\n  46.928\n26\n11.160\n12.198\n13.844\n15.379\n17.292\n  35.563\n  38.885\n  41.923\n  45.642\n  48.290\n27\n11.808\n12.879\n14.573\n16.151\n18.114\n  36.741\n  40.113\n  43.194\n  46.963\n  49.645\n28\n12.461\n13.565\n15.308\n16.928\n18.939\n  37.916\n  41.337\n  44.461\n  48.278\n  50.993\n29\n13.121\n14.257\n16.047\n17.708\n19.768\n  39.087\n  42.557\n  45.722\n  49.588\n  52.336\n30\n13.787\n14.954\n16.791\n18.493\n20.599\n  40.256\n  43.773\n  46.979\n  50.892\n  53.672\n40\n20.707\n22.164\n24.433\n26.509\n29.051\n  51.805\n  55.758\n  59.342\n  63.691\n  66.766\n50\n27.991\n29.707\n32.357\n34.764\n37.689\n  63.167\n  67.505\n  71.420\n  76.154\n  79.490\n60\n35.534\n37.485\n40.482\n43.188\n46.459\n  74.397\n  79.082\n  83.298\n  88.379\n  91.952\n70\n43.275\n45.442\n48.758\n51.739\n55.329\n  85.527\n  90.531\n  95.023\n100.425\n104.215\n80\n51.172\n53.540\n57.153\n60.391\n64.278\n  96.578\n101.879\n106.629\n112.329\n116.321\n90\n59.196\n61.754\n65.647\n69.126\n73.291\n107.565\n113.145\n118.136\n124.116\n128.299\n100\n67.328\n70.065\n74.222\n77.929\n82.358\n118.498\n124.342\n129.561\n135.807\n140.169\nSource: Donald B. Owen, Handbook of Statistical Tables.\nDegrees of Freedom\nn - 1\nConfidence interval or hypothesis test for a standard deviation s or variance s2\nk - 1\nGoodness-of-fit test with k different categories\n(r - 1)(c - 1)\nContingency table test with r rows and c columns\nk - 1\nKruskal-Wallis test with k different samples\n\n630\t\nAPPENDIX A  Tables\nTABLE A-5  F Distribution (a = 0.025 in the right tail)\nNumerator degrees of freedom (df1)\n1\n2\n3\n4\n5\n6\n7\n8\n9\nDenominator degrees of freedom (df2)\n    1\n  647.79\n  799.50\n  864.16\n  899.58\n  921.85\n  937.11\n  948.22\n  956.66\n  963.28\n    2\n    38.506\n    39.000\n    39.165\n    39.248\n    39.298\n    39.331\n    39.335\n    39.373\n    39.387\n    3\n    17.443\n    16.044\n    15.439\n    15.101\n    14.885\n    14.735\n    14.624\n    14.540\n    14.473\n    4\n    12.218\n    10.649\n9.9792\n9.6045\n9.3645\n9.1973\n9.0741\n8.9796\n8.9047\n    5\n    10.007\n8.4336\n7.7636\n7.3879\n7.1464\n6.9777\n6.8531\n6.7572\n6.6811\n    6\n8.8131\n7.2599\n6.5988\n6.2272\n5.9876\n5.8198\n5.6955\n5.5996\n5.5234\n    7\n8.0727\n6.5415\n5.8898\n5.5226\n5.2852\n5.1186\n4.9949\n4.8993\n4.8232\n    8\n7.5709\n6.0595\n5.4160\n5.0526\n4.8173\n4.6517\n4.5286\n4.4333\n4.3572\n    9\n7.2093\n5.7147\n5.0781\n4.7181\n4.4844\n4.3197\n4.1970\n4.1020\n4.0260\n  10\n6.9367\n5.4564\n4.8256\n4.4683\n4.2361\n4.0721\n3.9498\n3.8549\n3.7790\n  11\n6.7241\n5.2559\n4.6300\n4.2751\n4.0440\n3.8807\n3.7586\n3.6638\n3.5879\n  12\n6.5538\n5.0959\n4.4742\n4.1212\n3.8911\n3.7283\n3.6065\n3.5118\n3.4358\n  13\n6.4143\n4.9653\n4.3472\n3.9959\n3.7667\n3.6043\n3.4827\n3.3880\n3.3120\n  14\n6.2979\n4.8567\n4.2417\n3.8919\n3.6634\n3.5014\n3.3799\n3.2853\n3.2093\n  15\n6.1995\n4.7650\n4.1528\n3.8043\n3.5764\n3.4147\n3.2934\n3.1987\n3.1227\n  16\n6.1151\n4.6867\n4.0768\n3.7294\n3.5021\n3.3406\n3.2194\n3.1248\n3.0488\n  17\n6.0420\n4.6189\n4.0112\n3.6648\n3.4379\n3.2767\n3.1556\n3.0610\n2.9849\n  18\n5.9781\n4.5597\n3.9539\n3.6083\n3.3820\n3.2209\n3.0999\n3.0053\n2.9291\n  19\n5.9216\n4.5075\n3.9034\n3.5587\n3.3327\n3.1718\n3.0509\n2.9563\n2.8801\n  20\n5.8715\n4.4613\n3.8587\n3.5147\n3.2891\n3.1283\n3.0074\n2.9128\n2.8365\n  21\n5.8266\n4.4199\n3.8188\n3.4754\n3.2501\n3.0895\n2.9686\n2.8740\n2.7977\n  22\n5.7863\n4.3828\n3.7829\n3.4401\n3.2151\n3.0546\n2.9338\n2.8392\n2.7628\n  23\n5.7498\n4.3492\n3.7505\n3.4083\n3.1835\n3.0232\n2.9023\n2.8077\n2.7313\n  24\n5.7166\n4.3187\n3.7211\n3.3794\n3.1548\n2.9946\n2.8738\n2.7791\n2.7027\n  25\n5.6864\n4.2909\n3.6943\n3.3530\n3.1287\n2.9685\n2.8478\n2.7531\n2.6766\n  26\n5.6586\n4.2655\n3.6697\n3.3289\n3.1048\n2.9447\n2.8240\n2.7293\n2.6528\n  27\n5.6331\n4.2421\n3.6472\n3.3067\n3.0828\n2.9228\n2.8021\n2.7074\n2.6309\n  28\n5.6096\n4.2205\n3.6264\n3.2863\n3.0626\n2.9027\n2.7820\n2.6872\n2.6106\n  29\n5.5878\n4.2006\n3.6072\n3.2674\n3.0438\n2.8840\n2.7633\n2.6686\n2.5919\n  30\n5.5675\n4.1821\n3.5894\n3.2499\n3.0265\n2.8667\n2.7460\n2.6513\n2.5746\n  40\n5.4239\n4.0510\n3.4633\n3.1261\n2.9037\n2.7444\n2.6238\n2.5289\n2.4519\n  60\n5.2856\n3.9253\n3.3425\n3.0077\n2.7863\n2.6274\n2.5068\n2.4117\n2.3344\n120\n5.1523\n3.8046\n3.2269\n2.8943\n2.6740\n2.5154\n2.3948\n2.2994\n2.2217\n∞\n5.0239\n3.6889\n3.1161\n2.7858\n2.5665\n2.4082\n2.2875\n2.1918\n2.1136\n(continued )\nF\n0.025\n\n\t\nAPPENDIX A  Tables\t\n631\nTABLE A-5  (continued) F Distribution (a = 0.025 in the right tail)\nNumerator degrees of freedom (df1)\n10\n12\n15\n20\n24\n30\n40\n60\n120\n∞\nDenominator degrees of freedom (df2)\n    1\n 968.63\n 976.71\n 984.87\n 993.10\n 997.25\n 1001.4\n 1005.6\n 1009.8\n 1014.0\n 1018.3\n    2\n   39.398\n   39.415\n   39.431\n   39.448\n   39.456\n   39.465\n   39.473\n   39.481\n   39.490\n   39.498\n    3\n   14.419\n   14.337\n   14.253\n   14.167\n   14.124\n   14.081\n   14.037\n   13.992\n   13.947\n   13.902\n    4\n8.8439\n8.7512\n8.6565\n8.5599\n8.5109\n8.4613\n8.4111\n8.3604\n8.3092\n8.2573\n    5\n6.6192\n6.5245\n6.4277\n6.3286\n6.2780\n6.2269\n6.1750\n6.1225\n6.0693\n6.0153\n    6\n5.4613\n5.3662\n5.2687\n5.1684\n5.1172\n5.0652\n5.0125\n4.9589\n4.9044\n4.8491\n    7\n4.7611\n4.6658\n4.5678\n4.4667\n4.4150\n4.3624\n4.3089\n4.2544\n4.1989\n4.1423\n    8\n4.2951\n4.1997\n4.1012\n3.9995\n3.9472\n3.8940\n3.8398\n3.7844\n3.7279\n3.6702\n    9\n3.9639\n3.8682\n3.7694\n3.6669\n3.6142\n3.5604\n3.5055\n3.4493\n3.3918\n3.3329\n  10\n3.7168\n3.6209\n3.5217\n3.4185\n3.3654\n3.3110\n3.2554\n3.1984\n3.1399\n3.0798\n  11\n3.5257\n3.4296\n3.3299\n3.2261\n3.1725\n3.1176\n3.0613\n3.0035\n2.9441\n2.8828\n  12\n3.3736\n3.2773\n3.1772\n3.0728\n3.0187\n2.9633\n2.9063\n2.8478\n2.7874\n2.7249\n  13\n3.2497\n3.1532\n3.0527\n2.9477\n2.8932\n2.8372\n2.7797\n2.7204\n2.6590\n2.5955\n  14\n3.1469\n3.0502\n2.9493\n2.8437\n2.7888\n2.7324\n2.6742\n2.6142\n2.5519\n2.4872\n  15\n3.0602\n2.9633\n2.8621\n2.7559\n2.7006\n2.6437\n2.5850\n2.5242\n2.4611\n2.3953\n  16\n2.9862\n2.8890\n2.7875\n2.6808\n2.6252\n2.5678\n2.5085\n2.4471\n2.3831\n2.3163\n  17\n2.9222\n2.8249\n2.7230\n2.6158\n2.5598\n2.5020\n2.4422\n2.3801\n2.3153\n2.2474\n  18\n2.8664\n2.7689\n2.6667\n2.5590\n2.5027\n2.4445\n2.3842\n2.3214\n2.2558\n2.1869\n  19\n2.8172\n2.7196\n2.6171\n2.5089\n2.4523\n2.3937\n2.3329\n2.2696\n2.2032\n2.1333\n  20\n2.7737\n2.6758\n2.5731\n2.4645\n2.4076\n2.3486\n2.2873\n2.2234\n2.1562\n2.0853\n  21\n2.7348\n2.6368\n2.5338\n2.4247\n2.3675\n2.3082\n2.2465\n2.1819\n2.1141\n2.0422\n  22\n2.6998\n2.6017\n2.4984\n2.3890\n2.3315\n2.2718\n2.2097\n2.1446\n2.0760\n2.0032\n  23\n2.6682\n2.5699\n2.4665\n2.3567\n2.2989\n2.2389\n2.1763\n2.1107\n2.0415\n1.9677\n  24\n2.6396\n2.5411\n2.4374\n2.3273\n2.2693\n2.2090\n2.1460\n2.0799\n2.0099\n1.9353\n  25\n2.6135\n2.5149\n2.4110\n2.3005\n2.2422\n2.1816\n2.1183\n2.0516\n1.9811\n1.9055\n  26\n2.5896\n2.4908\n2.3867\n2.2759\n2.2174\n2.1565\n2.0928\n2.0257\n1.9545\n1.8781\n  27\n2.5676\n2.4688\n2.3644\n2.2533\n2.1946\n2.1334\n2.0693\n2.0018\n1.9299\n1.8527\n  28\n2.5473\n2.4484\n2.3438\n2.2324\n2.1735\n2.1121\n2.0477\n1.9797\n1.9072\n1.8291\n  29\n2.5286\n2.4295\n2.3248\n2.2131\n2.1540\n2.0923\n2.0276\n1.9591\n1.8861\n1.8072\n  30\n2.5112\n2.4120\n2.3072\n2.1952\n2.1359\n2.0739\n2.0089\n1.9400\n1.8664\n1.7867\n  40\n2.3882\n2.2882\n2.1819\n2.0677\n2.0069\n1.9429\n1.8752\n1.8028\n1.7242\n1.6371\n  60\n2.2702\n2.1692\n2.0613\n1.9445\n1.8817\n1.8152\n1.7440\n1.6668\n1.5810\n1.4821\n120\n2.1570\n2.0548\n1.9450\n1.8249\n1.7597\n1.6899\n1.6141\n1.5299\n1.4327\n1.3104\n∞\n2.0483\n1.9447\n1.8326\n1.7085\n1.6402\n1.5660\n1.4835\n1.3883\n1.2684\n1.0000\nBased on data from Maxine Merrington and Catherine M. Thompson, “Tables of Percentage Points of the Inverted Beta (F ) Distribution,” Biometrika 33 (1943): 80–84.\n\n632\t\nAPPENDIX A  Tables\nTABLE A-5  (continued) F Distribution (a = 0.05 in the right tail)\nNumerator degrees of freedom (df1)\n1\n2\n3\n4\n5\n6\n7\n8\n9\nDenominator degrees of freedom (df2)\n    1\n  161.45\n  199.50\n  215.71\n  224.58\n  230.16\n  233.99\n  236.77\n  238.88\n 240.54\n    2\n    18.513\n    19.000\n    19.164\n    19.247\n    19.296\n    19.330\n    19.353\n    19.371\n   19.385\n    3\n    10.128\n9.5521\n9.2766\n9.1172\n9.0135\n8.9406\n8.8867\n8.8452\n8.8123\n    4\n7.7086\n6.9443\n6.5914\n6.3882\n6.2561\n6.1631\n6.0942\n6.0410\n6.9988\n    5\n6.6079\n5.7861\n5.4095\n5.1922\n5.0503\n4.9503\n4.8759\n4.8183\n4.7725\n    6\n5.9874\n5.1433\n4.7571\n4.5337\n4.3874\n4.2839\n4.2067\n4.1468\n4.0990\n    7\n5.5914\n4.7374\n4.3468\n4.1203\n3.9715\n3.8660\n3.7870\n3.7257\n3.6767\n    8\n5.3177\n4.4590\n4.0662\n3.8379\n3.6875\n3.5806\n3.5005\n3.4381\n3.3881\n    9\n5.1174\n4.2565\n3.8625\n3.6331\n3.4817\n3.3738\n3.2927\n3.2296\n3.1789\n  10\n4.9646\n4.1028\n3.7083\n3.4780\n3.3258\n3.2172\n3.1355\n3.0717\n3.0204\n  11\n4.8443\n3.9823\n3.5874\n3.3567\n3.2039\n3.0946\n3.0123\n2.9480\n2.8962\n  12\n4.7472\n3.8853\n3.4903\n3.2592\n3.1059\n2.9961\n2.9134\n2.8486\n2.7964\n  13\n4.6672\n3.8056\n3.4105\n3.1791\n3.0254\n2.9153\n2.8321\n2.7669\n2.7144\n  14\n4.6001\n3.7389\n3.3439\n3.1122\n2.9582\n2.8477\n2.7642\n2.6987\n2.6458\n  15\n4.5431\n3.6823\n3.2874\n3.0556\n2.9013\n2.7905\n2.7066\n2.6408\n2.5876\n  16\n4.4940\n3.6337\n3.2389\n3.0069\n2.8524\n2.7413\n2.6572\n2.5911\n2.5377\n  17\n4.4513\n3.5915\n3.1968\n2.9647\n2.8100\n2.6987\n2.6143\n2.5480\n2.4943\n  18\n4.4139\n3.5546\n3.1599\n2.9277\n2.7729\n2.6613\n2.5767\n2.5102\n2.4563\n  19\n4.3807\n3.5219\n3.1274\n2.8951\n2.7401\n2.6283\n2.5435\n2.4768\n2.4227\n  20\n4.3512\n3.4928\n3.0984\n2.8661\n2.7109\n2.5990\n2.5140\n2.4471\n2.3928\n  21\n4.3248\n3.4668\n3.0725\n2.8401\n2.6848\n2.5727\n2.4876\n2.4205\n2.3660\n  22\n4.3009\n3.4434\n3.0491\n2.8167\n2.6613\n2.5491\n2.4638\n2.3965\n2.3419\n  23\n4.2793\n3.4221\n3.0280\n2.7955\n2.6400\n2.5277\n2.4422\n2.3748\n2.3201\n  24\n4.2597\n3.4028\n3.0088\n2.7763\n2.6207\n2.5082\n2.4226\n2.3551\n2.3002\n  25\n4.2417\n3.3852\n2.9912\n2.7587\n2.6030\n2.4904\n2.4047\n2.3371\n2.2821\n  26\n4.2252\n3.3690\n2.9752\n2.7426\n2.5868\n2.4741\n2.3883\n2.3205\n2.2655\n  27\n4.2100\n3.3541\n2.9604\n2.7278\n2.5719\n2.4591\n2.3732\n2.3053\n2.2501\n  28\n4.1960\n3.3404\n2.9467\n2.7141\n2.5581\n2.4453\n2.3593\n2.2913\n2.2360\n  29\n4.1830\n3.3277\n2.9340\n2.7014\n2.5454\n2.4324\n2.3463\n2.2783\n2.2229\n  30\n4.1709\n3.3158\n2.9223\n2.6896\n2.5336\n2.4205\n2.3343\n2.2662\n2.2107\n  40\n4.0847\n3.2317\n2.8387\n2.6060\n2.4495\n2.3359\n2.2490\n2.1802\n2.1240\n  60\n4.0012\n3.1504\n2.7581\n2.5252\n2.3683\n2.2541\n2.1665\n2.0970\n2.0401\n120\n3.9201\n3.0718\n2.6802\n2.4472\n2.2899\n2.1750\n2.0868\n2.0164\n1.9588\n∞\n3.8415\n2.9957\n2.6049\n2.3719\n2.2141\n2.0986\n2.0096\n1.9384\n1.8799\nF\n0.05\n(continued )\n\n\t\nAPPENDIX A  Tables\t\n633\nTABLE A-5  (continued) F Distribution (a = 0.05 in the right tail)\nNumerator degrees of freedom (df1)\n10\n12\n15\n20\n24\n30\n40\n60\n120\n∞\nDenominator degrees of freedom (df2)\n    1\n 241.88\n 243.91\n 245.95\n248.01\n 249.05\n 250.10\n 251.14\n 252.20\n 253.25\n 254.31\n    2\n   19.396\n   19.413\n   19.429\n19.446\n   19.454\n   19.462\n   19.471\n   19.479\n   19.487\n   19.496\n    3\n8.7855\n8.7446\n8.7029\n8.6602\n8.6385\n8.6166\n8.5944\n8.5720\n8.5494\n8.5264\n    4\n5.9644\n5.9117\n5.8578\n5.8025\n5.7744\n5.7459\n5.7170\n5.6877\n5.6581\n5.6281\n    5\n4.7351\n4.6777\n4.6188\n4.5581\n4.5272\n4.4957\n4.4638\n4.4314\n4.3985\n4.3650\n    6\n4.0600\n3.9999\n3.9381\n3.8742\n3.8415\n3.8082\n3.7743\n3.7398\n3.7047\n3.6689\n    7\n3.6365\n3.5747\n3.5107\n3.4445\n3.4105\n3.3758\n3.3404\n3.3043\n3.2674\n3.2298\n    8\n3.3472\n3.2839\n3.2184\n3.1503\n3.1152\n3.0794\n3.0428\n3.0053\n2.9669\n2.9276\n    9\n3.1373\n3.0729\n3.0061\n2.9365\n2.9005\n2.8637\n2.8259\n2.7872\n2.7475\n2.7067\n  10\n2.9782\n2.9130\n2.8450\n2.7740\n2.7372\n2.6996\n2.6609\n2.6211\n2.5801\n2.5379\n  11\n2.8536\n2.7876\n2.7186\n2.6464\n2.6090\n2.5705\n2.5309\n2.4901\n2.4480\n2.4045\n  12\n2.7534\n2.6866\n2.6169\n2.5436\n2.5055\n2.4663\n2.4259\n2.3842\n2.3410\n2.2962\n  13\n2.6710\n2.6037\n2.5331\n2.4589\n2.4202\n2.3803\n2.3392\n2.2966\n2.2524\n2.2064\n  14\n2.6022\n2.5342\n2.4630\n2.3879\n2.3487\n2.3082\n2.2664\n2.2229\n2.1778\n2.1307\n  15\n2.5437\n2.4753\n2.4034\n2.3275\n2.2878\n2.2468\n2.2043\n2.1601\n2.1141\n2.0658\n  16\n2.4935\n2.4247\n2.3522\n2.2756\n2.2354\n2.1938\n2.1507\n2.1058\n2.0589\n2.0096\n  17\n2.4499\n2.3807\n2.3077\n2.2304\n2.1898\n2.1477\n2.1040\n2.0584\n2.0107\n1.9604\n  18\n2.4117\n2.3421\n2.2686\n2.1906\n2.1497\n2.1071\n2.0629\n2.0166\n1.9681\n1.9168\n  19\n2.3779\n2.3080\n2.2341\n2.1555\n2.1141\n2.0712\n2.0264\n1.9795\n1.9302\n1.8780\n  20\n2.3479\n2.2776\n2.2033\n2.1242\n2.0825\n2.0391\n1.9938\n1.9464\n1.8963\n1.8432\n  21\n2.3210\n2.2504\n2.1757\n2.0960\n2.0540\n2.0102\n1.9645\n1.9165\n1.8657\n1.8117\n  22\n2.2967\n2.2258\n2.1508\n2.0707\n2.0283\n1.9842\n1.9380\n1.8894\n1.8380\n1.7831\n  23\n2.2747\n2.2036\n2.1282\n2.0476\n2.0050\n1.9605\n1.9139\n1.8648\n1.8128\n1.7570\n  24\n2.2547\n2.1834\n2.1077\n2.0267\n1.9838\n1.9390\n1.8920\n1.8424\n1.7896\n1.7330\n  25\n2.2365\n2.1649\n2.0889\n2.0075\n1.9643\n1.9192\n1.8718\n1.8217\n1.7684\n1.7110\n  26\n2.2197\n2.1479\n2.0716\n1.9898\n1.9464\n1.9010\n1.8533\n1.8027\n1.7488\n1.6906\n  27\n2.2043\n2.1323\n2.0558\n1.9736\n1.9299\n1.8842\n1.8361\n1.7851\n1.7306\n1.6717\n  28\n2.1900\n2.1179\n2.0411\n1.9586\n1.9147\n1.8687\n1.8203\n1.7689\n1.7138\n1.6541\n  29\n2.1768\n2.1045\n2.0275\n1.9446\n1.9005\n1.8543\n1.8055\n1.7537\n1.6981\n1.6376\n  30\n2.1646\n2.0921\n2.0148\n1.9317\n1.8874\n1.8409\n1.7918\n1.7396\n1.6835\n1.6223\n  40\n2.0772\n2.0035\n1.9245\n1.8389\n1.7929\n1.7444\n1.6928\n1.6373\n1.5766\n1.5089\n  60\n1.9926\n1.9174\n1.8364\n1.7480\n1.7001\n1.6491\n1.5943\n1.5343\n1.4673\n1.3893\n120\n1.9105\n1.8337\n1.7505\n1.6587\n1.6084\n1.5543\n1.4952\n1.4290\n1.3519\n1.2539\n∞\n1.8307\n1.7522\n1.6664\n1.5705\n1.5173\n1.4591\n1.3940\n1.3180\n1.2214\n1.0000\nBased on data from Maxine Merrington and Catherine M. Thompson, “Tables of Percentage Points of the Inverted Beta (F ) Distribution,” Biometrika 33 (1943): 80–84.\n\n634\t\nAPPENDIX A  Tables\nTABLE A-6  \u0007Critical Values of the  \nPearson Correlation  \nCoefficient r\nn\na = .05\na = .01\n    4\n.950\n.990\n    5\n.878\n.959\n    6\n.811\n.917\n    7\n.754\n.875\n    8\n.707\n.834\n    9\n.666\n.798\n  10\n.632\n.765\n  11\n.602\n.735\n  12\n.576\n.708\n  13\n.553\n.684\n  14\n.532\n.661\n  15\n.514\n.641\n  16\n.497\n.623\n  17\n.482\n.606\n  18\n.468\n.590\n  19\n.456\n.575\n  20\n.444\n.561\n  25\n.396\n.505\n  30\n.361\n.463\n  35\n.335\n.430\n  40\n.312\n.402\n  45\n.294\n.378\n  50\n.279\n.361\n  60\n.254\n.330\n  70\n.236\n.305\n  80\n.220\n.286\n  90\n.207\n.269\n100\n.196\n.256\nNOTE: To test H0: r = 0 (no correlation) against  \nH1: r ≠0 (correlation), reject H0 if the absolute value of r \nis greater than or equal to the critical value in the table.\n\n\t\nAPPENDIX A  Tables\t\n635\nTABLE A-7  Critical Values for the Sign Test\na\n \n \n \n \nn\n.005 \n(one tail) \n.01 \n(two tails)\n.01 \n(one tail) \n.02 \n(two tails)\n.025 \n(one tail) \n.05 \n(two tails)\n.05 \n(one tail) \n.10 \n(two tails)\n  1\n*\n*\n*\n*\n  2\n*\n*\n*\n*\n  3\n*\n*\n*\n*\n  4\n*\n*\n*\n*\n  5\n*\n*\n*\n0\n  6\n*\n*\n0\n0\n  7\n*\n0\n0\n0\n  8\n0\n0\n0\n1\n  9\n0\n0\n1\n1\n10\n0\n0\n1\n1\n11\n0\n1\n1\n2\n12\n1\n1\n2\n2\n13\n1\n1\n2\n3\n14\n1\n2\n2\n3\n15\n2\n2\n3\n3\n16\n2\n2\n3\n4\n17\n2\n3\n4\n4\n18\n3\n3\n4\n5\n19\n3\n4\n4\n5\n20\n3\n4\n5\n5\n21\n4\n4\n5\n6\n22\n4\n5\n5\n6\n23\n4\n5\n6\n7\n24\n5\n5\n6\n7\n25\n5\n6\n7\n7\nNOTES:\n1.  \u0007*indicates that it is not possible to get a value in the critical region, so fail to reject the \nnull hypothesis.\n2.  \u0007Reject the null hypothesis if the number of the less frequent sign (x) is less than or \nequal to the value in the table.\n3.  \u0007For values of n greater than 25, a normal approximation is used with\nz =\n1x + 0.52 - an\n2 b\n1n\n2\n\n636\t\nAPPENDIX A  Tables\nTABLE A-8  Critical Values of T for the Wilcoxon Signed-Ranks Test\na\n \n \n \n \nn\n.005 \n(one tail) \n.01 \n(two tails)\n.01 \n(one tail) \n.02 \n(two tails)\n.025 \n(one tail) \n.05 \n(two tails)\n.05 \n(one tail) \n.10 \n(two tails)\n  5\n*\n*\n*\n  1\n  6\n*\n*\n  1\n  2\n  7\n*\n  0\n  2\n  4\n  8\n  0\n  2\n  4\n  6\n  9\n  2\n  3\n  6\n  8\n10\n  3\n  5\n  8\n11\n11\n  5\n  7\n11\n14\n12\n  7\n10\n14\n17\n13\n10\n13\n17\n21\n14\n13\n16\n21\n26\n15\n16\n20\n25\n30\n16\n19\n24\n30\n36\n17\n23\n28\n35\n41\n18\n28\n33\n40\n47\n19\n32\n38\n46\n54\n20\n37\n43\n52\n60\n21\n43\n49\n59\n68\n22\n49\n56\n66\n75\n23\n55\n62\n73\n83\n24\n61\n69\n81\n92\n25\n68\n77\n90\n101\n26\n76\n85\n98\n110\n27\n84\n93\n107\n120\n28\n92\n102\n117\n130\n29\n100\n111\n127\n141\n30\n109\n120\n137\n152\nNOTES:\n1.  \u0007*indicates that it is not possible to get a value in the critical region, so fail to reject the null \nhypothesis.\n2.  \u0007Conclusions:\n     \u0007Reject the null hypothesis if the test statistic T is less than or equal to the critical value found in \nthis table.\n     \u0007Fail to reject the null hypothesis if the test statistic T is greater than the critical value found  \nin the table.\nBased on data from Some Rapid Approximate Statistical Procedures, Copyright © 1949, 1964 \nLederle Laboratories Division of American Cyanamid Company.\n\n\t\nAPPENDIX A  Tables\t\n637\nTABLE A-9  \u0007Critical Values of Spearman’s Rank  \nCorrelation Coefficient rs\nn\na = 0.10\na = 0.05\na = 0.02\na = 0.01\n  5\n.900\n—\n—\n—\n  6\n.829\n.886\n.943\n—\n  7\n.714\n.786\n.893\n.929\n  8\n.643\n.738\n.833\n.881\n  9\n.600\n.700\n.783\n.833\n10\n.564\n.648\n.745\n.794\n11\n.536\n.618\n.709\n.755\n12\n.503\n.587\n.678\n.727\n13\n.484\n.560\n.648\n.703\n14\n.464\n.538\n.626\n.679\n15\n.446\n.521\n.604\n.654\n16\n.429\n.503\n.582\n.635\n17\n.414\n.485\n.566\n.615\n18\n.401\n.472\n.550\n.600\n19\n.391\n.460\n.535\n.584\n20\n.380\n.447\n.520\n.570\n21\n.370\n.435\n.508\n.556\n22\n.361\n.425\n.496\n.544\n23\n.353\n.415\n.486\n.532\n24\n.344\n.406\n.476\n.521\n25\n.337\n.398\n.466\n.511\n26\n.331\n.390\n.457\n.501\n27\n.324\n.382\n.448\n.491\n28\n.317\n.375\n.440\n.483\n29\n.312\n.368\n.433\n.475\n30\n.306\n.362\n.425\n.467\nNOTES:\n1.  \u0007For n 7 30 use rs { z> 1n - 1, where z corresponds to the level of significance. \nFor example, if a = 0.05, then z = 1.96.\n2.  \u0007If the absolute value of the test statistic rs is greater than or equal to the positive \ncritical value, then reject H0: rs = 0 and conclude that there is sufficient evidence to \nsupport the claim of a correlation.\nBased on data from Biostatistical Analysis, 4th edition © 1999, by Jerrold Zar, Prentice \nHall, Inc., Upper Saddle River, New Jersey, and “Distribution of Sums of Squares of Rank \nDifferences to Small Numbers with Individuals,” The Annals of Mathematical Statistics, \nVol. 9, No. 2.\nrs\n1\n21\n2rs\na\u001f2\na\u001f2\n\nAPPENDIX B\nData Sets\nComplete data sets available at www.TriolaStats.com\nThis appendix lists only the first five rows of each data set. The complete data sets \nare available for download at www.TriolaStats.com for a variety of technologies, \nincluding Excel, SPSS, JMP, Minitab, and TI-83>84 Plus calculators. These data sets \nare included with Statdisk, which is free to users of this textbook; Statdisk can be \ndownloaded at www.statdisk.org.\nData Set 1:\t Body Data\nData Set 2:\t Body Temperatures\nData Set 3:\t Births\nData Set 4:\t Audiometry\nData Set 5:\t Vision\nData Set 6:\t Family Heights\nData Set 7:\t Foot and Height\nData Set 8:\t IQ and Lead\nData Set 9:\t IQ and Brain Size\nData Set 10:\tFreshman 15\nData Set 11:\tBear Measurements\nData Set 12:\tManatee Deaths\nData Set 13:\tAlcohol and Tobacco in Movies\nData Set 14:\tPassive and Active Smoke\nData Set 15:\tCigarette Contents\nData Set 16:\tIris Measurements\nData Set 17:\tCuckoo Egg Lengths\nData Set 18:\tPoplar Tree Weights\n638\n\nAGE\nGENDER (1 = M)\nPULSE\nSYSTOLIC\nDIASTOLIC\nHDL\nLDL\nWHITE\nRED\nPLATE\nWEIGHT\nHEIGHT\nWAIST\nARM CIRC\nBMI\n43\n0\n80\n100\n70\n73\n  68\n8.7\n4.80\n319\n  98.6\n172.0\n120.4\n40.7\n33.3\n57\n1\n84\n112\n70\n35\n116\n4.9\n4.73\n187\n  96.9\n186.0\n107.8\n37.0\n28.0\n38\n0\n94\n134\n94\n36\n223\n6.9\n4.47\n297\n108.2\n154.4\n120.3\n44.3\n45.4\n80\n1\n74\n126\n64\n37\n  83\n7.5\n4.32\n170\n  73.1\n160.5\n  97.2\n30.3\n28.4\n34\n1\n50\n114\n68\n50\n104\n6.1\n4.95\n140\n  83.1\n179.0\n  95.1\n34.0\n25.9\nData Set 1: Body Data\nBody and exam measurements are from 300 subjects (first five rows \nshown here). AGE is in years, for GENDER 0 = female and 1 =\nmale, PULSE is pulse rate (beats per minute), SYSTOLIC is systolic \nblood pressure (mm Hg), DIASTOLIC is diastolic blood pressure \n(mm Hg), HDL is HDL cholesterol (mg>dL), LDL is LDL choles-\nterol (mg>dL), WHITE is white blood cell count (1000 cells>mL),\n(1000 cells>mL), RED is red blood cell count (million cells>mL), \nPLATE is platelet count (1000 cells>mL), WEIGHT is weight (kg), \nHEIGHT is height (cm), WAIST is circumference (cm), ARM CIRC \nis arm circumference (cm), and BMI is body mass index (kg>m2). Data \nare from the National Center for Health Statistics.\nTI-83 , 84 list names  \u0007AGE, GENDR, PULSE, SYS, DIAS, HDL, \n(BODY):\t\n\u0007LDL, WHITE, REDBC, PLATE, WT, HT, \nWAIST, ARMC, BMI\nData Set 2: Body Temperatures\nBody temperatures (°F) are from 107 subjects taken on two consecu-\ntive days at 8 AM and 12 AM (first five rows shown here). SEX is gen-\nder of subject, and SMOKE indicates if subject smokes (Y) or does \nnot smoke (N). Data provided by Dr. Steven Wasserman, Dr. Philip \nMackowiak, and Dr. Myron Levine of the University of Maryland.\nTI-83 , 84 list names  D1T8, D1T12, D2T8, D2T12 \n(BODYTEMP):\t\n\u0007(no list for SEX and SMOKE). \nMissing data values are represented by 9999.\nSEX\nSMOKE\nDAY 1—8 AM\nDAY 1—12 AM\nDAY 2—8 AM\nDAY 2—12 AM\nM\nY\n98.0\n98.0\n98.0\n98.6\nM\nY\n97.0\n97.6\n97.4\n—\nM\nY\n98.6\n98.8\n97.8\n98.6\nM\nN\n97.4\n98.0\n97.0\n98.0\nM\nN\n98.2\n98.8\n97.0\n98.0\nData Set 3: Births\nData are from 400 births (first five rows shown here). For GENDER \n0 = female and 1 = male. LENGTH OF STAY is in days, BIRTH \nWEIGHT is in grams, and TOTAL CHARGES are in dollars.\nTI-83 , 84 list names  \u0007FLOS, MLOS, FBWT, MBWT, FCHRG, \n(BIRTHS):\t\n\u0007MCHRG [Separate lists provided for female \n(F) and male (M) babies. No list for  \nFACILITY, INSURANCE, ADMITTED,  \nand DISCHARGED]\nFACILITY\nINSURANCE\nGENDER (1 = M)\nLENGTH OF STAY\nADMITTED\nDISCHARGED\nBIRTH WEIGHT\nTOTAL CHARGES\nAlbany Medical Center Hospital\nInsurance Company\n0\n  2\nFRI\nSUN\n3500\n  13986\nAlbany Medical Center Hospital\nBlue Cross\n1\n  2\nFRI\nSUN\n3900\n    3633\nAlbany Medical Center Hospital\nBlue Cross\n0\n36\nWED\nTHU\n  800\n359091\nAlbany Medical Center Hospital\nInsurance Company\n1\n  5\nMON\nSAT\n2800\n    8537\nAlbany Medical Center Hospital\nInsurance Company\n1\n  2\nFRI\nSUN\n3700\n    3633\n\t\nAPPENDIX B  Data Sets\t\n639\n(Complete data sets available at www.TriolaStats.com)\n\n640\t\nAPPENDIX B  Data Sets\n(Complete data sets available at www.TriolaStats.com)\n640\t\nAPPENDIX B  Data Sets\nData Set 4: Audiometry\nData are from 350 subjects (first five rows shown here). AGE is in \nyears, for GENDER 0 = female and 1 = male, and RIGHT , LEFT \nTHRESHOLD are hearing measurements in each ear using pure tone \nsounds sent through earphones. Intensity of sound is varied until hear-\ning threshold at frequency of 1000 Hz (db) is identified. Data are from \nthe National Center for Health Statistics.\nTI-83 , 84 list names  AUDAG, AUDGN, AUDRT, AUDLT \n(AUDIO):\nAGE\nGENDER\nRIGHT THRESHOLD\nLEFT THRESHLOD\n42\n1\n  5\n  5\n46\n0\n  5\n15\n51\n0\n  5\n10\n70\n0\n15\n20\n78\n1\n  5\n10\nData Set 5: Vision\nData are from 300 subjects (first five rows shown here). AGE is in \nyears, for GENDER 0 = female and 1 = male, and RIGHT , LEFT \nEYE is measure of visual acuity with “usual correction,” which could \nbe eyeglasses, contacts, or no correction. Data are from the National \nCenter for Health Statistics.\nTI-83 , 84 list names  VISAG, VISGN, VISRT, VISLT\n(VISION):\nAGE\nGENDER\nRIGHT EYE\nLEFT EYE\n39\n1\n20\n20\n48\n1\n20\n20\n84\n0\n25\n20\n55\n0\n25\n20\n41\n1\n50\n50\nData Set 6: Family Heights\nHeight data are from 134 families (first five rows shown here). \nHeights are in inches. Only families with at least one child of each \ngender are included, and only heights of the first son and first \n­daughter are included. The data are from a journal of Francis Galton  \n(1822–1911), who developed the concepts of standard deviation, \n­regression line, and correlation between two variables.\nTI-83 , 84 list names  DAD, MOM, SON1, DGHT1\n(FAMHT):\nFATHER\nMOTHER\nFIRST SON\nFIRST DAUGHTER\n70.0\n64.0\n68.0\n65.0\n71.0\n65.5\n72.0\n66.0\n69.0\n63.5\n70.5\n65.0\n69.5\n66.0\n71.0\n66.5\n70.0\n58.0\n72.0\n66.0\n\n\t\nAPPENDIX B  Data Sets\t\n641\n(Complete data sets available at www.TriolaStats.com)\n\t\nAPPENDIX B  Data Sets\t\n641\nData Set 7: Foot and Height\nFoot and height measurements are from 40 subjects (first five rows \nshown here). SEX is gender of subject, AGE is age in years, FOOT \nLENGTH is length of foot (cm), SHOE PRINT is length of shoe \n(cm), SHOE SIZE is reported shoe size, and HEIGHT is height (cm) \nof the subject.\nData from Rohren, Brenda, “Estimation of Stature from Foot and \nShoe Length: Applications in Forensic Science.” Copyright © 2006. \nReprinted by permission of the author. Brenda Rohren (MA, MFS, \nLIMHP, LADC, MAC) was a graduate student at Nebraska Wesleyan \nUniversity when she conducted the research and wrote the report.\nTI-83 , 84 list names  \u0007FTSEX (1 = male), FTAGE, FTLN, SHOPT, \n(FOOTHT):\t\nSHOSZ, FHT\nSEX\nAGE\nFOOT LENGTH\nSHOE PRINT\nSHOE SIZE\nHEIGHT\nM\n67\n27.8\n31.3\n11.0\n180.3\nM\n47\n25.7\n29.7\n  9.0\n175.3\nM\n41\n26.7\n31.3\n11.0\n184.8\nM\n42\n25.9\n31.8\n10.0\n177.8\nM\n48\n26.4\n31.4\n10.0\n182.3\nData Set 8: IQ and Lead\nData are from 121 subjects (first five rows shown here). Data are mea-\nsured from children in two consecutive years, and the children were \nliving close to a lead smelter. LEAD is blood lead level group  \n[1 =  low lead level (blood lead levels 6 40 micrograms>100 mL \nin both years), 2 =  medium lead level (blood lead levels Ú  \n40 micrograms>100 mL in exactly one of two years), 3 =  high lead \nlevel (blood lead level Ú 40 micrograms>100 mL in both years)]. AGE \nis age in years, SEX is sex of subject (1 = male; 2 = female). YEAR1 \nis blood lead level in first year, and YEAR2 is blood lead level in \nsecond year. IQ VERB is measured verbal IQ score. IQ PERF is mea-\nsured performance IQ score. IQ FULL is measured full IQ score.\nData are from “Neuropsychological Dysfunction in Children \nwith Chronic Low-Level Lead Absorption,” by P. J. Landrigan,  \nR. H. Whitworth, R. W. Baloh, N. W. Staehling, W. F Barthel, and  \nB. F. Rosenblum, Lancet, Vol. 1, No. 7909.\nTI-83 , 84 list names  LEAD, IQAGE, IQSEX, YEAR1,  \n(IQLEAD):\t\nYEAR2, IQV, IQP, IQF\nLEAD\nAGE\nSEX\nYEAR1\nYEAR2\nIQ VERB\nIQ PERF\nIQ FULL\n1\n11\n1\n25\n18\n61\n  85\n70\n1\n  9\n1\n31\n28\n82\n  90\n85\n1\n11\n1\n30\n29\n70\n107\n86\n1\n  6\n1\n29\n30\n72\n  85\n76\n1\n11\n1\n  2\n34\n72\n100\n84\nData Set 9: IQ and Brain Size\nData are from 20 monozygotic (identical) twins (first five rows shown \nhere). PAIR identifies the set of twins, SEX is the gender of the \nsubject 11 = male, 2 = female2, ORDER is the birth order, IQ is \nmeasured full IQ score, VOL is total brain volume (cm3), AREA is \ntotal brain surface area (cm2), CCSA is corpus callosum (fissure con-\nnecting left and right cerebral hemispheres) surface area (cm2), CIRC \nis head circumference (cm), and WT is body weight (kg).\nData provided by M. J. Tramo, W. C. Loftus, T. A. Stukel,  \nJ. B. Weaver, M. S. Gazziniga. See “Brain Size, Head Size, and IQ in \nMonozygotic Twins,” Neurology, Vol. 50.\nTI-83 , 84 list names  PAIR, SEX, ORDER, IQ, VOL, AREA,  \n(IQBRAIN):\t\nCCSA, CIRC, BWT\nPAIR\nSEX (1 = M)\nORDER\nIQ\nVOL\nAREA\nCCSA\nCIRC\nWT\n1\n2\n1\n  96\n1005\n1913.88\n6.08\n54.7\n57.607\n1\n2\n2\n  89\n  963\n1684.89\n5.73\n54.2\n58.968\n2\n2\n1\n  87\n1035\n1902.36\n6.22\n53.0\n64.184\n2\n2\n2\n  87\n1027\n1860.24\n5.80\n52.9\n58.514\n3\n2\n1\n101\n1281\n2264.25\n7.99\n57.8\n63.958\n\n642\t\nAPPENDIX B  Data Sets\n(Complete data sets available at www.TriolaStats.com)\nData Set 10: Freshman 15\nWeights of 67 college students are provided (first five rows shown \nhere). SEX is gender of subject, WT is weight in kilograms, and BMI \nis measured body mass index. Measurements were made in September \nof freshman year and then later in April of freshman year.\nResults are published in Hoffman, D. J., Policastro, P., Quick, V., \nand Lee, S. K.: “Changes in Body Weight and Fat Mass of Men and \nWomen in the First Year of College: A Study of the ‘Freshman 15.’” \nJournal of American College Health, July 1, 2006, Vol. 55, No. 1,  \np. 41. Copyright © 2006. Reprinted by permission.\nTI-83 , 84 list names  WTSP, WTAPR, BMISP, BMIAP  \n(FRESH15): \t\n(no list for SEX)\nSEX\nWT SEPT\nWT APRIL\nBMI SEPT\nBMI APRIL\nM\n72\n59\n22.02\n18.14\nM\n97\n86\n19.70\n17.44\nM\n74\n69\n24.09\n22.43\nM\n93\n88\n26.97\n25.57\nF\n68\n64\n21.51\n20.10\nData Set 11: Bear Measurements\nData are from 54 anesthetized wild bears (first five rows shown \nhere). AGE is in months, MONTH is the month of measurement \nwith 1 = January, SEX is coded with 0 = female and 1 = male, \nHEADLEN is head length (inches), HEADWDTH is width of head \n(inches), NECK is distance around neck (in inches), LENGTH is \nlength of body (inches), CHEST is distance around chest (inches), \nand WEIGHT is measured in pounds. Data are from Gary Alt and \nMinitab, Inc.\nTI-83 , 84 list names   BAGE, BSEX, BHDLN, BHDWD, BNECK,  \n(BEARS):\t\n\u0007BLEN, BCHST, BWGHT (no list for \nMONTH)\nAGE\nMONTH\nSEX (1 = M)\nHEADLEN\nHEADWDTH\nNECK\nLENGTH\nCHEST\nWEIGHT\n  19\n7\n1\n11.0\n  5.5\n16.0\n53.0\n26.0\n  80\n  55\n7\n1\n16.5\n  9.0\n28.0\n67.5\n45.0\n344\n  81\n9\n1\n15.5\n  8.0\n31.0\n72.0\n54.0\n416\n115\n7\n1\n17.0\n10.0\n31.5\n72.0\n49.0\n348\n104\n8\n0\n15.5\n  6.5\n22.0\n62.0\n35.0\n166\nData Set 12: Manatee Deaths\nAnnual Florida data for 24 years are provided (first five rows shown \nhere). DEATHS is the annual number of manatee deaths caused by \nboats, BOATS is the number of registered pleasure boats (tens of \nthousands), POP is the Florida population (millions), and WATER \nTEMP is the annual mean water temperature 1°F2.\nTI-83 , 84 list names  DEATH, BOATS, POP, WTEMP  \n(MANATEE):\t\n(no list for YEAR)\nYEAR\nDEATHS\nBOATS\nPOP\nWATER TEMP\n1991\n53\n68\n13.3\n71.9\n1992\n38\n68\n13.5\n70.4\n1993\n35\n67\n13.7\n70.5\n1994\n49\n70\n14.0\n71.7\n1995\n42\n71\n14.3\n70.9\n\n\t\nAPPENDIX B  Data Sets\t\n643\n(Complete data sets available at www.TriolaStats.com)\nData Set 13: Alcohol and Tobacco in Movies\nData are from 50 animated children’s movies (first five rows shown \nhere). LENGTH is movie length in minutes, TOBACCO is tobacco \nuse time in seconds, and ALCOHOL is alcohol use time in seconds.\nThe data are based on Goldstein, Adam O., Sobel, Rachel A., \nNewman, Glen R., “Tobacco and Alcohol Use in G-Rated Children’s \nAnimated Films.” Journal of the American Medical Association, \nMarch 24/31, 1999, Vol. 281, No. 12, p. 1132. Copyright © 1999. All \nrights reserved.\nTI-83 , 84 list names   CHLEN, CHTOB, CHALC  \n(CHMOVIE): \t\n(no list for MOVIE and STUDIO)\nMOVIE\nSTUDIO\nLENGTH (MIN)\nTOBACCO (SEC)\nALCOHOL (SEC)\nSnow White\nDisney\n  83\n    0\n  0\nPinocchio\nDisney\n  88\n223\n80\nFantasia\nDisney\n120\n    0\n  0\nDumbo\nDisney\n  64\n176\n88\nBambi\nDisney\n  69\n    0\n  0\nData Set 14: Passive and Active Smoke\nData are from 120 subjects (first five rows shown here) in three \ngroups: SMOKER includes subjects who are smokers, ETS includes \nnonsmokers exposed to environmental tobacco smoke, and NOETS \nincludes nonsmokers not exposed to environmental tobacco smoke. \nAll values are measured levels of serum cotinine (in ng>mL), a  \nmetabolite of nicotine. (When nicotine is absorbed by the body, coti-\nnine is produced.) Data are from the U.S. Department of Health and \nHuman Services, National Center for Health Statistics, Third National \nHealth and Nutrition Examination Survey.\nTI-83 , 84 list names  SMKR, ETS, NOETS\n(SMOKE):\nSMOKER\nETS\nNOETS\n    1\n384\n0\n    0\n    0\n0\n131\n  69\n0\n173\n  19\n0\n265\n    1\n0\nData Set 15: Cigarette Contents\nData are from 75 cigarettes (first five rows shown here) from three  \ncategories: KING includes king-sized cigarettes that are nonfiltered, \nnonmenthol, and nonlight; MENTH includes menthol cigarettes that are \n100 mm long, filtered, and nonlight; and 100 includes 100-mm-long \ncigarettes that are filtered, nonmenthol, and nonlight. TAR is the \namount of tar per cigarette (milligrams), NICOTINE is the amount of \nnicotine per cigarette (milligrams), and CO is the amount of carbon \nmonoxide per cigarette (milligrams). Data are from the Federal Trade \nCommission.\nTI-83 , 84 list names  KGTAR, KGNIC, KGCO, MNTAR, MNNIC, \n(CIGARET):\t\nMNCO, FLTAR, FLNIC, FLCO\nKING TAR\nKING NICOTINE\nKING CO\nMENTH TAR\nMENTH NICOTINE\nMENTH CO\n100 TAR\n100 NIC\n100 CO\n20\n1.1\n16\n16\n1.1\n15\n  5\n0.4\n  4\n27\n1.7\n16\n13\n0.8\n17\n16\n1.0\n19\n27\n1.7\n16\n16\n1.0\n19\n17\n1.2\n17\n20\n1.1\n16\n  9\n0.9\n  9\n13\n0.8\n18\n20\n1.1\n16\n14\n0.8\n17\n13\n0.8\n18\n\n644\t\nAPPENDIX B  Data Sets\n(Complete data sets available at www.TriolaStats.com)\nData Set 16: Iris Measurements\nData are from 150 Iris Measurements (first five rows shown here) \nfrom three different classes (Setosa, Versicolor, Virginica). SL denotes \nsepal length (mm), SW denotes sepal width (mm), PL denotes petal \nlength (mm), and PW denotes petal width (mm). From “The Use \nof Multiple Measurements in Taxonomic Problems,” by Ronald A. \nFisher, Annals of Statistics, Vol. 7.\nTI-83 , 84 list names  \u0007SETSL, SETSW, SETPL, SETPW, VERSL, \n(IRIS):\t \t\n\u0007VERSW, VERPL, VERPW, VIRSL, VIRSW, \nVIRPL, VIRPW.\nCLASS\nSL\nSW\nPL\nPW\nsetosa\n5.1\n3.5\n1.4\n0.2\nsetosa\n4.9\n3.0\n1.4\n0.2\nsetosa\n4.7\n3.2\n1.3\n0.2\nsetosa\n4.6\n3.1\n1.5\n0.2\nsetosa\n5.0\n3.6\n1.4\n0.2\nData Set 17: Cuckoo Egg Lengths\nLengths (mm) of cuckoo eggs put in the nests of six other birds (first \nfive rows of data shown here). From The Methods of Statistics,  \n4th edition, by L. H. C. Tippett, John Wiley and Sons, Inc., as listed in \nthe Data and Story Library (online).\nTI-83 , 84 list names  MDW, TREE, HEDGE, ROBIN,  \n(CUCKOO):\t\nPIED, WREN.\nMEADOW PIPIT\nTREE PIPIT\nHEDGE SPARROW\nROBIN\nPIED WAGTAIL\nWREN\n19.65\n21.05\n20.85\n21.05\n21.05\n19.85\n20.05\n21.85\n21.65\n21.85\n21.85\n20.05\n20.65\n22.05\n22.05\n22.05\n21.85\n20.25\n20.85\n22.45\n22.85\n22.05\n21.85\n20.85\n21.65\n22.65\n23.05\n22.05\n22.05\n20.85\nData Set 18: Poplar Tree Weights\nData (first five rows shown here) are weights (kg) of trees in year 1 \nand year 2 grown with four different conditions (no treatment, fertil-\nizer, irrigation, fertilizer and irrigation) at two different sites. Site 1 is \nrich and moist, and Site 2 is sandy and dry. From a study conducted \nby researchers at Pennsylvania State University. Data obtained from \nMinitab, Inc.\nTI-83 , 84 list names  NONE, FERT, IRRIG, FRTIR\n(POPLAR):\nYEAR\nSITE\nNO TREATMENT\nFERTILIZER\nIRRIGATION\nFERT & IRRIG\n1\n1\n0.15\n1.34\n0.23\n2.03\n1\n1\n0.02\n0.14\n0.04\n0.27\n1\n1\n0.16\n0.02\n0.34\n0.92\n1\n1\n0.37\n0.08\n0.16\n1.07\n1\n1\n0.22\n0.08\n0.05\n2.38\n\n645\nWebsites and \nBibliography of Books\nAPPENDIX C \nWebsites\nTriola Stats: www.TriolaStats.com\nAccess continually updated digital resources, including download-\nable data sets, textbook supplements, online instructional videos, \nTriola Blog, and more.\nStatdisk: www.Statdisk.org\nDownload the free Statdisk statistical software that is designed spe-\ncifically for this book and contains all Appendix B data sets. Detailed \ninformation on using Statdisk is provided on the site’s Help page.\nStatCrunch: www.statcrunch.com\nBooks\n*An asterisk denotes a book recommended for reading. Other \nbooks are recommended as reference texts.\nBennett, D. 1998. Randomness. Cambridge, Mass.: Harvard ­University \nPress.\n*Best, J. 2012. Damned Lies and Statistics. Berkeley, Calif.: ­University \nof California Press.\n*Best, J. 2004. More Damned Lies and Statistics. Berkeley, Calif.: \nUniversity of California Press.\n*Campbell, S. 2004. Flaws and Fallacies in Statistical Thinking. \n­Mineola, N.Y.: Dover Publications.\n*Crossen, C. 1996. Tainted Truth: The Manipulation of Fact in \n­America. New York: Simon & Schuster.\n*Freedman, D., R. Pisani, R. Purves, and A. Adhikari. 2007. Statistics. \n4th ed. New York: W. W. Norton & Company.\n*Gonick, L., and W. Smith. 1993. The Cartoon Guide to Statistics. \nNew York: Harper Collins.\n*Heyde, C., and E. Seneta, eds. 2001. Statisticians of the Centuries. \nNew York: Springer-Verlag.\n*Hollander, M., and F. Proschan. 1984. The Statistical Exorcist: \n­Dispelling Statistics Anxiety. New York: Marcel Dekker.\n*Holmes, C. 1990. The Honest Truth About Lying with Statistics. \nSpringfield, Ill.: Charles C Thomas.\n*Hooke, R. 1983. How to Tell the Liars from the Statisticians. New \nYork: Marcel Dekker.\n*Huff, D. 1993. How to Lie with Statistics. New York: W. W. Norton \n& Company.\n*Jaffe, A., and H. Spirer. 1998. Misused Statistics. New York: Marcel \nDekker.\nKaplan, M. 2007. Chances Are. New York: Penguin Group.\nKotz, S., and D. Stroup. 1983. Educated Guessing—How to Cope in an \nUncertain World. New York: Marcel Dekker.\nMlodinow, L. 2009. The Drunkard’s Walk. New York: Vintage Books.\n*Moore, D., and W. Notz. 2012. Statistics: Concepts and Controver-\nsies. 8th ed. San Francisco: Freeman.\n*Paulos, J. 2001. Innumeracy: Mathematical Illiteracy and Its \n­Consequences. New York: Hill and Wang.\n*Reichmann, W. 1981. Use and Abuse of Statistics. New York: \n­Penguin.\n*Rossman, A., and B. Chance. 2011. Workshop Statistics: Discovery \nwith Data. 4th ed. Emeryville, Calif.: Key Curriculum Press.\n*Salsburg, D. 2001. The Lady Tasting Tea: How Statistics Revolution-\nized the Twentieth Century. New York: W. H. Freeman.\nSheskin, D. 2011. Handbook of Parametric and Nonparametric \n­Statistical Procedures. 5th ed. Boca Raton, Fla.: CRC Press.\nSimon, J. 1997. Resampling: The New Statistics. 2nd ed. Arlington, \nVa.: Resampling Stats.\n*Stigler, S. 1986. The History of Statistics. Cambridge, Mass.: ­Harvard \nUniversity Press.\nTaleb, N. 2010. The Black Swan. 2nd ed. New York: Random House.\n*Tufte, E. 2001. The Visual Display of Quantitative Information. 2nd \ned. Cheshire, Conn.: Graphics Press.\nTukey, J. 1977. Exploratory Data Analysis. Boston: Pearson.\nVickers, A. 2009. What Is a P-Value Anyway? Boston: Pearson.\nWhelan, C. 2013. Naked Statistics. New York: W. W. Norton & \n­Company.\nZwillinger, D., and S. Kokoska. 2000. CRC Standard Probability and \nStatistics Tables and Formulae. Boca Raton, Fla.: CRC Press.\n\nAPPENDIX D\nAnswers to Odd-Numbered Section Exercises, plus \nAnswers to All Chapter Quick Quizzes, Chapter \nReview Exercises, and Cumulative Review Exercises\nChapter 1 Answers\nSection 1-1\n\t 1.\t The respondents are a voluntary response sample or a self-selected \nsample. Because those with strong interests in the topic are more \nlikely to respond, it is very possible that their responses do not \nreflect the opinions or behavior of the general population.\n\t 3.\t Statistical significance is indicated when methods of statistics \nare used to reach a conclusion that a treatment is effective, but \ncommon sense might suggest that the treatment does not make \nenough of a difference to justify its use or to be practical. Yes, it \nis possible for a study to have statistical significance but not prac-\ntical significance.\n\t 5.\t Yes, there does appear to be a potential to create a bias.\n\t 7.\t No, there does not appear to be a potential to create a bias.\n\t 9.\t The sample is a voluntary response sample and has strong poten-\ntial to be flawed.\n\t11.\t The sampling method appears to be sound.\n\t13.\t With only a 1% chance of getting such results with a program \nthat has no effect, the program appears to have statistical \n­significance. Also, because the average loss of 22 pounds does \nseem substantial, the program appears to also have practical \n­significance.\n\t15.\t Because there is a 19% chance of getting that many girls by \nchance, the method appears to lack statistical significance. The \nresult of 1020 girls in 2000 births (51% girls) is above the ap-\nproximately 50% rate expected by chance, but it does not ap-\npear to be high enough to have practical significance. Not many \ncouples would bother with a procedure that raises the likelihood \nof a girl from 50% to 51%.\n\t17.\t Yes. Each column of 8 AM and 12 AM temperatures is recorded \nfrom the same subject, so each pair is matched.\n\t19.\t The data can be used to address the issue of whether there is a \ncorrelation between body temperatures at 8 AM and at 12 AM. \nAlso, the data can be used to determine whether there are differ-\nences between body temperatures at 8 AM and at 12 AM.\n\t21.\t No. The white blood cell counts measure a different quantity than \nthe red blood cell counts, so their differences are meaningless.\n\t23.\t No. The National Center for Health Statistics has no reason to \ncollect or present the data in a way that is biased.\n\t25.\t It is questionable that the sponsor is the Idaho Potato Commis-\nsion and the favorite vegetable is potatoes.\n\t27.\t The correlation, or association, between two variables does not \nmean that one of the variables is the cause of the other. Cor-\nrelation does not imply causation. Common sense suggests that \ncheese consumption is not directly related in any way to fatalities \nfrom bedsheet entanglements.\n\t29.\t a.\t1356.3 adults \n\t \t b.\t \u0007No. Because the result is a count of the people among the \n3014 who were surveyed, the result must be a whole number.\n\t \t c.\t 1356 adults  d.  40%\n\t31.\t The wording of the question is biased and tends to encourage \nnegative responses. The sample size of 20 is too small. Survey re-\nspondents are self-selected instead of being selected by the news-\npaper. If 20 readers respond, the percentages should be multiples \nof 5, so 87% and 13% are not possible results.\nSection 1-2\n\t 1.\t a.  \u0007The population consists of all adults in the United States and \nthe sample is the 1020 adults who were surveyed.\n\t\n\t b.  Statistic\n\t 3.\t a.\tQuantitative  b.  Categorical  c.  Categorical  d.  Quantitative\n\t 5.\t Statistic\t\n7.\t Statistic\t\n9.\t Statistic\n\t11.\t Parameter\t\n13.\t Continuous\t\n15.\t Continuous\n\t17.\t Discrete\t\n19.\t Discrete\t\n21.\t Ratio\n\t23.\t Interval\t\n25.\t Nominal\t\n27.\t Ordinal\n29.\t The numbers are not counts or measures of anything. They are at \nthe nominal level of measurement, and it makes no sense to com-\npute the average (mean) of them.\n31.\t The temperatures are at the interval level of measurement. \n­Because there is no natural starting point with 0°F representing \n“no heat,” ratios such as “twice” make no sense, so it is wrong to \nsay that the person is twice as warm as the outside air.\n\t33.\t a.\t\u0007Continuous, because the number of possible values is infinite \nand not countable\n\t \t b.\t Discrete, because the number of possible values is finite\n\t \t c.\t Discrete, because the number of possible values is finite\n\t \t d.\t \u0007Discrete, because the number of possible values is infinite and \ncountable\nSection 1-3\n\t 1.\t The study is an experiment because subjects were given treatments.\n\t 3.\t The group sample sizes of 547, 550, and 546 are all large so that \nthe researchers could see the effects of the paracetamol treatment.\n\t 5.\t The sample appears to be a convenience sample. By e-mailing the \nsurvey to a readily available group of Internet users, it was easy \nto obtain results. Although there is a real potential for getting a \nsample group that is not representative of the population, indica-\ntions of which ear is used for cell phone calls and which hand \nis dominant do not appear to be factors that would be distorted \nmuch by a sample bias.\n\t 7.\t With 717 responses, the response rate is 14%, which does appear \nto be quite low. In general, a very low response rate creates a \nserious potential for getting a biased sample that consists of those \nwith a special interest in the topic.\n646\n\n\t\nAppendix D\t\n647\n\t 3.\t The sample is a voluntary response sample, so the results are \nquestionable.\n\t 4.\t a.  \u0007It uses a voluntary response sample, and those with special \ninterests are more likely to respond, so it is very possible that \nthe sample is not representative of the population.\n\t \t b.  \u0007Because the statement refers to 72% of all Americans, it is \na parameter (but it is probably based on a 72% rate from the \nsample, and the sample percentage is a statistic).\n\t\n\t c.  Observational study\n\t 5.\t a.  \u0007If they have no fat at all, they have 100% less than any other \namount with fat, so the 125% figure cannot be correct.\n\t \t b.  686    c.  28%\n\t 6.\t Only part (c) is a simple random sample.\n\t 7.\t Because there is only a 4% chance of getting the results by \nchance, the method appears to have statistical significance. The \nresult of 112 girls in 200 births is above the approximately 50% \nrate expected by chance, but it does not appear to be high enough \nto have practical significance. Not many couples would bother \nwith a procedure that raises the likelihood of a girl from 50%  \nto 56%.\n\t 8.\t a.  Random    b.  Stratified    c.  Nominal\n\t \t d.  Statistic, because it is based on a sample.\n\t\n\t e.  \u0007The mailed responses would be a voluntary response sample. \nThose with strong opinions about the topic would be more \nlikely to respond, so it is very possible that the results would \nnot reflect the true opinions of the population of all adults.\n\t 9.\t a.  Systematic. It is likely to result in a representative sample.\n\t \t b.  Random. It is likely to result in a representative sample.\n\t \t c.  Cluster. It is likely to result in a representative sample.\n\t \t d.  Stratified. It is likely to result in a representative sample.\n\t\n\t e.  \u0007Convenience. It is very possible that the sample is not repre-\nsentative.\n\t10.\t a.  780 adults    b.  23%\n\t \t c.  Men: 48.5%; women: 51.5%\n\t \t d.  No, although this is a subjective judgment.\n\t \t e.  No, although this is a subjective judgment.\nChapter 1: Cumulative Review Exercises\n\t 1.\t 3162.5 grams. The weights all end with 00, suggesting that all of \nthe weights are rounded so that the last two digits are always 00.\n\t 2.\t 0.015625\n\t 3.\t 16.00 is a significantly high value.\n\t 4.\t -6.64\t\n5.\t 1067\t\n6.\t 575 grams\n\t 7.\t 27343.75 grams2\t 8.\t 0.20\t\n9.\t 0.00065536\n\t10.\t 31,381,059,609 (or about 31,381,060,000)\n\t11.\t 78,364,164,096 (or about 78,364,164,000)\n\t12.\t 0.000000531441\n\t 9.\t Systematic\t\n11.\t Random\t\n13.\t Cluster\n\t15.\t Stratified\t\n17.\t Random\t\n19.\t Convenience\n\t21.\t Observational study. The sample is a convenience sample consist-\ning of subjects who decided themselves to respond. Such volun-\ntary response samples have a high chance of not being represen-\ntative of the larger population, so the sample may well be biased. \nThe question was posted in an electronic edition of a newspaper, \nso the sample is biased from the beginning.\n\t23.\t Experiment. This experiment would create an extremely danger-\nous and illegal situation that has a real potential to result in injury \nor death. It’s difficult enough to drive in New York City while be-\ning completely sober.\n\t25.\t Experiment. The biased sample created by using subjects from \nNew York City cannot be fixed by using a larger sample. The \nlarger sample will still be a biased sample that is not representa-\ntive of subjects in the United States.\n\t27.\t Observational study. Respondents who have been convicted of \nfelonies are not likely to respond honestly to the second question. \nThe survey will suffer from a “social desirability bias” because \nsubjects will tend to respond in ways that will be viewed favor-\nably by those conducting the survey.\n\t29.\t Prospective study\t\n31.  Cross-sectional study\n\t33.\t Matched pairs design\t\n35.  Completely randomized design\n\t37.\t Prospective: The experiment was begun and results were fol-\nlowed forward in time. Randomized: Subjects were assigned \nto the different groups through a process of random selection, \nwhereby they had the same chance of belonging to each group. \nDouble-blind: The subjects did not know which of the three \ngroups they were in, and the people who evaluated results did not \nknow either. Placebo-controlled: There was a group of subjects \nwho were given a placebo; by comparing the placebo group to the \ntwo treatment groups, the effects of the treatments might be bet-\nter understood.\nChapter 1: Quick Quiz\n\t 1.\t No. The numbers do not measure or count anything.\n\t 2.\t Nominal\t\n3.\t Continuous\t\n4.\t Quantitative data\n\t 5.\t Ratio\t\n6.\t No\t\n7.\t No\n\t 8.\t Statistic\t\n9.\t Observational study\t\n10.\t False\nChapter 1: Review Exercises\n\t 1.\t a  Discrete    b.  Ratio    c.  Stratified    d.  Cluster\n\t \t e.  \u0007The mailed responses would be a voluntary response sample, \nso those with strong opinions are more likely to respond. It is \nvery possible that the results do not reflect the true opinions of \nthe population of all customers.\n\t 2.\t The survey was sponsored by the American Laser Centers, and \n24% said that the favorite body part is the face, which happens to \nbe a body part often chosen for some type of laser treatment. The \nsource is therefore questionable.\n\n648\t\nAppendix D\nChapter 2 Answers\nSection 2-1 \n\t 1.\t The table summarizes measurements from 40 subjects. It is not \npossible to identify the exact values of all of the original cotinine \nmeasurements.\n\t 3.\t\n\t17.\t Yes. The distribution appears to be approximately normal.\nRed Blood Cell Count (Males)\nFrequency\n3.00–3.49\n  1\n3.50–3.99\n16\n4.00–4.49\n29\n4.50–4.99\n57\n5.00–5.49\n44\n5.50–5.99\n  6\n\t19.\t\nCotinine (ng, mL)\nRelative Frequency\n  0–99\n27.5%\n100–199\n30.0%\n200–299\n35.0%\n300–399\n  2.5%\n400–499\n  5.0%\n\t 5.\t Class width: 100. Class midpoints: 49.5, 149.5, 249.5, 349.5, \n449.5, 549.5. Class boundaries: -0.5, 99.5, 199.5, 299.5, 399.5, \n499.5, 599.5.\n\t 7.\t Class width: 100. Class midpoints: 49.5, 149.5, 249.5, 349.5, \n449.5, 549.5, 649.5. Class boundaries: -0.5, 99.5, 199.5, 299.5, \n399.5, 499.5, 599.5, 699.5.\n\t 9.\t No. The maximum frequency is in the first class instead of being \nnear the middle.\n\t11.\t 89, 18, 12, 2\n\t13.\t The pulse rates appear to have a distribution that is approxi-\nmately normal.\nPulse Rate (Male)\nFrequency\n40–49\n  2\n50–59\n23\n60–69\n53\n70–79\n43\n80–89\n25\n90–99\n  5\n100–109\n  2\n\t15.\t The verbal IQ scores appear to have a distribution that is ap-\nproximately normal.\nIQ (Verbal)\nFrequency\n50–59\n  3\n60–69\n  8\n70–79\n13\n80–89\n26\n90–99\n18\n100–109\n  6\n110–119\n  2\n120–129\n  2\nWeight (kg) in September\nFrequency\n50–59\n  2\n60–69\n12\n70–79\n11\n80–89\n  3\n90–99\n  4\n\t21.\t The frequency distribution suggests that the reported heights \nwere rounded with disproportionately many 0s and 5s. This sug-\ngests that the results are not very accurate.\nLast Digit\nFrequency\n0\n  9\n1\n  2\n2\n  1\n3\n  3\n4\n  1\n5\n15\n6\n  2\n7\n  0\n8\n  3\n9\n  1\n\t23.\t The two distributions differ substantially. The presence of coti-\nnine appears to be much higher for smokers than for nonsmokers \nexposed to smoke.\n \nCotinine (ng, mL)\n \nSmokers\nNonsmokers Exposed  \nto Smoke\n  0–99\n27.5%\n85.0%\n100–199\n30.0%\n  5.0%\n200–299\n35.0%\n  2.5%\n300–399\n  2.5%\n  2.5%\n400–499\n  5.0%\n             0%\n500–599\n       0%\n  5.0%\n\n\t\nAppendix D\t\n649\n\t11.\t The IQ scores appear to have a distribution that is approximately \nnormal.\n\t13.\t Yes. The red blood cell counts appear to have a distribution that \nis very approximately normal, although some might describe the \ndistribution as being left-skewed instead of normal.\n\t15.\t\n25.\t\nCotinine (Nonsmokers  \nExposed to Smoke in ng, mL)\n \nCumulative Frequency\nLess than 100\n34\nLess than 200\n36\nLess than 300\n37\nLess than 400\n38\nLess than 500\n38\nLess than 600\n40\n\t27.\t a.  \u0007The values of 551 and 543 are clearly outliers; the values of \n384, 241, 197, and 178 could also be outliers.\n\t\n\t b.  \u0007The number of classes increases from six to ten. The outlier \ncan greatly increase the number of classes. If there are too \nmany classes, we might use a larger class width with the effect \nthat the true nature of the distribution may be hidden.\nCotinine (Nonsmokers  \nExposed to Smoke in ng, mL)\n \nFrequency\n  0–99\n34\n100–199\n2\n200–299\n1\n300–399\n1\n400–499\n0\n500–599\n2\n600–699\n0\n700–799\n0\n800–899\n0\n900–999\n1\nSection 2-2 \n\t 1.\t It is easier to see the distribution of the data by examining the \ngraph of the histogram than by examining the numbers in a fre-\nquency distribution.\n\t 3.\t With a data set that is so small, the true nature of the distribution \ncannot be seen with a histogram.\n\t 5.\t Approximately 50\n\t 7.\t Approximately 4.5 mm; no\n\t 9.\t The pulse rates of males appear to have a distribution that is \n­approximately normal.\n\t17.\t The histogram suggests that the reported heights were rounded \nwith disproportionately many 0s and 5s. This suggests that the \nresults are not very accurate.\n\t19.\t Only part (c) appears to represent data from a normal distribu-\ntion. Part (a) has a systematic pattern that is not that of a straight \nline, part (b) has points that are not close to a straight-line pattern, \nand part (d) is really bad because it shows a systematic pattern \nand points that are not close to a straight-line pattern.\nSection 2-3 \n\t 1.\t The data set is too small for a graph to reveal important charac-\nteristics of the data. With such a small data set, it would be better \nto simply list the data or place them in a table.\n\t 3.\t No. Graphs should be constructed in a way that is fair and objec-\ntive. The readers should be allowed to make their own judgments, \ninstead of being manipulated by misleading graphs.\n\t 5.\t The pulse rate of 36 beats per minute appears to be an outlier.\n\n650\t\nAppendix D\n\t 7.\t The data are arranged in order from lowest to highest, as 36, 56, \n56, and so on.\n\t 9.\t There was a steep jump in the first four years, but the numbers of \ntriplets have shown a downward trend in the past several years.\n\t11.\t Misconduct includes fraud, duplication, and plagiarism, so it does \nappear to be a major factor.\n\t13.\t\ndata and to recognize that there may be a correlation between the \ntwo variables.\n\t 5.\t There does not appear to be a linear correlation between brain \nvolume and IQ score.\n\t 7.\t There does not appear to be a linear correlation between body tem-\nperature at 8 AM on one day and at 8 AM on the following day.\n\t 9.\t There does not appear to be a linear correlation.\n\t11.\t There does not appear to be a linear correlation.\nChapter 2: Quick Quiz\n\t 1.\t 0.04\t\n2.\t 0.075 and 0.115\n\t 3.\t No, it is impossible to determine the original values.\n\t 4.\t 16, 17, 18, 18, 19\t\n5.\t Bell-shaped\n\t 6.\t Variation\t\n7.\t Time-series graph\n\t 8.\t Scatterplot\t\n9.\t Pareto chart\n\t10.\t A frequency distribution is in the format of a table, but a histo-\ngram is a graph.\nChapter 2: Review Exercises\n\t 1.\t\n\t15.\t The distribution appears to be roughly bell-shaped, so the distri-\nbution is approximately normal.\n\t17.\t Because the vertical scale starts with a frequency of 200 instead \nof 0, the difference between the “no” and “yes” responses is \ngreatly exaggerated. The graph makes it appear that about five \ntimes as many respondents said “no,” when the ratio is actually a \nlittle less than 2.5 to 1.\nSection 2-4 \n\t 1.\t The term linear refers to a straight line, and r measures how well \na scatterplot of the sample paired data fits a straight-line pattern.\n\t 3.\t A scatterplot is a graph of paired (x, y) quantitative data. It helps \nus by providing a visual image of the data plotted as points, and \nsuch an image is helpful in enabling us to see any patterns in the \nTemperature (°F)\nFrequency\n97.0–97.4\n2\n97.5–97.9\n4\n98.0–98.4\n7\n98.5–98.9\n5\n99.0–99.4\n2\n\t 2.\t Yes, the data appear to be from a population with a normal \n­distribution because the bars start low and reach a maximum, \nthen decrease, and the left half of the histogram is approximately \na mirror image of the right half. The graph is approximately \n­bell-shaped.\n\n\t\nAppendix D\t\n651\n\t 3.\t By using fewer classes, the histogram does a better job of illus-\ntrating the distribution.\n\t 4.\t There are no outliers.\n\t 5.\t Yes. There is a pattern suggesting that there is a relationship.\n\t 6.\t a.  Time-series graph\n\t\n\t b.  Scatterplot\n\t\n\t c.  Pareto chart\n\t 7.\t By using a vertical scale that starts at 45% instead of 0%, the \ndifference is greatly exaggerated. The graph creates the false \nimpression that male enrollees outnumber female enrollees by a \nratio of about 3:1, but the actual percentages of 53% and 47% are \nmuch closer than that.\nChapter 2: Cumulative Review Exercises\n\t 1.\t\nGrooming Time (min)\nFrequency\n0–9\n2\n10–19\n3\n20–29\n9\n30–39\n4\n40–49\n2\n\t 2.\t The histogram is approximately bell-shaped. The frequencies \nincrease to a maximum and then decrease, and the left half of the \nhistogram is roughly a mirror image of the right half. The data do \nappear to be from a population with a normal distribution.\n\t 3.\t\n4.\t There are disproportionately many last digits of 0 and 5. Fourteen \nof the 20 times have last digits of 0 or 5. It appears that the sub-\njects reported their results and they tended to round the results. \nThe data do not appear to be very accurate.\nLast Digit\nFrequency\n0\n5\n1\n0\n2\n2\n3\n0\n4\n1\n5\n9\n6\n0\n7\n2\n8\n1\n9\n0\n\t 5.\t a.  Ratio    b.  Continuous\n\t\n\t c.  No. The grooming times are quantitative data.\n\t\n\t d.  Statistic\n\t 6.\t The scatterplot helps address the issue of whether there is a corre-\nlation between heights of mothers and heights of their daughters. \nThe scatterplot does not reveal a clear pattern suggesting that \nthere is a correlation.\nChapter 3 Answers\nSection 3-1 \n\t 1.\t The term average is not used in statistics. The term mean should \nbe used for the result obtained by adding all of the sample values \nand dividing the total by the number of sample values.\n\t 3.\t They use different approaches for providing a value (or values) of \nthe center or middle of the sorted list of data.\n\t 5.\t x = $266,594.0; median = $251,632.5; mode = none; midrange =  \n$313,459.5. Apart from the fact that the other charges are lower \nthan those given, nothing meaningful can be known about the \npopulation of all charges.\n\t 7.\t x = 57.1; median = 60.0; mode = none; midrange = 53.0. \nThe jersey numbers are nominal data that are just replacements \nfor names, and they do not measure or count anything, so the re-\nsulting statistics are meaningless.\n\t 9.\t x = 1.9; median = 2.0; mode = 1; midrange = 2.5. The mode \nof 1 correctly indicates that the smooth-yellow peas occur more \nthan any other phenotype, but the other measures of center don’t \nmake sense with these data at the nominal level of measurement.\n\t11.\t x = 1.178 W>kg; median = 1.380 W>kg; mode = 1.45 W>kg; \nmidrange = 1.000 W>kg. If concerned about radiation absorption,  \n\n652\t\nAppendix D\n652\t\nAPPENDIX D\nyou might purchase the cell phone with the lowest absorption \nrate. All of the cell phones in the sample have absorption levels \nbelow the FCC maximum of 1.6 W>kg.\n\t13.\t x = 18.9 firefighters; median = 19.0 firefighters; mode = 15 \nfirefighters and 20 firefighters; midrange = 21.0 firefighters. The \ndata are time-series data but the measures of center do not reveal \nanything about a trend consisting of a pattern of change over \ntime.\n\t15.\t x = $54,862.0; median = $54,590.5; mode = none; midrange =\n$55,292.0. Apart from the fact that all other colleges have tuition \nand fee amounts less than those listed, nothing meaningful can be \nknown about the population.\n\t17.\t Systolic: x = 127.6 mm Hg; median = 124.0 mm Hg. Diastolic: \nx = 73.6 mm Hg; median = 75.0 mm Hg. Given that systolic \nand diastolic blood pressures measure different characteristics, a \ncomparison of the measures of center doesn’t make much sense. \nBecause the data are matched, it would make more sense to in-\nvestigate whether there is an association or correlation between \nsystolic blood pressure measurements and diastolic blood pres-\nsure measurements.\n19.\t Female: x = 7.35; median = 7.05. Male: x = 6.17; median =\n5.70. (All units are 1000 cells>mL). Females appear to have \nhigher white blood cell counts.\n\t21.\t x = 53.7 mg>dL; median = 52.0 mg>dL. After excluding the \nhighest value of 138, which does appear to be an outlier, we get \nx = 53.4 mg>dL and median = 52.0 mg>dL, so excluding that \noutlier does not cause much of a change in the mean, and the me-\ndian remains the same.\n\t23.\t x = 98.20°F; median = 98.40°F. These results suggest that the \nmean is less than 98.6°F.\n\t25.\t x = 224.0. The mean from the frequency distribution is quite \nclose to the mean obtained by using the original list of values.\n\t27.\t 3.14; yes\n\t29.\t a. 90 beats per minute    b. n - 1\n\t31.\t Mean: 113.7 mg>dL; 10% trimmed mean: 112.2 mg>dL; 20% \ntrimmed mean: 111.8 mg>dL. The 10% trimmed mean and 20% \ntrimmed mean are both fairly close, but the untrimmed mean of \n113.7 mg>dL differs from them because it is more strongly af-\nfected by the outliers.\nSection 3-2\n\t 1.\t 119.0 cm3 is quite close to the exact value of the standard devia-\ntion of 124.9 cm3.\n\t 3.\t 401.6577 kg2\n\t 5.\t Range = $315,205.0; s2 = 8,502,938,525.9 dollars squared; \ns = $92,211.4. (Many technologies will not provide all of the \ndigits shown for the variance s2, so any result close to the value \nshown here is acceptable.) Because only the 10 highest sample \nvalues are used, nothing much can be known about the population \nof all such charges.\n\t 7.\t Range = 92.0; s2 = 1149.5; s = 33.9. The jersey numbers \nare nominal data that are just replacements for names, and they \ndo not measure or count anything, so the resulting statistics are \nmeaningless.\n\t 9.\t Range = 3.0; s2 = 0.9; s = 0.9. The measures of variation can \nbe found, but they make no sense because the data don’t measure \nor count anything. They are nominal data.\n\t11.\t Range = 0.980 W>kg; s2 = 0.114 1W>kg2 2; s = 0.337 W>kg. \nNo. Some models of cell phones have a much larger market share \nthan others, so the measures from the different models should be \nweighted according to their size in the population.\n\t13.\t Range = 26.0 firefighters; s2 = 60.9 firefighters2; s = 7.8 fire-\nfighters. The data are time-series data but the measures of varia-\ntion do not reveal anything about a trend consisting of a pattern \nof change over time.\n\t15.\t Range = $3938.0; s2 = 1,638,970.9 (dollars)2; s = $1280.2. \nBecause the data include only the 10 highest costs, the measures \nof variation don’t tell us anything about the variation among costs \nfor the population of all U.S. college tuitions.\n\t17.\t Systolic: 14.6%. Diastolic: 16.9%. The variation is roughly about \nthe same.\n\t19.\t Females: 21.3%. Males: 24.8%. The variation is roughly the same \nfor females and males.\n\t21.\t Range = 112.0 mg>dL; s2 = 238.3 1mg>dL2 2; s = 15.4 mg>dL. \nAfter excluding the highest value of 138 mg>dL, we get: Range =  \n87.0 mg>dL; s2 = 215.2 1mg>dL2 2; s = 14.7 mg>dL, so the \nmeasures of variation do change, but they don’t change by sub-\nstantial amounts.\n\t23.\t Range = 3.10°F; s2 = 0.39 1°F2 2; s = 0.62°F.\n\t25.\t The estimate of 28.0 mg>dL is far from s = 15.4 mg>dL.\n\t27.\t The estimate of 0.78°F is not substantially different from \ns = 0.62°F.\n\t29.\t Significantly low values are less than or equal to 49.0 beats per \nminute, and significantly high values are greater than or equal to \n99.0 beats per minute. A pulse rate of 44 beats per minute is sig-\nnificantly low.\n\t31.\t Significantly low values are less than or equal to 24.74 cm, and \nsignificantly high values are greater than or equal to 29.90 cm. A \nfoot length of 30 cm is significantly high.\n\t33.\t s = 68.4 is somewhat far from the exact value of 59.5.\n\t35.\t a. 24.7 cigarettes2    b. 24.7 cigarettes2    c. 12.3 cigarettes2\n\t\n\t d. \u0007Part (b), because repeated samples result in variances that \ntarget the same value (24.7 cigarettes2) as the population vari-\nance. Use division by n - 1.\n\t\n\t e. \u0007No. The mean of the sample variances (24.7 cigarettes2) equals \nthe population variance (24.7 cigarettes2), but the mean of the \nsample standard deviations (3.5 cigarettes) does not equal the \npopulation standard deviation (5.0 cigarettes).\nSection 3-3\n\t 1.\t James’s height is 4.07 standard deviations above the mean.\n\t 3.\t The bottom boxplot represents weights of women, because it de-\npicts weights that are generally lower.\n\t 5.\t a. 30.0 BPM    b. 2.40 standard deviations    c. z = 2.40\n\t\n\t d. Yes, the maximum pulse rate of 104 BPM is significantly high.\n\t 7.\t a. 1.70°F    b. 2.74 standard deviations    c. z = -2.74\n\t\n\t d. The minimum of 96.5°F is significantly low.\n\t 9.\t Significantly low values are less than or equal to 10.9; signifi-\ncantly high values are greater than or equal to 31.3.\n\t11.\t Significantly low weights are less than or equal to 1765.2 g; sig-\nnificantly high weights are greater than or equal to 4538.8 g.\n\t13.\t With z scores of 10.83 and -16.83, the z score of -16.83 is far-\nther from the mean, so the shortest man has a height that is more \nextreme.\n\n\t\nAppendix D\t\n653\n\t 3.\t 23.0. The numbers don’t measure or count anything. They are \nused as replacements for the names of the categories, so the \nnumbers are at the nominal level of measurement. In this case the \nmean is a meaningless statistic.\n\t 4.\t The girl has the larger relative birth weight because her z score of \n0.23 is larger than the z score of 0.19 for the boy.\n\t 5.\t The outlier is 646. The mean and standard deviation with the out-\nlier included are x = 267.8 and s = 131.6. Those statistics with \nthe outlier excluded are x = 230.0 and s = 42.0. Both statistics \nchanged by a substantial amount, so here the outlier has a very \nstrong effect on the mean and standard deviation.\n\t 6.\t The minimum is 119 mm, the first quartile Q1 is 128.0 mm, the \nsecond quartile Q2 (or median) is 131.0 mm, the third quartile Q3 \nis 135.0 mm, and the maximum is 141 mm.\n\t 7.\t Significantly low heights are 83.7 cm or less; significantly high \nheights are 111.3 cm or greater. The height of 87.8 cm is not sig-\nnificant, so the physician should not be concerned.\n\t 8.\t The median would be better because it is not affected much by \nthe one very large income.\nChapter 3: Cumulative Review Exercises\n\t 1.\t\n15.\t Male: z score = -2.69; female: z score = -2.18. The male \nhas the more extreme weight, but the female has the larger weight \nrelative to the group from which she came.\n\t17.\t 50th percentile\t\n19.\t 81st percentile\t\n21.\t 63.0 in.\n\t23.\t 66.5 in. (Tech: Minitab: 66.63 in.; Excel: 66.625 in.)\n\t25.\t 60.75 in.\n\t27.\t 50.0 in. (Tech: Minitab: 49.75 in.; Excel: 49.75 in.)\n\t29.\t 5-number summary: 25.1 in., 26.40 in., 27.50 in., 28.60 in.,  \n29.2 in.\n\t31.\t 5-number summary: 128 mBq, 140.0 mBq, 150.0 mBq,  \n158.5 mBq, 172 mBq (Tech: Minitab yields Q1 = 139.0 mBq \nand Q3 = 159.75 mBq. Excel yields Q1 = 141.0 mBq and \nQ3 = 157.25 mBq.)\n33. The top boxplot represents BMI values for females. The two box-\nplots do not appear to be very different, so BMI values of males \nand females appear to be about the same, except for a few high \nBMI values for females that caused the boxplot to extend farther \nto the right.\n\t35.\t Top boxplot represents females. The two boxplots are not dramati-\ncally different. Outliers for females: 48.0 in., 52.6 in., 56.8 in., \n59.0 in. Outliers for males: 43.2 in., 43.7 in., 44.2 in., 45.9 in.\nChapter 3: Quick Quiz\n\t 1.\t 6.8 hours\t\n2.\t 7.0 hours\n\t 3.\t Two modes: 7 hours, 8 hours\t\n4.\t 1.7 hours2\n\t 5.\t Yes, because 0 hours is substantially less than all of the other data \nvalues.\n\t 6.\t -0.93\t\n7.\t 75%, or 60 sleep times\n\t 8.\t Minimum, first quartile Q1, second quartile Q2 (or median), third \nquartile Q3, maximum\n\t 9.\t 1.5 hours (from range>4)\t\n10.\t x, m, s, s, s2, s2\nChapter 3: Review Exercises\n\t 1.\t a. 1559.6 mm;    b. 1550.0 mm;    c. none;    d. 1569.5 mm;\n\t\n\t e. 145.0 mm;    f. 53.4 mm;       g. 2849.3 mm2\n\t 2.\t z = 1.54. The eye height is not significantly low or high because \nits z score is between 2 and -2, so it is within 2 standard devia-\ntions of the mean.\nArsenic (Mg)\nFrequency\n0.0–1.9\n1\n2.0–3.9\n0\n4.0–5.9\n3\n6.0–7.9\n7\n8.0–9.9\n1\n2.\n3.\n\t 4.\t a. 6.09 mg        b. 6.45 mg    c. 1.75 mg\n\t\n\t d. 3.06 (mg)2    e. 6.70 mg\n\t 5.\t a. \u0007Mode, because the others are numerical measures that require \ndata at the interval or ratio levels of measurement.\n\t\n\t b. Convenience\n\t\n\t c. \u0007More consistency can be achieved by lowering the standard de-\nviation. (It is also important to keep the mean at an acceptable \nlevel.)\n\n654\t\nAppendix D\nChapter 4 Answers\nSection 4-1 \n\t 1.\t The probability of selecting someone with blue eyes is 0.35.\n\t 3.\t P1A2 = 0.488\t\n5.\t 0, 3>5, 1, 0.135\n\t 7.\t 1>9 or 0.111\t\n9.\t Significantly high\n\t11.\t Neither significantly low nor significantly high\n\t13.\t 1>2 or 0.5\t\n15.\t 1>4 or 0.25\n\t17.\t 1>10 or 0.1\t\n19.\t 0\n\t21.\t 5>555 or 0.00901. The employer would suffer because it would \nbe at risk by hiring someone who uses drugs.\n\t23.\t 50>555 or 0.0901. This result does appear to be a reasonable esti-\nmate of the prevalence rate.\n\t25.\t 879>945 or 0.930. Yes, the technique appears to be effective.\n\t27.\t 428>580 or 0.738; yes\n\t29.\t 0.130. No, it is not unlikely for someone to never seek medical \ninformation online. Because the responses are from a voluntary \nresponse survey, it is very possible that the results are not very \ngood.\n\t31.\t a. brown>brown, brown>blue, blue>brown, blue>blue\n\t\n\t b. 1>4      c. 3>4\n\t33.\t 3>8 or 0.375\t\n35.\t 4>16 or 1>4 or 0.25.\n\t37.\t The high probability of 0.327 shows that the sample results could \nhave easily occurred by chance. It appears that there is not suf-\nficient evidence to conclude that pregnant women can correctly \npredict the gender of their baby.\n\t39.\t The low probability of less than 0.001 shows that the sample \nresults could not have easily occurred by chance. It appears that \nOxyContin does have an effect on sleepiness.\nSection 4-2\n\t 1.\t P(A) represents the probability of selecting an adult with blue \neyes and P1A2 represents the probability of selecting an adult \nwho does not have blue eyes.\n\t 3.\t Because the selections are made without replacement, the events \nare dependent. Because the sample size of 1068 is less than 5% \nof the population size of 15,524,971, the selections can be treated \nas being independent (based on the 5% guideline for cumbersome \ncalculations).\n\t 5.\t 0.74\t\n7.\t 0.841\n\t 9.\t 91>152 or 0.599\t\n11.\t 138>152 or 0.908; not disjoint.\n\t13.\t a. 0.00974. Yes, the events are independent.\n\t\n\t b. 0.00915. The events are dependent.\n\t15.\t a. 0.731. Yes, the events are independent.\n\t\n\t b. 0.731. The events are dependent.\n\t17.\t 87>152 or 0.572\t\n19.\t 0.0627\n\t21.\t a. 300    b. 154    c. 0.513\n\t23.\t 0.990\n\t25.\t a. 0.03    b. 0.0009    c. 0.000027\n\t\n\t d. \u0007By using one drive without a backup, the probability of total \nfailure is 0.03, and with three independent disk drives, the \nprobability drops to 0.000027. By changing from one drive \nto three, the probability of total failure drops from 0.03 to \n0.000027, and that is a very substantial improvement in reli-\nability. Back up your data!\n\t27.\t 0.838. The probability of 0.838 is high, so it is likely that the en-\ntire batch will be accepted, even though it includes many defects.\n\t29.\t a. 0.299\n\t\n\t b. \u0007Using the 5% guideline for cumbersome calculations: 0.00239 \n[using the rounded result from part (a)]; or 0.00238\n\t31.\t a. 0.999775      b. 0.970225\n\t\n\t c. The series arrangement provides better protection.\n\t33.\t a. P1A or B2 = P1A2 + P1B2 - 2P1A and B2\n\t\n\t b. 85>152 or 0.559\nSection 4-3\n\t 1.\t The event of not getting at least 1 defect among the 3 batteries, \nwhich means that all 3 batteries are good.\n\t 3.\t The probability that the test indicates that the subject has glau-\ncoma given that the subject actually does have glaucoma.\n\t 5.\t 7>8 or 0.875\t\n7.\t 0.982\t\n9.\t 0.344\n\t11.\t 0.994. The probability is high enough so that she can be reason-\nably sure of getting a defective transducer for her work.\n\t13.\t a. 1>3 or 0.333      b. 0.5\n\t15.\t 0.5\n\t17.\t 2>1155 or 0.00173. This is the probability of the test making it \nappear that the subject has hepatitis C when the subject does not \nhave it, so the subject is likely to experience needless stress and \nadditional testing.\n\t19.\t 335>337 or 0.994. The very high result makes the test appear to \nbe effective in identifying hepatitis C.\n\t21.\t a. 0.9991\n\t\n\t b. \u00070.999973. The usual round-off rule for probabilities would \nresult in a probability of 1.00, which would incorrectly indicate \nthat we are certain to have at least one working hard drive.\n\t23.\t 0.490. The probability is not low, so further testing of the individ-\nual samples will be necessary in 49% of the combined samples.\n\t25.\t 0.569\nSection 4-4\n\t 1.\t pt is the proportion of the characteristic in the treatment group, \nand pc is the proportion of the characteristic in the control group.\n\t 3.\t We need to treat 37 subjects with the influenza vaccine in order \nto prevent one case of influenza. The result applies to a large \nnumber of subjects, not every particular group of 37 subjects.\n\t 5.\t Prospective\n\t 7.\t With treatment: 0.159; with placebo: 0.040. The risk of a head-\nache appears to be higher in the treatment group.\n\t 9.\t 9 (rounded up from 8.4)\n\t11.\t 3.99 or roughly 4. The risk of headaches among Viagra users is \nroughly 4 times the risk of headaches for those who take a placebo.\n\t13.\t a. 0.103    b. 0.100\n\t\n\t c. \u00070.00313. The chance of infection in the atorvastatin treatment \ngroup is slightly higher than for the placebo group. For those in \nthe placebo group, there is a 0.313% reduced chance of infec-\ntion when compared to the atorvastatin treatment group.\n\t15.\t Atorvastatin: 89:774 or roughly 1:9. Placebo: 27:243 or 1:9. \nThere is not much of a difference between these two results.\n\t17.\t Relative risk: 0.939; odds ratio: 0.938; the risk of a headache with \nNasonex treatment is slightly less than the risk of a headache \nwith a placebo.\n\n\t\nAppendix D\t\n655\nSection 4-5\n\t 1.\t During a year in China, there are 12.3 births for every 1000 \npeople in the population.\n\t 3.\t About 16,737,380 births are expected in a year.\n\t 5.\t 4.0 per 1000\t\n7.\t 10.6 per 1000\n\t 9.\t 64.3 per 1000 women aged 15–44\n\t11.\t 3.7 per 1000\n\t13.\t 0.008; the rate uses fewer decimal places and is easier to \n­understand.\n\t15\t a. 0.0083    b. 0.0000689\n\t\n\t c. \u00070.999931; using three significant digits would result in a prob-\nability of 1.00, which would be misleading because it would \nincorrectly suggest that it is certain that at least one survives \nthe year.\n\t17\t a. 31.3    b. 0.324\n\t19.\t No, the health of the nation is not necessarily declining. The in-\ncreasing number of deaths each year is probably due to the grow-\ning population.\n\t21.\t The United States has a population distribution of 33.10190862%, \n52.41701653%, and 14.48107485% for the three age categories. \nIf the 18,934,195 Florida residents have that same distribu-\ntion, the three age groups would have these numbers of people: \n6,267,580, 9,924,740, and 2,741,875, respectively. Using the \nsame Florida mortality rates for the three individual age groups \nand using the new adjusted population sizes for the three Florida \nage categories, we get these numbers of Florida deaths: 3974, \n40,155, and 105,112, respectively. Using the adjusted numbers of \ndeaths and the adjusted population sizes for the different catego-\nries, the crude mortality rate for Florida becomes 7.9 per 1000, \nwhich is much closer to the U.S. mortality rate of 8.0 per 1000 \nthan the mortality rate of 9.1 per 1000 found for Florida before \nthe adjustments.\nSection 4-6\n\t 1.\t The symbol ! is the factorial symbol that represents the product \nof decreasing whole numbers, as in 6! = 6 # 5 # 4 # 3 # 2 # 1 =\n720. Six people can be scheduled for X-ray films 720 different \nways.\n\t 3.\t The result of 126 is the number of different combinations that are \npossible when 4 items are selected without replacement from 9 \ndifferent items that are available.\n\t 5.\t 1>10,000\t\n7.\t 1>171\n\t 9.\t 1>40,320\t\n11.\t 1>254,251,200\n\t13.\t 1>100,000,000. No, there are too many different possibilities.\n\t15.\t 168,168,000\t\n17.\t 1>100,000\n\t19.\t Area codes: 800. Phone numbers: 6,400,000,000. Yes. (With a \ntotal population of about 400,000,000, there would be about 16 \nphone numbers for every adult and child.)\n\t21.\t a. 5040    b. 210    c. 1>210\n\t23.\t 6720\t\n25.\t 653,837,184,000\n\t27.\t 1>258,890,850. There is a much better chance of being struck by \nlightning.\n\t29.\t There are 62 different possible characters. The alphabet requires \n26 characters and there are 10 digits, so the Morse code system is \nmore than adequate.\n\t31.\t 2,095,681,645,538 (about 2 trillion)\nChapter 4: Quick Quiz\n\t 1.\t 4>5 or 0.8\t\n2.\t 0.7\n\t 3.\t 4>12 or 1>3\t\n4.\t 0.458\n\t 5.\t Answer varies, but the probability should be low, such as 0.01.\n\t 6.\t 0.0680\t\n7.\t 0.727\n\t 8.\t 0.00874\t\n9.\t 0.00459\n\t10.\t 0.0131\nChapter 4: Review Exercises\n\t 1.\t 0.814\n\t 2.\t 0.723\n\t 3.\t 0.918\n\t 4.\t 0.853\n\t 5.\t 0.571\n\t 6.\t 0.662 (not 0.663)\n\t 7.\t 0.663\n\t 8.\t A is the event of selecting a patient and getting someone who was \nnot treated with surgery. P1A2 = 0.532\n\t 9.\t A is the event of selecting a patient and getting someone who did \nnot have a successful treatment. P1A2 = 0.186.\n\t10.\t 0.537\n\t11.\t a. 0.25    b. 0.316\n\t\n\t c. \u0007No, because the probability of 0.316 shows that the event is \nlikely to occur quite often.\n\t12.\t a. 1>365    b. 31>365\n\t\n\t c. Answer varies, but it is probably quite small, such as 0.01 or \nless.    d. Yes\n\t13.\t 0.0335. No.\n\t14.\t a. 999>1000 or 0.999    b. 999,999>1,000,000 or 0.999999\nChapter 4: Cumulative Review Exercises\n\t 1.\t a. 0.168 g>dL    b. 0.160 g>dL    c. 0.220 g>dL\n\t\n\t d. 0.260 g>dL    e. 0.069 g>dL    f. 0.005 (g>dL)2\n\t 2.\t a. 0.09, 0.120, 0.160, 0.180, 0.35 (all in units of g>dL). Outlier: \n0.35 g>dL.\n\t\n\t b. \n\t\n\t c. \n\t 3.\t a. 46%    b. 0.460    c. Stratified sample\n\t 4.\t a. Convenience sample\n\t\n\t b. \u0007If the students at the college are mostly from a surrounding \nregion that includes a large proportion of one ethnic group,  \nthe results might not reflect the general population of the \nUnited States.\n\t\n\t c. 0.75    d. 0.64\n\n656\t\nAppendix D\n\t 5.\t The lack of any pattern of the points in the scatterplot suggests \nthat there does not appear to be an association between systolic \nblood pressure and blood platelet count.\nChapter 5 Answers\nSection 5-1 \n\t 1.\t The random variable is x, which is the number of girls in four \nbirths. The possible values of x are 0, 1, 2, 3, and 4. The values of \nthe random variable x are numerical.\n\t 3.\t ΣP1x2 = 0.063 + 0.250 + 0.375 + 0.250 + 0.063 = 1.001. \nThe sum is not exactly 1 because of a round-off error. The sum is \nclose enough to 1 to satisfy the requirement. Also, the variable x \nis a numerical random variable and its values are associated with \nprobabilities, and each of the probabilities is between 0 and 1 \ninclusive, as required. The table does describe a probability distri-\nbution.\n\t 5.\t a. Continuous random variable\n\t \t b. Not a random variable\t\nc. Discrete random variable\n\t \t d. Continuous random variable\t\ne. Discrete random variable\n\t 7.\t Probability distribution with m = 2.5, s = 1.1.\n\t 9.\t Not a probability distribution because the sum of the probabilities \nis 0.94, which is not 1, as required.\n\t11.\t Probability distribution with m = 0.7, s = 0.7.\n\t13.\t m = 4.0 girls, s = 1.4 girls\n\t15.\t Significantly high numbers of girls are greater than or equal to \nm + 2s, and m + 2s = 4.0 + 2(1.4) = 6.8 girls. Because  \n6 girls is not greater than or equal to 6.8 girls, it is not a signifi-\ncantly high number of girls.\n\t17.\t a. 0.109    b. 0.144    c. Part (b)\n\t \t d. No, because the probability of 0.144 is not very low (less than \nor equal to 0.05).\n\t19.\t m = 1.5 sleepwalkers, s = 1.0 sleepwalker\n\t21.\t Significantly high numbers of sleepwalkers are greater than or \nequal to m + 2s, and m + 2s = 1.5 + 211.02 = 3.5 sleep-\nwalkers. Because 3 sleepwalkers is not greater than or equal \nto 3.5 sleepwalkers, 3 sleepwalkers is not a significantly high \n­number.\n\t23.\t a. 0.363    b. 0.535    c. The probability from part (b).\n\t \t d. \u0007No, because the probability of 1 or fewer sleepwalkers is \n0.535, which is not low (not less than or equal to 0.05).\nSection 5-2 \n\t 1.\t The given calculation assumes that the first two peas have green \npods and the last three peas have yellow pods, but there are other \narrangements consisting of two peas with green pods and three \npeas with yellow pods. The probabilities corresponding to those \nother arrangements should also be included in the result.\n\t 3.\t Because the 30 selections are made without replacement, they \nare dependent, not independent. Based on the 5% guideline for \ncumbersome calculations, the 30 selections can be treated as be-\ning independent. (The 30 selections constitute about 3% of the \npopulation of 1020 responses, and 3% is not more than 5% of the \npopulation.) The probability could be found using the binomial \nprobability formula.\n\t 5.\t Not binomial. Each of the weights has more than two possible \noutcomes.\n\t 7.\t Binomial\n\t 9.\t Not binomial; there are more than two possible outcomes.\n\t11.\t Binomial\n\t13.\t a. 0.128    b. WWC, WCW, CWW; 0.128 for each    c. 0.384\n\t15.\t 0.0000819 (Table: 0+)\t\n17.\t 0.797 (Table: 0.798)\n\t19.\t 0.168\t\n21.\t 0.300\t\n23.\t 0.353\n\t25.\t a. m = 18.0 girls; s = 3.0 girls\n\t \t b. \u0007Values of 12.0 girls or fewer are significantly low, values of \n24.0 girls or greater are significantly high, and values between \n12.0 girls and 24.0 girls are not significant.\n\t \t c. \u0007Yes, because the result of 26 girls is greater than or equal to \n24.0 girls. A result of 26 girls would suggest that the XSORT \nmethod is effective.\n\t27.\t a. m = 7.5 peas; s = 1.4 peas\n\t \t b. \u0007Values of 4.7 or less are significantly low, values of 10.3 or \ngreater are significantly high, and values between 4.7 and 10.3 \nare not significant.\n\t \t c. \u0007No, because the result of 9 peas with green pods is not greater \nthan or equal to 10.3.\n\t29.\t 0.304; no.\n\t31.\t 0.662. The probability shows that about 2>3 of all shipments will \nbe accepted. With about 1>3 of the shipments rejected, the sup-\nplier would be wise to improve quality.\n\t33.\t a. \u00073.3 and 10.7. The result of 13 girls is greater than 10.7, so 13 is \na significantly high number of girls.\n\t \t b. 0.000854      c. 0.000916\n\t \t d. \u0007The probability from part (c) is relevant. The result of 13 girls \nis significantly high.\n\t \t e. \u0007The results suggest that the XSORT method is effective in in-\ncreasing the likelihood that a baby is a girl.\n\t35.\t a. \u000729.3 and 41.2. Because 34 falls between those limits, it is \n­neither significantly low nor significantly high.\n\t \t b. 0.118    c. 0.390\n\t \t d. \u0007The probability from part (c) is relevant. The result of 34 peas \nwith long stems is not significantly low.\n\t \t e. \u0007The results do not provide strong evidence against Mendel’s \nclaim of 75% for peas with long stems.\n\t37.\t 0.0468\n\t39.\t Without replacement: 0.139; with replacement: 0.147.\nSection 5-3 \n\t 1.\t m = 31,645>365 = 86.7, which is the mean number of patient \nadmissions per day. x = 85, because we want the probability that \na randomly selected day has exactly 85 admissions, and e ≈\n2.71828, which is a constant used in all applications of Formula 5-9.\n\n\t\nAppendix D\t\n657\n\t 3.\t Possible values of x: 0, 1, 2, . . . (with no upper bound). It is not \npossible to have x = 90.3 patient admissions in a day. x is a dis-\ncrete random variable.\n\t 5.\t P1122 = 0.114\t\n7.\t 0.999991\n\t 9.\t 0.9 murder; 0.402 (0.407 using the rounded mean). There should \nbe many days (roughly 40%) with no murders.\n\t11.\t a. 0.170\n\t \t b. \u0007The expected number is between 97.9 and 98.2, depending on \nrounding.\n\t \t c. \u0007The expected number of regions with 2 hits is close to 93, \nwhich is the actual number of regions with 2 hits.\n\t13.\t 0.9999876 or 0.9999877 (using unrounded mean). Very high \nchance, or “almost certain,” that at least one fatality will occur.\n\t15.\t a. 10.6154    b. 0.0000245.\n\t \t c. \u00070.116. With 2 of the 13 years having exactly 9 cases of ru-\nbella, the probability appears to be 2>13 or 0.154; the Poisson \ndistribution yields a probability of 0.116, which is in the gen-\neral ballpark, but it is off by a fairly large amount.\n\t17.\t The distribution is skewed to the right.\nChapter 5: Quick Quiz\n\t 1.\t m = 13.2 males\t\n2.\t s = 3.2 males\t\n3.\t Parameters\n\t 4.\t Significantly low: 6.8 or fewer. Significantly high: 19.6 or more.\n\t 5.\t 0.154\n\t 6.\t Yes. The sum of the probabilities is 1, and all of the probabilities \nare between 0 and 1 inclusive, and the values of x are numerical.\n\t 7.\t 0.3 male\n\t 8.\t 0.3 male2 (or 0.2 male2 if using the unrounded standard devia-\ntion)\n\t 9.\t 0+ indicates that the probability is a very small positive number. \nIt does not indicate that it is impossible for all five adult males to \nbe heavy drinkers.\n\t10.\t 0.999. Yes, 4 is significantly high.\nChapter 5: Review Exercises\n\t 1.\t 0.293\n\t 2.\t 0.807. No. The five subjects from the same family are not ran-\ndomly selected from the population of adults. Because they are \nfrom the same family, they are likely to share similar diet and \ngenetic factors, so they are not independent.\n\t 3.\t m = 1.4 adults and s = 1.0 adult.\n\t 4.\t Using m = 1.4 adults and s = 1.0 adult, values are significantly \nhigh if they are equal to or greater than m + 2s = 3.4 adults. \nThe result of five adults with high cholesterol is significantly \nhigh because it is equal to or greater than 3.4 adults. Also, the \nprobability that the five adults have high cholesterol is 0.00172, \nwhich is low (less than or equal to 0.05).\n\t 5.\t Using m = 1.4 adults and s = 1.0 adult, values are significantly \nlow if they are equal to or less than m - 2s = -0.6 adult, which \nis impossible. Also, the probability that 1 or fewer adults have \nhigh cholesterol is 0.570, which is not low (less than or equal to \n0.05). A result of 1 adult with high cholesterol is not a signifi-\ncantly low number.\n\t 6.\t No. The responses are not numerical.\n\t 7.\t a. Yes. The sum of the probabilities is 1. Each probability is be-\ntween 0 and 1 inclusive. The values of x are numerical.\n\t \t b. m = 1.1 condoms\n\t \t c. s = 0.9 condom\n\t \t d. \u0007Yes, 5 failures is significantly high. A number is significantly \nhigh if it is equal to or greater than m + 2s = 2.9, and 5 does \nexceed 2.9. Also, the probability of 5 or more failures is 0.001, \nwhich is a low probability.\n\t \t e. \u0007Here, the symbol 0+ represents a positive probability that is so \nsmall that it is 0.000 when rounded.\n\t 8.\t a. 143>365 or 0.392 death per day    b. 0.676\n\t \t c. 0.00750 (or 0.00749 if using the unrounded mean)\n\t \t d. No, because the event is so rare.\nChapter 5: Cumulative Review Exercises\n\t 1.\t a. 82.4 manatees    b. 82.0 manatees\n\t \t c. 28.0 manatees    d. 9.3 manatees\n\t \t e. \u000787.2 manatees2 (86.5 manatees2 results from using the rounded \nstandard deviation of 9.3 manatees)\n\t \t f. \u0007The trend of the manatee deaths over time is not addressed by \nthe preceding statistics.\n\t \t g. \u0007Significantly low numbers are 63.8 manatees or lower, and sig-\nnificantly high numbers are 101 manatees or higher. (If using \nunrounded statistics, the limits are 63.7 manatees and 101.1 \nmanatees.)\n\t \t h. \u0007None of the listed numbers are significantly low or signifi-\ncantly high.\n\t \t i. Ratio    j. Discrete\n\t 2.\t a. x = 4.6 and s = 2.7. They are statistics.\n\t \t b. \u0007The last digits appear to be random. None of the frequencies \nappears to be substantially different from the others.\n\t \t c. \u0007No. The values of x are numerical, but the frequencies are not \nprobabilities, as required.\n\t 3.\t No vertical scale is shown, but a comparison of the numbers \nshows that 7,066,000 is roughly 1.2 times the number 6,000,000; \nhowever, the graph makes it appear that the goal of 7,066,000 \npeople is roughly 3 times the number of people enrolled. The \ngraph is misleading in the sense that it creates the false impres-\nsion that actual enrollments are far below the goal, which is not \nthe case. Fox News apologized for this graph and provided a cor-\nrected graph.\n\t 4.\t a. 0.885    b. 0.0132    c. 0.307\n\t \t d. m = 4.6 adults, s = 2.0 adults. These results are parameters.\n\t \t e. \u0007Significantly low numbers are 0.6 or lower, and significantly \nhigh numbers are 8.6 and higher. Because 10 is greater than \n8.6, it is a significantly high number of adults with diabetes \n(among 40).\n\n658\t\nAppendix D\nChapter 6 Answers\nSection 6-1 \n\t 1.\t The word “normal” has a special meaning in statistics. It refers \nto a specific bell-shaped distribution that can be described by \nFormula 6-1. The lottery digits do not have a normal distribution.\n\t 3.\t The mean is m = 0 and the standard deviation is s = 1.\n\t 5.\t 0.4\t\n7.\t 0.2\t\n9.\t 0.6700\n\t11.\t 0.6993 (Table: 0.6992)\t\n13.\t 1.23\t\n15.\t -1.45\n\t17.\t 0.1093\t\n19.\t 0.8997\t\n21.\t 0.4013\n\t23.\t 0.9772\t\n25.\t 0.0214 (Table: 0.0215)\n\t27.\t 0.0174\t\n29.\t 0.9545 (Table: 0.9544)\n\t31.\t 0.8413 (Table: 0.8412)\t\n33.\t 0.999997 (Table: 0.9999).\n\t35.\t 0.5000\t\n37.\t 2.33\t\n39.\t -2.05, 2.05\n\t41.\t 1.28\t\n43.\t 1.75\n\t45.\t 68.27% (Table: 68.26%)\t\n47.\t 99.73% (Table: 99.74%)\n\t49.\t a. 2.28%    b. 2.28%    c. 95.45% (Table: 95.44%)\nSection 6-2 \n\t 1.\t a. m = 0; s = 1\n\t \t b. The z scores are numbers without units of measurement.\n\t 3.\t The standard normal distribution has a mean of 0 and a standard \ndeviation of 1, but a nonstandard normal distribution has a differ-\nent value for one or both of those parameters.\n\t 5.\t 0.8849\t\n7.\t 0.9053\t\n9.\t 136\n\t11.\t 69\t\n13.\t 0.9812\t\n15.\t 0.2431\n\t17.\t 90.0 beats per minute\n\t19.\t 44.9 beats per minute and 103.1 beats per minute. No, 102 beats \nper minute is not significantly high.\n\t21.\t 0.2015 (Table: 0.2005). No, the proportion of schizophrenics is \nnot at all likely to be as high as 0.2005, or about 20%.\n\t23.\t a. 0.1717 (Table: 0.1711)    b. 2011.5 g (Table: 2011.4 g)\n\t \t c. \u0007Birth weights are significantly low if they are 2011.4 g or less, \nand they are “low birth weights” if they are 2495 g or less. \nBirth weights between 2011.4 g and 2495 g are “low birth \nweights” but they are not significantly low.\n\t25.\t a. \u0007The mean is 71.320 mm Hg and the standard deviation is \n11.994 mm Hg. A histogram confirms that the distribution is \nroughly normal.\n\t \t b. 47.8 mm Hg; 94.8 mm Hg\n\t27.\t 0.0070\nSection 6-3 \n\t 1.\t a. \u0007In the long run, the sample proportions will have a mean of \n0.512.\n\t \t b. \u0007The sample proportions will tend to have a distribution that is \napproximately normal.\n\t 3.\t Sample mean; sample variance; sample proportion\n\t 5.\t No. The sample is not a simple random sample from the popu-\nlation of all births worldwide. The proportion of boys born in \nChina is substantially higher than in other countries.\n\t 7.\t a. 4.7\n\t\n\t b.\nSample  \nVariance s2\n \nProbability\n  0.0\n3>9\n  0.5\n2>9\n  8.0\n2>9\n12.5\n2>9\n\t\n\t c. 4.7\n\t \t d. \u0007Yes. The mean of the sampling distribution of the sample vari-\nances (4.7) is equal to the value of the population variance (4.7), so \nthe sample variances target the value of the population variance.\n\t 9.\t a. 5\n\t\n\t b.\nSample Median\nProbability\n4.0\n1>9\n4.5\n2>9\n5.0\n1>9\n6.5\n2>9\n7.0\n2>9\n9.0\n1>9\n\t\n\t c. 6.0\n\t \t d. \u0007No. The mean of the sampling distribution of the sample me-\ndians is 6.0, and it is not equal to the value of the population \nmedian (5.0), so the sample medians do not target the value of \nthe population median.\n\t11.\t a.\nx\nProbability\n34\n1>16\n35\n2>16\n36\n1>16\n37.5\n2>16\n38.5\n2>16\n41\n1>16\n42.5\n2>16\n43.5\n2>16\n46\n2>16\n51\n1>16\n\t\n\t b. \u0007The mean of the population is 40.5 and the mean of the sample \nmeans is also 40.5.\n\t \t c. \u0007The sample means target the population mean. Sample means \nmake good estimators of population means because they target \nthe value of the population mean instead of systematically un-\nderestimating or overestimating it.\n\n\t\nAppendix D\t\n659\n\t\nAPPENDIX D\t\n659\n\t13.\t a.\n\t \t c. \u0007Because the original population has a normal distribution, the \ndistribution of sample means is normal for any sample size.\n\t 9.\t a. 79.08% (Table 79.19%)    b. 99.44%\n\t11.\t a. 3.85% (Table 3.84%)    b. 0.02% (Table 0.01%)\n\t13.\t a. 131    b. 0.0000179 (Table: 0.0001)\n\t \t c.\t \u0007No. It is possible that the 4 subjects have a mean of 132 while \nsome of them have scores below the Mensa requirement of 131.\n\t15.\t a. 140 lb    b. 0.9999999998 (Table: 0.9999)\n\t\n\t c. 0.9458 (Table: 0.9463)\n\t \t d. \u0007The new capacity of 20 passengers does not appear to be safe \nenough because the probability of overloading is too high.\n\t17.\t a. 0.0047    b. 0.0000 (Table: 0.0001)\n\t \t c. \u0007The result from part (a) is relevant because the seats are occu-\npied by individuals.\n\t19.\t a. 0.8877 (Table: 0.8869)\n\t\n\t b. 1.0000 when rounded to four decimal places (Table: 0.9999).\n\t\n\t c. \u0007The probability from part (a) is more relevant because it shows \nthat 89% of male passengers will not need to bend. The result \nfrom part (b) gives us information about the mean for a group \nof 100 men, but it doesn’t give us useful information about the \ncomfort and safety of individual male passengers.\n\t \t d. \u0007Because men are generally taller than women, a design that \naccommodates a suitable proportion of men will necessarily \naccommodate a greater proportion of women.\n\t21.\t a. \u0007Yes. The sampling is without replacement and the sample size \nof n = 50 is greater than 5% of the finite population size of \n275. sx = 2.0504584.\n\t \t b. 0.5963 (Table: 0.5947)\nSection 6-5 \n\t 1.\t The histogram should be approximately bell-shaped, and the nor-\nmal quantile plot should have points that approximate a straight-\nline pattern.\n\t 3.\t We must verify that the sample is from a population having a nor-\nmal distribution. We can check for normality using a histogram, \nidentifying the number of outliers, and constructing a normal \nquantile plot.\n\t 5.\t Normal. The points are reasonably close to a straight-line pattern, \nand there is no other pattern that is not a straight-line pattern.\n\t 7.\t Not normal. The points are not reasonably close to a straight-line \npattern, and there appears to be a pattern that is not a straight-line \npattern.\n\t 9.\t Not normal\t\n11.\t Normal\n\t13.\t Not normal\nRange\nProbability\n  0\n4>16\n  2\n2>16\n  5\n2>16\n  7\n2>16\n10\n2>16\n15\n2>16\n17\n2>16\n\t\n\t b. \u0007The range of the population is 17, but the mean of the sample \nranges is 7. Those values are not equal.\n\t \t c. \u0007The sample ranges do not target the population range of 17, \nso sample ranges do not make good estimators of population \nranges.\n\t15.\t\nProportion of Girls\nProbability\n0\n0.25\n0.5\n0.50\n1\n0.25\n\t\n\t Yes. The proportion of girls in 2 births is 0.5, and the mean of the \nsample proportions is 0.5. The result suggests that a sample pro-\nportion is an unbiased estimator of a population proportion.\n\t17.\t a.\nProportion Correct\nProbability\n0\n16>25\n0.5\n8>25\n1\n1>25\n\t\n\t b. 0.2\n\t \t c. \u0007Yes. The sampling distribution of the sample proportions has a \nmean of 0.2 and the population proportion is also 0.2 (because \nthere is 1 correct answer among 5 choices). Yes, the mean of \nthe sampling distribution of the sample proportions is always \nequal to the population proportion.\n\t19.\t The formula yields P102 = 0.25, P10.52 = 0.5, and \nP112 = 0.25, which does describe the sampling distribution of \nthe sample proportions. The formula is just a different way of \npresenting the same information in the table that describes the \nsampling distribution.\nSection 6-4 \n\t 1.\t The sample must have more than 30 values, or there must be evi-\ndence that the population of grade-point averages from statistics \nstudents has a normal distribution.\n\t 3.\t mx represents the mean of all sample means, and sx represents the \nstandard deviation of all sample means. For the samples of 64 IQ \nscores, mx = 100 and sx = 15> 264 = 1.875.\n\t 5.\t a. 0.6844    b. 0.9726\n\t \t c. \u0007Because the original population has a normal distribution, the \ndistribution of sample means is a normal distribution for any \nsample size.\n\t 7.\t a. 0.1271 (Table: 0.1272)    b. 0.2510\n\n660\t\nAppendix D\n\t15.\t Normal\n\t17.\t Normal. The points have coordinates (32.5, -1.28),  \n(34.2, -0.52), (38.5, 0), (40.7, 0.52), (44.3, 1.28).\n\t19.\t a. Yes    b. Yes    c. No\nSection 6-6 \n\t 1.\t a. The area below (to the left of) 502.5\n\t\n\t b. The area between 501.5 and 502.5\n\t \t c. The area above (to the right of) 502.5\n\t 3.\t  p = 0.2; q = 0.8; m = 20; s = 4. The value of m = 20  \nshows that for people who make 100 random guesses for the  \n100 questions, the mean number of correct answers is 20. For \ngroups of 100 people who make random guesses, the standard \ndeviation of s = 4 is a measure of how much the numbers of \ncorrect ­responses vary.\n\t 5.\t 0.1102 (Table: 0.1093)\n\t 7.\t Normal approximation should not be used.\n\t 9.\t Using normal approximation: 0.1727 (Table: 0.1736); Tech using \nbinomial: 0.1724. The result of 40 people with blue eyes is not \nsignificantly high.\n\t11.\t Using normal approximation: 0.0105 (Table: 0.0104); Tech using \nbinomial: 0.0053. The result of 4 people with green eyes is sig-\nnificantly low.\n\t13.\t a. \u0007Using normal approximation: 0.0204; Tech using binomial: \n0.0205.\n\t\n\t b. \u0007Using normal approximation: 0.0569 (Table: 0.0571); Tech \n­using binomial: 0.0513.\n\t \t c. No\n\t15.\t a. \u0007Using normal approximation: 0.1008 (Table: 0.1003); Tech \n­using binomial: 0.1012.\n\t\n\t b. \u0007The result of 455 who have sleepwalked is not significantly \nhigh.\n\t \t c. \u0007The result of 455 does not provide strong evidence against the \nrate of 29.2%.\n\t17.\t (1) 0.1723; (2) 0.1704; (3) 0.1726. No, the approximations are \nnot off by very much.\nChapter 6: Quick Quiz\n\t 1.\t\n\t 2.\t z = -1.34\t\n3.\t 0.9983\n\t 4.\t  0.1546 (Table: 0.1547)\n\t 5.\t a. m = 0 and s = 1\n\t \t b. \u0007mx represents the mean of all sample means and sx represents \nthe standard deviation of all sample means.\n\t 6.\t 0.8092 (Table: 0.8106)\t\n7.\t 0.6280 (Table: 0.6292)\n\t 8.\t 84.6 mm Hg (Table: 84.5 mm Hg)\n\t 9.\t 0.9568 (Table: 0.9564)\n\t10.\t The normal quantile plot suggests that diastolic blood pressure \nlevels of women are normally distributed.\nChapter 6: Review Exercises\n\t 1.\t a. 0.9382    b. 0.9382    c. 0.8983\n\t\n\t d. -0.67    e. 0.0668\n\t 2.\t a. 1.13%    b. 63.8 in.\n\t 3.\t a. 1.42% (Table: 1.43%)    b. 59.0 in.\n\t 4.\t a. Normal    b. 100    c. 15> 264 = 1.875\n\t 5.\t a. \u0007An unbiased estimator is a statistic that targets the value of the \npopulation parameter in the sense that the sampling distribution \nof the statistic has a mean that is equal to the corresponding \nparameter.\n\t\n\t b. Mean; variance; proportion    c. True\n\t 6.\t a. \u000788.77% (Table: 88.69%). With about 11% of all men needing \nto bend, the design does not appear to be adequate, but the \nMark VI monorail appears to be working quite well in practice.\n\t \t b. 75.1 in\n\t 7.\t a. \u0007Because women are generally a little shorter than men, a door-\nway height that accommodates men will also accommodate \nwomen.\n\t\n\t b. 1, but actually a really small amount less than 1 (Table: 0.9999)\n\t \t c. \u0007Because the mean height of 60 men is less than 72 in., it does \nnot follow that the 60 individual men all have heights less than \n72 in. In determining the suitability of the door height for men, \nthe mean of 60 heights is irrelevant, but the heights of indi-\nvidual men are relevant.\n\t 8.\t a. \u0007No. A histogram is far from bell-shaped. A normal quantile \nplot reveals a pattern of points that is far from a straight-line \npattern.\n\t \t b. \u0007No. The sample size of n = 13 does not satisfy the condition \nof n 7 30, and the values do not appear to be from a popula-\ntion having a normal distribution.\n\t 9.\t Using normal approximation: 0.2286 (Table: 0.2296); Tech using \nbinomial: 0.2278. The occurrence of 787 offspring plants with \nlong stems is not significantly low because the probability of 787 \nor fewer plants with long stems is not small. The results are con-\nsistent with Mendel’s claimed proportion of 3>4.\n\t10.\t a. 1.49% (Table: 1.50%)    b. 69.4 in.\n\n\t\nAppendix D\t\n661\nChapter 6: Cumulative Review Exercises\n\t 1.\t a. 26.82    b. 28.90    c. 4.76    d. 0.96\n\t\n\t e. Ratio    f. Continuous\n\t 2.\t a. 26.45, 28.90, 29.05\n\t\n\t b.\n\t \t c. \u0007The sample does not appear to be from a population having a \nnormal distribution.\n\t 3.\t a. 0.001    b. 0.271\n\t\n\t c. \u0007The requirement that np Ú 5 is not satisfied, indicating that the \nnormal approximation would result in errors that are too large.\n\t\n\t d. 5.0 people    e. 2.1 people\n\t \t f. No, 8 is within two standard deviations of the mean and is \nwithin the range of values that could easily occur by chance.\n\t 4.\t a. \u0007B is the event of selecting someone who does not have blue \neyes.\n\t\n\t b. 0.65    c. 0.0429\n\t\n\t d. \u0007Using normal approximation: 0.0232 (Table: 0.0233); Tech us-\ning binomial: 0.0246.\n\t \t e. Yes\n\t 5.\t a. 0.7881    b. 0.9968 (Table: 0.9967)\n\t\n\t c. 10.4 in.     d. 0.0228\nChapter 7 Answers\nSection 7-1 \n\t 1.\t The confidence level, such as 95%, was not provided.\n\t 3.\t pn = 0.13 is the sample proportion; qn = 0.87 (found from evalu-\nating 1 - pn); n = 227 is the sample size; E = 0.04 is the margin \nof error; p is the population proportion, which is unknown. The \nvalue of a is 0.05.\n\t 5.\t 1.645\t\n7.\t 2.81\n\t 9.\t 0.400 { 0.025\t\n11.\t 0.0780 6 p 6 0.162\n\t13.\t a. 0.0705    b. E = 0.0333    c. 0.0372 6 p 6 0.104 \n\t \t d. \u0007We have 95% confidence that among subjects treated with \nOxyContin, the interval from 0.0372 to 0.104 actually does \ncontain the true value of the population proportion of subjects \nwho experience headaches.\n\t15.\t a. 0.143    b. E = 0.00815    c. 0.135 6 p 6 0.152\n\t \t d. \u0007We have 90% confidence that the interval from 0.135 to 0.152 \nactually does contain the true value of the population propor-\ntion of returned surveys.\n\t17.\t 0.462 6 p 6 0.529. Because 0.512 is contained within the con-\nfidence interval, there is not strong evidence against 0.512 as the \nvalue of the proportion of boys in all births.\n\t19.\t a. 17.4% 6 p 6 28.4%\n\t \t b. \u0007Because the two confidence intervals overlap, it is possible \nthat the OxyContin treatment group and the placebo group \nhave the same rate of nausea. Nausea does not appear to be an \nadverse reaction made worse with OxyContin.\n\t21.\t a. \u00070.0276% 6 p 6 0.0366% (using x = 135: 0.0276% 6 p 6\n0.0367%).\n\t \t b. No, because 0.0340% is included in the confidence interval.\n\t23.\t 91.4% 6 p 6 94.6%. It appears that the success rate for the \nXSORT method is much higher than the success rate of about \n50% expected with no treatment, so the XSORT method appears \nto be successful.\n\t25.\t 0.496 6 p 6 0.514. No, because the proportion could easily \nequal 0.5. The proportion does not appear to be significantly less \nthan 0.5 the week before Thanksgiving.\n\t27.\t Sustained care: 77.6% 6 p 6 88.1% (using x = 164). Standard \ncare: 56.1% 6 p 6 69.5% (using x = 125). The two confi-\ndence intervals do not overlap. It appears that the success rate is \nhigher with sustained care.\n\t29.\t a. 1844 (Table: 1842)    b. 664\n\t\n\t c. \u0007The added knowledge results in a very substantial decrease in \nthe required sample size.\n\t31.\t a. 385    b. 369\n\t \t c. No, the sample size doesn’t change much.\n\t33.\t a. 1537    b. 1532    c. No\n\t35.\t a. 752    b. 749\n\t \t c. \u0007No. A sample of the adults you know is a convenience sample, \nnot a simple random sample, so it is very possible that the re-\nsults would not be representative of the population.\n\t37.\t 1238 (Table: 1237)\n\t39.\t a. \u0007The requirement of at least 5 successes and at least 5 failures \nis not satisfied, so the normal distribution cannot be used.\n\t \t b. 0.075\nSection 7-2 \n\t 1.\t a. 12.855 g>dL 6 m 6 13.391 g>dL\n\t\n\t b. \u0007Best point estimate of m is 13.123 g>dL. The margin of error \nis E = 0.268 g>dL.\n\t \t c. \u0007Because the sample size of 100 is greater than 30, we can con-\nsider the sample mean to be from a population with a normal \ndistribution.\n\t 3.\t We have 95% confidence that the limits of 12.855 g>dL and \n13.391 g>dL contain the true value of the mean hemoglobin \nlevel of the population of all adult females.\n\t 5.\t Neither the normal nor the t distribution applies.\n\t 7.\t za>2 = 2.576 (Table: 2.575)\n\t 9.\t 29.4 hg 6 m 6 31.4 hg. No, the results do not differ by much.\n\t11.\t 98.08°F 6 m 6 98.32°F. Because the confidence interval does \nnot contain 98.6°F, it appears that the mean body temperature is \nnot 98.6°F, as is commonly believed.\n\t13.\t 71.4 min 6 m 6 126.4 min. The confidence interval includes \nthe mean of 102.8 min that was measured before the treatment, \nso the mean could be the same after the treatment. This result \nsuggests that the zopiclone treatment does not have a significant \neffect.\n\t15.\t 1.8 6 m 6 3.4. The given numbers are just substitutes for the \nfour DNA base names, so the numbers don’t measure or count \nanything, and they are at the nominal level of measurement. The \nconfidence interval has no practical use.\n\t17.\t The sample data meet the loose requirement of having a normal \ndistribution. CI: 0.707 W>kg 6 m 6 1.169 W>kg. Because the \nconfidence interval is entirely below the standard of 1.6 W>kg, it \nappears that the mean amount of cell phone radiation is less than \nthe FCC standard, but there could be individual cell phones that \nexceed the standard.\n\t19.\t 0.284 ppm 6 m 6 1.153 ppm. Using the FDA guideline, the \nconfidence interval suggests that there could be too much mer-\ncury in fish because it is possible that the mean is greater than \n\n662\t\nAppendix D\n1 ppm. Also, one of the sample values exceeds the FDA guideline \nof 1 ppm, so at least some of the fish have too much mercury.\n\t21.\t 19.5 mg 6 m 6 45.6 mg. People consume some brands much \nmore often than others, but the 20 brands are all weighted equally \nin the calculations, so the confidence interval might not be a \ngood estimate of the population mean. Just the presence of five \nzeros suggests that the sample is not from a normally distributed \npopulation, so the normality requirement is violated and the \nconfidence interval might not be good estimate of the population \nmean.\n\t23.\t a. 5.8 days 6 m 6 6.2 days    b. 5.9 days 6 m 6 6.3 days\n\t \t c. \u0007The two confidence intervals are very similar. The echinacea \ntreatment group does not appear to fare any better than the pla-\ncebo group, so the echinacea treatment does not appear to be \neffective.\n\t25.\t Females: 72.0 bpm 6 m 6 76.1 bpm. Males: 67.8 bpm 6 m 6\n71.4 bpm. Adult females appear to have a mean pulse rate that is \nhigher than the mean pulse rate of adult males. Good to know.\n\t27.\t The sample size is 94, and it does appear to be very practical.\n\t29.\t The required sample size is 38,415 (Table: 38,416). The sample \nappears to be too large to be practical.\n\t31.\t 4814 (Table: 4815). Yes, the assumption seems reasonable.\n\t33.\t a. 425    b. 212\n\t \t c. \u0007The result from part (a) is substantially larger than the result \nfrom part (b). The result from part (b) is likely to be better \nbecause it uses s instead of the estimated s obtained from the \nrange rule of thumb.\n\t35.\t a. 234.2 6 m 6 276.0    b. 235.0 6 m 6 275.2\n\t \t c. \u0007The second confidence interval is narrower, indicating that we \nhave a more accurate estimate when the relatively large sample \nis selected without replacement from a relatively small finite \npopulation.\nSection 7-3 \n\t 1.\t 95.0 cm3 6 s 6 182.5 cm3. We have 95% confidence that the \nlimits of 95.0 cm3 and 182.5 cm3 contain the true value of the \nstandard deviation of brain volumes.\n\t 3.\t The dotplot does not appear to depict sample data from a nor-\nmally distributed population. The large sample size does not \njustify treating the values as being from a normally distributed \npopulation. Because the normality requirement is not satisfied, \nthe confidence interval estimate of s should not be constructed \nusing the methods of this section.\n\t 5.\t df = 24. x2\nL = 12.401 and x2\nR = 39.364. CI: 0.19 mg 6 s 6  \n0.33 mg.\n\t 7.\t df = 146. x2\nL = 105.741 (Table: 67.328) and x2\nR = 193.761 \n(Table: 140.169). CI: 56.8 6 s 6 76.8 (Table: 66.7 6 s 6 96.3).\n\t 9.\t 0.55°F 6 s 6 0.72°F (Table: 0.56°F 6 s 6 0.74°F)\n\t11.\t 29.6 min 6 s 6 71.6 min. No, the ­confidence interval does not \nindicate whether the treatment is effective.\n\t13.\t 0.19 g 6 s 6 0.41 g\n\t15.\t a. 10 BPM 6 s 6 27 BPM  b. 12 BPM 6 s 6 33 BPM\n\t \t c. The variation does not appear to be significantly different.\n\t17.\t a. \u00078.8 days 6 s 6 10.7 days. The sample appears to be from a \npopulation with a distribution that is far from normal, so the \nconfidence interval estimate might not be very good.\n\t\n\t b. \u00077.5 days 6 s 6 9.2 days. The sample appears to be from a \npopulation with a distribution that is far from normal, so the \nconfidence interval estimate might not be very good.\n\t \t c. The amounts of variation are about the same.\n\t19.\t 19,205 is too large. There aren’t 19,205 biostatistics professors \nin the population, and even if there were, that sample size is too \nlarge to be practical.\n\t21.\t The sample size is 48. No, with many very low incomes and a \nfew high incomes, the distribution is likely to be skewed to the \nright and will not satisfy the requirement of a normal distribution.\n\t23.\t x2\nL = 109.565 and x2\nR = 175.276. The values from the approxi-\nmation are quite close to the actual critical values.\nSection 7-4 \n\t 1.\t Without replacement, every sample would be identical to the \noriginal sample, so the proportions or means or standard devia-\ntions or variances would all be the same, and there would be no \nconfidence “interval.”\n\t 3.\t Parts b, d, e are not possible bootstrap samples.\n\t 5.\t 0.000 6 p 6 0.500\n\t 7.\t a. 0.1 kg 6 m 6 8.6 kg    b. 1.9 kg 6 s 6 6.3 kg\n\t 9.\t Answers vary, but here are typical answers.\n\t\n\t a. -0.8 kg 6 m 6 7.8 kg    b. 1.2 kg 6 s 6 7.0 kg\n\t11.\t Answers vary, but here are typical answers.\n\t\n\t a. \u0007Bootstrap: 55.3 min 6 m 6 67.3 min. This isn’t dramatically \ndifferent from 51.9 min 6 m 6 71.4 min.\n\t \t b. \u0007Bootstrap: 6.2 min 6 s 6 13.7 min. This isn’t dramatically \ndifferent from 7.7 min 6 s 6 18.4 min.\n\t13.\t Answers vary, but here is a typical result: 0.348% 6 p 6 1.62%. \nThis is quite close to the confidence interval of 0.288% 6\np 6 1.57% found in Exercise 22 “Lipitor” from ­Section 7-1.\n\t15.\t Answers vary, but here is a typical result: 0.135 6 p 6 0.152. \nThe result is essentially the same as the confidence interval of \n0.135 6 p 6 0.152 found in Exercise 15 from Section 7-1.\n\t17.\t Answers vary, but here is a typical result: 3.69 6 m 6 4.15. This \nresult is very close to the confidence interval 3.67 6 m 6 4.17 \nthat would be found by using the methods from Section 7-2.\n\t19.\t Answers vary, but here is a typical result: \n0.712 W>kg 6 m 6 1.18 W>kg. This result is very close to the \nconfidence interval of 0.707 W>kg 6 m 6 1.169 W>kg found in \nExercise 17 of Section 7-2.\n\t21.\t a. Answers vary, but here is a typical result: 2.5 6 s 6 3.3.\n\t\n\t b. 2.4 6 s 6 3.7\n\t \t c. \u0007The confidence interval from the bootstrap method is not very \ndifferent from the confidence interval found using the methods \nof Section 7-3. Because a histogram or normal quantile plot \nshows that the sample appears to be from a population not hav-\ning a normal distribution, the bootstrap confidence interval of \n2.5 6 s 6 3.3 would be a better estimate of s.\n\t23.\t Answers vary, but here is a typical result using 10,000 bootstrap \nsamples: 2.5 6 s 6 3.3. This result is the same as the confi-\ndence interval found using 1000 bootstrap samples. In this  \ncase, increasing the number of bootstrap samples from 1000  \nto 10,000 does not have much of an effect on the confidence  \ninterval.\n\n\t\nAppendix D\t\n663\nChapter 7: Cumulative Review Exercises\n\t 1.\t x = 27.27 cm, median = 27.15 cm, s = 1.24 cm, \nrange = 3.80 cm. These results are statistics.\n\t 2.\t Significantly low values are 25.37 cm or lower, and significantly \nhigh values are 29.17 cm or higher. Because 30 cm exceeds \n29.17 cm, a foot length of 30 cm is significantly high (or long).\n\t 3.\t Ratio level of measurement; continuous data.\n\t 4.\t A histogram is not very helpful with only 10 data values, but \na normal quantile plot shows that the sample data appear to be \nfrom a population having a distribution that is approximately \nnormal.\n\t 5.\t 26.38 cm 6 m 6 28.16 cm\n\t 6.\t 482 adult females\n\t 7.\t a. 0.2375 (Table: 0.2389)    b. 0.0002 (Table: 0.0001)\n\t \t c. 26.04 cm\n\t 8.\t 95.6% 6 p 6 98.0%. Yes.\nChapter 8 Answers\nSection 8-1 \n\t 1.\t Rejection of the claim about aspirin is more serious because it \nis a drug used for medical treatments. The wrong aspirin dosage \ncould cause more serious adverse reactions than a wrong vitamin \nC dosage. It would be wise to use a smaller significance level for \ntesting the claim about the aspirin.\n\t 3.\t a.  H0: m = 174.1 cm\n\t\n\t b.  H1: m ≠174.1 cm\n\t\n\t c.  Reject the null hypothesis or fail to reject the null hypothesis.\n\t \t d.  \u0007No. In this case, the original claim becomes the null hypoth-\nesis. For the claim that the mean height of men is equal to \n174.1 cm, we can either reject that claim or fail to reject it, but \nwe cannot state that there is sufficient evidence to support that \nclaim.\n\t 5.\t a.  p 7 0.5\n\t \t b.  H0: p = 0.5; H1: p 7 0.5\n\t 7.\t a.  m = 69 bpm\n\t \t b.  H0: m = 69 bpm; H1: m ≠69 bpm\n\t 9.\t There is sufficient evidence to support the claim that most adults \ndo not have hypertension.\n\t11.\t There is not sufficient evidence to warrant rejection of the claim that \nthe mean pulse rate (in beats per minute) of adult males is 69 bpm.\n\t13.\t z = 13.11\n\t15.\t t = 0.657\n\t17.\t a.  Right-tailed\n\t\n\t b.  P-value = 0.1587\n\t \t c.  Fail to reject H0.\n\t19.\t a.  Two-tailed\n\t\n\t b.  P-value = 0.0444\n\t \t c.  Reject H0.\n\t21.\t a.  z = 1.645\n\t \t b.  Fail to reject H0.\n\t23.\t a.  z = {1.96\n\t \t b.  Reject H0.\n\t25.\t a.  Fail to reject H0.\n\t \t b.  \u0007There is not sufficient evidence to support the claim that more \nthan 70% of adults do not have hypertension.\nChapter 7: Quick Quiz\n\t 1.\t 0.130\n\t 2.\t We have 95% confidence that the limits of 0.110 and 0.150 con-\ntain the true value of the proportion of adults in the population \nwho correct their vision by wearing contact lenses.\n\t 3.\t  z = 2.576 (Table: 2.575)\n\t 4.\t 0.02 6 p 6 0.04 or 2% 6 p 6 4%\n\t 5.\t 601\n\t 6.\t 136\n\t 7.\t There is a loose requirement that the sample values are from a \nnormally distributed population.\n\t 8.\t The degrees of freedom is the number of sample values that can \nvary after restrictions have been imposed on all of the values. For \nthe sample data described in Exercise 7, df = 11.\n\t 9.\t t = 2.201\n\t10.\t No, the use of the x2 distribution has a fairly strict requirement that \nthe data must be from a normal distribution. The bootstrap method \ncould be used to find a 95% confidence interval estimate of s.\nChapter 7: Review Exercises\n\t 1.\t 0.00301 6 p 6 0.00348. We have 95% confidence that the lim-\nits of 0.00301 and 0.00348 contain the value of the population \nproportion.\n\t 2.\t 423\n\t 3.\t a. 22.083 mm    b. 22.034 mm 6 m 6 22.133 mm\n\t \t c. \u0007We have 95% confidence that the limits of 22.034 mm and \n22.133 mm contain the value of the population mean m.\n\t 4.\t 94\n\t 5.\t a. Student t distribution    b. Normal distribution\n\t\n\t c. \u0007None of the three distributions is appropriate, but a confidence \ninterval could be constructed by using bootstrap methods.\n\t\n\t d. x2 (chi-square distribution)\n\t \t e. Normal distribution\n\t 6.\t a. 1068    b. 234    c. 1068\n\t 7.\t 308.2 mg 6 m 6 355.4 mg. The confidence interval limits do \ncontain the desired amount of 325 mg, so the mean is not too \nbad, but examination of the individual amounts of aspirin shows \nthat some tablets have considerably more than the desired amount \nof 325 mg, while others have considerable less than that desired \namount. These tablets indicate a serious production problem that \nshould be corrected.\n\t 8.\t a. 26.3 mg 6 s 6 63.0 mg    b. 5 mg\n\t \t c. \u0007The desired s = 5 mg from part (b) is not contained within \nthe confidence interval from part (a). It appears that the cur-\nrent production method produces aspirin tablets with too much \nvariation, and that should be corrected.\n\t 9.\t Answers vary, but here is a typical result: \n310.6 mg 6 m 6 350.9 mg. The result is very close to the confi-\ndence interval found in Exercise 7.\n\t10.\t a. 0.0113 6 p 6 0.0287\n\t\n\t b. Answers vary, but here is a typical result: 0.0120 6 p 6 0.0290\n\t \t c. The confidence intervals are quite close.\n\n664\t\nAppendix D\n\t27.\t a.  Reject H0.\n\t \t b.  \u0007There is sufficient evidence to warrant rejection of the claim \nthat the mean pulse rate of adult males is 72 bpm.\n\t29.\t Type I error: In reality p = 0.1, but we reject the claim that \np = 0.1. Type II error: In reality p ≠0.1, but we fail to reject \nthe claim that p = 0.1.\n\t31.\t Type I error: In reality p = 0.87, but we support the claim that \np 7 0.87. Type II error: In reality p 7 0.87, but we fail to  \nsupport that conclusion.\n\t33.\t The power of 0.96 shows that there is a 96% chance of rejecting the \nnull hypothesis of p = 0.08 when the true proportion is actually \n0.18. That is, if the proportion of Chantix users who experience \nabdominal pain is actually 0.18, then there is a 96% chance of  \nsupporting the claim that the proportion of Chantix users who  \nexperience abdominal pain is greater than 0.08.\n\t35.\t 617\nSection 8-2 \n\t 1.\t a.  270\n\t \t b.  pn = 0.53\n\t 3.\t The method based on a confidence interval is not equivalent to \nthe P-value method and the critical value method.\n\t 5.\t a.  Left-tailed\n\t\n\t b.  z = -4.46\n\t\n\t c.  P-value: 0.000004\n\t\n\t d.  H0: p = 0.10. Reject the null hypothesis.\n\t \t e.  \u0007There is sufficient evidence to support the claim that fewer \nthan 10% of treated subjects experience headaches.\n\t 7.\t a.  Two-tailed\n\t\n\t b.  z = -1.36\n\t\n\t c.  P-value: 0.174\n\t\n\t d.  H0: p = 0.67. Fail to reject the null hypothesis.\n\t \t e.  \u0007There is not sufficient evidence to warrant rejection of the \nclaim that 67% of adults wash their hands after touching an \nanimal.\n\t 9.\t H0: p = 0.5. H1: p 7 0.5. Test statistic: z = 10.96. P-value: \n0.0000 (Table: 0.0001). Critical value: z = 2.33. Reject H0. There \nis sufficient evidence to support the claim that the YSORT method is \neffective in increasing the likelihood that a baby will be a boy.\n\t11.\t H0: p = 0.5. H1: p ≠0.5. Test statistic: z = 2.69. P-value: 0.0071 \n(Table: 0.0072). Critical values: z = {2.576 (Table: {2.575).  \nReject H0. There is sufficient evidence to reject the claim that the  \nproportion of those in favor is equal to 0.5. The result suggests that \nthe politician is wrong in claiming that the responses are random \nguesses equivalent to a coin toss.\n\t13.\t H0: p = 0.20. H1: p 7 0.20. Test statistic: z = 1.10.  \nP-value: 0.1367 (Table: 0.1357). Critical value: z = 1.645. Fail \nto reject H0. There is not sufficient evidence to support the claim \nthat more than 20% of OxyContin users develop nausea.  \nHowever, with pn = 0.229, we see that a large percentage of \nOxyContin users experience nausea, so that rate does appear to \nbe very high.\n\t15.\t H0: p = 0.15. H1: p 6 0.15. Test statistic: z = -1.31.  \nP-value = 0.0956 (Table: 0.0951). Critical value: z = -2.33. \nFail to reject H0. There is not sufficient evidence to support the \nclaim that the return rate is less than 15%.\n\t17.\t H0: p = 0.512. H1: p ≠0.512. Test statistic: z = -0.98.  \nP-value = 0.3286 (Table: 0.3270). Critical values: z = {1.96. \nFail to reject H0. There is not sufficient evidence to warrant  \nrejection of the claim that 51.2% of newborn babies are boys.  \nThe results do not support the belief that 51.2% of newborn \nbabies are boys; the results merely show that there is not strong \nevidence against the rate of 51.2%.\n\t19.\t H0: p = 0.5. H1: p ≠0.5. Test statistic: z = 0.98.  \nP-value: 0.3268 (Table: 0.3270). Critical values: z = {1.96.  \nFail to reject H0. There is not sufficient evidence to warrant rejec-\ntion of the claim that women who guess the gender of their babies \nhave a success rate equal to 50%.\n\t21.\t H0: p = 0.5. H1: p ≠0.5. Test statistic: z = -2.03.  \nP-value: 0.0422 (Table: 0.0424). Critical values: z = {1.645.  \nReject H0. There is sufficient evidence to warrant rejection of the \nclaim that touch therapists use a method equivalent to random \nguesses. However, their success rate of 123>280, or 43.9%, indi-\ncates that they performed worse than random guesses, so they do \nnot appear to be effective.\n\t23.\t H0: p = 0.000340. H1: p ≠0.000340. Test statistic: \nz = -0.66. P-value: 0.5122 (Table: 0.5092). Critical values: \nz = {2.81. Fail to reject H0. There is not sufficient evidence to \nsupport the claim that the rate is different from 0.0340%. Cell \nphone users should not be concerned about cancer of the brain  \nor nervous system.\n\t25.\t H0: p = 0.5. H1: p 7 0.5. Test statistic: z = 0.83.  \nP-value: 0.2031 (Table: 0.2033). Critical value: z = 1.645. Fail \nto reject H0. There is not sufficient evidence to support the claim \nthat among smokers who try to quit with nicotine patch therapy, \nthe majority are smoking a year after the treatment. The results \nshow that about half of those who use nicotine patch therapy are \nsuccessful in quitting smoking.\n\t27.\t H0: p = 0.80. H1: p ≠0.80. Test statistic: z = 0.98 (using \npn = 0.828) or z = 0.99 (using x = 164). If using pn = 0.828, \nP-value = 0.3246 (Table: 0.3270). If using x = 164,  \nP-value = 0.3198 (Table: 0.3222). Critical values: z = {2.576 \n(Table: {2.575). Fail to reject H0. There is not sufficient evi-\ndence to warrant rejection of the claim that 80% of patients stop \nsmoking when given sustained care. With a success rate around \n80%, it appears that sustained care is effective.\n\t29.\t Normal approximation entries: 0.0114, 0.0012, 0.0054. Exact \nentries: 0.0215, 0.0034, 0.0059. Exact with simple continuity \ncorrection: 0.0117, 0.0018, 0.0054. The P-values agree reason-\nably well with the large sample size of n = 1009. The normal \napproximation to the binomial distribution appears to work better \nas the sample size increases.\n\t31.\t a.  0.7219 (Table: 0.7224)\n\t\n\t b.  0.2781 (Table: 0.2776)\n\t \t c.  \u0007The power of 0.7219 shows that there is a reasonably good \nchance of making the correct decision of rejecting the false \nnull hypothesis. It would be better if the power were even \nhigher, such as greater than 0.8 or 0.9.\nSection 8-3 \n\t 1.\t The requirements are (1) the sample must be a simple random \nsample, and (2) either or both of these conditions must be satis-\n\n\t\nAppendix D\t\n665\n\t23.\t H0: m = 1000 hic. H1: m 6 1000 hic. Test statistic: t = -2.661. \nP-value = 0.0224 (Table: P-value is between 0.01 and 0.025). \nCritical value: t = -3.365. Fail to reject H0. There is not suf-\nficient evidence to support the claim that the population mean is \nless than 1000 hic. There is not strong evidence that the mean is \nless than 1000 hic, and one of the booster seats has a measure-\nment of 1210 hic, which does not satisfy the specified require-\nment of being less than 1000 hic.\n\t25.\t H0: m = 75 bpm. H1: m 6 75 bpm. Test statistic: t = -0.927. \nP-value = 0.1777 (Table: 70.10). Critical value: t = -1.655 \n(Table: -1.660 approximately). Fail to reject H0. There is not \nsufficient evidence to support the claim that the mean pulse rate \nof adult females is less than 75 bpm.\n\t27.\t H0: m = 90 mm Hg. H1: m 6 90 mm Hg. Test statistic: \nt = -21.435. P-value = 0.0000 (Table: 60.005). Critical value: \nt = -1.655 (Table: -1.660 approximately). Reject H0. There \nis sufficient evidence to support the claim that the adult female \npopulation has a mean diastolic blood pressure level less than  \n90 mm Hg. The conclusion addresses the mean of a population, \nnot individuals, so we cannot conclude that there are no female \nadults in the sample with hypertension.\n\t29.\t The computed critical t score is -1.6554, which is the same as \nthe value of -1.6554 found using Statdisk. The approximation \nappears to work quite well.\nSection 8-4 \n\t 1.\t The sample must be a simple random sample and the sample \nmust be from a normally distributed population. The normality \nrequirement for a hypothesis test of a claim about a standard \ndeviation is much stricter, meaning that the distribution of the \npopulation must be much closer to a normal distribution.\n\t 3.\t a.  Reject H0.\n\t\n\t b.  \u0007Reject the claim that the sample is from a population with a \nstandard deviation equal to 0.470 kg.\n\t \t c.  \u0007It appears that the vitamin supplement does affect the varia-\ntion among birth weights.\n\t 5.\t H0: s = 10 bpm. H1: s ≠10 bpm. Test statistic: \nx2 = 195.172. P-value = 0.0208. Reject H0. There is sufficient \nevidence to warrant rejection of the claim that pulse rates of men \nhave a standard deviation equal to 10 beats per minute. Using the \nrange rule of thumb with the normal range of 60 to 100 beats per \nminute is not very good for estimating s in this case.\n\t 7.\t H0: s = 2.08°F. H1: s 6 2.08oF. Test statistic: x2 = 9.329.  \nP-value = 0.0000 (Table: 60.005). Critical value : x2 = 74.252 \n(Table: 70.065 approximately). Reject H0. There is sufficient evi-\ndence to support the claim that body temperatures have a standard \ndeviation less than 2.08°F. It is very highly unlikely that the con-\nclusion in the hypothesis test in Example 5 from Section 8-3 would \nchange because of a standard deviation from a different sample.\n\t 9.\t H0: s = 15. H1: s 6 15. Test statistic: x2 = 6.963.  \nP-value = 0.0160 (Table: 60.025). Critical value: x2 = 8.672. \nReject H0. There is sufficient evidence to support the claim that \nIQ scores of physicians have a standard deviation less than 15.\n\t11.\t H0: s = 4.25 g. H1: s 6 4.25 g. Test statistic: x2 = 58.042.  \nP-value = 0.1545 (Table: 70.10). Critical value: x2 = 51.739. \nFail to reject H0. There is not sufficient evidence to support the \nfied: The population is normally distributed or n 7 30. There is \nnot enough information given to determine whether the sample is \na simple random sample. Because the sample size is not greater \nthan 30, we must check for normality, but the value of 583 sec \nappears to be an outlier, and a normal quantile plot or histogram \nsuggests that the sample does not appear to be from a normally \ndistributed population. The requirements are not satisfied.\n\t 3.\t A t test is a hypothesis test that uses the Student t distribution, \nsuch as the method of testing a claim about a population mean as \npresented in this section. The letter t is used in reference to the \nStudent t distribution, which is used in a t test.\n\t 5.\t P-value = 0.0437 (Table: 0.025 6 P-value 6 0.05).\n\t 7.\t P-value = 0.2581 (Table: 70.10)\n\t 9.\t H0: m = 98.6°F. H1: m ≠98.6°F. Test statistic: t = -3.865.  \nP-value: 0.0004. Critical values assuming a 0.05 significance \nlevel: t = {2.026. Reject H0. There is sufficient evidence to \nwarrant rejection of the claim that the mean body temperature is \nequal to 98.6°F.\n\t11.\t H0: m = 270. H1: m 6 270. Test statistic: t = -2.764.  \nP-value: 0.0032. Critical value assuming a 0.05 significance \nlevel: t = -1.655. Reject H0. There is sufficient evidence to  \nsupport the claim that the population of adult females has a mean \nplatelet count less than 270.\n\t13.\t H0: m = 3000 g. H1: m 7 3000 g. Test statistic: t = 0.752.  \nP-value = 0.2264 (Table: 70.10). Critical value: t = 2.345. Fail \nto reject H0. There is not sufficient evidence to support the claim that \nthe population of birth weights of females is greater than 3000 g.\n\t15.\t H0: m = 0. H1: m 7 0. Test statistic: t = 0.133.  \nP-value = 0.4472 (Table: 70.10). Critical value: t = 1.677 \n(Table: 1.676 approximately). Fail to reject H0. There is not suffi-\ncient evidence to support the claim that with garlic treatment, the \nmean change in LDL cholesterol is greater than 0. There is not \nsufficient evidence to support a claim that the garlic treatment is \neffective in reducing LDL cholesterol levels.\n\t17.\t H0: m = 0 lb. H1: m 7 0 lb. Test statistic: t = 3.872.  \nP-value = 0.0002 (Table: 60.005). Critical value: t = 2.426. \nReject H0. There is sufficient evidence to support the claim that \nthe mean weight loss is greater than 0. Although the diet appears \nto have statistical significance, it does not appear to have practical \nsignificance because the mean weight loss of only 3.0 lb does not \nseem to be worth the effort and cost.\n\t19.\t H0: m = 4.00. H1: m ≠4.00. Test statistic: t = -1.139.  \nP-value = 0.2554 (Table: 70.20). Critical values: t = {1.965 \n(Table: 1.966 approximately). Fail to reject H0. There is not  \nsufficient evidence to warrant rejection of the claim that the pop-\nulation of student course evaluations has a mean equal to 4.00. \nBecause the data are from the University of Texas at Austin, they \ndon’t necessarily apply to a larger population that extends beyond \nthat one institution.\n\t21.\t The sample data meet the loose requirement of having a normal \ndistribution. H0: m = 14 mg>g. H1: m 6 14 mg>g. Test  \nstatistic: t = -1.444. P-value = 0.0913 (Table: 70.05).  \nCritical value: t = -1.833. Fail to reject H0. There is not suffi-\ncient evidence to support the claim that the mean lead concentra-\ntion for all such medicines is less than 14 mg>g.\n\n666\t\nAppendix D\n(Table: 60.005). Critical value: t = -2.426. Reject H0. There \nis sufficient evidence to warrant rejection of the claim that the \nsample is from a population with a mean less than 5.4 million \ncells per microliter. The test deals with the distribution of sample \nmeans, not individual values, so the result does not suggest that \neach of the 40 males has a red blood cell count below 5.4 million \ncells per microliter.\n\t 4.\t H0: p = 0.204. H1: p ≠0.204. Test statistic: z = 0.76.  \nP-value: 0.4480 (Table: 0.4472). Critical values: z = {1.96. Fail \nto reject H0. There is not sufficient evidence to warrant rejection \nof the claim that the rate of smoking by adult males is now the \nsame as in 2008. The smoking rate appears to be about the same.\n\t 5.\t H0: m = 25 mg. H1: m ≠25 mg. Test statistic: t = -0.744.  \nP-value: 0.4694 (Table: 70.10). Critical values: t = {2.145. \nFail to reject H0. There is not sufficient evidence to warrant rejec-\ntion of the claim that the pills come from a population in which \nthe mean amount of atorvastatin is equal to 25 mg.\n\t 6.\t H0: m = 20.16. H1: m 6 20.16. Test statistic: t = -3.732.  \nP-value = 0.0023 (Table: 60.005). Critical value: t = -2.821. \nReject H0. There is sufficient evidence to support the claim that \nthe population of recent winners has a mean BMI less than 20.16. \nRecent winners appear to be significantly smaller than those from \nthe 1920s and 1930s.\n\t 7.\t H0: s = 1.34. H1: s ≠1.34. Test statistic: x2 = 7.053.  \nP-value = 0.7368 (Table: 70.20). Critical values: x2 = 1.735, \n23.589. Fail to reject H0. There is not sufficient evidence to  \nsupport the claim that the recent winners have BMI values with \nvariation different from that of the 1920s and 1930s.\n\t 8.\t a.  \u0007A type I error is the mistake of rejecting a null hypothesis \nwhen it is actually true. A type II error is the mistake of failing \nto reject a null hypothesis when in reality it is false.\n\t \t b.  \u0007Type I error: In reality, the mean BMI is equal to 20.16, but \nwe support the claim that the mean BMI is less than 20.16. \nType II error: In reality, the mean BMI is less than 20.16, but \nwe fail to support that claim.\nChapter 8: Cumulative Review Exercises\n\t 1.\t a.  37.1 deaths\t \t\nb.  36.0 deaths\n\t\n\t c.  9.8 deaths\t\n\t\nd.  96.8 deaths2\n\t\n\t e.  28.0 deaths\n\t \t f.  \u0007The pattern of the data over time is not revealed by the statis-\ntics. A time-series graph would be very helpful in understand-\ning the pattern over time.\n\t 2.\t a.  Ratio\t\n\t\nb.  Discrete\n\t\n\t c.  Quantitative\n\t \t d.  \u0007No. The data are from recent and consecutive years, so they \nare not randomly selected.\n\t 3.\t 29.1 deaths 6 m 6 45.0 deaths. We have 99% confidence that \nthe limits of 29.1 deaths and 45.0 deaths contain the value of the \npopulation mean.\n\t 4.\t H0: m = 72.6 deaths. H1: m 6 72.6 deaths. Test statistic: \nt = -13.509. P-value = 0.0000 (Table: 60.005). Critical value: \nt = -2.650. Reject H0. There is sufficient evidence to support \nthe claim that the mean number of annual lightning deaths is now \nless than the mean of 72.6 deaths from the 1980s. Possible fac-\ntors: Shift in population from rural to urban areas; better lightning \nclaim that the new process dispenses amounts with a standard \ndeviation less than the standard deviation of 4.25 g for the old \nprocess. The new process does not appear to be better in the sense \nof dispensing amounts that are more consistent.\n\t13.\t H0: s = 6.0 lb. H1: s ≠6.0 lb. Test statistic: x2 = 26.011.  \nP-value = 0.1101 (Table: 70.10). Critical values: x2 = 19.996, \n65.475 (Table: approximate critical values: 20.707, 66.766). Fail \nto reject H0. There is not sufficient evidence to warrant rejection \nof the claim that the amounts of weight loss have a standard  \ndeviation equal to 6.0 lb.\n\t15.\t H0: s = 109.3 sec. H1: s 6 109.3 sec. Test statistic: x2 = 0.616. \nP-value = 0.0001 (Table: 60.005). Critical value : x2 = 3.325. \nReject H0. There is sufficient evidence to support the claim that \nwith a single waiting line, the waiting times have a standard devia-\ntion less than 109.3 sec. Because the variation among waiting times \nappears to be reduced with the single waiting line, patients are \nhappier because their waiting times are closer to being the same. \nPatients are not annoyed by being stuck in an individual line that \ntakes much more time than other individual lines.\n\t17.\t Critical value: x2 = 81.540 (or 81.494 if using z = 2.326348 \nfound from technology), which is close to the value of 82.292 \nobtained from Statdisk and Minitab.\nChapter 8: Quick Quiz\n\t 1.\t a.  t distribution\t\n\t\nb.  Normal distribution\n\t \t c.  Chi-square distribution\n\t 2.\t a.  Two-tailed\t\n\t\nb.  Left-tailed\n\t \t c.  Right-tailed\n\t 3.\t a.  H0: p = 0.5. H1: p 7 0.5.\n\t\n\t b.  z = 1.39\n\t\n\t c.  Fail to reject H0.\n\t \t d.  \u0007There is not sufficient evidence to support the claim that the \nmajority of Internet users aged 18−29 use Instagram.\n\t 4.\t 0.0100\t\n5.  True\n\t 6.\t False\t\t\n7.  False\n\t 8.\t No. All critical values of x2 are always positive.\n\t 9.\t The t test requires that the sample is from a normally distributed \npopulation, and the test is robust in the sense that the test works \nreasonably well if the departure from normality is not too ex-\ntreme. The x2 (chi-square) test is not robust against a departure \nfrom normality, meaning that the test does not work well if the \npopulation has a distribution that is far from normal.\n\t10.\t The only true statement is the one given in part (a).\nChapter 8: Review Exercises\n\t 1.\t a.  False.\t\nb.  True.\n\t\n\t c.  False.\t\nd.  False.\n\t \t e.  False.\n\t 2.\t H0: p = 0.5. H1: p 7 0.5. Test statistic: z = 40.91 (using pn = 0.64) \nor z = 40.90 (using x =  13,661). P-value: 0.0000 (Table: 0.0001). \nCritical value: z = 2.33. Reject H0. There is sufficient evidence to \nsupport the claim that most people believe that the Loch Ness monster \nexists. Because the sample is a voluntary response sample, the con-\nclusion about the population might not be valid.\n\t 3.\t H0: m = 5.4 million cells per microliter. H1: m 6 5.4 million \ncells per microliter. Test statistic: t = -5.873. P-value: 0.0000 \n\n\t\nAppendix D\t\n667\nprotection and grounding in electric and cable and phone lines; \nbetter medical treatment of people struck by lightning; fewer \npeople use phones attached to cords; better weather predictions.\n\t 5.\t Because the vertical scale starts at 50 and not at 0, the difference \nbetween the number of males and the number of females is exag-\ngerated, so the graph is deceptive by creating the false impression \nthat males account for nearly all lightning strike deaths. A com-\nparison of the numbers of deaths shows that the number of male \ndeaths is roughly 4 times the number of female deaths, but the \ngraph makes it appear that the number of male deaths is around \n25 times the number of female deaths.\n\t 6.\t H0: p = 0.5. H1: p 7 0.5. Test statistic: z = 10.45.  \nP-value = 0.0000 (Table: 0.0001). Critical value: z = 2.33. \nReject H0. There is sufficient evidence to support the claim that \nthe proportion of male deaths is greater than 1>2. More males are \ninvolved in certain outdoor activities, such as construction, fish-\ning, and golf.\n\t 7.\t 0.763 6 p 6 0.854. Because the entire confidence interval is \ngreater than 0.5, it does not seem feasible that males and females \nhave equal chances of being killed by lightning.\n\t 8.\t a.  0.512\t\n\t\nb.  0.008\n\t\n\t c.  0.992\t\n\t\nd.  0.205\n\t\n\t e.  m = 40.0 males; s = 2.8 males\n\t \t f.  \u0007Yes. Using the range rule of thumb, significantly high values \nare m + 2s or greater. With m + 2s = 45.6, values above \n45.6 are significantly high, so 46 would be a significantly high \nnumber of male victims in a group of 50.\n\t 9.\t OR = 1.14. The odds in favor of experiencing migraine head-\naches is about 1.14 times higher for overweight people than for \npeople with normal weight.\nChapter 9 Answers\nSection 9-1 \n\t 1.\t The samples are simple random samples that are independent. \nFor each of the two groups, the number of successes is at least \n5 and the number of failures is at least 5. (Depending on what \nwe call a success, the four numbers are 33, 115, 201,196, and \n200,630 and all of those numbers are at least 5.) The require-\nments are satisfied.\n\t 3.\t a. H0: p1 = p2. H1: p1 6 p2.\n\t \t b. \u0007There is sufficient evidence to support the claim that the rate of \npolio is less for children given the Salk vaccine than for chil-\ndren given a placebo. The Salk vaccine appears to be effective.\n\t 5.\t H0: p1 = p2. H1: p1 7 p2. Test statistic: z = 12.82. ­ \nP-value: 0.0000. Critical value: z = 2.33. Reject H0. There is \nsufficient evidence to support the claim that vinyl gloves have a \ngreater virus leak rate than latex gloves.\n\t 7.\t a. \u0007H0: p1 = p2. H1: p1 6 p2. Test statistic: z = -1.66. \nP-value: 0.0484 (Table: 0.0485). Critical value: z = -2.33. \nFail to reject H0. There is not sufficient evidence to support the \nclaim that the rate of dementia among those who use ginkgo \nis less than the rate of dementia among those who use a pla-\ncebo. There is not sufficient evidence to support the claim that \nginkgo is effective in preventing dementia.\n\t\n\t b. \u000798% CI: -0.0541 6 p1 - p2 6 0.00904 (Table: -0.0542 6\np1 - p2 6 0.00909). Because the confidence interval limits \ninclude 0, there does not appear to be a significant difference \nbetween dementia rates for those treated with ginkgo and those \ngiven a placebo. There is not sufficient evidence to support the \nclaim that the rate of dementia among those who use ginkgo is \nless than the rate of dementia among those who use a placebo. \nThere is not sufficient evidence to support the claim that ginkgo \nis effective in preventing dementia.\n\t \t c. \u0007The sample results suggest that ginkgo is not effective in pre-\nventing dementia.\n\t 9.\t a. \u0007H0:p1 = p2. H1: p1 7 p2. Test statistic: z = 2.64. P-value: \n0.0041. Critical value: z = 2.33. Reject H0. There is sufficient \nevidence to support the claim that the rate of success for smok-\ning cessation is greater with the sustained care program.\n\t\n\t b. \u000798% CI: 0.0135 6 p1 - p2 6 0.200 (Table: 0.0134 6\np1 - p2 6 0.200). Because the confidence interval limits do \nnot contain 0, there is a significant difference between the two \nproportions. Because the interval consists of positive numbers \nonly, it appears that the success rate for the sustained care \nprogram is greater than the success rate for the standard care \nprogram.\n\t \t c. \u0007Based on the samples, the success rates of the programs are \n25.8% (sustained care) and 15.1% (standard care). That differ-\nence does appear to be substantial, so the difference between \nthe programs does appear to have practical significance.\n\t11.\t a. \u0007H0: p1 = p2. H1: p1 7 p2. Test statistic: z = 6.44. P-value \n= 0.0000 (Table: 0.0001). Critical value: z = 2.33. Reject \nH0. There is sufficient evidence to support the claim that the \nproportion of people over 55 who dream in black and white is \ngreater than the proportion of those under 25.\n\t\n\t b. \u000798% CI: 0.117 6 p1 - p2 6 0.240. Because the confidence \ninterval limits do not include 0, it appears that the two propor-\ntions are not equal. Because the confidence interval limits \ninclude only positive values, it appears that the proportion of \npeople over 55 who dream in black and white is greater than \nthe proportion of those under 25.\n\t \t c. \u0007The results suggest that the proportion of people over 55 who \ndream in black and white is greater than the proportion of \nthose under 25, but the results cannot be used to verify the \ncause of that difference.\n\t13.\t a. \u0007H0: p1 = p2. H1: p1 7 p2. Test statistic: z = 6.11. P-value =\n0.0000 (Table: 0.0001). Critical value: z = 1.645. Reject H0. \nThere is sufficient evidence to support the claim that the fatal-\nity rate is higher for those not wearing seat belts.\n\t\n\t b. \u000790% CI: 0.00559 6 p1 - p2 6 0.0123. Because the confi-\ndence interval limits do not include 0, it appears that the two \nfatality rates are not equal. Because the confidence interval \nlimits include only positive values, it appears that the fatality \nrate is higher for those not wearing seat belts.\n\t \t c. \u0007The results suggest that the use of seat belts is associated with \nfatality rates lower than those associated with not using seat \nbelts.\n\t15.\t a. \u0007H0: p1 = p2. H1: p1 ≠p2. Test statistic: z = 0.57.  \nP-value: 0.5720 (Table: 0.5686). Critical values: z = {1.96. \nFail to reject H0. There is not sufficient evidence to support the \nclaim that echinacea treatment has an effect.\n\t\n\t b. \u000795% CI: -0.0798 6 p1 - p2 6 0.149. Because the confi-\ndence interval limits do contain 0, there is not a significant \n\n668\t\nAppendix D\ndifference between the two proportions. There is not sufficient \nevidence to support the claim that echinacea treatment has an \neffect.\n\t \t c. \u0007Echinacea does not appear to have a significant effect on the \ninfection rate. Because it does not appear to have an effect, it \nshould not be recommended.\n\t17.\t a. \u0007H0: p1 = p2. H1: p1 6 p2. Test statistic: z = -7.94.  \nP-value: 0.0000 (Table: 0.0001). Critical value: z = -2.33. \nReject H0. There is sufficient evidence to support the claim that \nthe rate of right-handedness for those who prefer to use their \nleft ear for cell phones is less than the rate of right-handedness \nfor those who prefer to use their right ear for cell phones.\n\t \t b. \u000798% CI: -0.266 6 p 6 -0.126. Because the confidence \ninterval limits do not contain 0, there is a significant difference \nbetween the two proportions. Because the interval consists of \nnegative numbers only, it appears that the claim is supported.\n\t19.\t a. \u0007H0: p1 = p2. H1: p1 7 p2. Test statistic: z = 9.97.  \nP-value = 0.0000 (Table: 0.0001). Critical value: z = 2.33. \nReject H0. There is sufficient evidence to support the claim that \nthe cure rate with oxygen treatment is higher than the cure rate \nfor those given a placebo. It appears that the oxygen treatment \nis effective.\n\t\n\t b. \u000798% CI: 0.467 6 p1 - p2 6 0.687. Because the confidence \ninterval limits do not include 0, it appears that the two cure \nrates are not equal. Because the confidence interval limits \ninclude only positive values, it appears that the cure rate with \noxygen treatment is higher than the cure rate for those given a \nplacebo. It appears that the oxygen treatment is effective.\n\t \t c. \u0007The results suggest that the oxygen treatment is effective in \ncuring cluster headaches.\n\t21.\t a. \u0007H0: p1 = p2. H1: p1 6 p2. Test statistic: z = -1.17.  \nP-value = 0.1214 (Table: 0.1210). Critical value: z = -2.33.  \nFail to reject H0. There is not sufficient evidence to support the \nclaim that the rate of left-handedness among males is less than \nthat among females.\n\t\n\t b. \u000798% CI: -0.0848 6 p1 - p2 6 0.0264 (Table: -0.0849 6\np1 - p2 6 0.0265). Because the confidence interval limits \ninclude 0, there does not appear to be a significant difference \nbetween the rate of left-handedness among males and the rate \namong females. There is not sufficient evidence to support the \nclaim that the rate of left-handedness among males is less than \nthat among females.\n\t \t c. \u0007The rate of left-handedness among males does not appear to be \nless than the rate of left-handedness among females.\n\t23.\t The samples should include 2135 men and 2135 women.\n\t25.\t a. \u00070.0227 6 p1 - p2 6 0.217; because the confidence interval \nlimits do not contain 0, it appears that p1 = p2 can be rejected.\n\t\n\t b. \u00070.491 6 p1 6 0.629; 0.371 6 p2 6 0.509; because the con-\nfidence intervals do overlap, it appears that p1 = p2 cannot be \nrejected.\n\t\n\t c. \u0007H0: p1 = p2. H1: p1 ≠p2. Test statistic: z = 2.40.  \nP-value: 0.0164. Critical values: z = {1.96. Reject H0. There \nis sufficient evidence to reject p1 = p2.\n\t \t d. \u0007Reject p1 = p2. Least effective method: Using the overlap \n­between the individual confidence intervals.\nSection 9-2 \n\t 1.\t Only part (c) describes independent samples.\n\t 3.\t a. Yes    b. Yes    c. 98%\n\t 5.\t H0: m1 = m2. H1: m1 ≠m2. Test statistic: t = - 0.452. Criti-\ncal values: t = {1.987 (Table: t = {2.014). P-value: 0.6521 \n(Table: 70.20). Fail to reject H0. There is not sufficient evidence \nto warrant rejection of the claim that the two groups are from \npopulations with the same mean. This result suggests that the in-\ncreased humidity does not help in the treatment of croup.\n\t 7.\t a. \u0007H0: m1 = m2. H1: m1 6 m2. Test statistic: t = -2.908.  \nP-value = 0.0019 (Table: 60.005). Critical value: t = -1.649 \n(Table: -1.653 approximately). Reject H0. There is sufficient \nevidence to support the claim that the children exposed to co-\ncaine have a lower mean score.\n\t \t b. \u000790% CI: -1.4 6 m1 - m2 6 -0.4. Because the confidence \ninterval consists of negative numbers only, there is sufficient \nevidence to support the claim that the children exposed to co-\ncaine have a lower mean score.\n\t 9.\t a. \u0007H0: m1 = m2. H1: m1 7 m2. Test statistic: t = 8.075.  \nP-value = 0.0000 (Table: 60.005). Critical value: t = 1.678 \n(Table: t = 1.711). Reject H0. There is sufficient evidence \nto support the claim that unfiltered king-size cigarettes have \na mean tar content greater than that of filtered 100-mm ciga-\nrettes. The result suggests that the filters are effective in reduc-\ning the tar content, assuming that both types of cigarettes are \nabout the same size.\n\t \t b. \u000790% CI: 6.3 mg 6 m1 - m2 6 9.5 mg (Table: 6.2 mg 6\nm1 - m2 6 9.6 mg). The confidence interval limits include \npositive numbers only, which suggests that the mean tar con-\ntent of unfiltered king-size cigarettes is greater than the mean \nfor filtered 100-mm cigarettes.\n\t11.\t a. \u0007H0: m1 = m2. H1: m1 ≠m2. Test statistic: t = 5.045. P-value =\n0.0000 (Table: 60.01). Critical values: t = {2.058  \n(Table: {2.080). Reject H0. There is sufficient evidence to \nsupport the claim that there is a significant difference between \nthe treatment group and control group. We cannot conclude \nthat the cause is due to the treatment.\n\t \t b. \u000795% CI:1.47 6 m1 - m2 6 3.51 (Table: 1.46 6\nm1 - m2 6 3.52). Because the confidence interval does not \ncontain zero, there appears to be a significant difference be-\ntween the two population means. It does appear that there are \nsignificantly more errors made by those treated with alcohol.\n\t13.\t a. \u0007H0: m1 = m2. H1: m1 7 m2. Test statistic: t = 1.845.  \nP-value = 0.0352 (Table: 60.05). Critical value: t = 1.673 \n(Table 1.685). Reject H0. There is sufficient evidence to sup-\nport the claim that nonsmokers exposed to tobacco smoke have \na higher mean cotinine level than nonsmokers not exposed to \ntobacco smoke.\n\t\n\t b. \u000790% CI: 4.12 ng>mL 6 (m1 - m2) 6 84.34 ng>mL  \n(Table: 3.85 ng>mL 6 (m1 - m2) 6 84.61 ng>mL).\n\t \t c. \u0007Exposure to second-hand smoke appears to have the effect \nof being associated with greater amounts of nicotine than for \nthose not exposed to second-hand smoke.\n\t15.\t a. \u0007H0: m1 = m2. H1: m1 7 m2. Test statistic: t = 2.282.  \nP-value = 0.0132 (Table: 60.05). Critical value: t = 1.673 \n\n\t\nAppendix D\t\n669\n\t 7.\t a. \u0007H0: md = 0°F. H1: md ≠0°F. Test statistic: t = -7.499.  \nP-value = 0.0003 (Table: 60.01). Critical values: \nt = {2.447. Reject H0. There is sufficient evidence to warrant \nrejection of the claim that there is no difference between body \ntemperatures measured at 8 AM and at 12 AM. There appears \nto be a difference.\n\t \t b. \u000795% CI: -1.97°F 6 md 6 -1.00°F. The confidence interval \nconsists of negative numbers only and does not include 0.\n\t 9.\t H0: md = 0 in. H1: md ≠0 in. Test statistic: t = -1.379.  \nP-value = 0.2013 (Table: 70.20). Critical values: t = {2.262. \nFail to reject H0. There is not sufficient evidence to warrant rejec-\ntion of the claim that there is no difference in heights between \nmothers and their first daughters.\n\t11.\t -6.5 admissions 6 md 6 -0.2 admissions. Because the confi-\ndence interval does not include 0 admissions, it appears that there \nis sufficient evidence to warrant rejection of the claim that when \nthe 13th day of a month falls on a Friday, the numbers of hospital \nadmissions from motor vehicle crashes are not affected. Hospital \nadmissions do appear to be affected.\n\t13.\t -66.7 cm3 6 md 6 49.7 cm3 (Table: -66.8 cm3 6 md 6\n49.8 cm3). Because the confidence interval includes 0 cm3, the \nmean of the differences could be equal to 0 cm3, so there does not \nappear to be a significant difference.\n\t15.\t -4.16 in. 6 md 6 2.16 in. Because the confidence interval limits \ncontain 0, there is not sufficient evidence to support a claim that \nthere is a difference between self-reported heights and measured \nheights. We might believe that males would tend to exaggerate \ntheir heights, but the given data do not provide enough evidence \nto support that belief.\n\t17.\t a. \u0007H0: md = 0°F. H1: md ≠0°F. Test statistic: t = -8.485.  \nP-value = 0.0000 (Table: 60.01). Critical values: \nt = {1.996 (Table: {1.994). Reject H0. There is sufficient \nevidence to warrant rejection of the claim of no difference \nbetween body temperatures measured at 8 AM and at 12 AM. \nThere appears to be a difference.\n\t \t b. \u000795% CI: -1.05°F 6 md 6 -0.65°F. The confidence interval \nconsists of negative numbers only and does not include 0.\n\t19.\t H0: md = 0 in. H1: md ≠0 in. Test statistic: t = -6.347.  \nP-value = 0.0000 (Table: 60.01). Critical values: t = {1.978 \n(Table: {1.984 approximately). Reject H0. There is sufficient \nevidence to warrant rejection of the claim of no difference in \nheights between fathers and their first sons.\n\t21.\t For the temperatures in degrees Fahrenheit and the temperatures \nin degrees Celsius, the test statistic (t = 0.124) is the same, the \nP-value of 0.9023 is the same, the critical values (t = {2.028) \nare the same, and the conclusions are the same, so the hypothesis \ntest results are the same in both cases. The confidence intervals \nare -0.25°F 6 md 6 0.28°F and -0.14°C 6 md 6 0.16°C. The \nconfidence interval limits of -0.14°C and 0.16°C have numeri-\ncal values that are 5>9 of the numerical values of -0.25°F and \n0.28°F.\nSection 9-4 \n\t 1.\t a. \u0007No    b. No    c. The two samples have standard deviations \n(or variances) that are very close in value.    d. Skewed right\n(Table: 1.725). Reject H0. There is sufficient evidence to sup-\nport the claim that the mean IQ score of people with low blood \nlead levels is higher than the mean IQ score of people with \nhigh blood lead levels.\n\t\n\t b. \u000790% CI: 1.6 6 m1 - m2 6 10.4  \n(Table: 1.5 6 m1 - m2 6 10.5)\n\t \t c. \u0007Yes, it does appear that exposure to lead has an effect on \nIQ scores.\n\t17.\t a. \u0007H0: m1 = m2. H1: m1 ≠m2. Test statistic: t = 0.462.  \nP-value = 0.6465 (Table: 70.20). Critical values: \nt = {2.012 (Table: {2.120). Fail to reject H0. There is not \nsufficient evidence to warrant rejection of the claim that Dis-\nney animated children’s movies and other animated children’s \nmovies have the same mean time showing tobacco use.\n\t\n\t b. \u000795% CI: -41.3 sec 6 (m1 - m2) 6 65.9 sec  \n(Table: -44.2 sec 6 (m1 - m2) 6 68.8 sec)\n\t \t c. \u0007The times appear to be from a population with a distribution \nthat is not normal, but the methods in this section are robust \nagainst departures from normality. (Results obtained by using \nother methods confirm that the results obtained here are quite \ngood, even though the non-Disney times appear to violate the \nnormality requirement.)\n\t19.\t a. \u0007H0: m1 = m2. H1: m1 6 m2. Test statistic: t = -1.810. \nP-value = 0.0442 (Table: 70.025). Critical value: \nt = -2.574 (Table: -2.650). Fail to reject H0. There is not \nsufficient evidence to support the claim that the mean longev-\nity for popes is less than the mean for British monarchs after \ncoronation.\n\t \t b. \u000798% CI: -23.6 years 6 m1 - m2 6 4.0 years  \n(Table: -23.6 years 6 m1 - m2 6 4.4 years)\n\t21.\t H0: m1 = m2. H1: m1 ≠m2. Test statistic: t = -0.863.  \nP-value = 0.3887 (Table:70.20). Critical values are \nt = {1.968 (Table: {1.984). Fail to reject H0. There is not suf-\nficient evidence to warrant rejection of the claim that women and \nmen have the same mean diastolic blood pressure.\n\t23.\t With pooling, df increases dramatically to 97, but the test sta-\ntistic decreases from 2.282 to 1.705 (because the estimated \nstandard deviation increases from 2.620268 to 3.507614), the \nP-value increases to 0.0457, and the 90% confidence interval \nbecomes wider. With pooling, these results do not show greater \n­significance.\n\t25.\t H0: m1 = m2. H1: m1 ≠m2. Test statistic: t = 15.322.  \nP-value = 0.0000 (Table: 60.01). Critical values: t = {2.080. \nReject H0. There is sufficient evidence to warrant rejection of the \nclaim that the two populations have the same mean.\nSection 9-3 \n\t 1.\t Only parts (a) and (c) are true.\n\t 3.\t The results will be the same.\n\t 5.\t H0: md = 0. H1: md ≠0. Test statistic: t = -17.339.  \nP-value: 0.0001 (Table: 60.01). Critical values: t = {4.604. \nReject H0. There is sufficient evidence to support the claim of a \ndifference in measurements between the two arms. The right and \nleft arms should yield the same measurements, but the given data \nshow that this is not happening for this person.\n\n670\t\nAppendix D\n\t 5.\t Fail to reject H0. There is not sufficient evidence to warrant rejec-\ntion of the claim that for the people who were aware of the state-\nment, the proportion of women is equal to the proportion of men.\n\t 6.\t True\n\t 7.\t False\n\t 8.\t Because the data consist of matched pairs, they are dependent.\n\t 9.\t H0: md = 0. H1: md ≠0.\n\t10.\t a. t = d - md\nsd\n2n\n    b. t = (x1 - x2) - (m1 - m2)\nB\ns2\n1\nn1\n+ s2\n2\nn2\n\t\n\t c. z = (pn1 - pn2) - (p1 - p2)\nA\np q\nn1\n+ p q\nn2\n    d. F = s 2\n1\ns 2\n2\nChapter 9: Review Exercises\n\t 1.\t H0: p1 = p2. H1: p1 ≠p2. Test statistic: z = -4.20.  \nP-value: 0.0000 (Table: 0.0002). Critical values: z = {2.576 \n(Table: {2.575). Reject H0. There is sufficient evidence to war-\nrant rejection of the claim that the acceptance rate is the same \nwith or without blinding. Without blinding, reviewers know the \nnames and institutions of the abstract authors, and they might be \ninfluenced by that knowledge.\n\t 2.\t  -0.0372 6 p1 - p2 6 -0.00892. The confidence interval lim-\nits do not contain 0, so it appears that there is a significant differ-\nence between the two proportions.\n\t 3.\t  -25.33 cm 6 (m1 - m2) 6 -7.51 cm (Table: -25.70 cm 6 \n(m1 - m2) 6 -7.14 cm). With 95% confidence, we conclude \nthat the mean height of women is less than the mean height of \nmen by an amount that is between 7.51 cm and 25.33 cm  \n(Table: 7.14 cm and 25.70 cm).\n\t 4.\t H0: m1 = m2. H1: m1 6 m2. Test statistic: t = -4.001.  \nP-value: 0.0008 (Table: 60.005). Critical value: -2.666  \n(Table: -2.821). Reject H0. There is sufficient evidence to sup-\nport the claim that women have heights with a mean that is less \nthan the mean height of men.\n\t 5.\t a. \u0007H0: md = 0 kg. H1: md ≠0 kg. Test statistic: t = 2.301.  \nP-value: 0.0469. Critical values: t = {2.262 (assuming a 0.05 \nsignificance level). Reject H0 (assuming a 0.05 significance \nlevel). There is sufficient evidence to conclude that there is a \ndifference between pre-training and post-training weights.\n\t \t b. 0.0 kg 6 md 6 4.0 kg\n\t 6.\t H0: s1 = s2. H1: s1 ≠s2. Test statistic: F =  4.9933. P-value: \n0.0252. Upper critical F value: 4.0260. Reject H0. There is suf-\nficient evidence to warrant rejection of the claim that women and \nmen have heights with the same variation.\nChapter 9: Cumulative Review Exercises\n\t 1.\t a. \u0007Because the sample data are matched with each column con-\nsisting of heights from the same family, the data are dependent.\n\t\n\t b. \u0007x = 69.7 in.; median = 71.0 in.; range = 7.7 in.; s = 2.6 in.; \ns2 = 6.6 in2\n\t\n\t c. Ratio    d. Continuous\n\t 3.\t No. Unlike some other tests that have a requirement that samples \nmust be from normally distributed populations or the samples \nmust have more than 30 values, the F test has a requirement that \nthe samples must be from normally distributed populations, re-\ngardless of how large the samples are.\n\t 5.\t H0: s1 = s2. H1: s1 7 s2. Test statistic: F = 9.3364. P-value: \n0.0000. Critical F value: 2.0842 (Table: Critical F value is be-\ntween 2.0540 and 2.0960). Reject H0. There is sufficient evidence \nto support the claim that the treatment group has errors that vary \nmore than the errors of the placebo group.\n\t 7.\t H0: s1 = s2. H1: s1 ≠s2. Test statistic: F = 1.7778. P-value: \n0.0762. Upper critical F value: 1.8907 (Table: Critical F value is \nbetween 1.8752 and 2.0739). Fail to reject H0. There is not suffi-\ncient evidence to warrant rejection of the claim that subjects from \nboth treatment groups have ages with the same amount of varia-\ntion. If treatment groups have different characteristics, compari-\nsons of treatments become unclear, because differences might be \ndue to the treatments or they might be due to the different group \ncharacteristics.\n\t 9.\t H0: s1 = s2. H1: s1 7 s2. Test statistic: F = 2.1267.  \nP-value: 0.0543. Critical F value: 2.1682 (Table: Critical F value \nis between 2.1555 and 2.2341). Fail to reject H0. There is not \nsufficient evidence to support the claim that those given a sham \ntreatment have pain reductions that vary more than the pain \n­reductions for those treated with magnets.\n\t11.\t H0: s1 = s2. H1: s1 7 s2. Test statistic: F = 3.7539. P-value: \n0.0400. Critical F value: 3.4445. Reject H0. There is sufficient \nevidence to support the claim that king-size cigarettes with filters \nhave amounts of nicotine that vary more than the amounts of \nnicotine in non-filtered king-size cigarettes.\n\t13.\t H0: s1 = s2. H1: s1 7 s2. Test statistic: F = 1.8184.  \nP-value: 0.0774. Critical F value: 1.9983 (Table: Critical F value \nis ­between 1.9926 and 2.0772). Fail to reject H0. There is not \n­sufficient evidence to support the claim that men have body tem-\nperatures that vary more than the body temperatures of women.\n\t15.\t H0: s1 = s2. H1: s1 ≠s2. Test statistic: F = 4.3103.  \nP-value: 0.0023. Upper critical F value: 2.5308 (Table: Critical \nF value is between 2.4665 and 2.5699). Reject H0. There is suffi-\ncient evidence to warrant rejection of the claim that both popula-\ntions of longevity times have the same variation.\n\t17.\t c1 = 3, c2 = 0, critical value is 7.4569. Fail to reject H0. There \nis not sufficient evidence to support a claim that the two popula-\ntions of scores have different amounts of variation.\n\t19.\t FL = 0.4103; FR = 2.7006\nChapter 9: Quick Quiz\n\t 1.\t H0: p1 = p2. H1: p1 ≠p2.\n\t 2.\t x1 = 258, x2 = 282, pn1 = 258>1121 = 0.230, \npn2 = 282>1084 = 0.260, p = 0.245.\n\t 3.\t 0.1010\n\t 4.\t a. -0.0659 6 p1 - p2 6 0.00591\n\t \t b. \u0007The confidence interval includes the value of 0, so it is pos-\nsible that the two proportions are equal. There is not a signifi-\ncant difference.\n\n\t\nAppendix D\t\n671\n\t 9.\t H0: m1 = m2. H1: m1 ≠m2. Test statistic: t = -3.259.  \nP-value = 0.0019 (Table: 60.005). Critical values: t = {2.664 \n(Table: {2.724). Reject H0. There is sufficient evidence to war-\nrant rejection of the claim that males and females have the same \nmean braking reaction time. Males appear to have lower reaction \ntimes.\n\t10.\t a. \u0007Males: 40.1 6 m 6 48.7. Females: 47.2 6 m 6 61.4. The \nconfidence intervals overlap, so there does not appear to be a \nsignificant difference between the mean braking reaction times \nof males and females.\n\t\n\t b. \u0007-18.0 6 m1 - m2 6 -1.8  \n(Table: -18.2 6 m1 - m2 6 -1.6). Because the confidence \ninterval consists of negative numbers and does not include 0, \nthere appears to be a significant difference between the mean \nbraking reaction times of males and females.\n\t\n\t c. The results from part (b) are better.\nChapter 10 Answers\nSection 10-1\n\t 1.\t a. \u0007r is a statistic that represents the value of the linear correlation \ncoefficient computed from the paired sample data, and r is a \nparameter that represents the value of the linear correlation co-\nefficient that would be computed by using all of the paired data \nin the population of all statistics students.\n\t\n\t b. \u0007The value of r is estimated to be 0, because it is likely that \nthere is no correlation between body temperature and head \n­circumference.\n\t \t c. \u0007The value of r does not change if the body temperatures are \nconverted to Fahrenheit degrees.\n\t 3.\t No. A correlation between two variables indicates that they are \nsomehow associated, but that association does not necessarily \nimply that one of the variables has a direct effect on the other \nvariable. Correlation does not imply causality.\n\t 5.\t Yes. r = 0.963. P-value = 0.000. Critical values: {0.268 \n(Table: {0.279 approximately). There is sufficient evidence to \nsupport the claim that there is a linear correlation between the \nweights of bears and their chest sizes. It is easier to measure the \nchest size of a bear than the weight, which would require lifting \nthe bear onto a scale. It does appear that chest size could be used \nto predict weight.\n\t 7.\t Yes. r = 0.552. P-value 60.0001. Critical values are approxi-\nmately -0.196 and 0.196. There is sufficient evidence to support \nthe claim that there is a linear correlation between the heights of \nfathers and the heights of their sons.\n\t 9.\t a.\n\t 2.\t There does not appear to be a correlation or association between \nthe heights of fathers and the heights of their sons.\n\t 3.\t 67.6 in. 6 m 6 71.9 in. We have 95% confidence that the limits \nof 67.6 in. and 71.9 in. actually contain the true value of the mean \nheight of all adult sons.\n\t 4.\t H0: md = 0 in. H1: md ≠0 in. Test statistic: t = -1.712.  \nP-value = 0.1326 (Table: 70.10). Critical values: t = {2.365. \nFail to reject H0. There is not sufficient evidence to warrant rejec-\ntion of the claim that differences between heights of fathers and \ntheir sons have a mean of 0. There does not appear to be a differ-\nence between heights of fathers and their sons.\n\t 5.\t Because the points lie reasonably close to a straight-line pattern, \nand there is no other pattern that is not a straight-line pattern and \nthere are no outliers, the sample data appear to be from a popula-\ntion with a normal distribution.\n\t 6.\t The shape of the histogram indicates that the sample data appear \nto be from a population with a distribution that is approximately \nnormal.\n\t 7.\t Because the points are reasonably close to a straight-line pattern \nand there is no other pattern that is not a straight-line pattern, \nit appears that the braking reaction times of females are from a \npopulation with a normal distribution.\n\t 8.\t Because the boxplots overlap, there does not appear to be a sig-\nnificant difference between braking reaction times of males and \nfemales, but the braking reaction times for males appear to be \ngenerally lower than the braking reaction times of females.\n\n672\t\nAppendix D\n\t\n\t b. \u0007r = 0.816. P-value = 0.002 (Table: 60.01). Critical values: \nr = {0.602 assuming a 0.05 significance level. There is suf-\nficient evidence to support the claim of a linear correlation \nbetween the two variables.\n\t \t c. \u0007The scatterplot reveals a distinct pattern that is not a straight-\nline pattern.\n\t11.\t a. \u0007Answer varies. Because there appears to be an upward pattern, \nit is reasonable to think that there is a linear correlation.\n\t\n\t b. \u0007r = 0.906. P-value = 0.000 (Table: 60.01). Critical values: \nr = {0.632 (for a 0.05 significance level). There is sufficient \nevidence to support the claim of a linear correlation.\n\t\n\t c. \u0007r = 0. P-value = 1.000 (Table: 70.05). Critical values: \nr = {0.666 (for a 0.05 significance level). There is not suf-\nficient evidence to support the claim of a linear correlation.\n\t \t d. \u0007The effect from a single pair of values can be very substantial, \nand it can change the conclusion.\n\t13.\t r = 0.441. P-value = 0.174 (Table: 70.05). Critical values: \nr = {0.602. There is not sufficient evidence to support the \nclaim that there is a linear correlation between IQ scores and \nbrain volumes. It does not appear that people with larger brains \nhave higher IQ scores.\n\t15.\t r = 0.591. P-value = 0.294 (Table: 70.05). Critical values: \nr = {0.878. There is not sufficient evidence to support the \nclaim that there is a linear correlation between shoe print lengths \nand heights of males. The given results do not suggest that police \ncan use a shoe print length to estimate the height of a male.\n\t17.\t r = -0.959. P-value = 0.010. Critical values: r = {0.878. \nThere is sufficient evidence to support the claim that there is \na linear correlation between weights of lemon imports from \nMexico and U.S. car fatality rates. The results do not suggest any \ncause-effect relationship between the two variables.\n\t19.\t r = 0.028. P-value = 0.932 (Table: 70.05). Critical values: \nr = {0.576. There is not sufficient evidence to support the \nclaim that there is a linear correlation between pulse rates and \nsystolic blood pressures of adult females.\n\t21.\t r = 0.948. P-value = 0.004 (Table: 60.01). Critical values: \nr = {0.811. There is sufficient evidence to support the claim \nof a linear correlation between the overhead width of a seal in a \nphotograph and the weight of a seal.\n\t23.\t r = 0.113. P-value = 0.700 (Table: 70.05). Critical values: \nr = {0.532. There is not sufficient evidence to support the \nclaim that there is a linear correlation between heights of win-\nning presidential candidates and heights of their main opponents. \nIn an ideal world, voters would focus on important issues and not \nheight or physical appearance of candidates, so there should not \nbe a correlation.\n\t25.\t r = -0.063. P-value = 0.791 (Table: 70.05). Critical values: \nr = {0.444. There is not sufficient evidence to support the \nclaim that there is a linear correlation between IQ scores and \nbrain volumes.\n\t27.\t r = 0.594. P-value =  0.007 (Table: 60.01). Critical values: \nr = {0.456. There is sufficient evidence to support the claim \nthat there is a linear correlation between shoe print lengths and \nheights of males. The given results do suggest that police can use \na shoe print length to estimate the height of a male.\n\t29.\t r = -0.16217. (In this exercise, extra decimal places are needed \nfor r and the P-value. Table A-6  is not adequate to determine the \ncritical values and P-value for this exercise.) P-value = 0.0497. \nCritical values: r = {0.16197. There is sufficient evidence to \nsupport the claim that there is a linear correlation between pulse \nrates and systolic blood pressures of adult females.\n\t31.\t r = 0.748. (Table A-6 is not adequate to determine the critical \nvalues and P-value for this exercise.) P-value = 0.000. Critical \nvalues: {0.105. There is sufficient evidence to support the claim \nthat there is a linear correlation between right ear threshold mea-\nsurements and left ear threshold measurements.\n\t33.\t a. 0.911    b. 0.787    c. 0.9999 (largest)\n\t\n\t d. 0.976    e. -0.948 \nSection 10-2 \n\t 1.\t a. yn = 98.3 - 0.001x\n\t \t b. yn represents a predicted value of temperature.\n\t 3.\t a. \u0007A residual is a value of y - yn, which is the difference between \nan observed value of y and a predicted value of y.\n\t \t b. \u0007The regression line has the property that the sum of squares of \nthe residuals is the lowest possible sum.\n\t 5.\t With no significant linear correlation, the best predicted value is \ny = 161.69 cm.\n\t 7.\t With a significant linear correlation, the best predicted value is \n92.0 kg.\n\t 9.\t yn =  3.00 + 0.500x. The data have a pattern that is not a straight \nline.\n\t11.\t a. yn = 0.264 + 0.906x\n\t\n\t b. \u0007yn = 2 + 0x (or yn = 2)\n\t \t c. \u0007The results are very different, indicating that one point can dra-\nmatically affect the regression equation.\n\t13.\t yn = 44.9 + 0.0488x. Best predicted value: y = 99.0.\n\t15.\t yn = 125 + 1.73x. Best predicted value: y = 177.30 cm. \n­Because the best predicted value is the mean height, it would not \nbe helpful to police in trying to obtain a description of the male.\n\t17.\t yn = 16.5 - 0.00282x. Best predicted value: 15.1 fatalities per \n100,000 population. Common sense suggests that the prediction \ndoesn’t make much sense.\n\t19.\t yn = 117 + 0.0458x. Best predicted value: 121.0 mm Hg.\n\t21.\t yn = -157 + 40.2x. Best predicted value: -76.6 kg. The predic-\ntion is a negative weight that cannot be correct. The overhead \nwidth of 2 cm is well beyond the scope of the sample widths, so \nthe extrapolation might be off by a considerable amount. Clearly, \nthe predicted negative weight makes no sense.\n\t23.\t yn = 162 + 0.0975x. Best predicted height: y = 179.7 cm. \nHeights of opponents do not appear to be predicted well by using \nthe heights of the presidents.\n\t25.\t yn = 109 - 0.00670x. Best predicted value: y = 101.0.\n\t27.\t yn = 93.5 + 2.85x. Best predicted value: 182.7 cm. Although \nthere is a linear correlation, with r = 0.594, we see that it is not \nvery strong, so an estimate of the height of a male might be off \nby a considerable amount.\n\t29.\t yn = 138 - 0.223x. Best predicted value: 120 mm Hg.\n\t31.\t yn = 4.67 + 0.758x. Best predicted value: 19.8.\n\t33.\t a. 12.28\n\t \t b. \u0007The sum of squares of the residuals is 15.71, which is larger \nthan 12.28.\n\n\t\nAppendix D\t\n673\nmonoxide. It is best because it has the highest adjusted R2 value \nof 0.927 and the lowest P-value of 0.000. It is a good regression \nequation for predicting nicotine content because it has a high \nvalue of adjusted R2 and a low P-value.\n\t15.\t There are three possible regression equations corresponding to \npredictor variables of (1) brain volume; (2) body weight; (3) \nbrain volume and body weight. The best regression equation is \nyn = 109 - 0.00670x1, where x1 represents brain volume. It is \nbest because it has the highest adjusted R2 value of 0.0513 and \nthe lowest P-value of 0.791. The three regression equations all \nhave adjusted values of R2 that are very close to 0, so none of \nthem are good for predicting IQ. It does not appear that people \nwith larger brains have higher IQ scores.\n\t17.\t For H0: b1 = 0, the test statistic is t = 10.814, the P-value is \nless than 0.0001, so reject H0 and conclude that the regression \ncoefficient of b1 = 0.769 should be kept. For H0: b2 = 0, the \ntest statistic is t = 29.856, the P-value is less than 0.0001, so re-\nject H0 and conclude that the regression coefficient of b2 = 1.01 \nshould be kept. It appears that the regression equation should \ninclude both of the independent variables of height and waist cir-\ncumference.\nSection 10-5 \n\t 1.\t A dummy variable is a variable having only two values and those \nvalues (such as 0 and 1) are used to represent the different catego-\nries of a qualitative variable.\n\t 3.\t With simple logistic regression, there is only one predictor vari-\nable, but with multiple logistic regression, there are two or more \npredictor variables.\n\t 5.\t Length and weight are predictor variables. The response variable \nis sex, which is a dummy variable.\n\t 7.\t The probability that the bear is a male is 0.826. The probability \nthat the bear is a female is 0.174.\n\t 9.\t Weight = 3.06 + 82.4(Sex) + 2.91(AGE). Female: 61 lb; \nmale: 144 lb. The sex of the bear does appear to have an effect on \nits weight. The regression equation indicates that the predicted \nweight of a male bear is about 82 lb more than the predicted \nweight of a female bear with other characteristics being the same.\n\t11.\t ln a\np\n1 - pb = -41.2 + 0.2501Height2 - 0.008561Weight2.\n\t\n\t The probability of a male is 0.629.\n\t13.\t ln a\np\n1 - pb = -101.5 + 1.911Foot Length2 + 0.3011Height2.\n\t\n\t The probability of a male is 0.9999.\nChapter 10: Chapter Quick Quiz\n\t 1.\t Conclude that there is not sufficient evidence to support the claim \nof a linear correlation between the systolic blood pressure mea-\nsurements of the right and left arms.\n\t 2.\t None of the given values change when the variables are switched.\n\t 3.\t The value of r does not change if all values of one of the vari-\nables are multiplied by the same constant.\n\t 4.\t Because r must be between -1 and 1 inclusive, the value of \n1.500 is the result of an error in the calculations.\n\t 5.\t The best predicted value is 163.2 mm Hg, which is the mean of \nthe five measurements for the left arm.\nSection 10-3 \n\t 1.\t The value of se = 16.27555 cm is the standard error of estimate, \nwhich is a measure of the differences between the observed \nweights and the weights predicted from the regression equation. \nIt is a measure of the variation of the sample points about the re-\ngression line.\n\t 3.\t The coefficient of determination is r2 = 0.155. We know that \n15.5% of the variation in weight is explained by the linear cor-\nrelation between height and weight, and 84.5% of the variation in \nweight is explained by other factors and>or random variation.\n\t 5.\t r2 = 0.764. 76.4% of the variation in temperature is explained by \nthe linear correlation between chirps and temperature, and 23.6% \nof the variation in temperature is explained by other factors  \nand>or random variation.\n\t 7.\t r2 = 0.872. 87.2% of the variation in weights of bears is ex-\nplained by the linear correlation between neck size and weight, \nand 12.8% of the variation in weights is explained by other fac-\ntors and>or random variation.\n\t 9.\t r = 0.850. Critical values: r = {0.404 (Table: r = {0.396 \napproximately), assuming a 0.05 significance level. There is suf-\nficient evidence to support a claim of a linear correlation between \nregistered boats and manatee fatalities.\n\t11.\t 70.5 manatees\n\t13.\t 42.7 manatees 6 y 6 98.3 manatees\n\t15.\t 65.1 manatees 6 y 6 106.8 manatees\n\t17.\t a. 618.9541    b. 304.7126\n\t \t c. 56.0 mm Hg 6 y 6 81.6 mm Hg\n\t19.\t a. 352.7278    b. 109.3722    c. 71.09oF 6 y 6 88.71oF\n\t21.\t a. 6.5 6 y 6 7.2    b. 6.2 6 y 6 6.8\nSection 10-4 \n\t 1.\t The response variable is weight, and the predictor variables are \nlength and chest size.\n\t 3.\t The unadjusted R2 increases (or remains the same) as more vari-\nables are included, but the adjusted R2 is adjusted for the number \nof variables and sample size. The unadjusted R2 incorrectly sug-\ngests that the best multiple regression equation is obtained by \nincluding all of the available variables, but by taking into account \nthe sample size and number of predictor variables, the adjusted \nR2 is much more helpful in weeding out variables that should not \nbe included.\n\t 5.\t Son = 18.0 + 0.504 Father + 0.277 Mother\n\t 7.\t P-value less than 0.0001 is low, but the values of R2 (0.3649) and \nadjusted R2 (0.3552) are not high. Although the multiple regres-\nsion equation fits the sample data best, it is not a good fit, so it \nshould not be used for predicting the height of a son based on the \nheight of his father and the height of his mother.\n\t 9.\t Waist circumference, because it has the highest adjusted R2 value \nand the P-values are the same for the three individual variables.\n\t11.\t Some subjective judgment is involved here. A good choice \nwould be to use all three variables because the adjusted R2 value \nof 0.939 is considerably higher than any of the other values of \nadjusted R2. With this reasoning, the best regression equation is \nyn = -147 + 0.632 HT + 0.697 WAIST + 1.58 ARM.\n\t13.\t The best regression equation is yn = 0.127 + 0.0878x1 -\n0.0250x2, where x1 represents tar and x2 represents carbon  \n\n674\t\nAppendix D\n\t\n\t b. \u0007Three of the original pairs of sample data are the same  \n(20, 16), so those three points are at the same location and they \nappear to be one point.\n\t\n\t c. \u0007r = 0.437. P-value = 0.279 (Table: 70.05). Critical values: \nr = {0.707 (assuming a 0.05 significance level). There is not \nsufficient evidence to support the claim that there is a linear \ncorrelation between amounts of tar and carbon monoxide.\n\t\n\t d. \u0007yn = 12.0 + 0.181x\n\t \t e. \u0007The predicted value is y = 16.1 mg, which is close to the ac-\ntual amount of 15 mg.\n\t 4.\t a. \u0007NICOTINE = -0.443 + 0.0968 TAR - 0.0262 CO, or \nyn = -0.443 + 0.0968x1 - 0.0262x2.\n\t\n\t b. \u0007R2 = 0.936; adjusted R2 = 0.910; P-value = 0.001.\n\t\n\t c. \u0007With high values of R2 and adjusted R2 and a small P-value \nof 0.001, it appears that the regression equation can be used \nto predict the amount of nicotine given the amounts of tar and \ncarbon monoxide.\n\t \t d. \u0007The predicted value is 1.39 mg, or 1.4 mg rounded, which is \nclose to the actual value of 1.3 mg of nicotine.\n\t 5.\t r = 0.450. P-value = 0.192 (Table 70.05). Critical values: \nr = {0.632 (assuming a 0.05 significance level). There is not \nsufficient evidence to support the claim that there is a linear cor-\nrelation between time and population size. Although there is no \nlinear correlation between time and population size, the scatter-\nplot shows a very distinct pattern revealing that time and popula-\ntion size are associated by a function that is not linear.\n\t 6.\t ln a\np\n1 - pb = -44.4 + 0.5571Temp. at 8 AM2 -\n\t\n\t 0.0981Temp. at 12 AM2.\n\t\n\t The probability that the subject smokes is 0.667. Because the \nregression equation has the high overall P-value of 0.521, the \npredicted value is not likely to be very accurate.\nChapter 10: Cumulative Review Exercises\n\t 1.\t x = 3.3 lb, s = 5.7 lb\n\t 2.\t The highest weight before the diet is 212 lb, which converts to \nz = 1.55. The highest weight is not significantly high because its \nz score of 1.55 shows that it is within 2 standard deviations of the \nmean.\n\t 3.\t H0: md = 0. H1: md 7 0. Test statistic: t = 1.613. P-value =\n0.0754 (Table: 70.05). Critical value: t = 1.895. Fail to reject \nH0. There is not sufficient evidence to support the claim that the \ndiet is effective.\n\t 4.\t 161.8 lb 6 m 6 197.0 lb. We have 95% confidence that the in-\nterval limits of 161.8 lb and 197.0 lb contain the true value of the \nmean of the population of all subjects before the diet.\n\t 5.\t a. r = 0.965. P-value = 0.0001. Critical values: r = {0.707 \n(assuming a 0.05 significance level). There is sufficient evidence \nto support the claim that there is a linear correlation between be-\nfore and after weights.\n\t\n\t b.\tr = 1    c. r = 1\n\t \t d. \u0007The effectiveness of the diet is determined by the amounts of \nweight lost, but the linear correlation coefficient is not sensi-\ntive to different amounts of weight loss. Correlation is not a \nsuitable tool for testing the effectiveness of the diet.\n\t 6.\t The best predicted value is 174.6 mm Hg, which is found by sub-\nstituting 100 for x in the regression equation.\n\t 7.\t r2 = 0.752\n\t 8.\t False.\n\t 9.\t False.\n\t10.\t r = -1\nChapter 10: Review Exercises\n\t 1.\t a. r = 0.962. P-value = 0.000 (Table: 60.01). Critical values: \nr = {0.707 (assuming a 0.05 significance level). There is suf-\nficient evidence to support the claim that there is a linear correla-\ntion between the amount of tar and the amount of nicotine.\n\t\n\t b. 92.5%\n\t\n\t c. yn = -0.758 + 0.0920x\n\t \t d. \u0007The predicted value is 1.358 mg, or 1.4 mg rounded, which is \nclose to the actual amount of 1.3 mg.\n\t 2.\t a. \u0007The scatterplot shows a pattern with nicotine and CO both increas-\ning from left to right, but it is a very weak pattern and the points \nare not very close to a straight-line pattern, so it appears that there \nis not sufficient sample evidence to support the claim of a linear \ncorrelation between amounts of nicotine and carbon monoxide.\n\t\n\t b. \u0007r = 0.329. P-value = 0.427 (Table: 70.05). Critical values: \nr = {0.707 (assuming a 0.05 significance level). There is not \nsufficient evidence to support the claim that there is a linear \ncorrelation between amount of nicotine and amount of carbon \nmonoxide.\n\t\n\t c. yn = 14.2 + 1.42x\n\t \t d. \u0007The predicted value is y = 16.1 mg, which is close to the ac-\ntual amount of 15 mg.\n\t 3.\t a. \u0007The scatterplot shows a pattern with amounts of tar and carbon \nmonoxide both increasing from left to right, but it is a very \nweak pattern and the points are not very close to a straight-\nline pattern, so it appears that there is not sufficient sample \nevidence to support the claim of a linear correlation between \namounts of tar and carbon monoxide.\n\n\t\nAppendix D\t\n675\n\t 6.\t a. 43.58% (Table: 43.64%)    b. 2785.6 g (Table: 2786.4 g)\n\t \t c. 5.00%. Yes, many of the babies do require special treatment.\n\t 7.\t a. \u0007No. Correlation can be used to investigate an association be-\ntween the two variables, not whether differences between val-\nues of the two variables are significant.\n\t \t b. \u0007Test statistic: t = 1.185. P-value: 0.2663 (Table: 70.20). \nCritical values: t = {2.262. Fail to reject H0: md = 0. There \nis not sufficient evidence to warrant rejection of the claim \nthat position has no effect. Position does not appear to have a \n­significant effect.\n\t 8.\t There must be an error, because the rates of 13.7% and 10.6% are \nnot possible with sample sizes of 100.\nChapter 11 Answers\nSection 11-1 \n\t 1.\t a. \u0007Observed values are represented by O and expected values are \nrepresented by E.\n\t \t b. \u0007For the leading digit of 2, O = 62 and  \nE = (317) (0.176)= 55.792.\n\t \t c. For the leading digit of 2, (O-E)2>E = 0.691.\n\t 3.\t There is sufficient evidence to warrant rejection of the claim that the \nleading digits have a distribution that fits well with Benford’s law.\n\t 5.\t Test statistic: x2 = 0.523. P@value = 0.9712 (Table: 70.95). \nCritical value: x2 = 9.488. There is not sufficient evidence to \nwarrant rejection of the claim that injuries and illnesses occur \nwith equal frequency on the different days of the week.\n\t 7.\t Test statistic: x2 = 47.200. P@value = 0.0000. Critical value: \nx2 = 19.675. There is sufficient evidence to warrant rejection \nof the claim that motorcycle fatalities occur with equal frequen-\ncies in the different months. Fatalities might be lower in winter \nmonths when colder weather is associated with substantially  \nless use of motorcycles.\n\t 9.\t Test statistic: x2 = 93.072. P@value = 0.000 (Table: 60.005). \nCritical value: x2 = 19.675. There is sufficient evidence to  \nwarrant rejection of the claim that American-born Major League \nBaseball players are born in different months with the same  \nfrequency. The sample data appear to support Gladwell’s claim.\n\t11.\t Test statistic: x2 = 9.658. P@value = 0.0080. Critical value: \nx2 = 5.991. There is sufficient evidence to warrant rejection of \nthe claim that the actual frequencies correspond to the predicted \ndistribution.\n\t13.\t Test statistic: x2 = 524.713. P@value = 0.000 (Table: 60.005). \nCritical value: x2 = 13.277. There is sufficient evidence to war-\nrant rejection of the claim that the distribution of clinical trial \nparticipants fits well with the population distribution. Hispanics \nhave an observed frequency of 60 and an expected frequency \nof 391.027, so they are very underrepresented. Also, the Asian>\nPacific Islander subjects have an observed frequency of 54 and an \nexpected frequency of 163.286, so they are also underrepresented.\n\t15.\t Test statistic: x2 = 3650.251. P@value = 0.0000 (Table: 60.005). \nCritical value: x2 = 20.090. There is sufficient evidence to warrant \nrejection of the claim that the leading digits are from a population \nwith a distribution that conforms to Benford’s law. It does appear \nthat the image has been corrupted.\n\t17.\t Test statistic: x2 = 9.500. P@value = 0.147 (Table: 70.10). \nCritical value: x2 = 16.812. There is not sufficient evidence to \nsupport the claim that births do not occur on the seven different \ndays of the week with equal frequency.\n\t19.\t a. 26, 46, 49, 26\n\t \t b. \u00070.2023, 0.3171, 0.3046, 0.1761 (Table: 0.2033, 0.3166, \n0.3039, 0.1762)\n\t \t c. \u000729.7381, 46.6137, 44.7762, 25.8867 (Table: 29.8851, 46.5402, \n44.6733, 25.9014)\n\t \t d. \u0007Test statistic: x2 = 0.877 (Table: 0.931). P@value = 0.831 \n(Table: 70.10). Critical value: x2 = 11.345. There is not suf-\nficient evidence to warrant rejection of the claim that heights \nwere randomly selected from a normally distributed popula-\ntion. The test suggests that we cannot rule out the possibility \nthat the data are from a normally distributed population.\nSection 11-2 \n\t 1.\t a. E = 4.173\n\t \t b. \u0007Because the expected frequency of a cell is less than 5, the  \nrequirements for the hypothesis test are not satisfied.\n\t 3.\t Test statistic:x2 = 64.517. P-value: 0.000. Reject the null  \nhypothesis of independence between handedness and cell phone \near preference.\n\t 5.\t Test statistic: x2 = 9.750. P@value = 0.002 (Table: 60.005). \nCritical value: x2 = 6.635. There is sufficient evidence to war-\nrant rejection of the claim that success is independent of the type \nof treatment. The results suggest that the surgery treatment is  \nbetter.\n\t 7.\t Test statistic: x2 = 0.751. P@value = 0.3862 (Table: 70.10). \nCritical value: x2 = 3.841. There is not sufficient evidence to \nwarrant rejection of the claim of independence between the type \nof restoration and adverse health conditions. Amalgam restora-\ntions do not appear to affect health conditions.\n\t 9.\t Test statistic: x2 = 34.345. P@value = 0.0000. Critical value: \nx2 = 6.635. There is sufficient evidence to warrant rejection of \nthe claim that the source of the sample is independent of the dog’s \nselections. The results suggest that the dogs have some ability to \ndetect bladder cancer, but they did not do well enough for accurate \ndiagnoses.\n\t11.\t Test statistic: x2 = 9.854. P@value = 0.0017 (Table: 60.005). \nCritical value: x2 = 6.635. There is sufficient evidence to war-\nrant rejection of the claim that nausea is independent of whether \nthe subject took a placebo or Chantix. It appears that nausea is \nmore likely to occur among those who use Chantix, so nausea  \nis a concern. However, the rate of nausea among Chantix users  \nis only about 3.7%, so it is not much of a concern.\n\t13.\t Test statistic: x2 = 18.773. P@value = 0.000 (Table: 60.005). \nCritical value: x2 = 3.841. There is sufficient evidence to war-\nrant rejection of the claim of independence between texting \nwhile driving and irregular seat belt use. Those two risky behav-\niors appear to be somehow related.\n\t15.\t Test statistic: x2 = 42.568. P@value = 0.0000 (Table: 60.005). \nCritical value: x2 = 9.210. There is sufficient evidence to war-\nrant rejection of the claim that experiencing an adverse reaction \nin the digestive system is independent of the treatment group. \nTreatments with 1332 mg doses of Campral appear to be associ-\nated with an increase in adverse effects of the digestive system.\n\n676\t\nAppendix D\n\t17.\t Test statistic: x2 = 1.358. P@value = 0.715 (Table: 70.10). \nCritical value: x2 = 7.815 (assuming a 0.05 significance level). \nThere is not sufficient evidence to warrant rejection of the claim \nthat the amount of smoking is independent of seat belt use. The \ntheory is not supported by the given data.\n\t19.\t Test statistic: x2 = 9.971. P@value = 0.041 (Table: 60.05). \nCritical value: x2 = 9.488 (assuming a 0.05 significance level). \nThere is sufficient evidence to warrant rejection of the claim that \ninjuries are independent of helmet color. It appears that motor-\ncycle drivers should use yellow or orange helmets.\n\t21.\t Test statistics: x2 = 9.7504 and z = -3.122560496 so \nthat z 2 = x2. Critical values: x2 = 6.635 and z = 2.57583 \n(Table: {2.575) so z2 = x2.\nChapter 11: Quick Quiz\n\t 1.\t H0: p0 = p1 =  . . . = p9. H1: At least one of the probabilities is \ndifferent from the others.\n\t 2.\t O = 27 and E = 30\n\t 3.\t Right-tailed\n\t 4.\t df = 9\n\t 5.\t There is not sufficient evidence to warrant rejection of the claim \nthat the last digits are equally likely. Because reported heights \nwould likely include more last digits of 0 and 5, it appears that \nthe heights were measured instead of reported. (Also, most U.S. \nresidents would have difficulty reporting heights in centimeters, be-\ncause the United States, Liberia, and Myanmar are the only coun-\ntries that continue to use the Imperial system of measurement.)\n\t 6.\t H0: Surviving the sinking is independent of whether the person is \na man, woman, boy, or girl.\n\t\n\t H1: Surviving the sinking and whether the person is a man, \nwoman, boy, or girl are somehow related.\n\t 7.\t Chi-square distribution.\n\t 8.\t Right-tailed\n\t 9.\t df = 3\n\t10.\t There is sufficient evidence to warrant rejection of the claim that \nsurviving the sinking is independent of whether the person is a \nman, woman, boy, or girl. Most of the women survived, 45% of the \nboys survived, and most girls survived, but only about 20% of the \nmen survived, so it appears that the rule was followed quite well.\nChapter 11: Review Exercises\n\t 1.\t Test statistic: x2 = 269.147. P@value = 0.000 (Table: 60.005).  \nCritical value: x2 = 24.725. There is sufficient evidence to war-\nrant rejection of the claim that weather-related deaths occur in the \ndifferent months with the same frequency. The months of May, \nJune, and July appear to have disproportionately more weather-\nrelated deaths, and that is probably due to the fact that vacations \nand outdoor activities are much greater during those months.\n\t 2.\t Test statistic: x2 = 71.679. P@value = 0.0000 (Table: 60.005). \nCritical value: x2 = 3.841. There is sufficient evidence to war-\nrant rejection of the claim that getting norovirus infection is \nindependent of the ship. It appears that an outbreak of norovirus \ninfection has a different effect on different ships.\n\t 3.\t Test statistic: x2 = 10.375. P@value = 0.4970 (Table: 70.10). \nCritical value: x2 = 19.675. There is not sufficient evidence to \nwarrant rejection of the claim that homicides in New York City \nare equally likely for each of the 12 months. There is not suf-\nficient evidence to support the police commissioner’s claim that \nhomicides occur more often in the summer when the weather is \nwarmer.\n\t 4.\t Test statistic: x2 = 784.647. P@value = 0.0000 (Table: 60.005). \nCritical value: x2 = 11.345. There is sufficient evidence to war-\nrant rejection of the claim that left-handedness is independent of \nparental handedness. It appears that handedness of the parents \nhas an effect on handedness of the offspring, so left-handedness \nappears to be an inherited trait.\n\t 5.\t Test statistic: x2 = 53.051. P@value = 0.0000 (Table: 60.005). \nCritical value: x2 = 7.815. There is sufficient evidence to war-\nrant rejection of the claim that the distribution of crashes is the \nsame as the distribution of ages. Drivers under 25 appear to have \ndisproportionately more crashes.\nChapter 11: Cumulative Review Exercises\n\t 1.\t x = 53.7 years, median = 60.0 years, s = 16.1 years,  \ns2 = 258.9 years2. Because an age of 16 is more than 2 standard \ndeviations below the mean of 53.7 years, it is significantly low.\n\t 2.\t 42.2 years 6 m 6 65.2 years. Yes, the confidence interval limits \ndo contain the value of 65.0 years that was found from a sample \nof 9269 ICU patients.\n\t 3.\t Test statistic: x2 = 10.708. P@value = 0.0011 (Table: 60.005). \nCritical value: x2 = 3.841. There is sufficient evidence to war-\nrant rejection of the claim that wearing a helmet has no effect on \nwhether facial injuries are received. It does appear that a helmet \nis helpful in preventing facial injuries in a crash.\n\t 4.\t a. 349>531 or 0.657\n\t \t b. 0.0450\n\t \t c. 0.787\n\t 5.\t a. 630 mm\n\t \t b. \u000714.48 (Table: 14.46%). That percentage is too high, because \ntoo many women would not be accommodated.\n\t \t c. \u00070.7599 (Table: 0.7611). Groups of 16 women do not occupy a \ndriver’s seat or cockpit; because individual women occupy the \ndriver’s seat>cockpit, this result has no effect on the design.\n\t 6.\t Determine whether there is a linear correlation between diastolic \nblood pressure and height. r = -0.146. P@value = 0.7824 \n(Table: 70.05). Critical values: r = {0.811 (assuming a 0.05 \nsignificance level). There is not sufficient evidence to support the \nclaim that for males, there is a linear correlation between diastolic \nblood pressure and height.\nChapter 12 Answers\nSection 12-1\n\t 1.\t a. \u0007The chest deceleration measurements are categorized accord-\ning to the one characteristic of size.\n\t \t b. \u0007The terminology of analysis of variance refers to the method \nused to test for equality of the three population means. That \nmethod is based on two different estimates of a common popu-\nlation variance.\n\t 3.\t The test statistic is F = 3.288, and the F distribution applies.\n\t 5.\t Test statistic: F = 0.39. P-value: 0.677. Fail to reject  \nH0: m1 = m2 = m3. There is not sufficient evidence to warrant \nrejection of the claim that the three categories of blood lead level \n\n\t\nAppendix D\t\n677\nhave the same mean verbal IQ score. Exposure to lead does not \nappear to have an effect on verbal IQ scores.\n\t 7.\t Test statistic: F = 0.161. P-value: 0.852. Fail to reject  \nH0: m1 = m2 = m3. There is not sufficient evidence to warrant  \nrejection of the claim that the three size categories have the same \nmean head injury measurement. Based on the available data, the \nsize of a car does not appear to affect head injuries.\n\t 9.\t Test statistic: F = 1.304. P-value: 0.275. Fail to reject  \nH0: m1 = m2 = m3. There is not sufficient evidence to warrant \nrejection of the claim that males from the three age brackets have \nthe same mean pulse rate. It appears that pulse rates of males are \nnot affected by age bracket.\n\t11.\t Test statistic: F = 0.3476. P-value: 0.7111. Fail to reject  \nH0: m1 = m2 = m3. There is not sufficient evidence to warrant  \nrejection of the claim that the three size categories have the same \nmean pelvis injury measurement. The size of a car does not  \nappear to affect pelvis injuries.\n\t13.\t Test statistic: F = 6.1413. P-value: 0.0056. Reject H0: m1 =\nm2 = m3 = m4. There is sufficient evidence to warrant rejection \nof the claim that the four treatment categories yield poplar trees \nwith the same mean weight. Although not justified by the results \nfrom analysis of variance, the treatment of fertilizer and irriga-\ntion appears to be most effective.\n\t15.\t Test statistic: F = 18.9931. P-value: 0.0000. Reject H0: m1 = \nm2 = m3. There is sufficient evidence to warrant rejection of the \nclaim that the three different types of cigarettes have the same \nmean amount of nicotine. Given that the king-size cigarettes \nhave the largest mean of 1.26 mg per cigarette, compared to the \nother means of 0.87 mg per cigarette and 0.92 mg per cigarette, \nit appears that the filters do make a difference, although this con-\nclusion is not justified by the results from analysis of variance.\n\t17.\t The Tukey test results show different P-values, but they are not \ndramatically different. The Tukey test results suggest the same \nconclusions as the Bonferroni test.\nSection 12-2\n\t 1.\t The pulse rates are categorized using two different factors of  \n(1) age bracket and (2) gender.\n\t 3.\t a. \u0007An interaction between two factors or variables occurs if the  \neffect of one of the factors changes for different categories of \nthe other factor.\n\t\n\t b. \u0007If there is an interaction effect, we should not proceed with \nindividual tests for effects from the row factor and column \nfactor. If there is an interaction, we should not consider the ef-\nfects of one factor without considering the effects of the other \nfactor.\n\t \t c. \u0007Because the lines are far from parallel, the two genders have \nvery different effects for the different age brackets, so there does \nappear to be an interaction between gender and age bracket.\n\t 5.\t For interaction, the test statistic is F = 9.58 and the P-value is \n0.0003, so there is sufficient evidence to warrant rejection of the \nnull hypothesis of no interaction effect. Because there appears \nto be an interaction between age bracket and gender, we should \nnot proceed with a test for an effect from age bracket and a test \nfor an effect from gender. It appears an interaction between age \nbracket and gender has an effect on pulse rates. (Remember, \nthese results are based on fabricated data used in one of the cells, \nso this conclusion does not necessarily correspond to real data.)\n\t 7.\t For interaction, the test statistic is F = 1.7970 and the P-value is \n0.1756, so there is not sufficient evidence to conclude that there is an \ninteraction effect. For the row variable of age bracket, the test statis-\ntic is F = 2.0403 and the P-value is 0.1399, so there is not sufficient \nevidence to conclude that age bracket has an effect on height. For the \ncolumn variable of gender, the test statistic is F = 43.4607 and the \nP-value is less than 0.0001, so there is sufficient evidence to support \nthe claim that gender has an effect on height.\n\t 9.\t For interaction, the test statistic is F = 3.7332 and the P-value \nis 0.0291, so there is sufficient evidence to conclude that there is \nan interaction effect. The measures of self-esteem appear to be \naffected by an interaction between the self-esteem of the subject \nand the self-esteem of the target. Because there appears to be an \ninteraction effect, we should not proceed with individual tests of \nthe row factor (target’s self-esteem) and the column factor  \n(subject’s self-esteem).\n\t11.\t a. Test statistics and P-values do not change.\n\t\n\t b. Test statistics and P-values do not change.\n\t\n\t c. Test statistics and P-values do not change.\n\t \t d. \u0007An outlier can dramatically affect and change test statistics and \nP-values.\nChapter 12: Quick Quiz\n\t 1.\t The sample data are partitioned into the three different categories \naccording to the one factor of epoch.\n\t 2.\t H0: m1 = m2 = m3. H1: At least one of the three population \nmeans is different from the others.\n\t 3.\t Test statistic: F = 4.0497. Larger test statistics result in smaller \nP-values.\n\t 4.\t Reject H0. There is sufficient evidence to support the claim that \nthe different epochs have mean skull breadths that are not all  \nthe same.\n\t 5.\t Right-tailed. Yes, all one-way analysis of variance tests are right-tailed.\n\t 6.\t No. The method of analysis of variance does not justify a conclu-\nsion that any particular mean is different from the others.\n\t 7.\t With one-way analysis of variance, data from the different \nsamples are categorized using only one factor, but with two-way \nanalysis of variance, the sample data are categorized into differ-\nent cells determined by two different factors.\n\t 8.\t Test statistic: F = 1.41. P-value: 0.281. Fail to reject the null hy-\npothesis of no interaction effect. There is not sufficient evidence to \nwarrant rejection of the claim that head injury measurements are not \naffected by an interaction between the type of car (foreign, domes-\ntic) and size of the car (small, medium, large). There does not appear \nto be an effect from an interaction between the type of car (foreign or \ndomestic) and whether the car is small, medium, or large.\n\t 9.\t Test statistic: F = 2.25. P-value: 0.159. Fail to reject the null  \nhypothesis of no effect from the type of car. There is not suffi-\ncient evidence to support the claim that whether the car is foreign \nor domestic has an effect on head injury measurements.\n\t10.\t Test statistic: F = 0.44. P-value: 0.655. Fail to reject the null \nhypothesis of no effect from the size of the car. There is not suf-\nficient evidence to support the claim that whether the car is small, \nmedium, or large has an effect on head injury measurements.\n\n678\t\nAppendix D\nChapter 12: Review Exercises\n\t 1.\t a. One (type of diet)\n\t\n\t b. One-way analysis of variance\n\t\n\t c. \u0007Because the P-value is high, it appears that the four samples have \nmeans that do not differ by significant amounts. It appears that the \nmean ages of the four treatment groups are about the same.\n\t \t d. \u0007A small P-value would indicate that at least one of the treat-\nment groups has a mean age that is significantly different from \nthe others, so we would not know if differences from the diet \ntreatments are due to the diets or to differences in age. A small \nP-value would undermine the effectiveness of the experiment.\n\t 2.\t Test statistic: F = 42.9436. P-value: 0.000. Reject H0: m1 =\nm2 = m3. There is sufficient evidence to warrant rejection of the \nclaim that the three different types of cigarettes have the same \nmean amount of tar. Given that the king-size cigarettes have the \nlargest mean of 21.1 mg per cigarette, compared to the other \nmeans of 12.9 mg per cigarette and 13.2 mg per cigarette, it ap-\npears that the filters do make a difference, although this conclu-\nsion is not justified by the results from analysis of variance.\n\t 3.\t For interaction, the test statistic is F = 1.7171 and the P-value is \n0.1940, so there is not sufficient evidence to warrant rejection of \nno interaction effect. There does not appear to be an interaction \nbetween femur and car size. For the row variable of femur, the \ntest statistic is F = 1.3896 and the P-value is 0.2462, so there is \nnot sufficient evidence to conclude that whether the femur is right \nor left has an effect on load. For the column variable of car size, \nthe test statistic is F = 2.2296 and the P-value is 0.1222, so there \nis not sufficient evidence to warrant rejection of the claim of no \neffect from car size. It appears that the crash test loads are not af-\nfected by an interaction between femur and car size, they are not \naffected by femur, and they are not affected by car size.\n\t 4.\t For interaction, the test statistic is F = 0.8733 and the P-value is \n0.3685, so there does not appear to be an effect from an interac-\ntion between gender and whether the subject smokes. For gender, \nthe test statistic is F = 0.0178 and the P-value is 0.8960, so \ngender does not appear to have an effect on body temperature. \nFor smoking, the test statistic is F = 3.0119 and the P-value is \n0.1082, so there does not appear to be an effect from smoking on \nbody temperature.\nChapter 12: Cumulative Review Exercises\n\t 1.\t a. 15.5 years, 13.1 years, 22.7 years\n\t\n\t b. 9.7 years, 9.0 years, 18.6 years\n\t\n\t c. \u000794.5 years2, 80.3 years2, 346.1 years2\n\t \t d. Ratio\n\t 2.\t Test statistic: t = -1.383. P-value = 0.1860. Critical values as-\nsuming a 0.05 significance level: t = {2.123 (Table: {2.160). \nFail to reject H0: m1 = m2. There is not sufficient evidence to \nsupport the claim that there is a difference between the means for \nthe two groups.\n\t 3.\t Normal, because the histogram is approximately bell-shaped \nor the points in a normal quantile plot are reasonably close to a \nstraight-line pattern with no other pattern that is not a straight-\nline pattern.\n\t 4.\t 12.3 years 6 m 6 18.7 years. We have 95% confidence that the \nlimits of 12.3 years and 18.7 years contain the true value of the \npopulation mean.\n\t 5.\t a. H0: m1 = m2 = m3\n\t \t b. \u0007Because the P-value of 0.051 is greater than the significance \nlevel of 0.05, fail to reject the null hypothesis of equal means. \nThere is not sufficient evidence to warrant rejection of the \nclaim that the three means are equal. The three populations do \nnot appear to have means that are significantly different.\n\t 6.\t a. \u0007r = 0.918. Critical values: r = {0.707. P-value = 0.001.  \nThere is sufficient evidence to support the claim that there is a \nlinear correlation between September weights and the subse-\nquent April weights.\n\t\n\t b. yn = 9.28 + 0.823x\n\t \t c. \u000786.6 kg, which is not very close to the actual April weight of \n105 kg.\n\t 7.\t a. 0.1587\n\t\n\t b. 0.6827 (Table: 0.6826)\n\t\n\t c. 0.9987\n\t \t d. 334.7 (Table: 334.6)\n\t 8.\t a. 200\n\t\n\t b. 0.175 6 p 6 0.225\n\t \t c. \u0007Yes. The confidence interval shows us that we have 95% con-\nfidence that the true population proportion is contained within \nthe limits of 0.175 and 0.225, and 1>4 or 0.25 is not included \nwithin that range.\n\t 9.\t Using normal as approximation to binomial: 0.1020. (Exact result \nusing technology: 0.0995.) Assuming that one-quarter of all off-\nspring have blue eyes, the probability of getting 19 or fewer off-\nspring with blue eyes is high, so there is not sufficient evidence to \nconclude that the one-quarter rate is wrong.\n\t10.\t Test statistic: x2 = 2.909. P@value = 0.2335 (Table: 70.10). \nCritical value: x2 = 5.991. There is not sufficient evidence to \nwarrant rejection of the claim of independence between injury \ncategory and whether the firearm was a handgun or a rifle or \nshotgun. The type of injury doesn’t appear to be affected by \nwhether the firearm is a handgun or a rifle or shotgun.\nChapter 13 Answers\nSection 13-2\n\t 1.\t a. \u0007The only requirement for the matched pairs is that they consti-\ntute a simple random sample.\n\t \t b. \u0007There is no requirement of a normal distribution or any other \nspecific distribution.\n\t \t c. \u0007The sign test is “distribution free” in the sense that it does not \nrequire a normal distribution or any other specific distribution.\n\t 3.\t H0: There is no difference between the populations of body  \ntemperatures at 8 AM and at 12 AM. H1: There is a difference  \nbetween the populations of body temperatures at 8 AM and at  \n12 AM. The sample data do not contradict H1 because the numbers \nof positive signs (1) and negative signs (4) are not exactly the same.\n\t 5.\t The test statistic of x = 2 is not less than or equal to the criti-\ncal value of 0. There is not sufficient evidence to reject the \nclaim of no difference in heights between mothers and their \nfirst daughters.\n\t 7.\t The test statistic of x = 1 is not less than or equal to the criti-\ncal value of 0. There is not sufficient evidence to warrant rejec-\ntion of the claim that when the 13th day of a month falls on a \nFriday, the numbers of hospital admissions from motor vehicle \n\n\t\nAppendix D\t\n679\ncrashes are not affected. Hospital admissions do not appear to \nbe affected.\n\t 9.\t The test statistic of z = -2.66 results in a P-value of 0.0078 and \nit is in the critical region bounded by z = -2.575 and 2.575. \nThere is sufficient evidence to warrant rejection of the claim that \nthere is no difference between the proportions of those opposed \nand those in favor.\n\t11.\t The test statistic of z = -0.24 results in a P-value of 0.8103 and \nit is not in the critical region bounded by z = -1.96 and 1.96. \nThere is not sufficient evidence to reject the claim that boys and \ngirls are equally likely.\n\t13.\t The test statistic of x = 9 is not less than or equal to the critical \nvalue of 5. There is not sufficient evidence to warrant rejection of \nthe claim that the sample is from a population with a median  \nIQ score of 100.\n\t15.\t The test statistic of z = -2.30 results in a P-value of 0.0214 and \nit is in the critical region bounded by z = -1.96 and 1.96. There \nis sufficient evidence to warrant rejection of the claim that the \nsample is from a population with a median diastolic blood pres-\nsure level of 72.\n\t17.\t Second approach: The test statistic of z = -4.29 results in a \nP-value of 0.0000 and it is in the critical region bounded by \nz = -1.645, so the conclusions are the same as in Example 4.  \nThird approach: The test statistic of z = -2.82 results in a \nP-value of 0.0024 and it is in the critical region bounded by \nz = -1.645, so the conclusions are the same as in Example 4. \nThe different approaches can lead to very different results; see the \ntest statistics of -4.21, -4.29, and -2.82. The conclusions are \nthe same in this case, but they could be different in other cases.\nSection 13-3\n\t 1.\t a. \u0007The only requirements are that the matched pairs be a simple \nrandom sample and the population of differences be approxi-\nmately symmetric.\n\t\n\t b. \u0007There is no requirement of a normal distribution or any other \nspecific distribution.\n\t \t c. \u0007The Wilcoxon signed-ranks test is “distribution free” in the \nsense that it does not require a normal distribution or any other \nspecific distribution.\n\t 3.\t The sign test uses only the signs of the differences, but the  \nWilcoxon signed-ranks test uses ranks that are affected by the \nmagnitudes of the differences.\n\t 5.\t Test statistic: T = 8.5. Critical value: T = 4. Fail to reject the \nnull hypothesis that the population of differences has a median of \n0. There is not sufficient evidence to reject the claim of no differ-\nence in heights between mothers and their first daughters. There \ndoes not appear to be a difference in heights between mothers and \ntheir first daughters.\n\t 7.\t Test statistic: T = 1.5. Critical value: T = 1. Fail to reject the \nnull hypothesis that the population of differences has a median \nof 0. There is not sufficient evidence to warrant rejection of the \nclaim that when the 13th day of a month falls on a Friday, the \nnumbers of hospital admissions from motor vehicle crashes are \nnot affected. Hospital admissions do not appear to be affected.\n\t 9.\t Test statistic: T = 98. Critical value: T = 52. There is not suf-\nficient evidence to warrant rejection of the claim that the sample \nis from a population with a median IQ score of 100.\n\t11.\t Convert T = 16,236 to the test statistic z = -1.89.  \nP-value = 0.0588. Critical values: z = {1.96. There is not  \nsufficient evidence to warrant rejection of the claim that the  \nsample is from a population with a median diastolic blood  \npressure level of 72.\n\t13.\t a. 0 and 45,150\n\t \t b. 22,575\n\t \t c. 32,805\n\t \t d. n(n + 1)\n2\n- k\nSection 13-4\n\t 1.\t The two samples are from populations with the same median.\n\t 3.\t Yes. The samples are independent and both samples have more \nthan 10 values.\n\t 5.\t R1 = 172, R2 = 179, mR = 189, sR = 19.4422, test statistic: \nz = -0.87. P-value: 0.3843. Critical values: z = {1.96. Fail to \nreject the null hypothesis that the populations have the same me-\ndian. There is not sufficient evidence to warrant rejection of the \nclaim that girls and boys have the same median birth weight.\n\t 7.\t R1 = 253.5, R2 = 124.5, mR = 182, sR = 20.607, test statistic: \nz = 3.47. P-value = 0.001. Critical values: z = {1.96. Reject \nthe null hypothesis that the populations have the same median. \nThere is sufficient evidence to reject the claim that for those \ntreated with 20 mg of atorvastatin and those treated with 80 mg \nof atorvastatin, changes in LDL cholesterol have the same me-\ndian. It appears that the dosage amount does have an effect on the \nchange in LDL cholesterol.\n\t 9.\t R1 = 36,531.5, R2 = 43,668.5, mR = 41,102.5, sR = 1155.782, \ntest statistic: z = -3.95. P-value: 0.0001 (Table: 0.0002). \nCritical values: z = {1.96. Reject the null hypothesis that the \npopulations have the same median. There is sufficient evidence to \nwarrant rejection of the claim that girls and boys have the same \nmedian birth weight.\n\t11.\t R1 = 501, R2 = 445, mR =  484, sR =  41.158, test statistic: \nz = 0.41. P-value 0.3409. Critical value: z = 1.645. Fail to \nreject the null hypothesis that the populations have the same \nmedian. There is not sufficient evidence to support the claim that \nsubjects with medium lead levels have a higher median of the \nfull IQ scores than subjects with high lead levels. Based on these \ndata, it does not appear that lead level affects full IQ scores.\n\t13.\t Using U = 86.5, we get z = 1.26. The test statistic is the same \nvalue with opposite sign.\nSection 13-5\n\t 1.\t R1 = 36.5, R2 = 52.5, R3 = 47\n\t 3.\t n1 = 5, n2 = 6, n3 = 5, and N = 16.\n\t 5.\t Test statistic: H = 4.9054. Critical value: x2 = 5.991.  \n(Tech: P-value = 0.0861.) Fail to reject the null hypothesis of \nequal medians. The data do not suggest that larger cars are safer.\n\t 7.\t Test statistic: H = 22.8157. Critical value: x2 = 9.210.  \n(Tech: P-value = 0.000.) Reject the null hypothesis of equal \nmedians. It appears that the three states have median amounts of \narsenic that are not all the same.\n\t 9.\t Test statistic: H = 59.1546. Critical value: x2 = 9.210.  \n(Tech: P-value = 0.000.) Reject the null hypothesis of equal me-\ndians. The data suggest that the amounts of nicotine absorbed by  \n\n680\t\nAppendix D\nsmokers are different from the amounts absorbed by people who \ndon’t smoke.\n\t11.\t Test statistic: H = 27.9098. Critical value: x2 = 5.991.  \n(Tech: P-value: 0.000.) Reject the null hypothesis of equal medi-\nans. There is sufficient evidence to warrant rejection of the claim \nthat the three different types of cigarettes have the same median \namount of nicotine. It appears that the filters do make a difference.\n\t13.\t There are 10 zeros and 2 ones, so the values of t are 10 and 2. \nThe values of T are (103 - 10) = 990 and (23 - 2) = 6, so \nΣT = 990 + 6 = 996. Using ΣT = 996 and N = 18, the cor-\nrected value of H is 8.114, which is quite different from the value \nof 6.724 found in Example 1. In this case, the large numbers of \nties do appear to have a considerable effect on the test statistic H.\nSection 13-6\n\t 1.\t The methods of Section 10-2 should not be used for predictions. \nThe regression equation is based on a linear correlation between \nthe two variables, but the methods of this section do not require  \na linear relationship. The methods of this section could suggest  \nthat there is a correlation with paired data associated by some \nnonlinear relationship, so the regression equation would not be a \nsuitable model for making predictions.\n\t 3.\t r represents the linear correlation coefficient computed from \nsample paired data; r represents the parameter of the linear \ncorrelation coefficient computed from a population of paired \ndata; rs denotes the rank correlation coefficient computed \nfrom sample paired data; rs represents the rank correlation \ncoefficient computed from a population of paired data. The \nsubscript s is used so that the rank correlation coefficient can \nbe distinguished from the linear correlation coefficient r. The \nsubscript does not represent the standard deviation s. It is used \nin recognition of Charles Spearman, who introduced the rank \ncorrelation method.\n\t 5.\t rs = 1. Critical values are -0.648 and 0.648. Reject the null \nhypothesis of rs = 0. There is sufficient evidence to support a \nclaim of a correlation between ages and heights of trees.\n\t 7.\t rs = 0.857. Critical values: -0.738, 0.738. Reject the null  \nhypothesis of rs = 0. There is sufficient evidence to support \na conclusion that there is a correlation between the number of \nchirps in 1 min and the temperature.\n\t 9.\t rs = 0.624. Critical values: rs = {0.587. Reject the null  \nhypothesis of rs = 0. There is sufficient evidence to support a \nconclusion that there is a correlation between the number of  \ncigarettes smoked and the cotinine level.\n\t11.\t rs = 0.360. Critical values: -0.159, 0.159. Reject the null  \nhypothesis of rs = 0. There is sufficient evidence to support a \nconclusion that there is a correlation between the systolic and  \ndiastolic blood pressure levels in males.\n\t13.\t rs = 0.984. Critical values: -0.269, 0.269. Reject the null  \nhypothesis of rs = 0. There is sufficient evidence to support the \nclaim of a correlation between chest sizes and weights of bears.\n\t15.\t -0.159 and 0.159. (Use either t = 1.975799 from technology \nor use interpolation in Table A-3 with 151 degrees of freedom, \nso the critical value of t is approximately halfway between 1.984 \nand 1.972, which is 1.978.) The critical values are the same as \nthose found by using Formula 13-1.\nChapter 13: Quick Quiz\n\t 1.\t 5, 7, 11, 4, 9.5, 2, 3, 8, 9.5, 1, 6\n\t 2.\t The efficiency rating of 0.91 indicates that with all other factors \nbeing the same, rank correlation requires 100 pairs of sample ob-\nservations to achieve the same results as 91 pairs of observations \nwith the parametric test for linear correlation, assuming that the \nstricter requirements for using linear correlation are met.\n\t 3.\t a. Distribution-free test\n\t \t b. \u0007The term “distribution-free test” suggests correctly that the test \ndoes not require that a population must have a particular distri-\nbution, such as a normal distribution. The term “nonparametric \ntest” incorrectly suggests that the test is not based on a param-\neter, but some nonparametric tests are based on the median, \nwhich is a parameter; the term “distribution-free test” is better \nbecause it does not make that incorrect suggestion.\n\t 4.\t Rank correlation should be used. The rank correlation test is used \nto investigate whether there is a correlation between foot length \nand height.\n\t 5.\t No, the P-values are almost always different, and the conclusions \nmay or may not be the same.\n\t 6.\t Rank correlation can be used in a wider variety of circumstances \nthan linear correlation. Rank correlation does not require a nor-\nmal distribution for any population. Rank correlation can be used \nto detect some (not all) relationships that are not linear.\n\t 7.\t Because the sign test uses only signs of differences while the \nWilcoxon signed-ranks test uses ranks of the differences, the \nWilcoxon signed-ranks test uses more information about the data \nand tends to yield conclusions that better reflect the true nature \nof the data.\n\t 8.\t Kruskal-Wallis test\n\t 9.\t Two independent samples\n\t10.\t Matched pairs\nChapter 13: Review Exercises\n\t 1.\t Use the sign test. The test statistic of z = -4.46 results in a  \nP-value of 0.0000 (Table: 0.0001) and it is less than or equal to \nthe critical value of z = -1.645. Reject the null hypothesis of  \np = 0.5. There is sufficient evidence to support the claim that the \nmajority of adults obtain medical information more often from \nthe Internet than a doctor.\n\t 2.\t The test statistic of x = 3 is less than or equal to the critical \nvalue of 5 (from Table A-7). There is sufficient evidence to war-\nrant rejection of the claim that the sample is from a population \nwith a median equal to 5 min.\n\t 3.\t Test statistic T = 21 is less than or equal to the critical value of \n59. There is sufficient evidence to warrant rejection of the claim \nthat the sample is from a population with a median equal to 5 min.\n\t 4.\t Test statistic: H = 2.5288. P-value = 0.2824. Critical value: \nx2 = 5.991. Fail to reject the null hypothesis of equal medians. It \nappears that times of longevity after inauguration for presidents, \npopes, and British monarchs have the same median.\n\t 5.\t rs = 0.888. Critical values: -0.618, 0.618. Reject the null  \nhypothesis of rs = 0. There is sufficient evidence to support the \nclaim of a correlation between chocolate consumption and the \nrate of Nobel Laureates. It does not make sense to think that there \n\n\t\nAppendix D\t\n681\nis a cause>effect relationship, so the correlation could be the re-\nsult of a coincidence or other factors that affect the variables the \nsame way.\n\t 6.\t Test statistic: H = 6.6305. P-value = 0.0363. Critical value: \nx2 = 5.991. Reject the null hypothesis of equal medians.  \nInterbreeding of cultures is suggested by the data.\n\t 7.\t R1 = 60, R2 = 111, mR = 85.5, sR = 11.3248, test statistic: \nz = -2.25. P-value = 0.0244. Critical values: z = {1.96.  \nReject the null hypothesis that the populations have the same \nmedian. Skull breadths from 4000 B.C. appear to have a different \nmedian than those from A.D. 150.\n\t 8.\t rs = 0.714. Critical values: {0.738. Fail to reject the null  \nhypothesis of rs = 0. There is not sufficient evidence to support \nthe claim that there is a correlation between the student ranks \nand the magazine ranks. When ranking colleges, students and the \nmagazine do not appear to agree.\nChapter 13: Cumulative Review Exercises\n\t 1.\t x = 14.6 credit hours, median = 15.0 credit hours, s = 1.7 \ncredit hours, s2 = 2.9 (credit hours)2, range = 6.0 credit hours\n\t 2.\t a. Convenience sample\n\t \t b. \u0007Because the sample is from one class of statistics students, it is \nnot likely to be representative of the population of all full-time \ncollege students.\n\t \t c. Discrete\n\t \t d. Ratio\n\t 3.\t H0: m = 14 credit hours. H1: m 7 14 credit hours. Test statistic: \nt = 1.446. P-value = 0.0822 (Table: 70.05). Critical value: \nt = 1.729 (assuming a 0.05 significance level). Fail to reject \nH0. There is not sufficient evidence to support the claim that the \nmean is greater than 14 credit hours.\n\t 4.\t The test statistic of x = 5 is not less than or equal to the critical \nvalue of 4. There is not sufficient evidence to support the claim \nthat the sample is from a population with a median greater than \n14 credit hours.\n\t 5.\t 13.8 credit hours 6 m 6 15.3 credit hours. We have 95% con-\nfidence that the limits of 13.8 credit hours and 15.3 credit hours \ncontain the true value of the population mean.\n\t 6.\t 3.1% 6 p 6 4.7%. We have 95% confidence that the limits of \n3.1% and 4.7% actually contain the true percentage of the popu-\nlation of workers who test positive for drugs.\n\t 7.\t H0: p = 0.03. H1: p 7 0.03. Test statistic: z = 2.36.  \nP-value: 0.0091. Critical value: z = 1.645. Reject H0. There is \nsufficient evidence to support the claim that the rate of positive \ndrug test results among workers in the United States is greater \nthan 3.0%.\n\t 8.\t 2401\n\t 9.\t H0: p = 0.5. H1: p 7 0.5. Test statistic: z = 1.36. P-value: 0.0865 \n(Table: 0.0869). Critical value: z = 1.645. Fail to reject  \nH0. There is not sufficient evidence to support the claim that the \nmajority of the population is not afraid of heights in tall build-\nings. Because respondents themselves chose to reply, the sample \nis a voluntary response sample, not a random sample, so the  \nresults might not be valid.\n\t10.\t There must be an error, because the rates of 13.7% and 10.6% are \nnot possible with samples of size 100.\nChapter 14 Answers\nSection 14-1 \n\t 1. \tA cohort life table is a record of the actual observed mortality \nexperience for a particular group, whereas a period life table de-\nscribes mortality and longevity data for a hypothetical group that \nwould have lived with the same mortality conditions throughout \ntheir lives.\n\t 3. \tThe values in columns 3 through 6 would be halved, but the \nother values would remain the same.\n\t 5. \t0.000382\n\t 7. \t0.99491\n\t 9. \t0.999256; 4996.28 people (or 0.999252; 4996.26)\n\t11.\t 0.840024\n13.\t a.  0.006550    b. 0.000483\n\t\n\t The results are so different because of the exceptionally high \nmortality rate at or very near birth.\n15. \t2–4; 0.000483; 99,345; 48; 198,638; 7,667,195; 77.2\n17. \tUsing H1: p 7 0.000744, the test statistic is z = 1.87, the \nP-value is 0.0308 (Table: 0.0307), and the critical value is \nz = 1.645, so reject the null hypothesis of p = 0.000744 and \nconclude that there is sufficient evidence to support the claim \nthat the number of deaths is significantly high. [If the probability \nof dying is calculated from the third column of Table 14-1, use \nH1: p 7 0.00074815 to get a test statistic of z = 1.85, a P-value \nof 0.0323 (Table: 0.0322), and the same critical value and  \nconclusions.]\n19. \tUsing H1: p 7 0.011198 the test statistic is z = 4.95, the \nP-value is 0.0000 (Table: 0.0001), and the critical value is \nz = 1.645, so reject the null hypothesis of p = 0.011198 and \nconclude that there is sufficient evidence to support the claim \nthat the number of deaths is significantly high.\nSection 14-2 \n\t 1. \tA survivor is a subject that successfully lasted throughout a par-\nticular time period without reaching some terminating event. A \nsurvivor could be a person or an object or some other entity such \nas a marriage.\n\t 3. \tA life table is based on fixed intervals of time, but a table of sur-\nvival data and Kaplan-Meier calculations is based on times that \nvary according to the terminating event.\n\t 5. \tThe fast walkers are more likely to be healthier with greater lon-\ngevity, so they correspond to the top (green) curve. The moderate \ngroup corresponds to the middle (black) curve. The slow group \nof walkers is more likely to have health issues with lower longev-\nity, so they correspond to the bottom (red) curve.\n\t 7.\t a.  4 years    b.   1 year\n\t 9. \tThe five-year survival rates are 0.2 for the group of slow walkers, \n0.5 for the group with moderate walking speeds, and 0.9 for the \ngroup of fast walkers. The differences are substantial, and they \nsuggest that after five years, those with faster walking speeds \nhave much greater survival rates, and those with slow walking \nspeeds have much lower survival rates.\n\t\n\t \t\nThe data do not necessarily suggest that we can get older \npeople to live longer by somehow getting them to walk faster. It’s \nvery possible that walking speed is one manifestation of overall \n\n682\t\nAppendix D\n\t 7.\t\n\t 8. \tThe treatment group and the placebo group appear to have ap-\nproximately the same behavior. The treatment does not appear to \nbe effective.\nChapter 14: Cumulative Review Exercises\n\t 1. \tThe table shows that among 100,000 births, 99,492 sur-\nvived to the second birthday, so the probability of dying is \n1 - 0.99492 = 0.00508. Using H1: p 6 0.00508, the test statis-\ntic is z = -0.67, the P-value is 0.2501 (Table: 0.2514), and the \ncritical value is z = -1.645 (assuming a 0.05 significance level), \nso fail to reject the null hypothesis of p = 0.00508 and conclude \nthat there is not sufficient evidence to support the claim that the \nproportion of deaths is less than 0.00508. The program does not \nappear to be effective in reducing the mortality rate.\n\t 2.\t 0.99294 6 p 6 0.99953; the confidence interval limits contain \n0.99492, so it appears that the mortality rate has not been lowered \nby a significant amount.\n\t 3. \t0.986\n\t 4. \t0.0188; no, because being in the same family causes the events \nto be dependent, instead of being independent, as required by the \nmultiplication rule. It is reasonable to expect that four Hispanic \nfemales in the same family are more likely to experience similar \nenvironmental and hereditary characteristics.\n\t 5. \tThe graph is misleading. The vertical scale begins with a fre-\nquency of 800 instead of 0, so the difference between the “yes” \nand “no” responses is greatly exaggerated.\n\t 6.\t a.  99.89% (Table: 99.88%)\t\nb.  0.1587\nhealth status, so longevity and walking speed are likely both af-\nfected by one or more other extraneous variables.\n\t11.\t\n\t13.\t The graph does not show any information about the six censored \nsurvival times. The graph shows information about the two sur-\nvival times that were not censored.\nChapter 14: Quick Quiz\n\t 1.\t Life table\n\t 2.\t Survival table with Kaplan-Meier calculations\n\t 3.\t A period life table describes mortality and longevity data for a \nhypothetical group that would have lived with the same mortality \nconditions throughout their lives.\n\t 4.\t A cohort life table is a record of the actual observed mortality \nexperience for a particular group.\n\t 5.\t False\t\n\t 6.\tTrue\n\t 7.\t False\t\n\t 8.\tTrue\n\t 9.\t The entries are 1, 0, 0, and 0.\t\n10.\t0.999345\nChapter 14: Review Exercises\n\t 1.\t 0.000352\t\n2.\t 35\t\n3.\t 0.99492\n\t 4.\t 0–2; 0.00508; 100,000; 508; 199,098; 8,382,303; 83.8\n\t 5.\t 83.8 years; 83.2 years; the second value is less than the first \nvalue. As we age, our expected remaining lifetime steadily \n­decreases.\n6.\n \n \n \n \n \nDay\n \n \n \nStatus  \n0 = Censored \n1 = Failed\n \n \n \nNumber \nof  \nPatients\n \n \nPatients  \nNot  \nRequiring \nRetreatment\n \nProportion of \nPatients  \nNot  \nRequiring \nRetreatment\nCumulative \nProportion  \nof Patients  \nNot  \nRequiring \nRetreatment\n  3\n1\n4\n3\n3>4 = 0.75\n0.75\n12\n1\n3\n2\n2>3 = 0.667\n       0.5\n20\n1\n2\n1\n1>2 = 0.5\n0.25\n30\n0\n\nCredits\nPhotos\nChapter 1\nP1, Wavebreakmedia/Shutterstock;  P5, Gary Blakeley Shutterstock;  P6, USBFCO/Shutterstock;  P9, Wavebreakmedia/Shutterstock;  P15, Khamidulin \nSergey/Shutterstock;  P15, Suppakij1017/Shutterstock;  P18, Dotshock/Shutterstock;  P19, 18percentgrey/Shutterstock;  P21, Ollyy/Shutterstock;   \nP25, Andersen Ross/Stockbyte/Getty Images;  P26, Triff/Shutterstock;  P27, Fujji/Shutterstock\nChapter 2\nP40, Kodda/Shutterstock;  P43, Monkey Business Images/Shutterstock;  P53, Valua Vitaly/Shutterstock;  P58, Stockbyte/Getty Images;  P67, Dmitriy \n­Eremenkov. Shutterstock\nChapter 3\nP75, Toysf400/Shutterstock;  P79, Image Point Fr/Shutterstock;  P90, Kitch Bain/Shutterstock;  P91, Ariwasabi/Shutterstock;  P104, Sergey Nivens/ \nShutterstock\nChapter 4\nP118, Sculpies/Shutterstock;  P121, Photomatz/Shutterstock;  P123, Africa Studio/Shutterstock;  P123, Monkey Business Images/Shutterstock;   \nP123, Pakhnyushchy/Shutterstock;  P126, Bochkarev Photography/Shutterstock;  P132, Vitalinka/Shutterstock;  P145, Africa Studio/Shutterstock;   \nP148, Alexander Raths/Shutterstock;  P154, Eric Isselee/Shutterstock\nChapter 5\nP180, Katrina Elena Trninich/123RF;  P189, Kzenon/Shutterstock;  P195, JHDT Stock Images/Shutterstock;  P215, Alfred Eisenstaedt/The LIFE Picture \nCollection/Getty Images;  P215, Wikimedia Commons\nChapter 6\nP216, Mikael Damkier/Shutterstock;  P233, RGtimeline/Shutterstock;  P255, Ciurea Adrian/Shutterstock;  P263, Triff/Shutterstock\nChapter 7\nP282, Pearson Education, Inc.;  P285, Mama_mia/Shutterstock;  P287, Roland IJdema/Shutterstock;  P301, Eric Isselee/Fotolia;  P304, Robin W/Shutterstock;  \nP325, Andresr/Shutterstock\nChapter 8\nP336, Monkey Business Images/Shutterstock;  P339, Viktoria/Shutterstock;  P344, Azuzl/Shutterstock;  P346, Alexey Burmakin/123RF;   \nP355, David H.Seymour/Shutterstock;  P357, ­Suravid/Shutterstock;  P359, Elena Stepanova/Shutterstock;  P368, B Calkins/Shutterstock;   \nP369, Laborant/Shutterstock;  P371, Zentilia/Shutterstock\nChapter 9\nP392, Andresr/Shutterstock;  P409, Amy Walters/Shutterstock;  P412, Pressmaster/Shutterstock;  P421, D7INAMI7S/Shutterstock;  P423, Andrey Arkusha/\nShutterstock\nChapter 10\nP442, Lightwise/Shutterstock;  P448, Africa Studio/Shutterstock;  P464, Zffoto/Shutterstock;  P466, Leah-Anne Thompson/Shutterstock;   \nP477, Steve Snowden/Shutterstock\nChapter 11\nP502, Racorn/Shutterstock;  P505, Alex Kalashnikov/Shutterstock;  P508, Dundanim/Shutterstock;  P509, Serhiy Shullye/Shutterstock;   \nP517, Lenetstan/Shutterstock;  P520, Tatiana Popova/Shutterstock\nChapter 12\nP531, Bikeriderlondon/Shutterstock\nChapter 13\nP560, karen Roach/Shutterstock;  P595, Sinisa Botas/Shutterstock\nChapter 14\nAsianShow/Shutterstock\nCover\nRobert Essel NYC/Getty Images\nFM\niii, Marc Triola;  iii, Mario F. Triola;  iv, Jason Roy\n683\n\n684\t\nCredits\nText\nChapter 1\nP9, Dell Pub. Co\nChapter 4\nP154, Sir Arthur Stanley Eddington\nChapter 14\nP606–607, U.S. Department of Health and Human Services;  P610, U.S. Department of Health and Human Services;  P612, U.S. Department of Health  \nand Human Services;  P620, U.S. Department of Health and Human Services;  P622, U.S. Department of Health and Human Services\nAppendix B\nP639, Dr. Steven Wasserman, Dr. Philip Mackowiak, and Dr. Myron Levine;  P639, National Center for Health Statistics;  P640, National Center for  \nHealth Statistics;  P642, Hoffman, D. J., Policastro, P., Quick, V., and Lee, S. K., Changes in Body Weight and Fat Mass of Men and Women in the First  \nYear of College: A Study of the Freshman 15. Journal of American College Health, July 1, 2006, Vol. 55, No. 1, p. 41. Copyright © 2006. Reprinted by \nPermission;  P643, Federal Trade Commission;  P643, National Center for Health Statistics\nMulti: Statdisk screenshots, Triola Statdisk (c) Triola Stats. All rights reserved;  TI-83/84 Plus screenshots, Texas Instruments\nBarrelfold \nP4, Handbook of Statistical Tables, Addison-Wesley Pub. Co.\n\n685\nINDEX\nA\nAbnormal populations, 372–373\nAbridged life table, 609–611\nAbsolute risk reduction, 154\nAcceptance sampling, 204\nActive smoke, 643\nActual odds against, 157\nActual odds in favor, 157\nAddition rule, 140\ncomplementary events and, 134\ndisjoint events and, 133\nformal, 131–132\nintuitive, 131–132\nnotation for, 131–132\nAdjusted coefficient of determination, 483\nAdjusted rates, 164\nAlcohol, 643\na, 285–287, 342, 348–349\nAlternative hypothesis\ncontingency tables, 515\ndefinition, 341\ngoodness-of-fit test, 504\nAnalysis of variance (ANOVA). See ­One-way analysis of \n­variance, Two-way analysis of variance\nApproximations, 124\nArea\ncritical values, 228\ncumulative, 221\nwith nonstandard normal distribution, 232\nprobability and, 219, 220, 222\nsignificance and, 236–237\nbetween two boundaries, 221\nvalues from known, 235–237\nbetween z scores, 225\nz scores from known, 225–228\nArithmetic mean. See Mean\nAspirin, 339\nAssumptions, 398\n“At least one,” 144–145\nAttribute data, 14\nAudiometry data, 640\nAutomobile accidents, 67\nAverage, 79. See also Center\nB\nBar graphs, 58\nBayes’ theorem, 148–150\nBear measurements, 642\nBell-shaped distribution histogram, 53\nBenford’s law, 508–509\nb, 348–349\nBias\nin data, 21\nin internet surveys, 285\npublication, 7\nsurvivorship, 5\nBiased estimator, 91, 97, 247\nBig data, 15\napplications of, 19\ndefinition, 19\njobs in, 20\nBimodal, 80\nBinomial, Poisson as approximation to, 208–209\nBinomial probabilities, 625\nBinomial probability distributions\nbasics of, 193–198\nin claims testing, 354\ncontinuous, 269\ndefinition, 194\ndiscrete, 269\nmethods for finding, 195–197\nnormal distribution as approximation to, 270\nnotation for, 194, 269\nrationale for formula, 200–201\ntechnology, 197, 273–274\nBipolar depression, 415\nBirths, 639\ngender probabilities, 125\nBivariate data, 444\nBladder cancer, 523\nBlinding, 26\nBlocks, 29\nBlood pressure, 33, 177, 377, 460–461, 473–474,  \n480, 618\nBody data, 639\nBody mass index, 115, 278, 387, 416\nBody temperatures, 639\nBonferroni multiple comparison test, 540–541\nBootstrapping\nfor confidence interval estimate, 325–326\ndistribution-free method, 324–325\nnonparametric method, 324–325\nproportions, 326–327\nBootstrap resampling, 372–373\nBootstrap sample, 325\nBoundary, class, 42\nBox-and-whisker diagram, 108\nBoxplots, 102–111\nconstruction of, 109\ndefinition, 108–109\nskewness of, 109\nBrain size, 641\n\n686\t\nIndex\nC\nCar chases, 67\nCar safety, 505\nCase-control study, 28\nCategorical data, 14\nin frequency distributions, 44–45\nCausation\ncorrelation and, 8, 66\ninterpreting with, 453\nCause-specific death rate, 166\nCell phones, 352, 404, 499, 522\nCell phones and cancer, 131, 276\nCensored data, 614\nCensus, 4\nCenter\nof data, 51\nmeasures of, 77–84\nCentral limit theorem, 259–260\napplication of, 254–256\ndefinition, 252\nfinite population correction, 257–258\nfuzzy, 255\nkey elements of, 253\nsampling distribution and, 253\nChi-square distribution\nin claims testing, 378–379\ndefinition, 315\nin population standard deviation, 315–318\nin population variance, 315–318\nproperties of, 378–379\nvalues, 629\nChi-square test of homogeneity, 519\nCholesterol, 211–212, 322, 375, 553\nCigarette contents, 643. See also Smoking\nClaimed distribution, 505–506\nClaims testing\nwith abnormal populations, 372–373, 382\nalternative method, 382\nbinomial distribution in, 354\nchi-square distribution in, 378–379\nconfidence interval method for, ­357–359, 371,  \n381–382\ncritical value in, 354, 357, 359, 370, 380–381\nequivalent methods, 355, 366–367, 378\nexact method, 359–361\nabout means, 366–373\nnormal approximation method, ­354–359\nnormality in, 367\nnotation, 354, 367, 377\nabout population proportion, 354–361\nP-value in, 354, 355, 368–369\nrequirements, 354, 367, 378\nabout standard deviation, 377–382\nstudent t distribution in, 367–368\ntechnology in, 355–356\ntest statistic in, 354, 367, 378\nabout variance, 377–382\nXSORT method, 355\nClass boundaries, 42\nClassical approach to probability, 123\nClass limits, 42\nClass midpoints, 43\nClassroom length, 335, 390\nClass width, 43\nClinical trials, 25, 466\nalternatives to, 517\nCloning, 180, 297\nClopper-Pearson method, 294\nCluster sampling, 26\nCoefficient of determination\nadjusted, 483\ndefinition, 478\ninterpreting, 479\nmultiple, 483–484\nprediction interval and, 478\nCoefficient of variation\ndefinition, 96\nround-off rule for, 96\nCohort study, 28\nColumn factor, 549\nCombinations\ndefinition, 168\nmnemonics for, 168\npermutations compared with, 170\nrule, 170\nCommercial jet safety, 508\nComparisons, 318–319\nComplementary events\naddition rule and, 134\ndefinition, 127\nrule of, 134\nComplements, 144–145\nCompletely randomized design, 540\nComposite sampling, 204\nCompound event, 132\nConditional probability\nconfusion of inverse, 147\ndefinition, 145\nformal approach for, 145\nintuitive approach for, 145\nnotation, 145–146\nConfidence coefficient, 285\nConfidence interval, 347\nbetter-performing, 293–294\nbootstrapping for, 325–326\nfor comparisons, 318–319\nconstructing, 289, 295, 302, 318\ncritical values, 286–288\ndefinition, 275, 474\nfor dependent samples, 419–420\nexploration of data with, 305\nformats of, 295\n\n\t\nIndex\t\n687\nfor hypothesis tests, 291, 318–319\nindependent samples and, 407, 411\ninterpreting, 286, 304\nmargin of error in, 287–288, 304–305\nfor mean, 324\nmethod, 357–359, 371, 381–382\nnotation, 288, 300, 317\nplus four method, 294\npoint estimate from, 290, 304–305\nin population means, 300, 302, 304\nin population standard deviation, 315\nin population variance, 317–318\nfor proportion, 324, 394, 398–400\nrationale for, 320\nrequirements, 288\nround-off rule for, 288, 300, 318\nWald, 293\nWilson score, 294\nConfidence level, 285, 286\nConfounding, 28\nConfusion of inverse, 147\nContext, 4, 6\nContingency tables, 514–521\nalternative hypothesis, 515\ncritical values in, 515\ndefinition, 514\nexpected frequencies in, 516\nexpected value in, 516–518\nnotation, 515\nnull hypothesis, 515\nobserved frequencies in, 516\nP-values in, 515\nrequirements, 515\ntest statistic in, 515\nContinuity correction\ndefinition, 272\nto exact method of claims testing, 361\nnormal approximations, 270, 272–273\nContinuous binomial probability distributions, 269\nContinuous data, 15–16\nContinuous random variable\ndefinition, 183\nidentification of, 190–191\nContinuous uniform distribution, 229\nConvenience sampling, 26\nCorrelation\nbasic concepts of, 444–456\ncausation and, 8, 66\ncommon errors with, 453\ndefinition, 65, 444\nlinear, 65, 444\nscatterplot and, 65–66\nCorrelation coefficient\nlinear, 65–67, 446–450\nPearson, 634\nPearson product moment, 446\nCount five method, 431–432\nCounting, 167–171\nCounting rule, 167\nCoverage probability, 293\nCritical region\ndefinition, 343\nin hypothesis testing, 343\nWilcoxon signed-ranks test, 576\nCritical thinking, 4–9, 296–297\nmean for, 198–201\nmeasures of center and, 82–83\nrange rule of thumb and, 198\nstandard deviation for, 198–201\nCritical t value, 628\nCritical values\narea, 228\nfor claims testing, 354, 357, 359, 370,  \n380–381\nconfidence interval, 286–288\nin contingency tables, 515\ndecision criteria, 346\ndefinition, 228, 287, 345\nfor dependent samples, 419\nfinding, 295\nhypothesis testing, 340, 342–343, 345\nfor independent samples, 408, 410\nKruskal-Wallis test, 588\none-way analysis of variance, 539, 541\nof Pearson correlation coefficient, 634\nin population mean, 301\nin population standard deviation, 315\nin population variance, 315\nproportion, 398\nrank correlation, 593, 637\nsign test and, 566, 635\nWilcoxon rank-sum test, 582\nof Wilcoxon signed-ranks procedure, 636\nCross-sectional study, 28\nCrude rate, 164\nCuckoo egg lengths, 644\nCumulative area, 221\nCumulative frequency distribution, 45\nCurrent. See Period\nD\nData\nalcohol in movies, 643\nattribute, 14\naudiometry, 640\nbear measurements, 642\nbiased results, 21\nbig, 15, 19–20\nbirths, 639\nbivariate, 444\nbody, 639\nbody temperatures, 639\n\n688\t\nIndex\nData (Continued )\nbrain size, 641\ncategorical, 14, 44–45\ncensored, 614\ncenter of, 51\ncigarette contents, 643\nconfidence intervals in exploring, 305\ncontinuous, 15–16\ncuckoo egg lengths, 644\ndefinition, 4, 19\ndiscrete, 15–16\ndistribution of, 51\nfamily heights, 640\nfoot length, 641\nfrequency distributions and, 46–48\nfreshman 15, 642\nheight, 641\nIQ and, 641\niris measurements, 644\nmanatee deaths, 642\nmeasuring, 8–9\nmissing, 20–22\nmissing completely at random, 21\nmissing not at random, 21\nnominal, 568–570\nnormal distributions and, 46\nnumerical, 14, 15–16\npercentiles of, 104–105\nphony, 104\npitfalls in analysis of, 8–9\nPoplar tree weights, 644\nqualitative, 14\nquantitative, 14\nreporting, 8–9\nscience, 19\nset magnitudes, 19\nsignificantly high, 102\nsignificantly low, 102\nsmoking, 643\nsources of, 4, 6, 10\nspread of, 51\nstatistics in, 19\ntransformations, 266, 461\ntypes of, 13–19\nvision, 640\nDeath, 464\ncause-specific rate of, 166\nDegree of confidence, 285\nDegrees of freedom (df), 301\nindependent samples, 408\nin population standard deviation, 315\nin population variance, 315\nDelete cases, 21\nDensity curve, 219\nDependent events, 135\nindependent events and, 195\nDependent samples\nconfidence intervals for, 419–420\ncritical values for, 419\ndefinition, 407\nequivalent methods, 420–421\nexperiment design, 418–423\ninferences about, 419–420\nnotation, 419–420\nP-values for, 419\nrequirements, 419\ntest statistic for, 419–420\nDependent variable, 462\nDepression, 15, 415\nDescriptive statistics, 76\nDeterministic, 462\nDeviation. See also Population standard ­deviation; Standard \ndeviation; Variation\nexplained, 477\ntotal, 477\nunexplained, 477\ndf. See Degrees of freedom\nDiet pills, 409\nDisagreement, 505–506\nDiscordant pairs, 521\nDiscrete binomial probability distributions, 269\nDiscrete data, 15–16\nDiscrete random variable\ndefinition, 183\nidentification of, 190–191\nDisjoint events, 133\nDispersion. See Variation\nDistribution. See specific types \nDistribution-free method, 324–325\nDistribution-free tests. See Nonparametric tests\nDivision by n - 1, 96\nDotplots, 56–57\nDouble-blind experiments, 26\nDrug testing, 412\nDummy variables\ndefinition, 489\nas predictor variable, 489–490\nas response variable, 490–494\nE\nEfficiency rating, 564\nElectrical shock study, 33\nE-mail survey, 31, 330, 364\nEmpirical rule, 231\nEquivalent methods, 355\nErgonomics problems, 260–261\nErrors\nin correlation, 453\nmargin of, 287–288, 304–305\nmaximum error of the estimate, 288\nin multiple regression, 486\nnonrandom sampling, 30\n\n\t\nIndex\t\n689\nnonsampling, 30\nsampling, 29–31\nstandard error of estimate, 475\ntype I, 347–349\ntype II, 347–349\nEstimate\nmaximum error of, 288\nstandard error of, 475\nEstimating. See Confidence interval\nEstimators\nbiased, 91, 97, 247\ndefinition, 247\nunbiased, 95, 97, 247, 274–275\nEthics, 477\nEvents. See also Rare event rule\ncomplementary, 127, 134\ncompound, 132\ndefinition, 122\ndependent, 135, 195\ndisjoint, 133\nindependent, 135, 195\nmutually exclusive, 133\nprobability of, 122–126\nsequential, 149\nsimple, 122\nExact method of claims testing, 359–360\ncontinuity correction to, 361\nimproving, 361\nExpected frequencies\nin contingency tables, 516\nin goodness-of-fit test, 504–505\nrationale for, 519\nExpected value\nin contingency tables, 516–518\ndefinition, 186\nrationale for formulas, 189–190\nExperimental units, 25\nExperimenter effect, 26\nExperiments and experiment design\nblinding in, 26\ncompletely randomized, 540\ndefinition, 25\ndependent samples, 418–423\ndouble-blind, 26\ngold standard of, 24–25\nin hypothesis testing, 350–351\none-way analysis of variance, 540\nplacebo effect in, 26\npower and, 350–351\nrandomization and, 26\nreplication in, 25–26\nrigorously controlled, 540\nExplained deviation, 477\nExplained variation, 452–453\nprediction intervals and, 476–478\nExplanatory variable, 462\nF\nFacial variation, 91\nFactorial rule, 167–168\nFactorial symbol, 167\nFalse negative, 119, 149\nFalse positive, 119, 149, 240\nFamily heights, 640\nF distribution, 429–430\nin one-way analysis of variance, 533–534\nin right tail, 630–633\nFertility rates, 162\nFetal death, 162\nFinite populations, 257–258\nFischer, R. A., 536\nFisher’s exact test, 520\n5-number summary, 108\nFluoride, 421\nFoot length data, 641\nFormal addition rule, 131–132\nFormal hypothesis test\nalternative hypothesis in, 453\nnull hypothesis in, 453\none-tailed, 454\nrationale, 454–456\ntest statistic in, 453–454\nFormal multiplication rule, 135\nFractiles, 104\nFrequency. See Expected frequencies\nFrequency distributions, 42–50\ncalculation of means from, 83–84\ncategorical data in, 44–45\nconstructing, 43–45\ncumulative, 45\ndata and, 46–48\ndefinition, 42\npercentage, 45\nrelative, 45\nFrequency polygon, 60\nFrequency tables, one-way, 503\nFreshman 15, 642\nF test\nfor standard deviation, 428–431\nfor variance, 428–431\nFuzzy central limit theorem, 255\nG\nGalton, Francis, 462\nGaps, 47\nGender\nbirth probabilities, 125, 197\ndrug testing and, 412\nselection, 11, 121, 129, 180–181, 297, 335, 359–360,  \n363, 569\nsmoking and, 554, 556\nGenetics, 192–193, 199–200\nGenotypes, 512\n\n690\t\nIndex\nGeometric distribution, 206\nGoodness-of-fit test\nalternative hypothesis, 504\nclaimed distribution in, 505–506\ndefinition, 503\nexpected frequencies in, 504–505\nnotation, 504\nnull hypothesis, 504\nrequirements, 504\ntest statistic for, 504, 508\nGosset, William, 301\nGould, Stephen Jay, 78\nGraphs and graphing, 7\nbar, 58\ndeception and, 61–62\ndotplots, 56–57\nenlightenment and, 56–60\ninteraction, 547–552\nnonzero vertical axis, 61–62\nPareto charts, 58–59\npictographs, 62–63\npie charts, 59–60\npower of, 58\nstemplots, 57\ntime-series, 57–58\nGroup testing, 146\nGrowth charts, 43\nH\nHawthorne effect, 26\nHeart failure, 368\nHeight data, 641\nHistogram\nbasic concepts, 51–53\nbell-shaped distribution, 53\ndefinition, 51\ndistribution shapes, 52–53\nimportant uses of, 51\ninterpretation, 52\nnormal distributions, 52–53, 262\nfor normality determination, 263\nnormal quantile plots and, 262–263\noutliers and, 51\nprobability, 184–185\nrelative frequency, 51–52\nskewness of, 53\nuniform distribution, 53\nHomogeneity, test of, 519–520\nHomoscedasticity, 173\nHormone therapy, 25\nH test. See Kruskal-Wallis test\nHypergeometric distribution, 206\nHypothesis\nalternative, 341, 504, 515\ndefinition, 338\nnull, 341, 504, 515\nHypothesis test, 120\naccept or fail to reject, 346\nalternative methods, 431–432\nbasic concepts of, 338–347\nconfidence interval for, 291, 318–319, 347\ncount five method, 431–432\ncritical region in, 343\ncritical value in, 340, 342–343, 345\ndecision criteria, 346\ndefinition, 338\nequivalent methods, 347\nexperiment design in, 350–351\nfailures and successes in, 399–400\nfinal conclusions, 346–347\nformal, 453–456\nindependent samples and, 407\nintroduction to, 256–257\nLevene-Brown-Forsyth, 432\nmultiple negatives, 346–347\nnotation, 428\noriginal claim in, 341–342\npower of, 349–351\nprobability in, 256–257\nfor proportion, 394, 395–396\nP-value in, 340, 342–343, 343–345\nrare event rule in, 256–257\nrationale for, 400\nrequirements, 428\nsignificance in, 339\nsignificance level in, 342\nstandard deviation in, 428–429\ntechnology in, 339–340\ntest statistic in, 342–343, 429\ntype I and type II errors, 347–349\nvariance in, 428–429\nI\nImpute missing value, 21\nIncidence rates, 155, 156, 163\nIndependence, 135–138\ntest of, 514–515\nIndependent events, 135\ndependent events and, 195\nIndependent samples\nalternative methods, 411–413\nconfidence interval and, 407, 411\ncritical values for, 408, 410\ndefinition, 407\ndegrees of freedom for, 408\nhypothesis testing and, 407\nnotation, 408\nP-values for, 408, 409–410\nrequirements, 408\nsample variances and, 411–412\ntest statistic for, 408\nunknown and not assumed equal, 406–411\n\n\t\nIndex\t\n691\nIndependent variable, 462\nInfants, 162\nInferences\nfrom matched pairs, 418–424\nfrom mean, 406–413\nfrom proportions, 394–400\nfrom variance, 428–432\nInferential statistics, 127–128\nrare event rule for, 188–189, 256–257\nInfluential points, 468\nInteraction\ndefinition, 547\neffects, 548\ngraph, 547–552\nInternet surveys, bias in, 285\nInterquartile range, 108\nInterval estimate. See Confidence interval\nInterval level of measurement, 17\nIntuition, probability and, 121\nIntuitive addition rule, 131–132\nIntuitive multiplication rule, 135\nIQ, 641\nIris measurement, 644\nJ\nJet engines, 186\nJobs in big data, 20\nK\nKaplan-Meier survival analysis, 614–617\ndefinition, 614\nfor specific time period, 617\nKruskal-Wallis test\ncritical values, 588\ndefinition, 587\nnotation, 587\nprocedure for, 588–590\nrationale, 590\nrequirements, 587\nright-tailed, 587\ntest statistic, 588\nfor three or more samples, 586–590\nL\nLarge numbers, law of, 124\nLast digits, 46–47\nLaw of large numbers, 124\nLead pollution, 531\nLeast-squares property\ndefinition, 469\nin regression, 468–469\nLeft-handedness, 359\nLeftmost residual plots, 470\nLeft-tailed test, 343\nLevene-Brown-Forsyth test, 432\nLie detectors, 358\nLife insurance, 604–605\nLife tables\nabridged, 609–611\napplications of, 609–611\nperiod, 605–609\nprobability in, 611\nLimits. See also Central limit theorem\nlower class, 42\nupper class, 42\nLinear correlation\ndefinition, 65, 444\nfinding, 450–452\ninterpretation, 452–453\nstrength of, 446–448\ntesting for, 459–461\nLinear correlation coefficient, 65, 66\ncalculating, 448–450\ndefinition, 67, 446\ndetermining, 67–68\nformulas, 447\ninterpreting, 446–447\nnotation, 446\nproperties, 448\nrequirements, 446\nrounding, 447\nLinear regression, 65\nLinear relationships, 481\nLipitor, 161\nLogistic regression\ndefinition, 490\nmultiple, 492–493\nsimple, 490–491\nLognormal distribution, 266\nLongitudinal study, 28\nLower class limits, 42\nLung cancer, 159–160, 512–513, 603\nLurking variables, 25\nM\nMAD, 95–96\nManatee deaths, 479, 642\nMann-Whitney U test, 581\nMarginal change\ndefinition, 467\nin regression equation, 467\nMargin of error\nin confidence interval, 287–288, 304–305\ndefinition, 288\nMatched pairs\nclaims about, 567–568, 575–578\ndefinition, 407\ndesign, 29\ninferences from, 418–424\nMcNemar’s Test for, 520–521\nWilcoxon signed-ranks test and, 575–578\nMaximum error of the estimate, 288\n\n692\t\nIndex\nMcNemar’s test, 520–521\nMean. See also Population mean\nbootstrapping, 327–328\ncalculation of, 78–79\ncalculation of, from frequency distribution,  \n83–84\nclaims testing about, 366–373\nconfidence interval for, 324\nfor critical thinking, 198–201\ndefinition, 77\nimportant properties of, 77–78\ninferences about, 407–408\ninferences from, 406–413\nnotation of, 78–79\nfor probability distribution, 185\nresistant, 78\nsample, 243–245\ntest statistic and, 539\ntrimmed, 88\nweighted, 84\nMean absolute deviation (MAD), 95–96\nMeasurement\ninterval level of, 17\nlevels of, 16–19\nnominal level of, 16\nordinal level of, 16–17\nratio level of, 17\nunits of, 14–15\nMeasures of center. See also Mean; Median;  \nMode\nadvanced techniques, 83–84\nbasic concepts of, 77–84\ncritical thinking and, 82–83\nrounding, 81–82\nround-off rule for, 81\nMedian\ncalculation of, 79\nclaims about, of single population, 570–572, 579\ndefinition, 79\nimportant properties of, 79\nnotation of, 79\nMendel, Gregor, 270–271\nMeta-analysis, 369\nMiddle residual plots, 470\nMidpoints, class, 43\nMidquartile, 108\nMidrange\ndefinition, 81\nimportant properties of, 81\nMilgram, Stanley, 33\nMisleading conclusions, 8\nMissing completely at random, 21\nMissing data, 20–22\ncorrecting for, 21\nMissing not at random, 21\nMissing values, 21\nMode\ndefinition, 80\nfinding, 80\nimportant properties of, 80\nno, 80\ntwo, 80\nModified boxplots, 110–111\nMonkey typists, 154\nMorbidity rates, 163\nMortality rates, 162, 605\nMultimodal, 80\nMultinomial distribution, 206\nMultiple-choice questions, 150, 174\nMultiple coefficient of determination, 484\ndefinition, 483\nformula, 483\nMultiple comparison tests, 540\nMultiple logistic regression, 492–493\nMultiple regression, 481–488\ncommon errors involving, 486\nMultiple regression equation\ndefinition, 481\nfinding, 482\nguidelines, 484–486\nnotation, 482\nprocedure for, 482\nP-value, 484\nrequirements, 482\nMultiplication counting rule, 167\nMultiplication rule, 140\napplications of, 138–139\nformal, 135\nindependence and, 135–138\nintuitive, 135\nnotation for, 134–135\nrationale for, 139\nredundancy and, 138–139\nMultistage sampling, 27–28\nMutually exclusive events, 133\nN\nNegative predictive value, 119\nNegative terms, 346\nNegative z-scores, 626\nNeonatal death, 162\nNeonates, 162\nNewborn discharge, 157–158\nNicotine patch, 365\nNightingale, Florence, 60\nNNT. See Number needed to treat\nNominal data, 568–570\nNominal level of measurement, 16\nNonlinear pattern\ndetecting, 596–597\nin rank correlation, 596–597\nNonparametric method of bootstrapping, 324–325\n\n\t\nIndex\t\n693\nNonparametric tests, 571\nadvantages, 562\ndefinitions, 562\ndisadvantages, 562\nefficiency of, 563\nNonrandom sampling error, 30\nNonresponse, 9\nNonsampling error, 30\nNonstandard normal distribution, 232\nNonzero vertical axis, 61–62\nNormal approximations, 275–276\nbinomial distributions and, 270\ncontinuity correction, 270, 272–273\nrationale for, 269–270\nNormal distribution\nchoosing, 308\ndata and, 46\ndefinition, 218\nformulas for, 221\nhistogram, 52–53, 262\nnormal quantile plots in, 262\noutliers in, 262\npopulation mean and, 308\nrequirements, 270\nNormality\nadvanced methods of determining, 263\nassessment feature, 265\nassessment of, with normal quantile plots, 53–54\nbasic concepts in, 261–263\nin claims testing, 367\ndata transformations, 266\nhistograms for, 263\nnormal quantile plots for, 263\nin population mean, 301\nskewness and, 263\ntwo-way analysis of variance, 548\nNormal probability plot, 261\nNormal quantile plots, 261\nconstruction of, 268\ndefinition, 262\nhistograms and, 262–263\ninterpreting, 267–268\nmanual construction of, 263–265\nin normal distributions, 262\nnormality assessed with, 53–54\nfor normality determination, 263\nNotation\nfor addition rule, 131–132\nfor binomial probability distributions, 194, 269\nclaims testing, 354, 367, 377\nconditional probability, 145–146\nconfidence interval, 288, 300, 317\ncontingency tables, 515\ndependent samples, 419–420\ngoodness-of-fit test, 504\nindependent samples, 408\nKruskal-Wallis test, 587\nlinear correlation coefficient, 446\nof mean, 78–79\nof median, 79\nmultiple regression equation, 482\nfor multiplication rule, 134–135\nof percentiles, 105–106\nfor probability, 122\nrank correlation, 593\nof regression equation, 463\nfor sample proportion, 243\nin sample size, 291–292, 306\nfor sampling distribution, 254\nsign test, 566\nvariance, 95\nWilcoxon rank-sum test, 582\nin Wilcoxon signed-ranks test, 575\nNull hypothesis\ncontingency tables, 515\ndefinition, 341\ngoodness-of-fit test, 504\nNumber needed to treat (NNT)\ndefinition, 156\nround-off rule, 156\nNumerical data, 14\ndefinition, 15–16\nO\nObservational studies, 25\nObserved frequencies in contingency tables, 516\nOdds, 153–160\nactual, against, 157\nactual, in favor, 157\npayoff, 157\nratio, 158–159\nOne-tailed tests, 454–455\nOne-way analysis of variance, 533–542\nbasics of, 534–537\ncalculations, 537–542\ncritical values in, 539, 541\ndefinition, 534\ndifferent means in, 540–541\nexperiment design, 540\nF distribution in, 533–534\nP-values, 541\nrequirements, 534\ntesting procedure, 534\nOne-way frequency table, 503\nOrdinal level of measurement, 16–17\nOutliers\ndefinition, 468\nhistograms and, 51\nidentification of, 110\nmodified boxplots and, 110–111\nin normal distributions, 262\nin regression, 468\n\n694\t\nIndex\nP\nPalm reading, 448\nParameter, 13\nParametric tests, 571\ndefinitions, 562\nPareto charts, 58–59\nPassive smoke, 643\nPayoff odds, 157\nPearson correlation coefficient, 634\nPearson product moment correlation coefficient,  \n446\nPercentage frequency distribution, 45\nPercentages, 9\nprobabilities as, 124\nPercentiles, 107\nconversion of, 105–106\nof data values, 104–105\nfinding, 105\nnotation, 105–106\nPerinatal mortality, 162\nPeriod life table, 605–609\ncomponents of, 608–609\ndefinition, 605\nPermutations\ncombinations compared with, 170\ndefinition, 168\nmnemonics for, 168\nPermutations rule, 168–169\nPhony data, 104\nPictographs, 62–63\nPie charts, 59–60\nPlacebo effect, 263\nin experiments, 26\nPlus four method, 294\nPoint estimate\nfrom confidence interval, 290, 304–305\ndefinition, 274\nfor population mean, 300\nin population standard deviation, 315\nunbiased estimator in, 274–275\nPoisson probability distribution\nas approximation to binomial,  \n208–209\ndefinition, 207\nparameters of, 207\nproperties of, 207\nrequirements, 207\nPolice deaths, 67\nPolio vaccine, 153–157, 389, 529\nPoll conduction, 287, 510\nPolygon, frequency, 60\nPooled sample proportion, 394\nPoplar tree weights, 644\nPopulation\nabnormal, 372–373\nclaims about median of, 570–572, 579\nclaims testing with abnormal, 372–373, 382\ndefinition, 4\nfinite, 257–258\nlarge, 136\nin sample size, 306\nsampling from different, 519–520\nstandard deviation of, 94\ntotal, 605, 606\nvariance of, 94–95\nPopulation mean\nconfidence interval in, 300, 302, 304\ncritical values in, 301\nestimation of, 299–309\nnormal distributions and, 308\nnormality in, 301\npoint estimate for, 300\nsample size in, 305–307\nstudent t distribution and, 308\nPopulation proportion\nclaims testing about, 354–361\nestimation of, 284–294\nsample size for, 291–292\nPopulation standard deviation, 94–95\nchi-square distribution in, 315–318\nconfidence interval in, 315\ncritical values in, 315\ndegrees of freedom in, 315\npoint estimate in, 315\nsample size in, 320–321\nPopulation variance\nchi-square distribution in, 315–318\nconfidence interval in, 317–318\ncritical values in, 315\ndegrees of freedom in, 315\nsample size in, 320–321\nPositive predictive value, 119\nPositive z-scores, 627\nPosterior probability, 149\nPower, 349–351\nPractical significance, 7–8\nPrediction intervals\ndefinition, 474\nexplained variation and, 476–478\nformulas for, 475\nrequirements, 475\nunexplained variation and, 476–478\nPrediction models, 466\nPredictor variable\ndefinition, 462\ndummy variables as, 489–490\nPregnancy, 240\nPreparation, 4\nPrevalence rate, 119, 163\nPrior probability, 149\nPrisoners, 477\nProbabilistic models, 462\n\n\t\nIndex\t\n695\nProbability\narea and, 219, 220, 222\nbasics of, 121–122\nbinomial, 625\nclassical approach to, 123\nconditional, 145–147\ncoverage, 293\nof events, 122–126\nformula, 184\ngender, 125\nin hypothesis testing, 256–257\nidentification of significant results with, 127–128, 188\ninterpreting, 120\nintuition and, 121\nin life tables, 611\nnotation for, 122\nas percentages, 124\nposterior, 149\nprior, 149\nrelative frequency approximation of, 123\nrole of, 120–121\nrounding, 124\nsimulations, 124\nsubjective, 123\nz scores, 221–225\nProbability distribution, 182\nbasic concepts, 183\nbinomial, 193–198\ndefinition, 183\nidentification of, 191–192\nmean for, 185\nparameters of, 185–186\nrequirements, 183–184\nround-off rule for, 186\nstandard deviation for, 185\nvariance for, 185\nProbability histogram, 184–185\nProduct-limit method. See Kaplan-Meier  \nsurvival analysis\nProportion. See also Population proportion\nbad samples in, 399\nbootstrapping, 326–327\nconfidence interval for, 324, 394, 398–400\ncritical value method, 398\nhypothesis test for, 394, 395–396\ninferences about, 394–395\nnotation for two, 394\npooled sample, 394\nP-values and, 396–398\ntechnology and, 398\ntest statistics for, 395\nProportions, inferences from, 394–400\nProsecutor’s fallacy, 145\nProspective study, 28, 159\nPublication bias, 7\nPulse rates, 84\nP-values, 119\nclaims testing, 354–355, 368–369\nin contingency tables, 515\ndecision criteria, 346\ndefinition, 343\nfor dependent samples, 419\nfinding, 344\nhypothesis testing, 340, 342–345\nfor independent samples, 408–410\nin multiple regression equation, 484\none-way analysis of variance, 541\nfor proportion, 396–398\nrank correlation, 593\nsign test and, 566\ntechnology and, 370, 410\ntest statistic and, 536\nWilcoxon rank-sum test, 582\nWilcoxon signed-ranks test, 576\nQ\nQualitative data, 14\nQuantiles, 104\nQuantitative data, 14\nQuartiles\ncalculation of, 107–108, 111\ndefinition, 107\nfirst, 107\nsecond, 107\nthird, 107\nQuestions\nloaded, 8\norder of, 8–9\nR\nRandomization, 26\nRandomized block design, 29\nRandom number problems, 177\nRandom sample, 26\nRandom variable, 183\nRange\ndefinition, 90\nimportant properties of, 90\nRange rule of thumb, 203–204\ncritical thinking and, 198\nidentification of significant results with, 187–188\nfor standard deviation, 92–94\nRange tests, 540\nRank\ndefinition, 563\nhandling ties, 563–564\nRank correlation\nadvantages of, 595\ncritical values, 593, 637\ndefinition, 592\ndisadvantages of, 595\nefficiency of, 595–596\n\n696\t\nIndex\nRank correlation (Continued )\nnonlinear pattern in, 596–597\nnotation, 593\nprocedure, 594\nP-values, 593\nrequirements, 593\ntest statistic, 593\nRare event rule, 127–128\nin hypothesis testing, 256–257\nfor inferential statistics, 188–189, 256–257\nRate\nadjusted, 164\ndefinition, 162\nfertility, 162\nmorbidity, 163\nmortality, 162\nspecific, 164\nRatio level of measurement, 17\nRatio test, 18\nRedundancy, 138–139\nRegression, 68–69\nadvanced techniques, 467–471\nbasic concepts, 462–467\ninfluential points in, 468\nleast-squares property in, 468–469\nlogistic, 490–494\nmultiple, 481–488\noutliers in, 468\npredictions and, 472–473\nresidual plots, 469–470\nresiduals in, 468–469\nRegression coefficient, tests of, 486\nRegression equation, 69\ndefinition, 462\nmarginal change in, 467\nnotation of, 463\npredictions with, 466–467\nrequirements, 463\nrounding, 463\nslope of, 463\ntechnology for, 464\ny-intercept in, 463\nRegression line\ndefinition, 69, 462\nfinding equation of, 463\nrequirements, 463\nRelative frequency approximation of ­probability, 123\nRelative frequency distribution, 45\nRelative frequency histogram, 51–52\nRelative frequency polygon, 60\nRelative odds. See Odds\nRelative risk, 154–156\ndefinition, 155\ninterpreting, 155\nfor retrospective studies, 159–160\nRelative standing, 102–111\nReplication, 25–26\nResidual\ndefinition, 468\nin regression, 468–469\nResidual plot\ndefinition, 470\nleftmost, 470\nmiddle, 470\nregression, 469–470\nrightmost, 470\nResistant mean, 78\nResistant statistics, 78\nResponse variable\ndefinition, 462\ndummy variable as, 490–494\nRetrospective studies, 28\nrelative risk for, 159–160\nRightmost residual plots, 470\nRight-tailed test, 343\nRigorously controlled design, 29, 540\nRisk ratio. See Relative risk\nRisks, 153–160\nabsolute, reduction, 154\nrelative, 154–160\nRounding\nlinear correlation coefficient, 447\nmeasures of center, 81–82\nprobabilities, 124\nsample size, 306\nRound-off rule\nfor coefficient of variation, 96\nfor confidence interval, 288, 300, 318\nexceptions to, 186\nfor measures of center, 81\nNNT, 156\nfor probability distribution, 186\nfor sample size, 292, 306\nfor variation, 89\nfor z scores, 102\nRow factor, 549\nRules. See also Round-off rule\naddition, 131–134, 140\nof complementary events, 134\ncounting, 167\nfactorial, 167–168\nmultiplication, 135–140\nmultiplication counting, 167\npermutations, 168–169\nrare event, 127–128, 188–189, 256–257\nRyan-Joiner test, 265–266\nS\nSalk vaccine, 25, 153, 389, 529\nSample\nbad, in proportions, 399\nbootstrap, 325\n\n\t\nIndex\t\n697\ndefinition, 4\nKruskal-Wallis test for three or more, 586–590\nrandom, 26\nself-selected, 6\nsimple random, 26\nsmall, 136\nstandard deviation of, 90–92\nvariance between, 538\nvariance of, 94–95, 246\nvariance within, 538\nvoluntary response, 6\nWilcoxon rank-sum test for two ­independent, 581–584\nSample data, collection of, 24–33\nSample mean\nreal applications involving, 253\nsampling distributions of, 243–245\nSample proportion, 398\nbehavior of, 243\nnotation for, 243\nsampling distributions of, 242\nSample size, 78, 313–314\ndetermining, 291–293, 297–298, ­305–307, 323\nnotation in, 291–292, 306\npopulation in, 306\nin population means, 305–307\nfor population proportion, 291–292\nin population standard deviation, 320–321\nin population variance, 320–321\nrequirements, 291–292, 306\nrole of, 293\nrounding, 306\nround-off rule for, 292, 306\nunequal, 539–540\nunknowns, 306\nSample space, 122\nSample variance\nindependent samples and, 411–412\npooling, 411–412\nsampling distributions of, 246\nSampling\nacceptance, 204\ncluster, 26\ncomposite, 204\nconvenience, 26\nfrom different populations, 519–520\nmethod, 4, 6, 10\nmultistage, 27–28\nwith replacement, 136, 249\nwithout replacement, 136\nrequirements, 324\nstratified, 26\nsystematic, 26\nSampling distribution\ncentral limit theorem and, 253\ngeneral behavior of, 241\nnotation for, 254\nof sample mean, 243–245\nof sample proportion, 242\nof sample variance, 246\nof statistic, 242\nof test statistic, 342\nSampling errors, 29–31\ndefinition, 30\nScatter diagram, 65\nScatterplot, 455\ncorrelation and, 65–66\ndefinition, 65\ninterpreting, 445\nSeat belts, 161, 403, 416–417, 505\nSecond-hand smoke, 117, 305–306, 433, 560–561, 589\nSelf-selected sample, 6\nSemi-interquartile range, 108\nSequential events, 149\nSignificance. See also Hypothesis test\narea and, 236–237\nin hypothesis testing, 339\nSignificance level\ndefinition, 342\nin hypothesis testing, 342\nSignificant results\nidentification of, with probability, 127–128, 188\nidentification of, with range rule of thumb,  \n187–188\nSign test\nbasic concept, 564–567\ncritical values and, 566, 635\ndefinition, 564\nnotation, 566\nprocedure, 566\nP-value and, 566\nrequirements, 566\ntest statistic in, 566\nSimple event, 122\nSimple logistic regression, 490–491\nSimple random sample, 26\nSimulations, 124, 177\nSkewness\nof boxplots, 109\nof histograms, 53\nto left, 53\nnormality and, 263\nto right, 53\nSlope, 463\nSmoking, 589\ndata, 643\ngender and, 554, 556\nSocial security, 611\nSort, 57\nSpearmen’s rank correlation test. See Rank correlation\nSpecific rate, 164\nSpread of data, 51\nSquaring, 96\n\n698\t\nIndex\nStandard deviation. See also Population  \nstandard deviation\nclaims testing about, 377–382\nfor critical thinking, 198–201\ndefinition, 95\nF test for, 428–431\nin hypothesis test, 428–429\nimportant properties of, 91\nMAD and, 95–96\nfor probability distribution, 185\nrange rule of thumb for, 92–94\nsample, 90–92, 95\nStandard error of estimate, 475\nStandard normal distribution, 220, ­229–230\ndefinition, 221\nStatistical methods, 7\nStatistical significance, 7–8\nStatistical thinking, 4–9\nStatistics\nin data science, 20\ndefinition, 4, 13\ndescriptive, 76\ninferential, 127–128\nresistant, 78\nrole of probability in, 120–121\nsampling distributions of, 242\nvariation in, 200\nStemplots, 57\nStigler, Stephen, 536\nStratified sampling, 26\nStudent t distribution, 301–302\nchoosing, 308\nin claims testing, 367–368\nSubjective probability, 123\nSubjects, 25\nSuccesses, 127–128, 188, 357–358\nSugar, 302\nSurvey pitfalls, 32\nSurvival time, 614\nSurvivors, 614\nSurvivorship bias, 5\nSystematic patterns, 262, 263\nSystematic sampling, 26\nt distribution, 628. See also Student t ­distribution\nT\nTechnology\nbinomial probability distributions, 197\nin hypothesis testing, 339–340\nproportion and, 398\nP-values and, 370, 410\nfor regression equation, 464\nTest of homogeneity, chi-square, 519\nTest of independence\ndefinition, 514\ntest statistic for, 515\nTest of significance. See Hypothesis test\nTest power, 349–351\nTest sensitivity, 119\nTest specificity, 119\nTests of regression coefficients, 486\nTest statistic\ncalculating, 537–538\nin claims testing, 354, 367, 378\nin contingency tables, 515\ndefinition, 342\nfor dependent samples, 419–420\nin formal hypothesis test, 453–454\nfor goodness-of-fit test, 504, 508\nin hypothesis test, 342–343, 429\nfor independent samples, 408\ninterpreting, 430–431\nKruskal-Wallis test, 588\nmean and, 539\nfor proportion, 395\nP-value and, 536\nrank correlation, 593\nrationale for, 510, 573\nsampling distribution of, 342\nin sign test, 566\nfor test of independence, 515\nWilcoxon rank-sum test, 582–584\nWilcoxon signed-ranks test, 576\nThanksgiving Day, 126\nTime-series graphs, 57–58\nTobacco use. See Smoking\nToothpaste, 421\nTotal deviation, 477\nTotal population, 605, 606\nTouch therapy, 282, 285, 289, 364\nTreatment, 534\neffectiveness, 466, 499–500\ngroup, 25, 30\nTree height, 461, 473, 480, 598\nTrimmed mean, 88\nTrue negative, 119\nTrue positive, 119\nTrue zero, 18\nt test. See Student t distribution\nTufte, Edward, 63\nTukey test, 546\nTwins, 423\nTwo-tailed test, 343\nTwo-way analysis of variance, 547–552\ncolumn factor, 549\ninteraction graph and, 547–552\nmeans and, 547–552\nnormality, 548\nprocedure for, 549\nrequirements, 548\nrow factor, 549\nvariation in, 548\n\n\t\nIndex\t\n699\nType I errors, 347–349\ncontrolling, 349\nmemory hints for, 348\nType II errors, 347–349\ncontrolling, 349\nmemory hints for, 348\nU\nUltrasound images, 508–509\nUnbiased estimators, 95, 97\ndefinition, 247\nin point estimate, 274–275\nUnderestimation, 97\nUnequal sample sizes, 539–540\nUnexplained deviation, 477\nUnexplained variation, 476–478\nUniform distribution\ndefinition, 219\nhistogram, 53\nUpper class limits, 42\nV\nVaccine problems, 25, 153, 389, 529\nValue of statistical life (VSL), 27\nVariables\ncontinuous random, 183, 190–191\ndependent, 462\ndiscrete random, 183, 190–191\ndummy, 489–494\nexplanatory, 462\nindependent, 462\nlurking, 25\npredictor, 462, 489–490\nrandom, 183\nresponse, 462, 490–494\nVariance. See also Analysis of variance;  \nPopulation variance\nclaims testing about, 377–382\ndefinition, 94\nF test for, 428–431\nin hypothesis test, 428–429\nimportant properties of, 95\ninferences from, 428–432\nnotation, 95\nof population, 94–95\nfor probability distribution, 185\nsample, 94–95, 246\nbetween samples, 538\nwithin samples, 538\nVariation\nadvanced techniques, 95–97\nbasic concepts, 89–95\ncoefficient of, 96–97\ncomparing, 96–97\nexplained, 452–453, 476–478\nin faces, 91\nround-off rule for, 89\nin statistics, 200\nin two-way analysis of variance, 548\nunexplained, 476–478\nViagra, 160–161\nVision data, 640\nVoluntary response sample, 6\nVSL, 27\nW\nWald confidence interval, 293\nWeighted mean, 84\nWeighting, 195\nWeight problems, 8, 482, 487\nWidth, class, 43\nWilcoxon rank-sum test\ncritical values, 582\nnotation, 582\nP-value, 582\nrequirements, 582\ntest statistic, 582–584\nfor two independent samples, 581–584\nWilcoxon signed-ranks test\ncritical region, 576\ncritical values of, 636\ndefinition, 575\nmatched pairs and, 575–578\nnotation, 575\nP-values, 576\nrequirements, 576\ntest statistic, 576\nWildlife, 301\nWilson score confidence interval, 294\nWorld War II, 5, 146, 210\nX\nx. See Sample mean\nXSORT method, 355\nY\nYates’s correction for continuity, 526\ny-intercept, 463\nZ\nZero, true, 18\n0+, notation for, 184\nz scores\narea between, 225\ndefinition, 102\nfrom known areas, 225–228\nnegative, 626\npositive, 627\nprobability, 221–225\nproperties of, 102–103\nround-off rule for, 102\nsignificant values and, 103–104\n\nTable A-2  Standard Normal (z) Distribution: Cumulative Area from the LEFT\nz\n.00\n.01\n.02\n.03\n.04\n.05\n.06\n.07\n.08\n.09\n-3.50 and \nlower\n \n.0001\n \n \n \n \n-3.4\n.0003\n.0003\n.0003\n.0003\n.0003\n.0003\n.0003\n.0003\n.0003\n.0002\n-3.3\n.0005\n.0005\n.0005\n.0004\n.0004\n.0004\n.0004\n.0004\n.0004\n.0003\n-3.2\n.0007\n.0007\n.0006\n.0006\n.0006\n.0006\n.0006\n.0005\n.0005\n.0005\n-3.1\n.0010\n.0009\n.0009\n.0009\n.0008\n.0008\n.0008\n.0008\n.0007\n.0007\n-3.0\n.0013\n.0013\n.0013\n.0012\n.0012\n.0011\n.0011\n.0011\n.0010\n.0010\n-2.9\n.0019\n.0018\n.0018\n.0017\n.0016\n.0016\n.0015\n.0015\n.0014\n.0014\n-2.8\n.0026\n.0025\n.0024\n.0023\n.0023\n.0022\n.0021\n.0021\n.0020\n.0019\n-2.7\n.0035\n.0034\n.0033\n.0032\n.0031\n.0030\n.0029\n.0028\n.0027\n.0026\n-2.6\n.0047\n.0045\n.0044\n.0043\n.0041\n.0040\n.0039\n.0038\n.0037\n.0036\n-2.5\n.0062\n.0060\n.0059\n.0057\n.0055\n.0054\n.0052\n.0051\n.0049\n.0048\n-2.4\n.0082\n.0080\n.0078\n.0075\n.0073\n.0071\n.0069\n.0068\n.0066\n.0064\n-2.3\n.0107\n.0104\n.0102\n.0099\n.0096\n.0094\n.0091\n.0089\n.0087\n.0084\n-2.2\n.0139\n.0136\n.0132\n.0129\n.0125\n.0122\n.0119\n.0116\n.0113\n.0110\n-2.1\n.0179\n.0174\n.0170\n.0166\n.0162\n.0158\n.0154\n.0150\n.0146\n.0143\n-2.0\n.0228\n.0222\n.0217\n.0212\n.0207\n.0202\n.0197\n.0192\n.0188\n.0183\n-1.9\n.0287\n.0281\n.0274\n.0268\n.0262\n.0256\n.0250\n.0244\n.0239\n.0233\n-1.8\n.0359\n.0351\n.0344\n.0336\n.0329\n.0322\n.0314\n.0307\n.0301\n.0294\n-1.7\n.0446\n.0436\n.0427\n.0418\n.0409\n.0401\n.0392\n.0384\n.0375\n.0367\n-1.6\n.0548\n.0537\n.0526\n.0516\n.0505\n.0495\n.0485\n.0475\n.0465\n.0455\n-1.5\n.0668\n.0655\n.0643\n.0630\n.0618\n.0606\n.0594\n.0582\n.0571\n.0559\n-1.4\n.0808\n.0793\n.0778\n.0764\n.0749\n.0735\n.0721\n.0708\n.0694\n.0681\n-1.3\n.0968\n.0951\n.0934\n.0918\n.0901\n.0885\n.0869\n.0853\n.0838\n.0823\n-1.2\n.1151\n.1131\n.1112\n.1093\n.1075\n.1056\n.1038\n.1020\n.1003\n.0985\n-1.1\n.1357\n.1335\n.1314\n.1292\n.1271\n.1251\n.1230\n.1210\n.1190\n.1170\n-1.0\n.1587\n.1562\n.1539\n.1515\n.1492\n.1469\n.1446\n.1423\n.1401\n.1379\n-0.9\n.1841\n.1814\n.1788\n.1762\n.1736\n.1711\n.1685\n.1660\n.1635\n.1611\n-0.8\n.2119\n.2090\n.2061\n.2033\n.2005\n.1977\n.1949\n.1922\n.1894\n.1867\n-0.7\n.2420\n.2389\n.2358\n.2327\n.2296\n.2266\n.2236\n.2206\n.2177\n.2148\n-0.6\n.2743\n.2709\n.2676\n.2643\n.2611\n.2578\n.2546\n.2514\n.2483\n.2451\n-0.5\n.3085\n.3050\n.3015\n.2981\n.2946\n.2912\n.2877\n.2843\n.2810\n.2776\n-0.4\n.3446\n.3409\n.3372\n.3336\n.3300\n.3264\n.3228\n.3192\n.3156\n.3121\n-0.3\n.3821\n.3783\n.3745\n.3707\n.3669\n.3632\n.3594\n.3557\n.3520\n.3483\n-0.2\n.4207\n.4168\n.4129\n.4090\n.4052\n.4013\n.3974\n.3936\n.3897\n.3859\n-0.1\n.4602\n.4562\n.4522\n.4483\n.4443\n.4404\n.4364\n.4325\n.4286\n.4247\n-0.0\n.5000\n.4960\n.4920\n.4880\n.4840\n.4801\n.4761\n.4721\n.4681\n.4641\nNOTE: For values of z below -3.49, use 0.0001 for the area.\n*Use these common values that result from interpolation:\nNEGATIVE z Scores\n*\nz Score\nArea\n-1.645\n0.0500\n-2.575\n0.0050\n*\n0\nz\n(continued)\n\nPOSITIVE z Scores\nTable A-2 (continued)  Cumulative Area from the LEFT\nz\n.00\n.01\n.02\n.03\n.04\n.05\n.06\n.07\n.08\n.09\n0.0\n.5000\n.5040\n.5080\n.5120\n.5160\n.5199\n.5239\n.5279\n.5319\n.5359\n0.1\n.5398\n.5438\n.5478\n.5517\n.5557\n.5596\n.5636\n.5675\n.5714\n.5753\n0.2\n.5793\n.5832\n.5871\n.5910\n.5948\n.5987\n.6026\n.6064\n.6103\n.6141\n0.3\n.6179\n.6217\n.6255\n.6293\n.6331\n.6368\n.6406\n.6443\n.6480\n.6517\n0.4\n.6554\n.6591\n.6628\n.6664\n.6700\n.6736\n.6772\n.6808\n.6844\n.6879\n0.5\n.6915\n.6950\n.6985\n.7019\n.7054\n.7088\n.7123\n.7157\n.7190\n.7224\n0.6\n.7257\n.7291\n.7324\n.7357\n.7389\n.7422\n.7454\n.7486\n.7517\n.7549\n0.7\n.7580\n.7611\n.7642\n.7673\n.7704\n.7734\n.7764\n.7794\n.7823\n.7852\n0.8\n.7881\n.7910\n.7939\n.7967\n.7995\n.8023\n.8051\n.8078\n.8106\n.8133\n0.9\n.8159\n.8186\n.8212\n.8238\n.8264\n.8289\n.8315\n.8340\n.8365\n.8389\n1.0\n.8413\n.8438\n.8461\n.8485\n.8508\n.8531\n.8554\n.8577\n.8599\n.8621\n1.1\n.8643\n.8665\n.8686\n.8708\n.8729\n.8749\n.8770\n.8790\n.8810\n.8830\n1.2\n.8849\n.8869\n.8888\n.8907\n.8925\n.8944\n.8962\n.8980\n.8997\n.9015\n1.3\n.9032\n.9049\n.9066\n.9082\n.9099\n.9115\n.9131\n.9147\n.9162\n.9177\n1.4\n.9192\n.9207\n.9222\n.9236\n.9251\n.9265\n.9279\n.9292\n.9306\n.9319\n1.5\n.9332\n.9345\n.9357\n.9370\n.9382\n.9394\n.9406\n.9418\n.9429\n.9441\n1.6\n.9452\n.9463\n.9474\n.9484\n.9495\n.9505\n.9515\n.9525\n.9535\n.9545\n1.7\n.9554\n.9564\n.9573\n.9582\n.9591\n.9599\n.9608\n.9616\n.9625\n.9633\n1.8\n.9641\n.9649\n.9656\n.9664\n.9671\n.9678\n.9686\n.9693\n.9699\n.9706\n1.9\n.9713\n.9719\n.9726\n.9732\n.9738\n.9744\n.9750\n.9756\n.9761\n.9767\n2.0\n.9772\n.9778\n.9783\n.9788\n.9793\n.9798\n.9803\n.9808\n.9812\n.9817\n2.1\n.9821\n.9826\n.9830\n.9834\n.9838\n.9842\n.9846\n.9850\n.9854\n.9857\n2.2\n.9861\n.9864\n.9868\n.9871\n.9875\n.9878\n.9881\n.9884\n.9887\n.9890\n2.3\n.9893\n.9896\n.9898\n.9901\n.9904\n.9906\n.9909\n.9911\n.9913\n.9916\n2.4\n.9918\n.9920\n.9922\n.9925\n.9927\n.9929\n.9931\n.9932\n.9934\n.9936\n2.5\n.9938\n.9940\n.9941\n.9943\n.9945\n.9946\n.9948\n.9949\n.9951\n.9952\n2.6\n.9953\n.9955\n.9956\n.9957\n.9959\n.9960\n.9961\n.9962\n.9963\n.9964\n2.7\n.9965\n.9966\n.9967\n.9968\n.9969\n.9970\n.9971\n.9972\n.9973\n.9974\n2.8\n.9974\n.9975\n.9976\n.9977\n.9977\n.9978\n.9979\n.9979\n.9980\n.9981\n2.9\n.9981\n.9982\n.9982\n.9983\n.9984\n.9984\n.9985\n.9985\n.9986\n.9986\n3.0\n.9987\n.9987\n.9987\n.9988\n.9988\n.9989\n.9989\n.9989\n.9990\n.9990\n3.1\n.9990\n.9991\n.9991\n.9991\n.9992\n.9992\n.9992\n.9992\n.9993\n.9993\n3.2\n.9993\n.9993\n.9994\n.9994\n.9994\n.9994\n.9994\n.9995\n.9995\n.9995\n3.3\n.9995\n.9995\n.9995\n.9996\n.9996\n.9996\n.9996\n.9996\n.9996\n.9997\n3.4\n.9997\n.9997\n.9997\n.9997\n.9997\n.9997\n.9997\n.9997\n.9997\n.9998\n3.50 and up\n.9999\nNOTE: For values of z above 3.49, use 0.9999 for the area.\n*Use these common values that result from interpolation:\nz score\nArea\n1.645\n0.9500\n2.575\n0.9950\n*\n*\n0\nz\nCommon Critical Values\nConfidence \nLevel\nCritical \nValue\n0.90\n1.645\n0.95\n1.96\n0.99\n2.575\n\nTable A-3  t Distribution: Critical t Values\n0.005\n0.01\nArea in One Tail  \n0.025\n0.05\n0.10\nDegrees of  \nFreedom\n0.01\n0.02\nArea in Two Tails \n0.05\n0.10\n0.20\n1\n63.657\n31.821\n12.706\n6.314\n3.078\n2\n9.925\n6.965\n4.303\n2.920\n1.886\n3\n5.841\n4.541\n3.182\n2.353\n1.638\n4\n4.604\n3.747\n2.776\n2.132\n1.533\n5\n4.032\n3.365\n2.571\n2.015\n1.476\n6\n3.707\n3.143\n2.447\n1.943\n1.440\n7\n3.499\n2.998\n2.365\n1.895\n1.415\n8\n3.355\n2.896\n2.306\n1.860\n1.397\n9\n3.250\n2.821\n2.262\n1.833\n1.383\n10\n3.169\n2.764\n2.228\n1.812\n1.372\n11\n3.106\n2.718\n2.201\n1.796\n1.363\n12\n3.055\n2.681\n2.179\n1.782\n1.356\n13\n3.012\n2.650\n2.160\n1.771\n1.350\n14\n2.977\n2.624\n2.145\n1.761\n1.345\n15\n2.947\n2.602\n2.131\n1.753\n1.341\n16\n2.921\n2.583\n2.120\n1.746\n1.337\n17\n2.898\n2.567\n2.110\n1.740\n1.333\n18\n2.878\n2.552\n2.101\n1.734\n1.330\n19\n2.861\n2.539\n2.093\n1.729\n1.328\n20\n2.845\n2.528\n2.086\n1.725\n1.325\n21\n2.831\n2.518\n2.080\n1.721\n1.323\n22\n2.819\n2.508\n2.074\n1.717\n1.321\n23\n2.807\n2.500\n2.069\n1.714\n1.319\n24\n2.797\n2.492\n2.064\n1.711\n1.318\n25\n2.787\n2.485\n2.060\n1.708\n1.316\n26\n2.779\n2.479\n2.056\n1.706\n1.315\n27\n2.771\n2.473\n2.052\n1.703\n1.314\n28\n2.763\n2.467\n2.048\n1.701\n1.313\n29\n2.756\n2.462\n2.045\n1.699\n1.311\n30\n2.750\n2.457\n2.042\n1.697\n1.310\n31\n2.744\n2.453\n2.040\n1.696\n1.309\n32\n2.738\n2.449\n2.037\n1.694\n1.309\n33\n2.733\n2.445\n2.035\n1.692\n1.308\n34\n2.728\n2.441\n2.032\n1.691\n1.307\n35\n2.724\n2.438\n2.030\n1.690\n1.306\n36\n2.719\n2.434\n2.028\n1.688\n1.306\n37\n2.715\n2.431\n2.026\n1.687\n1.305\n38\n2.712\n2.429\n2.024\n1.686\n1.304\n39\n2.708\n2.426\n2.023\n1.685\n1.304\n40\n2.704\n2.423\n2.021\n1.684\n1.303\n45\n2.690\n2.412\n2.014\n1.679\n1.301\n50\n2.678\n2.403\n2.009\n1.676\n1.299\n60\n2.660\n2.390\n2.000\n1.671\n1.296\n70\n2.648\n2.381\n1.994\n1.667\n1.294\n80\n2.639\n2.374\n1.990\n1.664\n1.292\n90\n2.632\n2.368\n1.987\n1.662\n1.291\n100\n2.626\n2.364\n1.984\n1.660\n1.290\n200\n2.601\n2.345\n1.972\n1.653\n1.286\n300\n2.592\n2.339\n1.968\n1.650\n1.284\n400\n2.588\n2.336\n1.966\n1.649\n1.284\n500\n2.586\n2.334\n1.965\n1.648\n1.283\n1000\n2.581\n2.330\n1.962\n1.646\n1.282\n2000\n2.578\n2.328\n1.961\n1.646\n1.282\nLarge\n2.576\n2.326\n1.960\n1.645\n1.282\n\nFormulas and Tables by Triola, Triola, and Roy\nCopyright 2018 Pearson Education, Inc.\nTable A-4  Chi-Square (x2) Distribution\nArea to the Right of the Critical Value\nDegrees of \nFreedom\n0.995\n0.99\n0.975\n0.95\n0.90\n0.10\n0.05\n0.025\n0.01\n0.005\n1\n—\n—\n0.001\n0.004\n0.016\n2.706\n3.841\n5.024\n6.635\n7.879\n2\n0.010\n0.020\n0.051\n0.103\n0.211\n4.605\n5.991\n7.378\n9.210\n10.597\n3\n0.072\n0.115\n0.216\n0.352\n0.584\n6.251\n7.815\n9.348\n11.345\n12.838\n4\n0.207\n0.297\n0.484\n0.711\n1.064\n7.779\n9.488\n11.143\n13.277\n14.860\n5\n0.412\n0.554\n0.831\n1.145\n1.610\n9.236\n11.071\n12.833\n15.086\n16.750\n6\n0.676\n0.872\n1.237\n1.635\n2.204\n10.645\n12.592\n14.449\n16.812\n18.548\n7\n0.989\n1.239\n1.690\n2.167\n2.833\n12.017\n14.067\n16.013\n18.475\n20.278\n8\n1.344\n1.646\n2.180\n2.733\n3.490\n13.362\n15.507\n17.535\n20.090\n21.955\n9\n1.735\n2.088\n2.700\n3.325\n4.168\n14.684\n16.919\n19.023\n21.666\n23.589\n10\n2.156\n2.558\n3.247\n3.940\n4.865\n15.987\n18.307\n20.483\n23.209\n25.188\n11\n2.603\n3.053\n3.816\n4.575\n5.578\n17.275\n19.675\n21.920\n24.725\n26.757\n12\n3.074\n3.571\n4.404\n5.226\n6.304\n18.549\n21.026\n23.337\n26.217\n28.299\n13\n3.565\n4.107\n5.009\n5.892\n7.042\n19.812\n22.362\n24.736\n27.688\n29.819\n14\n4.075\n4.660\n5.629\n6.571\n7.790\n21.064\n23.685\n26.119\n29.141\n31.319\n15\n4.601\n5.229\n6.262\n7.261\n8.547\n22.307\n24.996\n27.488\n30.578\n32.801\n16\n5.142\n5.812\n6.908\n7.962\n9.312\n23.542\n26.296\n28.845\n32.000\n34.267\n17\n5.697\n6.408\n7.564\n8.672\n10.085\n24.769\n27.587\n30.191\n33.409\n35.718\n18\n6.265\n7.015\n8.231\n9.390\n10.865\n25.989\n28.869\n31.526\n34.805\n37.156\n19\n6.844\n7.633\n8.907\n10.117\n11.651\n27.204\n30.144\n32.852\n36.191\n38.582\n20\n7.434\n8.260\n9.591\n10.851\n12.443\n28.412\n31.410\n34.170\n37.566\n39.997\n21\n8.034\n8.897\n10.283\n11.591\n13.240\n29.615\n32.671\n35.479\n38.932\n41.401\n22\n8.643\n9.542\n10.982\n12.338\n14.042\n30.813\n33.924\n36.781\n40.289\n42.796\n23\n9.260\n10.196\n11.689\n13.091\n14.848\n32.007\n35.172\n38.076\n41.638\n44.181\n24\n9.886\n10.856\n12.401\n13.848\n15.659\n33.196\n36.415\n39.364\n42.980\n45.559\n25\n10.520\n11.524\n13.120\n14.611\n16.473\n34.382\n37.652\n40.646\n44.314\n46.928\n26\n11.160\n12.198\n13.844\n15.379\n17.292\n35.563\n38.885\n41.923\n45.642\n48.290\n27\n11.808\n12.879\n14.573\n16.151\n18.114\n36.741\n40.113\n43.194\n46.963\n49.645\n28\n12.461\n13.565\n15.308\n16.928\n18.939\n37.916\n41.337\n44.461\n48.278\n50.993\n29\n13.121\n14.257\n16.047\n17.708\n19.768\n39.087\n42.557\n45.722\n49.588\n52.336\n30\n13.787\n14.954\n16.791\n18.493\n20.599\n40.256\n43.773\n46.979\n50.892\n53.672\n40\n20.707\n22.164\n24.433\n26.509\n29.051\n51.805\n55.758\n59.342\n63.691\n66.766\n50\n27.991\n29.707\n32.357\n34.764\n37.689\n63.167\n67.505\n71.420\n76.154\n79.490\n60\n35.534\n37.485\n40.482\n43.188\n46.459\n74.397\n79.082\n83.298\n88.379\n91.952\n70\n43.275\n45.442\n48.758\n51.739\n55.329\n85.527\n90.531\n95.023\n100.425\n104.215\n80\n51.172\n53.540\n57.153\n60.391\n64.278\n96.578\n101.879\n106.629\n112.329\n116.321\n90\n59.196\n61.754\n65.647\n69.126\n73.291\n107.565\n113.145\n118.136\n124.116\n128.299\n100\n67.328\n70.065\n74.222\n77.929\n82.358\n118.498\n124.342\n129.561\n135.807\n140.169\nSource: From Donald B. Owen, Handbook of Statistical Tables.\nDegrees of Freedom\nn - 1\nConfidence Interval or Hypothesis Test for a standard deviation or variance\nk - 1\nGoodness-of-fit test with k different categories\n(r - 1)(c - 1)\nContingency table test with r rows and c columns\nk - 1\nKruskal-Wallis test with k different samples\n\nFormulas and Tables by Triola, Triola, and Roy\nCopyright 2018 Pearson Education, Inc.\nCh. 3: Descriptive Statistics\nx = Σx\nn   Mean\nx =\nΣ1f # x2\nΣf\n  Mean (frequency table)\ns = B\nΣ1x - x2 2\nn - 1\n  Standard deviation\ns = B\nn 1Σx22 - 1Σx2 2\nn 1n - 12\n  Standard deviation (shortcut)\ns = B\nn 3Σ1f # x22 4 - 3Σ1f # x2 42\nn 1n - 12\n  Standard deviation  \n(frequency table)\nvariance = s2\nCh. 4: Probability\nP1A or B2 = P1A2 + P1B2  if A, B are mutually exclusive\nP1A or B2 = P1A2 + P1B2 - P1A and B2  \n    if A, B are not mutually exclusive\nP1A and B2 = P1A2 # P1B2  if A, B are independent\nP1A and B2 = P1A2 # P1B0 A2  if A, B are dependent\nP1A2 = 1 - P1A2  Rule of complements\nnPr =\nn!\n1n - r2!  Permutations (no elements alike)\nn!\nn1! n2! c nk!  Permutations (n1 alike, c)\nnCr =\nn!\n1n - r2! r!  Combinations\nCh. 5: Probability Distributions\nm = Σ 3x # P1x2 4  Mean (prob. dist.)\ns = 2Σ 3x2 # P1x2 4 - m2  Standard deviation (prob. dist.)\nP1x2 =\nn!\n1n - x2! x! # px # qn-x  Binomial probability\nm = n # p\t\nMean (binomial)\ns2 = n # p # q\t\nVariance (binomial)\ns = 1n # p # q\t\nStandard deviation (binomial)\nP1x2 = mx # e-m\nx!\nPoisson distribution where \ne = 2.71828\nCh. 6: Normal Distribution\nz = x - m\ns\n or  x - x\ns\n  Standard score\nmx = m  Central limit theorem\nsx =\ns\n2n\n  Central limit theorem (Standard error)\nCh. 7: Confidence Intervals (one population)\npn - E 6 p 6 pn + E  Proportion\n    where E = za>2B\npnqn\nn  \nx - E 6 m 6 x + E  Mean\n    where E = ta>2\ns\n1n  (s unknown)\n    or E = za>2\ns\n1n  (s known)\n1n - 12s2\nx2\nR\n6 s2 6\n1n - 12s2\nx2\nL\n  Variance\nCh. 7: Sample Size Determination\nn =\n3za>2420.25\nE2\n  Proportion\nn =\n3za>242pnqn\nE2\n  Proportion (pn and qn are known)\nn = J\nza>2s\nE\nR\n2\n  Mean\nCh. 8: Test Statistics (one population)\nz = pn - p\nB\npq\nn\n  Proportion—one population\nt = x - m\ns\n1n\n  Mean—one population (s unknown)\nz = x - m\ns\n1n\n  Mean—one population (s known)\nx2 =\n1n - 12s2\ns2\n \n\u0007Standard deviation or variance— \none population\n\n(df = smaller of\nn1 - 1, n2 - 1)\n(s1 and s2 unknown and not assumed equal)\nCh. 9: Confidence Intervals (two populations)\n1 pn1 - pn22 - E 6 1 p1 - p22 6 1 pn1 - pn22 + E\n    where E = za>2B\npn1qn1\nn1\n+ pn2qn2\nn2\n1x1 - x22 - E 6 1m1 - m22 6 1x1 - x22 + E  (Indep.)\nwhere E = ta>2B\ns2\n1\nn1\n+ s2\n2\nn2\n \n\t\nE = ta>2B\ns2p\nn1\n+\ns2p\nn2 1df = n1 + n2 - 22\n\t\ns2\np =\n1n1 - 12s2\n1 + 1n2 - 12s2\n2\n1n1 - 12 + 1n2 - 12\n(s1 and s2 unknown but assumed equal)\n\t\nE = za>2B\ns2\n1\nn1\n+ s2\n2\nn2\n\t\n(s1, s2 known)\nd - E 6 md 6 d + E  (Matched pairs)\n\t\nwhere E = ta>2\nsd\n1n \n1df = n - 12\nFormulas and Tables by Triola, Triola, and Roy\nCopyright 2018 Pearson Education, Inc.\nCh. 9: Test Statistics (two populations)\nz =\n1pn1 - pn22 - 1p1 - p22\nB\np q\nn1\n+ p q\nn2\n  Two proportions\np = x1 + x2\nn1 + n2\nt =\n1x1 - x22 - 1m1 - m22\nB\ns2\n1\nn1\n+ s2\n2\nn2\ndf = smaller of  \nn1 - 1, n2 - 1\n    \u0007Two means—independent; s1 and s2 unknown, and not  \nassumed equal.\nt =\n1x1 - x22 - 1m1 - m22\nB\ns2p\nn1\n+\ns2p\nn2\n \n1df = n1 +  n2 - 22\ns2\np =\n1n1 - 12s2\n1 + 1n2 - 12s2\n2\nn1 + n2 - 2\n    \u0007Two means—independent; s1 and s2 unknown, but  \nassumed equal.\nz =\n1x1 - x22 - 1m1 - m22\nB\ns2\n1\nn1\n+ s2\n2\nn2\n  \u0007Two means—independent;  \ns1, s2 known.\nt = d - md\nsd\n1n\n  Two means—matched pairs (df = n - 1)\nF = s2\n1\ns2\n2\n  \u0007Standard deviation or variance— \n\u0007two populations (where s2\n1 Ú s2\n2)\nCh. 10: Linear Correlation/Regression\nCorrelation r =\nnΣxy - 1Σx21Σy2\n2n1Σx22 - 1Σx2 22n1Σy22 - 1Σy2 2\n         or r =\ng1zx zy2\nn - 1   \u0007\nwhere \u0007zx = z score for x \nzy = z score for y\nSlope:  b1 =\nnΣxy - 1Σx21Σy2\nn 1Σx22 - 1Σx2 2  or b1 = r \nsy\nsx\ny-Intercept:\nb0 = y - b1x or  b0 =\n1Σy21Σx22 - 1Σx21Σxy2\nn 1Σx22 - 1Σx2 2\nyn = b0 + b1x  Estimated eq. of regression line\nr2 =\nexplained variation\ntotal variation\nse = B\nΣ1y - yn2 2\nn - 2\n or B\nΣy2 - b0Σy - b1Σxy\nn - 2\nyn - E 6 y 6 yn + E Prediction interval \nwhere E = ta>2se B1 + 1\nn +\nn1x0 - x2 2\nn1Σx22 - 1Σx2 2\nCh. 11: Goodness-of-Fit and Contingency Tables\nx2 = g\n1O - E2 2\nE\n  Goodness-of-fit (df = k - 1)\nx2 = g\n1O - E2 2\nE\n  Contingency table [df = (r - 1)(c - 1)]\n       where E =\n1row total21column total2\n1grand total2\nx2 =\n10 b - c0 - 12 2\nb + c\n  McNemar’s test for matched pairs 1df = 12\nCh. 12: One-Way Analysis of Variance\nProcedure for testing H0: m1 = m2 = m3 = c\n1.\t Use software or calculator to obtain results.\n2.\t Identify the P-value.\n3.\t Form conclusion:\nIf P-value … a, reject the null hypothesis  \n    of equal means.\nIf P-value 7 a, fail to reject the null hypothesis  \n    of equal means.\nCh. 12: Two-Way Analysis of Variance\nProcedure:\n1.\t Use software or a calculator to obtain results.\n2.\t Test H0: There is no interaction between the row factor and  \ncolumn factor.\n3.\t Stop if H0 from Step 2 is rejected.\nIf H0 from Step 2 is not rejected (so there does not appear to be an \ninteraction effect), proceed with these two tests:\n  Test for effects from the row factor.\n  Test for effects from the column factor.\n\nH =\n12\nN1N + 12\n aR2\n1\nn1\n+ R2\n2\nn2\n+ g + R2\nk\nnk\nb - 31N + 12\n    Kruskal-Wallis (chi-square df = k - 1)\nrs = 1 -\n6Σd2\nn1n2 - 12  Rank correlation\nacritical values for n 7 30: \n{ z\n1n - 1b\nFormulas and Tables by Triola, Triola, and Roy\nCopyright 2018 Pearson Education, Inc.\nCh. 13: Nonparametric Tests\nz =\n1x + 0.52 - 1n>22\n1n\n2\n  Sign test for n 7 25\nz =\nT - n 1n + 12>4\nB\nn 1n + 1212n + 12\n24\n \nTable A-6  \u0007Critical Values of the Pearson \nCorrelation Coefficient r\nn \na = .05\na = .01\n4\n.950\n.990\n5\n.878\n.959\n6\n.811\n.917\n7\n.754\n.875\n8\n.707\n.834\n9\n.666\n.798\n10\n.632\n.765\n11\n.602\n.735\n12\n.576\n.708\n13\n.553\n.684\n14\n.532\n.661\n15\n.514\n.641\n16\n.497\n.623\n17\n.482\n.606\n18\n.468\n.590\n19\n.456\n.575\n20\n.444\n.561\n25\n.396\n.505\n30\n.361\n.463\n35\n.335\n.430\n40\n.312\n.402\n45\n.294\n.378\n50\n.279\n.361\n60\n.254\n.330\n70\n.236\n.305\n80\n.220\n.286\n90\n.207\n.269\n100\n.196\n.256\nNOTE: To test H0: r = 0 (no correlation) against H1: r ≠0 (correlation), reject  \nH0 if the absolute value of r is greater than or equal to the critical value in the table.\nWilcoxon signed ranks  \n(matched pairs and n 7 30)\nz = R - mR\nsR\n=\nR -\nn11n1 + n2 + 12\n2\nB\nn1n21n1 + n2 + 12\n12\n \nWilcoxon rank-sum  \n(two independent  \nsamples)\nInferences about M: choosing between t and normal distributions\nt distribution:\ns not known and normally distributed population\nor\ns not known and n 7 30\nNormal distribution:\ns known and normally distributed population\nor\ns known and n 7 30\nNonparametric method or bootstrapping: Population not normally distributed and n … 30\n\nProcedure for \nHypothesis \nTests\nFinding P-Values\n8. Restate Decision in Nontechnical Terms\nRestate this previous decision in simple nontechnical terms, and \naddress the original claim.\n5. Identify the Test Statistic\nIdentify the test statistic that is relevant to the test and determine its \nsampling distribution (such as normal, t, chi-square).\n4. Select Signiﬁcance Level\nSelect the signiﬁcance level A based on the seriousness of a type I error. \nMake A small if the consequences of rejecting a true H0 are severe.\n \n• The values of 0.05 and 0.01 are very common.\n2. Give Symbolic Form\nGive the symbolic form that must be true when the original claim is false.\n1. Identify the Claim\nIdentify the claim to be tested and express it in symbolic form.\n3. Identify Null and Alternative Hypothesis\nConsider the two symbolic expressions obtained so far:\n \n• Alternative hypothesis H1 is the one NOT containing equality, so H1 uses \n \n the symbol . or , or Þ.\n \n• Null hypothesis H0 is the symbolic expression that the parameter equals\n \n the ﬁxed value being considered.\n7. Make a Decision\n• Reject H0 if P-value # a.\n• Fail to reject H0 if P-value . a.\n6. Find Values\nFind the value of the test statistic and \nthe P-value (see Figure 8-3). Draw a \ngraph and show the test statistic and \nP-value.\n7. Make a Decision\n• Reject H0 if the test statistic is in the\ncritical region.\n• Fail to reject H0 if the test statistic is \nnot in the critical region.\n6. Find Values\nP-Value Method\nCritical Value Method\nFind the value of the test statistic and \nthe critical values. Draw a graph \nshowing the test statistic, critical \nvalue(s) and critical region.\nIs the test\nstatistic to the\nright or left of\ncenter?\nLeft\nRight\nLeft-tailed\nRight-tailed\nP-value 5 twice the area to\nthe left of the test statistic\nP-value 5 area to the left\nof the test statistic\nP-value 5 twice the area to\nthe right of the test statistic\nP-value 5 area to the right\nof the test statistic\nWhat type\nof test?\nStart\n\nTable A-3  t Distribution: Critical t Values\n \n0.005\n \n0.01\nArea in One Tail \n0.025\n \n0.05\n \n0.10\nDegrees of \nFreedom\n \n0.01\n \n0.02\nArea in Two Tails \n0.05\n \n0.10\n \n0.20\n  1\n \n63.657\n    31.821\n    12.706\n6.314\n3.078\n  2\n9.925\n6.965\n4.303\n2.920\n1.886\n  3\n5.841\n4.541\n3.182\n2.353\n1.638\n  4\n4.604\n3.747\n2.776\n2.132\n1.533\n  5\n4.032\n3.365\n2.571\n2.015\n1.476\n  6\n3.707\n3.143\n2.447\n1.943\n1.440\n  7\n3.499\n2.998\n2.365\n1.895\n1.415\n  8\n3.355\n2.896\n2.306\n1.860\n1.397\n  9\n3.250\n2.821\n2.262\n1.833\n1.383\n10\n3.169\n2.764\n2.228\n1.812\n1.372\n11\n3.106\n2.718\n2.201\n1.796\n1.363\n12\n3.055\n2.681\n2.179\n1.782\n1.356\n13\n3.012\n2.650\n2.160\n1.771\n1.350\n14\n2.977\n2.624\n2.145\n1.761\n1.345\n15\n2.947\n2.602\n2.131\n1.753\n1.341\n16\n2.921\n2.583\n2.120\n1.746\n1.337\n17\n2.898\n2.567\n2.110\n1.740\n1.333\n18\n2.878\n2.552\n2.101\n1.734\n1.330\n19\n2.861\n2.539\n2.093\n1.729\n1.328\n20\n2.845\n2.528\n2.086\n1.725\n1.325\n21\n2.831\n2.518\n2.080\n1.721\n1.323\n22\n2.819\n2.508\n2.074\n1.717\n1.321\n23\n2.807\n2.500\n2.069\n1.714\n1.319\n24\n2.797\n2.492\n2.064\n1.711\n1.318\n25\n2.787\n2.485\n2.060\n1.708\n1.316\n26\n2.779\n2.479\n2.056\n1.706\n1.315\n27\n2.771\n2.473\n2.052\n1.703\n1.314\n28\n2.763\n2.467\n2.048\n1.701\n1.313\n29\n2.756\n2.462\n2.045\n1.699\n1.311\n30\n2.750\n2.457\n2.042\n1.697\n1.310\n31\n2.744\n2.453\n2.040\n1.696\n1.309\n32\n2.738\n2.449\n2.037\n1.694\n1.309\n33\n2.733\n2.445\n2.035\n1.692\n1.308\n34\n2.728\n2.441\n2.032\n1.691\n1.307\n35\n2.724\n2.438\n2.030\n1.690\n1.306\n36\n2.719\n2.434\n2.028\n1.688\n1.306\n37\n2.715\n2.431\n2.026\n1.687\n1.305\n38\n2.712\n2.429\n2.024\n1.686\n1.304\n39\n2.708\n2.426\n2.023\n1.685\n1.304\n40\n2.704\n2.423\n2.021\n1.684\n1.303\n45\n2.690\n2.412\n2.014\n1.679\n1.301\n50\n2.678\n2.403\n2.009\n1.676\n1.299\n60\n2.660\n2.390\n2.000\n1.671\n1.296\n70\n2.648\n2.381\n1.994\n1.667\n1.294\n80\n2.639\n2.374\n1.990\n1.664\n1.292\n90\n2.632\n2.368\n1.987\n1.662\n1.291\n100\n2.626\n2.364\n1.984\n1.660\n1.290\n200\n2.601\n2.345\n1.972\n1.653\n1.286\n300\n2.592\n2.339\n1.968\n1.650\n1.284\n400\n2.588\n2.336\n1.966\n1.649\n1.284\n500\n2.586\n2.334\n1.965\n1.648\n1.283\n1000\n2.581\n2.330\n1.962\n1.646\n1.282\n2000\n2.578\n2.328\n1.961\n1.646\n1.282\nLarge\n2.576\n2.326\n1.960\n1.645\n1.282\nCritical t value\n(negative)\na\nLeft tail\nCritical t value\n(positive)\na\nRight tail\nCritical t value\n(positive)\nCritical t value\n(negative)\na\u001f2\na\u001f2\nTwo tails\n\nTable A-2  Standard Normal (z) Distribution: Cumulative Area from the LEFT\nz\n.00\n.01\n.02\n.03\n.04\n.05\n.06\n.07\n.08\n.09\n-3.50 and \nlower\n \n.0001\n-3.4\n.0003\n.0003\n.0003\n.0003\n.0003\n.0003\n.0003\n.0003\n.0003\n.0002\n-3.3\n.0005\n.0005\n.0005\n.0004\n.0004\n.0004\n.0004\n.0004\n.0004\n.0003\n-3.2\n.0007\n.0007\n.0006\n.0006\n.0006\n.0006\n.0006\n.0005\n.0005\n.0005\n-3.1\n.0010\n.0009\n.0009\n.0009\n.0008\n.0008\n.0008\n.0008\n.0007\n.0007\n-3.0\n.0013\n.0013\n.0013\n.0012\n.0012\n.0011\n.0011\n.0011\n.0010\n.0010\n-2.9\n.0019\n.0018\n.0018\n.0017\n.0016\n.0016\n.0015\n.0015\n.0014\n.0014\n-2.8\n.0026\n.0025\n.0024\n.0023\n.0023\n.0022\n.0021\n.0021\n.0020\n.0019\n-2.7\n.0035\n.0034\n.0033\n.0032\n.0031\n.0030\n.0029\n.0028\n.0027\n.0026\n-2.6\n.0047\n.0045\n.0044\n.0043\n.0041\n.0040\n.0039\n.0038\n.0037\n.0036\n-2.5\n.0062\n.0060\n.0059\n.0057\n.0055\n.0054\n.0052\n.0051\n.0049\n.0048\n-2.4\n.0082\n.0080\n.0078\n.0075\n.0073\n.0071\n.0069\n.0068\n.0066\n.0064\n-2.3\n.0107\n.0104\n.0102\n.0099\n.0096\n.0094\n.0091\n.0089\n.0087\n.0084\n-2.2\n.0139\n.0136\n.0132\n.0129\n.0125\n.0122\n.0119\n.0116\n.0113\n.0110\n-2.1\n.0179\n.0174\n.0170\n.0166\n.0162\n.0158\n.0154\n.0150\n.0146\n.0143\n-2.0\n.0228\n.0222\n.0217\n.0212\n.0207\n.0202\n.0197\n.0192\n.0188\n.0183\n-1.9\n.0287\n.0281\n.0274\n.0268\n.0262\n.0256\n.0250\n.0244\n.0239\n.0233\n-1.8\n.0359\n.0351\n.0344\n.0336\n.0329\n.0322\n.0314\n.0307\n.0301\n.0294\n-1.7\n.0446\n.0436\n.0427\n.0418\n.0409\n.0401\n.0392\n.0384\n.0375\n.0367\n-1.6\n.0548\n.0537\n.0526\n.0516\n.0505\n.0495\n.0485\n.0475\n.0465\n.0455\n-1.5\n.0668\n.0655\n.0643\n.0630\n.0618\n.0606\n.0594\n.0582\n.0571\n.0559\n-1.4\n.0808\n.0793\n.0778\n.0764\n.0749\n.0735\n.0721\n.0708\n.0694\n.0681\n-1.3\n.0968\n.0951\n.0934\n.0918\n.0901\n.0885\n.0869\n.0853\n.0838\n.0823\n-1.2\n.1151\n.1131\n.1112\n.1093\n.1075\n.1056\n.1038\n.1020\n.1003\n.0985\n-1.1\n.1357\n.1335\n.1314\n.1292\n.1271\n.1251\n.1230\n.1210\n.1190\n.1170\n-1.0\n.1587\n.1562\n.1539\n.1515\n.1492\n.1469\n.1446\n.1423\n.1401\n.1379\n-0.9\n.1841\n.1814\n.1788\n.1762\n.1736\n.1711\n.1685\n.1660\n.1635\n.1611\n-0.8\n.2119\n.2090\n.2061\n.2033\n.2005\n.1977\n.1949\n.1922\n.1894\n.1867\n-0.7\n.2420\n.2389\n.2358\n.2327\n.2296\n.2266\n.2236\n.2206\n.2177\n.2148\n-0.6\n.2743\n.2709\n.2676\n.2643\n.2611\n.2578\n.2546\n.2514\n.2483\n.2451\n-0.5\n.3085\n.3050\n.3015\n.2981\n.2946\n.2912\n.2877\n.2843\n.2810\n.2776\n-0.4\n.3446\n.3409\n.3372\n.3336\n.3300\n.3264\n.3228\n.3192\n.3156\n.3121\n-0.3\n.3821\n.3783\n.3745\n.3707\n.3669\n.3632\n.3594\n.3557\n.3520\n.3483\n-0.2\n.4207\n.4168\n.4129\n.4090\n.4052\n.4013\n.3974\n.3936\n.3897\n.3859\n-0.1\n.4602\n.4562\n.4522\n.4483\n.4443\n.4404\n.4364\n.4325\n.4286\n.4247\n-0.0\n.5000\n.4960\n.4920\n.4880\n.4840\n.4801\n.4761\n.4721\n.4681\n.4641\nNOTE: For values of z below -3.49, use 0.0001 for the area.\n*Use these common values that result from interpolation:\nNEGATIVE z Scores\nz Score\nArea\n-1.645\n0.0500\n-2.575\n0.0050\n(continued )\n0\nz\n*\n*\n\nPOSITIVE z Scores\nTable A-2 (continued)  Cumulative Area from the LEFT\nz\n.00\n.01\n.02\n.03\n.04\n.05\n.06\n.07\n.08\n.09\n0.0\n.5000\n.5040\n.5080\n.5120\n.5160\n.5199\n.5239\n.5279\n.5319\n.5359\n0.1\n.5398\n.5438\n.5478\n.5517\n.5557\n.5596\n.5636\n.5675\n.5714\n.5753\n0.2\n.5793\n.5832\n.5871\n.5910\n.5948\n.5987\n.6026\n.6064\n.6103\n.6141\n0.3\n.6179\n.6217\n.6255\n.6293\n.6331\n.6368\n.6406\n.6443\n.6480\n.6517\n0.4\n.6554\n.6591\n.6628\n.6664\n.6700\n.6736\n.6772\n.6808\n.6844\n.6879\n0.5\n.6915\n.6950\n.6985\n.7019\n.7054\n.7088\n.7123\n.7157\n.7190\n.7224\n0.6\n.7257\n.7291\n.7324\n.7357\n.7389\n.7422\n.7454\n.7486\n.7517\n.7549\n0.7\n.7580\n.7611\n.7642\n.7673\n.7704\n.7734\n.7764\n.7794\n.7823\n.7852\n0.8\n.7881\n.7910\n.7939\n.7967\n.7995\n.8023\n.8051\n.8078\n.8106\n.8133\n0.9\n.8159\n.8186\n.8212\n.8238\n.8264\n.8289\n.8315\n.8340\n.8365\n.8389\n1.0\n.8413\n.8438\n.8461\n.8485\n.8508\n.8531\n.8554\n.8577\n.8599\n.8621\n1.1\n.8643\n.8665\n.8686\n.8708\n.8729\n.8749\n.8770\n.8790\n.8810\n.8830\n1.2\n.8849\n.8869\n.8888\n.8907\n.8925\n.8944\n.8962\n.8980\n.8997\n.9015\n1.3\n.9032\n.9049\n.9066\n.9082\n.9099\n.9115\n.9131\n.9147\n.9162\n.9177\n1.4\n.9192\n.9207\n.9222\n.9236\n.9251\n.9265\n.9279\n.9292\n.9306\n.9319\n1.5\n.9332\n.9345\n.9357\n.9370\n.9382\n.9394\n.9406\n.9418\n.9429\n.9441\n1.6\n.9452\n.9463\n.9474\n.9484\n.9495\n.9505\n.9515\n.9525\n.9535\n.9545\n1.7\n.9554\n.9564\n.9573\n.9582\n.9591\n.9599\n.9608\n.9616\n.9625\n.9633\n1.8\n.9641\n.9649\n.9656\n.9664\n.9671\n.9678\n.9686\n.9693\n.9699\n.9706\n1.9\n.9713\n.9719\n.9726\n.9732\n.9738\n.9744\n.9750\n.9756\n.9761\n.9767\n2.0\n.9772\n.9778\n.9783\n.9788\n.9793\n.9798\n.9803\n.9808\n.9812\n.9817\n2.1\n.9821\n.9826\n.9830\n.9834\n.9838\n.9842\n.9846\n.9850\n.9854\n.9857\n2.2\n.9861\n.9864\n.9868\n.9871\n.9875\n.9878\n.9881\n.9884\n.9887\n.9890\n2.3\n.9893\n.9896\n.9898\n.9901\n.9904\n.9906\n.9909\n.9911\n.9913\n.9916\n2.4\n.9918\n.9920\n.9922\n.9925\n.9927\n.9929\n.9931\n.9932\n.9934\n.9936\n2.5\n.9938\n.9940\n.9941\n.9943\n.9945\n.9946\n.9948\n.9949\n.9951\n.9952\n2.6\n.9953\n.9955\n.9956\n.9957\n.9959\n.9960\n.9961\n.9962\n.9963\n.9964\n2.7\n.9965\n.9966\n.9967\n.9968\n.9969\n.9970\n.9971\n.9972\n.9973\n.9974\n2.8\n.9974\n.9975\n.9976\n.9977\n.9977\n.9978\n.9979\n.9979\n.9980\n.9981\n2.9\n.9981\n.9982\n.9982\n.9983\n.9984\n.9984\n.9985\n.9985\n.9986\n.9986\n3.0\n.9987\n.9987\n.9987\n.9988\n.9988\n.9989\n.9989\n.9989\n.9990\n.9990\n3.1\n.9990\n.9991\n.9991\n.9991\n.9992\n.9992\n.9992\n.9992\n.9993\n.9993\n3.2\n.9993\n.9993\n.9994\n.9994\n.9994\n.9994\n.9994\n.9995\n.9995\n.9995\n3.3\n.9995\n.9995\n.9995\n.9996\n.9996\n.9996\n.9996\n.9996\n.9996\n.9997\n3.4\n.9997\n.9997\n.9997\n.9997\n.9997\n.9997\n.9997\n.9997\n.9997\n.9998\n3.50 and up\n.9999\nNOTE: For values of z above 3.49, use 0.9999 for the area.\n*Use these common values that result from interpolation:\nCommon Critical Values\nConfidence\nLevel\nCritical\nValue\n0.90\n1.645\n0.95\n1.96\n0.99\n2.575\nz Score\nArea\n1.645\n0.9500\n2.575\n0.9950\n*\n*\n0\nz\n\n",
  "first_page": "",
  "extracted_at": "2026-02-07T23:03:46.230603+00:00"
}